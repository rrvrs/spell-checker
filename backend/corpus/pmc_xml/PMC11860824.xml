<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006454</article-id><article-id pub-id-type="pmc">PMC11860824</article-id><article-id pub-id-type="doi">10.3390/s25041225</article-id><article-id pub-id-type="publisher-id">sensors-25-01225</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Smart Organization of Imbalanced Traffic Datasets for Long-Term Traffic Forecasting</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1239-5911</contrib-id><name><surname>Kara</surname><given-names>Mustafa M.</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8690-0725</contrib-id><name><surname>Turkmen</surname><given-names>H. Irem</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-2728-8900</contrib-id><name><surname>Guvensan</surname><given-names>M. Amac</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="c1-sensors-25-01225" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Yannis</surname><given-names>George</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Chen</surname><given-names>Chen</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01225">Computer Engineering Department, Yildiz Technical University, Istanbul 34220, T&#x000fc;rkiye; <email>mmkara@yildiz.edu.tr</email> (M.M.K.); <email>irem@yildiz.edu.tr</email> (H.I.T.)</aff><author-notes><corresp id="c1-sensors-25-01225"><label>*</label>Correspondence: <email>amac@yildiz.edu.tr</email></corresp></author-notes><pub-date pub-type="epub"><day>18</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1225</elocation-id><history><date date-type="received"><day>12</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>23</day><month>1</month><year>2025</year></date><date date-type="accepted"><day>30</day><month>1</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Predicting traffic speed is an important issue, especially in urban regions. Precise long-term forecasts would enable individuals to conserve time and financial resources while diminishing air pollution. Despite extensive research on this subject, to our knowledge, no publications investigate or tackle the issue of imbalanced datasets in traffic speed prediction. Traffic speed data are often biased toward high numbers because low traffic speeds are infrequent. The temporal aspect of traffic carries two important factors for low-speed value. The daily population movement, captured by the time of day, and the weather data, recorded by month, are both considered in this study. Hour-wise Pattern Organization and Month-wise Pattern Organization techniques were devised, which organize the speed data using these two factors as a metric with a view to providing a superior representation of data characteristics that are in the minority. In addition to these two methods, a Speed-wise Pattern Organization strategy is proposed, which arranges train and test samples by setting boundaries on speed while taking the volatile nature of traffic into consideration. We evaluated these strategies using four popular model types: long short-term memory (LSTM), gated recurrent unit networks (GRUs), bi-directional LSTM, and convolutional neural networks (CNNs). GRU had the best performance, achieving a MAPE (Mean Absolute Percentage Error) of 13.51%, whereas LSTM demonstrated the lowest performance, with a MAPE of 13.74%. We validated their robustness through our studies and observed improvements in model accuracy across all categories. While the average improvement was approximately 4%, our methodologies demonstrated superior performance in low-traffic speed scenarios, augmenting model prediction accuracy by 11.2%. The presented methodologies in this study are applied in the pre-processing steps, allowing their application with various models and additional pre-processing procedures to attain comparable performance improvements.</p></abstract><kwd-group><kwd>long-term traffic speed prediction</kwd><kwd>intelligent transportation systems</kwd><kwd>deep learning</kwd><kwd>data preprocessing</kwd><kwd>imbalanced datasets</kwd><kwd>data grouping</kwd><kwd>training enhancements</kwd></kwd-group><funding-group><award-group><funding-source>Scientific and Technological Research Council of Turkey (TUBITAK)</funding-source><award-id>TUBITAK1001-120E357</award-id></award-group><funding-statement>This work was supported by the Scientific and Technological Research Council of Turkey (TUBITAK) under the grant number TUBITAK1001-120E357.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01225"><title>1. Introduction</title><p>Traffic speed prediction is a crucial and longstanding research domain within Intelligent Transportation Systems (ITS) [<xref rid="B1-sensors-25-01225" ref-type="bibr">1</xref>]. Accurately predicting traffic speed has the potential to mitigate numerous severe issues, including extended travel times, a high incidence of accidents, and carbon emissions. Additionally, it benefits city planning and countless other ITS applications [<xref rid="B2-sensors-25-01225" ref-type="bibr">2</xref>]. The issue of speed prediction encompasses two fundamental characteristics. One of these characteristics pertains to the road network and the inter-dependencies among various route segments. A segment may precede or follow another segment with distinct characteristics or be entirely unconnected geographically yet exhibit nearly comparable patterns. Another element is temporality, which includes not just the periodicity of traffic influenced by the day of the week but also factors such as weather, special occasions, or recurring occurrences like the start of the school semesters. Initial research into this topic mostly concentrated on the temporal attributes of traffic, particularly the historical speed component, as they can be easily learned using statistics and basic machine learning models [<xref rid="B3-sensors-25-01225" ref-type="bibr">3</xref>]. Subsequently, with the progress in deep learning methodologies, increased integration of temporal and spatial features was employed, mostly together, to forecast traffic speed [<xref rid="B4-sensors-25-01225" ref-type="bibr">4</xref>].</p><p>Another aspect of traffic speed prediction that has evolved is the prediction horizon. The majority of research on this topic concentrates on short-term forecasts that operate within an acceptable margin of error, generally ranging from 15 to 60 min and extending to several hours [<xref rid="B5-sensors-25-01225" ref-type="bibr">5</xref>]. Over the years, we utilized not only thousands of hours of speed data for training but also integrated additional data such as weather [<xref rid="B6-sensors-25-01225" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-01225" ref-type="bibr">7</xref>], accidents [<xref rid="B8-sensors-25-01225" ref-type="bibr">8</xref>], holidays and special events [<xref rid="B9-sensors-25-01225" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-01225" ref-type="bibr">10</xref>], and road topography [<xref rid="B11-sensors-25-01225" ref-type="bibr">11</xref>]. These changes enabled predictions for days [<xref rid="B12-sensors-25-01225" ref-type="bibr">12</xref>] or even weeks [<xref rid="B13-sensors-25-01225" ref-type="bibr">13</xref>] ahead of time. Despite the incorporation of extra data sources, forecasting traffic speed one week in advance continues to be a challenging issue, with existing literature predominantly focused on short-term prediction research [<xref rid="B14-sensors-25-01225" ref-type="bibr">14</xref>]. Several studies addressing this issue [<xref rid="B12-sensors-25-01225" ref-type="bibr">12</xref>] typically possess a prediction horizon of one day and exclusively employ short-term forecasting methodologies, which may be inadequate for long-term predictions. A further complication with long-term speed forecasting is necessary for more historical data. In contrast to short-term prediction, which predominantly depends on immediate preceding data, known as short-term dependencies, long-term prediction is based on extensive past data and necessitates a greater volume of past data for accurate forecasting. This requirement also affects the resemblance of historical data used in the input to the predicted label because as the window of history lengthens, the similarities between previous and future data decrease.</p><p>A prevalent issue seen in both long-term and short-term forecasting is the presence of imbalanced datasets. Traffic speeds vary during the day, and although the nighttime traffic flow rate is significantly high, representing one-third of the day, the periods of congestion, characterized by reduced speed, are confined to a few hours. This disparity is present in every traffic dataset and impacts prediction accuracy. Our tests revealed that models designed for long-term predictions with a one-week horizon were adversely affected by this phenomenon. Predictions from models trained on four months&#x02019; worth of imbalanced historical speed data are typically greater than what should be expected at low traffic speeds.</p><p>Oversampling and undersampling techniques are prevalent in the literature for addressing the issue of imbalanced datasets. Undersampling approaches may lose effectiveness because they exclude crucial samples from the majority group, causing a bias against it [<xref rid="B15-sensors-25-01225" ref-type="bibr">15</xref>]. Conversely, oversampling presents certain drawbacks. Oversampling results in an enlarged training set due to the duplication of patterns, which consequently extends learning durations and elevates the likelihood of over-fitting [<xref rid="B16-sensors-25-01225" ref-type="bibr">16</xref>]. However, in our experiments, we discovered that these conventional methodologies are not effective when dealing with traffic speed data. Therefore, domain-specific strategies are utilized not only to alleviate dataset imbalance but also to acquire training data that accurately reflects the patterns of the samples to be forecasted.</p><p>This work presents three innovative ways to address the limitations of an imbalanced traffic dataset, hence enhancing the efficacy of long-term traffic speed prediction.</p><list list-type="bullet"><list-item><p>
<bold>Hour-wise Pattern Organization</bold>
</p><p>The hours of a day exhibit constant patterns regardless of external circumstances. Hour-wise Pattern Organization entails the categorization of patterns by dividing the day into distinct segments based on hours that exhibit analogous patterns, followed by the training of a model for each segment.</p></list-item><list-item><p>
<bold>Speed-wise Pattern Organization</bold>
</p><p>Training models at similar speeds enhances the model&#x02019;s ability to comprehend the relationships within the data. We conducted pattern organization by segmenting speed data with boundaries that encapsulate analogous patterns and trained a model for each of these clusters.</p></list-item><list-item><p>
<bold>Month-wise Pattern Organization</bold>
</p><p>Training models using immediate preceding months produces models that learn patterns that do not match the tested month (for example, using patterns from August to learn September). Month-wise Pattern Organization entails the structuring of patterns utilizing similar months for model training. This method can additionally be employed alongside both Speed-wise Patterns Organization and Hour-wise Pattern Organization to further enhance accuracy.</p></list-item></list><p>This work is, to our knowledge, the first research employing this type of organization to address imbalanced traffic dataset issues and enhance long-term traffic speed forecasting. The approaches presented in this research utilize traffic speed data exclusively to illustrate their adaptability for application with any model or dataset that may include supplementary variables. The proposed strategies are straightforward to adopt during the preprocessing step and do not negatively impact the training process, enhancing the accuracy at no cost. We demonstrate the impact of the proposed methods in our experimental results by using four models with established success in traffic speed prediction: LSTM, Bi-Directional LSTM, GRU, and CNN. This paper concentrates on preprocessing techniques aimed at enhancing long-term predictive performance. We have selected to experiment with the previously mentioned fundamental models. Firstly, to illustrate the efficacy of our methods across various models, and secondly, to validate our methods without the confounding influence of additional variables that complex models may introduce.</p><p>In the next section, we go over the research done in traffic speed prediction and review certain changes that happened in this domain. In <xref rid="sec3-sensors-25-01225" ref-type="sec">Section 3</xref>, we introduce the dataset used in this paper, while in <xref rid="sec4-sensors-25-01225" ref-type="sec">Section 4</xref> we explain the proposed techniques in detail and show the results by using a simple LSTM network for long-term speed prediction utilizing the traffic data collected from a metropolitan city, Istanbul. In <xref rid="sec5-sensors-25-01225" ref-type="sec">Section 5</xref>, we test our proposed methods with four different deep-learning architectures to show their effectiveness with different model types. In <xref rid="sec6-sensors-25-01225" ref-type="sec">Section 6</xref> we discuss our research and its short comings. And in the <xref rid="sec7-sensors-25-01225" ref-type="sec">Section 7</xref>, we conclude our work and give a discussion about how this research might evolve in the future.</p></sec><sec id="sec2-sensors-25-01225"><title>2. Literature Review</title><p>Traffic forecasting is an important subject in intelligent transportation systems. As it has become a popular topic, many studies with statistical methods were published at an early stage. Among these models, ARIMA (auto-regressive integrated moving average) has achieved the most success and remains a benchmark due to its ability to capture the periodicity of traffic data and its robustness to outliers. Ahmed et al. [<xref rid="B17-sensors-25-01225" ref-type="bibr">17</xref>] found that ARIMA worked very well when they compared it to other statistical models like moving average, double-exponential smoothing, and Trigg and Leach adaptive models. Later on, variations of ARIMA also became popular in literature. Van Der Voort et al. [<xref rid="B18-sensors-25-01225" ref-type="bibr">18</xref>] used ARIMA with Kohonen maps to divide days into different clusters and build an ARIMA model for each cluster. Although ARIMA has remained a hot topic among researchers, most of the attention has shifted to more complex models with the rise of machine learning algorithms. Researchers have extensively explored k-NN (k-nearest neighbor) and SVR (support vector regression) models for predicting traffic speed and flow [<xref rid="B19-sensors-25-01225" ref-type="bibr">19</xref>,<xref rid="B20-sensors-25-01225" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-01225" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-01225" ref-type="bibr">22</xref>,<xref rid="B23-sensors-25-01225" ref-type="bibr">23</xref>].</p><p>At some point, researchers started to think of traffic prediction as a non-linear problem, and with the availability of data increasing over the years, neural networks and deep learning methods became the focus of the traffic prediction problem. Refs. [<xref rid="B24-sensors-25-01225" ref-type="bibr">24</xref>,<xref rid="B25-sensors-25-01225" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-01225" ref-type="bibr">26</xref>] are early works exploiting neural networks for short-term traffic prediction. More recent papers [<xref rid="B27-sensors-25-01225" ref-type="bibr">27</xref>], have benefited from neural networks with ensemble model structures along with the average speed of the previous weeks.</p><p>Although neural network models could yield good results, they could hardly capture the complexity of traffic data, which has both spatial and temporal qualities. To capture such features, CNN and LSTM variants [<xref rid="B28-sensors-25-01225" ref-type="bibr">28</xref>] are widely utilized in current research studies. Refs. [<xref rid="B29-sensors-25-01225" ref-type="bibr">29</xref>,<xref rid="B30-sensors-25-01225" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-01225" ref-type="bibr">31</xref>] are early papers that used LSTMs. They didn&#x02019;t make many changes to the original LSTM model or add any new steps to prepare the data for LSTM to use it on traffic data. Due to the compatibility of LSTM and traffic data, even these types of models could produce better results than statistical or machine learning models. However, in recent years, researchers have employed various techniques to enhance prediction accuracy. GRU (Gated Recurrent Units) [<xref rid="B32-sensors-25-01225" ref-type="bibr">32</xref>] is a recurrent neural network model that works similarly to LSTM&#x02019;s but has a lower amount of variables to learn data relations. Fu et al. [<xref rid="B33-sensors-25-01225" ref-type="bibr">33</xref>] compared LSTM and GRU, and they found that GRU performed better than LSTM on traffic flow prediction. Another interesting change to the LSTM structure was the attention mechanism [<xref rid="B4-sensors-25-01225" ref-type="bibr">4</xref>,<xref rid="B11-sensors-25-01225" ref-type="bibr">11</xref>,<xref rid="B34-sensors-25-01225" ref-type="bibr">34</xref>,<xref rid="B35-sensors-25-01225" ref-type="bibr">35</xref>,<xref rid="B36-sensors-25-01225" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-01225" ref-type="bibr">37</xref>,<xref rid="B38-sensors-25-01225" ref-type="bibr">38</xref>,<xref rid="B39-sensors-25-01225" ref-type="bibr">39</xref>], which became a de facto technique for LSTMs and GRUs.</p><p>CNN, on the other hand, is better at capturing spatial properties in traffic data. Different road segments and their relations with each other significantly contribute to expediting prediction. However, defining the relationships between roads is necessary for this process. Earlier work using CNNs took this relation as a grid map to build this relation with the help of Euclidean. In a different way, Zang et al. [<xref rid="B40-sensors-25-01225" ref-type="bibr">40</xref>] use convolution layers in the Generative Adversarial Network(GAN) structure to predict daily speed through the generator. They then train the generator with a discriminator that compares real speed data with the generated data. To test this model, the authors used one year of data from two road segments and made predictions for the day after. They achieved a 32 MAE (Mean Absolute Error) in high-traffic, low-speed moments. Mendez et al. [<xref rid="B41-sensors-25-01225" ref-type="bibr">41</xref>] used CNN and Bi-LSTM together by using CNN to extract hidden temporal relations while making Bi-LSTM learn these relations. They were able to achieve an 8% improvement in prediction performance over a 3-day prediction horizon. Ma et al. [<xref rid="B42-sensors-25-01225" ref-type="bibr">42</xref>] uses a similar logic, but rather than using CNN for extracting spatial relations, a method called STFSA (spatial-temporal feature selection algorithm) is used instead. The CNN-GRU block then received the results of the STFSA as input.</p><p>Regular convolutional methods fail to grasp the nature of spatial information in traffic data. Since roads in a city build a graph, a grid cannot capture this complex relationship. Thus, Graph CNN (GCN) [<xref rid="B43-sensors-25-01225" ref-type="bibr">43</xref>,<xref rid="B44-sensors-25-01225" ref-type="bibr">44</xref>] were used extensively in traffic prediction. In [<xref rid="B12-sensors-25-01225" ref-type="bibr">12</xref>], graph convolution layers were exploited to guess traffic flow a day later with a MAPE (Mean Absolute Percentage Error) score of 10. Most recent models leverage temporality in conjunction with GCN to effectively capture these two characteristics. Bogaerts et al. [<xref rid="B45-sensors-25-01225" ref-type="bibr">45</xref>] find similarities to roads before training; it first uses a GCN to learn these spatial relationships and then uses LSTM to capture temporal information. Han et al. [<xref rid="B46-sensors-25-01225" ref-type="bibr">46</xref>] use daily traffic data to find other similar roads and apply this similarity to quantify the effect of each road on the predicted part of the day. Chen et al. [<xref rid="B47-sensors-25-01225" ref-type="bibr">47</xref>] used visual data to quantify traffic flow and then used GCN and GRU to extract spatial and temporal features. In their work, they utilized downflow information to predict sudden changes in the traffic and managed to improve prediction accuracy on 30-min predictions by 17% compared to state-of-the-art models. Qi et al. [<xref rid="B48-sensors-25-01225" ref-type="bibr">48</xref>] used environmental variables along with temporal variables and then used a spatio-temporal graph convolutional network for predicting traffic speed 3 h later. They managed to outperform other spatio-temporal graph models by 5% in their experiments.</p><p>Relationships (similarities) between the roads are hard to find with statistical methods. Kara et al. [<xref rid="B49-sensors-25-01225" ref-type="bibr">49</xref>] used a variation of the k-nearest neighbor algorithm to find similar road segments in order to fill missing values. State-of-the-art models, on the other hand, utilize dynamic correlation between roads and learn this relationship while training a prediction model. In [<xref rid="B11-sensors-25-01225" ref-type="bibr">11</xref>], researchers used a dataset from 2015 that has speed values for 5-min windows. They used a model that is a mix of GRU and Graph Convolution Layers, and it learns from its own attention how the k-hop neighbors affect the current road segment. It predicts 60 min ahead with a MAPE value of 2. In another study, an attention mechanism is employed to identify road relations [<xref rid="B38-sensors-25-01225" ref-type="bibr">38</xref>]. However, unlike other papers, it does not define a connected graph but learns the relations of every road on the map. Wang et al. [<xref rid="B50-sensors-25-01225" ref-type="bibr">50</xref>] use a similar idea but with the addition of a multi-scale attention module to also extract the temporal relations and then combine it with the dynamic spatial relations. Qui et al. [<xref rid="B51-sensors-25-01225" ref-type="bibr">51</xref>] developed a graph model that takes events into account for traffic speed prediction that achieved an 8.09% MAPE score for a two-hour prediction.</p><p>We have so far discussed the history of speed prediction techniques. However, our analysis of traffic speed data revealed that the distribution of speed values leads to a significant issue known as the data imbalance problem, which poses a significant challenge for the deep learning domain. In the real world, it is common to encounter such imbalances across various datasets, specially collected by sensors. There are two methods frequently employed to deal with this problem. Both of these methods involve modifying the dataset. Undersampling is a method that selects samples to ensure an equal or balanced distribution of classes [<xref rid="B16-sensors-25-01225" ref-type="bibr">16</xref>], or continuous labels in regression problems. The other method is called oversampling, where new samples are produced using existing samples through different methods [<xref rid="B52-sensors-25-01225" ref-type="bibr">52</xref>].</p><p>A widely utilized oversampling technique is the Synthetic Minority Oversampling Technique (SMOTE) [<xref rid="B53-sensors-25-01225" ref-type="bibr">53</xref>] for imbalanced classification issues and the Synthetic Minority Over-Sampling Technique for Regression (SMOTER) [<xref rid="B54-sensors-25-01225" ref-type="bibr">54</xref>] for imbalanced regression problems. SMOTE employs statistical methods to generate more samples for the minority class. Throughout the years, various iterations of these techniques have been published in the literature, each with distinct focuses, such as Gavas et al. [<xref rid="B55-sensors-25-01225" ref-type="bibr">55</xref>], who incorporated spatial information to balance the dataset, and Camocho et al. [<xref rid="B56-sensors-25-01225" ref-type="bibr">56</xref>], who developed weights for each sample based on their rarity to use in SMOTER calculations. Despite the widespread application of these oversampling strategies, their efficacy is not universally applicable. Avelino et al. conducted a survey comparing resampling approaches, including SMOTER and its modifications, over 30 distinct imbalanced datasets. Two conclusions may be drawn from the findings of this paper: first, in numerous instances, the absence of a balancing strategy yielded the highest accuracy; second, the optimal resampling technique varied depending on the dataset, indicating that no universal strategy exists. These conclusions indicate that data balance is significantly influenced by the dataset and the context of the prediction problem.</p><p>The advancement of data creation techniques, such as variational autoencoders (VAEs) and GAN models, has shifted the emphasis regarding oversampling and data augmentation strategies toward deep learning methodologies. Abdulganiyu et al. utilized a combination of class-wise focal loss and variational autoencoder for data augmentation on network traffic data. Engelmann et al. [<xref rid="B57-sensors-25-01225" ref-type="bibr">57</xref>] employed Conditional Wasserstein GAN for oversampling, whereas Fan et al. [<xref rid="B58-sensors-25-01225" ref-type="bibr">58</xref>] utilized CycleGAN for data augmentation. Sharma et al. utilized a hybrid approach that integrates GAN and SMOTE methodologies. The authors first use SMOTE to generate synthetic samples and then employ a GAN model to enhance the quality of these artificial samples. This approach effectively integrates both techniques to overcome their respective limitations. While data generation methods effectively balance datasets, they are not well suited for the domain of traffic speed prediction. Traffic speed datasets are too small to train data-generating models such as GANs. The lack of data lowers the quality of synthetic data, and the low number of minority classes in traffic speed datasets makes it even harder for models to find underlying patterns in traffic, which results in synthetic data that are not realistic.</p><p>Alternative approaches for addressing unbalanced datasets employ various strategies that do not involve balancing the dataset, which include specific models or training processes that mitigate bias. Guo et al. [<xref rid="B59-sensors-25-01225" ref-type="bibr">59</xref>] used a focal loss-based approach for adaptive gradient boosting. Ren et al. [<xref rid="B60-sensors-25-01225" ref-type="bibr">60</xref>] employed a modified Mean Squared Error (MSE) to address the imbalanced dataset, whereas Steininger et al. [<xref rid="B61-sensors-25-01225" ref-type="bibr">61</xref>] developed weights for samples based on their rarity; however, instead of applying these weights in a technique such as SMOTER, the authors utilized them to adjust the loss value for each sample.</p><p>Domain-specific balancing methods are necessary in all domains but especially traffic speed prediction. Furthermore, the distinction in methodology that is required when it comes to long- and short-term predictions extends to this problem. Since the same reasons that limit the effectiveness of short-term prediction methods for long-term forecasting also apply, similar concerns should be addressed in the context of data balancing strategies. However, the current traffic speed prediction literature primarily focuses on models that extract the best spatio-temporal features rather than addressing the inherent problems in the traffic speed datasets. Few papers that specifically focus on this problem either try to tackle it for accidents and anomalies in the dataset [<xref rid="B62-sensors-25-01225" ref-type="bibr">62</xref>] or focus on short-term predictions [<xref rid="B63-sensors-25-01225" ref-type="bibr">63</xref>,<xref rid="B64-sensors-25-01225" ref-type="bibr">64</xref>]. To the best of our knowledge, we are the first research that focuses on the data imbalance problem for long-term traffic speed predictions. Our proposed methodology does not involve removing or creating samples but focuses on reorganizing the training dataset to extract useful patterns and increase the learning capacity of the prediction model. We propose three different ways to reorganize the dataset: hour-wise, to emphasize hourly characteristics; speed-wise, to emphasize the temporal relations of speed values; and month-wise, to emphasize seasonal changes brought about by weather. Our methods serve as a preprocessing step, allowing for compatibility with various model types and other preprocessing steps. This flexibility and robustness enable them to seamlessly integrate with various methodologies and features without incurring additional computation costs.</p></sec><sec id="sec3-sensors-25-01225"><title>3. Dataset</title><p>All experiments were conducted using a traffic speed dataset gathered by the Istanbul Municipality in 2018. <xref rid="sensors-25-01225-t001" ref-type="table">Table 1</xref> presents the specifications of the dataset. This dataset contains traffic speed data, dates, and location information for 441 primary road segments in Istanbul, all segments averaging 1 km in length. A total of 111 segments were chosen from 441 segments to reduce the training time. The selection involved choosing one from four successive segments, enabling an accurate and equitable representation.</p><p>All data were gathered at one-minute intervals. Each road segment comprises 525,600 traffic speed data points. Certain data were absent due to sensor errors. To address the missing data and enhance the accuracy of our prediction problem [<xref rid="B65-sensors-25-01225" ref-type="bibr">65</xref>], we modified the data interval to 5-minute segments by averaging 5-minute windows. Following this step, we employed a moving average window of size 6, containing data from the preceding 30 min, to impute the remaining missing values. Given the minimal missing values, we eliminated them from the training and testing datasets. Given that traffic patterns are consistent on the same weekdays, our dataset comprises the last 6 weeks of data corresponding to the specific day of the week. All models in the methodology and the experiment results were trained to forecast up to one week ahead utilizing historical data from the preceding six weeks, including 15 min before and after the predicted time. It is important to note that the train data have traffic speed values weeks before the label data; therefore, using 15 min after the expected time of day does not result in a data leak.</p></sec><sec sec-type="methods" id="sec4-sensors-25-01225"><title>4. Methodology</title><p>Traffic speed prediction is based on the periodic characteristics of traffic, and models designed for this problem attempt to capture this by utilizing previous speed data or supplementary variables such as the date. The more the model learns these features, the better the forecast results will be. To improve results, training models for common patterns is a feasible choice. Previous research on traffic prediction lacks data to measure such similar patterns. The current practice in the literature ([<xref rid="B11-sensors-25-01225" ref-type="bibr">11</xref>,<xref rid="B38-sensors-25-01225" ref-type="bibr">38</xref>], etc.) is to find similarities between road segments to achieve successful model training. This study presents three distinct ways of representing the general characteristics of traffic data. The fundamental concept underlying these three strategies is to identify similar historical data and categorize them to highlight traffic trends. These organizational schemes are predicated on temporal factors, velocity, and monthly data. To demonstrate their efficacy, the proposed methodologies are compared to a base model with no pattern -rganizing procedure applied to it.</p><p><xref rid="sensors-25-01225-f001" ref-type="fig">Figure 1</xref> presents a general overview of the proposed methodology. The process starts with an imbalanced traffic speed dataset. This dataset is then organized according to one of the three proposed methods. It is worth noting that these strategies can be combined, as stated in the introduction. Following the determination of the methodology to be employed, a more balanced dataset is produced, which has been divided into different groups, each of which exhibits similar characteristics. After pattern organization, model training occurs on the balanced dataset. In this paper, we experimented with four different deep learning models: LSTM, CNN, bi-directional LSTM, and GRU, although our methods are applicable to other machine learning and deep learning models as well. After model training, generated models were collected into a pool. The test data are processed using the chosen pattern organization technique to balance the dataset and are then assigned to the most suitable model, trained on data with characteristics similar to the test sample. Following the model selection, we obtain the predicted traffic speed value.</p><p>The proposed methods categorize the dataset according to three strategies: Hour-wise, Speed-wise and Month-wise Pattern Organization. Each strategy relies on separating the dataset into tailor-made groups that have high in-class consistency and the capacity to adequately represent the general characteristics of the group. In the training phase, a separate prediction model is created for each group. In the testing phase, samples are assigned to the model based on the features utilized to form distinct groups. The Hour-wise Pattern Organization utilizes the time-of-day feature to form five distinct groups. This approach organizes the dataset into discrete categories according to the hour of sampling. Samples are segregated identically during both the training and testing phases. In the context of speed-based pattern organization, the data were divided into four distinct groups. During the training phase, the label values were utilized to establish separate groups; however, in the testing phase, where direct label usage is not permitted, the average of the input speed values was employed to select the most appropriate prediction model. We also establish overlapping groups in the training phase to ensure that distinct models created for each speed group also incorporate samples from other speed groups, should there be a need to forecast such volatile samples. Month-wise Pattern Organization identifies the most similar months for training, ensuring that the training and test datasets exhibit similar characteristics. Our suggested methodology achieves this by creating a representation for each month and making comparisons among them. After identifying similar months, we trained a model for each month using the most similar months.</p><p>Both Mean Absolute Percentage Error (MAPE) and Mean Absolute Error (MAE) are widely utilized metrics to illustrate the performance results of forecasting algorithms. We noticed that MAPE values provide a more accurate representation of model performance, as they emphasize errors occurring during peak traffic periods. Consequently, we chose MAPE to demonstrate the efficacy of our approach.<disp-formula id="FD1-sensors-25-01225"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>MAE</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD2-sensors-25-01225"><label>(2)</label><mml:math id="mm2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>MAPE</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD3-sensors-25-01225"><label>(3)</label><mml:math id="mm3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Loss</mml:mi><mml:mspace width="4.pt"/><mml:mi>Function</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mo>&#x02217;</mml:mo><mml:mi>MAPE</mml:mi><mml:mo>+</mml:mo><mml:mi>MAE</mml:mi></mml:mrow><mml:mn>4</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>During the training process, we employed a combination of MAE and MAPE metrics. We have tested each separately and noted that using them individually results in each of these error rates introducing bias into the model. The formulas for these two measures are presented in Equations (<xref rid="FD1-sensors-25-01225" ref-type="disp-formula">1</xref>) and (<xref rid="FD2-sensors-25-01225" ref-type="disp-formula">2</xref>). These equations provide insight into the cause of the bias. MAE values represent the absolute disparity between the actual and projected sequences. The MAPE metric, on the other hand, computes an error rate that is proportional to the real value. Consequently, MAPE has an elevated error rate when the real values are lower. When utilized as a loss function, this contrast causes MAE-trained models to output higher values and MAPE-trained models to output lower values. In light of this bias, we have opted to build a custom loss function that integrates both measures. The proposed custom loss function is presented in Equation (<xref rid="FD3-sensors-25-01225" ref-type="disp-formula">3</xref>). We utilize several coefficients in our calculations to assign greater significance to the MAPE score. We have noted that the implementation of this custom loss function achieved less bias in the trained models.</p><p>The results presented in this section are obtained from LSTM-based models. These models have a single LSTM layer, followed by a dense layer and an output layer. The LSTM layer has 256 hidden units, whereas the dense layer has 128. Each layer incorporates a dropout layer with a dropout rate of 0.4. The dense layer undergoes batch normalization, whereas the LSTM layer does not.</p><sec id="sec4dot1-sensors-25-01225"><title>4.1. Training Models with Hour-Wise Pattern Organization</title><p>The most clear trend that traffic data shows is related to the time of day. The most prominent illustration of this trend is the rush hours, which lead to significant traffic congestion irrespective of the day of the week. Another case is nighttime, when no traffic congestion can be seen. While weather and special occasions create variations, such diversions primarily influence the magnitude of speed rather than its exhibited pattern.</p><p><xref rid="sensors-25-01225-f002" ref-type="fig">Figure 2</xref> illustrates that specific periods in a day exhibit similar characteristics. Consequently, we decided to partition 24 h into five distinct intervals. The initial period spans from 05:40 to 09:40, the subsequent period extends from 09:40 to 14:00, the third period lasts from 14:00 to 19:00, the fourth period ranges from 19:00 to 22:00, and the final period occurs from 22:00 to 05:40. We created these subsets to separate increasing and decreasing characteristics so that models could learn them more effectively. <xref rid="sensors-25-01225-f003" ref-type="fig">Figure 3</xref> presents the percentage of data corresponding to each of these temporal subsets. For each of the five periods, a distinct model was used, and to forecast a specific hour of the day, the model corresponding to the hour in question was applied.</p><p>An illustration of this procedure is depicted in <xref rid="sensors-25-01225-f004" ref-type="fig">Figure 4</xref>. This graphic displays a matrix including six rows of data from the past week and seven columns representing 30 min intervals of traffic speed data. Furthermore, the labels of these samples and their corresponding dates are also included in the same figure. Based on the temporal data of the associated sample, we determine the time group and which model these samples will train and test. In this instance, samples were collected at approximately 12 p.m., categorizing them under the Noon Model, which includes the hours from 10 a.m. to 2 p.m.</p><p>To evaluate the performance of this method, a model is trained on the entire dataset, and the outcomes are compared to those of a model trained using the proposed technique. <xref rid="sensors-25-01225-t002" ref-type="table">Table 2</xref> presents the outcomes of the base LSTM model and the results of the suggested pattern-organizing techniques. Hour-wise Pattern Organization improved normal training MAPE by only 0.2%. <xref rid="sensors-25-01225-f005" ref-type="fig">Figure 5</xref> presents the data obtained on an hourly basis. The upper graphic illustrates a comparison between the normal training process using an LSTM model and the proposed Hour-wise Pattern Organization training approach. The lower graphic shows the disparity between these two training methodologies, with green areas denoting the intervals during which Hour-wise Pattern Organization has surpassed the normal training procedure, and red areas showing where it has underperformed. This figure reveals that, despite a low average improvement, there is a significant improvement of 0.8 percent MAPE during peak rush hours.</p></sec><sec id="sec4dot2-sensors-25-01225"><title>4.2. Training Models with
Speed-Wise Pattern Organization</title><p>Traffic speed datasets have an intrinsic imbalance, with low-speed samples comprising merely 11% of the overall data. <xref rid="sensors-25-01225-f006" ref-type="fig">Figure 6</xref> illustrates the speed distribution of our dataset. The spike at 60 km/h is because of the default value assigned in the speed collection process. <xref rid="sensors-25-01225-f007" ref-type="fig">Figure 7</xref> illustrates the percentages of low-, normal-, and high-density traffic states. This imbalance complicates learning from these datasets, and most models predict greater values than usual speeds. To address this issue, we trained various models according to distinct speed categories. The primary idea behind this strategy is to divide the dataset into speed groups and then train a separate model for each group. The key aspect of this process involves determining the speed limits. Two significant issues must be considered. The initial issue is the volume of data inside each group. Because deep learning methods require a particular quantity of data, if a group has insufficient training samples, the outcomes will be poor. The second part is more complicated since it includes the volatile nature of traffic speed data. Traffic speeds, particularly at lower sampling frequencies such as 5 or 15 min, can fluctuate fast, so there may be underperformance on border speeds when establishing groups with rigid boundaries. For instance, a model designed for predicting speeds ranging from 60 to 80 will have numerous samples labeled 55 or 85. Consequently, boundaries must be adaptable to accommodate such samples.</p><p>Determining the boundaries for this method requires consideration of two factors: the volume of data within each speed group and the data&#x02019;s volatility. The objective is to achieve a uniform percentage of data across each group, ensuring that all groups possess a comparable volume of data. Additionally, each group must include sufficient data for a deep-learning model. Volatility can be controlled by utilizing overlaps among speed groups. An overlap arises when the average of input data, comprising 30 min of data from six weeks before the labeled speed, which serves as the input matrix for our models, is categorized into a different speed group than the label itself. This sample is considered an overlap between the two-speed groups.</p><p>The train and test phases have distinct objectives concerning overlaps. We aim for minimal overlaps in test samples to ensure that models predict speeds specific to that group. However, we require a significant degree of overlap in the training dataset to enhance the robustness of the trained model against the overlaps present in the test samples. Training models to achieve robustness against different labels is important; however, it is essential to recognize that the primary objective of this approach is to minimize variations in traffic characteristics within each model and to isolate these characteristics effectively. Thus, the overlap in a dataset should be limited, as excessive overlap would require the model to learn multiple traffic characteristics. Our analysis indicated that the 10 km/h range includes sufficient overlaps to enhance model robustness while excluding other traffic characteristics. The analyses were conducted using the training dataset to prevent data leakage between the training and testing datasets. Due to the differing priorities in the creation of train and test datasets, we utilized two distinct sets of boundaries for their formation, as illustrated in <xref rid="sensors-25-01225-f008" ref-type="fig">Figure 8</xref>.</p><list list-type="bullet"><list-item><p><italic toggle="yes">Pattern Organization of Train Samples</italic>:</p><p>We divided training samples along intersecting boundaries to enhance the robustness of trained models against the aforementioned volatility. The values used in this process were the labels of training samples. For instance, in <xref rid="sensors-25-01225-f008" ref-type="fig">Figure 8</xref>, the input sample with a value of 68 is categorized within two intersecting groups: the light-traffic model, defined by boundaries of 50 and 90, and the medium-traffic Model within the boundaries of 40 and 70. Both models will use this sample during the training phase. The intersecting boundaries enhance the trained model&#x02019;s capacity to predict values beyond initial boundaries and increase the sample size for model training.</p></list-item><list-item><p><italic toggle="yes">Pattern Organization of Test Samples</italic>:</p><p>Following the training phase, it is important to assign test samples to the model that fits them. Unlike the training phase, we cannot use labels for this choice. To make this choice, we use the historical data in the input matrix. We calculate the average of all historical data used as input values and determine the corresponding model based on this average. The training process is characterized by independent boundaries that do not intersect. For instance, in <xref rid="sensors-25-01225-f008" ref-type="fig">Figure 8</xref>, the average of the input matrix is computed as 64.2, corresponding solely to the Light Traffic Model. We employ this speed group model for our final prediction.</p></list-item></list><p>In our dataset, we established the boundaries illustrated in <xref rid="sensors-25-01225-f009" ref-type="fig">Figure 9</xref>, which shows the percentage of samples within each group. The upper section of the figure illustrates the division of test samples. Each bar indicates a speed range of 10 km/h, with the percentage value reflecting the number of samples within that speed range. The colors of these bars indicate the categories assigned to the respective ranges. Red, yellow, light green, and dark green correspond to heavy traffic, medium traffic, light traffic, and no traffic, respectively. No overlap can be observed in the prediction of test samples. The lower section of the figure illustrates the division of the training samples. Each bar continues to represent a speed range of 10 km/h. The bar colors in this figure represent the same groups as in the upper figure. Numerous overlaps can be observed in this figure. For example, when making predictions, a traffic flow of 50&#x02013;60 km/h represents a medium traffic state; however, in training, we use data within this range for heavy, medium, and light traffic states.</p><p><xref rid="sensors-25-01225-t002" ref-type="table">Table 2</xref> presents the results of speed-wise organization achieved using an LSTM network. The analysis of these results indicates that this method improved MAPE by 0.5 units, representing a 4% enhancement. <xref rid="sensors-25-01225-f010" ref-type="fig">Figure 10</xref> presents the hourly MAPE results for both the base method and the model trained using Speed-wise Pattern Organization. The graphic demonstrates that our method resulted in a 1.0 MAPE score improvement during morning rush hours, with a gain of 2.8 MAPE score observed in the evening rush hours, representing an 11% increase over the previously recorded MAPE score during that period.</p></sec><sec id="sec4dot3-sensors-25-01225"><title>4.3. Training Models with Month-Wise Pattern Organization</title><p>Studies in the literature primarily use the months preceding the test month to train a model, particularly for long-term predictions. Two prevalent strategies are employed for the pre-processing of training datasets. The first method involves a random division of the dataset into training and testing subsets, whereas the second method utilizes the preceding consecutive months as training data. Despite their widespread application, these approaches fail to account for the variations in traffic characteristics over different months. The former strategy is mainly used due to insufficient data, while the latter is used because of the scarcity of research examining the commonalities between months.</p><p><xref rid="sensors-25-01225-f011" ref-type="fig">Figure 11</xref> depicts the speed data for five consecutive months, starting in May and ending in September. This graphic elucidates the disparities between these months, particularly between September and August. Although these months are sequential, it is crucial to recognize that they are the most different within this figure. This distinction extends not only to speed but also to weather patterns, with August being one of the driest months in Istanbul and September being typically rainy and windy. This difference extends into June and July, but May appears most comparable due to its predominantly rainy conditions in Istanbul. Furthermore, schools are open in June and September, while many individuals take vacations in July and August.</p><p>This disparity is also evident in the MAPE scores obtained from regular speed prediction training. <xref rid="sensors-25-01225-f012" ref-type="fig">Figure 12</xref> illustrates the MAPE scores of an LSTM model trained to forecast one month based on the preceding four months. This graphic illustrates that transitional months between seasons have higher MAPE scores compared to months that closely resemble their preceding months.</p><p><xref rid="sensors-25-01225-f013" ref-type="fig">Figure 13</xref> illustrates the method of the proposed Month-wise Pattern Organization. We create histograms to determine the similarity between months. This approach effectively captures the distribution of speed data, serving as a reliable representation of traffic. To enhance the representation of temporal patterns, we generate seven histograms for each month, encompassing daily speed data for every day of the week; therefore, we mitigate the influence of distinct patterns associated with each day. The histogram bins start at the minimum speed limit of 10 in our dataset and extend to the maximum speed limit of 132, increasing by 5 at each interval. All values from 441 segments have been merged into these histograms. For each day of the week, we calculate the average of the corresponding 5-minute readings, totaling 288 values per day (24 &#x000d7; 60/5).</p><p><xref rid="sensors-25-01225-f014" ref-type="fig">Figure 14</xref> presents the average histograms for April and August. The numbers depicted in this image are the mean values of the seven histograms generated and used for similarity assessment. We present the histograms of these two months that overlapped to highlight the differences between them. April exhibits lower average speed numbers, whereas August demonstrates higher average speed values. August does not exhibit any average values below 20. This does not imply that speed values below 20 were not observed in August, but that, on average, August does not exhibit traffic speed values below 20. We employed the Euclidean Distance Method to quantify the distance. When looking for similar months, we compared the 12 months preceding each one. For instance, March 2018 was analyzed in relation to the preceding months, extending back to March 2017.</p><p><xref rid="sensors-25-01225-f015" ref-type="fig">Figure 15</xref> illustrates a heat map depicting the distance between different months. This heat map corroborates our hypothesis that specific months differ from their preceding months. Specifically, September is found to be more similar to May and April than to the preceding month, August. <xref rid="sensors-25-01225-t003" ref-type="table">Table 3</xref> presents the six most similar months for each month of the year. The suggested Month-wise Pattern Organization led to a 0.1 unit increase in MAPE compared to a baseline model that did not have pattern organization, as shown in <xref rid="sensors-25-01225-t002" ref-type="table">Table 2</xref>.</p></sec></sec><sec id="sec5-sensors-25-01225"><title>5. Experimental Results</title><p>This section assesses the efficacy of three proposed pattern organization approaches and the hybrid approach combining speed-wise pattern organization with month-wise pattern organization methods. The examination involves comparing our methods with widely-used deep learning models against their baseline counterparts that do not include any pattern organization techniques.</p><sec id="sec5dot1-sensors-25-01225"><title>5.1. Experimental Setup</title><p>To prove the effectiveness of our pattern organization schemes for the long-term success of traffic flow prediction, we exploit four well-known deep learning models, CNN, LSTM, Bi-Directional LSTM, and GRU.</p><p><xref rid="sensors-25-01225-t004" ref-type="table">Table 4</xref> gives a summary of the hyperparameters employed in our experiments. The second column of this table presents the range of values examined using the grid-search technique to identify the optimal values specified in the corresponding columns for each model type. Our CNN model has two convolutional layers with ReLU (rectified linear unit) activation, both of which are batch-normalized and employ the dropout technique. Subsequent to the convolutional layers, an average pooling layer and a batch-normalized dense layer are employed, along with the application of the dropout technique. Each convolutional layer contains 128 kernels, while the dense layer has 128 hidden nodes. There is a single recurrent neural network layer in LSTM, Bi-Directional LSTM, and GRU. This is followed by a dense layer and an output layer. The LSTM layer comprises 256 units, whereas the bi-directional and GRU layers consist of 512 units each. All of these fundamental model types employ dropout and kernel regularization. We perform batch normalization after each dense layer.</p><p>The models in this research were trained on a server equipped with an A5000 GPU (Graphics Processing Unit). On average, training each model for 111 road segments required roughly one day. This indicates that each part underwent training for roughly 13 min. We used early stopping, which allowed each model to undergo training for a varying number of epochs; on average, each model underwent training for 800 to 1500 epochs with a batch size of 2048. Conversely, evaluating a sample requires less than a second, so the system&#x02019;s performance is satisfactory for practical application.</p></sec><sec id="sec5dot2-sensors-25-01225"><title>5.2. Experimental Results for Proposed Pattern Organization Methods</title><p><xref rid="sensors-25-01225-f016" ref-type="fig">Figure 16</xref> illustrates the MAPE results of the proposed pattern organizations implemented on popular deep learning models, LSTM, CNN, Bi-directional LSTM, and GRU. The outcomes of our proposed methods are compared with those of a baseline model that does not utilize pattern organization prior to training. Each proposed approach is examined independently, and additionally, a test was performed to evaluate the compatibility of Month-wise Pattern Organization with Speed-wise Pattern Organization when utilized simultaneously.</p><p>The analysis of hourly pattern organization in <xref rid="sensors-25-01225-f017" ref-type="fig">Figure 17</xref> shows that the LSTM and bi-directional models perform better than the base model at all times. CNN, on the other hand, only performs better in the evening and worsens during the other hours, while GRU consistently performs worse at all times.</p><p>In terms of Speed-wise Pattern Organization, <xref rid="sensors-25-01225-f016" ref-type="fig">Figure 16</xref> illustrates that every model type exhibits improvement, albeit the extent of this improvement varies among different model types. LSTM exhibits a greater enhancement than the other model types, achieving a percentage increase of 4, whereas CNN demonstrates the least improvement, with a percentage increase of 2.5. The CNN&#x02019;s incapacity to learn from smaller datasets may account for this outcome. Although GRU has only enhanced by 3.2%, this improvement occurred at elevated MAPE values, indicating that it has acquired more substantial information.</p><p><xref rid="sensors-25-01225-f018" ref-type="fig">Figure 18</xref> demonstrates that while the MAPE improvement appears minor on average, it is substantially greater in high-traffic points, demonstrating the effectiveness of our strategy. All trained model types exhibit similar improvements, despite variations in their magnitude. This suggests that our approach simplifies the learning of elements that the various base models struggle to identify. Therefore, pattern organization is suitable for a wide range of models, as it facilitates the understanding of various traffic features.</p><p><xref rid="sensors-25-01225-f016" ref-type="fig">Figure 16</xref> shows that for Month-wise Pattern Organization, the average improvement over the base model is less than 1%. Although the calculated average is small, <xref rid="sensors-25-01225-t005" ref-type="table">Table 5</xref> demonstrates that monthly improvement varies based on the dissimilarity of the tested month to the preceding months. Forecasting distinct months such as September or March yielded a reduction in the MAPE score of approximately 0.3, reflecting a 1.7% enhancement in performance. Another point to consider is that although some months may not show improvement, they do not show a decline.</p><p>In the preceding section, we discussed the combination of multiple pattern-organizing techniques. We tested this idea by combining speed-wise and Month-wise Pattern Organization. The two strategies are not mutually exclusive, as one utilizes speed values from the training dataset, while the other modifies the months chosen as the training dataset. <xref rid="sensors-25-01225-f016" ref-type="fig">Figure 16</xref> illustrates that optimal outcomes are achieved using this combination. GRU attains the highest overall success with a MAPE score of 13. The application of both Speed-wise Pattern Organization and Month-wise Pattern Organization approaches yields a 0.51 improvement in the MAPE score relative to a model devoid of pattern organization techniques. This contribution represents an enhancement of 3.77%; however, the most significant improvement is attributed to the LSTM model. The application of the LSTM model results in a 4.8% reduction in the MAPE score and an improvement of 0.66 points. The CNN and bi-directional models exhibit improvements of 3.2% and 3.7%, respectively. The distinction between this combination and a Speed-wise Pattern Organization parallels the difference between the base model and training employing a Month-wise Pattern Organization. Both of these methods help the model learn different patterns, so mixing them does not take away from the benefits of either one alone.</p></sec></sec><sec sec-type="discussion" id="sec6-sensors-25-01225"><title>6. Discussion</title><p>The goal of this study, its findings, and the suggested method is to make it easier to learn about traffic patterns that occur as a result of external influences. The finite capacity for information collection and processing may result in certain patterns remaining undiscovered by deep learning algorithms. This paper&#x02019;s methodology involves structuring traffic speed data to facilitate the learning process and enhance the capacity of deep learning algorithms to identify difficult-to-detect patterns. Contemporary research addressing the issue of long-term traffic speed prediction may fail to cover these patterns, as it emphasizes spatial&#x02013;temporal correlations in traffic data while neglecting underlying patterns that lack an apparent rationale. Our research focuses on this issue in order to close this gap in the literature.</p><p>The presented strategies, while efficient in enhancing model performance, do not yield uniform results. The Hour-wise Pattern Organization method does not improve system performance during regular hours, whereas the Speed-wise Pattern Organization demonstrates superior overall performance as it is independent of the time elements. The Month-wise Pattern Organization demonstrates its effectiveness during transition months but fails to improve model accuracy in regular months and in fact worsens the model performance in some months. This tendency to improve more abnormal data while struggling with regular patterns is also seen in all the proposed approaches, although in the hour-wise organization, some hours such as 10 am and 7 pm are the most affected. The proposed methods concentrate on unpredictable chaotic moments. However, they are unable to substantially improve the model&#x02019;s performance if the predicted road follows a regular pattern, despite their excellent performance on these samples. This constraint suggests that our methods work best on routes that experience sporadic events within the designated timeframe, or when applied to restricted data that does not fully represent the patterns in the dataset.</p><p>The proposed strategy for organizing monthly patterns is to identify related months that have similar characteristics. This concept, while accurate in its premise, is too inflexible to adequately capture the essence of changing traffic characteristics. Taking time periods in months fails to account for the shifts that are intended to be separated. For example, the first few weeks of September or March are not the same as the last few weeks and have distinct traffic characteristics. Future research could build on this hypothesis by investigating dynamic seasonal periods that are not limited to months or weeks.</p><p>A further limitation of Month-wise Pattern Organization is the representation of months we have used. Our work concentrates on anomalous instances; therefore, we opted to depict each month in a manner that emphasizes these irregularities. The inability to demonstrate consistent improvement on a monthly basis can be addressed by enhancing the quality of representation, which may facilitate the identification of subtle variations in traffic characteristics that can be measured in minutes. Such representations would most likely focus on external data such as weather, events, accident profiles, and so on, as opposed to the suggested methodology, which attempts to capture these underlying factors when they cause significant fluctuations.</p><p>In the Hour-wise Pattern Organization method, enhancing the performance of regular hours is more challenging than in the Month-wise Pattern Organization. Enhanced time segmentation may potentially augment the efficacy of the methods; for instance, dynamically adjusting the time frame based on the day of the week or month could enable the creation of groups that more effectively isolate traffic characteristics.</p><p>The Speed-wise Pattern Organization performed well when compared to regular time periods; however, samples with different labels and input averages present a significant challenge to this strategy. While we have mitigated the effects of these samples, they remain the primary bottleneck for this technique. Further research can examine the effects of employing adjacent models for prediction, for example, using light and heavy traffic models when the input average corresponds to the medium model. With this approach, volatile samples may be predicted more accurately as the correct model type is included in the process.</p><p>A further constraint of our study is the dependence on data from a singular metropolitan area, thus constraining the generalization of our findings to other places. The Hour-wise Pattern Organization periods, Speed-wise Pattern Organization boundaries, and Month-wise Pattern Organization similarities established are optimal for Istanbul; however, they may differ for other cities or in future years in Istanbul due to evolving traffic characteristics.</p><p>The variation and imbalanced nature of traffic speed datasets can lead to biased and inaccurate models, which may result in erroneous decision-making regarding urban management. Our methodologies are currently able to provide effective support for short-term predictions. However, the incorporation of recent vehicular data has the potential to enhance short-term forecasting [<xref rid="B66-sensors-25-01225" ref-type="bibr">66</xref>]. Addressing performance issues and improving forecasting accuracy could enhance investment policies and resource management, potentially guiding decision-makers toward more proactive decision-making strategies.</p></sec><sec sec-type="conclusions" id="sec7-sensors-25-01225"><title>7. Conclusions</title><p>In this paper, we evaluated our pattern organization strategies using four popular model types and discovered that our techniques significantly improved predictive performance relative to regular training. Our Hour-wise Pattern Organization technique, which focuses on traffic characteristics based on the time of day, improved forecast performance by 1.8%. Speed-wise Pattern Organization, concentrating on speed values directly, improved prediction accuracy by 4%. Meanwhile, Month-wise Pattern Organization, which prioritizes traffic characteristics based on months, improved prediction performance by 1% when used with an LSTM model. We show similar improvements across several model types, confirming the compatibility of our three techniques with other potential models. Furthermore, the integration of speed-wise and month-wise methodologies resulted in an increased improvement percentage of 4.8%, demonstrating the adaptability of our approaches when used in conjunction. Upon analyzing our results on an hourly basis rather than as a general average, we find that the improvements in predictive performance are greater at lower speed levels and indicate that the effectiveness of our methods is beyond what the average improvement suggests. We observed an improvement around 11% with our proposed methods during peak hours. This analysis demonstrates the effectiveness of our methods, as peak hours are critical for traffic forecasts.</p><p>In the future, we intend to demonstrate the effectiveness of our methods not only with more intricate model structures such as GCN but also by incorporating external factors such as weather and accidents as inputs. We aim to conduct experiments on various datasets to establish more universal parameters applicable to different cities. Although this research focuses on long-term predictions, our methods are theoretically applicable to short-term predictions as well. One of our future objectives is to demonstrate the effectiveness of our methods for short-term traffic predictions while incorporating additional external data such as traffic lights and bus stops. These parameters, while not beneficial for long-term predictions, are crucial for short-term forecasts and can enhance the proposed algorithms. We generate subsets that contain critical information to train distinct models. However, we can also utilize these subsets in ensemble learning, as our algorithms effectively split the dataset to address the diversity concern of ensemble learning. We can also create subsets with Speed-wise Pattern Organization to show the speed characteristics of a road segment or Hour-wise Pattern Organization to identify similar road segments. This type of analysis could assist decision-makers in urban management during their city planning process.</p></sec></body><back><ack><title>Acknowledgments</title><p>We want to thank to Traffic Division of Istanbul Metropolitan Municipality for their time and valuable feedback.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, M.M.K., H.I.T. and M.A.G.; methodology, M.M.K.; software, M.M.K.; validation, M.M.K., H.I.T. and M.A.G.; formal analysis, M.M.K., H.I.T. and M.A.G.; investigation, M.M.K.; resources, M.A.G. and H.I.T.; data curation, H.I.T. and M.A.G.; writing&#x02014;original draft preparation, M.M.K.; writing&#x02014;review and editing, M.M.K., H.I.T. and M.A.G.; visualization, M.M.K.; supervision, M.A.G. and H.I.T.; project administration, M.A.G.; funding acquisition, M.M.K., H.I.T. and M.A.G. All authors have read and agreed to the published version of the manuscript.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>Data is contained within the article.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01225"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Do</surname><given-names>V.M.</given-names></name>
<name><surname>Tran</surname><given-names>Q.H.</given-names></name>
<name><surname>Le</surname><given-names>K.G.</given-names></name>
<name><surname>Vuong</surname><given-names>X.C.</given-names></name>
<name><surname>Vu</surname><given-names>V.T.</given-names></name>
</person-group><article-title>Enhanced Deep Neural Networks for Traffic Speed Forecasting Regarding Sustainable Traffic Management Using Probe Data from Registered Transport Vehicles on Multilane Roads</article-title><source>Sustainability</source><year>2024</year><volume>16</volume><elocation-id>2453</elocation-id><pub-id pub-id-type="doi">10.3390/su16062453</pub-id></element-citation></ref><ref id="B2-sensors-25-01225"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cao</surname><given-names>C.</given-names></name>
<name><surname>Bao</surname><given-names>Y.</given-names></name>
<name><surname>Shi</surname><given-names>Q.</given-names></name>
<name><surname>Shen</surname><given-names>Q.</given-names></name>
</person-group><article-title>Dynamic spatiotemporal correlation graph convolutional network for traffic speed prediction</article-title><source>Symmetry</source><year>2024</year><volume>16</volume><elocation-id>308</elocation-id><pub-id pub-id-type="doi">10.3390/sym16030308</pub-id></element-citation></ref><ref id="B3-sensors-25-01225"><label>3.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Lin</surname><given-names>W.H.</given-names></name>
</person-group><article-title>A Gaussian maximum likelihood formulation for short-term forecasting of traffic flow</article-title><source>Proceedings of the ITSC 2001. 2001 IEEE Intelligent Transportation Systems. Proceedings (Cat. No. 01TH8585)</source><conf-loc>Oakland, CA, USA</conf-loc><conf-date>25&#x02013;29 August 2001</conf-date><fpage>150</fpage><lpage>155</lpage></element-citation></ref><ref id="B4-sensors-25-01225"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>A.</given-names></name>
<name><surname>Liu</surname><given-names>Q.</given-names></name>
<name><surname>Zhang</surname><given-names>T.</given-names></name>
</person-group><article-title>Spatial&#x02013;temporal attention fusion for traffic speed prediction</article-title><source>Soft Comput.</source><year>2022</year><volume>26</volume><fpage>695</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1007/s00500-021-06521-7</pub-id></element-citation></ref><ref id="B5-sensors-25-01225"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhou</surname><given-names>Z.</given-names></name>
<name><surname>Yang</surname><given-names>Z.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Huang</surname><given-names>Y.</given-names></name>
<name><surname>Chen</surname><given-names>H.</given-names></name>
<name><surname>Yu</surname><given-names>Z.</given-names></name>
</person-group><article-title>A comprehensive study of speed prediction in transportation system: From vehicle to traffic</article-title><source>Iscience</source><year>2022</year><volume>25</volume><fpage>103909</fpage><pub-id pub-id-type="doi">10.1016/j.isci.2022.103909</pub-id><pub-id pub-id-type="pmid">35281740</pub-id>
</element-citation></ref><ref id="B6-sensors-25-01225"><label>6.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Nasser</surname><given-names>A.</given-names></name>
<name><surname>Simon</surname><given-names>V.</given-names></name>
</person-group><article-title>A Novel Method for Analyzing Weather Effect on Smart City Traffic</article-title><source>Proceedings of the 2021 IEEE 22nd International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)</source><conf-loc>Pisa, Italy</conf-loc><conf-date>7&#x02013;11 June 2021</conf-date><fpage>335</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1109/WoWMoM51794.2021.00061</pub-id></element-citation></ref><ref id="B7-sensors-25-01225"><label>7.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Bilgin</surname><given-names>E.</given-names></name>
<name><surname>Turkmen</surname><given-names>H.I.</given-names></name>
<name><surname>Guvensan</surname><given-names>M.A.</given-names></name>
</person-group><article-title>A Weather Oriented Pre-Tuning Methodology For Long-term Traffic Speed Estimation</article-title><source>Proceedings of the 2023 IEEE 24th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)</source><conf-loc>Boston, MA, USA</conf-loc><conf-date>12&#x02013;15 June 2023</conf-date><fpage>451</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1109/WoWMoM57956.2023.00079</pub-id></element-citation></ref><ref id="B8-sensors-25-01225"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>An</surname><given-names>J.</given-names></name>
<name><surname>Fu</surname><given-names>L.</given-names></name>
<name><surname>Hu</surname><given-names>M.</given-names></name>
<name><surname>Chen</surname><given-names>W.</given-names></name>
<name><surname>Zhan</surname><given-names>J.</given-names></name>
</person-group><article-title>A novel fuzzy-based convolutional neural network method to traffic flow prediction with uncertain traffic accident information</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>20708</fpage><lpage>20722</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2896913</pub-id></element-citation></ref><ref id="B9-sensors-25-01225"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kwoczek</surname><given-names>S.</given-names></name>
<name><surname>Di Martino</surname><given-names>S.</given-names></name>
<name><surname>Nejdl</surname><given-names>W.</given-names></name>
</person-group><article-title>Predicting and visualizing traffic congestion in the presence of planned special events</article-title><source>J. Vis. Lang. Comput.</source><year>2014</year><volume>25</volume><fpage>973</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1016/j.jvlc.2014.10.028</pub-id></element-citation></ref><ref id="B10-sensors-25-01225"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Atilgan</surname><given-names>I.</given-names></name>
<name><surname>Turkmen</surname><given-names>H.I.</given-names></name>
<name><surname>Guvensan</surname><given-names>M.A.</given-names></name>
</person-group><article-title>Traffic Characteristics of Short and Long Public Holidays: A Hybrid Holiday-Oriented Speed Prediction Approach via Feature Engineering</article-title><source>IEEE Sens. J.</source><year>2023</year><volume>23</volume><fpage>25016</fpage><lpage>25025</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2023.3312189</pub-id></element-citation></ref><ref id="B11-sensors-25-01225"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zheng</surname><given-names>G.</given-names></name>
<name><surname>Chai</surname><given-names>W.K.</given-names></name>
<name><surname>Katos</surname><given-names>V.</given-names></name>
</person-group><article-title>A dynamic spatial&#x02013;temporal deep learning framework for traffic speed prediction on large-scale road networks</article-title><source>Expert Syst. Appl.</source><year>2022</year><volume>195</volume><fpage>116585</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2022.116585</pub-id></element-citation></ref><ref id="B12-sensors-25-01225"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>James</surname><given-names>J.</given-names></name>
<name><surname>Markos</surname><given-names>C.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
</person-group><article-title>Long-term urban traffic speed prediction with deep learning on graphs</article-title><source>IEEE Trans. Intell. Transp. Syst.</source><year>2021</year><volume>23</volume><fpage>7359</fpage><lpage>7370</lpage></element-citation></ref><ref id="B13-sensors-25-01225"><label>13.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>He</surname><given-names>Z.</given-names></name>
<name><surname>Chow</surname><given-names>C.Y.</given-names></name>
<name><surname>Zhang</surname><given-names>J.D.</given-names></name>
</person-group><article-title>STCNN: A spatio-temporal convolutional neural network for long-term traffic prediction</article-title><source>Proceedings of the 2019 20th IEEE International Conference on Mobile Data Management (MDM)</source><conf-loc>Hong Kong, China</conf-loc><conf-date>10&#x02013;13 June 2019</conf-date><fpage>226</fpage><lpage>233</lpage></element-citation></ref><ref id="B14-sensors-25-01225"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shaygan</surname><given-names>M.</given-names></name>
<name><surname>Meese</surname><given-names>C.</given-names></name>
<name><surname>Li</surname><given-names>W.</given-names></name>
<name><surname>Zhao</surname><given-names>X.G.</given-names></name>
<name><surname>Nejad</surname><given-names>M.</given-names></name>
</person-group><article-title>Traffic prediction using artificial intelligence: Review of recent advances and emerging opportunities</article-title><source>Transp. Res. Part C Emerg. Technol.</source><year>2022</year><volume>145</volume><fpage>103921</fpage><pub-id pub-id-type="doi">10.1016/j.trc.2022.103921</pub-id></element-citation></ref><ref id="B15-sensors-25-01225"><label>15.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Gonz&#x000e1;lez-Barcenas</surname><given-names>V.</given-names></name>
<name><surname>Rend&#x000f3;n</surname><given-names>E.</given-names></name>
<name><surname>Alejo</surname><given-names>R.</given-names></name>
<name><surname>Granda-Guti&#x000e9;rrez</surname><given-names>E.</given-names></name>
<name><surname>Valdovinos</surname><given-names>R.M.</given-names></name>
</person-group><article-title>Addressing the big data multi-class imbalance problem with oversampling and deep learning neural networks</article-title><source>Proceedings of the Pattern Recognition and Image Analysis: 9th Iberian Conference, IbPRIA 2019</source><conf-loc>Madrid, Spain</conf-loc><conf-date>1&#x02013;4 July 2019</conf-date><comment>Proceedings, Part I 9</comment><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2019</year><fpage>216</fpage><lpage>224</lpage></element-citation></ref><ref id="B16-sensors-25-01225"><label>16.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Devi</surname><given-names>D.</given-names></name>
<name><surname>Biswas</surname><given-names>S.K.</given-names></name>
<name><surname>Purkayastha</surname><given-names>B.</given-names></name>
</person-group><article-title>A review on solution to class imbalance problem: Undersampling approaches</article-title><source>Proceedings of the 2020 International Conference on Computational Performance Evaluation (ComPE)</source><conf-loc>Shillong, India</conf-loc><conf-date>2&#x02013;4 July 2020</conf-date><fpage>626</fpage><lpage>631</lpage></element-citation></ref><ref id="B17-sensors-25-01225"><label>17.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Ahmed</surname><given-names>M.S.</given-names></name>
<name><surname>Cook</surname><given-names>A.R.</given-names></name>
</person-group><article-title>Analysis of Freeway Traffic Time-Series Data by Using Box-Jenkins Techniques</article-title><year>1979</year><comment>Available online: <ext-link xlink:href="https://onlinepubs.trb.org/Onlinepubs/trr/1979/722/722-001.pdf" ext-link-type="uri">https://onlinepubs.trb.org/Onlinepubs/trr/1979/722/722-001.pdf</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-12-11">(accessed on 11 December 2024)</date-in-citation></element-citation></ref><ref id="B18-sensors-25-01225"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Van Der Voort</surname><given-names>M.</given-names></name>
<name><surname>Dougherty</surname><given-names>M.</given-names></name>
<name><surname>Watson</surname><given-names>S.</given-names></name>
</person-group><article-title>Combining Kohonen maps with ARIMA time series models to forecast traffic flow</article-title><source>Transp. Res. Part C Emerg. Technol.</source><year>1996</year><volume>4</volume><fpage>307</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1016/S0968-090X(97)82903-8</pub-id></element-citation></ref><ref id="B19-sensors-25-01225"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>L.</given-names></name>
<name><surname>Liu</surname><given-names>Q.</given-names></name>
<name><surname>Yang</surname><given-names>W.</given-names></name>
<name><surname>Wei</surname><given-names>N.</given-names></name>
<name><surname>Dong</surname><given-names>D.</given-names></name>
</person-group><article-title>An improved k-nearest neighbor model for short-term traffic flow prediction</article-title><source>Procedia-Soc. Behav. Sci.</source><year>2013</year><volume>96</volume><fpage>653</fpage><lpage>662</lpage><pub-id pub-id-type="doi">10.1016/j.sbspro.2013.08.076</pub-id></element-citation></ref><ref id="B20-sensors-25-01225"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cai</surname><given-names>P.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Lu</surname><given-names>G.</given-names></name>
<name><surname>Chen</surname><given-names>P.</given-names></name>
<name><surname>Ding</surname><given-names>C.</given-names></name>
<name><surname>Sun</surname><given-names>J.</given-names></name>
</person-group><article-title>A spatiotemporal correlative k-nearest neighbor model for short-term traffic multistep forecasting</article-title><source>Transp. Res. Part C Emerg. Technol.</source><year>2016</year><volume>62</volume><fpage>21</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1016/j.trc.2015.11.002</pub-id></element-citation></ref><ref id="B21-sensors-25-01225"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xu</surname><given-names>D.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Peng</surname><given-names>P.</given-names></name>
<name><surname>Beilun</surname><given-names>S.</given-names></name>
<name><surname>Deng</surname><given-names>Z.</given-names></name>
<name><surname>Guo</surname><given-names>H.</given-names></name>
</person-group><article-title>Real-time road traffic state prediction based on kernel-KNN</article-title><source>Transp. A Transp. Sci.</source><year>2020</year><volume>16</volume><fpage>104</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1080/23249935.2018.1491073</pub-id></element-citation></ref><ref id="B22-sensors-25-01225"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wu</surname><given-names>C.H.</given-names></name>
<name><surname>Ho</surname><given-names>J.M.</given-names></name>
<name><surname>Lee</surname><given-names>D.T.</given-names></name>
</person-group><article-title>Travel-time prediction with support vector regression</article-title><source>IEEE Trans. Intell. Transp. Syst.</source><year>2004</year><volume>5</volume><fpage>276</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1109/TITS.2004.837813</pub-id></element-citation></ref><ref id="B23-sensors-25-01225"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Castro-Neto</surname><given-names>M.</given-names></name>
<name><surname>Jeong</surname><given-names>Y.S.</given-names></name>
<name><surname>Jeong</surname><given-names>M.K.</given-names></name>
<name><surname>Han</surname><given-names>L.D.</given-names></name>
</person-group><article-title>Online-SVR for short-term traffic flow prediction under typical and atypical traffic conditions</article-title><source>Expert Syst. Appl.</source><year>2009</year><volume>36</volume><fpage>6164</fpage><lpage>6173</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2008.07.069</pub-id></element-citation></ref><ref id="B24-sensors-25-01225"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yasdi</surname><given-names>R.</given-names></name>
</person-group><article-title>Prediction of road traffic using a neural network approach</article-title><source>Neural Comput. Appl.</source><year>1999</year><volume>8</volume><fpage>135</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1007/s005210050015</pub-id></element-citation></ref><ref id="B25-sensors-25-01225"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dougherty</surname><given-names>M.S.</given-names></name>
<name><surname>Cobbett</surname><given-names>M.R.</given-names></name>
</person-group><article-title>Short-term inter-urban traffic forecasts using neural networks</article-title><source>Int. J. Forecast.</source><year>1997</year><volume>13</volume><fpage>21</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/S0169-2070(96)00697-8</pub-id></element-citation></ref><ref id="B26-sensors-25-01225"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dia</surname><given-names>H.</given-names></name>
</person-group><article-title>An object-oriented neural network approach to short-term traffic forecasting</article-title><source>Eur. J. Oper. Res.</source><year>2001</year><volume>131</volume><fpage>253</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1016/S0377-2217(00)00125-9</pub-id></element-citation></ref><ref id="B27-sensors-25-01225"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Moretti</surname><given-names>F.</given-names></name>
<name><surname>Pizzuti</surname><given-names>S.</given-names></name>
<name><surname>Panzieri</surname><given-names>S.</given-names></name>
<name><surname>Annunziato</surname><given-names>M.</given-names></name>
</person-group><article-title>Urban traffic flow forecasting through statistical and neural network bagging ensemble hybrid modeling</article-title><source>Neurocomputing</source><year>2015</year><volume>167</volume><fpage>3</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2014.08.100</pub-id></element-citation></ref><ref id="B28-sensors-25-01225"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hochreiter</surname><given-names>S.</given-names></name>
<name><surname>Schmidhuber</surname><given-names>J.</given-names></name>
</person-group><article-title>Long short-term memory</article-title><source>Neural Comput.</source><year>1997</year><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id>
</element-citation></ref><ref id="B29-sensors-25-01225"><label>29.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Tian</surname><given-names>Y.</given-names></name>
<name><surname>Pan</surname><given-names>L.</given-names></name>
</person-group><article-title>Predicting short-term traffic flow by long short-term memory recurrent neural network</article-title><source>Proceedings of the 2015 IEEE international conference on smart city/SocialCom/SustainCom (SmartCity)</source><conf-loc>Chengdu, China</conf-loc><conf-date>19&#x02013;21 December 2015</conf-date><fpage>153</fpage><lpage>158</lpage></element-citation></ref><ref id="B30-sensors-25-01225"><label>30.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kang</surname><given-names>D.</given-names></name>
<name><surname>Lv</surname><given-names>Y.</given-names></name>
<name><surname>Chen</surname><given-names>Y.y.</given-names></name>
</person-group><article-title>Short-term traffic flow prediction with LSTM recurrent neural network</article-title><source>Proceedings of the 2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)</source><conf-loc>Yokohama, Japan</conf-loc><conf-date>16&#x02013;19 October 2017</conf-date><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B31-sensors-25-01225"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ma</surname><given-names>X.</given-names></name>
<name><surname>Tao</surname><given-names>Z.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Yu</surname><given-names>H.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
</person-group><article-title>Long short-term memory neural network for traffic speed prediction using remote microwave sensor data</article-title><source>Transp. Res. Part C Emerg. Technol.</source><year>2015</year><volume>54</volume><fpage>187</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1016/j.trc.2015.03.014</pub-id></element-citation></ref><ref id="B32-sensors-25-01225"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cho</surname><given-names>K.</given-names></name>
<name><surname>Van Merri&#x000eb;nboer</surname><given-names>B.</given-names></name>
<name><surname>Bahdanau</surname><given-names>D.</given-names></name>
<name><surname>Bengio</surname><given-names>Y.</given-names></name>
</person-group><article-title>On the properties of neural machine translation: Encoder-decoder approaches</article-title><source>arXiv</source><year>2014</year><pub-id pub-id-type="arxiv">1409.1259</pub-id></element-citation></ref><ref id="B33-sensors-25-01225"><label>33.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Fu</surname><given-names>R.</given-names></name>
<name><surname>Zhang</surname><given-names>Z.</given-names></name>
<name><surname>Li</surname><given-names>L.</given-names></name>
</person-group><article-title>Using LSTM and GRU neural network methods for traffic flow prediction</article-title><source>Proceedings of the 2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)</source><conf-loc>Wuhan, China</conf-loc><conf-date>11&#x02013;13 November 2016</conf-date><fpage>324</fpage><lpage>328</lpage></element-citation></ref><ref id="B34-sensors-25-01225"><label>34.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Cheng</surname><given-names>W.</given-names></name>
<name><surname>Shen</surname><given-names>Y.</given-names></name>
<name><surname>Zhu</surname><given-names>Y.</given-names></name>
<name><surname>Huang</surname><given-names>L.</given-names></name>
</person-group><article-title>A neural attention model for urban air quality inference: Learning the weights of monitoring stations</article-title><source>Proceedings of the AAAI Conference on Artificial Intelligence</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>2&#x02013;7 February 2018</conf-date><volume>Volume 32</volume></element-citation></ref><ref id="B35-sensors-25-01225"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Su</surname><given-names>X.</given-names></name>
<name><surname>Ding</surname><given-names>Z.</given-names></name>
</person-group><article-title>Long-term traffic prediction based on lstm encoder-decoder architecture</article-title><source>IEEE Trans. Intell. Transp. Syst.</source><year>2020</year><volume>22</volume><fpage>6561</fpage><lpage>6571</lpage><pub-id pub-id-type="doi">10.1109/TITS.2020.2995546</pub-id></element-citation></ref><ref id="B36-sensors-25-01225"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Khodabandelou</surname><given-names>G.</given-names></name>
<name><surname>Kheriji</surname><given-names>W.</given-names></name>
<name><surname>Selem</surname><given-names>F.H.</given-names></name>
</person-group><article-title>Link traffic speed forecasting using convolutional attention-based gated recurrent unit</article-title><source>Appl. Intell.</source><year>2021</year><volume>51</volume><fpage>2331</fpage><lpage>2352</lpage><pub-id pub-id-type="doi">10.1007/s10489-020-02020-8</pub-id></element-citation></ref><ref id="B37-sensors-25-01225"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xu</surname><given-names>M.</given-names></name>
<name><surname>Dai</surname><given-names>W.</given-names></name>
<name><surname>Liu</surname><given-names>C.</given-names></name>
<name><surname>Gao</surname><given-names>X.</given-names></name>
<name><surname>Lin</surname><given-names>W.</given-names></name>
<name><surname>Qi</surname><given-names>G.J.</given-names></name>
<name><surname>Xiong</surname><given-names>H.</given-names></name>
</person-group><article-title>Spatial-temporal transformer networks for traffic flow forecasting</article-title><source>arXiv</source><year>2020</year><pub-id pub-id-type="arxiv">2001.02908</pub-id></element-citation></ref><ref id="B38-sensors-25-01225"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>J.</given-names></name>
<name><surname>Liu</surname><given-names>Z.</given-names></name>
<name><surname>Sun</surname><given-names>Q.</given-names></name>
<name><surname>Li</surname><given-names>Q.</given-names></name>
<name><surname>Jia</surname><given-names>X.</given-names></name>
<name><surname>Zhang</surname><given-names>R.</given-names></name>
</person-group><article-title>Attention-based dynamic spatial-temporal graph convolutional networks for traffic speed forecasting</article-title><source>Expert Syst. Appl.</source><year>2022</year><volume>204</volume><fpage>117511</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2022.117511</pub-id></element-citation></ref><ref id="B39-sensors-25-01225"><label>39.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Zheng</surname><given-names>C.</given-names></name>
<name><surname>Fan</surname><given-names>X.</given-names></name>
<name><surname>Wang</surname><given-names>C.</given-names></name>
<name><surname>Qi</surname><given-names>J.</given-names></name>
</person-group><article-title>Gman: A graph multi-attention network for traffic prediction</article-title><source>Proceedings of the AAAI Conference on Artificial Intelligence</source><conf-loc>New York, NY, USA</conf-loc><conf-date>9&#x02013;11 February 2020</conf-date><volume>Volume 34</volume><fpage>1234</fpage><lpage>1241</lpage></element-citation></ref><ref id="B40-sensors-25-01225"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zang</surname><given-names>D.</given-names></name>
<name><surname>Fang</surname><given-names>Y.</given-names></name>
<name><surname>Wei</surname><given-names>Z.</given-names></name>
<name><surname>Tang</surname><given-names>K.</given-names></name>
<name><surname>Cheng</surname><given-names>J.</given-names></name>
</person-group><article-title>Traffic flow data prediction using residual deconvolution based deep generative network</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>71311</fpage><lpage>71322</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2919996</pub-id></element-citation></ref><ref id="B41-sensors-25-01225"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>M&#x000e9;ndez</surname><given-names>M.</given-names></name>
<name><surname>Merayo</surname><given-names>M.G.</given-names></name>
<name><surname>N&#x000fa;&#x000f1;ez</surname><given-names>M.</given-names></name>
</person-group><article-title>Long-term traffic flow forecasting using a hybrid CNN-BiLSTM model</article-title><source>Eng. Appl. Artif. Intell.</source><year>2023</year><volume>121</volume><fpage>106041</fpage><pub-id pub-id-type="doi">10.1016/j.engappai.2023.106041</pub-id></element-citation></ref><ref id="B42-sensors-25-01225"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ma</surname><given-names>C.</given-names></name>
<name><surname>Zhao</surname><given-names>Y.</given-names></name>
<name><surname>Dai</surname><given-names>G.</given-names></name>
<name><surname>Xu</surname><given-names>X.</given-names></name>
<name><surname>Wong</surname><given-names>S.C.</given-names></name>
</person-group><article-title>A Novel STFSA-CNN-GRU Hybrid Model for Short-Term Traffic Speed Prediction</article-title><source>IEEE Trans. Intell. Transp. Syst.</source><year>2023</year><volume>24</volume><fpage>3728</fpage><lpage>3737</lpage><pub-id pub-id-type="doi">10.1109/TITS.2021.3117835</pub-id></element-citation></ref><ref id="B43-sensors-25-01225"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bruna</surname><given-names>J.</given-names></name>
<name><surname>Zaremba</surname><given-names>W.</given-names></name>
<name><surname>Szlam</surname><given-names>A.</given-names></name>
<name><surname>LeCun</surname><given-names>Y.</given-names></name>
</person-group><article-title>Spectral networks and locally connected networks on graphs</article-title><source>arXiv</source><year>2013</year><pub-id pub-id-type="arxiv">1312.6203</pub-id></element-citation></ref><ref id="B44-sensors-25-01225"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kipf</surname><given-names>T.N.</given-names></name>
<name><surname>Welling</surname><given-names>M.</given-names></name>
</person-group><article-title>Semi-supervised classification with graph convolutional networks</article-title><source>arXiv</source><year>2016</year><pub-id pub-id-type="arxiv">1609.02907</pub-id></element-citation></ref><ref id="B45-sensors-25-01225"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bogaerts</surname><given-names>T.</given-names></name>
<name><surname>Masegosa</surname><given-names>A.D.</given-names></name>
<name><surname>Angarita-Zapata</surname><given-names>J.S.</given-names></name>
<name><surname>Onieva</surname><given-names>E.</given-names></name>
<name><surname>Hellinckx</surname><given-names>P.</given-names></name>
</person-group><article-title>A graph CNN-LSTM neural network for short and long-term traffic forecasting based on trajectory data</article-title><source>Transp. Res. Part C Emerg. Technol.</source><year>2020</year><volume>112</volume><fpage>62</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.trc.2020.01.010</pub-id></element-citation></ref><ref id="B46-sensors-25-01225"><label>46.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Han</surname><given-names>L.</given-names></name>
<name><surname>Du</surname><given-names>B.</given-names></name>
<name><surname>Sun</surname><given-names>L.</given-names></name>
<name><surname>Fu</surname><given-names>Y.</given-names></name>
<name><surname>Lv</surname><given-names>Y.</given-names></name>
<name><surname>Xiong</surname><given-names>H.</given-names></name>
</person-group><article-title>Dynamic and multi-faceted spatio-temporal deep learning for traffic speed forecasting</article-title><source>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &#x00026; Data Mining</source><conf-loc>Singapore</conf-loc><conf-date>14&#x02013;18 August 2021</conf-date><fpage>547</fpage><lpage>555</lpage></element-citation></ref><ref id="B47-sensors-25-01225"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>J.</given-names></name>
<name><surname>Xu</surname><given-names>M.</given-names></name>
<name><surname>Xu</surname><given-names>W.</given-names></name>
<name><surname>Li</surname><given-names>D.</given-names></name>
<name><surname>Peng</surname><given-names>W.</given-names></name>
<name><surname>Xu</surname><given-names>H.</given-names></name>
</person-group><article-title>A Flow Feedback Traffic Prediction Based on Visual Quantified Features</article-title><source>IEEE Trans. Intell. Transp. Syst.</source><year>2023</year><volume>24</volume><fpage>10067</fpage><lpage>10075</lpage><pub-id pub-id-type="doi">10.1109/TITS.2023.3269794</pub-id></element-citation></ref><ref id="B48-sensors-25-01225"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Qi</surname><given-names>X.</given-names></name>
<name><surname>Mei</surname><given-names>G.</given-names></name>
<name><surname>Tu</surname><given-names>J.</given-names></name>
<name><surname>Xi</surname><given-names>N.</given-names></name>
<name><surname>Piccialli</surname><given-names>F.</given-names></name>
</person-group><article-title>A Deep Learning Approach for Long-Term Traffic Flow Prediction With Multifactor Fusion Using Spatiotemporal Graph Convolutional Network</article-title><source>IEEE Trans. Intell. Transp. Syst.</source><year>2023</year><volume>24</volume><fpage>8687</fpage><lpage>8700</lpage><pub-id pub-id-type="doi">10.1109/TITS.2022.3201879</pub-id></element-citation></ref><ref id="B49-sensors-25-01225"><label>49.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kara</surname><given-names>M.M.</given-names></name>
<name><surname>Turkmen</surname><given-names>H.I.</given-names></name>
<name><surname>Guvensan</surname><given-names>M.A.</given-names></name>
</person-group><article-title>Missing Traffic Speed Data Imputation Using Road Segment Characteristics for Long-Term Traffic Speed Prediction</article-title><source>Proceedings of the 2023 IEEE 24th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)</source><conf-loc>Boston, MA, USA</conf-loc><conf-date>12&#x02013;15 June 2023</conf-date><fpage>457</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.1109/WoWMoM57956.2023.00080</pub-id></element-citation></ref><ref id="B50-sensors-25-01225"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Ren</surname><given-names>Q.</given-names></name>
<name><surname>Li</surname><given-names>J.</given-names></name>
</person-group><article-title>Spatial&#x02013;temporal multi-feature fusion network for long short-term traffic prediction</article-title><source>Expert Syst. Appl.</source><year>2023</year><volume>224</volume><fpage>119959</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2023.119959</pub-id></element-citation></ref><ref id="B51-sensors-25-01225"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Qiu</surname><given-names>Z.</given-names></name>
<name><surname>Zhu</surname><given-names>T.</given-names></name>
<name><surname>Jin</surname><given-names>Y.</given-names></name>
<name><surname>Sun</surname><given-names>L.</given-names></name>
<name><surname>Du</surname><given-names>B.</given-names></name>
</person-group><article-title>A graph attention fusion network for event-driven traffic speed prediction</article-title><source>Inf. Sci.</source><year>2023</year><volume>622</volume><fpage>405</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/j.ins.2022.11.168</pub-id></element-citation></ref><ref id="B52-sensors-25-01225"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Johnson</surname><given-names>J.M.</given-names></name>
<name><surname>Khoshgoftaar</surname><given-names>T.M.</given-names></name>
</person-group><article-title>Survey on deep learning with class imbalance</article-title><source>J. Big Data</source><year>2019</year><volume>6</volume><fpage>1</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1186/s40537-019-0192-5</pub-id></element-citation></ref><ref id="B53-sensors-25-01225"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chawla</surname><given-names>N.V.</given-names></name>
<name><surname>Bowyer</surname><given-names>K.W.</given-names></name>
<name><surname>Hall</surname><given-names>L.O.</given-names></name>
<name><surname>Kegelmeyer</surname><given-names>W.P.</given-names></name>
</person-group><article-title>SMOTE: Synthetic Minority Over-sampling Technique</article-title><source>J. Artif. Intell. Res.</source><year>2002</year><volume>16</volume><fpage>321</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1613/jair.953</pub-id></element-citation></ref><ref id="B54-sensors-25-01225"><label>54.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Torgo</surname><given-names>L.</given-names></name>
<name><surname>Ribeiro</surname><given-names>R.</given-names></name>
<name><surname>Pfahringer</surname><given-names>B.</given-names></name>
<name><surname>Branco</surname><given-names>P.</given-names></name>
</person-group><article-title>SMOTE for Regression</article-title><source>Progress in Artificial Intelligence</source><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2013</year><volume>Volume 8154</volume><fpage>378</fpage><lpage>389</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-40669-0_33</pub-id></element-citation></ref><ref id="B55-sensors-25-01225"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Gavas</surname><given-names>R.D.</given-names></name>
<name><surname>Das</surname><given-names>M.</given-names></name>
<name><surname>Ghosh</surname><given-names>S.K.</given-names></name>
<name><surname>Pal</surname><given-names>A.</given-names></name>
</person-group><article-title>Spatial-SMOTE for handling imbalance in spatial regression tasks</article-title><source>Multimed. Tools Appl.</source><year>2024</year><volume>83</volume><fpage>14111</fpage><lpage>14132</lpage><pub-id pub-id-type="doi">10.1007/s11042-023-15919-4</pub-id></element-citation></ref><ref id="B56-sensors-25-01225"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Camacho</surname><given-names>L.</given-names></name>
<name><surname>Bacao</surname><given-names>F.</given-names></name>
</person-group><article-title>WSMOTER: A novel approach for imbalanced regression</article-title><source>Appl. Intell.</source><year>2024</year><volume>54</volume><fpage>8789</fpage><lpage>8799</lpage><pub-id pub-id-type="doi">10.1007/s10489-024-05608-6</pub-id></element-citation></ref><ref id="B57-sensors-25-01225"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Engelmann</surname><given-names>J.</given-names></name>
<name><surname>Lessmann</surname><given-names>S.</given-names></name>
</person-group><article-title>Conditional Wasserstein GAN-based oversampling of tabular data for imbalanced learning</article-title><source>Expert Syst. Appl.</source><year>2021</year><volume>174</volume><fpage>114582</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2021.114582</pub-id></element-citation></ref><ref id="B58-sensors-25-01225"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fan</surname><given-names>S.K.S.</given-names></name>
<name><surname>Chen</surname><given-names>W.Y.</given-names></name>
</person-group><article-title>A generative-adversarial-network-based temporal raw trace data augmentation framework for fault detection in semiconductor manufacturing</article-title><source>Eng. Appl. Artif. Intell.</source><year>2025</year><volume>139</volume><fpage>109624</fpage><pub-id pub-id-type="doi">10.1016/j.engappai.2024.109624</pub-id></element-citation></ref><ref id="B59-sensors-25-01225"><label>59.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Guo</surname><given-names>Y.</given-names></name>
<name><surname>Li</surname><given-names>Z.</given-names></name>
<name><surname>Li</surname><given-names>Z.</given-names></name>
<name><surname>Xiong</surname><given-names>G.</given-names></name>
<name><surname>Jiang</surname><given-names>M.</given-names></name>
<name><surname>Gou</surname><given-names>G.</given-names></name>
</person-group><article-title>FLAGB: Focal loss based adaptive gradient boosting for imbalanced traffic classification</article-title><source>Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN)</source><conf-loc>Glasgow, UK</conf-loc><conf-date>19&#x02013;24 July 2020</conf-date><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="B60-sensors-25-01225"><label>60.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Ren</surname><given-names>J.</given-names></name>
<name><surname>Zhang</surname><given-names>M.</given-names></name>
<name><surname>Yu</surname><given-names>C.</given-names></name>
<name><surname>Liu</surname><given-names>Z.</given-names></name>
</person-group><article-title>Balanced mse for imbalanced visual regression</article-title><source>Proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>21&#x02013;24 June 2022</conf-date><fpage>7926</fpage><lpage>7935</lpage></element-citation></ref><ref id="B61-sensors-25-01225"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Steininger</surname><given-names>M.</given-names></name>
<name><surname>Kobs</surname><given-names>K.</given-names></name>
<name><surname>Davidson</surname><given-names>P.</given-names></name>
<name><surname>Krause</surname><given-names>A.</given-names></name>
<name><surname>Hotho</surname><given-names>A.</given-names></name>
</person-group><article-title>Density-based weighting for imbalanced regression</article-title><source>Mach. Learn.</source><year>2021</year><volume>110</volume><fpage>2187</fpage><lpage>2211</lpage><pub-id pub-id-type="doi">10.1007/s10994-021-06023-5</pub-id></element-citation></ref><ref id="B62-sensors-25-01225"><label>62.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>B.</given-names></name>
<name><surname>Zhang</surname><given-names>C.</given-names></name>
<name><surname>Wong</surname><given-names>Y.D.</given-names></name>
<name><surname>Hou</surname><given-names>L.</given-names></name>
<name><surname>Zhang</surname><given-names>M.</given-names></name>
<name><surname>Xiang</surname><given-names>Y.</given-names></name>
</person-group><article-title>Comparing resampling algorithms and classifiers for modeling traffic risk prediction</article-title><source>Int. J. Environ. Res. Public Health</source><year>2022</year><volume>19</volume><elocation-id>13693</elocation-id><pub-id pub-id-type="doi">10.3390/ijerph192013693</pub-id><pub-id pub-id-type="pmid">36294267</pub-id>
</element-citation></ref><ref id="B63-sensors-25-01225"><label>63.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cai</surname><given-names>L.</given-names></name>
<name><surname>Yu</surname><given-names>Y.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
<name><surname>Song</surname><given-names>Y.</given-names></name>
<name><surname>Xiong</surname><given-names>Z.</given-names></name>
<name><surname>Zhou</surname><given-names>T.</given-names></name>
</person-group><article-title>A sample-rebalanced outlier-rejected <italic toggle="yes">k</italic>-nearest neighbor regression model for short-term traffic flow forecasting</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>22686</fpage><lpage>22696</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2970250</pub-id></element-citation></ref><ref id="B64-sensors-25-01225"><label>64.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhaowei</surname><given-names>Q.</given-names></name>
<name><surname>Haitao</surname><given-names>L.</given-names></name>
<name><surname>Zhihui</surname><given-names>L.</given-names></name>
<name><surname>Tao</surname><given-names>Z.</given-names></name>
</person-group><article-title>Short-term traffic flow forecasting method with MB-LSTM hybrid network</article-title><source>IEEE Trans. Intell. Transp. Syst.</source><year>2020</year><volume>23</volume><fpage>225</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1109/TITS.2020.3009725</pub-id></element-citation></ref><ref id="B65-sensors-25-01225"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Song</surname><given-names>Z.</given-names></name>
<name><surname>Guo</surname><given-names>Y.</given-names></name>
<name><surname>Wu</surname><given-names>Y.</given-names></name>
<name><surname>Ma</surname><given-names>J.</given-names></name>
</person-group><article-title>Short-term traffic speed prediction under different data collection time intervals using a SARIMA-SDGM hybrid prediction model</article-title><source>PLoS ONE</source><year>2019</year><volume>14</volume><elocation-id>e0218626</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0218626</pub-id><pub-id pub-id-type="pmid">31242226</pub-id>
</element-citation></ref><ref id="B66-sensors-25-01225"><label>66.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Iranmanesh</surname><given-names>S.</given-names></name>
<name><surname>Abkenar</surname><given-names>F.S.</given-names></name>
<name><surname>Jamalipour</surname><given-names>A.</given-names></name>
<name><surname>Raad</surname><given-names>R.</given-names></name>
</person-group><article-title>A Heuristic Distributed Scheme to Detect Falsification of Mobility Patterns in Internet of Vehicles</article-title><source>IEEE Internet Things J.</source><year>2022</year><volume>9</volume><fpage>719</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1109/JIOT.2021.3085315</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01225-f001"><label>Figure 1</label><caption><p>An overview of the general flow of the proposed methodology.</p></caption><graphic xlink:href="sensors-25-01225-g001" position="float"/></fig><fig position="float" id="sensors-25-01225-f002"><label>Figure 2</label><caption><p>Average Speed of 441 Segments separated to 5 different groups based on time of day.</p></caption><graphic xlink:href="sensors-25-01225-g002" position="float"/></fig><fig position="float" id="sensors-25-01225-f003"><label>Figure 3</label><caption><p>Percentage of data belonging to each time group.</p></caption><graphic xlink:href="sensors-25-01225-g003" position="float"/></fig><fig position="float" id="sensors-25-01225-f004"><label>Figure 4</label><caption><p>An example of how model creation using Hour-wise Pattern Organization works.</p></caption><graphic xlink:href="sensors-25-01225-g004" position="float"/></fig><fig position="float" id="sensors-25-01225-f005"><label>Figure 5</label><caption><p>The upper graphics present the MAPE scores of the LSTM model with and without hour-wise pattern organization. The lower part displays the MAPE difference between the two models. Green segments correspond to time regions where the applied method performs better, while red segments belong to regions where the base LSTM model is superior.</p></caption><graphic xlink:href="sensors-25-01225-g005" position="float"/></fig><fig position="float" id="sensors-25-01225-f006"><label>Figure 6</label><caption><p>Distribution of speed values within the dataset.</p></caption><graphic xlink:href="sensors-25-01225-g006" position="float"/></fig><fig position="float" id="sensors-25-01225-f007"><label>Figure 7</label><caption><p>Percentage of data regarding traffic density.</p></caption><graphic xlink:href="sensors-25-01225-g007" position="float"/></fig><fig position="float" id="sensors-25-01225-f008"><label>Figure 8</label><caption><p>An example of how model creation using Speed-wise Pattern Organization method works.</p></caption><graphic xlink:href="sensors-25-01225-g008" position="float"/></fig><fig position="float" id="sensors-25-01225-f009"><label>Figure 9</label><caption><p>Grouping speed values with the help of speed-wise pattern organization. The upper side of the figure shows the arrangement of the test samples, while the lower side shows the arrangement of the training samples.</p></caption><graphic xlink:href="sensors-25-01225-g009" position="float"/></fig><fig position="float" id="sensors-25-01225-f010"><label>Figure 10</label><caption><p>Comparison of the base LSTM model with the model applying Speed-wise Pattern Organization. The upper figure presents the MAPE values of two methods, whereas the lower figure illustrates the MAPE difference between them.</p></caption><graphic xlink:href="sensors-25-01225-g010" position="float"/></fig><fig position="float" id="sensors-25-01225-f011"><label>Figure 11</label><caption><p>Hourly average speed data of 5 consecutive months belonging to all 441 road segments in Istanbul.</p></caption><graphic xlink:href="sensors-25-01225-g011" position="float"/></fig><fig position="float" id="sensors-25-01225-f012"><label>Figure 12</label><caption><p>The average monthly MAPE values were obtained from a base LSTM model that was trained without any pattern organization scheme. Each color represents a different season.</p></caption><graphic xlink:href="sensors-25-01225-g012" position="float"/></fig><fig position="float" id="sensors-25-01225-f013"><label>Figure 13</label><caption><p>An illustration of the model development process with Month-wise Pattern Organization.</p></caption><graphic xlink:href="sensors-25-01225-g013" position="float"/></fig><fig position="float" id="sensors-25-01225-f014"><label>Figure 14</label><caption><p>Speed histograms of April and August. We present the speed values of the respective months in bins.</p></caption><graphic xlink:href="sensors-25-01225-g014" position="float"/></fig><fig position="float" id="sensors-25-01225-f015"><label>Figure 15</label><caption><p>This is a figure illustrating the comparison of month similarities obtained from the proposed methodology. In this heat map, a row depicts the similarity between the month it represents and the twelve previous months shown in the columns. The column designated February indicates the resemblance of the current year&#x02019;s January and February to February of the preceding year. However, March of this year has similarities to February of this year. The color gradient in this figure progresses from dark red, representing greater distance values, to bright green, denoting lesser distance values.</p></caption><graphic xlink:href="sensors-25-01225-g015" position="float"/></fig><fig position="float" id="sensors-25-01225-f016"><label>Figure 16</label><caption><p>MAPE ratings obtained from four base models. The base models exhibit the MAPE scores obtained without the application of additional methods. The Hour-wise Pattern Organization presents the outcomes obtained using the methodology outlined in <xref rid="sec3-sensors-25-01225" ref-type="sec">Section 3</xref>-A. Speed-wise Pattern Organization presents the outcomes obtained using the methodology outlined in <xref rid="sec3-sensors-25-01225" ref-type="sec">Section 3</xref>-B. The Month-wise Pattern Organization presents the outcomes obtained using the methodology outlined in <xref rid="sec3-sensors-25-01225" ref-type="sec">Section 3</xref>-C. The Multiple Method presents the outcomes obtained using the technique outlined in <xref rid="sec4-sensors-25-01225" ref-type="sec">Section 4</xref>-E.</p></caption><graphic xlink:href="sensors-25-01225-g016" position="float"/></fig><fig position="float" id="sensors-25-01225-f017"><label>Figure 17</label><caption><p>Hourly MAPE Difference between models trained with no additional process and models trained with the hour-wise pattern organization method.</p></caption><graphic xlink:href="sensors-25-01225-g017" position="float"/></fig><fig position="float" id="sensors-25-01225-f018"><label>Figure 18</label><caption><p>Hourly MAPE Difference between models trained with no additional process and models trained using the Speed-wise Pattern Organization method.</p></caption><graphic xlink:href="sensors-25-01225-g018" position="float"/></fig><table-wrap position="float" id="sensors-25-01225-t001"><object-id pub-id-type="pii">sensors-25-01225-t001_Table 1</object-id><label>Table 1</label><caption><p>Dataset and Input Specifications.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Information Name</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Value</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Data Size for Each Segment</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">365 Days</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Year</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2018</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Number of Segments</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">111</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Segment Length</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 km</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Interval</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5 min</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Input Shape</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7 &#x000d7; 6 (15 min Before and After &#x000d7;<break/>
6 Weeks Before Prediction)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prediction Horizon</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 Week</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01225-t002"><object-id pub-id-type="pii">sensors-25-01225-t002_Table 2</object-id><label>Table 2</label><caption><p>We analyze the effects of three proposed pattern organizing methods on the base LSTM model. The average MAPE scores for 111 segments are provided for the proposed preprocessing methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">MAPE</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Difference with Base Model</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>No Pattern Organization</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.74</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Hour-wise Pattern</bold>
<break/>
<bold>Organization</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.49</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.25</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Speed-wise Pattern</bold>
<break/>
<bold>Organization</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.18</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.56</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Month-wise Pattern</bold>
<break/>
<bold>Organization</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.14</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01225-t003"><object-id pub-id-type="pii">sensors-25-01225-t003_Table 3</object-id><label>Table 3</label><caption><p>Month similarity information calculated by the proposed method regarding the traffic characteristics of corresponding months.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Most Similar</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">2nd Most Similar</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">3rd Most Similar</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">4th Most Similar</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">5th Most Similar</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">6th Most Similar</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Jan</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dec</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sep</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Feb</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jan</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dec</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sep</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Mar</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Feb</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dec</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jan</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sep</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Apr</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dec</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Feb</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jan</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>May</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dec</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jan</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Jun</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dec</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jan</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Jul</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jun</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Aug</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jul</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jun</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Sep</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jul</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jun</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Oct</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sep</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jul</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jun</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Nov</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sep</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Apr</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jul</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Dec</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Nov</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sep</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Oct</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mar</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Jul</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">May</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01225-t004"><object-id pub-id-type="pii">sensors-25-01225-t004_Table 4</object-id><label>Table 4</label><caption><p>Hyper-parameters tested and used in our experiments.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Hyper-<break/>Parameters</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Tested<break/>Range</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LSTM</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CNN</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Bi-<break/>Directional</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GRU</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Layer Count</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1&#x02013;3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 RNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2 Conv</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 RNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 RNN</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Layer Hidden</bold>
<break/>
<bold>Nodes</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32&#x02013;1024</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">256</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">128</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">512</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">512</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Dense Layer</bold>
<break/>
<bold>Count</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0&#x02013;3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Dense Layer</bold>
<break/>
<bold>Hidden Nodes</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32&#x02013;1024</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">128</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">128</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">128</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">256</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Dropout</bold>
<break/>
<bold>Percentage</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0&#x02013;50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Learning Rate</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0001&#x02013;0.1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01225-t005"><object-id pub-id-type="pii">sensors-25-01225-t005_Table 5</object-id><label>Table 5</label><caption><p>The performance of LSTM, bi-directional LSTM (BD), GRU, and CNN models is affected by month-wise pattern organization (MPO).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LSTM Base</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LSTM MPO</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BD Base</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BD MPO</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CNN Base</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CNN MPO</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GRU Base</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GRU MPO</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Jan</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.52</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.41</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.47</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.39</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.35</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Feb</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.82</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.78</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.68</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.68</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.69</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.68</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.78</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.74</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Mar</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.42</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.34</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.48</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.3</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Apr</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.61</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.49</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.63</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.42</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>May</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.63</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.68</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.41</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.61</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.56</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Jun</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.82</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.76</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.63</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.92</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.68</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Jul</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.68</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.53</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.58</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.63</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.7</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Aug</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.48</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.41</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.36</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.36</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.49</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Sep</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.81</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.51</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">17.06</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.72</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.63</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.39</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.55</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.38</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Oct</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.91</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.58</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.64</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.44</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.85</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.46</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.58</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.47</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Nov</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.85</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.61</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.65</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.44</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.48</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.39</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.27</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Dec</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.72</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.55</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.74</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.47</td></tr></tbody></table></table-wrap></floats-group></article>