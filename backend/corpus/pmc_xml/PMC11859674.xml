<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006317</article-id><article-id pub-id-type="pmc">PMC11859674</article-id><article-id pub-id-type="doi">10.3390/s25041088</article-id><article-id pub-id-type="publisher-id">sensors-25-01088</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Restoration of Turbid Underwater Images of Cobalt Crusts Using Combined Homomorphic Filtering and a Polarization Imaging System</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0008-5825-507X</contrib-id><name><surname>Peng</surname><given-names>Enzu</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af1-sensors-25-01088" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Chengyi</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="af1-sensors-25-01088" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0026-8299</contrib-id><name><surname>Zhao</surname><given-names>Haiming</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af1-sensors-25-01088" ref-type="aff">1</xref><xref rid="af2-sensors-25-01088" ref-type="aff">2</xref><xref rid="c1-sensors-25-01088" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Deng</surname><given-names>Liang-Jian</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01088"><label>1</label>The College of Mechanical and Electrical Engineering, Central South University, Changsha 410083, China; <email>8204222401@csu.edu.cn</email> (E.P.); </aff><aff id="af2-sensors-25-01088"><label>2</label>State Key Laboratory of High Performance Complex Manufacturing, Central South University, Changsha 410083, China</aff><author-notes><corresp id="c1-sensors-25-01088"><label>*</label>Correspondence: <email>zhm0097@126.com</email></corresp></author-notes><pub-date pub-type="epub"><day>11</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1088</elocation-id><history><date date-type="received"><day>23</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>31</day><month>1</month><year>2025</year></date><date date-type="accepted"><day>10</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Marine cobalt-rich crusts, extensively used in industries such as aerospace, automotive, and electronics, are crucial mineral resources located on the ocean floor. To effectively exploit these valuable resources, underwater imaging is essential for real-time detection and distribution mapping in mining areas. However, the presence of suspended particles in the seabed mining environment severely degrades image quality due to light scattering and absorption, hindering the effective identification of the target objects. Traditional image processing techniques&#x02014;including spatial and frequency domain methods&#x02014;are ineffective in addressing the interference caused by suspended particles and offer only limited enhancement effects. This paper proposes a novel underwater image restoration method that combines polarization imaging and homomorphic filtering. By exploiting the differences in polarization characteristics between suspended particles and target objects, polarization imaging is used to separate backscattered light from the target signal, enhancing the clarity of the cobalt crust images. Homomorphic filtering is then applied to improve the intensity distribution and contrast of the orthogonal polarization images. To optimize the parameters, a genetic algorithm is used with image quality evaluation indices as the fitness function. The proposed method was compared with traditional image processing techniques and classical polarization imaging methods. Experimental results demonstrate that the proposed approach more effectively suppresses backscattered light, enhancing the clarity of target object features. With significant improvements in image quality confirmed by several no-reference quality metrics, the method shows promise as a solution for high-quality underwater imaging in turbid environments, particularly for deep-sea mining of cobalt-rich crusts.</p></abstract><kwd-group><kwd>homomorphic filtering</kwd><kwd>polarization imaging</kwd><kwd>backscattered light</kwd><kwd>imaging through turbid media</kwd><kwd>cobalt crust</kwd></kwd-group><funding-group><award-group><funding-source>National Natural Science Foundation of China</funding-source><award-id>51874353</award-id></award-group><award-group><funding-source>China Ocean Mineral Resources R&#x00026;D Association</funding-source></award-group><funding-statement>This research was funded by National Natural Science Foundation of China, grant number 51874353. We wish to thank the China Ocean Mineral Resources R&#x00026;D Association for distributing deep-sea trawl samples.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01088"><title>1. Introduction</title><p>Cobalt is an important mineral resource widely used in aerospace, aviation, automotive, chemical, ceramics, and other industries. Marine cobalt crust resources are richer than those on land, mainly existing attached to bedrock, but the surface coverage is only about 50% [<xref rid="B1-sensors-25-01088" ref-type="bibr">1</xref>]. With continuous surveys since the end of the last century, research on seafloor cobalt crusts has shifted from mining area detection to exploration and extraction [<xref rid="B2-sensors-25-01088" ref-type="bibr">2</xref>]. Real-time identification of cobalt crusts is a crucial prerequisite for mining; therefore, accurately detecting and identifying the distribution of deep-sea cobalt crust deposits is of great significance.</p><p>Currently, underwater target detection mainly employs two methods: sonar detection and optical imaging. Sonar detection has the advantages of a wide detection range and strong anti-interference capability, but, due to limitations in the number of beams and recognition accuracy, the efficiency of substrate identification within the area is not high. Optical imaging methods can obtain richer and more intuitive information, enhancing recognition efficiency and accuracy. However, during actual mining operations, sediment stirred up by mining equipment can significantly interfere with imaging effects, causing images to become blurred and &#x0201c;foggy&#x0201d;, leading to the loss of target details. To achieve precise excavation and minimize the image degradation effects caused by suspended particles, further research on imaging technology in turbid underwater environments is necessary.</p><p>Underwater image processing technologies are mainly divided into image enhancement techniques based on pixel transformation and image restoration methods based on degradation models. Common methods include histogram-based processing, Retinex theory-based methods, image fusion, and deep learning-based underwater image enhancement [<xref rid="B3-sensors-25-01088" ref-type="bibr">3</xref>]. These methods process images by directly manipulating pixels or by inversely solving degradation models, with their effectiveness directly dependent on the original image and the constructed prior model. However, due to the lack of information about actual interference sources and the inability to avoid inherent interference from suspended particles present in the scene, the fundamental problem of reduced image clarity remains unsolved, limiting the ability to restore target details.</p><p>In contrast, polarization imaging is based on physical imaging models. By capturing images of the same scene under different polarization states and exploiting the differences in polarization characteristics between scattered light and target signal light, it calculates the degree of polarization of backscattered light and the transmission coefficient. This enables the separation of scattered light from the target signal light, thereby achieving clearer imaging. In 2003 and 2005, Schechner et al. proposed a polarization imaging model and a passive underwater polarization imaging model, respectively [<xref rid="B4-sensors-25-01088" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-01088" ref-type="bibr">5</xref>], marking the first introduction of underwater imaging de-scattering models. However, in practical applications, due to the high attenuation coefficient in underwater environments and the weakness of natural illumination, imaging requirements are not met, researchers began adopting active illumination in polarization imaging systems. Treibitz et al. [<xref rid="B6-sensors-25-01088" ref-type="bibr">6</xref>] proposed an active polarization de-scattering model in turbid water. One of the assumptions of this method is that the degree of polarization of background scattered light is constant. Under active illumination, the light field is non-uniform, leading to an uneven spatial distribution of the degree of polarization of background scattered light in the scene. This makes it difficult to fully suppress backscattered light, and issues of image detail degradation and uneven illumination still exist.</p><p>To more accurately calculate the spatial distribution of the degree of polarization of scattered light and improve imaging quality, researchers have studied this from different perspectives. Liu et al. [<xref rid="B7-sensors-25-01088" ref-type="bibr">7</xref>] proposed an underwater image restoration method based on Stokes decomposition, but this method requires orthogonal polarized illumination, increasing the requirements for experimental equipment. Li et al. [<xref rid="B8-sensors-25-01088" ref-type="bibr">8</xref>] obtained the degree of polarization of experimental objects and background scattered light using optimization algorithms but ignored the global differences in the degree of polarization within the image. Hu et al. [<xref rid="B9-sensors-25-01088" ref-type="bibr">9</xref>] removed the light from the target object area of the polarized image and used information from the background area to perform polynomial fitting on the light intensity and degree of polarization in the target object area, estimating a more accurate global degree of polarization value. However, the experiments in this study were conducted in a water tank constructed with acrylic plates, the camera&#x02019;s shooting range was small, and the target objects were simple, with low grayscale levels used. This differs significantly from wide water environments, limiting the applicability of the method. Wang et al. [<xref rid="B10-sensors-25-01088" ref-type="bibr">10</xref>] suppressed the impact of active illumination non-uniformity through frequency-domain homogenization and polarization-weighted fusion. However, the local DoLP-based weight calculation inadequately corrected the global spatial distribution differences in the polarization degree of scattered light, which may result in residual gradient effects under complex light fields. Shen et al. [<xref rid="B11-sensors-25-01088" ref-type="bibr">11</xref>] mitigated scattering and illumination non-uniformity through iterative polarization optimization. However, the globally uniform scattering correction parameters failed to adapt to local polarization attenuation variations in complex substrates, which may lead to reduced stability in detail reconstruction for highly heterogeneous seabed regions. Li et al. [<xref rid="B12-sensors-25-01088" ref-type="bibr">12</xref>] mitigated underwater illumination non-uniformity using polarizing lenses and averaging filters. But, the fixed parameter set for scattering light correction failed to adapt to spatial variations in complex seabed environments, resulting in unstable scattering suppression performance within high-turbidity zones.</p><p>Homomorphic filtering (HF) combines frequency filtering and spatial gray-level transformation. Based on the illumination&#x02013;reflectance model of images as the foundation for frequency domain processing, setting appropriate parameters can compress the global brightness range, meeting image restoration requirements in complex scenes. Therefore, to mitigate the effects of uneven active illumination and address the uneven distribution of the global degree of polarization in scattering in images without significantly increasing system complexity, this paper incorporates homomorphic filtering into the classical polarization restoration method. By applying homomorphic filtering to the original orthogonally polarized images, the contrast of the images is enhanced, and the light intensity is balanced. While maintaining the polarization relationship is unchanged, the corresponding polarization images are obtained, reducing spatial differences in the degree of polarization and suppressing backscattered light. After optimizing various parameters using a genetic algorithm, the polarization restoration algorithm is employed to ultimately achieve clear imaging in turbid water environments.</p></sec><sec id="sec2-sensors-25-01088"><title>2. Fundamental Theory</title><sec id="sec2dot1-sensors-25-01088"><title>2.1. Underwater Imaging Model</title><p>The Jaffe&#x02013;McGlamery model [<xref rid="B13-sensors-25-01088" ref-type="bibr">13</xref>] is a classic and commonly used underwater imaging model. This model indicates that the total light intensity received by an underwater imaging system is composed of a linear superposition of direct components, forward scattering components, and backscattering components. In turbid water imaging environments, the primary factor leading to image quality degradation is the interference of backscattered light. Neglecting the forward scattering component, the total light intensity <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as the sum of the target reflected light <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the backscattered light <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD1-sensors-25-01088"><label>(1)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Among them, the target reflected light <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is the original reflected light <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (the restored image) that enters the camera after absorption and scattering by particles, represented as the product of the original reflected light <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the transmittance <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The target reflected light <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is inversely proportional to the transmittance of the backscattered light <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore, the backscattered light is expressed as the product of the backscattered light at infinity <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x0221e;</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (corresponding to the background region in the image) and the transmittance function <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD2-sensors-25-01088"><label>(2)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD3-sensors-25-01088"><label>(3)</label><mml:math id="mm14" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x0221e;</mml:mo></mml:msub><mml:mfenced close="]" open="["><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>By substituting Equations (2) and (3) into Equation (1) and simplifying, formulas for calculating the transmission rate <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and the restored image <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> are derived.<disp-formula id="FD4-sensors-25-01088"><label>(4)</label><mml:math id="mm17" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x0221e;</mml:mo></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD5-sensors-25-01088"><label>(5)</label><mml:math id="mm18" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec2dot2-sensors-25-01088"><title>2.2. Orthogonally Polarized Images</title><p>After passing through a fixed linear polarizer (polarizer), the active light source becomes linearly polarized light. By rotating the linear polarizer (analyzer) in front of the camera lens, orthogonally polarized images of the same scene can be captured. When the analyzer is aligned parallel to the polarizer, the maximum intensity image <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is obtained; when it is perpendicular, the minimum intensity image <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is obtained. The total intensity <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the sum of these two images, combined with Equation (1):<disp-formula id="FD6-sensors-25-01088"><label>(6)</label><mml:math id="mm22" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Cobalt crusts exhibit low polarization characteristics due to their irregular surfaces and porous medium properties. Assuming that the polarization direction of the target reflected light <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is completely random (unpolarized), we have this equation:<disp-formula id="FD7-sensors-25-01088"><label>(7)</label><mml:math id="mm24" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Under this assumption, the target reflected light components <inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in both the maximum and minimum intensity images are equal. Combining Equations (6) and (7), this can be expressed:<disp-formula id="FD8-sensors-25-01088"><label>(8)</label><mml:math id="mm26" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>D</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>+</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD9-sensors-25-01088"><label>(9)</label><mml:math id="mm27" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>+</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Subtracting Equation (9) from Equation (8) shows that the difference image between the orthogonally polarized images <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> equals the difference in backscattered light <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD10-sensors-25-01088"><label>(10)</label><mml:math id="mm30" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Due to water interference and the uneven illumination caused by active lighting, the degree of polarization of scattered light <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> varies across the image. Using only the original orthogonally polarized images <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, traditional polarization restoration methods cannot effectively separate the backscattered light from the target reflected light, making it difficult to achieve satisfactory imaging results.</p></sec><sec id="sec2dot3-sensors-25-01088"><title>2.3. Homomorphic Filtering Preprocessing</title><p>Homomorphic filtering is an image processing method that combines frequency filtering with spatial domain grayscale transformations. Using the illumination&#x02013;reflectance model of the image as the foundation for frequency domain processing, it can compress the brightness range and enhance contrast. This approach can overcome the shortcomings of traditional polarization restoration methods to a certain extent without complicating the model. The homomorphic filtering applied to an image can be expressed:<disp-formula id="FD11-sensors-25-01088"><label>(11)</label><mml:math id="mm34" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>&#x003bc;</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced><mml:mo>&#x02217;</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD12-sensors-25-01088"><label>(12)</label><mml:math id="mm35" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>exp</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are the high-frequency and low-frequency gains, respectively; <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> is the sharpening coefficient; and <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the cutoff frequency.</p><p>A pair of orthogonally polarized images has a fixed polarization relationship, defined by the global degree of polarization <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD13-sensors-25-01088"><label>(13)</label><mml:math id="mm41" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>To maintain the inherent polarization relationship of the orthogonally polarized images after filtering, homomorphic filtering is applied only to the maximum intensity image <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to obtain <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The corresponding minimum intensity image <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is then derived using the degree of polarization, ensuring that the degree of polarization of each pair of orthogonally polarized images <inline-formula><mml:math id="mm45" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> remains unchanged before and after filtering [<xref rid="B14-sensors-25-01088" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-01088" ref-type="bibr">15</xref>]:<disp-formula id="FD14-sensors-25-01088"><label>(14)</label><mml:math id="mm46" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD15-sensors-25-01088"><label>(15)</label><mml:math id="mm47" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec2dot4-sensors-25-01088"><title>2.4. Polarization Restoration</title><p>The degree of polarization of the backscattered light in the background region <inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as:<disp-formula id="FD16-sensors-25-01088"><label>(16)</label><mml:math id="mm49" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the horizontally and vertically polarized components of the homomorphic filtered backscattered light, respectively.</p><p>The degree of polarization of the backscattered light <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is taken from the average value of the background region of the image.<disp-formula id="FD17-sensors-25-01088"><label>(17)</label><mml:math id="mm53" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> varies across the background region, it is multiplied by a correction coefficient <inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow></mml:math></inline-formula> [<xref rid="B4-sensors-25-01088" ref-type="bibr">4</xref>] to reduce errors. The backscattered light <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is then calculated:<disp-formula id="FD18-sensors-25-01088"><label>(18)</label><mml:math id="mm57" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b5;</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The backscattered light at infinity <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x0221e;</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is obtained by averaging the backscattered light in the background region:<disp-formula id="FD19-sensors-25-01088"><label>(19)</label><mml:math id="mm59" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x0221e;</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Finally, the transmittance <inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the restored image <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are calculated:<disp-formula id="FD20-sensors-25-01088"><label>(20)</label><mml:math id="mm62" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b5;</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x0221e;</mml:mo></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD21-sensors-25-01088"><label>(21)</label><mml:math id="mm63" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b5;</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec2dot5-sensors-25-01088"><title>2.5. Image Quality Assessment and Optimization</title><p>To objectively evaluate the restoration effect, we introduce the image enhancement measure (EME) [<xref rid="B16-sensors-25-01088" ref-type="bibr">16</xref>] under no-reference conditions as a quantitative metric for assessing the quality of the restored images:<disp-formula id="FD22-sensors-25-01088"><label>(22)</label><mml:math id="mm64" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>M</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="|" open="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mi>log</mml:mi><mml:mfenced><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>i</mml:mi><mml:mrow><mml:mi>max</mml:mi><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>i</mml:mi><mml:mrow><mml:mi>min</mml:mi><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, the image is divided into <inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> blocks; <inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>i</mml:mi><mml:mrow><mml:mi>max</mml:mi><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>i</mml:mi><mml:mrow><mml:mi>min</mml:mi><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the maximum and minimum intensities in the <inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:math></inline-formula>-th block; and <inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> (set to 0.001) is a infinitesimal value to prevent division by zero. A higher EME value indicates clearer image details and better image quality. Additionally, the EME value serves as the fitness function in the genetic algorithm to optimize the parameters of homomorphic filtering and polarization restoration.</p></sec><sec id="sec2dot6-sensors-25-01088"><title>2.6. Polarization Image Restoration Procedure</title><p>The following is a flowchart of the proposed method: see <xref rid="sensors-25-01088-f001" ref-type="fig">Figure 1</xref>.</p><p>The method proposed begins by acquiring the original image <inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, along with its horizontal <inline-formula><mml:math id="mm71" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and vertical <inline-formula><mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> polarization components. The degree of polarization <inline-formula><mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is calculated by superimposing <inline-formula><mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm75" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Subsequently, homomorphic filtering is applied to <inline-formula><mml:math id="mm76" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, resulting in the filtered image <inline-formula><mml:math id="mm77" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Based on <inline-formula><mml:math id="mm78" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm79" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the corresponding orthogonal polarization image <inline-formula><mml:math id="mm80" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is derived. Polarization restoration is performed by selecting the compensation coefficient <inline-formula><mml:math id="mm81" overflow="scroll"><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow></mml:math></inline-formula> and minimum transmittance <inline-formula><mml:math id="mm82" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, yielding the final restored image <inline-formula><mml:math id="mm83" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>. Finally, image quality evaluation metrics (EME) are employed to assess <inline-formula><mml:math id="mm84" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, the EME assessment also served as fitness function to optimize the parameters of homomorphic filtering and polarization restoration.</p></sec></sec><sec id="sec3-sensors-25-01088"><title>3. Experimental Design</title><sec id="sec3dot1-sensors-25-01088"><title>3.1. Water Tank Simulating Mining Environment</title><p>Due to the high cost of conducting experiments in a real deep-sea mining environment and to reduce experimental difficulty, a detection experimental system simulating the deep-sea mining environment was designed and established, as shown in <xref rid="sensors-25-01088-f002" ref-type="fig">Figure 2</xref>. The experimental water tank has dimensions of length 5 m, width 3 m, and height 1.8 m. A set of straight-blade impellers positioned 0.3 m above the bottom of the tank was used to simulate the spiral mining head. The impellers were driven to rotate by a reduction motor through chain transmission, stirring the sediments at the bottom of the tank. Fluent 2023R1 software was utilized to simulate the impact of the spiral mining head and multiple impeller models on the underwater flow field, confirming that the experimental model can effectively reflect the real mining environment [<xref rid="B17-sensors-25-01088" ref-type="bibr">17</xref>].</p></sec><sec id="sec3dot2-sensors-25-01088"><title>3.2. Experimental Equipment and Samples</title><p>The experimental setup utilized the LBF-C50HD3 model three-in-one digital underwater camera manufactured by Robotfish Co., (Qingdao, China), as shown in <xref rid="sensors-25-01088-f003" ref-type="fig">Figure 3</xref>. This system includes an underwater camera (2 megapixels, 1/2.8-inch CMOS sensor, resolution ratio of 1920 &#x000d7; 1080), two LED underwater illumination lights, and a rotating cleaning brush. These components are integrated with linear polarizers to facilitate active polarized light illumination and the acquisition of orthogonally polarized images. The cobalt crust samples used in the experiment, sourced from deep-sea trawl samples as shown in <xref rid="sensors-25-01088-f004" ref-type="fig">Figure 4</xref>, were placed at the bottom of a water tank, 20 cm away from the camera. To simulate sediments, 100 kg of fine river sand with particle sizes of less than 1 mm was pre-deposited at the bottom of the tank.</p></sec><sec id="sec3dot3-sensors-25-01088"><title>3.3. Image Acquisition</title><p>To avoid interference from natural light, the experiment was conducted at night. The impeller rotation speed was set to 30 rpm, and, after stable operation, images of the cobalt crust were captured. By fixing the orientations of the polarizers at the two light sources and rotating the polarizer (analyzer) in front of the lens in <xref rid="sensors-25-01088-f003" ref-type="fig">Figure 3</xref> to be parallel and perpendicular to polarizers, respectively, the maximum intensity image and the minimum intensity image of the orthogonally polarized images <inline-formula><mml:math id="mm85" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm86" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x022a5;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> were obtained, as shown in <xref rid="sensors-25-01088-f005" ref-type="fig">Figure 5</xref>a,b. In polarization restoration methods, the key to restoration quality lies in the accurate evaluation of the degree of polarization of backscattered light <inline-formula><mml:math id="mm87" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and the backscattered light at infinity <inline-formula><mml:math id="mm88" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x0221e;</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Since the maximum intensity image <inline-formula><mml:math id="mm89" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>I</mml:mi><mml:mo>&#x02225;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> retains most of the backscattered light, applying homomorphic filtering to it can more effectively compress the brightness range of the backscattered light, making subsequent calculations more accurate. Finally, the filtered maximum intensity image <inline-formula><mml:math id="mm90" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is associated with the global degree of polarization <inline-formula><mml:math id="mm91" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to derive the corresponding minimum intensity image <inline-formula><mml:math id="mm92" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#x022a5;</mml:mo></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, as shown in <xref rid="sensors-25-01088-f005" ref-type="fig">Figure 5</xref>c,d. This approach maximizes the suppression of scattered light and highlights the texture details of the target object while maintaining the inherent polarization relationships.</p></sec><sec id="sec3dot4-sensors-25-01088"><title>3.4. Advantages of the Proposed Method</title><p>Compared to existing methods, aside from the differences in principles, the method presented in this paper offers several advantages. Complex experimental setups (such as high-frequency iterative optimization [<xref rid="B11-sensors-25-01088" ref-type="bibr">11</xref>]) are not required, and real-time underwater image restoration can be achieved with relatively lower computational resource demands, thus fulfilling the requirements for real-time identification in deep-sea mining operations. Additionally, the experimental system developed in this paper demonstrates a high degree of simulation accuracy, more effectively reflecting image degradation in actual mining environments, thereby enhancing the reliability and adaptability of the method in practical applications.</p></sec></sec><sec sec-type="results" id="sec4-sensors-25-01088"><title>4. Results and Discussion</title><sec id="sec4dot1-sensors-25-01088"><title>4.1. Parameter Optimization</title><p>Homomorphic filtering can simultaneously adjust brightness and improve contrast, but it has many parameters, and the optimal values are related to the specific filtered images. Randomly selecting parameters may result in blurred details and unclear contours; therefore, experimental testing is necessary to determine them. In the polarization restoration process, the selection of the correction coefficient <inline-formula><mml:math id="mm93" overflow="scroll"><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow></mml:math></inline-formula> in Equation (18) plays a crucial role in the final restoration effect. Additionally, to avoid incorrect estimation of the transmittance <inline-formula><mml:math id="mm94" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in complex environments [<xref rid="B19-sensors-25-01088" ref-type="bibr">19</xref>], we imposed a lower bound on the transmittance <inline-formula><mml:math id="mm95" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD23-sensors-25-01088"><label>(23)</label><mml:math id="mm96" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02265;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Based on the experiments conducted in this manuscript and references [<xref rid="B20-sensors-25-01088" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-01088" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-01088" ref-type="bibr">22</xref>,<xref rid="B23-sensors-25-01088" ref-type="bibr">23</xref>], the parameter ranges are set as follows: <inline-formula><mml:math id="mm97" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm98" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm99" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:mi>c</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm100" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm101" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x003b5;</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>1.3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm102" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Using the EME value as the fitness function, a genetic algorithm is employed to optimize the parameters within these intervals, yielding the optimal values: <inline-formula><mml:math id="mm103" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm104" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.87</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm105" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>2.48</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm106" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>49</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm107" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003b5;</mml:mi><mml:mo>=</mml:mo><mml:mn>1.29</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm108" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.087</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="sec4dot2-sensors-25-01088"><title>4.2. Comparison with Schechner&#x02019;s Method</title><p>The restored image obtained using the above parameters is shown in <xref rid="sensors-25-01088-f006" ref-type="fig">Figure 6</xref>a. For comparison, the restored image obtained using the classical Schechner method is also presented in <xref rid="sensors-25-01088-f006" ref-type="fig">Figure 6</xref>b. To facilitate clearer detail comparison and quantitative analysis, the regions within the red boxes in <xref rid="sensors-25-01088-f006" ref-type="fig">Figure 6</xref>a,b are enlarged, as shown in <xref rid="sensors-25-01088-f006" ref-type="fig">Figure 6</xref>c,d.</p><p>In <xref rid="sensors-25-01088-f006" ref-type="fig">Figure 6</xref>a, the background region appears pure black due to the suppression of backscattered light, resulting in high contrast with the target object, making the boundary between the target object and the background distinguishable. As seen in <xref rid="sensors-25-01088-f006" ref-type="fig">Figure 6</xref>c, the key texture details of the cobalt-rich crust are richer. The EME values for the images in <xref rid="sensors-25-01088-f006" ref-type="fig">Figure 6</xref> are calculated as EME(a) = 0.7414, EME(b) = 0.6077, EME(c) = 1.3879, and EME(d) = 1.1125, with EME(a) &#x0003e; EME(b) and EME(c) &#x0003e; EME(d). This analysis indicates that the proposed method suppresses backscattered light more effectively than Schechner&#x02019;s method, better addressing the issue of uneven backscattered light distribution caused by non-uniform illumination. The overall image quality and target details are both enhanced.</p></sec><sec id="sec4dot3-sensors-25-01088"><title>4.3. Comparison with Image Enhancement Methods</title><p>To further verify the advantages of the proposed method over other methods, three commonly used image enhancement methods&#x02014;CLAHE, Retinex, and HF&#x02014;were employed for comparative study, as shown in <xref rid="sensors-25-01088-f007" ref-type="fig">Figure 7</xref>. There is a significant difference between the images obtained using the polarization restoration method (<xref rid="sensors-25-01088-f007" ref-type="fig">Figure 7</xref>b,c) and those obtained using digital image enhancement methods, manifested in the suppression of scattered light, reduced overall brightness, and significantly enhanced texture details of the target object. Compared with other experiments that use a smaller field of view and increased turbidity using milk [<xref rid="B9-sensors-25-01088" ref-type="bibr">9</xref>,<xref rid="B23-sensors-25-01088" ref-type="bibr">23</xref>], in the broader water body containing sediment deposits, the background region has uneven scattering and the gray-level variations on the cobalt-rich crust surface are drastic. The CLAHE and Retinex methods not only fail to restore the image but also increase noise in the background region. Although applying HF directly to the original light intensity image improves contrast and image quality to certain extent, the texture details of the cobalt-rich crust are not effectively recovered.</p></sec><sec id="sec4dot4-sensors-25-01088"><title>4.4. Image Quality Evaluation Metrics</title><p>To provide a more comprehensive quantitative analysis of each restored image, in addition to the previously mentioned EME, two other no-reference image quality evaluation metrics were introduced for comprehensive assessment: BRISQUE [<xref rid="B24-sensors-25-01088" ref-type="bibr">24</xref>], based on image statistical features, and IC [<xref rid="B4-sensors-25-01088" ref-type="bibr">4</xref>], representing the image&#x02019;s local contrast, as shown in <xref rid="sensors-25-01088-t001" ref-type="table">Table 1</xref>. It should be noted that higher values of IC and EME indicate better image quality, whereas a lower BRISQUE value signifies better image quality. The EME value is calculated as the average of the ratio function of the maximum and minimum gray-level values within each region of the image, and the IC value depends on the degree of gray-level variation in the image.</p><p>However, since the CLAHE and Retinex methods introduce noise, which in turn increases the overall image contrast and results in higher numerical values, they cannot effectively reflect the actual image quality; therefore, they are marked with an asterisk *. Comparing the other methods, it can be seen that the proposed method in this paper achieves the highest numerical values. By analyzing the BRISQUE values of each restored image, it is evident that the restored images using the polarization method demonstrate a substantial improvement over other methods, indicating a substantial enhancement in image quality.</p></sec><sec id="sec4dot5-sensors-25-01088"><title>4.5. Image Enhancement Under Varying Conditions</title><p>To further validate the robustness and effectiveness of the proposed method in different scenarios, the shooting angle of the cobalt-rich crust was adjusted, and the rotation speed of the impeller was increased to alter the water&#x02019;s turbidity. After achieving stable operation, polarized images were captured, resulting in high-turbidity images as shown in <xref rid="sensors-25-01088-f008" ref-type="fig">Figure 8</xref>b. In <xref rid="sensors-25-01088-f008" ref-type="fig">Figure 8</xref>c, the scattered light in the background region is suppressed, and the target details have been restored to a certain extent. In <xref rid="sensors-25-01088-f008" ref-type="fig">Figure 8</xref>d, the target boundaries are unclear, and the target exhibits fewer gray levels; compared to <xref rid="sensors-25-01088-f008" ref-type="fig">Figure 8</xref>c, more details are missing. The EME values of each image were calculated as EME(a) = 0.6138, EME(b) = 0.4849, EME(c) = 1.0133, and EME(d) = 0.7949, satisfying the inequality EME(c) &#x0003e; EME(d) &#x0003e; EME(a) &#x0003e; EME(b). These results demonstrate that the proposed method in this paper maintains advantages over classical methods in enhancing image quality.</p><p>The sediment particles employed in the experiment exhibit intrinsic consistency with genuine deep-sea suspended particles in optical interference mechanisms. The silicon-oxygen framework structures of quartz/feldspar components in sediments demonstrate less than 8% refractive index discrepancy compared to deep-sea bedrock fragments (pyroxene, plagioclase), with both particle size distributions (sediment <inline-formula><mml:math id="mm110" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mn>50</mml:mn><mml:mo>=</mml:mo><mml:mn>18.5</mml:mn><mml:mo>&#x000a0;</mml:mo><mml:mi mathvariant="normal">&#x003bc;</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, cobalt crust debris <inline-formula><mml:math id="mm111" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mn>50</mml:mn><mml:mo>=</mml:mo><mml:mn>22</mml:mn><mml:mo>&#x000a0;</mml:mo><mml:mi mathvariant="normal">&#x003bc;</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm112" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mn>50</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> represents the median diameter of the particles) residing within the scattering-dominated regime [<xref rid="B25-sensors-25-01088" ref-type="bibr">25</xref>]. This ensures universal suppression capability against wide-angle scattering noise. For deep-sea-specific metallic oxide fragments (e.g., ferromanganese nodules), the proposed method suppresses strong specular reflections from metallic particles through polarization-based scattering separation mechanism (Equations (5)&#x02013;(7)). Although constrained by deep-sea in situ experimental conditions, theoretical analysis and characteristic mapping confirm that sediment scattering properties encompass core interference patterns of multiple deep-sea suspended particle types. Combined with the algorithm&#x02019;s synergistic optimization of polarization disparity and spatial intensity distribution, this substantiates the method&#x02019;s adaptability to authentic cobalt crust mining environments. Subsequent in situ verification through deep-sea exploration equipment integration should be conducted to enhance performance evaluation frameworks.</p></sec><sec id="sec4dot6-sensors-25-01088"><title>4.6. Practical Application Potential and Engineering Challenges</title><p>The deployment of polarization imaging technology faces challenges in cost and system integration. High-precision polarization cameras and pressure-resistant components significantly increase hardware costs. Additionally, electrical synchronization and mechanical adaptation with existing mining systems (e.g., sonar and robotic arms) are required. The high frame rate needed for polarization image transmission demands a communication bandwidth over 50 Mbps, which necessitates preprocessing through edge computing. Experimental validation indicates scalability for operational ranges of several tens of meters, but further testing is required in complex terrains like fissures and steep slopes. To improve adaptability, lightweight algorithms such as model quantization could enhance edge computing performance.</p><p>In terms of mining efficiency, the proposed method improved the image&#x02019;s EME value by 103%, from 0.6138 to 1.2488, and local contrast by 64%. The BRISQUE score decreased by 31%, indicating a substantial improvement in image quality. Additionally, the improved surface texture and boundary recognition of the cobalt crust allowed for more accurate robotic arm path planning. The integration of sonar data fusion optimized excavation trajectories, while dynamic turbid environments were managed through adaptive parameter updates, maintaining algorithm robustness.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-01088"><title>5. Conclusions</title><p>In this paper, an underwater image restoration method combining digital image processing techniques with polarization imaging is proposed to address the imaging requirements of cobalt-rich crusts in deep-sea mining environments. This method effectively integrates homomorphic filtering with classical polarization restoration and introduces a genetic algorithm to optimize parameter values. Addressing the issue of uneven global polarization degree. Underwater imaging experiments were conducted under different scenarios. The results were compared with other methods using three no-reference image quality evaluation metrics: IC, EME, and BRISQUE. Compared with previous methods, the combination of homomorphic filtering and polarization imaging can effectively suppress scattered light in the background regions of wider water bodies containing sediment deposits, thereby enhancing the contrast of texture details on the surface of the target cobalt-rich crust. Finally, the practical application potential and engineering challenges of this algorithm are analyzed.</p><p>Due to experimental limitations, the detection range of the underwater camera was relatively short. Only one cobalt-rich crust sample was placed within the camera&#x02019;s field of view, and the concentration of suspended particles was relatively uniform. Future research can further explore methods to accurately calculate the global degree of polarization and backscattered light, thereby achieving image restoration in mining environments with non-uniform concentration scenarios.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, E.P., C.L. and H.Z.; methodology, E.P.; software, C.L.; validation, E.P. and H.Z.; formal analysis, E.P.; investigation, E.P.; resources, H.Z.; data curation, E.P., C.L. and H.Z.; writing&#x02014;original draft preparation, E.P.; writing&#x02014;review and editing, E.P., C.L. and H.Z.; visualization, E.P.; supervision, H.Z. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data presented in this study are available on request from the corresponding author.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01088"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>F.Y.</given-names></name>
<name><surname>Zhang</surname><given-names>W.Y.</given-names></name>
<name><surname>Zhu</surname><given-names>K.C.</given-names></name>
</person-group><article-title>Parameter and Index for Delineation and Evaluation of Co-Rich Crust Resources</article-title><source>Earth Sci.-J. China Univ. Geosci.</source><year>2008</year><volume>33</volume><fpage>251</fpage><lpage>258</lpage></element-citation></ref><ref id="B2-sensors-25-01088"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shao</surname><given-names>M.J.</given-names></name>
<name><surname>Wang</surname><given-names>S.L.</given-names></name>
<name><surname>Zhang</surname><given-names>W.</given-names></name>
</person-group><article-title>Status of exploration contract in the &#x0201c;area&#x0201d;</article-title><source>China Min. Mag.</source><year>2016</year><volume>25</volume><fpage>54</fpage><lpage>57+96</lpage></element-citation></ref><ref id="B3-sensors-25-01088"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lin</surname><given-names>S.</given-names></name>
<name><surname>Zhao</surname><given-names>Y.</given-names></name>
</person-group><article-title>Review on Key Technologies of Target Exploration in Underwater Optical Images</article-title><source>Laser Optoelectron. Prog.</source><year>2020</year><volume>57</volume><fpage>26</fpage><lpage>37</lpage></element-citation></ref><ref id="B4-sensors-25-01088"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Schechner</surname><given-names>Y.Y.</given-names></name>
<name><surname>Karpel</surname><given-names>N.</given-names></name>
</person-group><article-title>Recovery of Underwater Visibility and Structure by Polarization Analysis</article-title><source>IEEE J. Ocean. Eng.</source><year>2005</year><volume>30</volume><fpage>570</fpage><lpage>587</lpage><pub-id pub-id-type="doi">10.1109/JOE.2005.850871</pub-id></element-citation></ref><ref id="B5-sensors-25-01088"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Schechner</surname><given-names>Y.Y.</given-names></name>
<name><surname>Narasimhan</surname><given-names>S.G.</given-names></name>
<name><surname>Nayar</surname><given-names>S.K.</given-names></name>
</person-group><article-title>Polarization-Based Vision through Haze</article-title><source>Appl. Opt.</source><year>2003</year><volume>42</volume><fpage>511</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1364/AO.42.000511</pub-id><pub-id pub-id-type="pmid">12570274</pub-id>
</element-citation></ref><ref id="B6-sensors-25-01088"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Treibitz</surname><given-names>T.</given-names></name>
<name><surname>Schechner</surname><given-names>Y.Y.</given-names></name>
</person-group><article-title>Active Polarization Descattering</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2009</year><volume>31</volume><fpage>385</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2008.85</pub-id><pub-id pub-id-type="pmid">19147870</pub-id>
</element-citation></ref><ref id="B7-sensors-25-01088"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>X.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Chen</surname><given-names>S.-C.</given-names></name>
</person-group><article-title>Enhanced Polarization Demosaicking Network via a Precise Angle of Polarization Loss Calculation Method</article-title><source>Opt. Lett.</source><year>2022</year><volume>47</volume><fpage>1065</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1364/OL.451335</pub-id><pub-id pub-id-type="pmid">35230291</pub-id>
</element-citation></ref><ref id="B8-sensors-25-01088"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>H.</given-names></name>
<name><surname>Zhu</surname><given-names>J.</given-names></name>
<name><surname>Deng</surname><given-names>J.</given-names></name>
<name><surname>Guo</surname><given-names>F.</given-names></name>
<name><surname>Zhang</surname><given-names>N.</given-names></name>
<name><surname>Sun</surname><given-names>J.</given-names></name>
<name><surname>Hou</surname><given-names>X.</given-names></name>
</person-group><article-title>Underwater Active Polarization Descattering Based on a Single Polarized Image</article-title><source>Opt. Express</source><year>2023</year><volume>31</volume><fpage>21988</fpage><lpage>22000</lpage><pub-id pub-id-type="doi">10.1364/OE.491900</pub-id><pub-id pub-id-type="pmid">37381283</pub-id>
</element-citation></ref><ref id="B9-sensors-25-01088"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hu</surname><given-names>H.</given-names></name>
<name><surname>Zhao</surname><given-names>L.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Wang</surname><given-names>H.</given-names></name>
<name><surname>Liu</surname><given-names>T.</given-names></name>
</person-group><article-title>Underwater Image Recovery Under the Nonuniform Optical Field Based on Polarimetric Imaging</article-title><source>IEEE Photonics J.</source><year>2018</year><volume>10</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1109/JPHOT.2018.2791517</pub-id></element-citation></ref><ref id="B10-sensors-25-01088"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Wan</surname><given-names>M.</given-names></name>
<name><surname>Cao</surname><given-names>X.</given-names></name>
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Gu</surname><given-names>G.</given-names></name>
<name><surname>Chen</surname><given-names>Q.</given-names></name>
</person-group><article-title>Active non-uniform illumination-based underwater polarization imaging method for objects with complex polarization properties</article-title><source>Opt. Express</source><year>2022</year><volume>30</volume><fpage>46926</fpage><lpage>46943</lpage><pub-id pub-id-type="doi">10.1364/OE.474026</pub-id><pub-id pub-id-type="pmid">36558632</pub-id>
</element-citation></ref><ref id="B11-sensors-25-01088"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shen</surname><given-names>L.</given-names></name>
<name><surname>Reda</surname><given-names>M.</given-names></name>
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Zhao</surname><given-names>Y.</given-names></name>
<name><surname>Kong</surname><given-names>S.G.</given-names></name>
</person-group><article-title>Polarization-Driven Solution for Mitigating Scattering and Uneven Illumination in Underwater Imagery</article-title><source>IEEE Trans. Geosci. Remote Sens.</source><year>2024</year><volume>62</volume><fpage>4202615</fpage><pub-id pub-id-type="doi">10.1109/TGRS.2024.3358828</pub-id></element-citation></ref><ref id="B12-sensors-25-01088"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>T.</given-names></name>
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Yao</surname><given-names>K.</given-names></name>
</person-group><article-title>Visibility enhancement of underwater images based on active polarized illumination and average filtering technology</article-title><source>Eng. J.</source><year>2022</year><volume>61</volume><fpage>701</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1016/j.aej.2021.06.007</pub-id></element-citation></ref><ref id="B13-sensors-25-01088"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Boffety</surname><given-names>M.</given-names></name>
<name><surname>Galland</surname><given-names>F.</given-names></name>
<name><surname>Allais</surname><given-names>A.-G.</given-names></name>
</person-group><article-title>Color Image Simulation for Underwater Optics</article-title><source>Appl. Opt.</source><year>2012</year><volume>51</volume><fpage>5633</fpage><lpage>5642</lpage><pub-id pub-id-type="doi">10.1364/AO.51.005633</pub-id><pub-id pub-id-type="pmid">22885575</pub-id>
</element-citation></ref><ref id="B14-sensors-25-01088"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xu</surname><given-names>J.</given-names></name>
<name><surname>Zhao</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Liu</surname><given-names>T.</given-names></name>
<name><surname>Zhai</surname><given-names>J.</given-names></name>
<name><surname>Hu</surname><given-names>H.</given-names></name>
</person-group><article-title>Polarization Imaging in Turbid Water Based on Spectral Information</article-title><source>Acta Opt. Sin.</source><year>2023</year><volume>43</volume><fpage>269</fpage><lpage>277</lpage></element-citation></ref><ref id="B15-sensors-25-01088"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Deng</surname><given-names>C.</given-names></name>
<name><surname>Gong</surname><given-names>W.</given-names></name>
<name><surname>Han</surname><given-names>S.</given-names></name>
</person-group><article-title>Polarization Difference Ghost Imaging in Turbid Medium</article-title><source>Acta Opt. Sin.</source><year>2021</year><volume>41</volume><fpage>124</fpage><lpage>131</lpage></element-citation></ref><ref id="B16-sensors-25-01088"><label>16.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Agaian</surname><given-names>S.S.</given-names></name>
<name><surname>Panetta</surname><given-names>K.</given-names></name>
<name><surname>Grigoryan</surname><given-names>A.M.</given-names></name>
</person-group><article-title>A New Measure of Image Enhancement</article-title><source>Proceedings of the IASTED International Conference on Signal Processing &#x00026; Communication</source><conf-loc>Malaga, Spain</conf-loc><conf-date>19&#x02013;22 September 2000</conf-date></element-citation></ref><ref id="B17-sensors-25-01088"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hao</surname><given-names>Q.</given-names></name>
<name><surname>Zhao</surname><given-names>H.M.</given-names></name>
<name><surname>Ji</surname><given-names>Y.Q.</given-names></name>
</person-group><article-title>Experimental device for simulating reverberation environment in deep sea mining</article-title><source>Chin. J. Eng.</source><year>2017</year><volume>39</volume><fpage>655</fpage><lpage>662</lpage></element-citation></ref><ref id="B18-sensors-25-01088"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>H.</given-names></name>
<name><surname>Ji</surname><given-names>Y.</given-names></name>
<name><surname>Hong</surname><given-names>Y.</given-names></name>
<name><surname>Hao</surname><given-names>Q.</given-names></name>
<name><surname>Ma</surname><given-names>L.</given-names></name>
</person-group><article-title>A Volterra series-based method for extracting target echoes in the seafloor mining environment</article-title><source>Ultrasonics</source><year>2016</year><volume>71</volume><fpage>29</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.ultras.2016.05.019</pub-id><pub-id pub-id-type="pmid">27262353</pub-id>
</element-citation></ref><ref id="B19-sensors-25-01088"><label>19.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>L.</given-names></name>
</person-group><article-title>Research of Recovering the Gray Image Based on Polarimetric in Complex Underwater Imaging Environment</article-title><source>Master&#x02019;s Thesis</source><publisher-name>School of Precision Instrument and Opto-Electronics Engineering, Tianjin University</publisher-name><publisher-loc>Tianjin, China</publisher-loc><year>2018</year><fpage>26</fpage><lpage>28</lpage></element-citation></ref><ref id="B20-sensors-25-01088"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>J.M.</given-names></name>
<name><surname>He</surname><given-names>N.</given-names></name>
</person-group><article-title>Low contrast image enhancement based on improved homomorphic filtering</article-title><source>Comput. Appl. Softw.</source><year>2020</year><volume>37</volume><fpage>220</fpage><lpage>224</lpage></element-citation></ref><ref id="B21-sensors-25-01088"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Z.Q.</given-names></name>
<name><surname>Li</surname><given-names>R.B.</given-names></name>
<name><surname>Liu</surname><given-names>J.Y.</given-names></name>
</person-group><article-title>Image enhancement algorithm based on homomorphic filtering and histogram equalization</article-title><source>Electron. Meas. Technol.</source><year>2020</year><volume>43</volume><fpage>75</fpage><lpage>80</lpage></element-citation></ref><ref id="B22-sensors-25-01088"><label>22.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>X.</given-names></name>
</person-group><article-title>Image Enhancement Algorithm Based on Homomorphic Filtering</article-title><source>Master&#x02019;s Thesis</source><publisher-name>School of Electronic Engineering, Xi&#x02019;an University of Posts and Telecommunications</publisher-name><publisher-loc>Xi&#x02019;an, China</publisher-loc><year>2016</year><fpage>34</fpage><lpage>39</lpage></element-citation></ref><ref id="B23-sensors-25-01088"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Hu</surname><given-names>H.</given-names></name>
<name><surname>Zhao</surname><given-names>L.</given-names></name>
<name><surname>Wang</surname><given-names>H.</given-names></name>
<name><surname>Yu</surname><given-names>Y.</given-names></name>
<name><surname>Wu</surname><given-names>L.</given-names></name>
<name><surname>Liu</surname><given-names>T.</given-names></name>
</person-group><article-title>Polarimetric Image Recovery Method Combining Histogram Stretching for Underwater Imaging</article-title><source>Sci. Rep.</source><year>2018</year><volume>8</volume><elocation-id>12430</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-30566-8</pub-id><pub-id pub-id-type="pmid">30127366</pub-id>
</element-citation></ref><ref id="B24-sensors-25-01088"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mittal</surname><given-names>A.</given-names></name>
<name><surname>Moorthy</surname><given-names>A.K.</given-names></name>
<name><surname>Bovik</surname><given-names>A.C.</given-names></name>
</person-group><article-title>No-Reference Image Quality Assessment in the Spatial Domain</article-title><source>IEEE Trans. Image Process.</source><year>2012</year><volume>21</volume><fpage>4695</fpage><lpage>4708</lpage><pub-id pub-id-type="doi">10.1109/TIP.2012.2214050</pub-id><pub-id pub-id-type="pmid">22910118</pub-id>
</element-citation></ref><ref id="B25-sensors-25-01088"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mie</surname><given-names>G.</given-names></name>
</person-group><article-title>Beitr&#x000e4;ge zur Optik tr&#x000fc;ber Medien, speziell kolloidaler Metallsuspendierungen</article-title><source>Ann. Phys.</source><year>1908</year><volume>330</volume><fpage>377</fpage><lpage>445</lpage><pub-id pub-id-type="doi">10.1002/andp.19083300302</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01088-f001"><label>Figure 1</label><caption><p>Flowchart of the proposed method in this paper.</p></caption><graphic xlink:href="sensors-25-01088-g001" position="float"/></fig><fig position="float" id="sensors-25-01088-f002"><label>Figure 2</label><caption><p>Schematic Diagram of the Experimental Setup. (<bold>a</bold>) is taken from Figure 1a of the article A Volterra series-based method for extracting target echoes in the seafloor mining environment, published in the journal Ultrasonic by Elsevier, and used with permission. Copyright &#x000a9; [<xref rid="B18-sensors-25-01088" ref-type="bibr">18</xref>].</p></caption><graphic xlink:href="sensors-25-01088-g002" position="float"/></fig><fig position="float" id="sensors-25-01088-f003"><label>Figure 3</label><caption><p>Underwater camera.</p></caption><graphic xlink:href="sensors-25-01088-g003" position="float"/></fig><fig position="float" id="sensors-25-01088-f004"><label>Figure 4</label><caption><p>Cobalt crust sample.</p></caption><graphic xlink:href="sensors-25-01088-g004" position="float"/></fig><fig position="float" id="sensors-25-01088-f005"><label>Figure 5</label><caption><p>Original orthogonal polarization images and filtered images.</p></caption><graphic xlink:href="sensors-25-01088-g005a" position="float"/><graphic xlink:href="sensors-25-01088-g005b" position="float"/></fig><fig position="float" id="sensors-25-01088-f006"><label>Figure 6</label><caption><p>Restoration image comparison.</p></caption><graphic xlink:href="sensors-25-01088-g006" position="float"/></fig><fig position="float" id="sensors-25-01088-f007"><label>Figure 7</label><caption><p>Comparison of Different Methods for Restoring Images. (<bold>a</bold>) Original intensity image method. (<bold>b</bold>) Our method. (<bold>c</bold>) Schechner. (<bold>d</bold>) CLAHE. (<bold>e</bold>) Retinex. (<bold>f</bold>) HF.</p></caption><graphic xlink:href="sensors-25-01088-g007" position="float"/></fig><fig position="float" id="sensors-25-01088-f008"><label>Figure 8</label><caption><p>Comparison of restored images with different turbidity levels.</p></caption><graphic xlink:href="sensors-25-01088-g008" position="float"/></fig><table-wrap position="float" id="sensors-25-01088-t001"><object-id pub-id-type="pii">sensors-25-01088-t001_Table 1</object-id><label>Table 1</label><caption><p>Quantitative comparison of recovered images for the images in <xref rid="sensors-25-01088-f007" ref-type="fig">Figure 7</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">IC</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">EME</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">BRISQUE</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Intensity image</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1123</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6138</td><td align="center" valign="middle" rowspan="1" colspan="1">35.1301</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Our</td><td align="center" valign="middle" rowspan="1" colspan="1">0.18</td><td align="center" valign="middle" rowspan="1" colspan="1">1.2488</td><td align="center" valign="middle" rowspan="1" colspan="1">24.0987</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Schechner</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1478</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9308</td><td align="center" valign="middle" rowspan="1" colspan="1">20.6782</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HF</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1360</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9732</td><td align="center" valign="middle" rowspan="1" colspan="1">36.5511</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CLAHE</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1966 *</td><td align="center" valign="middle" rowspan="1" colspan="1">1.4675 *</td><td align="center" valign="middle" rowspan="1" colspan="1">41.8575</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Retinex</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
0.2153 *</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
1.7789 *</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">43.0674</td></tr></tbody></table></table-wrap></floats-group></article>