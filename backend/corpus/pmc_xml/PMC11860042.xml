<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006222</article-id><article-id pub-id-type="pmc">PMC11860042</article-id><article-id pub-id-type="doi">10.3390/s25040993</article-id><article-id pub-id-type="publisher-id">sensors-25-00993</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>MTL-DoHTA: Multi-Task Learning-Based DNS over HTTPS Traffic Analysis for Enhanced Network Security</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-0107-9197</contrib-id><name><surname>Jung</surname><given-names>Woong Kyo</given-names></name></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-2009-4580</contrib-id><name><surname>Kwak</surname><given-names>Byung Il</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="c1-sensors-25-00993" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Kozik</surname><given-names>Rafal</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Choras</surname><given-names>Michal</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Pawlicki</surname><given-names>Marek</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-00993">Division of Software, Hallym University, Chuncheon 24252, Republic of Korea; <email>m24053@hallym.ac.kr</email></aff><author-notes><corresp id="c1-sensors-25-00993"><label>*</label>Correspondence: <email>kwacka12@hallym.ac.kr</email></corresp></author-notes><pub-date pub-type="epub"><day>07</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>993</elocation-id><history><date date-type="received"><day>20</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>03</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>05</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>The adoption of DNS over HTTPS (DoH) has significantly enhanced user privacy and security by encrypting DNS queries. However, it also presents new challenges for detecting malicious activities, such as DNS tunneling, within encrypted traffic. In this study, we propose MTL-DoHTA, a multi-task learning-based framework designed to analyze DoH traffic and classify it into three tasks: (1) DoH vs. non-DoH traffic, (2) benign vs. malicious DoH traffic, and (3) the identification of DNS tunneling tools (e.g., dns2tcp, dnscat2, iodine). Leveraging statistical features derived from network traffic and a 2D-CNN architecture enhanced with GradNorm and attention mechanisms, MTL-DoHTA achieves a macro-averaging F1-score of 0.9905 on the CIRA-CIC-DoHBrw-2020 dataset. Furthermore, the model effectively handles class imbalance and mitigates overfitting using downsampling techniques while maintaining high classification performance. The proposed framework can serve as a reliable tool for monitoring and securing sensor-based network systems against sophisticated threats, while also demonstrating its potential to enhance multi-tasking capabilities in resource-constrained sensor environments.</p></abstract><kwd-group><kwd>DNS over HTTPS</kwd><kwd>DNS covert channel</kwd><kwd>multi-task learning</kwd><kwd>deep learning</kwd></kwd-group><funding-group><award-group><funding-source>Hallym University Research Fund</funding-source><award-id>HRF-202110-009</award-id></award-group><funding-statement>This research was supported by Hallym University Research Fund, 2021 (HRF-202110-009).</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-00993"><title>1. Introduction</title><p>The increasing importance of internet security and privacy has made the Domain Name System (DNS) a critical but vulnerable target for cyberattacks. As&#x000a0;the backbone of the Internet, DNS translates human-readable hostnames into machine-readable IP addresses, enabling seamless and efficient communication between users and websites. However, the&#x000a0;traditional DNS design transmits data in plaintext, making it susceptible to threats like eavesdropping, data manipulation, and&#x000a0;Man-in-the-Middle (MitM) attacks [<xref rid="B1-sensors-25-00993" ref-type="bibr">1</xref>]. Attackers have exploited these vulnerabilities to intercept sensitive information or manipulate DNS responses for malicious purposes, such as redirecting users to phishing websites or delivering malware. Recognizing the need to secure DNS communications, the&#x000a0;Internet Engineering Task Force (IETF) introduced DNS over HTTPS (DoH) in 2018 [<xref rid="B2-sensors-25-00993" ref-type="bibr">2</xref>]. This standardized protocol encrypts DNS queries using HTTPS, ensuring that communication between users and DNS resolvers remains confidential and protected against interception, thus significantly enhancing user privacy and security [<xref rid="B3-sensors-25-00993" ref-type="bibr">3</xref>].</p><p>Despite its benefits, DoH poses new challenges for network security. By&#x000a0;encrypting DNS traffic and embedding it within HTTPS, DoH obscures the visibility of DNS queries, making them indistinguishable from other web traffic [<xref rid="B4-sensors-25-00993" ref-type="bibr">4</xref>]. This encryption prevents traditional packet inspection techniques from identifying DNS-related activities, complicating detecting and mitigating malicious behaviors. Attackers have exploited this characteristic to perform DNS tunneling, a&#x000a0;method that uses DNS queries to covertly transfer data or communicate with command and control (C2) servers [<xref rid="B4-sensors-25-00993" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-00993" ref-type="bibr">5</xref>]. Such misuse has been observed in high-profile cases, including Godlua malware and Oilrig (APT34), where DoH was used to exfiltrate data and maintain C2 channels [<xref rid="B6-sensors-25-00993" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-00993" ref-type="bibr">7</xref>]. These incidents highlight a critical gap in existing DNS traffic analysis methods as they struggle to address the complexities introduced by encrypted DNS&#x000a0;traffic.</p><p>In light of these challenges, research has shifted towards developing more robust detection mechanisms. Machine learning (ML) and deep learning (DL) approaches are increasingly employed to analyze encrypted DNS traffic. As&#x000a0;noted by Jehad Ali&#x000a0;et&#x000a0;al. [<xref rid="B8-sensors-25-00993" ref-type="bibr">8</xref>], advanced ML algorithms, such as anomaly detection and behavior analysis, have shown promise in identifying deviations from normal patterns within encrypted communications. Such approaches enable the detection of sophisticated threats while maintaining privacy safeguards. Ali&#x000a0;et&#x000a0;al. emphasize the importance of integrating AI-driven security frameworks, particularly in environments with significant IoT and network interconnectivity, such as smart cities. Their work highlights the role of adaptive AI systems in continuously learning and evolving to address emerging cyber&#x000a0;threats.</p><p>Furthermore, while meta-learning frameworks have demonstrated efficacy in detecting intrusions and abnormal encrypted network traffic in IoT environments [<xref rid="B9-sensors-25-00993" ref-type="bibr">9</xref>], their applicability to DoH remains underexplored. As&#x000a0;DoH evolves, methodologies that enhance adaptability to new DNS tunneling technologies and attack vectors need to be incorporated. This adaptability can be achieved through multi-task learning frameworks that allow models to generalize across diverse scenarios without compromising detection accuracy or&#x000a0;scalability.</p><p>Developing advanced detection mechanisms requires a multifaceted approach that combines machine learning algorithms with behavioral analysis to identify anomalies in DNS traffic patterns while maintaining strict privacy safeguards. These mechanisms must enhance model performance and preserve user privacy, a&#x000a0;cornerstone of encrypted DNS traffic such as DoH. Furthermore, security solutions need to remain adaptable and effective even in diverse and dynamic network environments, providing a critical layer of resilience against the evolving landscape of cyber&#x000a0;threats.</p><p>Motivated by these challenges, we propose multi-task learning (MTL)-based traffic classification model to address the complexities of DoH traffic detection and malicious activity identification. The&#x000a0;MTL model is designed to tackle three interconnected tasks: (1) classifying network traffic into DoH and non-DoH categories, (2) distinguishing between benign and malicious DoH traffic, and&#x000a0;(3) conducting a multi-class classification to identify specific DNS tunneling tools used in malicious activities. Leveraging time-series classification techniques, our MTL model offers comprehensive insight into network traffic, enabling rapid and accurate detection across all tasks. By&#x000a0;achieving the high performance of single-task models while simultaneously addressing multiple objectives, this MTL-based approach enhances network security by effectively identifying malicious behaviors and specific DNS tunneling tools while preserving the privacy benefits of&#x000a0;DoH.</p><p>The research contributions of the multi-task learning-based traffic classification model proposed in this study are as&#x000a0;follows:<list list-type="order"><list-item><p>It introduces a novel framework that integrates both classification tasks, enabling more efficient learning and improved accuracy in detecting threats within encrypted&#x000a0;traffic.</p></list-item><list-item><p>The model leverages shared representations across tasks, which not only reduces the computational burden but also enhances generalization capabilities by learning from diverse data patterns present in both benign and malicious traffic.</p></list-item><list-item><p>The proposed methodology has been confirmed to achieve high accuracy and superior performance in both learning and testing. This represents a significant contribution to the research, demonstrating the effectiveness of multi-task processing.</p></list-item><list-item><p>The framework employs downsampling techniques to address class imbalance in the dataset, ensuring that the model maintains high performance across underrepresented classes. This approach not only improves classification accuracy but also reduces the risk of overfitting, especially in multi-class tasks such as DNS tunneling tool&#x000a0;identification.</p></list-item></list></p><p>The rest of this paper is organized as follows. <xref rid="sec2-sensors-25-00993" ref-type="sec">Section 2</xref> reviews the related studies. <xref rid="sec3-sensors-25-00993" ref-type="sec">Section 3</xref> presents our multi-task learning method based on DoH traffic analysis and classification. <xref rid="sec4-sensors-25-00993" ref-type="sec">Section 4</xref> describes the experimental results and evaluates our proposed approach. Finally, <xref rid="sec5-sensors-25-00993" ref-type="sec">Section 5</xref> provides limitations and the concluding remarks.</p></sec><sec id="sec2-sensors-25-00993"><title>2. Related Work</title><p>To comprehensively understand the research themes, characteristics, and&#x000a0;limitations of existing studies related to DoH traffic analysis, we added a comparative analysis table that examines whether Tasks 1, 2, and&#x000a0;3 were addressed in prior research, particularly emphasizing the usability of DoH (See <xref rid="sensors-25-00993-t001" ref-type="table">Table 1</xref>).</p><p>The adoption of DoH has significantly enhanced DNS security through encryption, yet it also introduces new challenges for detecting malicious activities such as DNS tunneling. By&#x000a0;obfuscating traffic within HTTPS, DoH complicates the ability of existing detection technologies to differentiate DNS requests from standard web traffic, allowing malicious entities to covertly transmit data or obscure communication with C2 servers [<xref rid="B1-sensors-25-00993" ref-type="bibr">1</xref>]. DNS tunneling is a technique used to hide malicious data within normal DNS queries. This method allows attackers to bypass firewalls and security measures, which can result in unauthorized data being extracted and malware being activated remotely. Instances of such exploitation underscore the inadequacies of conventional static rule-based detection systems in scrutinizing DoH traffic and accentuate the necessity for more advanced detection methodologies [<xref rid="B4-sensors-25-00993" ref-type="bibr">4</xref>].</p><p>Recent studies have explored machine learning (ML) techniques to detect malicious DoH traffic, with&#x000a0;particular emphasis on time-series analysis. Singh&#x000a0;et&#x000a0;al. [<xref rid="B11-sensors-25-00993" ref-type="bibr">11</xref>] demonstrated that integrating ML algorithms with temporal attributes improves the detection of DNS tunneling activities. Ensemble learning methods such as Gradient Boosting and Random Forest have shown high precision in classifying DoH traffic based on packet dimensions, transmission velocity, and&#x000a0;session length [<xref rid="B13-sensors-25-00993" ref-type="bibr">13</xref>]. Moreover, some studies have incorporated feature extraction techniques using machine learning and PCAP-based novel features to enhance model performance and improve malicious DoH detection [<xref rid="B15-sensors-25-00993" ref-type="bibr">15</xref>].</p><p>Building on these techniques, MontazeriShatoori&#x000a0;et&#x000a0;al. [<xref rid="B12-sensors-25-00993" ref-type="bibr">12</xref>] proposed a DoH detection approach together with the CIRA-CICDoHBrw-2020 dataset [<xref rid="B17-sensors-25-00993" ref-type="bibr">17</xref>], which contained pre-extracted flow statistics. Their experiments compared multiple ML algorithms (Random Forest, Decision Tree, SVM, Naive Bayes), 2D-CNN, and&#x000a0;LSTM; Random Forest achieved a notably high F1-score using 28 features. Furthermore, other research efforts leveraged deep learning architectures. In&#x000a0;particular, Singh&#x000a0;et&#x000a0;al. [<xref rid="B11-sensors-25-00993" ref-type="bibr">11</xref>] explored LSTM (Long Short-Term Memory) networks, demonstrating how temporal analysis can help to uncover malicious patterns in DoH&#x000a0;traffic.</p><p>To further enhance the interpretability of DoH detection models, researchers have integrated visualization techniques. Mohammad&#x000a0;et&#x000a0;al. [<xref rid="B10-sensors-25-00993" ref-type="bibr">10</xref>] performed visualization work on the CIRA-CIC-DoHBrw-2020 dataset (also referred to as CIC-DoHBrw-2020) using Eigen Centrality (EC) in graph/network theory, Principal Component Analysis (PCA), and&#x000a0;a Gaussian Mixture Model (GMM). These methods analyzed specific clusters in the data to identify potential anomalies. Similarly, Zebin&#x000a0;et&#x000a0;al. [<xref rid="B16-sensors-25-00993" ref-type="bibr">16</xref>] focused on classifying benign versus malicious DoH using a machine learning&#x02013;based Random Forest algorithm, augmenting interpretability through Shapley additive explanations (SHAP) and the visualization of packet data. Furthermore, Jerabek&#x000a0;et&#x000a0;al. [<xref rid="B18-sensors-25-00993" ref-type="bibr">18</xref>] performed a comparative analysis on both the CIC-DoHBrw-2020 dataset and a real-world dataset [<xref rid="B19-sensors-25-00993" ref-type="bibr">19</xref>], examining the transferability, usability, and&#x000a0;longevity of previously published malicious DoH detection machine learning models across these different data&#x000a0;sources.</p><p>Stalder [<xref rid="B15-sensors-25-00993" ref-type="bibr">15</xref>] proposed a three-layered framework to address three distinct classification tasks: DoH vs. non-DoH, Benign vs. Malicious DoH, and&#x000a0;DNS tunneling tool classification. This framework integrates ML algorithms tailored for each classification task and employs feature importance analysis during preprocessing to enhance detection accuracy. However, the&#x000a0;research lacked results for Task 3 (DNS tunneling tool classification), leaving this aspect&#x000a0;unexplored.</p><p>Although previous research has contributed to DoH detection, recent studies indicate that existing datasets and models remain insufficient in addressing evolving threats comprehensively. The&#x000a0;recent datasets require broader attack vector coverage and improved malicious behavior representations. Moreover, many ML/DL-based models must address task scalability, ensuring that existing models can be reused or extended when new malicious DNS tunneling tools emerge. In&#x000a0;response to these gaps, this paper proposes a multi-task learning&#x02013;based traffic analysis and classification approach which aims to enhance task scalability and adaptability in the face of evolving&#x000a0;threats.</p></sec><sec sec-type="methods" id="sec3-sensors-25-00993"><title>3. Methodology</title><p>In this section, we show the proposed method concerning multi-task learning-based DoH traffic analysis and classification (MTL-DoHTA). <xref rid="sensors-25-00993-f001" ref-type="fig">Figure 1</xref> shows the overview of our MTL-DoHTA, which integrates various machine learning techniques to simultaneously analyze and classify DoH traffic patterns. By&#x000a0;leveraging shared representations across multiple tasks, this approach not only improves the accuracy of detection but also enhances the model&#x02019;s ability to generalize across different types of network behaviors. The overview is composed three stages: first, the&#x000a0;data preprocessing phase, where raw DoH traffic is cleaned and transformed into a suitable format for analysis; second, the&#x000a0;feature extraction stage, which identifies key characteristics of the traffic that are critical for effective classification; and third, the&#x000a0;model training phase, where machine learning algorithms are employed to learn from the extracted features and optimize performance across tasks.</p><sec id="sec3dot1-sensors-25-00993"><title>3.1. Data Collection by Traffic Flow Unit</title><p>In this subsection, to&#x000a0;integrate network traffic into the MTL algorithm, the&#x000a0;raw traffic is transformed into a flow-based representation that encapsulates the essential attributes of individual data packets. This representation not only facilitates efficient processing but also enhances the model&#x02019;s ability to identify patterns and detect anomalies within the traffic, ultimately improving classification accuracy. Once the flow-based features are generated, they undergo a feature extraction process to select only the most critical features. These refined features are then utilized as inputs to the MTL algorithm, ensuring optimal performance in the classification tasks.</p></sec><sec id="sec3dot2-sensors-25-00993"><title>3.2. Feature Selection with Feature Importance</title><p>We extracted a total of 29 features from network traffic using the &#x02018;DoHlyzer&#x02019; tool [<xref rid="B12-sensors-25-00993" ref-type="bibr">12</xref>], generating flow-based statistical features. The&#x000a0;complete list of these features is provided in <xref rid="sensors-25-00993-t002" ref-type="table">Table 2</xref>. These features are categorized into attributes such as duration, number of bytes, packet length, packet time, and&#x000a0;request/response time difference. To&#x000a0;ensure model efficiency and lightweight processing, we selected 25 features with the highest feature importance as inputs for the model. This feature selection process is conducted only during the training phase and is not repeated during validation or testing. Instead, the&#x000a0;features selected during training are directly used in the validation and testing phases. By&#x000a0;focusing on the most relevant information, the&#x000a0;selected features enhance the model&#x02019;s performance and ensure better generalization on unseen&#x000a0;data.</p><p>To identify the top 25 features out of the initial 29, we applied the Random Forest [<xref rid="B20-sensors-25-00993" ref-type="bibr">20</xref>] algorithm as a single-task learning approach to each of the tasks (Task 1, Task 2, and Task&#x000a0;3). Based on the feature importance scores obtained for each task, we identified the top 25 features that were commonly ranked highly across all tasks (see <xref rid="sensors-25-00993-f002" ref-type="fig">Figure 2</xref>). These features, representing the most significant attributes overall, were then used as inputs to the 2D-CNN and attention-based models in this&#x000a0;study.</p><p>The 25 selected features undergo a MinMax normalization process, where their values are scaled between 0 and 1 according to Equation&#x000a0;(<xref rid="FD1-sensors-25-00993" ref-type="disp-formula">1</xref>), as&#x000a0;shown in <xref rid="sensors-25-00993-f003" ref-type="fig">Figure 3</xref>. After&#x000a0;normalization, the&#x000a0;features are arranged sequentially into a 5 &#x000d7; 5 vector, resulting in an image-like&#x000a0;representation.<disp-formula id="FD1-sensors-25-00993"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mo movablelimits="true" form="prefix">min</mml:mo></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mo movablelimits="true" form="prefix">min</mml:mo></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec3dot3-sensors-25-00993"><title>3.3. MTL-DoHTA Model</title><p>To enable the simultaneous processing of multiple tasks, we designed the architecture of a MTL algorithm, as&#x000a0;illustrated in <xref rid="sensors-25-00993-f004" ref-type="fig">Figure 4</xref>. The&#x000a0;proposed MTL algorithm consists of three main components: 1. A&#x000a0;shared network architecture in the neural network structure; 2. a&#x000a0;task-specific attention architecture for each task; 3. an&#x000a0;output layer that computes the outputs and dynamically updates task weights using GradNorm [<xref rid="B21-sensors-25-00993" ref-type="bibr">21</xref>].</p><p>The proposed architecture leverages a shared network to learn common features across tasks, thereby enhancing the model&#x02019;s generalization capability. Increasing the width of the shared network can further improve its ability to generalize; however, overly generalized shared features may lack robustness in capturing task-specific characteristics. To&#x000a0;address this, the&#x000a0;network incorporates dedicated task-specific layers, structured as a multi-task shared layer, a&#x000a0;task-specific attention layer, and&#x000a0;an output layer with GradNorm-based weight updates. The task-specific attention layer utilizes precomputed and fixed attention weights to assign feature importance for each task. These static attention weights guide the model in updating network parameters effectively, ensuring that each layer focuses on task-specific information based on pre-extracted features. Meanwhile, the&#x000a0;output layer employs task-specific loss functions to compute final losses and predictions. In&#x000a0;addition, the&#x000a0;gradient norms of the final dense layer in the shared network are computed to compare the gradient norms across tasks. This enables dynamic updates of task weights using GradNorm, ensuring balanced learning among the tasks. The components and their detailed functionalities are described in the subsequent&#x000a0;sections.</p><sec id="sec3dot3dot1-sensors-25-00993"><title>3.3.1. Multi-Task Shared Layer</title><p>The shared layer is responsible for extracting common features from the input data in the early stages of the network. In&#x000a0;this study, the&#x000a0;convolutional networks in the shared layer employ 3 &#x000d7; 3 filters and are structured to enhance feature extraction efficiency. The&#x000a0;shared layer consists of three convolutional layers, a&#x000a0;max-pooling layer, and&#x000a0;two fully connected layers, with&#x000a0;ReLU activation functions incorporated into the 2D-CNN structure to introduce non-linearity and enable the network to learn diverse features.</p><p>The input data, represented as a 2D image, sequentially pass through four shared layers before entering the task-specific layers. The&#x000a0;first shared layer expands the 5 &#x000d7; 5 &#x000d7; 1 input into 32 feature maps and compresses it using a max-pooling layer, reducing the spatial dimensions to 2 &#x000d7; 2. The&#x000a0;second and third shared layers further expand the number of feature maps to 64 and 128, respectively, progressively capturing more abstract representations. Following this, a&#x000a0;global average pooling (GAP) layer computes the average values of the output feature maps. It transforms them into a 128-dimensional dense vector, a&#x000a0;predefined size independent of the feature map dimensions. The&#x000a0;flattened vector is then processed through the fully connected layers, where a 64-unit shared fully connected layer compresses the representation before passing it into the task-specific attention layer.</p></sec><sec id="sec3dot3dot2-sensors-25-00993"><title>3.3.2. Task Specific Attention Layer</title><p>The task-specific attention layer consists of separate, fully connected layers, each with 29 units corresponding to the number of features used in this study. Each task-specific layer functions as an attention mechanism, where precomputed feature importance values are statically multiplied by fixed attention weights throughout the training process. This allows each task to focus on the most relevant features while preserving the structural integrity of the shared representation.</p><p>After passing through the attention layer, Task 1 and Task 2 employ the BCEWithLogits loss function for independent binary classification, generating probability values for classification decisions. In&#x000a0;contrast, Task 3 utilizes the cross-entropy loss function to classify inputs into five categories, effectively capturing multi-class relationships.</p></sec><sec id="sec3dot3dot3-sensors-25-00993"><title>3.3.3. Static Attention Mechanism Based on Feature Importance</title><p>In this study, the&#x000a0;feature importance values for each task are precomputed using the Random Forest algorithm and utilized as prior knowledge during training. Instead of dynamically learning the attention weights, the&#x000a0;model leverages task-specific feature importance to guide specialized training for each&#x000a0;task.</p><p>The reasons for not dynamically learning attention weights are as&#x000a0;follows:<list list-type="bullet"><list-item><p>The robust weights learned through the shared layer provide generalized representation power across all tasks, while the additional attention layer further emphasizes this generalized representation.</p></list-item><list-item><p>Dynamically learning attention weights can significantly increase computational costs, especially when combined with the computations required for the shared layer. This consideration makes static attention weights a more efficient choice.</p></list-item><list-item><p>By explicitly reflecting the important features, the&#x000a0;model ensures task-specific alignment, allowing each task to focus on its most relevant features without additional&#x000a0;complexity.</p></list-item></list></p></sec><sec id="sec3dot3dot4-sensors-25-00993"><title>3.3.4. Attention Mechanism</title><p>To enhance the learning effectiveness of our MTL-DoHTA model, the&#x000a0;attention mechanism enables the model to focus on the most relevant parts of the input data, thereby improving its performance [<xref rid="B22-sensors-25-00993" ref-type="bibr">22</xref>]. This approach assigns attention weights to the encoder&#x02019;s hidden states, emphasizing the importance of each input token during decoding.</p><p>First, we compute a weighted sum of the encoder&#x02019;s hidden states, guided by these attention weights. Let this weighted sum be denoted by <italic toggle="yes">z</italic>, as&#x000a0;defined in Equation&#x000a0;(<xref rid="FD2-sensors-25-00993" ref-type="disp-formula">2</xref>):<disp-formula id="FD2-sensors-25-00993"><label>(2)</label><mml:math id="mm2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, <italic toggle="yes">x</italic> represents the input network weights, which are learned through backpropagation. Next, to&#x000a0;ensure that the resulting attention weights sum to 1, we apply a softmax function to <italic toggle="yes">z</italic> (Equation (<xref rid="FD3-sensors-25-00993" ref-type="disp-formula">3</xref>)):<disp-formula id="FD3-sensors-25-00993"><label>(3)</label><mml:math id="mm3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="italic">attention</mml:mi><mml:mo>_</mml:mo><mml:msub><mml:mi mathvariant="italic">scores</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo form="prefix">exp</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle><mml:mspace width="1.em"/><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
producing a probability distribution that indicates how much attention is allocated to each token. Finally, we multiply the encoder&#x02019;s hidden states by these normalized attention scores in an element-wise manner to obtain the context vector <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, as&#x000a0;shown in Equation&#x000a0;(<xref rid="FD4-sensors-25-00993" ref-type="disp-formula">4</xref>):<disp-formula id="FD4-sensors-25-00993"><label>(4)</label><mml:math id="mm5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02299;</mml:mo><mml:mi mathvariant="italic">attention</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="italic">scores</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This context vector highlights the most important features of the input data for predicting the current output, enabling the MTL-DoHTA model to adaptively focus on different tokens at each step.</p></sec><sec id="sec3dot3dot5-sensors-25-00993"><title>3.3.5. Output Layer and GradNorm for Dynamic Task Weighting</title><p>After the fully connected layer for each task, the&#x000a0;loss values are calculated using the respective loss functions. During&#x000a0;the backward pass, the&#x000a0;gradient norms of the fully connected network weights in the last shared layer (64 units) are computed. These gradient norms are normalized to a common scale and multiplied by the relative inverse training rate of each task. As&#x000a0;a result, the&#x000a0;task weights are dynamically adjusted during backpropagation based on these common-scale gradient norms. In multi-task learning, the&#x000a0;final loss function is typically the sum of the loss values for each task. To&#x000a0;account for differing learning speeds among tasks, task weights <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are introduced to regulate each task&#x02019;s contribution to the total loss. Equation&#x000a0;(<xref rid="FD5-sensors-25-00993" ref-type="disp-formula">5</xref>) shows this weighted multi-task loss function, where <italic toggle="yes">i</italic> indexes each task: <disp-formula id="FD5-sensors-25-00993"><label>(5)</label><mml:math id="mm7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>T</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>GradNorm is a normalization technique designed to balance the loss values across tasks by directly tuning <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> based on the gradient magnitudes of the shared layer. Unlike grid search, GradNorm uses a single hyperparameter <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula> to adjust task weights dynamically, allowing tasks with slower learning rates to catch up and train at a pace similar to other tasks. The&#x000a0;GradNorm update rule for each task weight <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is shown in Equation&#x000a0;(<xref rid="FD6-sensors-25-00993" ref-type="disp-formula">6</xref>):<disp-formula id="FD6-sensors-25-00993"><label>(6)</label><mml:math id="mm11" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> indicates the L2 norm of the gradients associated with task <italic toggle="yes">i</italic>. Although&#x000a0;some approaches [<xref rid="B22-sensors-25-00993" ref-type="bibr">22</xref>] suggest using the entire shared layer for this computation, we focus on the gradients in the last shared layer only for efficiency. Equation&#x000a0;(<xref rid="FD7-sensors-25-00993" ref-type="disp-formula">7</xref>) defines <inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD7-sensors-25-00993"><label>(7)</label><mml:math id="mm14" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mo>&#x02207;</mml:mo><mml:mi>W</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The common scale <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is then computed as the average of these gradient norms across all <italic toggle="yes">T</italic> tasks (Equation (<xref rid="FD8-sensors-25-00993" ref-type="disp-formula">8</xref>)):<disp-formula id="FD8-sensors-25-00993"><label>(8)</label><mml:math id="mm16" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac></mml:mstyle><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In addition to gradient norms, GradNorm also calculates a loss ratio, <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which represents how much the loss for task <italic toggle="yes">i</italic> has changed relative to its initial value. Equation&#x000a0;(<xref rid="FD9-sensors-25-00993" ref-type="disp-formula">9</xref>) shows how <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is derived: <disp-formula id="FD9-sensors-25-00993"><label>(9)</label><mml:math id="mm19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>A smaller <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> implies faster convergence (lower loss over time), whereas a larger <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> indicates slower learning. GradNorm then uses the relative inverse training rate, <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, to&#x000a0;measure how a task&#x02019;s progress compares to the overall average loss, as&#x000a0;shown in Equation&#x000a0;(<xref rid="FD10-sensors-25-00993" ref-type="disp-formula">10</xref>): <disp-formula id="FD10-sensors-25-00993"><label>(10)</label><mml:math id="mm23" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>L</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>L</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the average loss across all tasks. If&#x000a0;<inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003e;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, it suggests that the task <italic toggle="yes">i</italic> is learning more slowly than average and therefore requires more attention (i.e., a&#x000a0;higher weight). GradNorm leverages these metrics to adjust <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> so that all tasks can maintain a balanced learning pace. In addition to adjusting the task weights, GradNorm also updates the gradient norm for each task to reflect this inverse training rate. As&#x000a0;shown in Equation&#x000a0;(<xref rid="FD11-sensors-25-00993" ref-type="disp-formula">11</xref>), the&#x000a0;gradient norm <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is shifted closer to the common scale <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> based on <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD11-sensors-25-00993"><label>(11)</label><mml:math id="mm31" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula> is a hyperparameter that controls how strongly the gradient update prioritizes tasks with higher losses. Tasks displaying slower learning rates (<inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003e;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) thus receive proportionally larger adjustments in their gradient norms. Finally, GradNorm defines a gradient loss <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> that quantifies the discrepancy between the individual gradient magnitudes <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and the rescaled common scale <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Equation&#x000a0;(<xref rid="FD12-sensors-25-00993" ref-type="disp-formula">12</xref>) shows how <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is computed: <disp-formula id="FD12-sensors-25-00993"><label>(12)</label><mml:math id="mm38" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfenced separators="" open="|" close="|"><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>G</mml:mi><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>By minimizing <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the&#x000a0;method encourages each task&#x02019;s gradient norm to remain close to the overall average, ensuring that all tasks progress at a similar pace. The&#x000a0;task weights are normalized at each time step so that their sum equals <italic toggle="yes">T</italic>, the&#x000a0;total number of tasks. The overall process of the MTL-DoHTA model is illustrated in Algorithms 1 and 2, detailing both the forward pass and backward propagation&#x000a0;steps.
<array><tbody><tr><td colspan="2" align="left" style="border-top:solid thin;border-bottom:solid thin" rowspan="1"><bold>Algorithm 1</bold> DoHTA Multi-task Learning Forward&#x000a0;Pass</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;1:</label><p><bold>Input:</bold>&#x000a0;<inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">
</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;2:</label><p><bold>Output:</bold>&#x000a0;<inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">
</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;3:</label><p>Permute <italic toggle="yes">X</italic> to <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Reorganize input tensor</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;4:</label><p><inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>ReLU</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Conv</mml:mi><mml:mn>2</mml:mn><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02192;</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Output channels = 32</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;5:</label><p><inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>MaxPool</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Downsample to 2 &#x000d7; 2</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;6:</label><p><inline-formula><mml:math id="mm45" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>ReLU</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Conv</mml:mi><mml:mn>2</mml:mn><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow><mml:mn>32</mml:mn><mml:mo>&#x02192;</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Output channels = 64</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;7:</label><p><inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>ReLU</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Conv</mml:mi><mml:mn>2</mml:mn><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow><mml:mn>64</mml:mn><mml:mo>&#x02192;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Output channels = 128</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;8:</label><p><inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>Global</mml:mi><mml:mspace width="4.pt"/><mml:mi>Average</mml:mi><mml:mspace width="4.pt"/><mml:mi>Pooling</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Global Average Pooling</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;9:</label><p><inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>Dropout</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ReLU</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">
</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>10:</label><p><inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>Dropout</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ReLU</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Shared output for task-specific heads</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>11:</label><p><bold>for</bold>&#x000a0;<inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>&#x000a0;<bold>do</bold></p></list-item></list></td><td align="right" rowspan="1" colspan="1">
</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>12:</label><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;<inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02190;</mml:mo><mml:mi>Softmax</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Static feature importance <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>13:</label><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;<inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02299;</mml:mo><mml:msup><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">&#x025b9; Attention applied for task <italic toggle="yes">i</italic></td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>14:</label><p><bold>end for</bold></p></list-item></list></td><td align="right" rowspan="1" colspan="1">
</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>15:</label><p><inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>BCEWithLogits</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">
</td></tr><tr><td align="left" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>16:</label><p><inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>BCEWithLogits</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" rowspan="1" colspan="1">
</td></tr><tr><td align="left" style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>17:</label><p><inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>CrossEntropy</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p><p><bold>&#x000a0;&#x000a0;&#x000a0;&#x000a0;return</bold>&#x000a0;<inline-formula><mml:math id="mm57" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td><td align="right" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr></tbody></array>
<array><tbody><tr><td style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 2</bold> DoHTA GradNorm Backward&#x000a0;Propagation</td></tr><tr><td style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>&#x000a0;&#x000a0;1:</label><p><bold>Input:</bold></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0; Task losses <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0; Shared output <inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0; Task weights <inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;2:</label><p><bold>Output:</bold></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0; Total loss <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0; Updated task weights <inline-formula><mml:math id="mm62" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;3:</label><p><bold>Step 1: Compute Total Loss</bold></p></list-item><list-item><label>&#x000a0;&#x000a0;4:</label><p><inline-formula><mml:math id="mm63" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;5:</label><p><bold>Step 2: Backpropagate Gradients for Shared Output</bold></p></list-item><list-item><label>&#x000a0;&#x000a0;6:</label><p>Compute gradients of total loss with respect to <inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:</p></list-item><list-item><label>&#x000a0;&#x000a0;7:</label><p><inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mo>&#x02207;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;8:</label><p><bold>Step 3: GradNorm Application</bold></p></list-item><list-item><label>&#x000a0;&#x000a0;9:</label><p>Compute updated task weights using GradNorm function:</p></list-item><list-item><label>10:</label><p><inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>GradNorm</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>11:</label><p><bold>Step 4: Return Values</bold></p></list-item><list-item><label>12:</label><p><bold>return</bold> Total loss <inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and updated task weights <inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item></list></td></tr></tbody></array></p></sec></sec></sec><sec id="sec4-sensors-25-00993"><title>4. Experimental Evaluation</title><sec id="sec4dot1-sensors-25-00993"><title>4.1. Dataset and Performance Metrics</title><p>The CIC-DoHBrw-2020 dataset, developed by the Canadian Institute for Cybersecurity Research, provides valuable insights, detailed in <xref rid="sensors-25-00993-t003" ref-type="table">Table 3</xref> [<xref rid="B12-sensors-25-00993" ref-type="bibr">12</xref>]. It includes DoH traffic generated using Google Chrome, Mozilla Firefox, and three DNS covert channel tools: iodine, dnscat2, and dns2tcp. This traffic interacts with four DoH servers, namely AdGuard, Cloudflare, Google DNS, and Quad9, to capture diverse behaviors. The dataset is organized into three categories: non-DoH (regular HTTPS traffic), benign-DoH (normal DoH traffic), and malicious-DoH (DoH-encrypted DNS covert channels). While non-DoH and benign-DoH traffic are created by accessing Alexa&#x02019;s top 10,000 domains, malicious DoH traffic is generated by covert channel tools using TLS-encrypted HTTPS requests to specific DoH servers. To train our model, we divided the CIC-DoHBrw-2020 dataset 8:2 in the experiment. The total train data comprised 927,419 (80%), and the test data comprised 231,822 (20%). The experiment was operated on a system with Windows 11 OS, an Intel(R) Core i9-14900KF processor, and a Geforce RTX 4090 GPU, using Python 3.9 (see <xref rid="sensors-25-00993-t004" ref-type="table">Table 4</xref>).</p></sec><sec id="sec4dot2-sensors-25-00993"><title>4.2. Hyperparameter Settings</title><p>To calculate the importance for each single task, the Random Forest algorithm was used with default hyperparameter settings. Specifically, the number of decision trees was set to 100, the maximum tree depth was &#x0201c;unlimited&#x0201d;, and Gini impurity was applied. For the MTL DNN algorithm, the following hyperparameters were used: a dropout rate of 0.3, a batch size of 32, and an Adam optimizer. The scaling factor <inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula> for GradNorm, which balances tasks, was set to 1.9. GradNorm weights were updated every 10 batch sequences to naturally integrate with the mini-batch gradient descent method. Training was conducted for 50 epochs with a learning rate of 0.001, and the final evaluation was based on the model achieving the highest total F1-score during these epochs. Additionally, the Optuna library [<xref rid="B23-sensors-25-00993" ref-type="bibr">23</xref>] was used to optimize the hyperparameters, including the learning rate, batch size, and dropout rate. The search ranges were as follows:<list list-type="bullet"><list-item><p>Learning rate: [1 &#x000d7; 10<sup>&#x02212;4</sup>, 1 &#x000d7; 10<sup>&#x02212;2</sup>];</p></list-item><list-item><p>Batch size: [16, 32, 64];</p></list-item><list-item><p>Dropout rate: [0.1, 0.5].</p></list-item></list></p><p>To obtain the optimal hyperparameters, we set another dataset that was a 50% downsampled version of the previous train dataset. To further analyze the model&#x02019;s performance, the structural parameters of the MTL-DoHTA model, which play a critical role in processing these datasets, are detailed in <xref rid="sensors-25-00993-t005" ref-type="table">Table 5</xref>.</p></sec><sec id="sec4dot3-sensors-25-00993"><title>4.3. Performance Evaluation</title><p>To validate the performance of our proposed model, we conducted evaluations from three perspectives:<list list-type="order"><list-item><p>We assessed task-specific performance based on changes in the layer width of the model&#x02019;s shared structure.</p></list-item><list-item><p>We evaluated the performance improvements resulting from applying GradNorm and the attention mechanism to the baseline 2D-CNN architecture.</p></list-item><list-item><p>We examined the model&#x02019;s performance when using downsampling to address class imbalance and prevent overfitting caused by data redundancy.</p></list-item></list></p><p>In the first evaluation, we analyzed the F1-score for each task based on changes in the convolutional structure of the shared layer (see <xref rid="sensors-25-00993-t006" ref-type="table">Table 6</xref>). As shown in <xref rid="sensors-25-00993-t006" ref-type="table">Table 6</xref>, increasing the width of the shared layer consistently improved performance across all tasks.</p><p>For the second evaluation, we measured the performance improvements from applying GradNorm and the attention mechanism to the baseline 2D-CNN architecture. The results show that adding GradNorm to the 2D-CNN significantly improved the model&#x02019;s performance. Furthermore, applying both GradNorm and the attention mechanism yielded the highest performance. While the F1-score for Task 2 in the baseline 2D-CNN (32-64-128) was comparable to that of the MTL-DoHTA model, the F1-scores for Task 1 and Task 3 were noticeably higher with MTL-DoHTA.</p><p>In the third evaluation, we explored the performance of both the baseline model and MTL-DoHTA with varying downsampling rates (see <xref rid="sensors-25-00993-t007" ref-type="table">Table 7</xref>). Downsampling offers advantages such as addressing class imbalance, reducing computational resources, and preventing overfitting. However, it can also lead to performance degradation due to insufficient training data. Despite this, as shown in <xref rid="sensors-25-00993-t007" ref-type="table">Table 7</xref>, the MTL-DoHTA model maintained robust performance even with a downsampling percentage of 50%. Specifically, addressing class imbalance through downsampling resulted in only a minor decrease in F1-score, with an average difference of just 0.003 compared to using the full dataset. This demonstrates that MTL-DoHTA effectively mitigates the impact of downsampling.</p><p><xref rid="sensors-25-00993-t008" ref-type="table">Table 8</xref> presents the performance comparison results for different attention weight selection strategies applied in the MTL-DoHTA model. As shown in the <xref rid="sensors-25-00993-t008" ref-type="table">Table 8</xref>, the highest macro-averaging F1-score of 0.9905 was achieved when applying the 2D-CNN + Grad-Norm + Attention mechanism with static attention weights based on feature importance. Furthermore, it can be observed that increasing the width of the shared layer consistently improved the model&#x02019;s performance.</p><p>The proposed model in this study was evaluated for prediction time performance. The dataset used for training and prediction did not undergo downsampling, and the full dataset was used for evaluation. From the full dataset, 20% (231,822 flows) was selected, and the prediction process was repeated 1000 times to calculate the average prediction time. The average prediction time was recorded as 0.021379 s.</p></sec><sec id="sec4dot4-sensors-25-00993"><title>4.4. Comparison with Other Methods</title><p>Along with our proposed MTL-DoHTA model with 2D-CNN, GradNorm, and Static attention weight (feature importance), we have also compared it with other study methods. As shown in <xref rid="sensors-25-00993-t009" ref-type="table">Table 9</xref>, we confirmed that our proposed MTL-DoHTA model has subtle differences from different studies in terms of performance on Task 1 and Task 2. However, in other studies, the F1-score of Task 3, which was not focused on, was high at 0.9837. Since the study by Liu et al. [<xref rid="B5-sensors-25-00993" ref-type="bibr">5</xref>] used an algorithm that applied few shots, it is somewhat limited to directly comparing the performance with this paper&#x02019;s algorithm.</p><p>In addition, we confirmed the differences between our study and previous studies through a comparative analysis of model complexity, scalability, and the number of model parameters (see <xref rid="sensors-25-00993-t010" ref-type="table">Table 10</xref>). MontazeriShatoori et al. [<xref rid="B12-sensors-25-00993" ref-type="bibr">12</xref>] used approximately 37,000 parameters, showing that the model size is relatively smaller than the algorithms of other studies. Our proposed model uses 105,546 parameters, and the total model size is approximately 450KB, a small resource requirement that allows the model to be sufficiently executed on embedded devices. Although many methodologies and algorithms have been proposed in previous studies, they were not shown in <xref rid="sensors-25-00993-t010" ref-type="table">Table 10</xref> because the model size of machine learning algorithms varies depending on the learning criteria of the records. When looking at the complexity of the model, excluding the number of parameters, deep learning-based methods have a part where the complexity of the model changes depending on the layer width and depth settings. Accordingly, the model proposed in this study is relatively different. Compared to deep learning algorithms, it has low complexity, and in the case of deep learning algorithms with simple structures, the model complexity can be expressed as middle. In addition, since it is more free to update the model output layer in a new environment or when a new task appears, it has been shown to have high scalability in this study. However, general machine learning-based algorithms are performed as a single task even when performing multi-class classification, and there is a cumbersome part in that a new algorithm must be re-learned for other tasks, so in general, the model appears to have low scalability.</p></sec><sec id="sec4dot5-sensors-25-00993"><title>4.5. Performance Comparison in Two Datasets</title><p>To evaluate the generalization performance of the proposed MTL-DoHTA model, experiments were conducted on two datasets: the DNS Over HTTPS network traffic [<xref rid="B25-sensors-25-00993" ref-type="bibr">25</xref>] and CIRA-CIC-DoHBrw-2020 and DoH-Tunnel-Traffic-HKD combined dataset [<xref rid="B26-sensors-25-00993" ref-type="bibr">26</xref>,<xref rid="B27-sensors-25-00993" ref-type="bibr">27</xref>]. The first dataset, the IEEE Dataport Dataset, will be referred to as Dataset 1 for simplicity. Similarly, the second dataset, CIRA-CIC-DoHBrw-2020 and DoH-Tunnel-Traffic-HKD combined dataset will be referred to as Dataset 2 throughout the remainder of this section.</p><p>Dataset 1 was used to assess the model&#x02019;s performance across various tasks, while the DoH Tunnel Traffic HKD dataset introduced a new DNS tunneling technique to evaluate the model&#x02019;s adaptability to novel threats. For Dataset 1, we pre-trained the MTL-DoHTA model and fine-tuned it over 100 epochs to ensure sufficient training. The model achieved an average F1-score of 0.9863, with Task 1 scoring 0.9841 and Task 3 scoring 0.9907. This dataset, which supports flow-based processing with Pcap and includes diverse DNS resolvers, allowed comprehensive evaluations for Task 1 and Task 3. However, due to the absence of malicious DoH tunneling tools, Task 2 evaluations were limited in scope and feasibility. Dataset 2, which augments the CIC-DoHBRW-2020 dataset by including a new type of malicious DoH tunneling tool, was used to assess the model&#x02019;s performance specifically for Task 3. Since Task 1 and Task 2 of Dataset 2 align with the existing CIC-DoHBRW-2020 dataset, fine-tuning was limited to 10 epochs to preserve computational efficiency. The model achieved an impressive F1-score of 0.9996 for Task 3, demonstrating its effectiveness in identifying new tunneling techniques.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-00993"><title>5. Conclusions</title><p>The proposed MTL-DoHTA framework effectively classifies DNS over HTTPS (DoH) traffic across three tasks: (1) differentiating DoH vs. non-DoH traffic, (2) classifying benign vs. malicious DoH traffic, and (3) identifying DNS tunneling tools such as dns2tcp, dnscat2, and iodine. By leveraging statistical features and a simple 2D-CNN architecture, MTL-DoHTA achieves a macro-averaging F1-score of 0.9905 on the CIC-DoHBrw-2020 dataset, outperforming GradNorm and static attention-based methods and thus demonstrating robustness and adaptability.</p><p>Despite these achievements, applying MTL-DoHTA in real-time environments presents challenges due to the reliance on pre-extracted features and the computational complexity of the network, potentially hindering deployment in latency-sensitive scenarios. Moreover, retraining is required to adapt to novel or evolving DNS tunneling tools. To address these limitations, future work will prioritize lightweight model optimization and explore continual learning approaches to enhance real-time detection, adaptability, and scalability. Our next experimental phase will also include testing with a real-nature dataset and additional tasks to further validate the model&#x02019;s performance under diverse conditions.</p><p>The effectiveness of the 2D-CNN-based MTL-DoHTA model was validated through comparisons with baseline models. However, the model&#x02019;s complex structure imposes limitations on real-time performance, which remains an area for improvement. Future research will focus on enhancing both the accuracy and real-time efficiency of the proposed approach by investigating more compact network designs and incremental training strategies.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, B.I.K.; methodology, W.K.J.; investigation, W.K.J.; writing&#x02014;original draft, W.K.J.; writing&#x02014;review &#x00026; editing, B.I.K.; supervision, B.I.K.; project administration, B.I.K. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data presented in this study are available on request from the corresponding author.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-00993"><label>1.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Hjelm</surname><given-names>D.</given-names></name>
</person-group><source>A New Needle and Haystack: Detecting DNS over HTTPS Usage</source><publisher-name>SANS Institute, Information Security Reading Room</publisher-name><publisher-loc>Bethesda, MD, USA</publisher-loc><year>2019</year></element-citation></ref><ref id="B2-sensors-25-00993"><label>2.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Hoffman</surname><given-names>P.</given-names></name>
<name><surname>McManus</surname><given-names>P.</given-names></name>
</person-group><source>DNS Queries over HTTPS (DoH)</source><series>Technical Report</series><publisher-name>Internet Engineering Task Force</publisher-name><publisher-loc>Fremont, CA, USA</publisher-loc><year>2018</year></element-citation></ref><ref id="B3-sensors-25-00993"><label>3.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Chung</surname><given-names>T.</given-names></name>
<name><surname>van Rijswijk-Deij</surname><given-names>R.</given-names></name>
<name><surname>Chandrasekaran</surname><given-names>B.</given-names></name>
<name><surname>Choffnes</surname><given-names>D.</given-names></name>
<name><surname>Levin</surname><given-names>D.</given-names></name>
<name><surname>Maggs</surname><given-names>B.M.</given-names></name>
<name><surname>Mislove</surname><given-names>A.</given-names></name>
<name><surname>Wilson</surname><given-names>C.</given-names></name>
</person-group><article-title>A Longitudinal,{End-to-End} View of the {DNSSEC} Ecosystem</article-title><source>Proceedings of the 26th USENIX Security Symposium (USENIX Security 17)</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>16&#x02013;18 August 2017</conf-date><fpage>1307</fpage><lpage>1322</lpage></element-citation></ref><ref id="B4-sensors-25-00993"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Patsakis</surname><given-names>C.</given-names></name>
<name><surname>Casino</surname><given-names>F.</given-names></name>
<name><surname>Katos</surname><given-names>V.</given-names></name>
</person-group><article-title>Encrypted and covert DNS queries for botnets: Challenges and countermeasures</article-title><source>Comput. Secur.</source><year>2020</year><volume>88</volume><fpage>101614</fpage><pub-id pub-id-type="doi">10.1016/j.cose.2019.101614</pub-id></element-citation></ref><ref id="B5-sensors-25-00993"><label>5.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>X.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Yang</surname><given-names>X.</given-names></name>
<name><surname>Gai</surname><given-names>W.</given-names></name>
<name><surname>Sun</surname><given-names>B.</given-names></name>
</person-group><article-title>MFC-DoH: DoH Tunnel Detection Based on the Fusion of MAML and F-CNN</article-title><source>Proceedings of the 21st ACM International Conference on Computing Frontiers</source><conf-loc>Ischia, Italy</conf-loc><conf-date>7&#x02013;9 May 2024</conf-date><fpage>267</fpage><lpage>275</lpage></element-citation></ref><ref id="B6-sensors-25-00993"><label>6.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Singh</surname><given-names>S.K.</given-names></name>
<name><surname>Roy</surname><given-names>P.K.</given-names></name>
</person-group><article-title>Detecting malicious dns over https traffic using machine learning</article-title><source>Proceedings of the 2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies (3ICT)</source><conf-loc>Sakheer, Bahrain</conf-loc><conf-date>20&#x02013;21 December 2020</conf-date><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B7-sensors-25-00993"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhan</surname><given-names>M.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Yu</surname><given-names>G.</given-names></name>
<name><surname>Li</surname><given-names>B.</given-names></name>
<name><surname>Wang</surname><given-names>W.</given-names></name>
</person-group><article-title>Detecting DNS over HTTPS based data exfiltration</article-title><source>Comput. Netw.</source><year>2022</year><volume>209</volume><fpage>108919</fpage><pub-id pub-id-type="doi">10.1016/j.comnet.2022.108919</pub-id></element-citation></ref><ref id="B8-sensors-25-00993"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ali</surname><given-names>J.</given-names></name>
<name><surname>Singh</surname><given-names>S.K.</given-names></name>
<name><surname>Jiang</surname><given-names>W.</given-names></name>
<name><surname>Alenezi</surname><given-names>A.M.</given-names></name>
<name><surname>Islam</surname><given-names>M.</given-names></name>
<name><surname>Daradkeh</surname><given-names>Y.I.</given-names></name>
<name><surname>Mehmood</surname><given-names>A.</given-names></name>
</person-group><article-title>A deep dive into cybersecurity solutions for AI-driven IoT-enabled smart cities in advanced communication networks</article-title><source>Comput. Commun.</source><year>2025</year><volume>229</volume><fpage>108000</fpage><pub-id pub-id-type="doi">10.1016/j.comcom.2024.108000</pub-id></element-citation></ref><ref id="B9-sensors-25-00993"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wu</surname><given-names>Y.</given-names></name>
<name><surname>Lin</surname><given-names>G.</given-names></name>
<name><surname>Liu</surname><given-names>L.</given-names></name>
<name><surname>Hong</surname><given-names>Z.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Yang</surname><given-names>X.</given-names></name>
<name><surname>Jiang</surname><given-names>Z.L.</given-names></name>
<name><surname>Ji</surname><given-names>S.</given-names></name>
<name><surname>Wen</surname><given-names>Z.</given-names></name>
</person-group><article-title>MASiNet: Network Intrusion Detection for IoT Security Based on Meta-Learning Framework</article-title><source>IEEE Internet Things J.</source><year>2024</year><volume>11</volume><fpage>25136</fpage><lpage>25146</lpage><pub-id pub-id-type="doi">10.1109/JIOT.2024.3395629</pub-id></element-citation></ref><ref id="B10-sensors-25-00993"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yusof</surname><given-names>M.H.M.</given-names></name>
<name><surname>Almohammedi</surname><given-names>A.A.</given-names></name>
<name><surname>Shepelev</surname><given-names>V.</given-names></name>
<name><surname>Ahmed</surname><given-names>O.</given-names></name>
</person-group><article-title>Visualizing realistic benchmarked IDS dataset: CIRA-CIC-DoHBrw-2020</article-title><source>IEEE Access</source><year>2022</year><volume>10</volume><fpage>94624</fpage><lpage>94642</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2022.3204690</pub-id></element-citation></ref><ref id="B11-sensors-25-00993"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Singh</surname><given-names>S.K.</given-names></name>
<name><surname>Roy</surname><given-names>P.K.</given-names></name>
</person-group><article-title>Malicious traffic detection of DNS over https using ensemble machine learning</article-title><source>Int. J. Comput. Digit. Syst.</source><year>2022</year><volume>11</volume><fpage>189</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.12785/ijcds/110185</pub-id><pub-id pub-id-type="pmid">39153339</pub-id>
</element-citation></ref><ref id="B12-sensors-25-00993"><label>12.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>MontazeriShatoori</surname><given-names>M.</given-names></name>
<name><surname>Davidson</surname><given-names>L.</given-names></name>
<name><surname>Kaur</surname><given-names>G.</given-names></name>
<name><surname>Lashkari</surname><given-names>A.H.</given-names></name>
</person-group><article-title>Detection of doh tunnels using time-series classification of encrypted traffic</article-title><source>Proceedings of the 2020 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)</source><conf-loc>Calgary, AB, Canada</conf-loc><conf-date>17&#x02013;22 August 2020</conf-date><fpage>63</fpage><lpage>70</lpage></element-citation></ref><ref id="B13-sensors-25-00993"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Aggarwal</surname><given-names>A.</given-names></name>
<name><surname>Kumar</surname><given-names>M.</given-names></name>
</person-group><article-title>An ensemble framework for detection of DNS-Over-HTTPS (DOH) traffic</article-title><source>Multimed. Tools Appl.</source><year>2024</year><volume>83</volume><fpage>32945</fpage><lpage>32972</lpage><pub-id pub-id-type="doi">10.1007/s11042-023-16956-9</pub-id></element-citation></ref><ref id="B14-sensors-25-00993"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Casanova</surname><given-names>L.F.G.</given-names></name>
<name><surname>Po-Chiang</surname><given-names>L.</given-names></name>
</person-group><article-title>Malicious Network Traffic Detection for DNS over HTTPS using Machine Learning Algorithms</article-title><source>APSIPA Trans. Signal Inf. Process.</source><year>2023</year><volume>12</volume><fpage>e11</fpage></element-citation></ref><ref id="B15-sensors-25-00993"><label>15.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Stalder</surname><given-names>D.</given-names></name>
</person-group><article-title>Machine-Learning Based Detection of Malicious DNS-over-HTTPS (DoH) Traffic Based on Packet Captures</article-title><source>Bachelor&#x02019;s Thesis</source><publisher-name>University of Zurich</publisher-name><publisher-loc>Z&#x000fc;rich, Switzerland</publisher-loc><year>2021</year></element-citation></ref><ref id="B16-sensors-25-00993"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zebin</surname><given-names>T.</given-names></name>
<name><surname>Rezvy</surname><given-names>S.</given-names></name>
<name><surname>Luo</surname><given-names>Y.</given-names></name>
</person-group><article-title>An explainable AI-based intrusion detection system for DNS over HTTPS (DoH) attacks</article-title><source>IEEE Trans. Inf. Forensics Secur.</source><year>2022</year><volume>17</volume><fpage>2339</fpage><lpage>2349</lpage><pub-id pub-id-type="doi">10.1109/TIFS.2022.3183390</pub-id></element-citation></ref><ref id="B17-sensors-25-00993"><label>17.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>MontazeriShatoori</surname><given-names>M.</given-names></name>
<name><surname>Davidson</surname><given-names>L.</given-names></name>
<name><surname>Kaur</surname><given-names>G.</given-names></name>
<name><surname>Lashkari</surname><given-names>A.H.</given-names></name>
</person-group><article-title>CIRA-CIC-DoHBrw-2020</article-title><year>2020</year><comment>Available online: <ext-link xlink:href="https://www.unb.ca/cic/datasets/dohbrw-2020.html" ext-link-type="uri">https://www.unb.ca/cic/datasets/dohbrw-2020.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-01-25">(accessed on 25 January 2025)</date-in-citation></element-citation></ref><ref id="B18-sensors-25-00993"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jerabek</surname><given-names>K.</given-names></name>
<name><surname>Hynek</surname><given-names>K.</given-names></name>
<name><surname>Rysavy</surname><given-names>O.</given-names></name>
</person-group><article-title>Comparative analysis of DNS over HTTPS detectors</article-title><source>Comput. Netw.</source><year>2024</year><volume>247</volume><fpage>110452</fpage><pub-id pub-id-type="doi">10.1016/j.comnet.2024.110452</pub-id></element-citation></ref><ref id="B19-sensors-25-00993"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Je&#x00159;&#x000e1;bek</surname><given-names>K.</given-names></name>
<name><surname>Hynek</surname><given-names>K.</given-names></name>
<name><surname>&#x0010c;ejka</surname><given-names>T.</given-names></name>
<name><surname>Ry&#x00161;av&#x01ef3;</surname><given-names>O.</given-names></name>
</person-group><article-title>Collection of datasets with DNS over HTTPS traffic</article-title><source>Data Brief</source><year>2022</year><volume>42</volume><fpage>108310</fpage><pub-id pub-id-type="doi">10.1016/j.dib.2022.108310</pub-id><pub-id pub-id-type="pmid">35677460</pub-id>
</element-citation></ref><ref id="B20-sensors-25-00993"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Breiman</surname><given-names>L.</given-names></name>
</person-group><article-title>Random forests</article-title><source>Mach. Learn.</source><year>2001</year><volume>45</volume><fpage>5</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></element-citation></ref><ref id="B21-sensors-25-00993"><label>21.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>Z.</given-names></name>
<name><surname>Badrinarayanan</surname><given-names>V.</given-names></name>
<name><surname>Lee</surname><given-names>C.Y.</given-names></name>
<name><surname>Rabinovich</surname><given-names>A.</given-names></name>
</person-group><article-title>Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks</article-title><source>Proceedings of the International Conference on Machine Learning, PMLR</source><conf-loc>Stockholm, Sweden</conf-loc><conf-date>10&#x02013;15 July 2018</conf-date><fpage>794</fpage><lpage>803</lpage></element-citation></ref><ref id="B22-sensors-25-00993"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bahdanau</surname><given-names>D.</given-names></name>
</person-group><article-title>Neural machine translation by jointly learning to align and translate</article-title><source>arXiv</source><year>2014</year><pub-id pub-id-type="arxiv">1409.0473</pub-id></element-citation></ref><ref id="B23-sensors-25-00993"><label>23.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Akiba</surname><given-names>T.</given-names></name>
<name><surname>Sano</surname><given-names>S.</given-names></name>
<name><surname>Yanase</surname><given-names>T.</given-names></name>
<name><surname>Ohta</surname><given-names>T.</given-names></name>
<name><surname>Koyama</surname><given-names>M.</given-names></name>
</person-group><article-title>Optuna: A next-generation hyperparameter optimization framework</article-title><source>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &#x00026; Data Mining</source><conf-loc>Anchorage, AK, USA</conf-loc><conf-date>4&#x02013;8 August 2019</conf-date><fpage>2623</fpage><lpage>2631</lpage></element-citation></ref><ref id="B24-sensors-25-00993"><label>24.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Casanova</surname><given-names>L.F.G.</given-names></name>
<name><surname>Lin</surname><given-names>P.C.</given-names></name>
</person-group><article-title>Generalized classification of DNS over HTTPS traffic with deep learning</article-title><source>Proceedings of the 2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</source><conf-loc>Tokyo, Japan</conf-loc><conf-date>14&#x02013;17 December 2021</conf-date><fpage>1903</fpage><lpage>1907</lpage></element-citation></ref><ref id="B25-sensors-25-00993"><label>25.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Je&#x00159;&#x000e1;bek</surname><given-names>K.</given-names></name>
<name><surname>Stuchl&#x000fd;</surname><given-names>S.</given-names></name>
</person-group><article-title>DNS over HTTPS Network Traffic</article-title><year>2021</year><comment>Available online: <ext-link xlink:href="https://ieee-dataport.org/documents/dns-over-https-network-traffic" ext-link-type="uri">https://ieee-dataport.org/documents/dns-over-https-network-traffic</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-01-25">(accessed on 25 January 2025)</date-in-citation></element-citation></ref><ref id="B26-sensors-25-00993"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mitsuhashi</surname><given-names>R.</given-names></name>
<name><surname>Jin</surname><given-names>Y.</given-names></name>
<name><surname>Iida</surname><given-names>K.</given-names></name>
<name><surname>Shinagawa</surname><given-names>T.</given-names></name>
<name><surname>Takai</surname><given-names>Y.</given-names></name>
</person-group><article-title>Malicious DNS tunnel tool recognition using persistent DoH traffic analysis</article-title><source>IEEE Trans. Netw. Serv. Manag.</source><year>2022</year><volume>20</volume><fpage>2086</fpage><lpage>2095</lpage><pub-id pub-id-type="doi">10.1109/TNSM.2022.3215681</pub-id></element-citation></ref><ref id="B27-sensors-25-00993"><label>27.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>MontazeriShatoori</surname><given-names>M.</given-names></name>
<name><surname>Davidson</surname><given-names>L.</given-names></name>
<name><surname>Kaur</surname><given-names>G.</given-names></name>
<name><surname>Lashkari</surname><given-names>A.H.</given-names></name>
</person-group><article-title>CIRA-CIC-DoHBrw-2020 and DoH-Tunnel-Traffic-HKD Combined Dataset</article-title><year>2022</year><comment>Available online: <ext-link xlink:href="https://github.com/doh-traffic-dataset/CIRA-CIC-DoHBrw-2020-and-DoH-Tunnel-Traffic-HKD?tab=readme-ov-file" ext-link-type="uri">https://github.com/doh-traffic-dataset/CIRA-CIC-DoHBrw-2020-and-DoH-Tunnel-Traffic-HKD?tab=readme-ov-file</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-01-25">(accessed on 25 January 2025)</date-in-citation></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-00993-f001"><label>Figure 1</label><caption><p>Overview of MTL-DoHTA framework. The * in &#x02018;.pcap&#x02019; represents all file names.</p></caption><graphic xlink:href="sensors-25-00993-g001" position="float"/></fig><fig position="float" id="sensors-25-00993-f002"><label>Figure 2</label><caption><p>Feature importance via Random Forest algorithm. X-axis is a feature importance value, and Y-axis is a statistical feature name.</p></caption><graphic xlink:href="sensors-25-00993-g002" position="float"/></fig><fig position="float" id="sensors-25-00993-f003"><label>Figure 3</label><caption><p>Statistical features to image.</p></caption><graphic xlink:href="sensors-25-00993-g003" position="float"/></fig><fig position="float" id="sensors-25-00993-f004"><label>Figure 4</label><caption><p>Structure of MTL-DoHTA.</p></caption><graphic xlink:href="sensors-25-00993-g004" position="float"/></fig><table-wrap position="float" id="sensors-25-00993-t001"><object-id pub-id-type="pii">sensors-25-00993-t001_Table 1</object-id><label>Table 1</label><caption><p>Literature review via characteristics and limitations related to&#x000a0;DoH.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Study</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Research Themes</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Characteristics</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Limitations</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Task 1
</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Task 2</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Task 3</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B1-sensors-25-00993" ref-type="bibr">1</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Investigating preliminary identification methodologies for the recognition of DoH utilization.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Acknowledge the significance of early detection of DoH traffic and elucidate fundamental detection methodologies.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Preliminary investigations exhibit inadequate detection precision, and&#x000a0;there exists an absence of systematic classification and comprehensive examination of malevolent traffic.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B10-sensors-25-00993" ref-type="bibr">10</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Centers on advanced visualization (Eigen Centrality, PCA, GMM) and dataset exploration for IDS enhancements in DoH-based cyber threats.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Demonstrates the importance of Layer 3 data and realistic threat simulation to inform the development of more effective IDS models.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dataset imbalances, inconsistent classification performance across varied methods, and&#x000a0;limitations of task scalability</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B4-sensors-25-00993" ref-type="bibr">4</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Analyze how encrypted DNS queries are used in botnets and other malicious activities</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Presenting techniques and countermeasures for botnet activities and DNS tunneling exploiting DoH</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Discuss misuse cases rather than detection techniques</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B5-sensors-25-00993" ref-type="bibr">5</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Proposal of a DNS tunneling detection framework that integrates model-agnostic meta-learning and Convolutional Neural Networks.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Facilitates elevated precision via swift adjustment within constrained data contexts.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The emphasis is placed on particular DNS tunneling instruments, resulting in the generalized detection paradigm lacking scalability.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B6-sensors-25-00993" ref-type="bibr">6</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Research on methodologies for identifying nefarious DoH traffic through the application of machine learning algorithms.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Examine a range of machine learning frameworks and propose strategies for enhancing detection precision.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Concentrate on binary classification instead of multi-class classification.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B11-sensors-25-00993" ref-type="bibr">11</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Identify nefarious behavior within DoH traffic by employing ensemble machine learning methodologies.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Conduct a comparative analysis of the efficacy of various models, documenting elevated detection accuracy alongside minimal rates of false positives.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The emphasis is placed on binary classification as opposed to multi-class classification.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B12-sensors-25-00993" ref-type="bibr">12</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Proposed temporal series classification framework for the identification of DNS tunneling phenomena occurring within DoH traffic.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Enhance precision and operational efficacy through the recommendation of detection methodologies grounded in time series classification algorithms.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">No experiments for Task 3 to identify specific DNS tunneling tools</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B13-sensors-25-00993" ref-type="bibr">13</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Research on methodologies for DNS covert channel detection with Multi-layer perceptron, Multi-Head Attention, and&#x000a0;Residual Neural Networks</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Feature fusion of session feature and sequence feature</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Single tasks in multi-class classification and limitation of model&#x02019;s scalability</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B14-sensors-25-00993" ref-type="bibr">14</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Focuses on simple recurrent neural network multi-stage classification (Task 1 and Task 2) for malicious DoH detection.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Employs the CIC-DoHBrw-2020 dataset with LSTM/GRU models, emphasizing preprocessing, class imbalance handling, and&#x000a0;two-layer classification.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Single tasks in RNNs algorithms (LSTM, GRU, deepRNN, and&#x000a0;biLSTM) and limitation of model&#x02019;s scalability</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B15-sensors-25-00993" ref-type="bibr">15</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Focuses on machine-learning detection of malicious DoH traffic, emphasizing a two-step classification (benign vs. malicious DoH).</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Implements a PCAP-based novel feature extraction and ML (e.g., LGBM) to identify malicious DoH activity.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Reduced accuracy across diverse datasets, limited realism in browser settings, and&#x000a0;no evaluation of Task 3.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">[<xref rid="B16-sensors-25-00993" ref-type="bibr">16</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Proposes an explainable AI framework using a balanced Random Forest to accurately detect and classify malicious DoH traffic.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Leverages the CIC-DoHBrw-2020 dataset, achieves high metrics, and&#x000a0;employs SHAP for transparent model decisions.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Lacks of large-scale deployment considerations, and&#x000a0;limitations model&#x02019;s task scalability</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">X</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t002"><object-id pub-id-type="pii">sensors-25-00993-t002_Table 2</object-id><label>Table 2</label><caption><p>List of statistical traffic&#x000a0;features.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Category</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Statistical Feature Name</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Duration</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Flow&#x000a0;duration</td></tr><tr><td rowspan="4" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Number of bytes</td><td align="left" valign="middle" rowspan="1" colspan="1">2</td><td align="left" valign="middle" rowspan="1" colspan="1">Number of flow bytes&#x000a0;sent</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">3</td><td align="left" valign="middle" rowspan="1" colspan="1">Rate of flow bytes&#x000a0;sent</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">4</td><td align="left" valign="middle" rowspan="1" colspan="1">Number of flow bytes&#x000a0;received</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Rate of flow bytes&#x000a0;received</td></tr><tr><td rowspan="8" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Packet length</td><td align="left" valign="middle" rowspan="1" colspan="1">6</td><td align="left" valign="middle" rowspan="1" colspan="1">Mean packet&#x000a0;length</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">7</td><td align="left" valign="middle" rowspan="1" colspan="1">Median packet&#x000a0;length</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">8</td><td align="left" valign="middle" rowspan="1" colspan="1">Mode packet&#x000a0;length</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">9</td><td align="left" valign="middle" rowspan="1" colspan="1">Variance of packet&#x000a0;length</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">10</td><td align="left" valign="middle" rowspan="1" colspan="1">Standard deviation of packet&#x000a0;length</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">11</td><td align="left" valign="middle" rowspan="1" colspan="1">Coefficient of variation of packet&#x000a0;length</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">12</td><td align="left" valign="middle" rowspan="1" colspan="1">Skew from median packet&#x000a0;length</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Skew from mode packet&#x000a0;length</td></tr><tr><td rowspan="8" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Packet time</td><td align="left" valign="middle" rowspan="1" colspan="1">14</td><td align="left" valign="middle" rowspan="1" colspan="1">Mean packet&#x000a0;time</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">15</td><td align="left" valign="middle" rowspan="1" colspan="1">Median packet&#x000a0;time</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">16</td><td align="left" valign="middle" rowspan="1" colspan="1">Mode packet&#x000a0;time</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">17</td><td align="left" valign="middle" rowspan="1" colspan="1">Variance of packet&#x000a0;time</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">18</td><td align="left" valign="middle" rowspan="1" colspan="1">Standard deviation of packet&#x000a0;time</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">19</td><td align="left" valign="middle" rowspan="1" colspan="1">Coefficient of variation of packet&#x000a0;time</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">20</td><td align="left" valign="middle" rowspan="1" colspan="1">Skew from median packet&#x000a0;time</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Skew from mode packet&#x000a0;time</td></tr><tr><td rowspan="8" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Request/responsetime difference</td><td align="left" valign="middle" rowspan="1" colspan="1">22</td><td align="left" valign="middle" rowspan="1" colspan="1">Mean request/response time&#x000a0;difference</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">23</td><td align="left" valign="middle" rowspan="1" colspan="1">Median request/response time&#x000a0;difference</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">24</td><td align="left" valign="middle" rowspan="1" colspan="1">Mode request/response time&#x000a0;difference</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">25</td><td align="left" valign="middle" rowspan="1" colspan="1">Variance of request/response time&#x000a0;difference</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">26</td><td align="left" valign="middle" rowspan="1" colspan="1">Standard deviation of request/response time&#x000a0;difference</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">27</td><td align="left" valign="middle" rowspan="1" colspan="1">Coefficient of variation of request/response time&#x000a0;difference</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">28</td><td align="left" valign="middle" rowspan="1" colspan="1">Skew from median request/response time&#x000a0;difference</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">29</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Skew from mode request/response time&#x000a0;difference</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t003"><object-id pub-id-type="pii">sensors-25-00993-t003_Table 3</object-id><label>Table 3</label><caption><p>CIC-DoHBrw-2020 dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Browsers/Tools</th><th align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Benign-DoH</th><th align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Non-DoH</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Malicious DoH</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Google Chrome/Mozilla Firefox
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Google Chrome/Mozilla Firefox
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
iodine
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
dnscat2
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
dns2tcp
</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Number of Flows</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">19,807</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">897,493</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">46,613</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">35,622</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">167,515</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t004"><object-id pub-id-type="pii">sensors-25-00993-t004_Table 4</object-id><label>Table 4</label><caption><p>Experimental settings.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Category</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Experimental Environment</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Operating system</td><td align="center" valign="middle" rowspan="1" colspan="1">Windows 11</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Processor</td><td align="center" valign="middle" rowspan="1" colspan="1">Intel (R) Core&#x02122; i9-14900KF</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">GPU</td><td align="center" valign="middle" rowspan="1" colspan="1">GeForce RTX 4090</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Programming language and version</td><td align="center" valign="middle" rowspan="1" colspan="1">Python 3.9</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Library</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pytorch, scikit-learn</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t005"><object-id pub-id-type="pii">sensors-25-00993-t005_Table 5</object-id><label>Table 5</label><caption><p>Structural parameters in MTL-DoHTA.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Structure</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Layer</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Operation</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Input</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Output</th></tr></thead><tbody><tr><td rowspan="9" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Shared Layers</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Conv2D</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2D Convolution (32 filters, 3 kernels, 1 padding)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ReLU + MaxPool</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ReLU Activation + Max Pooling (2 kernels)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm75" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Conv2D</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2D Convolution (64 filters, kernel = 3, padding = 1)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm76" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm77" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ReLU</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ReLU Activation</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm78" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm79" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Conv2D</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2D Convolution (128 filters, kernel = 3, padding = 1)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm80" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm81" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ReLU</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ReLU Activation</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm82" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm83" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Global Average Pooling</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pooling over spatial dimensions</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm84" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm85" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>128</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Fully Connected (fc1)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear transformation + ReLU + Dropout</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm86" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>128</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm87" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>64</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Fully Connected (fc2)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear transformation + ReLU + Dropout</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm88" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>64</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm89" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Task-Specific Attention</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 1 Attention</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Weighted Attention using Task Importance</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm90" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm91" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 2 Attention</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Weighted Attention using Task Importance</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm92" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm93" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3 Attention</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Weighted Attention using Task Importance</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm94" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm95" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Task-Specific Heads</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 1 Head</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear transformation</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm96" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm97" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 2 Head</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear transformation</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm98" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm99" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3 Head</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Linear transformation (Softmax)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm100" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>29</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm101" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>5</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t006"><object-id pub-id-type="pii">sensors-25-00993-t006_Table 6</object-id><label>Table 6</label><caption><p>Performance of F1-score comparison changing layer structure and function adaptation.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Shared Layer <break/>
(Layer 1&#x02013;2&#x02013;3)</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">2D-CNN</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">2D-CNN + GradNorm</th><th colspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">MTL-DoHTA <break/>
(2D-CNN + GradNorm + Attention)</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Each Task
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Average
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Each Task
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Average
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Each Task
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Average
</th></tr></thead><tbody><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">16&#x02013;32&#x02013;64</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9785</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9817</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9765</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9775</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9868</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9863</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9951</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9922</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9968</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9715</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9638</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9754</td></tr><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">32&#x02013;32&#x02013;64</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9823</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9852</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9849</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9871</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9834</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9860</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9963</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9978</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9969</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9769</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9785</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9777</td></tr><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">32&#x02013;64&#x02013;128</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9838</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9871</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9864</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9881</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1: 0.9891</td><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">0.9905</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9988</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9984</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 2: 0.9988</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9786</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9794</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3: 0.9837</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t007"><object-id pub-id-type="pii">sensors-25-00993-t007_Table 7</object-id><label>Table 7</label><caption><p>Performance evaluation (F1-score) by downsampling rate. In the 2D-CNN, we choose the shared layer&#x02019;s width 16&#x02013;32&#x02013;64 to set the baseline.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Model</th><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Tasks</th><th colspan="5" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Downsampling Percentage</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
10%
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
20%
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
30%
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
40%
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
50%
</th></tr></thead><tbody><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">2D-CNN</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9874</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9857</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9858</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9860</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9841</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Task 2</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9968</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9975</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9868</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9979</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9946</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9776</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9788</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9740</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9753</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9699</td></tr><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">MTL-DoHTA (2D-CNN + GradNorm + Attention)</td><td align="left" valign="middle" rowspan="1" colspan="1">Task 1</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9853</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9855</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9852</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9865</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9855</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Task 2</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9982</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9977</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9978</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9981</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9983</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9786</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9786</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9763</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9783</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9787</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t008"><object-id pub-id-type="pii">sensors-25-00993-t008_Table 8</object-id><label>Table 8</label><caption><p>Macro-averaging F1-score of MTL-DoHTA with attention weights (baseline: 2D-CNN + GradNorm).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Shared Layer <break/>
(Layer 1&#x02013;2&#x02013;3)</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Baseline</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Baseline + Dynamic<break/>
Attention Weight</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Baseline + Static Attention Weight<break/>
(Average Weight Value)</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Baseline + Static Attention Weight<break/>
(Feature Importance)</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">16&#x02013;32&#x02013;64</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9775</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9819</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9832</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9863</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">32&#x02013;32&#x02013;64</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9871</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9846</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9866</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9860</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32&#x02013;64&#x02013;128</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9881</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9817</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9879</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9905</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t009"><object-id pub-id-type="pii">sensors-25-00993-t009_Table 9</object-id><label>Table 9</label><caption><p>Performance comparison with other methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Paper</th><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Best Algorithm</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">F1-Score</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Task 1
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Task 2
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Task 3
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">Singh&#x000a0;et&#x000a0;al. [<xref rid="B6-sensors-25-00993" ref-type="bibr">6</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">RF</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Singh&#x000a0;et&#x000a0;al. [<xref rid="B11-sensors-25-00993" ref-type="bibr">11</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">Ensemble ML</td><td align="left" valign="middle" rowspan="1" colspan="1">0.997</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9970</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">MontazeriShatoori&#x000a0;et&#x000a0;al. [<xref rid="B12-sensors-25-00993" ref-type="bibr">12</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">LSTM-based</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9980</td><td align="left" valign="middle" rowspan="1" colspan="1">0.999</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Casanova&#x000a0;et&#x000a0;al. [<xref rid="B24-sensors-25-00993" ref-type="bibr">24</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">BiLSTM</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9870</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9990</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Zebin&#x000a0;et&#x000a0;al. [<xref rid="B16-sensors-25-00993" ref-type="bibr">16</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">Balanced Stacked RF</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9990</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9990</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Casanova&#x000a0;et&#x000a0;al. [<xref rid="B14-sensors-25-00993" ref-type="bibr">14</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">BiLSTM</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9950</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9900</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Stalder [<xref rid="B15-sensors-25-00993" ref-type="bibr">15</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">ML</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9980</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9890</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Aggarwal&#x000a0;et&#x000a0;al. [<xref rid="B13-sensors-25-00993" ref-type="bibr">13</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">Ensemble ML</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9986</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9999</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Liu&#x000a0;et&#x000a0;al. [<xref rid="B5-sensors-25-00993" ref-type="bibr">5</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">MFC-DoH (few-shot 20)</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td><td align="left" valign="middle" rowspan="1" colspan="1">X</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9100</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MTL-DoHTA</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MTL-DoHTA</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9891</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9988</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9837</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00993-t010"><object-id pub-id-type="pii">sensors-25-00993-t010_Table 10</object-id><label>Table 10</label><caption><p>Parameter comparison with deep learning methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Paper</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Model Complexity</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Scalability</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number of Parameter <break/>
(Model)</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">MontazeriShatoori&#x000a0;et&#x000a0;al. [<xref rid="B12-sensors-25-00993" ref-type="bibr">12</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">Middle</td><td align="left" valign="middle" rowspan="1" colspan="1">Middle</td><td align="left" valign="middle" rowspan="1" colspan="1">about 37,000</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Casanova&#x000a0;et&#x000a0;al. [<xref rid="B14-sensors-25-00993" ref-type="bibr">14</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">Middle</td><td align="left" valign="middle" rowspan="1" colspan="1">Middle</td><td align="left" valign="middle" rowspan="1" colspan="1">72,244</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Liu&#x000a0;et&#x000a0;al. [<xref rid="B5-sensors-25-00993" ref-type="bibr">5</xref>]</td><td align="left" valign="middle" rowspan="1" colspan="1">High</td><td align="left" valign="middle" rowspan="1" colspan="1">High</td><td align="left" valign="middle" rowspan="1" colspan="1">1,147,904</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MTL-DoHTA</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">High</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">105,546</td></tr></tbody></table></table-wrap></floats-group></article>