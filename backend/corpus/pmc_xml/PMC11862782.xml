<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">JMIR Hum Factors</journal-id><journal-id journal-id-type="iso-abbrev">JMIR Hum Factors</journal-id><journal-id journal-id-type="publisher-id">JMIR Human Factors</journal-id><journal-title-group><journal-title>JMIR Human Factors</journal-title></journal-title-group><issn pub-type="epub">2292-9495</issn><publisher><publisher-name>JMIR Publications</publisher-name><publisher-loc>Toronto, Canada</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39932773</article-id><article-id pub-id-type="pmc">PMC11862782</article-id><article-id pub-id-type="publisher-id">v12i1e60273</article-id><article-id pub-id-type="doi">10.2196/60273</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group><subj-group subj-group-type="article-type"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>The Effects of Presenting AI Uncertainty Information on Pharmacists&#x02019; Trust in Automated Pill Recognition Technology: Exploratory Mixed Subjects Study</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Kushniruk</surname><given-names>Andre</given-names></name></contrib><contrib contrib-type="editor"><name><surname>Borycki</surname><given-names>Elizabeth</given-names></name></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Waterson</surname><given-names>James</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Neyedli</surname><given-names>Heather F</given-names></name></contrib></contrib-group><contrib-group><contrib id="contrib1" contrib-type="author"><name><surname>Kim</surname><given-names>Jin Yong</given-names></name><degrees>BSE</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0009-0002-1626-7204</contrib-id></contrib><contrib id="contrib2" contrib-type="author"><name><surname>Marshall</surname><given-names>Vincent D</given-names></name><degrees>MS</degrees><xref rid="aff2" ref-type="aff">2</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2594-7407</contrib-id></contrib><contrib id="contrib3" contrib-type="author"><name><surname>Rowell</surname><given-names>Brigid</given-names></name><degrees>MA</degrees><xref rid="aff2" ref-type="aff">2</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8469-899X</contrib-id></contrib><contrib id="contrib4" contrib-type="author"><name><surname>Chen</surname><given-names>Qiyuan</given-names></name><degrees>MSE</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0009-0006-4112-014X</contrib-id></contrib><contrib id="contrib5" contrib-type="author"><name><surname>Zheng</surname><given-names>Yifan</given-names></name><degrees>PharmD</degrees><xref rid="aff2" ref-type="aff">2</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6997-735X</contrib-id></contrib><contrib id="contrib6" contrib-type="author"><name><surname>Lee</surname><given-names>John D</given-names></name><degrees>PhD</degrees><xref rid="aff3" ref-type="aff">3</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9808-2160</contrib-id></contrib><contrib id="contrib7" contrib-type="author"><name><surname>Kontar</surname><given-names>Raed Al</given-names></name><degrees>PhD</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4546-324X</contrib-id></contrib><contrib id="contrib8" contrib-type="author"><name><surname>Lester</surname><given-names>Corey</given-names></name><degrees>PharmD, PhD</degrees><xref rid="aff2" ref-type="aff">2</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8774-793X</contrib-id></contrib><contrib id="contrib9" contrib-type="author" corresp="yes"><name><surname>Yang</surname><given-names>Xi Jessie</given-names></name><degrees>PhD</degrees><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6071-0387</contrib-id><xref rid="aff1" ref-type="aff">1</xref><address><institution/><institution>Industrial and Operations Engineering</institution><institution>University of Michigan</institution><addr-line>1640 IOE</addr-line><addr-line>1205 Beal Avenue</addr-line><addr-line>Ann Arbor, MI, 48105</addr-line><country>United States</country><phone>1 7347630541</phone><email>xijyang@umich.edu</email></address></contrib></contrib-group><aff id="aff1">
<label>1</label>
<institution>Industrial and Operations Engineering</institution>
<institution>University of Michigan</institution>
<addr-line>Ann Arbor, MI</addr-line>
<country>United States</country>
</aff><aff id="aff2">
<label>2</label>
<institution>College of Pharmacy</institution>
<institution>University of Michigan</institution>
<addr-line>Ann Arbor, MI</addr-line>
<country>United States</country>
</aff><aff id="aff3">
<label>3</label>
<institution>Industrial and Systems Engineering</institution>
<institution>University of Wisconsin-Madison</institution>
<addr-line>Madison, MI</addr-line>
<country>United States</country>
</aff><author-notes><corresp>Corresponding Author: Xi Jessie Yang <email>xijyang@umich.edu</email></corresp></author-notes><pub-date pub-type="collection"><year>2025</year></pub-date><pub-date pub-type="epub"><day>11</day><month>2</month><year>2025</year></pub-date><volume>12</volume><elocation-id>e60273</elocation-id><history><date date-type="received"><day>6</day><month>5</month><year>2024</year></date><date date-type="rev-request"><day>13</day><month>9</month><year>2024</year></date><date date-type="rev-recd"><day>8</day><month>11</month><year>2024</year></date><date date-type="accepted"><day>22</day><month>12</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9;Jin Yong Kim, Vincent D Marshall, Brigid Rowell, Qiyuan Chen, Yifan Zheng, John D Lee, Raed Al Kontar, Corey Lester, Xi Jessie Yang. Originally published in JMIR Human Factors (https://humanfactors.jmir.org), 11.02.2025.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link xlink:href="https://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Human Factors, is properly cited. The complete bibliographic information, a link to the original publication on <ext-link xlink:href="https://humanfactors.jmir.org" ext-link-type="uri">https://humanfactors.jmir.org</ext-link>, as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:href="https://humanfactors.jmir.org/2025/1/e60273"/><abstract><sec sec-type="background"><title>Background</title><p>Dispensing errors significantly contribute to adverse drug events, resulting in substantial health care costs and patient harm. Automated pill verification technologies have been developed to aid pharmacists with medication dispensing. However, pharmacists&#x02019; trust in such automated technologies remains unexplored.</p></sec><sec sec-type="objective"><title>Objective</title><p>This study aims to investigate pharmacists&#x02019; trust in automated pill verification technology designed to support medication dispensing.</p></sec><sec sec-type="methods"><title>Methods</title><p>Thirty licensed pharmacists in the United States performed a web-based simulated pill verification task to determine whether an image of a filled medication bottle matched a known reference image. Participants completed a block of 100 verification trials without any help, and another block of 100 trials with the help of an imperfect artificial intelligence (AI) aid recommending acceptance or rejection of a filled medication bottle. The experiment used a mixed subjects design. The between-subjects factor was the AI aid type, with or without an AI uncertainty plot. The within-subjects factor was the four potential verification outcomes: (1) the AI rejects the incorrect drug, (2) the AI rejects the correct drug, (3) the AI approves the incorrect drug, and (4) the AI approves the correct drug. Participants&#x02019; trust in the AI system was measured. Mixed model (generalized linear models) tests were conducted with 2-tailed <italic>t</italic> tests to compare the means between the 2 AI aid types for each verification outcome.</p></sec><sec sec-type="results"><title>Results</title><p>Participants had an average trust propensity score of 72 (SD 18.08) out of 100, indicating a positive attitude toward trusting automated technologies. The introduction of an uncertainty plot to the AI aid significantly enhanced pharmacists&#x02019; end trust (<italic>t</italic><sub>28</sub>=&#x02013;1.854<italic>; P=</italic>.04). Trust dynamics were influenced by AI aid type and verification outcome. Specifically, pharmacists using the AI aid with the uncertainty plot had a significantly larger trust increment when the AI approved the correct drug (<italic>t</italic><sub>78.98</sub>=3.93; <italic>P</italic>&#x0003c;.001) and a significantly larger trust decrement when the AI approved the incorrect drug (<italic>t</italic><sub>2939.72</sub>=&#x02013;4.78; <italic>P</italic>&#x0003c;.001). Intriguingly, the absence of the uncertainty plot led to an increase in trust when the AI correctly rejected an incorrect drug, whereas the presence of the plot resulted in a decrease in trust under the same circumstances (<italic>t</italic><sub>509.77</sub>=&#x02013;3.96; <italic>P</italic>&#x0003c;.001). A pronounced &#x0201c;negativity bias&#x0201d; was observed, where the degree of trust reduction when the AI made an error exceeded the trust gain when the AI made a correct decision (<italic>z</italic>=&#x02013;11.30; <italic>P</italic>&#x0003c;.001).</p></sec><sec sec-type="conclusions"><title>Conclusions</title><p>To the best of our knowledge, this study is the first attempt to examine pharmacists&#x02019; trust in automated pill verification technology. Our findings reveal that pharmacists have a favorable disposition toward trusting automation. Moreover, providing uncertainty information about the AI&#x02019;s recommendation significantly boosts pharmacists&#x02019; trust in AI aid, highlighting the importance of developing transparent AI systems within health care.</p></sec></abstract><kwd-group><kwd>artificial intelligence</kwd><kwd>human-computer interaction</kwd><kwd>uncertainty communication</kwd><kwd>visualization</kwd><kwd>medication errors</kwd><kwd>safety</kwd><kwd>artificial intelligence aid</kwd><kwd>pharmacists</kwd><kwd>pill verification</kwd><kwd>automation</kwd></kwd-group></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><sec><title>Background</title><p>Pharmacists play a pivotal role in ensuring patients receive the correct medications as prescribed by health care providers. This involves a critical verification task, where pharmacists must match the medication dispensed in filled bottles with the prescription labels. Dispensing errors, defined as instances when patients receive the wrong drug or dosage, significantly contribute to preventable adverse drug events, leading to approximately 700,000 emergency department visits and 100,000 hospital admissions each year [<xref rid="ref1" ref-type="bibr">1</xref>]. Several challenges contribute to these errors including, but not limited to, limitations in current technology; lack of standardized procedures; and the high cognitive workload imposed on pharmacy staff, who often manage numerous tasks simultaneously [<xref rid="ref1" ref-type="bibr">1</xref>-<xref rid="ref4" ref-type="bibr">4</xref>]. To enhance patient health outcomes, reduce unnecessary health care costs, and alleviate the burden on pharmacists, it is essential to develop and implement reliable tools that minimize the risk of dispensing errors [<xref rid="ref5" ref-type="bibr">5</xref>].</p><p>Since the 1990s, the implementation of barcode scanning systems has been advocated as a means to reduce medication errors [<xref rid="ref6" ref-type="bibr">6</xref>]. The adoption of such systems within pharmacies and broader health care environments has led to a notable reduction in medication errors [<xref rid="ref7" ref-type="bibr">7</xref>-<xref rid="ref10" ref-type="bibr">10</xref>]. Nevertheless, research indicates that barcode scanning systems are not immune to workarounds and human errors [<xref rid="ref11" ref-type="bibr">11</xref>-<xref rid="ref13" ref-type="bibr">13</xref>]. Moreover, these systems do not adequately address the challenges faced by overburdened pharmacists [<xref rid="ref14" ref-type="bibr">14</xref>-<xref rid="ref17" ref-type="bibr">17</xref>].</p><p>In response to these challenges, pill counting and verification or recognition systems using image classification technologies have emerged [<xref rid="ref18" ref-type="bibr">18</xref>-<xref rid="ref21" ref-type="bibr">21</xref>]. Innovations like Eyecon and VIVID use vision-based methods to count medications placed on the tray. More recently, advancements have been made in automated pill identification through feature engineering. For example, Yu et al [<xref rid="ref22" ref-type="bibr">22</xref>] and Yu et al [<xref rid="ref23" ref-type="bibr">23</xref>] proposed an automatic pill recognition method based on pill imprints, achieving an accuracy of 86.01% and 90.46%, respectively. Caban et al [<xref rid="ref18" ref-type="bibr">18</xref>] used a modified shape distribution technique to determine the shape, color, and imprint of a pill to identify the drug. The proposed technique was evaluated with 568 of the most prescribed drugs in the United States and achieved a 91.13% accuracy.</p><p>The advent of deep learning has further enhanced the capabilities of automated pill recognition systems [<xref rid="ref5" ref-type="bibr">5</xref>,<xref rid="ref24" ref-type="bibr">24</xref>]. For instance, Larios Delgado et al [<xref rid="ref5" ref-type="bibr">5</xref>] developed a pill recognition method using 2 deep learning models. They used a deep convolutional neural network model for pill blob detection to isolate the pill from the background and then passed the output to a deep learning&#x02013;based classifier to identify the 5 most likely pills with 94% accuracy [<xref rid="ref5" ref-type="bibr">5</xref>]. Similarly, Wong et al [<xref rid="ref25" ref-type="bibr">25</xref>] proposed a deep convolutional network model and achieved a mean accuracy of 95.35%. Lester et al [<xref rid="ref24" ref-type="bibr">24</xref>] trained a ResNet-18 deep learning model to predict the labeled features of a medication product using an image showing medication inside a filled prescription bottle. In a test set containing 65,274 images of 345 unique oral drug products, the overall macroaverage precision, that is, the mean of precision values for each class, was 98.5%.</p><p>Despite the impressive strides in model accuracy, realizing the potential of these technologies is only possible if people establish appropriate trust in them. Trust in automation, defined as &#x0201c;the attitude that an agent will help achieve an individual&#x02019;s goals in situations characterized by uncertainty and vulnerability&#x0201d; [<xref rid="ref26" ref-type="bibr">26</xref>], is one of the most crucial factors determining the use of automation [<xref rid="ref27" ref-type="bibr">27</xref>,<xref rid="ref28" ref-type="bibr">28</xref>]. There is a growing body of research examining people&#x02019;s trust in autonomous and robotic technologies in various domains, including transportation [<xref rid="ref29" ref-type="bibr">29</xref>-<xref rid="ref31" ref-type="bibr">31</xref>], health care [<xref rid="ref32" ref-type="bibr">32</xref>,<xref rid="ref33" ref-type="bibr">33</xref>], education [<xref rid="ref34" ref-type="bibr">34</xref>], and defense [<xref rid="ref35" ref-type="bibr">35</xref>,<xref rid="ref36" ref-type="bibr">36</xref>]. In addition, researchers have developed various methods to enhance people&#x02019;s (proper) trust in automation or autonomy [<xref rid="ref37" ref-type="bibr">37</xref>,<xref rid="ref38" ref-type="bibr">38</xref>], including the use of various graphical representations [<xref rid="ref37" ref-type="bibr">37</xref>,<xref rid="ref39" ref-type="bibr">39</xref>-<xref rid="ref42" ref-type="bibr">42</xref>].</p><p>For example, a military perimeter defense experiment conducted by Mercado et al [<xref rid="ref43" ref-type="bibr">43</xref>] aimed to investigate the role of intelligent agent transparency on operator trust. Participants were tasked with selecting optimal routes for unmanned vehicles, assisted by an artificial intelligence (AI) agent. The AI agent operated at three levels of transparency: (1) basic details only; (2) basic details supplemented with reasoning and rationale; and (3) comprehensive information, including basic details, reasoning, rationale, and uncertainty indication, in a text description. They observed a positive correlation between transparency levels and participant trust. They concluded that providing operators with the agent&#x02019;s reasoning process and uncertainty metrics fostered a deeper understanding of the system&#x02019;s capabilities, thereby enhancing trust and increasing usability [<xref rid="ref43" ref-type="bibr">43</xref>]. This finding emphasizes the importance of transparent AI systems in supporting effective human-machine collaboration.</p><p>Another study investigated the impact of visual explanations on human trust in machine learning systems [<xref rid="ref40" ref-type="bibr">40</xref>]. Participants performed leaf classifying tasks with or without visual explanations. The leaf examples were presented in 2 formats: images and feature charts. Results revealed that providing visual explanations enhanced trust and confidence in participants&#x02019; decision-making. Interestingly, the feature charts were designed with intentional omissions of detailed explanations of features to prevent information overload. However, this simplification led participants to struggle to interpret the charts, and expert users expressed a need for more comprehensive feature descriptions to inform their decisions [<xref rid="ref40" ref-type="bibr">40</xref>]. This insight reveals the importance of integrating visual explanations with a thoughtfully managed information load for appropriate human trust.</p><p>Signal detection theory (SDT) is commonly used to study trust in automation by modeling the reliability of automated systems used by human operators. SDT evaluates how AI systems distinguish signals from noise, categorizing the state of the world as either &#x0201c;signal present&#x0201d; or &#x0201c;signal absent.&#x0201d; Based on SDT categorization, AI performance results in 4 outcomes: hit (error flagged correctly), miss (error not flagged), false alarm (FA; no error, but flagged incorrectly), and correct rejection (CR; no error and no flag). Correct identifications (hit and CR) increase trust, while incorrect ones (FA and miss) decrease trust [<xref rid="ref44" ref-type="bibr">44</xref>,<xref rid="ref45" ref-type="bibr">45</xref>]. Research indicates that FAs typically reduce trust less than misses, prompting designers to design more liberal systems (ie, more willing to flag an error) with higher rates of FAs to ensure potential issues are flagged [<xref rid="ref46" ref-type="bibr">46</xref>-<xref rid="ref48" ref-type="bibr">48</xref>]. In the context of pill dispensing, FAs may lead to minor disruptions, while misses could lead to dispensing errors, indicating that a more liberal AI system prioritizing safety by minimizing misses is beneficial.</p></sec><sec><title>Objectives</title><p>This study, therefore, aimed to explore pharmacists&#x02019; trust in automated pill verification technology, which is designed to assist with the critical task of medication dispensing. Specifically, we aimed to study the role of presenting AI uncertainty information on pharmacists&#x02019; trust in the system. The primary hypothesis was as follows:</p><list list-type="bullet"><list-item><p>H1: Presenting AI uncertainty information of predicted probability in a visualization format will increase AI transparency, leading to enhanced pharmacists&#x02019; trust in pill verification technology.</p></list-item></list><p>Beyond this primary focus, we also explored how pharmacists&#x02019; trust behavior varied across different AI performance patterns categorized by SDT. Drawing from these arguments, we derived the following hypotheses:</p><list list-type="bullet"><list-item><p>H2: Misses would result in a more significant decline in trust compared to FAs.</p></list-item><list-item><p>H3: Furthermore, given the differing consequences associated with the 4 SDT patterns, we speculate that presenting AI uncertainty information might have varying effects depending on the specific type of patterns.</p></list-item></list></sec></sec><sec sec-type="methods"><title>Methods</title><sec><title>Ethical Considerations</title><p>This research was exempt from institutional review board oversight by the University of Michigan (HUM#00213493). Before participating, participants signed an electronic informed consent form, and all data were collected anonymously. Participants received US $150 upon completion of the study.</p></sec><sec><title>Recruitment and Participants</title><p>Recruitment emails were dispatched to pharmacists through the Minnesota Pharmacy Practice-Based Research Network and the University of Michigan College of Pharmacy Pharmacist Preceptor Network. To meet the inclusion criteria, pharmacists were required to (1) be licensed pharmacists in the United States, (2) be aged at least 18 years, and (3) have access to a laptop or desktop computer with a webcam. Pharmacists who (1) require assistive technology to use the computer; (2) wear eyeglasses with more than one power; (3) have uncorrected cataracts, intraocular implants, glaucoma, or permanently dilated pupils; and (4) have eye movement or alignment abnormalities (eg, lazy eye, strabismus, nystagmus) were excluded from participation in the study (<xref rid="figure1" ref-type="fig">Figure 1</xref>). A total number of 30 licensed pharmacists in the United States completed the study. <xref rid="table1" ref-type="table">Table 1</xref> shows the demographic information.</p><fig position="float" id="figure1"><label>Figure 1</label><caption><p>Participant recruitment timeline.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig1" position="float"/></fig><table-wrap position="float" id="table1"><label>Table 1</label><caption><p>Participant demographic information (n=30).</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="30" span="1"/><col width="470" span="1"/><col width="500" span="1"/><col width="0" span="1"/><thead><tr valign="top"><td rowspan="2" colspan="2">Characteristic</td><td rowspan="2" colspan="1">Value</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td></tr></thead><tbody><tr valign="top"><td colspan="2" rowspan="1">
<bold>Age (years), mean (SD)</bold>
</td><td rowspan="1" colspan="1">39.40 (11.23)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td colspan="3" rowspan="1">
<bold>Sex, n (%)</bold>
</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Female</td><td rowspan="1" colspan="1">17 (57)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Male</td><td rowspan="1" colspan="1">13 (43)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td colspan="3" rowspan="1">
<bold>Practice setting, n (%)</bold>
</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Community pharmacy</td><td rowspan="1" colspan="1">15 (50)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Hospital pharmacy</td><td rowspan="1" colspan="1">6 (20)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Specialty pharmacy</td><td rowspan="1" colspan="1">1 (3)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Grocery store or mass merchandise pharmacy</td><td rowspan="1" colspan="1">1 (3)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Other</td><td rowspan="1" colspan="1">7 (23)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td colspan="3" rowspan="1">
<bold>Years worked, n (%)</bold>
</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">1-5</td><td rowspan="1" colspan="1">7 (23)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">6-10</td><td rowspan="1" colspan="1">7 (23)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">11-20</td><td rowspan="1" colspan="1">10 (33)</td><td rowspan="1" colspan="1">
<break/>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">21 or more</td><td rowspan="1" colspan="1">6 (20)</td><td rowspan="1" colspan="1">
<break/>
</td></tr></tbody></table></table-wrap></sec><sec><title>AI Model</title><p>The AI model used in this study is a Bayesian neural network that predicts the National Drug Code (NDC), a unique identifier assigned by the Food and Drug Administration to catalog drug products in the United States [<xref rid="ref49" ref-type="bibr">49</xref>,<xref rid="ref50" ref-type="bibr">50</xref>]. The Bayesian neural network used a technique known as random dropout [<xref rid="ref51" ref-type="bibr">51</xref>], applied to a ResNet-34 convolutional neural network architecture [<xref rid="ref52" ref-type="bibr">52</xref>] to estimate the probability associated with each NDC (ie, each class). The model produced 50 different predictions, where each prediction is a probability vector that quantifies the probabilities that an input belongs to each of the NDCs. The predicted NDC was then attained by finding the highest average probability derived from the 50 predictions.</p><p>To train the AI model, we acquired a dataset of 432,974 images from a mail-order pharmacy in the United States. This pharmacy uses a robotic system that counts pills, fills and labels the bottle, captures the images of the contents, and seals the bottle with a cap. The image dataset consists of 1 year&#x02019;s worth of robot-captured images of oral medications, such as tablets and capsules, inside prescription bottles filled by the robotic system. Each image in the dataset is associated with an NDC label and various attributes of color, shape, size, manufacturer, tablet scoring, and imprint. The number of images available for each NDC varied, ranging from 3 to 12,105, with a median of 540 (IQR 257-1291). The medications featured in these datasets were classified into 12 different colors and 7 distinct shapes. The detailed classification is shown in <xref rid="table2" ref-type="table">Table 2</xref>.</p><table-wrap position="float" id="table2"><label>Table 2</label><caption><p>Percentage of medication characteristics featured in the training dataset (N=260,119).</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="30" span="1"/><col width="470" span="1"/><col width="500" span="1"/><thead><tr valign="top"><td colspan="2" rowspan="1">Characteristics</td><td rowspan="1" colspan="1">Dataset, n (%)</td></tr></thead><tbody><tr valign="top"><td colspan="3" rowspan="1">
<bold>Colors</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">White</td><td rowspan="1" colspan="1">109,487 (42.1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Yellow</td><td rowspan="1" colspan="1">32,041 (12.3)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Pink</td><td rowspan="1" colspan="1">23,585 (9.1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Orange</td><td rowspan="1" colspan="1">18,541 (7.1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Multicolor</td><td rowspan="1" colspan="1">15,289 (5.9)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Green</td><td rowspan="1" colspan="1">13,644 (5.2)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Red</td><td rowspan="1" colspan="1">13,474 (5.2)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Blue</td><td rowspan="1" colspan="1">12,452 (4.8)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Brown</td><td rowspan="1" colspan="1">9792 (3.8)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Purple</td><td rowspan="1" colspan="1">8184 (3.1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Turquoise</td><td rowspan="1" colspan="1">1858 (0.7)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Gray</td><td rowspan="1" colspan="1">1772 (0.7)</td></tr><tr valign="top"><td colspan="3" rowspan="1">
<bold>Shapes</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Round</td><td rowspan="1" colspan="1">128,947 (49.6)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Oval</td><td rowspan="1" colspan="1">86,844 (33.4)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Capsule</td><td rowspan="1" colspan="1">42,040 (16.2)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Hexagon (6-sided)</td><td rowspan="1" colspan="1">1150 (0.4)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Triangle</td><td rowspan="1" colspan="1">738 (0.3)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Trapezoid</td><td rowspan="1" colspan="1">280 (0.1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Pentagon (5-sided)</td><td rowspan="1" colspan="1">120 (0)</td></tr></tbody></table></table-wrap></sec><sec><title>Experimental Testbed and Stimuli</title><p>In the experiment, participants performed a pill verification task with the help of an imperfect AI aid that recommends whether to accept or reject a filled medication. The participant&#x02019;s task was to verify whether the filled medication matched the reference image. If the reference image and filled medication did not match, the correct action was to click &#x0201c;reject.&#x0201d; If the reference image and filled medication matched, the correct action was to click &#x0201c;accept.&#x0201d;</p><p>The user interface was designed following pharmacists&#x02019; feedback from a focus group study conducted by the research team [<xref rid="ref50" ref-type="bibr">50</xref>]. The interface displayed an image of a filled medication, a reference image, prescription information, and AI aids. There were 2 types of AI aids powered by the same AI model: one aid augmented with an uncertainty plot indicating the degree of certainty (or uncertainty) of the AI recommendation, and the other aid without this feature. Both AI aids recommend the action the pharmacist should take, using 4 checkboxes. A recommendation to accept was indicated when all four checkboxes turned green (<xref rid="figure2" ref-type="fig">Figure 2</xref>); otherwise, the recommendation was to reject. For the AI aid with the uncertainty plot, an additional histogram was integrated (<xref rid="figure3" ref-type="fig">Figure 3</xref>). The histogram displayed the distribution of the 50 probabilities for the predicted NDC, generated by the 50 predictions. The purpose of the histogram was to provide a visual representation of the certainty or uncertainty level associated with the AI&#x02019;s NDC prediction.</p><p>With the help of an AI aid, participants performed a block of 100 pill verification trials. The experimental stimuli for the 100 trials, including the reference NDC and the filled medication, were carefully selected from the dataset of 432,974 images. The selection process ensured a broad representation of colors and shapes (<xref rid="table3" ref-type="table">Table 3</xref>), while blurry images were excluded to maintain clarity. To minimize learning effects, each reference NDC was intentionally shown no more than twice throughout the experiment.</p><fig position="float" id="figure2"><label>Figure 2</label><caption><p>Interface for the AI aid without the uncertainty plot. Checkboxes indicate AI&#x02019;s recommendation. When all 4 checkboxes are green, the AI advises to accept; otherwise, it advises to reject. AI: artificial intelligence; NDC: National Drug Code.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig2" position="float"/></fig><fig position="float" id="figure3"><label>Figure 3</label><caption><p>Interface for the AI aid with the uncertainty plot. In addition to Figure 2, the histogram shows the distribution of the 50 predicted probabilities associated with the predicted NDC. AI: artificial intelligence; NDC: National Drug Code.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig3" position="float"/></fig><table-wrap position="float" id="table3"><label>Table 3</label><caption><p>Percentage of medication characteristics featured in artificial intelligence&#x02013;aided trials (N=100) for reference images and filled images.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="30" span="1"/><col width="470" span="1"/><col width="250" span="1"/><col width="250" span="1"/><thead><tr valign="top"><td colspan="2" rowspan="1">Characteristics</td><td rowspan="1" colspan="1">Reference, n (%)</td><td rowspan="1" colspan="1">Filled, n (%)</td></tr></thead><tbody><tr valign="top"><td colspan="4" rowspan="1">
<bold>Color</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">White</td><td rowspan="1" colspan="1">35 (35)</td><td rowspan="1" colspan="1">37 (37)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Yellow</td><td rowspan="1" colspan="1">12 (12)</td><td rowspan="1" colspan="1">12 (12)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Pink</td><td rowspan="1" colspan="1">8 (8)</td><td rowspan="1" colspan="1">8 (8)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Orange</td><td rowspan="1" colspan="1">8 (8)</td><td rowspan="1" colspan="1">8 (8)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Multicolor</td><td rowspan="1" colspan="1">3 (3)</td><td rowspan="1" colspan="1">3 (3)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Green</td><td rowspan="1" colspan="1">6 (6)</td><td rowspan="1" colspan="1">6 (6)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Red</td><td rowspan="1" colspan="1">3 (3)</td><td rowspan="1" colspan="1">2 (2)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Blue</td><td rowspan="1" colspan="1">10 (10)</td><td rowspan="1" colspan="1">10 (10)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Brown</td><td rowspan="1" colspan="1">10 (10)</td><td rowspan="1" colspan="1">10 (10)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Purple</td><td rowspan="1" colspan="1">4 (4)</td><td rowspan="1" colspan="1">3 (3)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Turquoise</td><td rowspan="1" colspan="1">1 (1)</td><td rowspan="1" colspan="1">1 (1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Gray</td><td rowspan="1" colspan="1">1 (1)</td><td rowspan="1" colspan="1">0 (0)</td></tr><tr valign="top"><td colspan="4" rowspan="1">
<bold>Shape</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Round</td><td rowspan="1" colspan="1">54 (54)</td><td rowspan="1" colspan="1">51 (51)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Oval</td><td rowspan="1" colspan="1">24 (24)</td><td rowspan="1" colspan="1">28 (28)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Capsule</td><td rowspan="1" colspan="1">19 (19)</td><td rowspan="1" colspan="1">19 (19)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Hexagon (6-sided)</td><td rowspan="1" colspan="1">2 (2)</td><td rowspan="1" colspan="1">1 (1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Triangle</td><td rowspan="1" colspan="1">0 (0)</td><td rowspan="1" colspan="1">0 (0)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Trapezoid</td><td rowspan="1" colspan="1">1 (1)</td><td rowspan="1" colspan="1">1 (1)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Pentagon (5-sided)</td><td rowspan="1" colspan="1">0 (0)</td><td rowspan="1" colspan="1">0 (0)</td></tr></tbody></table></table-wrap><p>Furthermore, the AI aid was not perfect for the 100 trials, that is, it occasionally offered incorrect recommendations. Based on SDT, we mapped out the relationship between the AI&#x02019;s recommendation and the true state of the world [<xref rid="ref53" ref-type="bibr">53</xref>]. In the context of this experiment, a signal in the world was an incorrectly filled medication. The extent to which the AI recommended rejecting an incorrectly filled medication reflects its ability to detect the signal. The combination of the state of the world and the AI&#x02019;s recommendation resulted in four potential outcomes: (1) the AI rejects the incorrect drug (hit), (2) the AI approves the incorrect drug (miss), (3) the AI rejects the correct drug (FAs), and (4) the AI approves the correct drug (CRs), as shown in <xref rid="figure4" ref-type="fig">Figure 4</xref>.</p><fig position="float" id="figure4"><label>Figure 4</label><caption><p>Four potential AI performance patterns according to signal detection theory. AI: artificial intelligence.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig4" position="float"/></fig><p>Benchmarking prior literature [<xref rid="ref54" ref-type="bibr">54</xref>], the base rate was set to be 24%, that is, 24% of the trials contained wrongly filled medication. The AI accuracy was set as 82% to ensure that the AI would be perceived as useful while providing sufficient misses and false alarms [<xref rid="ref55" ref-type="bibr">55</xref>]. By combining the filled image accuracy and AI accuracy, there were 60 cases of the AI approving the correct drug, 22 cases of the AI rejecting the incorrect drug, 2 cases of the AI approving the incorrect drug, and 16 cases of the AI rejecting the correct drug.</p><p>After each trial, participants received performance feedback indicating the correctness of their decision to accept or reject, as well as whether the prescription bottle was correctly or incorrectly filled (ie, &#x0201c;Your decision was correct. The medication was correctly filled&#x0201d;). Following this step, participants reported their trust in the recognition AI on a visual analog scale, with the leftmost point labeled &#x0201c;Not at all trust&#x0201d; and the rightmost point labeled &#x0201c;Completely trust&#x0201d; (<xref rid="figure5" ref-type="fig">Figure 5</xref>) [<xref rid="ref44" ref-type="bibr">44</xref>,<xref rid="ref56" ref-type="bibr">56</xref>,<xref rid="ref57" ref-type="bibr">57</xref>].</p><fig position="float" id="figure5"><label>Figure 5</label><caption><p>Participants reported their trust in the recognition AI on a visual analog scale. AI: artificial intelligence.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig5" position="float"/></fig></sec><sec><title>Experimental Design</title><p>The experiment used a mixed subjects design. The between-subjects factor was the type of AI aid, distinguished by the presence or absence of an uncertainty plot. The within-subjects factor was the four potential outcomes: (1) the AI rejects the incorrect drug, (2) the AI rejects the correct drug, (3) the AI approves the incorrect drug, and (4) the AI approves the correct drug (<xref rid="figure4" ref-type="fig">Figure 4</xref>).</p><p>Half of the participants used the AI aid without the uncertainty plot, and the other half used the AI aid with the uncertainty plot. Each participant completed 2 blocks of 100 trials each. One block involved using the AI aid (either with or without the uncertainty plot), and the other block required participants to perform the task manually. The order of the 2 blocks was counterbalanced. Additionally, benchmarking prior literature [<xref rid="ref45" ref-type="bibr">45</xref>], the trial sequence was fixed for the 100 trials in each block.</p><p>As this study is focused on the pharmacists&#x02019; trust in AI, data from the manual task block were excluded from the analysis, concentrating the study&#x02019;s findings on interactions involving the AI aid.</p></sec><sec><title>Measures</title><sec><title>Trust propensity</title><p>Before the experiment, we measured participants&#x02019; trust propensity using the 6-item survey used by Merritt et al [<xref rid="ref58" ref-type="bibr">58</xref>]. Trust propensity is &#x0201c;a stable, trait-like tendency to trust or not trust others&#x0201d; [<xref rid="ref59" ref-type="bibr">59</xref>], and the propensity to trust machines reflects a person&#x02019;s tendency to trust machines in general rather than in a particular machine.</p></sec><sec><title>End Trust</title><p>End trust, <italic>Trust</italic>(<italic>100</italic>), is the participant&#x02019;s final trust rating after interacting with the AI help scenario.</p></sec><sec><title>Average Trust</title><p>Average trust denotes the mean of moment-to-moment trust ratings collected throughout the experiment.</p><disp-formula>
<graphic xlink:href="humanfactors_v12i1e60273_fig12.jpg" position="float"/>
</disp-formula></sec><sec><title>Trust Change</title><p>After each trial <italic>i</italic>, participants reported their <italic>Trust</italic>(<italic>i</italic>) in the AI. We calculated a trust change as follows.</p><disp-formula>Trust change (<italic>i</italic>) = Trust(<italic>i</italic>) &#x02013; Trust(<italic>i</italic> &#x02013; 1), where <italic>i</italic>=2, 3, ..., 100.</disp-formula><p>Since the moment-to-moment trust was reported after each trial, 99 trust changes were obtained from each participant.</p></sec></sec><sec><title>Experimental Procedure</title><p>The experiment was conducted remotely with interested participants who met the inclusion criteria. Each interested individual was phone screened to determine their eligibility. Before each experiment, participants had a brief web-based meeting with a member of the study team to ensure that the physical environment, including lighting conditions, was suitable for the experiment. Subsequently, the pharmacists were directed to Labvanced&#x02019;s website on their computer and presented with a 15-minute video tutorial that explained how to perform a simulated medication verification task using the testbed interface. Pharmacists were informed that the objective of the task was to determine whether an image of a filled medication bottle matched a known reference image. The tutorial also explained the 2 AI aids.</p><p>Before engaging in the verification task, participants were directed to complete a demographics survey and a trust propensity survey [<xref rid="ref58" ref-type="bibr">58</xref>]. Additionally, they went through a set of calibration procedures for the eye-tracking software. Participants then completed a block of 100 verification trials using an AI aid&#x02014;either with or without the uncertainty plot&#x02014;and another block of 100 verification trials manually, conducted in a counterbalanced order. Upon completion of the 200 trials, participants filled out a postexperimental survey and answered nonmandatory free-response feedback questions. All participants finished each block within the time limit of 60 minutes.</p><p>After completing all the tasks and surveys described earlier, participants were invited to a 30-minute debriefing session with one of the study team members. Study team members described 6 concepts of automation evaluation: observability, predictability, directing attention, exploring solution space, adaptability, and calibrated trust [<xref rid="ref60" ref-type="bibr">60</xref>], and provided an example scenario for each concept. After each description and example, the participants were asked to provide their thoughts on how the concept relates to our system.</p></sec><sec><title>Statistical Analysis</title><p>Participants&#x02019; trust propensity, end trust, and trust change when using both types of AI aids were analyzed. First, we conducted a descriptive analysis of the participants&#x02019; trust propensity. Then, to test our directional hypothesis that AI aids with uncertainty will result in higher end and average trust, we conducted a 1-tailed <italic>t</italic> test. Finally, we analyzed how trust increased and decreased after participants experienced each of the 4 AI performance patterns using mixed-linear models with random intercept. Regression 2-tailed <italic>t</italic> tests were conducted to compare the means between the 2 AI aids for each AI performance pattern. The Kenward-Roger method was used to estimate degrees of freedom. Mixed model (generalized linear models) tests were conducted using the R (version 4.2.2; R Foundation for Statistical Computing) <italic>lme4</italic> package [<xref rid="ref61" ref-type="bibr">61</xref>]. All statistical significance was determined at the &#x00251;=.05 level and analyses were carried out using R statistical software [<xref rid="ref62" ref-type="bibr">62</xref>].</p></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Trust Propensity</title><p>Participants had an average trust propensity score of 72 (SD 18.08) out of 100, indicating the participants generally had a positive attitude toward trusting automated technologies. There was no significant difference between the 2 AI aids (t<sub>28</sub>=&#x02013;0.854; <italic>P</italic>=.20; Cohen <italic>d=</italic>.312).</p></sec><sec><title>End Trust Toward AI Aid</title><p>The 1-tailed <italic>t</italic> test indicated that participants trusted the AI aid with the uncertainty plot significantly more than the AI aid without the plot at the end of the experiment (t<sub>28</sub>=&#x02013;1.854; <italic>P</italic>=.04; Cohen <italic>d</italic>=&#x02013;.677; <xref rid="figure6" ref-type="fig">Figure 6</xref>).</p><fig position="float" id="figure6"><label>Figure 6</label><caption><p>Mean end trust by AI aid help type (with or without the uncertainty plot). The error bars represent a 95% CI. AI: artificial intelligence.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig6" position="float"/></fig></sec><sec><title>Average Trust Toward AI Aid</title><p>Participants showed a slightly higher average trust in the AI aid in the with-uncertainty condition (mean 76.92, SD 13.42) than in the without-uncertainty condition (mean 70.29, SD 20.88; <xref rid="figure7" ref-type="fig">Figure 7</xref>). However, the difference did not reach statistical significance (t<sub>28</sub>=&#x02013;1.036; <italic>P</italic>=.16; Cohen <italic>d</italic>=&#x02013;.378).</p><fig position="float" id="figure7"><label>Figure 7</label><caption><p>Mean average trust by AI aid help type (with or without the uncertainty plot). The error bars represent a 95% CI. AI: artificial intelligence.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig7" position="float"/></fig></sec><sec><title>Trust Change</title><p><xref rid="figure8" ref-type="fig">Figure 8</xref> shows the trust change after participants experienced the 4 AI performance patterns. When the AI approved the correct drug, there was a significantly greater trust increment when participants used the AI aid with the uncertainty plot compared to the one without (t<sub>78.98</sub>=3.93; <italic>P</italic>&#x0003c;.001; Cohen <italic>d</italic>=.214); When the AI approved the incorrect drug, there was a significantly greater trust decrement using the AI aid with the uncertainty plot (t<sub>2939.72</sub>=&#x02013;4.78; <italic>P</italic>&#x0003c;.001; Cohen <italic>d</italic>=.712). Interestingly, when the AI rejected the incorrect drug, we observed a decrement of trust for participants using the AI aid with the uncertainty plot (t<sub>509.77</sub>=&#x02013;3.96; <italic>P</italic>&#x0003c;.001; Cohen <italic>d</italic>=.312). When the AI rejected the correct drug, both AI help types showed a decrease in trust and there was no statistical difference between them (t<sub>856.57</sub>=&#x02013;0.68; <italic>P</italic>=.49; Cohen <italic>d</italic>=.045). Overall, participants using the AI aid with the uncertainty plot displayed a large magnitude of trust adjustment. In addition, we observed a significant &#x0201c;negativity bias&#x0201d; in that the magnitude of trust change when the AI made an error (ie, the AI approves the incorrect drug or the AI rejects the correct drug) was significantly larger than the magnitude of trust adjustment when the AI provided correct recommendations (generalized linear model test; <italic>z</italic>=&#x02013;11.30; <italic>P</italic>&#x0003c;.001).</p><p>To examine variation in pharmacists&#x02019; trust behavior across different AI performance patterns categorized by SDT, we initially combined the data from both the with and without uncertainty help scenarios. Trust decreased significantly more when the AI approved the incorrect drug compared to when the AI rejected the correct drug (t<sub>509</sub>=&#x02013;4.687; <italic>P</italic>&#x0003c;.001; Cohen <italic>d</italic>=.475). This trend was observed in the with-uncertainty AI help scenario (t<sub>254</sub>=&#x02013;4.91; <italic>P</italic>&#x0003c;.001; Cohen <italic>d</italic>=.758). However, in the without-uncertainty AI help scenario, although there was a greater trust decrease in trust when the AI approved the incorrect drug than when the AI rejected the correct drug, the difference was not statistically significant (t<sub>254</sub>=&#x02013;1.14<italic>; P</italic>=.255; Cohen <italic>d</italic>=.014).</p><p>As we measured participants&#x02019; trust toward AI continuously, we calculated the autocorrelation between the trust ratings. Autocorrelation measures the relationship between a variable&#x02019;s current value and its past values in a time series. <xref rid="figure9" ref-type="fig">Figure 9</xref> shows the mean autocorrelation as a function of time separation between the ratings. For both AI aids, the correlation decreased as the time separation increased. The AI aid with the uncertainty plot had a lower mean autocorrelation compared to the aid without the uncertainty plot (<xref rid="figure9" ref-type="fig">Figure 9</xref>).</p><fig position="float" id="figure8"><label>Figure 8</label><caption><p>Trust change for different AI performance patterns. Red shades represent negative trust change, and blue shades represent positive trust change.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig8" position="float"/></fig><fig position="float" id="figure9"><label>Figure 9</label><caption><p>Autocorrelation of trust as a function of time separation. The blue solid line represents AI aid with the uncertainty plot, and the red dashed line represents the AI aid without the uncertainty plot. The error bars represent 2 SEs. AI: artificial intelligence.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig9" position="float"/></fig></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Principal Findings</title><p>This study aimed to investigate pharmacists&#x02019; trust in automated pill verification technology and how the presentation of AI uncertainty information would influence them. Overall, the findings revealed that pharmacists have a favorable disposition toward trusting automation, and including the AI&#x02019;s uncertainty information increases pharmacists&#x02019; trust in the AI recommendation <italic>(</italic><xref rid="figure6" ref-type="fig">Figure 6</xref><italic>)</italic>.</p></sec><sec><title>Comparison With Prior Work</title><p>The propensity to trust automation refers to an individual&#x02019;s general inclination to trust automated or autonomous systems, shaped by their past experiences and future expectations [<xref rid="ref58" ref-type="bibr">58</xref>,<xref rid="ref59" ref-type="bibr">59</xref>]. Research has shown that levels of trust propensity vary among individuals. For example, an early study by Merritt et al [<xref rid="ref58" ref-type="bibr">58</xref>], which included 69 college students (average age of 25 years), found an average trust propensity of 3.56 (SD 0.6) on a 7-point Likert scale [<xref rid="ref59" ref-type="bibr">59</xref>]. More recently, Montag et al [<xref rid="ref63" ref-type="bibr">63</xref>] surveyed 289 participants aged between 18 and 70 years and reported their propensity to trust automation to be 4.98 (SD 1.06) after converting to a 7-point Likert scale. Similarly, Miller et al [<xref rid="ref64" ref-type="bibr">64</xref>] reported a trust propensity score of 4.97 (SD 1.21) from a smaller cohort of 28 participants aged between 18 to 60 years. Another investigation by Yang et al [<xref rid="ref65" ref-type="bibr">65</xref>] with 75 adults (mean age 23.0) split into 3 groups reported trust propensity scores of 72.6 (SD 14.8), 69.4 (SD 10.4), and 69.4 (SD 14.4), equivalent to average scores of 5.08 (SD 1.89), 4.86 (SD 1.62) and 4.86 (SD 1.86) on a 7-point Likert scale.</p><p>In line with these findings [<xref rid="ref63" ref-type="bibr">63</xref>-<xref rid="ref66" ref-type="bibr">66</xref>], our study revealed that pharmacists generally have a favorable disposition toward trusting automation, with an average rating of 72 (SD 18.08) on a 100-point scale, or 5.03 (SD 2.09) on a 7-point Likert scale. This positive attitude may be attributed to the frequent use of automated technologies, such as barcode scanners and pill counters in their daily work [<xref rid="ref6" ref-type="bibr">6</xref>,<xref rid="ref7" ref-type="bibr">7</xref>]. Additionally, as expected, no significant difference was observed between the groups using different AI aids because the participants were randomly assigned to use either of the AI aids.</p><p>Examining pharmacists&#x02019; end trust, our findings reveal that the AI aid with the uncertainty plot significantly enhanced the end trust scores. We attribute this enhancement to the increased transparency achieved through the presentation of a histogram showing the distribution of 50 predicted probabilities. While AI advancements promise to improve human performance, a prevailing issue is the perception of AI as a &#x0201c;black box.&#x0201d; This lack of transparency contributes to a lack of trust in AI and can undermine team performance [<xref rid="ref66" ref-type="bibr">66</xref>-<xref rid="ref68" ref-type="bibr">68</xref>]. The higher end trust observed in participants using the AI aid with the uncertainty plot indicates that making the AI more transparent by revealing its decision-making process can foster a higher level of trust in automation. Participants 14 and 24 captured this sentiment well stating: &#x0201c;As soon as the uncertainty plot became red and yellow, I slowed down, which could be helpful because sometimes slowing down when there is uncertainty, just knowing there&#x02019;s uncertainty, is enough&#x0201d; (P14) and &#x0201c;if the uncertainty plot was all green bar and AI thought it was doing a 100% accurate job then it was easier to make my decision&#x0201d; (P24).</p><p>Regarding the dynamics of trust, that is, moment-to-moment trust change, when AI approved the correctly filled bottle, we noted trust increments for both AI aids. Furthermore, the inclusion of uncertainty information led to a larger increment in trust compared to when such information was absent. When the AI mistakenly approved the incorrect drug, we observed a significant trust decrement for both AI aids, potentially attributed to the adverse outcome associated with the wrong medication. Furthermore, the trust decrement was significantly larger when the uncertainty information was shown. This pronounced trust decrement could have resulted directly from the distribution of the histogram: participants were shown a histogram indicating a high level of certainty (<xref rid="figure10" ref-type="fig">Figure 10</xref>A). Therefore, participants may have perceived the error made by the AI aid as a &#x0201c;confident&#x0201d; error and therefore reduced their trust even more. Studies examining likelihood alarms reported that&#x000a0;highly likely alarms (ie, &#x0201c;confident&#x0201d; alarms) engender a greater decline in momentary trust upon automation failures [<xref rid="ref57" ref-type="bibr">57</xref>,<xref rid="ref69" ref-type="bibr">69</xref>].</p><fig position="float" id="figure10"><label>Figure 10</label><caption><p>Uncertainty plots with (A) narrower and (B) wider IQRs. IQR is a measure of statistical dispersion, or how spread out the data points are.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig10" position="float"/></fig><p>Our study also offers additional validation of prior findings regarding the SDT modeling of trust [<xref rid="ref47" ref-type="bibr">47</xref>,<xref rid="ref48" ref-type="bibr">48</xref>]. When the AI mistakenly approved the incorrect drug (miss), a greater trust decrease appeared compared to when the AI rejected the correctly filled bottle (FA). However, the difference was statistically significant only in the with-uncertainty AI help type. This finding may provide further evidence that &#x0201c;confident&#x0201d; AI errors lead to a greater trust decrement [<xref rid="ref57" ref-type="bibr">57</xref>,<xref rid="ref69" ref-type="bibr">69</xref>].</p><p>Intriguingly, when the AI rejected an incorrectly filled bottle, the absence of uncertainty information resulted in an increase in trust, whereas the presence of such information led to a decrease in trust. Such contrasting results could have stemmed from the uncertainty plots influencing the participants&#x02019; decision-making process. When the AI approved the correct drug, all uncertainty plots presented to participants showed a consistent solid green bar (<xref rid="figure10" ref-type="fig">Figure 10</xref>A). However, when the AI rejected the incorrect drug, the IQR of the uncertainty plot was broader, indicating the lack of certainty (<xref rid="figure11" ref-type="fig">Figure 11</xref>). A total of 16 (73%) out of 22 uncertainty plots displayed a wider spread with mixed color bars (<xref rid="figure10" ref-type="fig">Figure 10</xref>B). This ambiguity might unintentionally cause the human participants to doubt the capability of the AI aid with the uncertainty plot, resulting in a decrease in their trust, as evidenced by P18&#x02019;s statement: &#x0201c;When the checkboxes were not all green and the histogram had a bunch of colors (variability), I was even less trusting of the AI tool.&#x0201d; This perspective is also supported by P25, who noted: &#x0201c;When the uncertainty plot had some red, it made me double check and decreased my confidence for sure.&#x0201d;</p><fig position="float" id="figure11"><label>Figure 11</label><caption><p>Mean IQR by outcome pattern. The error bars represent a 95% CI. AI: artificial intelligence.</p></caption><graphic xlink:href="humanfactors_v12i1e60273_fig11" position="float"/></fig><p>Finally, when AI rejected the correctly filled bottle, trust decrements occurred, with no significant differences between the 2 AI aids. If this circumstance happened in the real world, the pharmacists would reinspect the filled prescription. It will likely lead to an increased workload, fatigue, and stress, which could potentially lead to a lower quality of work and a higher frequency of errors [<xref rid="ref70" ref-type="bibr">70</xref>,<xref rid="ref71" ref-type="bibr">71</xref>]. However, P21 offered a contrasting viewpoint that more flagging would be better than AI approving the incorrect, highlighting: &#x0201c;I didn&#x02019;t lose as much trust when AI rejected the correct drug. I feel like AI should be there as a cautionary tool.&#x0201d;</p><p>The observed trends in the moment-to-moment dynamics of trust indicate a greater degree of trust adjustment when participants were assisted by the AI with the uncertainty plot. This observation is further confirmed by the autocorrelation analysis. Specifically, the trust autocorrelation plot (<xref rid="figure9" ref-type="fig">Figure 9</xref>) reveals a lower autocorrelation between trust ratings when the uncertainty information was presented. This suggests that current trust levels were less influenced by past trust levels, implying more significant changes in trust from moment to moment. Pharmacists relied less on previous trials and more on the information presented in the present trial, highlighting the advantages of a more transparent display.</p><p>In addition, for both AI aids, participants displayed a larger trust decrement due to incorrect automation predictions. Even though these observations may seem alarming initially, they align with the prior literature addressing negativity bias. The study suggests that failure in automation typically has a more significant negative impact on trust than a positive impact from successful automation [<xref rid="ref56" ref-type="bibr">56</xref>,<xref rid="ref65" ref-type="bibr">65</xref>].</p></sec><sec><title>Limitations and Future Directions</title><p>We acknowledge several limitations of this study and propose directions for future research. First, as a pioneering investigation in this domain, we did not strictly control the interquartile range of the uncertainty plot (<xref rid="figure11" ref-type="fig">Figure 11</xref>). Future investigation should systematically examine the effects of presenting different distributions within the uncertainty plot on pharmacists&#x02019; trust. Exploring similar variations in the IQR among different outcome patterns could provide a deeper understanding of how outcome patterns could impact trust while avoiding potential confounding factors.</p><p>Second, the uncertainty plot used in this study displayed the distribution of only 1 (2%) out of 50 probabilities for the predicted NDC. Future research should consider incorporating additional contextual information to enhance the interpretability of these distributions. A notable challenge identified was that users unfamiliar with statistical representation found the uncertainty plot difficult to understand. P11 suggested simplifying the uncertainty presentation because &#x0201c;it would be a little bit too much for some people not as comfortable with statistics or technology.&#x0201d; Nonetheless, there is potential for pharmacists to become more comfortable with these plots with prolonged use and training, as evidenced by P30&#x02019;s remark: &#x0201c;I started skeptical because it&#x02019;s something I&#x02019;m not familiar with, but as I got more examples of it, my trust built up quickly.&#x0201d; Consequently, researchers should continue to develop alternative visualization techniques that provide a more comprehensive and intuitive representation of the AI&#x02019;s uncertainty, while maintaining a low complexity to accommodate users with varying degrees of statistical proficiency.</p><p>Third, this exploratory study was limited by a small sample size, which may have impacted the statistical power of the analyses on trust propensity, end trust, and average trust. This limitation likely contributed to the lack of significance observed in some results. However, despite being underpowered, our analysis still revealed a significant difference in end trust, indicating a large effect size. Regarding trust change, to maintain the AI&#x02019;s perceived usefulness while still providing enough examples of both misses and FAs, we incorporated only 2 trials of the AI approving the incorrect drug (miss) and 16 trials of the AI rejecting the correct drug (FA), setting the accuracy at 82%. The statistical power to detect significant differences may have been compromised by the small sample sizes. Future research should aim to include larger participant pools to enhance the generalizability and robustness of the findings.</p><p>Finally, this study only focused on pharmacists&#x02019; trust and trust change and did not include the analysis of accuracy and reaction time. Even though focusing on trust alone is an accepted practice [<xref rid="ref53" ref-type="bibr">53</xref>], a more comprehensive analysis linking performance with trust would likely reveal the relationship between performance and trust calibration.</p></sec><sec><title>Conclusions</title><p>Dispensing errors are significant contributors to adverse drug events, which lead to considerable health care expenses and harm to patients. Despite progress made in developing automated technologies to aid pill verification, pharmacists&#x02019; trust in these systems has not been thoroughly investigated. Our research represents an initial exploration into pharmacists&#x02019; trust in automated pill verification technology, marking a significant step in understanding the integration of such systems into health care settings.</p><p>Our findings reveal that pharmacists have a favorable disposition toward trusting automation, which can likely be attributed to their frequent use of automated technologies in their daily work. Moreover, providing uncertainty information about the AI&#x02019;s recommendation significantly boosts pharmacists&#x02019; trust in the AI aid, highlighting the importance of transparency in AI development. The dynamics of trust vary depending on the AI&#x02019;s performance. Pharmacists using the AI aid with the uncertainty plot had a significantly larger trust increment when the AI approved the correct drug and a significantly larger trust decrement when the AI approved the incorrect drug<italic>.</italic> Intriguingly, the absence of the uncertainty plot led to an increase in trust when the AI correctly rejected an incorrect drug, whereas the presence of the plot resulted in a decrease in trust under the same circumstances. In addition, a pronounced &#x0201c;negativity bias&#x0201d; was observed, where the degree of trust reduction when the AI made an error exceeded the trust gain when the AI made a correct decision.</p></sec></sec></body><back><ack><p>This research study was supported by the National Library of Medicine of the National Institutes of Health (R01LM013624). The contents are solely the responsibility of the authors and do not necessarily represent the official views of the National Institutes of Health.</p></ack><fn-group><fn fn-type="con"><p>Authors' Contributions: The authors confirm their contribution to the article as follows: study conception and design: JYK conducted subject testing, conducted statistical analysis, interpreted the results, and wrote the manuscript, VDM conducted statistical analysis and interpreted the results, BR conducted subject testing, QC interpreted the results, provided data for <xref rid="table1" ref-type="table">Tables 1</xref>, <xref rid="table2" ref-type="table">2</xref>, and <xref rid="table3" ref-type="table">3</xref>, YZ conducted subject testing, JDL interpreted the results and provided suggestion for <xref rid="figure9" ref-type="fig">Figure 9</xref>, RAK interpreted the results, CL interpreted the results, and XJY conducted statistical analysis, interpreted the results, and wrote the manuscript; All authors designed and conceptualized the study, reviewed the results, and approved the final version of the manuscript.</p></fn><fn fn-type="COI-statement"><p>Conflicts of Interest: None declared.</p></fn></fn-group><glossary><title>Abbreviations</title><def-list><def-item><term id="abb1">AI</term><def><p>artificial intelligence</p></def></def-item><def-item><term id="abb2">CR</term><def><p>correct rejection</p></def></def-item><def-item><term id="abb3">FA</term><def><p>false alarm</p></def></def-item><def-item><term id="abb4">NDC</term><def><p>National Drug Code</p></def></def-item><def-item><term id="abb5">SDT</term><def><p>signal detection theory</p></def></def-item></def-list></glossary><notes><sec sec-type="data-availability"><title>Data Availability</title><p>The deidentified data produced in this study are available upon reasonable request through a data use agreement with the University of Michigan.</p></sec></notes><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reiner</surname><given-names>G</given-names></name><name><surname>Pierce</surname><given-names>SL</given-names></name><name><surname>Flynn</surname><given-names>J</given-names></name></person-group><article-title>Wrong drug and wrong dose dispensing errors identified in&#x000a0;pharmacist professional liability claims</article-title><source>J Am Pharm Assoc</source><year>2020</year><volume>60</volume><issue>5</issue><fpage>e50</fpage><lpage>e56</lpage><pub-id pub-id-type="doi">10.1016/j.japh.2020.02.027</pub-id><pub-id pub-id-type="medline">32217085</pub-id><pub-id pub-id-type="pii">S1544-3191(20)30107-2</pub-id></element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chui</surname><given-names>MA</given-names></name><name><surname>Look</surname><given-names>KA</given-names></name><name><surname>Mott</surname><given-names>DA</given-names></name></person-group><article-title>The association of subjective workload dimensions on quality of care and pharmacist quality of work life</article-title><source>Res Social Adm Pharm</source><year>2014</year><volume>10</volume><issue>2</issue><fpage>328</fpage><lpage>340</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/23791360" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.sapharm.2013.05.007</pub-id><pub-id pub-id-type="medline">23791360</pub-id><pub-id pub-id-type="pii">S1551-7411(13)00094-6</pub-id><!--<pub-id pub-id-type="pmcid">PMC3805762</pub-id>--><pub-id pub-id-type="pmid">23791360</pub-id>
</element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chui</surname><given-names>MA</given-names></name><name><surname>Mott</surname><given-names>DA</given-names></name></person-group><article-title>Community pharmacists' subjective workload and perceived task performance: a human factors approach</article-title><source>J Am Pharm Assoc</source><year>2012</year><volume>52</volume><issue>6</issue><fpage>e153</fpage><lpage>e160</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/23229977" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1331/JAPhA.2012.11135</pub-id><pub-id pub-id-type="medline">23229977</pub-id><pub-id pub-id-type="pii">S1544-3191(15)30579-3</pub-id><!--<pub-id pub-id-type="pmcid">PMC3624990</pub-id>--></element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balchaites</surname><given-names>A</given-names></name><name><surname>McCarthy</surname><given-names>S</given-names></name><name><surname>Fleming</surname><given-names>A</given-names></name></person-group><article-title>Exploring the human factors of medication errors in community pharmacy: a mixed methods study</article-title><source>Int J Pharm Pract</source><year>2022</year><fpage>i39</fpage><lpage>i40</lpage><pub-id pub-id-type="doi">10.1093/ijpp/riac019.055</pub-id></element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larios Delgado</surname><given-names>N</given-names></name><name><surname>Usuyama</surname><given-names>N</given-names></name><name><surname>Hall</surname><given-names>AK</given-names></name><name><surname>Hazen</surname><given-names>RJ</given-names></name><name><surname>Ma</surname><given-names>M</given-names></name><name><surname>Sahu</surname><given-names>S</given-names></name><name><surname>Lundin</surname><given-names>J</given-names></name></person-group><article-title>Fast and accurate medication identification</article-title><source>NPJ Digit Med</source><year>2019</year><volume>2</volume><issue>1</issue><fpage>10</fpage><comment>
<ext-link xlink:href="https://doi.org/10.1038/s41746-019-0086-0" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1038/s41746-019-0086-0</pub-id><pub-id pub-id-type="medline">31304359</pub-id><pub-id pub-id-type="pii">86</pub-id><!--<pub-id pub-id-type="pmcid">PMC6550183</pub-id>--><pub-id pub-id-type="pmid">31304359</pub-id>
</element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name></person-group><article-title>Using information technology to reduce rates of medication errors in hospitals</article-title><source>BMJ</source><year>2000</year><volume>320</volume><issue>7237</issue><fpage>788</fpage><lpage>791</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/10720369" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1136/bmj.320.7237.788</pub-id><pub-id pub-id-type="medline">10720369</pub-id><!--<pub-id pub-id-type="pmcid">PMC1117776</pub-id>--><pub-id pub-id-type="pmid">10720369</pub-id>
</element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poon</surname><given-names>EG</given-names></name><name><surname>Cina</surname><given-names>JL</given-names></name><name><surname>Churchill</surname><given-names>W</given-names></name><name><surname>Patel</surname><given-names>N</given-names></name><name><surname>Featherstone</surname><given-names>E</given-names></name><name><surname>Rothschild</surname><given-names>JM</given-names></name><name><surname>Keohane</surname><given-names>CA</given-names></name><name><surname>Whittemore</surname><given-names>AD</given-names></name><name><surname>Bates</surname><given-names>DW</given-names></name><name><surname>Gandhi</surname><given-names>TK</given-names></name></person-group><article-title>Medication dispensing errors and potential adverse drug events before and after implementing bar code technology in the pharmacy</article-title><source>Ann Intern Med</source><year>2006</year><volume>145</volume><issue>6</issue><fpage>426</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.7326/0003-4819-145-6-200609190-00006</pub-id><pub-id pub-id-type="medline">16983130</pub-id><pub-id pub-id-type="pii">145/6/426</pub-id><pub-id pub-id-type="pmid">16983130</pub-id>
</element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poon</surname><given-names>EG</given-names></name><name><surname>Keohane</surname><given-names>CA</given-names></name><name><surname>Yoon</surname><given-names>CS</given-names></name><name><surname>Ditmore</surname><given-names>M</given-names></name><name><surname>Bane</surname><given-names>A</given-names></name><name><surname>Levtzion-Korach</surname><given-names>O</given-names></name><name><surname>Moniz</surname><given-names>T</given-names></name><name><surname>Rothschild</surname><given-names>JM</given-names></name><name><surname>Kachalia</surname><given-names>AB</given-names></name><name><surname>Hayes</surname><given-names>J</given-names></name><name><surname>Churchill</surname><given-names>WW</given-names></name><name><surname>Lipsitz</surname><given-names>S</given-names></name><name><surname>Whittemore</surname><given-names>AD</given-names></name><name><surname>Bates</surname><given-names>DW</given-names></name><name><surname>Gandhi</surname><given-names>TK</given-names></name></person-group><article-title>Effect of bar-code technology on the safety of medication administration</article-title><source>N Engl J Med</source><year>2010</year><volume>362</volume><issue>18</issue><fpage>1698</fpage><lpage>1707</lpage><pub-id pub-id-type="doi">10.1056/NEJMsa0907115</pub-id><pub-id pub-id-type="medline">20445181</pub-id><pub-id pub-id-type="pii">362/18/1698</pub-id><pub-id pub-id-type="pmid">20445181</pub-id>
</element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paoletti</surname><given-names>R</given-names></name><name><surname>Suess</surname><given-names>T</given-names></name><name><surname>Lesko</surname><given-names>M</given-names></name><name><surname>Feroli</surname><given-names>AA</given-names></name><name><surname>Kennel</surname><given-names>JA</given-names></name><name><surname>Mahler</surname><given-names>JM</given-names></name><name><surname>Sauders</surname><given-names>T</given-names></name></person-group><article-title>Using bar-code technology and medication observation methodology for safer medication administration</article-title><source>Am J Health Syst Pharm</source><year>2007</year><volume>64</volume><issue>5</issue><fpage>536</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.2146/ajhp060140</pub-id><pub-id pub-id-type="medline">17322168</pub-id><pub-id pub-id-type="pii">64/5/536</pub-id><pub-id pub-id-type="pmid">17322168</pub-id>
</element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>D</given-names></name></person-group><article-title>Veterans Affairs bar-code-scanning system reduces medication errors</article-title><source>Am J Health Syst Pharm</source><year>2002</year><volume>59</volume><issue>7</issue><fpage>591</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1093/ajhp/59.7.591</pub-id><pub-id pub-id-type="medline">11944599</pub-id><pub-id pub-id-type="pmid">11944599</pub-id>
</element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debono</surname><given-names>DS</given-names></name><name><surname>Greenfield</surname><given-names>D</given-names></name><name><surname>Travaglia</surname><given-names>JF</given-names></name><name><surname>Long</surname><given-names>JC</given-names></name><name><surname>Black</surname><given-names>D</given-names></name><name><surname>Johnson</surname><given-names>J</given-names></name><name><surname>Braithwaite</surname><given-names>J</given-names></name></person-group><article-title>Nurses' workarounds in acute healthcare settings: a scoping review</article-title><source>BMC Health Serv Res</source><year>2013</year><volume>13</volume><fpage>175</fpage><comment>
<ext-link xlink:href="https://bmchealthservres.biomedcentral.com/articles/10.1186/1472-6963-13-175" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1186/1472-6963-13-175</pub-id><pub-id pub-id-type="medline">23663305</pub-id><pub-id pub-id-type="pii">1472-6963-13-175</pub-id><!--<pub-id pub-id-type="pmcid">PMC3663687</pub-id>--><pub-id pub-id-type="pmid">23663305</pub-id>
</element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koppel</surname><given-names>R</given-names></name><name><surname>Wetterneck</surname><given-names>T</given-names></name><name><surname>Telles</surname><given-names>JL</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name></person-group><article-title>Workarounds to barcode medication administration systems: their occurrences, causes, and threats to patient safety</article-title><source>J Am Med Inform Assoc</source><year>2008</year><volume>15</volume><issue>4</issue><fpage>408</fpage><lpage>423</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/18436903" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1197/jamia.M2616</pub-id><pub-id pub-id-type="medline">18436903</pub-id><pub-id pub-id-type="pii">M2616</pub-id><!--<pub-id pub-id-type="pmcid">PMC2442264</pub-id>--><pub-id pub-id-type="pmid">18436903</pub-id>
</element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oldland</surname><given-names>AR</given-names></name><name><surname>Golightly</surname><given-names>LK</given-names></name><name><surname>May</surname><given-names>SK</given-names></name><name><surname>Barber</surname><given-names>GR</given-names></name><name><surname>Stolpman</surname><given-names>NM</given-names></name></person-group><article-title>Electronic inventory systems and barcode technology: impact on pharmacy technical accuracy and error liability</article-title><source>Hosp Pharm</source><year>2015</year><volume>50</volume><issue>1</issue><fpage>34</fpage><lpage>41</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/25684799" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1310/hpj5001-34</pub-id><pub-id pub-id-type="medline">25684799</pub-id><!--<pub-id pub-id-type="pmcid">PMC4321427</pub-id>--><pub-id pub-id-type="pmid">25684799</pub-id>
</element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buchanan</surname><given-names>TL</given-names></name><name><surname>Barker</surname><given-names>KN</given-names></name><name><surname>Gibson</surname><given-names>JT</given-names></name><name><surname>Jiang</surname><given-names>BC</given-names></name><name><surname>Pearson</surname><given-names>RE</given-names></name></person-group><article-title>Illumination and errors in dispensing</article-title><source>Am J Hosp Pharm</source><year>1991</year><volume>48</volume><issue>10</issue><fpage>2137</fpage><lpage>2145</lpage><pub-id pub-id-type="medline">1781468</pub-id><pub-id pub-id-type="pmid">1781468</pub-id>
</element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gidman</surname><given-names>W</given-names></name></person-group><article-title>Increasing community pharmacy workloads in England: causes and consequences</article-title><source>Int J Clin Pharm</source><year>2011</year><volume>33</volume><issue>3</issue><fpage>512</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1007/s11096-011-9498-x</pub-id><pub-id pub-id-type="medline">21424615</pub-id><pub-id pub-id-type="pmid">21424615</pub-id>
</element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lea</surname><given-names>VM</given-names></name><name><surname>Corlett</surname><given-names>SA</given-names></name><name><surname>Rodgers</surname><given-names>RM</given-names></name></person-group><article-title>Workload and its impact on community pharmacists' job satisfaction and stress: a review of the literature</article-title><source>Int J Pharm Pract</source><year>2012</year><volume>20</volume><issue>4</issue><fpage>259</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1111/j.2042-7174.2012.00192.x</pub-id><pub-id pub-id-type="medline">22775522</pub-id><pub-id pub-id-type="pmid">22775522</pub-id>
</element-citation></ref><ref id="ref17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>GM</given-names></name><name><surname>Wu</surname><given-names>MSH</given-names></name><name><surname>Bergin</surname><given-names>JK</given-names></name></person-group><article-title>Pharmacist's attitudes towards dispensing errors: their causes and prevention</article-title><source>J Clin Pharm Ther</source><year>1999</year><volume>24</volume><issue>1</issue><fpage>57</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1046/j.1365-2710.1999.00199.x</pub-id><pub-id pub-id-type="medline">10319909</pub-id><pub-id pub-id-type="pmid">10319909</pub-id>
</element-citation></ref><ref id="ref18"><label>18</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Caban</surname><given-names>JJ</given-names></name><name><surname>Rosebrock</surname><given-names>A</given-names></name><name><surname>Yoo</surname><given-names>TS</given-names></name></person-group><article-title>Automatic identification of prescription drugs using shape distribution models</article-title><year>2012</year><conf-name>19th IEEE International Conference on Image Processing</conf-name><conf-date>October 3, 2012</conf-date><conf-loc>Orlando, FL</conf-loc><fpage>1005</fpage><lpage>1008</lpage></element-citation></ref><ref id="ref19"><label>19</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>RN</given-names></name></person-group><article-title>Pharmacy pill counting vision system</article-title><source>Google Patents</source><year>2004</year><date-in-citation content-type="access-date">2025-01-10</date-in-citation><comment>
<ext-link xlink:href="https://patents.google.com/patent/US6574580B2/en" ext-link-type="uri">https://patents.google.com/patent/US6574580B2/en</ext-link>
</comment></element-citation></ref><ref id="ref20"><label>20</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Popovich</surname><given-names>J</given-names></name><name><surname>Jordan</surname><given-names>ML</given-names></name></person-group><article-title>Automated drug discrimination during dispensing</article-title><source>US Patent</source><year>2011</year><date-in-citation content-type="access-date">2025-01-13</date-in-citation><comment>
<ext-link xlink:href="https://scholar.google.com/citations?view_op=view_citation&#x00026;hl=en&#x00026;user=YAZqaxkAAAAJ&#x00026;citation_for_view=YAZqaxkAAAAJ:WF5omc3nYNoC" ext-link-type="uri">https://scholar.google.com/citations?view_op=view_citation&#x00026;hl=en&#x00026;user=YAZqaxkAAAAJ&#x00026;citation_for_view=YAZqaxkAAAAJ:WF5omc3nYNoC</ext-link>
</comment></element-citation></ref><ref id="ref21"><label>21</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Wootton</surname><given-names>JR</given-names></name><name><surname>Reznack</surname><given-names>VV</given-names></name><name><surname>Hobson</surname><given-names>G</given-names></name></person-group><article-title>Pharmaceutical pill recognition and verification system</article-title><source>Google Patents</source><year>2003</year><date-in-citation content-type="access-date">2025-01-10</date-in-citation><comment>
<ext-link xlink:href="https://patents.google.com/patent/US6535637B1/en" ext-link-type="uri">https://patents.google.com/patent/US6535637B1/en</ext-link>
</comment></element-citation></ref><ref id="ref22"><label>22</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Kamata</surname><given-names>S</given-names></name></person-group><article-title>Pill recognition using imprint information by two-step sampling distance sets</article-title><year>2014</year><conf-name>22nd International Conference on Pattern Recognition</conf-name><conf-date>August 24-28, 2014</conf-date><conf-loc>Stockholm, Sweden</conf-loc><fpage>3156</fpage><lpage>3161</lpage></element-citation></ref><ref id="ref23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Kamata</surname><given-names>S</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name></person-group><article-title>Accurate system for automatic pill recognition using imprint information</article-title><source>IET Image Processing</source><year>2015</year><volume>9</volume><issue>12</issue><fpage>1039</fpage><lpage>1047</lpage><pub-id pub-id-type="doi">10.1049/iet-ipr.2014.1007</pub-id></element-citation></ref><ref id="ref24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lester</surname><given-names>CA</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Ding</surname><given-names>Y</given-names></name><name><surname>Rowell</surname><given-names>B</given-names></name><collab>Yang</collab><name><surname>Kontar</surname><given-names>RA</given-names></name></person-group><article-title>Performance evaluation of a prescription medication image classification model: an observational cohort</article-title><source>NPJ Digit Med</source><year>2021</year><volume>4</volume><issue>1</issue><fpage>118</fpage><comment>
<ext-link xlink:href="https://doi.org/10.1038/s41746-021-00483-8" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1038/s41746-021-00483-8</pub-id><pub-id pub-id-type="medline">34315995</pub-id><pub-id pub-id-type="pii">10.1038/s41746-021-00483-8</pub-id><!--<pub-id pub-id-type="pmcid">PMC8316316</pub-id>--><pub-id pub-id-type="pmid">34315995</pub-id>
</element-citation></ref><ref id="ref25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>YF</given-names></name><name><surname>Ng</surname><given-names>HT</given-names></name><name><surname>Leung</surname><given-names>KY</given-names></name><name><surname>Chan</surname><given-names>KY</given-names></name><name><surname>Chan</surname><given-names>SY</given-names></name><name><surname>Loy</surname><given-names>CC</given-names></name></person-group><article-title>Development of fine-grained pill identification algorithm using deep convolutional network</article-title><source>J Biomed Inform</source><year>2017</year><volume>74</volume><fpage>130</fpage><lpage>136</lpage><comment>
<ext-link xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S1532-0464(17)30202-2" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.jbi.2017.09.005</pub-id><pub-id pub-id-type="medline">28923366</pub-id><pub-id pub-id-type="pii">S1532-0464(17)30202-2</pub-id><pub-id pub-id-type="pmid">28923366</pub-id>
</element-citation></ref><ref id="ref26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JD</given-names></name><name><surname>See</surname><given-names>KA</given-names></name></person-group><article-title>Trust in automation: designing for appropriate reliance</article-title><source>Hum Factors</source><year>2004</year><volume>46</volume><issue>1</issue><fpage>50</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1518/hfes.46.1.50_30392</pub-id><pub-id pub-id-type="medline">15151155</pub-id><pub-id pub-id-type="pmid">15151155</pub-id>
</element-citation></ref><ref id="ref27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoff</surname><given-names>KA</given-names></name><name><surname>Bashir</surname><given-names>M</given-names></name></person-group><article-title>Trust in automation: integrating empirical evidence on factors that influence trust</article-title><source>Hum Factors</source><year>2015</year><volume>57</volume><issue>3</issue><fpage>407</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1177/0018720814547570</pub-id><pub-id pub-id-type="medline">25875432</pub-id><pub-id pub-id-type="pii">0018720814547570</pub-id><pub-id pub-id-type="pmid">25875432</pub-id>
</element-citation></ref><ref id="ref28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>KE</given-names></name><name><surname>Chen</surname><given-names>JYC</given-names></name><name><surname>Szalma</surname><given-names>JL</given-names></name><name><surname>Hancock</surname><given-names>PA</given-names></name></person-group><article-title>A meta-analysis of factors influencing the development of trust in automation: implications for understanding autonomy in future systems</article-title><source>Hum Factors</source><year>2016</year><volume>58</volume><issue>3</issue><fpage>377</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1177/0018720816634228</pub-id><pub-id pub-id-type="medline">27005902</pub-id><pub-id pub-id-type="pii">0018720816634228</pub-id><pub-id pub-id-type="pmid">27005902</pub-id>
</element-citation></ref><ref id="ref29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azevedo-Sa</surname><given-names>H</given-names></name><name><surname>Jayaraman</surname><given-names>SK</given-names></name><name><surname>Esterwood</surname><given-names>CT</given-names></name><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Robert</surname><given-names>LP</given-names></name><name><surname>Tilbury</surname><given-names>DM</given-names></name></person-group><article-title>Real-time estimation of drivers' trust in automated driving systems</article-title><source>Int J Soc Robot</source><year>2020</year><volume>13</volume><issue>8</issue><fpage>1911</fpage><lpage>1927</lpage><pub-id pub-id-type="doi">10.1007/s12369-020-00694-1</pub-id></element-citation></ref><ref id="ref30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JD</given-names></name><name><surname>Kolodge</surname><given-names>K</given-names></name></person-group><article-title>Exploring trust in self-driving vehicles through text analysis</article-title><source>Hum Factors</source><year>2020</year><volume>62</volume><issue>2</issue><fpage>260</fpage><lpage>277</lpage><pub-id pub-id-type="doi">10.1177/0018720819872672</pub-id><pub-id pub-id-type="medline">31502885</pub-id><pub-id pub-id-type="pmid">31502885</pub-id>
</element-citation></ref><ref id="ref31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayoub</surname><given-names>J</given-names></name><name><surname>Avetisian</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Zhou</surname><given-names>F</given-names></name></person-group><article-title>Real-time trust prediction in conditionally automated driving using physiological measures</article-title><source>IEEE Trans Intell Transport Syst</source><year>2023</year><volume>24</volume><issue>12</issue><fpage>14642</fpage><lpage>14650</lpage><pub-id pub-id-type="doi">10.1109/tits.2023.3295783</pub-id></element-citation></ref><ref id="ref32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gombolay</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Hayes</surname><given-names>B</given-names></name><name><surname>Seo</surname><given-names>N</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Wadhwania</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>T</given-names></name><name><surname>Shah</surname><given-names>N</given-names></name><name><surname>Golen</surname><given-names>T</given-names></name><name><surname>Shah</surname><given-names>J</given-names></name></person-group><article-title>Robotic assistance in the coordination of patient care</article-title><source>Int J Robot Res</source><year>2018</year><volume>37</volume><issue>10</issue><fpage>1300</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1177/0278364918778344</pub-id></element-citation></ref><ref id="ref33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>EH</given-names></name><name><surname>Gross</surname><given-names>CP</given-names></name><name><surname>Tilburt</surname><given-names>JC</given-names></name><name><surname>Yu</surname><given-names>JB</given-names></name><name><surname>Nguyen</surname><given-names>PL</given-names></name><name><surname>Smaldone</surname><given-names>MC</given-names></name><name><surname>Shah</surname><given-names>ND</given-names></name><name><surname>Abouassally</surname><given-names>R</given-names></name><name><surname>Sun</surname><given-names>M</given-names></name><name><surname>Kim</surname><given-names>SP</given-names></name></person-group><article-title>Shared decision making and use of decision AIDS for localized prostate cancer : perceptions from radiation oncologists and urologists</article-title><source>JAMA Intern Med</source><year>2015</year><volume>175</volume><issue>5</issue><fpage>792</fpage><lpage>799</lpage><pub-id pub-id-type="doi">10.1001/jamainternmed.2015.63</pub-id><pub-id pub-id-type="medline">25751604</pub-id><pub-id pub-id-type="pii">2174940</pub-id><pub-id pub-id-type="pmid">25751604</pub-id>
</element-citation></ref><ref id="ref34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nazaretsky</surname><given-names>T</given-names></name><name><surname>Ariely</surname><given-names>M</given-names></name><name><surname>Cukurova</surname><given-names>M</given-names></name><name><surname>Alexandron</surname><given-names>G</given-names></name></person-group><article-title>Teachers' trust in AI&#x02010;powered educational technology and a professional development program to improve it</article-title><source>Brit J Educational Tech</source><year>2022</year><volume>53</volume><issue>4</issue><fpage>914</fpage><lpage>931</lpage><pub-id pub-id-type="doi">10.1111/bjet.13232</pub-id></element-citation></ref><ref id="ref35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jamieson</surname><given-names>GA</given-names></name><name><surname>Hollands</surname><given-names>JG</given-names></name></person-group><article-title>Trust and reliance on an automated combat identification system</article-title><source>Hum Factors</source><year>2009</year><volume>51</volume><issue>3</issue><fpage>281</fpage><lpage>291</lpage><pub-id pub-id-type="doi">10.1177/0018720809338842</pub-id><pub-id pub-id-type="medline">19750792</pub-id><pub-id pub-id-type="pmid">19750792</pub-id>
</element-citation></ref><ref id="ref36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>N</given-names></name><name><surname>Huang</surname><given-names>KY</given-names></name><name><surname>Yang</surname><given-names>XJ</given-names></name></person-group><article-title>Not all information is equal: effects of disclosing different types of likelihood information on trust, compliance and reliance, and task performance in human-automation teaming</article-title><source>Hum Factors</source><year>2020</year><volume>62</volume><issue>6</issue><fpage>987</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1177/0018720819862916</pub-id><pub-id pub-id-type="medline">31348863</pub-id><pub-id pub-id-type="pmid">31348863</pub-id>
</element-citation></ref><ref id="ref37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chatzimparmpas</surname><given-names>A</given-names></name><name><surname>Martins</surname><given-names>RM</given-names></name><name><surname>Jusufi</surname><given-names>I</given-names></name><name><surname>Kucher</surname><given-names>K</given-names></name><name><surname>Rossi</surname><given-names>F</given-names></name><name><surname>Kerren</surname><given-names>A</given-names></name></person-group><article-title>The state of the art in enhancing trust in machine learning models with the use of visualizations</article-title><source>Comput Graph Forum</source><year>2020</year><volume>39</volume><issue>3</issue><fpage>713</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1111/cgf.14034</pub-id></element-citation></ref><ref id="ref38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudin</surname><given-names>C</given-names></name><name><surname>Ustun</surname><given-names>B</given-names></name></person-group><article-title>Optimized scoring systems: toward trust in machine learning for healthcare and criminal justice</article-title><source>Interfaces</source><year>2018</year><volume>48</volume><issue>5</issue><fpage>449</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1287/inte.2018.0957</pub-id></element-citation></ref><ref id="ref39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dasgupta</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Wilson</surname><given-names>R</given-names></name><name><surname>Lafrance</surname><given-names>RA</given-names></name><name><surname>Cramer</surname><given-names>N</given-names></name><name><surname>Cook</surname><given-names>K</given-names></name><name><surname>Payne</surname><given-names>S</given-names></name></person-group><article-title>Familiarity vs trust: a comparative study of domain scientists' trust in visual analytics and conventional analysis methods</article-title><source>IEEE Trans Vis Comput Graph</source><year>2017</year><volume>23</volume><issue>1</issue><fpage>271</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1109/TVCG.2016.2598544</pub-id><pub-id pub-id-type="medline">27608465</pub-id><pub-id pub-id-type="pmid">27608465</pub-id>
</element-citation></ref><ref id="ref40"><label>40</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>F</given-names></name><name><surname>Huang</surname><given-names>Z</given-names></name><name><surname>Scholtz</surname><given-names>J</given-names></name><name><surname>Arendt</surname><given-names>DL</given-names></name></person-group><article-title>How do visual explanations foster end users' appropriate trust in machine learning?</article-title><year>2020</year><conf-name>IUI '20: Proceedings of the 25th International Conference on Intelligent User Interfaces</conf-name><conf-date>March 17, 2020</conf-date><conf-loc>Cagliari, Italy</conf-loc><fpage>189</fpage><lpage>201</lpage></element-citation></ref><ref id="ref41"><label>41</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sacha</surname><given-names>D</given-names></name><name><surname>Sedlmair</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Lee</surname><given-names>JA</given-names></name><name><surname>Peltonen</surname><given-names>J</given-names></name><name><surname>Weiskopf</surname><given-names>D</given-names></name><name><surname>North</surname><given-names>SC</given-names></name><name><surname>Keim</surname><given-names>DA</given-names></name></person-group><article-title>Human-centered machine learning through interactive visualization</article-title><year>2016</year><conf-name>ESANN 2016 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning</conf-name><conf-date>April 27-29, 2016</conf-date><conf-loc>Bruges, Belgium</conf-loc><pub-id pub-id-type="doi">10.1016/j.neucom.2017.01.105</pub-id></element-citation></ref><ref id="ref42"><label>42</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>D</given-names></name><name><surname>Popov</surname><given-names>I</given-names></name><name><surname>Drucker</surname><given-names>S</given-names></name><name><surname>schraefel</surname><given-names>MC</given-names></name></person-group><article-title>Trust me, i'm partially right: incremental visualization lets analysts explore large datasets faster</article-title><year>2012</year><conf-name>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</conf-name><conf-date>May 5, 2012</conf-date><conf-loc>Austin, TX</conf-loc><fpage>1673</fpage><lpage>1682</lpage></element-citation></ref><ref id="ref43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mercado</surname><given-names>JE</given-names></name><name><surname>Rupp</surname><given-names>MA</given-names></name><name><surname>Chen</surname><given-names>JYC</given-names></name><name><surname>Barnes</surname><given-names>MJ</given-names></name><name><surname>Barber</surname><given-names>D</given-names></name><name><surname>Procci</surname><given-names>K</given-names></name></person-group><article-title>Intelligent agent transparency in human-agent teaming for multi-UxV management</article-title><source>Hum Factors</source><year>2016</year><volume>58</volume><issue>3</issue><fpage>401</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1177/0018720815621206</pub-id><pub-id pub-id-type="medline">26867556</pub-id><pub-id pub-id-type="pii">0018720815621206</pub-id><pub-id pub-id-type="pmid">26867556</pub-id>
</element-citation></ref><ref id="ref44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Schemanske</surname><given-names>C</given-names></name><name><surname>Searle</surname><given-names>C</given-names></name></person-group><article-title>Toward quantifying trust dynamics: how people adjust their trust after moment-to-moment interaction with automation</article-title><source>Hum Factors</source><year>2023</year><volume>65</volume><issue>5</issue><fpage>862</fpage><lpage>878</lpage><comment>
<ext-link xlink:href="https://journals.sagepub.com/doi/abs/10.1177/00187208211034716?url_ver=Z39.88-2003&#x00026;rfr_id=ori:rid:crossref.org&#x00026;rfr_dat=cr_pub0pubmed" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1177/00187208211034716</pub-id><pub-id pub-id-type="medline">34459266</pub-id><!--<pub-id pub-id-type="pmcid">PMC10374998</pub-id>--><pub-id pub-id-type="pmid">34459266</pub-id>
</element-citation></ref><ref id="ref45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Moray</surname><given-names>N</given-names></name></person-group><article-title>Trust, control strategies and allocation of function in human-machine systems</article-title><source>Ergonomics</source><year>1992</year><volume>35</volume><issue>10</issue><fpage>1243</fpage><lpage>1270</lpage><pub-id pub-id-type="doi">10.1080/00140139208967392</pub-id><pub-id pub-id-type="medline">1516577</pub-id><pub-id pub-id-type="pmid">1516577</pub-id>
</element-citation></ref><ref id="ref46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><article-title>The science of choosing the right decision threshold in high-stakes diagnostics</article-title><source>Am Psychol</source><year>1992</year><volume>47</volume><issue>4</issue><fpage>522</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1037//0003-066x.47.4.522</pub-id><pub-id pub-id-type="medline">1595983</pub-id><pub-id pub-id-type="pmid">1595983</pub-id>
</element-citation></ref><ref id="ref47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davenport</surname><given-names>RB</given-names></name><name><surname>Bustamante</surname><given-names>EA</given-names></name></person-group><article-title>Effects of false-alarm vs. miss-prone automation and likelihood alarm technology on trust, reliance, and compliance in a miss-prone task</article-title><source>Proc Hum Factors Ergon Soc Annu Meet</source><year>2010</year><volume>54</volume><issue>19</issue><fpage>1513</fpage><lpage>1517</lpage><pub-id pub-id-type="doi">10.1177/154193121005401933</pub-id></element-citation></ref><ref id="ref48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanton</surname><given-names>NS</given-names></name><name><surname>Ragsdale</surname><given-names>SA</given-names></name><name><surname>Bustamante</surname><given-names>EA</given-names></name></person-group><article-title>The effects of system technology and probability type on trust, compliance, and reliance</article-title><source>HFES Ann Conf Proc</source><year>2009</year><volume>53</volume><issue>18</issue><fpage>1368</fpage><lpage>1372</lpage><pub-id pub-id-type="doi">10.1518/107118109x12524443347238</pub-id></element-citation></ref><ref id="ref49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Q</given-names></name><name><surname>Al Kontar</surname><given-names>R</given-names></name><name><surname>Nouiehed</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Lester</surname><given-names>C</given-names></name></person-group><article-title>Rethinking cost-sensitive classification in deep learning via adversarial data augmentation</article-title><source>INFORMS J Data Sci</source><year>2022</year><pub-id pub-id-type="doi">10.1287/ijds.2022.0033</pub-id></element-citation></ref><ref id="ref50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Rowell</surname><given-names>B</given-names></name><name><surname>Chen</surname><given-names>Q</given-names></name><name><surname>Kim</surname><given-names>JY</given-names></name><name><surname>Kontar</surname><given-names>RA</given-names></name><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Lester</surname><given-names>CA</given-names></name></person-group><article-title>Designing human-centered AI to prevent medication dispensing errors: focus group study with pharmacists</article-title><source>JMIR Form Res</source><year>2023</year><volume>7</volume><fpage>e51921</fpage><comment>
<ext-link xlink:href="https://formative.jmir.org/2023//e51921/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/51921</pub-id><pub-id pub-id-type="medline">38145475</pub-id><pub-id pub-id-type="pii">v7i1e51921</pub-id><!--<pub-id pub-id-type="pmcid">PMC10775023</pub-id>--><pub-id pub-id-type="pmid">38145475</pub-id>
</element-citation></ref><ref id="ref51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gal</surname><given-names>Y</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name></person-group><article-title>Dropout as a Bayesian approximation: representing model uncertainty in deep learning</article-title><source>Proc Mach Learn Res</source><year>2016</year><fpage>1050</fpage><lpage>1059</lpage></element-citation></ref><ref id="ref52"><label>52</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group><article-title>Deep residual learning for image recognition</article-title><year>2016</year><conf-name>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</conf-name><conf-date>June 27-30, 2016</conf-date><conf-loc>Las Vegas, NV</conf-loc><fpage>770</fpage><lpage>778</lpage></element-citation></ref><ref id="ref53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanner</surname><given-names>WP</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><article-title>A decision-making theory of visual detection</article-title><source>Psychol Rev</source><year>1954</year><volume>61</volume><issue>6</issue><fpage>401</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1037/h0058700</pub-id><pub-id pub-id-type="pmid">13215690</pub-id>
</element-citation></ref><ref id="ref54"><label>54</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reilly</surname><given-names>S</given-names></name><name><surname>Grasha</surname><given-names>AF</given-names></name><name><surname>Matthews</surname><given-names>G</given-names></name><name><surname>Schafer</surname><given-names>J</given-names></name></person-group><article-title>Automatic-controlled information processing and error detection in a simulated pharmacy-verification task</article-title><source>Percept Mot Skills</source><year>2003</year><volume>97</volume><issue>1</issue><fpage>151</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.2466/pms.2003.97.1.151</pub-id><pub-id pub-id-type="medline">14604036</pub-id><pub-id pub-id-type="pmid">14604036</pub-id>
</element-citation></ref><ref id="ref55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wickens</surname><given-names>CD</given-names></name><name><surname>Dixon</surname><given-names>SR</given-names></name></person-group><article-title>The benefits of imperfect diagnostic automation: a synthesis of the literature</article-title><source>Theor Issues Ergon Sci</source><year>2007</year><volume>8</volume><issue>3</issue><fpage>201</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1080/14639220500370105</pub-id></element-citation></ref><ref id="ref56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manzey</surname><given-names>D</given-names></name><name><surname>Reichenbach</surname><given-names>J</given-names></name><name><surname>Onnasch</surname><given-names>L</given-names></name></person-group><article-title>Human performance consequences of automated decision aids</article-title><source>J Cogn Eng Decis Mak</source><year>2012</year><volume>6</volume><issue>1</issue><fpage>57</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1177/1555343411433844</pub-id></element-citation></ref><ref id="ref57"><label>57</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Unhelkar</surname><given-names>VV</given-names></name><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Shah</surname><given-names>JA</given-names></name></person-group><article-title>Evaluating effects of user experience and system transparency on trust in automation</article-title><year>2017</year><conf-name>Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction</conf-name><conf-date>March 6, 2017</conf-date><conf-loc>Vienna, Austria</conf-loc><fpage>408</fpage><lpage>416</lpage></element-citation></ref><ref id="ref58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merritt</surname><given-names>SM</given-names></name><name><surname>Heimbaugh</surname><given-names>H</given-names></name><name><surname>LaChapell</surname><given-names>J</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name></person-group><article-title>I trust it, but I don't know why: effects of implicit attitudes toward automation on trust in an automated system</article-title><source>Hum Factors</source><year>2013</year><volume>55</volume><issue>3</issue><fpage>520</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1177/0018720812465081</pub-id><pub-id pub-id-type="medline">23829027</pub-id><pub-id pub-id-type="pmid">23829027</pub-id>
</element-citation></ref><ref id="ref59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merritt</surname><given-names>SM</given-names></name><name><surname>Ilgen</surname><given-names>DR</given-names></name></person-group><article-title>Not all trust is created equal: dispositional and history-based trust in human-automation interactions</article-title><source>Hum Factors</source><year>2008</year><volume>50</volume><issue>2</issue><fpage>194</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1518/001872008X288574</pub-id><pub-id pub-id-type="medline">18516832</pub-id><pub-id pub-id-type="pmid">18516832</pub-id>
</element-citation></ref><ref id="ref60"><label>60</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>P</given-names></name><name><surname>Dominguez</surname><given-names>C</given-names></name><name><surname>Kasdaglis</surname><given-names>N</given-names></name><name><surname>Ryan</surname><given-names>M</given-names></name><name><surname>Trhan</surname><given-names>I</given-names></name><name><surname>Nelson</surname><given-names>A</given-names></name></person-group><article-title>Human-machine teaming systems engineering guide</article-title><source>Defense Technical Information Center</source><year>2018</year><date-in-citation content-type="access-date">2025-01-10</date-in-citation><comment>
<ext-link xlink:href="https://apps.dtic.mil/sti/citations/AD1108020" ext-link-type="uri">https://apps.dtic.mil/sti/citations/AD1108020</ext-link>
</comment></element-citation></ref><ref id="ref61"><label>61</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>DM</given-names></name><name><surname>M&#x000e4;chler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><article-title>Fitting linear mixed-effects models using lme4</article-title><source>J Stat Software</source><year>2015</year><volume>67</volume><issue>1</issue><fpage>1</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="ref62"><label>62</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>R Core Team</collab></person-group><article-title>R: A language and environment for statistical computing</article-title><source>R Foundation for Statistical Computing</source><year>2019</year><date-in-citation content-type="access-date">2025-01-20</date-in-citation><comment>
<ext-link xlink:href="https://www.R-project.org" ext-link-type="uri">https://www.R-project.org</ext-link>
</comment></element-citation></ref><ref id="ref63"><label>63</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montag</surname><given-names>C</given-names></name><name><surname>Kraus</surname><given-names>J</given-names></name><name><surname>Baumann</surname><given-names>M</given-names></name><name><surname>Rozgonjuk</surname><given-names>D</given-names></name></person-group><article-title>The propensity to trust in (automated) technology mediates the links between technology self-efficacy and fear and acceptance of artificial intelligence</article-title><source>Comput Human Behav</source><year>2023</year><volume>11</volume><fpage>100315</fpage><pub-id pub-id-type="doi">10.1016/j.chbr.2023.100315</pub-id></element-citation></ref><ref id="ref64"><label>64</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>L</given-names></name><name><surname>Kraus</surname><given-names>J</given-names></name><name><surname>Babel</surname><given-names>F</given-names></name><name><surname>Baumann</surname><given-names>M</given-names></name></person-group><article-title>More than a feeling-interrelation of trust layers in human-robot interaction and the role of user dispositions and state anxiety</article-title><source>Front Psychol</source><year>2021</year><volume>12</volume><fpage>592711</fpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/33912098" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.3389/fpsyg.2021.592711</pub-id><pub-id pub-id-type="medline">33912098</pub-id><!--<pub-id pub-id-type="pmcid">PMC8074795</pub-id>--><pub-id pub-id-type="pmid">33912098</pub-id>
</element-citation></ref><ref id="ref65"><label>65</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>XJ</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Schemanske</surname><given-names>C</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Duffy</surname><given-names>VG</given-names></name><name><surname>Landry</surname><given-names>SJ</given-names></name><name><surname>Lee</surname><given-names>JD</given-names></name><name><surname>Stanton</surname><given-names>N</given-names></name></person-group><article-title>From trust to trust dynamics: combining empirical and computational approaches to model and predict trust dynamics in human-autonomy interaction</article-title><source>Human-Automation Interaction: Transportation</source><year>2022</year><publisher-loc>Cham, Switzerland</publisher-loc><publisher-name>Springer</publisher-name><fpage>253</fpage><lpage>265</lpage></element-citation></ref><ref id="ref66"><label>66</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Visser</surname><given-names>EJ</given-names></name><name><surname>Pak</surname><given-names>R</given-names></name><name><surname>Shaw</surname><given-names>TH</given-names></name></person-group><article-title>From 'automation' to 'autonomy': the importance of trust repair in human-machine interaction</article-title><source>Ergonomics</source><year>2018</year><volume>61</volume><issue>10</issue><fpage>1409</fpage><lpage>1427</lpage><pub-id pub-id-type="doi">10.1080/00140139.2018.1457725</pub-id><pub-id pub-id-type="medline">29578376</pub-id><pub-id pub-id-type="pmid">29578376</pub-id>
</element-citation></ref><ref id="ref67"><label>67</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lyons</surname><given-names>JB</given-names></name><name><surname>Sadler</surname><given-names>GG</given-names></name><name><surname>Koltai</surname><given-names>K</given-names></name><name><surname>Battiste</surname><given-names>H</given-names></name><name><surname>Ho</surname><given-names>NT</given-names></name><name><surname>Hoffmann</surname><given-names>LC</given-names></name><name><surname>Smith</surname><given-names>D</given-names></name><name><surname>Johnson</surname><given-names>W</given-names></name><name><surname>Shively</surname><given-names>R</given-names></name></person-group><source>Shaping Trust Through Transparent Design: Theoretical and Experimental Guidelines</source><year>2017</year><publisher-loc>Cham, Switzerland</publisher-loc><publisher-name>Springer</publisher-name><fpage>127</fpage><lpage>136</lpage></element-citation></ref><ref id="ref68"><label>68</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>R</given-names></name><name><surname>Du</surname><given-names>N</given-names></name><name><surname>Yang</surname><given-names>XJ</given-names></name></person-group><article-title>Evaluating effects of enhanced autonomy transparency on trust, dependence, and human-autonomy team performance over time</article-title><source>Int J Hum Comput</source><year>2022</year><volume>38</volume><issue>18-20</issue><fpage>1962</fpage><lpage>1971</lpage><pub-id pub-id-type="doi">10.1080/10447318.2022.2097602</pub-id></element-citation></ref><ref id="ref69"><label>69</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorkin</surname><given-names>RD</given-names></name><name><surname>Kantowitz</surname><given-names>BH</given-names></name><name><surname>Kantowitz</surname><given-names>SC</given-names></name></person-group><article-title>Likelihood alarm displays</article-title><source>Hum Factors</source><year>1988</year><volume>30</volume><issue>4</issue><fpage>445</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1177/001872088803000</pub-id></element-citation></ref><ref id="ref70"><label>70</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carayon</surname><given-names>P</given-names></name><name><surname>Gurses</surname><given-names>AP</given-names></name></person-group><article-title>Nursing workload and patient safety&#x02014;a human factors engineering perspective</article-title><source>Patient Safety and Quality: An Evidence-Based Handbook for Nurses</source><year>2008</year><publisher-loc>Rockville, MD</publisher-loc><publisher-name>Agency for Healthcare Research and Quality</publisher-name></element-citation></ref><ref id="ref71"><label>71</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watterson</surname><given-names>TL</given-names></name><name><surname>Look</surname><given-names>KA</given-names></name><name><surname>Steege</surname><given-names>L</given-names></name><name><surname>Chui</surname><given-names>MA</given-names></name></person-group><article-title>Operationalizing occupational fatigue in pharmacists: an exploratory factor analysis</article-title><source>Res Social Adm Pharm</source><year>2021</year><volume>17</volume><issue>7</issue><fpage>1282</fpage><lpage>1287</lpage><pub-id pub-id-type="doi">10.1016/j.sapharm.2020.09.012</pub-id><pub-id pub-id-type="medline">33004303</pub-id><pub-id pub-id-type="pii">S1551-7411(20)31111-6</pub-id><pub-id pub-id-type="pmid">33004303</pub-id>
</element-citation></ref></ref-list></back></article>