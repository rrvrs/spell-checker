<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Dent Res Dent Clin Dent Prospects</journal-id><journal-id journal-id-type="iso-abbrev">J Dent Res Dent Clin Dent Prospects</journal-id><journal-id journal-id-type="publisher-id">J Dent Res Dent Clin Dent Prospects</journal-id><journal-id journal-id-type="publisher-id">TBZMED</journal-id><journal-title-group><journal-title>Journal of Dental Research, Dental Clinics, Dental Prospects</journal-title></journal-title-group><issn pub-type="ppub">2008-210X</issn><issn pub-type="epub">2008-2118</issn><issn-l>2008-210X</issn-l><publisher><publisher-name>Tabriz University of Medical Sciences</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC11786010</article-id><article-id pub-id-type="doi">10.34172/joddd.41114</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Determination of cervical vertebral maturation using machine learning in lateral cephalograms</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9129-5435</contrib-id><name><surname>Kavousinejad</surname><given-names>Shahab</given-names></name><role content-type="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="A01" ref-type="aff">
<sup>1</sup>
</xref><xref rid="A02" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8946-954X</contrib-id><name><surname>Ebadifar</surname><given-names>Asghar</given-names></name><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="A01" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Tehranchi</surname><given-names>Azita</given-names></name><role content-type="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="https://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="A01" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Zakermashhadi</surname><given-names>Farzan</given-names></name><role content-type="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="A03" ref-type="aff">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5430-3301</contrib-id><name><surname>Dalaie</surname><given-names>Kazem</given-names></name><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role content-type="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="https://credit.niso.org/contributor-roles/resources/">Resources</role><role content-type="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="A01" ref-type="aff">
<sup>1</sup>
</xref><xref rid="A02" ref-type="aff">
<sup>2</sup>
</xref><xref rid="COR1" ref-type="corresp">*</xref></contrib></contrib-group><aff id="A01">
<sup>1</sup>Dentofacial Deformities Research Center, Research Institute for Dental Sciences, School of Dentistry, Shahid Beheshti University of Medical Sciences, Tehran, Iran</aff><aff id="A02">
<sup>2</sup>Department of Orthodontics, School of Dentistry, Shahid Beheshti University of Medical Sciences, Tehran, Iran</aff><aff id="A03">
<sup>3</sup>School of Dentistry, Shahid Beheshti University of Medical Sciences, Tehran, Iran</aff><author-notes><corresp id="COR1">
<label>*</label><bold>Corresponding author:</bold> Kazem Dalaie, Email: <email>Kazemdalaie@gmail.com</email></corresp></author-notes><pub-date pub-type="ppub"><season>Autumn</season><year>2024</year></pub-date><pub-date pub-type="epub"><day>14</day><month>12</month><year>2024</year></pub-date><volume>18</volume><issue>4</issue><fpage>232</fpage><lpage>241</lpage><history><date date-type="received"><day>01</day><month>3</month><year>2024</year></date><date date-type="accepted"><day>25</day><month>10</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; 2024 The Author(s).</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense" start_date="2024-12-14">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>
This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
</license-p></license></permissions><self-uri xlink:href="https://joddd.tbzmed.ac.ir">This article is available from: https://joddd.tbzmed.ac.ir</self-uri><abstract><sec id="sa1"><title>Background.</title><p> The accurate timing of growth modification treatments is crucial for optimal results in orthodontics. However, traditional methods for assessing growth status, such as hand-wrist radiographs and subjective interpretation of lateral cephalograms, have limitations. This study aimed to develop a semi-automated approach using machine learning based on cervical vertebral dimensions (CVD) for determining skeletal maturation status.</p></sec><sec id="sa2"><title>Methods.</title><p> A dataset comprising 980 lateral cephalograms was collected from the Department of Orthodontics, Shahid Beheshti Dental School in Tehran, Iran. Eight landmarks representing the corners of the third and fourth cervical vertebrae were selected. A ratio-based approach was employed to compute the values of C3 and C4, accompanied by the implementation of an auto_error_reduction (AER) function to enhance the accuracy of landmark selection. Linear distances and ratios were measured using the dedicated software. A novel data augmentation technique was applied to expand the dataset. Subsequently, a stacking model was developed, trained on the augmented dataset, and evaluated using a separate test set of 196 cephalograms. </p></sec><sec id="sa3"><title>Results.</title><p> The proposed model achieved an accuracy of 99.49% and demonstrated a loss of 0.003 on the test set. </p></sec><sec id="sa4"><title>Conclusion.</title><p> By employing feature engineering, simplified landmark selection, AER function, data augmentation, and eliminating gender and age features, a model was developed for accurate assessment of skeletal maturation for clinical applications.</p></sec></abstract><kwd-group><kwd>Cervical vertebra dimensions</kwd><kwd>Growth modification treatment</kwd><kwd>Machine learning</kwd><kwd>Skeletal age</kwd></kwd-group><funding-group><funding-statement>Dentofacial Deformities Research Center, Research Institute of Dental Sciences, School of Dentistry, Shahid Beheshti University of Medical Sciences.</funding-statement></funding-group></article-meta></front><body><sec sec-type="introduction" id="s1"><title>Introduction</title><p> The timing of growth modification treatments is crucial for achieving optimal results. The peak of mandibular growth represents the ideal time for intervention.<sup><xref rid="R1" ref-type="bibr">1</xref></sup> Skeletal age determination is an important method for assessing growth status in orthodontics.<sup><xref rid="R2" ref-type="bibr">2</xref>-<xref rid="R4" ref-type="bibr">4</xref></sup> However, chronological age does not always correlate well with skeletal age,<sup><xref rid="R5" ref-type="bibr">5</xref>-<xref rid="R7" ref-type="bibr">7</xref></sup> leading to the introduction of alternative methods for skeletal age assessment.<sup><xref rid="R8" ref-type="bibr">8</xref>-<xref rid="R11" ref-type="bibr">11</xref></sup> While hand-wrist radiographs are considered the gold standard for skeletal age determination,<sup><xref rid="R12" ref-type="bibr">12</xref></sup> their limited use in dentistry is due to concerns about excessive radiation exposure.<sup><xref rid="R13" ref-type="bibr">13</xref>-<xref rid="R15" ref-type="bibr">15</xref></sup> In dentistry, evaluating cervical vertebra maturation (CVM) on lateral cephalograms is the most common approach to assessing skeletal age, as it is easy to perform and provides valuable information for initial diagnosis in orthodontics.<sup><xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R16" ref-type="bibr">16</xref>-<xref rid="R18" ref-type="bibr">18</xref></sup></p><p> However, interpreting lateral cephalograms for CVM analysis can be challenging due to variations in image clarity and the absence of a definitive cutoff point between CVM stages.<sup><xref rid="R18" ref-type="bibr">18</xref>,<xref rid="R19" ref-type="bibr">19</xref></sup> By incorporating a quantitative approach, we can enhance our understanding of the patient&#x02019;s skeletal maturation, ultimately leading to more effective treatment outcomes. Moreover, several studies have reported low inter- and intra-observer agreement, indicating that the CVM method lacks reliability and reproducibility.<sup><xref rid="R1" ref-type="bibr">1</xref>,<xref rid="R20" ref-type="bibr">20</xref>-<xref rid="R23" ref-type="bibr">23</xref></sup> These limitations arise from the qualitative nature of parameters assessed in the CVM method, such as the amount of concavity and the shape of cervical vertebrae, highlighting the need for quantitative approaches. Quantitative methods have been developed to address these limitations, focusing on measuring cervical vertebra dimensions (CVD) to determine skeletal age.<sup><xref rid="R9" ref-type="bibr">9</xref>,<xref rid="R24" ref-type="bibr">24</xref>,<xref rid="R25" ref-type="bibr">25</xref></sup> A strong and statistically significant correlation between CVM and CVD has been demonstrated.<sup><xref rid="R25" ref-type="bibr">25</xref></sup> In this method, the six groups (CVM method) were divided into three groups. Groups 3 and 4 in the CVM method (group 2 in the CVD method) are associated with the mandibular peak growth period <sup><xref rid="R25" ref-type="bibr">25</xref>,<xref rid="R26" ref-type="bibr">26</xref></sup> Therefore, we used the three-class method (pre-peak, peak, and post-peak) in the present study.</p><p> In recent years, the rapid advancement of imaging technologies, coupled with the increasing complexity of interpretation, has sparked a surge of interest among researchers in exploring the potential application of artificial intelligence (AI) in orthodontics. AI can potentially assist orthodontists in diagnosing and predicting outcomes with high accuracy and reduce time compared to trained dentists.<sup><xref rid="R27" ref-type="bibr">27</xref></sup> Several studies have evaluated the accuracy of deep learning models in determining CVM stages. Atici et al<sup><xref rid="R28" ref-type="bibr">28</xref></sup> and Khazaei et al<sup><xref rid="R29" ref-type="bibr">29</xref></sup> achieved accuracy rates ranging from 75% to 82%. K&#x000f6;k et al<sup><xref rid="R30" ref-type="bibr">30</xref></sup> compared deep learning models with machine learning models and concluded that deep learning models outperformed machine learning models. However, considering the novel methodology employed to measure CVD in the present study, integrating feature engineering and feature selection into machine learning models is expected to yield significantly higher accuracy than deep learning models. This study aimed to determine skeletal maturation status using machine learning algorithms based on quantitative measurements of CVD obtained from lateral cephalograms. By leveraging the potential of AI, this research aimed to enhance the accuracy of skeletal age assessment in orthodontics.</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec sec-type="subsection" id="s2-1"><title> Data collection and dataset preparation</title><p> In this study, 980 digital cephalograms were collected from 6&#x02012;17-year-olds. The cephalograms were collected from existing files in the Department of Orthodontics, Shahid Beheshti Dental School, Tehran, Iran. Inclusion criteria consisted of high-quality cephalograms and cervical vertebrae and the absence of specific syndromes and systemic problems in patients. Each cephalogram was randomly assigned a unique identifier in the format of a letter and a value (e.g., A0). To perform feature engineering, the ratio of CVD was calculated according to the following formula.<sup><xref rid="R25" ref-type="bibr">25</xref></sup> This method is described in <xref rid="F1" ref-type="fig">Figure 1</xref>.</p><fig position="float" id="F1"><label>Figure 1</label><graphic xlink:href="joddd-18-232-g001" position="float"/><statement><p>
The selected landmarks, indicated by red and blue dots, represent the corners of the third and fourth cervical vertebrae, respectively. Eight landmarks were selected. For C4, a red line connects the midpoint of the perpendicular line from C4a to the line C4c-C4d with the midpoint of the perpendicular line from C4b to the line C4c-C4d. The length of this line represents the value of AP4. The blue line, AH4, shows the perpendicular line from C4b to the line C4c-C4d. The value of C4 is presented as the ratio AH4/AP4. A similar method was applied to the third cervical vertebra, determining the value corresponding to C3.</p></statement></fig><disp-formula id="DF1">
<mml:math id="m1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>H</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext>&#x02004;</mml:mtext><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>H</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula><p> In this method, eight landmarks representing the corners of the third and fourth cervical vertebrae were meticulously selected. In cases where the corners exhibited curvature, the midpoint of the curve was selected. A software application was developed using the C# programming language to facilitate the measurement of linear distances and ratios. The cephalograms were subsequently imported into the software, where they underwent resizing to achieve a uniform width of 2000 pixels while preserving the original aspect ratio. This resizing operation was necessary to standardize the pixels for subsequent steps. To calculate the lengths, the pixel count between the selected landmarks (X and Y coordinates) was measured using the following formula:</p><disp-formula id="DF2">
<mml:math id="m2" display="block" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:math>
</disp-formula><p> The values of C3 and C4 were calculated for each sample. By employing the ratio-based approach, inherent variations in magnification associated with diverse radiographic views and x-ray devices were effectively eliminated. An innovative AER function was implemented within the software framework to enhance the accuracy of landmark selection by the researcher (<xref rid="F2" ref-type="fig">Figure 2</xref>). Within this function, the coordinates of each selected landmark within the software were subjected to random displacements spanning 1 to 4 pixels in both the X and Y directions relative to the original landmark. Subsequently, the values of C3 and C4 were computed for each iteration of the AER function, which was repeated a thousand times (as a loop). Ultimately, the average values of C3 and C4 were derived as the output for each sample. This sophisticated approach substantially reduced the error stemming from discrepancies in landmark selection across researcher iterations, as the selection area encompassed a set of randomly distributed landmarks within a maximum radius of 4 pixels. AER function is a probabilistic average of surrounding landmarks.</p><fig position="float" id="F2"><label>Figure 2</label><graphic xlink:href="joddd-18-232-g002" position="float"/><statement><p>
The AER function&#x02019;s operational procedure is depicted. We anticipated an operator error of up to 4 pixels during point selection, which the function systematically addresses. Within this function, a thousand randomly generated points are automatically distributed across the designated selection area. The corresponding values of C3 and C4 were calculated for each generated point. This iterative process is repeated a thousand times, resulting in a dataset of a thousand C3 and C4 values for each sample. Finally, the average values of C3 and C4 were computed and considered as the definitive C3 and C4 values for each sample, respectively.</p></statement></fig><p> The data, including age, gender, C3 and C4 values, were placed in a CSV file. A three-class label column called &#x0201c;Maturation&#x0201d; was considered in this CSV file. To prevent bias, blind labeling was performed, meaning the expert determining the class of each sample was unaware of the features of each sample. Initially, labeling was done based on the CVM method for each sample&#x02019;s cephalometric measurements by an orthodontist. Using this method, six classes were identified (CVS1 to CVS6). In the next step, the final classification (maturation) was determined as follows:</p><p> Class 1: Pre-peak of mandibular growth (CVS1 and CVS2 classes)</p><p> Class 2: Peak of mandibular growth (CVS3 and CVS4 classes)</p><p> Class 3: Post-peak of mandibular growth (CVS5 and CVS6 classes)</p><p> Two other important indices, SumC3C4 and C3C4, were calculated for each sample based on the following formulas and included in the dataset:</p><disp-formula id="DF3">
<mml:math id="m3" display="block" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>S</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn><mml:mi>C</mml:mi><mml:mn>4</mml:mn><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula><p> Therefore, the final dataset included age, gender, C3, C4, SumC3C4, C3C4, and maturation. The project was coded in Python programming language using the Jupyter Notebook environment (version 6.4.12). The following Python libraries were used: Scikit-learn (sklearn), CatBoost, LightGBM, and XGBoost.</p></sec><sec sec-type="subsection" id="s2-2"><title> Data preprocessing and feature selection</title><p> The dataset had no missing values, and the sample sizes for each class were balanced. The labels were converted from qualitative (pre-peak, peak, post-peak) to quantitative, representing three classes: 1, 2, and 3. The dataset was randomly split into two sets: train (80%) and test (20%). <xref rid="F3" ref-type="fig">Figure 3</xref> visually presents the three-dimensional distribution of the training data categorized by class before and after data augmentation. The x, y, and z axes correspond to the values C3, C4, and SumC3C4, respectively. Additionally, the size of each sample (represented as a sphere) is determined by the weighted value of C3C4.</p><fig position="float" id="F3"><label>Figure 3</label><graphic xlink:href="joddd-18-232-g003" position="float"/><statement><p>
Visualization of the training dataset in 3D format before (A) and after (B) data augmentation</p></statement></fig><p> To enhance the generalization and accuracy of our machine learning model, introduce data diversity, and mitigate overfitting, we developed a data augmentation technique called CVD_Generator specifically for the training data. This method involves generating random values within the range of minimum and maximum values for C3 and C4 for each class, considering their distributions within the training data. As a result, 1000 new samples were created for each class, with random values of C3 and C4 based on their respective classifications. Additionally, the values of SumC3C4 and C3C4 were calculated for each newly generated sample. The CVD_Generator method is defined as follows:</p><p> n&#x02005;=&#x02005;1000, G&#x02005;=&#x02005;{1, 2, 3}, C&#x02005;=&#x02005;{C3, C4}</p><p> Where n represents the number of new samples, and G is the set of groups defined based on the maturation column. The values in C include the set of columns C3 and C4. For each group gi &#x02208; G and each value j &#x02208; {1, 2,..., n}, a new sample was generated as follows:</p><disp-formula id="DF4">
<mml:math id="m4" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext>&#x02004;</mml:mtext><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext>&#x02004;</mml:mtext><mml:mi>S</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn><mml:mi>C</mml:mi><mml:mn>4</mml:mn><mml:mo>:</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext>&#x02004;</mml:mtext><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:math>
</disp-formula><p> Where S<sub>ij</sub> is a new row added to the data frame, and v<sub>ijk</sub> is a new random value of the C<sub>k</sub> column within the range of values for that group. Then, the age and gender values were also randomly generated based on their respective distributions in each class for the new samples.</p><p> To reduce the model&#x02019;s reliance on age and gender and mitigate bias, we exclusively focused on the independent variables (X): C3, C4, SumC3C4, and C3C4, while considering the three-class label as the dependent variable (Y). As the selected features possess the same nature (dimension ratio), we refrained from applying any data normalization techniques (e.g., employing the StandardScaler method) or feature scaling to them.</p></sec><sec sec-type="subsection" id="s2-3"><title> Model architecture</title><p> Figure S1 visually represents the data preprocessing process, model architecture, and model testing. In the initial stage, we employed the 5-fold cross-validation technique along with grid search and genetic algorithms (for MLP) to determine the optimal hyperparameters for each stage 1 model. The hyperparameters of each model were adjusted accordingly. Subsequently, each model underwent individual training using the training data and evaluation using the test data. Consequently, the hyperparameters for the base models were appropriately configured. The fine-tuned models were then integrated as base models within the stacking model (depicted as stage 1 in Figure S1). The stacking model was trained using the training data. The fundamental concept of model stacking involves training multiple diverse base models and combining their predictions through the training of a meta model. The meta model generates the final prediction by considering the predictions made by the base models. The base models underwent training based on 5-fold cross-validation (CV) on the data and forwarded their predictions to the final estimator. In our proposed model, we used logistic regression as the final estimator, employing default hyperparameters. The 5-fold CV technique divides the data into 5 subsets, using one-fifth as the test data and the remaining 4 subsets as the training data in each iteration. The final prediction is then obtained by averaging the results of these 5 iterations. The architecture of the stacking model is depicted in Figure S1.</p></sec><sec sec-type="subsection" id="s2-4"><title> Base models</title><list list-type="bullet"><list-item><p>ExtraTreesClassifier </p></list-item><list-item><p>Multi-layer perceptron (MLP) </p></list-item><list-item><p>XGBClassifier </p></list-item><list-item><p>CatBoostClassifier </p></list-item><list-item><p>LGBMClassifier (LightGBM) </p></list-item><list-item><p>VotingClassifier </p></list-item></list></sec><sec sec-type="subsection" id="s2-5"><title> Final model</title><list list-type="bullet"><list-item><p>Classification Meta Model: As the ultimate estimator in the stacking model, logistic regression was used, providing a reliable and interpretable prediction for the ensemble model. </p></list-item></list></sec><sec sec-type="subsection" id="s2-6"><title> Evaluation</title><p> In evaluating our model on the test data, we employed various metrics to assess its effectiveness. These metrics encompass accuracy, precision, F1 score, recall, log loss, Jaccard, and the confusion matrix.</p><p>
<bold>Log loss:</bold> This function gauges the performance of a classification model by computing the negative logarithm of the predicted probability for the correct label. In the provided formula, N denotes the number of samples, <italic toggle="yes">y</italic><sub>ij</sub> represents the true label for sample <italic toggle="yes">i</italic> and class <italic toggle="yes">j</italic>, and <italic toggle="yes">p</italic><sub>ij</sub> corresponds to the predicted probability for sample <italic toggle="yes">i</italic> and class <italic toggle="yes">j</italic>.</p><disp-formula id="DF5">
<mml:math id="m5" display="block" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mfenced><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:math>
</disp-formula><p>
<bold>Accuracy:</bold> Accuracy measures the overall correctness of the model&#x02019;s predictions, calculated as the ratio of correct predictions to the total number of predictions.</p><disp-formula id="DF6">
<mml:math id="m6" display="block" overflow="scroll"><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula><list list-type="bullet"><list-item><p>TP (True Positive): The number of positive instances correctly predicted as positive </p></list-item><list-item><p>FP (False Positive): The number of negative instances incorrectly predicted as positive </p></list-item><list-item><p>TN (True Negative): The number of negative instances correctly predicted as negative </p></list-item><list-item><p>FN (False Negative): The number of positive instances incorrectly predicted as negative </p></list-item></list><p>
<bold>Precision:</bold> Precision assesses the model&#x02019;s capability to accurately predict positive samples, computed as the ratio of true positive predictions to the total number of predicted positives.</p><disp-formula id="DF7">
<mml:math id="m7" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula><p>
<bold>Recall:</bold> Recall evaluates the model&#x02019;s ability to correctly identify all positive samples, expressed as the ratio of true positive predictions to the total number of true positives.</p><disp-formula id="DF8">
<mml:math id="m8" display="block" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula><p>
<bold>F1 score:</bold> The F1 score represents a measure of the balance between precision and recall, computed as the harmonic mean of precision and recall.</p><disp-formula id="DF9">
<mml:math id="m9" display="block" overflow="scroll"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula><p> Additionally, as an extra objective in our study, we used the following formula to determine the cutoff points between the three classes:</p><p> Class_1_range&#x02005;=&#x02005;{x&#x02208;X&#x02223;y(x)&#x02005;=&#x02005;1}, Class_2_range&#x02005;=&#x02005;{x&#x02208;X&#x02223;y(x)&#x02005;=&#x02005;2}, Class_3_range&#x02005;=&#x02005;{x&#x02208;X&#x02223;y(x)&#x02005;=&#x02005;3}</p><disp-formula id="DF10">
<mml:math id="m10" display="block" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>max</mml:mi><mml:mfenced><mml:mrow><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>_</mml:mo><mml:mn>1</mml:mn><mml:mo>_</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>min</mml:mi><mml:mfenced><mml:mrow><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>_</mml:mo><mml:mn>2</mml:mn><mml:mo>_</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mtext>&#x000a0;</mml:mtext></mml:mrow></mml:math>
</disp-formula><p> The first and second cutoff points were determined using the following formula.</p><disp-formula id="DF11">
<mml:math id="m11" display="block" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>max</mml:mi><mml:mfenced><mml:mrow><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>_</mml:mo><mml:mn>2</mml:mn><mml:mo>_</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>min</mml:mi><mml:mfenced><mml:mrow><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>_</mml:mo><mml:mn>3</mml:mn><mml:mo>_</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mtext>&#x000a0;</mml:mtext></mml:mrow></mml:math>
</disp-formula><p> To ensure the presence of a cutoff point that includes both the SumC3C4 and C3C4 features, we devised the following formula:</p><disp-formula id="DF12">
<mml:math id="m12" display="block" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mn>1</mml:mn><mml:mtext>&#x000a0;</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mo>_</mml:mo><mml:mn>1</mml:mn><mml:mtext>&#x02004;</mml:mtext><mml:mfenced><mml:mrow><mml:mi>C</mml:mi><mml:mn>3</mml:mn><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mo>_</mml:mo><mml:mn>1</mml:mn><mml:mtext>&#x000a0;</mml:mtext><mml:mfenced><mml:mrow><mml:mi>S</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:mfenced><mml:mtext>&#x000a0;</mml:mtext></mml:mrow></mml:mfrac><mml:mo>&#x000d7;</mml:mo><mml:mn>100</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mo>_</mml:mo><mml:mn>2</mml:mn><mml:mtext>&#x000a0;</mml:mtext><mml:mfenced><mml:mrow><mml:mi>C</mml:mi><mml:mn>3</mml:mn><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mo>_</mml:mo><mml:mn>2</mml:mn><mml:mtext>&#x000a0;</mml:mtext><mml:mfenced><mml:mrow><mml:mi>S</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn><mml:mi>C</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:mfenced><mml:mtext>&#x000a0;</mml:mtext></mml:mrow></mml:mfrac><mml:mo>&#x000d7;</mml:mo><mml:mtext>100&#x000a0;</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula></sec></sec><sec sec-type="results" id="s3"><title>Results</title><p>
<xref rid="T1" ref-type="table">Table 1</xref> shows the means and standard deviations of dataset features. <xref rid="F4" ref-type="fig">Figure 4a</xref> visualizes the correlation among the initial features, indicating a weak correlation with &#x0201c;gender&#x0201d; and strong positive correlations among the other features. <xref rid="T2" ref-type="table">Table 2</xref> presents the results of fine-tuning various base models, with the stacking model outperforming base models (99.49% accuracy, 0.003 log loss). The confusion matrix for the proposed model on the test data is shown in <xref rid="F4" ref-type="fig">Figure 4b</xref>. Sensitivity analysis in <xref rid="F4" ref-type="fig">Figure 4c</xref> highlights the highest importance of &#x0201c;C3C4&#x0201d; and the least importance of &#x0201c;C4.&#x0201d; <xref rid="T3" ref-type="table">Table 3</xref> displays cutoff points between the three groups based on &#x0201c;SumC3C4&#x0201d; and &#x0201c;C3C4&#x0201d; features. The dataset ranges from a minimum SumC3C4 value of 0.62 to a maximum of 2.38 and a minimum C3C4 value of 0.09 to a maximum of 1.42.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><title>The mean and standard deviation for C3C4, SumC3C4, C4, C3, and age in the initial dataset
</title></caption><table frame="hsides" rules="none"><tbody><tr style="background-color:#cddcf0"><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Maturation</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Age</bold>
<break/>
<bold>(mean&#x000b1;SD)</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Gender</bold>
<break/>
<bold>(Counts)</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>C3</bold>
<break/>
<bold>(mean&#x000b1;SD)</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>C4</bold>
<break/>
<bold>(mean&#x000b1;SD)</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>SumC3C4</bold>
<break/>
<bold>(mean&#x000b1;SD)</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>C3C4</bold>
<break/>
<bold>(mean&#x000b1;SD)</bold>
</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">Pre peak (n&#x02005;=&#x02005;326)</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">8.61&#x02005;&#x000b1;&#x02005;1.65</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">M:192<break/>F:134</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">0.52&#x02005;&#x000b1;&#x02005;0.08</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">0.49&#x02005;&#x000b1;&#x02005;0.08</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">1.01&#x02005;&#x000b1;&#x02005;0.14</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">0.26&#x02005;&#x000b1;&#x02005;0.07</td></tr><tr><td style="text-align:left;vertical-align:middle;" rowspan="1" colspan="1">Peak (n&#x02005;=&#x02005;326)</td><td style="text-align:center;vertical-align:middle;" rowspan="1" colspan="1">11.53&#x02005;&#x000b1;&#x02005;1.37</td><td style="text-align:center;vertical-align:middle;" rowspan="1" colspan="1">M:178<break/>F:148</td><td style="text-align:center;vertical-align:middle;" rowspan="1" colspan="1">0.74&#x02005;&#x000b1;&#x02005;0.08</td><td style="text-align:center;vertical-align:middle;" rowspan="1" colspan="1">0.68&#x02005;&#x000b1;&#x02005;0.08</td><td style="text-align:center;vertical-align:middle;" rowspan="1" colspan="1">1.42&#x02005;&#x000b1;&#x02005;0.14</td><td style="text-align:center;vertical-align:middle;" rowspan="1" colspan="1">0.51&#x02005;&#x000b1;&#x02005;0.1</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">Post peak (n&#x02005;=&#x02005;328)</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">16.1&#x02005;&#x000b1;&#x02005;1.23</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">M:194<break/>F:134</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">1.01&#x02005;&#x000b1;&#x02005;0.14</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">0.94&#x02005;&#x000b1;&#x02005;0.12</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">1.96&#x02005;&#x000b1;&#x02005;0.23</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">0.97&#x02005;&#x000b1;&#x02005;0.23</td></tr></tbody></table></table-wrap><fig position="float" id="F4"><label>Figure 4</label><graphic xlink:href="joddd-18-232-g004" position="float"/><statement><p>
A) Heatmap of the correlation among the initial dataset features. B) Confusion matrix of the proposed model on the test data. C) The importance of each feature for the proposed model</p></statement></fig><table-wrap position="float" id="T2"><label>Table 2</label><caption><title>Model performance metrics on the test data and fine-tuned hyperparameters for base models
</title></caption><table frame="hsides" rules="none"><tbody><tr style="background-color:#cddcf0"><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
</td><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Model</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Accuracy (%)</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Precision*</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Recall*</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>F1 score*</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Log loss</bold>
</td><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Hyperparameters (fine-tuned)</bold>
</td></tr><tr><td rowspan="9" style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" colspan="1">Base models</td><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Support vector machine</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">96.94</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.97</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.97</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.97</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.08</td><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Kernel&#x02005;=&#x02005;'rbf', C&#x02005;=&#x02005;800</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">K-nearest neighbors</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">97.96</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.19</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">n_neighbors&#x02005;=&#x02005;4</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Random forest</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">98.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.06</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">n_estimators&#x02005;=&#x02005;211, max_depth&#x02005;=&#x02005;13</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Extra trees classifier</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">97.44</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.97</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.97</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.10</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">n_estimators&#x02005;=&#x02005;63, max_depth&#x02005;=&#x02005;12</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Multi-layer perceptron</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">97.45</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.97</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.97</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.09</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">hidden_layer_sizes&#x02005;=&#x02005;(20,), learning_rate_init&#x02005;=&#x02005;0.01 (adaptive), activation&#x02005;=&#x02005;logistic, max_iter&#x02005;=&#x02005;300, solver&#x02005;=&#x02005;'adam', alpha&#x02005;=&#x02005;0.0001</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">XGB classifier</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">98.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.02</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">n_estimators&#x02005;=&#x02005;100, max_depth&#x02005;=&#x02005;3, learning_rate&#x02005;=&#x02005;0.2, subsample&#x02005;=&#x02005;0.9, colsample_bytree&#x02005;=&#x02005;0.85</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">CatBoost classifier</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">97.42</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.09</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Iterations&#x02005;=&#x02005;100, learning_rate&#x02005;=&#x02005;0.1, depth&#x02005;=&#x02005;5</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">LGBM classifier</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">98.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.04</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">n_estimators&#x02005;=&#x02005;1000, learning_rate&#x02005;=&#x02005;0.1, max_depth&#x02005;=&#x02005;10</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Voting classifier</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">98.47</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.98</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.09</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.25pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Default</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Final model</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">Proposed Stacking model</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>99.49</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">1.0</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.99</td><td style="text-align:center;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">0.003</td><td style="text-align:left;vertical-align:middle;border-width:0.25pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">final_estimator (logisticRegression)</td></tr></tbody></table><table-wrap-foot><fn><p> * Weighted average</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="T3"><label>Table 3</label><caption><title>The cutoff points for class separation based on C3C4 and SumC3C4 features
</title></caption><table frame="hsides" rules="none"><tbody><tr style="background-color:#cddcf0"><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Class separation</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Cutoff point SumC3C4</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Cutoff point C3C4</bold>
</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0.5pt 0pt;border-style: solid none solid none;" rowspan="1" colspan="1">
<bold>Final cutoff point</bold>
</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">Between Class 1 and Class 2</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">1.22 </td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">0.365</td><td style="text-align:center;vertical-align:middle;border-width:0.5pt 0pt 0pt 0pt;border-style: solid none none none;" rowspan="1" colspan="1">29.91</td></tr><tr><td style="text-align:left;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">Between Class 2 and Class 3</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">1.56 </td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">0.62</td><td style="text-align:center;vertical-align:middle;border-width:0pt 0pt 0.5pt 0pt;border-style: none none solid none;" rowspan="1" colspan="1">39.74</td></tr></tbody></table></table-wrap></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p> The present study aimed to assess skeletal maturation using cervical vertebrae. We gained valuable insights into feature engineering, correlation visualization, model fine-tuning, sensitivity analysis, and classification cutoff points through data analysis and model evaluation. The proposed model achieved 99.49% accuracy and a test set loss of 0.003, outperforming base models. This highlights the effectiveness of combining multiple models to improve skeletal maturation prediction accuracy.</p><p> The relationship between hand-wrist radiographs and skeletal age is well established.<sup><xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R32" ref-type="bibr">32</xref></sup> Kim et al<sup><xref rid="R33" ref-type="bibr">33</xref></sup> found that an ensemble model of eight machine learning models achieved the highest accuracy of 43% in predicting hand-wrist maturation stages based on cervical vertebrae from lateral cephalograms. However, the CVM method on lateral cephalograms is widely recognized as a reliable approach for determining skeletal age.<sup><xref rid="R16" ref-type="bibr">16</xref></sup></p><p> Two studies compared the performance of deep learning models with human visual analysis and reported a low agreement percentage of 58%, possibly due to small sample sizes or the specific AI models used.<sup><xref rid="R34" ref-type="bibr">34</xref>,<xref rid="R35" ref-type="bibr">35</xref></sup> Khazaei et al<sup><xref rid="R29" ref-type="bibr">29</xref></sup> increased the sample size to 1846 patients in a study using CNN models, resulting in a higher agreement percentage. However, the highest accuracy was still relatively low in the three-group classification at 82%. Similarly, Atici et al<sup><xref rid="R28" ref-type="bibr">28</xref></sup> used data augmentation and found their CNN model superior to other deep learning models, but the accuracy remained below 83% for females and 75% for males. In contrast, Seo et al<sup><xref rid="R36" ref-type="bibr">36</xref></sup> achieved a higher average accuracy of 95.6% using a deep learning approach and image segmentation on a relatively large sample size of 900 participants for bone age estimation based on the CVM method. Therefore, one strength of our study is the use of a large sample size and a novel data augmentation approach.</p><p> What sets our study apart is its higher accuracy, using only eight vertebral reference points and four linear measurements. In contrast, Amasya et al<sup><xref rid="R37" ref-type="bibr">37</xref></sup> compared five machine learning models in CVM analysis using 26 marked landmarks and evaluating 54 features on each lateral cephalogram, and their results indicated that ANN had the highest agreement of 86.93% with visual analysis. Additionally, Xie et al<sup><xref rid="R38" ref-type="bibr">38</xref>,<xref rid="R39" ref-type="bibr">39</xref></sup> achieved accuracies of 87% and 88% in two separate studies by considering various parameters such as chronological age, C3 height (H3), and the ratio of posterior height to lower width of C4 (PH4/LW4). K&#x000f6;k et al<sup><xref rid="R40" ref-type="bibr">40</xref></sup> evaluated 24 ANN models with 27 vertebral reference points and 32 linear measurements, with the best model achieving an accuracy of 94.27% using 32 linear measurements and age. The highest accuracy with the fewest linear measurements (13) was 86.87%. Therefore, the advantages of our study include higher accuracy, fewer landmarks, AER function, data augmentation, and feature engineering.</p><p> The results revealed a weak correlation between the &#x0201c;gender&#x0201d; variable and other features, while strong positive correlations were observed among the remaining features. These findings suggest that the &#x0201c;gender&#x0201d; variable may have limited influence on skeletal maturation assessment, while the other features exhibit interdependencies that can be leveraged for accurate evaluation. In this study, we aimed to develop a skeletal maturation assessment model free from gender and age bias. To achieve this, we excluded the gender feature from the model input, as it showed no significant correlation with other factors. Additionally, we removed the age feature to ensure that our model solely relies on the geometric dimensions of the third and fourth vertebrae. Consequently, when the model is deployed in the application software, we may confidently avoid the influence of chronological age on skeletal maturation status, even if an individual presents with a higher chronologic age but has delayed skeletal maturation due to factors such as illness, syndrome, or vitamin D deficiency.<sup><xref rid="R41" ref-type="bibr">41</xref></sup></p><p> We used feature engineering and machine learning techniques to evaluate skeletal maturation based on cervical vertebrae. We focused on the changing dimensions of the third and fourth vertebrae as important features through feature engineering, which may explain the lower accuracies observed in CNN studies. By considering the variability of the anterior border of the third and fourth vertebrae during the 6-stage cervical vertebral maturation process, we emphasized the length features of AH3 and AH4. To standardize radiographs, we used ratios by dividing these values by AP3 and AP4. Consequently, the values of C3 and C4 contain valuable information about skeletal growth features. We also introduced the features SumC3C4 and C3C4 to represent an individual&#x02019;s current peak growth status within a specified range. C3C4 had the most significant impact on the classification model among these features. Multiplying features together may increase their importance, suggesting the advantage of generating new features by combining existing ones in other machine learning studies with numerous features in this field.</p><p> This study introduces a new method for selecting cervical vertebra landmarks, using a simplified process and fewer landmarks. Instead of using many landmarks, we only selected eight landmarks from the cervical vertebrae on lateral cephalometric radiographs, making the process faster and more user-friendly. This approach offers a more efficient alternative to previous machine learning studies on cervical vertebrae. The core of our proposed method is the AER function, which reduces researcher error in landmark selection. We predicted a four-pixel operator error within the AER function. We standardized the width of all cephalometric images while maintaining the aspect ratio and performed landmark selection three times on 20 randomly selected samples. On average, the coordinates of three points for each landmark fell within a four-pixel radius. By automatically executing the AER function, we calculated the values of C3 and C4 a thousand times for each sample. This procedure improved calculation accuracy, reduced bias, and minimized landmark selection errors.</p><p> By maintaining the data distribution, our data augmentation approach effectively generated additional samples, enhancing the diversity present in the data. This approach helped avoid overfitting, enhancing the model&#x02019;s ability to generalize. Additionally, by increasing the quantity of training data within each class, our augmentation method provided the model with more samples to learn from patterns.</p><p> Unlike previous studies, our method eliminated the need to determine the curvature of the inferior border and focused on the correlation between vertebral dimensions and stages of CVM. The classification model used in the study did not rely on chronological age, enhancing confidence in the results&#x02019; validity and accuracy. The study suggested that the optimal timing for growth modification in the CVM method is between CS3 and CS4. However, according to the three-class cervical vertebral maturation method, the middle of group 2 is considered the best treatment timing. This implies that the patient&#x02019;s current skeletal position can be visually represented as resembling Figure S2.</p></sec><sec sec-type="conclusion" id="s5"><title>Conclusion</title><p> The proposed model achieved an accuracy of 99.49% in evaluating skeletal maturation based on cervical vertebrae. Overall, by employing feature engineering, simplified landmark selection, AER function, data augmentation, and the elimination of gender and age features, a model has been developed for accurate assessment of skeletal maturation for clinical applications.</p></sec><sec sec-type="acknowledgments" id="s6"><title>Acknowledgments</title><p> We would like to thank the Dentofacial Deformities Research Center at Shahid Beheshti University of Medical Sciences for their support and contributions to this research. We thank the faculty members, researchers, and staff for their guidance and expertise.</p></sec><sec sec-type="COI-statement" id="s7"><title>Competing Interests</title><p> None.</p></sec><sec sec-type="ethical approval" id="s8"><title>Ethical Approval</title><p> This study was approved by Shahid Beheshti University of Medical Sciences (IR.SBMU.DRC.REC.1402.126).</p></sec><sec sec-type="supplementary-material" id="Suppl"><title>Supplementary File
</title><supplementary-material id="Suppl1" position="float" content-type="local-data"><caption><p>Supplementary file contain Figures S1 and S2.
</p></caption><media xlink:href="joddd-18-232-s001.pdf"/></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="R1"><label>1</label><mixed-citation publication-type="other"> Gabriel DB, Southard KA, Qian F, Marshall SD, Franciscus RG, Southard TE. Cervical vertebrae maturation method: poor reproducibility. Am J Orthod Dentofacial Orthop 2009;136(4):478.e1-478.e7. <pub-id pub-id-type="doi">10.1016/j.ajodo.2007.08.028</pub-id>. </mixed-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cameriere</surname><given-names>R</given-names></name>
<name><surname>Giuliodori</surname><given-names>A</given-names></name>
<name><surname>Zampi</surname><given-names>M</given-names></name>
<name><surname>Gali&#x00107;</surname><given-names>I</given-names></name>
<name><surname>Cingolani</surname><given-names>M</given-names></name>
<name><surname>Pagliara</surname><given-names>F</given-names></name>
<etal/>
</person-group><article-title>Age estimation in children and young adolescents for forensic purposes using fourth cervical vertebra (C4)</article-title><source>Int J Legal Med</source><year>2015</year><volume>129</volume><issue>2</issue><fpage>347</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1007/s00414-014-1112-z</pub-id><pub-id pub-id-type="pmid">25384987</pub-id>
</element-citation></ref><ref id="R3"><label>3</label><mixed-citation publication-type="other"> Hauspie RC, Cameron N, Molinari L. Methods in Human Growth Research. Cambridge University Press; 2004. </mixed-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Thevissen</surname><given-names>PW</given-names></name>
<name><surname>Kaur</surname><given-names>J</given-names></name>
<name><surname>Willems</surname><given-names>G</given-names></name>
</person-group><article-title>Human age estimation combining third molar and skeletal development</article-title><source>Int J Legal Med</source><year>2012</year><volume>126</volume><issue>2</issue><fpage>285</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1007/s00414-011-0639-5</pub-id><pub-id pub-id-type="pmid">22072309</pub-id>
</element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Demirturk Kocasarac</surname><given-names>H</given-names></name>
<name><surname>Altan</surname><given-names>AB</given-names></name>
<name><surname>Yerlikaya</surname><given-names>C</given-names></name>
<name><surname>Sinanoglu</surname><given-names>A</given-names></name>
<name><surname>Noujeim</surname><given-names>M</given-names></name>
</person-group><article-title>Correlation between spheno-occipital synchondrosis, dental age, chronological age and cervical vertebrae maturation in Turkish population: is there a link?</article-title><source>Acta Odontol Scand</source><year>2017</year><volume>75</volume><issue>2</issue><fpage>79</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1080/00016357.2016.1255352</pub-id><pub-id pub-id-type="pmid">27881042</pub-id>
</element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dzemidzic</surname><given-names>V</given-names></name>
<name><surname>Sokic</surname><given-names>E</given-names></name>
<name><surname>Tiro</surname><given-names>A</given-names></name>
<name><surname>Nakas</surname><given-names>E</given-names></name>
</person-group><article-title>Computer based assessment of cervical vertebral maturation stages using digital lateral cephalograms</article-title><source>Acta Inform Med</source><year>2015</year><volume>23</volume><issue>6</issue><fpage>364</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.5455/aim.2015.23.364-368</pub-id><pub-id pub-id-type="pmid">26862247</pub-id>
</element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Sokic</surname><given-names>E</given-names></name>
<name><surname>Tiro</surname><given-names>A</given-names></name>
<name><surname>Sokic-Begovic</surname><given-names>E</given-names></name>
<name><surname>Nakas</surname><given-names>E</given-names></name>
</person-group><article-title>Semi-automatic assessment of cervical vertebral maturation stages using cephalograph images and centroid-based clustering</article-title><source>Acta Stomatol Croat</source><year>2012</year><volume>46</volume><issue>4</issue><fpage>280</fpage><lpage>90</lpage></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cameron</surname><given-names>N</given-names></name>
</person-group><article-title>Can maturity indicators be used to estimate chronological age in children?</article-title><source>Ann Hum Biol</source><year>2015</year><volume>42</volume><issue>4</issue><fpage>302</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.3109/03014460.2015.1032349</pub-id><pub-id pub-id-type="pmid">26073641</pub-id>
</element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chandrasekar</surname><given-names>R</given-names></name>
<name><surname>Chandrasekhar</surname><given-names>S</given-names></name>
<name><surname>Sundari</surname><given-names>KKS</given-names></name>
<name><surname>Ravi</surname><given-names>P</given-names></name>
</person-group><article-title>Development and validation of a formula for objective assessment of cervical vertebral bone age</article-title><source>Prog Orthod</source><year>2020</year><volume>21</volume><issue>1</issue><fpage>38</fpage><pub-id pub-id-type="doi">10.1186/s40510-020-00338-0</pub-id><pub-id pub-id-type="pmid">33043408</pub-id>
</element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Flores-Mir</surname><given-names>C</given-names></name>
<name><surname>Nebbe</surname><given-names>B</given-names></name>
<name><surname>Major</surname><given-names>PW</given-names></name>
</person-group><article-title>Use of skeletal maturation based on hand-wrist radiographic analysis as a predictor of facial growth: a systematic review</article-title><source>Angle Orthod</source><year>2004</year><volume>74</volume><issue>1</issue><fpage>118</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1043/0003-3219(2004)074&#x0003c;0118:Uosmbo&#x0003e;2.0.Co;2</pub-id><pub-id pub-id-type="pmid">15038500</pub-id>
</element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Simmons</surname><given-names>K</given-names></name>
<name><surname>Greulich</surname><given-names>WW</given-names></name>
</person-group><article-title>Menarcheal age and the height, weight, and skeletal age of girls age 7 to 17 years</article-title><source>J Pediatr</source><year>1943</year><volume>22</volume><issue>5</issue><fpage>518</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1016/s0022-3476(43)80022-6</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Baccetti</surname><given-names>T</given-names></name>
<name><surname>Franchi</surname><given-names>L</given-names></name>
<name><surname>McNamara</surname><given-names>JA</given-names></name>
</person-group><article-title>The cervical vertebral maturation (CVM) method for the assessment of optimal treatment timing in dentofacial orthopedics</article-title><source>Semin Orthod</source><year>2005</year><volume>11</volume><issue>3</issue><fpage>119</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1053/j.sodo.2005.04.005</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ferrillo</surname><given-names>M</given-names></name>
<name><surname>Curci</surname><given-names>C</given-names></name>
<name><surname>Roccuzzo</surname><given-names>A</given-names></name>
<name><surname>Migliario</surname><given-names>M</given-names></name>
<name><surname>Invernizzi</surname><given-names>M</given-names></name>
<name><surname>de Sire</surname><given-names>A</given-names></name>
</person-group><article-title>Reliability of cervical vertebral maturation compared to hand-wrist for skeletal maturation assessment in growing subjects: a systematic review</article-title><source>J Back Musculoskelet Rehabil</source><year>2021</year><volume>34</volume><issue>6</issue><fpage>925</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.3233/bmr-210003</pub-id><pub-id pub-id-type="pmid">33998532</pub-id>
</element-citation></ref><ref id="R14"><label>14</label><mixed-citation publication-type="other"> Liu N. Chronological age estimation of lateral cephalometric radiographs with deep learning. ArXiv [Preprint]. January 28, 2021. Available from: <uri xlink:href="https://arxiv.org/abs/2101.11805">https://arxiv.org/abs/2101.11805</uri>. </mixed-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Szemraj</surname><given-names>A</given-names></name>
<name><surname>Wojtaszek-S&#x00142;omi&#x00144;ska</surname><given-names>A</given-names></name>
<name><surname>Racka-Pilszak</surname><given-names>B</given-names></name>
</person-group><article-title>Is the cervical vertebral maturation (CVM) method effective enough to replace the hand-wrist maturation (HWM) method in determining skeletal maturation?-A systematic review</article-title><source>Eur J Radiol</source><year>2018</year><volume>102</volume><fpage>125</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.ejrad.2018.03.012</pub-id><pub-id pub-id-type="pmid">29685525</pub-id>
</element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Baccetti</surname><given-names>T</given-names></name>
<name><surname>Franchi</surname><given-names>L</given-names></name>
<name><surname>McNamara JA</surname><given-names>Jr</given-names></name>
</person-group><article-title>An improved version of the cervical vertebral maturation (CVM) method for the assessment of mandibular growth</article-title><source>Angle Orthod</source><year>2002</year><volume>72</volume><issue>4</issue><fpage>316</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1043/0003-3219(2002)072&#x0003c;0316:Aivotc&#x0003e;2.0.Co;2</pub-id><pub-id pub-id-type="pmid">12169031</pub-id>
</element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hassel</surname><given-names>B</given-names></name>
<name><surname>Farman</surname><given-names>AG</given-names></name>
</person-group><article-title>Skeletal maturation evaluation using cervical vertebrae</article-title><source>Am J Orthod Dentofacial Orthop</source><year>1995</year><volume>107</volume><issue>1</issue><fpage>58</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1016/s0889-5406(95)70157-5</pub-id><pub-id pub-id-type="pmid">7817962</pub-id>
</element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>O&#x02019;Reilly</surname><given-names>MT</given-names></name>
<name><surname>Yanniello</surname><given-names>GJ</given-names></name>
</person-group><article-title>Mandibular growth changes and maturation of cervical vertebrae--a longitudinal cephalometric study</article-title><source>Angle Orthod</source><year>1988</year><volume>58</volume><issue>2</issue><fpage>179</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1043/0003-3219(1988)058&#x0003c;0179:Mgcamo&#x0003e;2.0.Co;2</pub-id><pub-id pub-id-type="pmid">3164596</pub-id>
</element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lee</surname><given-names>JG</given-names></name>
<name><surname>Jun</surname><given-names>S</given-names></name>
<name><surname>Cho</surname><given-names>YW</given-names></name>
<name><surname>Lee</surname><given-names>H</given-names></name>
<name><surname>Kim</surname><given-names>GB</given-names></name>
<name><surname>Seo</surname><given-names>JB</given-names></name>
<etal/>
</person-group><article-title>Deep learning in medical imaging: general overview</article-title><source>Korean J Radiol</source><year>2017</year><volume>18</volume><issue>4</issue><fpage>570</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.3348/kjr.2017.18.4.570</pub-id><pub-id pub-id-type="pmid">28670152</pub-id>
</element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Anthimopoulos</surname><given-names>M</given-names></name>
<name><surname>Christodoulidis</surname><given-names>S</given-names></name>
<name><surname>Ebner</surname><given-names>L</given-names></name>
<name><surname>Christe</surname><given-names>A</given-names></name>
<name><surname>Mougiakakou</surname><given-names>S</given-names></name>
</person-group><article-title>Lung pattern classification for interstitial lung diseases using a deep convolutional neural network</article-title><source>IEEE Trans Med Imaging</source><year>2016</year><volume>35</volume><issue>5</issue><fpage>1207</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1109/tmi.2016.2535865</pub-id><pub-id pub-id-type="pmid">26955021</pub-id>
</element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>H&#x000e4;gg</surname><given-names>U</given-names></name>
<name><surname>Taranger</surname><given-names>J</given-names></name>
</person-group><article-title>Maturation indicators and the pubertal growth spurt</article-title><source>Am J Orthod</source><year>1982</year><volume>82</volume><issue>4</issue><fpage>299</fpage><lpage>309</lpage><pub-id pub-id-type="doi">10.1016/0002-9416(82)90464-x</pub-id><pub-id pub-id-type="pmid">6961802</pub-id>
</element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hunter</surname><given-names>CJ</given-names></name>
</person-group><article-title>The correlation of facial growth with body height and skeletal maturation at adolescence</article-title><source>Angle Orthod</source><year>1966</year><volume>36</volume><issue>1</issue><fpage>44</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1043/0003-3219(1966)036&#x0003c;0044:Tcofgw&#x0003e;2.0.Co;2</pub-id><pub-id pub-id-type="pmid">5218761</pub-id>
</element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>XG</given-names></name>
<name><surname>Lin</surname><given-names>J</given-names></name>
<name><surname>Jiang</surname><given-names>JH</given-names></name>
<name><surname>Wang</surname><given-names>Q</given-names></name>
<name><surname>Ng</surname><given-names>SH</given-names></name>
</person-group><article-title>Validity and reliability of a method for assessment of cervical vertebral maturation</article-title><source>Angle Orthod</source><year>2012</year><volume>82</volume><issue>2</issue><fpage>229</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.2319/051511-333.1</pub-id><pub-id pub-id-type="pmid">21875315</pub-id>
</element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mito</surname><given-names>T</given-names></name>
<name><surname>Sato</surname><given-names>K</given-names></name>
<name><surname>Mitani</surname><given-names>H</given-names></name>
</person-group><article-title>Cervical vertebral bone age in girls</article-title><source>Am J Orthod Dentofacial Orthop</source><year>2002</year><volume>122</volume><issue>4</issue><fpage>380</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1067/mod.2002.126896</pub-id><pub-id pub-id-type="pmid">12411883</pub-id>
</element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Tehranchi</surname><given-names>A</given-names></name>
<name><surname>Mahmoum</surname><given-names>M</given-names></name>
<name><surname>Kavousinejad</surname><given-names>S</given-names></name>
</person-group><article-title>Quantitative determination of skeletal age using cervical vertebral dimensions</article-title><source>Orthod Waves</source><year>2021</year><volume>80</volume><issue>3</issue><fpage>135</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1080/13440241.2021.1952369</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Radwan</surname><given-names>MT</given-names></name>
<name><surname>Sin</surname><given-names>&#x000c7;</given-names></name>
<name><surname>Akkaya</surname><given-names>N</given-names></name>
<name><surname>Vahdettin</surname><given-names>L</given-names></name>
</person-group><article-title>Artificial intelligence-based algorithm for cervical vertebrae maturation stage assessment</article-title><source>Orthod Craniofac Res</source><year>2023</year><volume>26</volume><issue>3</issue><fpage>349</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1111/ocr.12615</pub-id><pub-id pub-id-type="pmid">36259291</pub-id>
</element-citation></ref><ref id="R27"><label>27</label><mixed-citation publication-type="other"> Mohammad-Rahimi H, Nadimi M, Rohban MH, Shamsoddin E, Lee VY, Motamedian SR. Machine learning and orthodontics, current trends and the future opportunities: a scoping review. Am J Orthod Dentofacial Orthop 2021;160(2):170-92.e4. <pub-id pub-id-type="doi">10.1016/j.ajodo.2021.02.013</pub-id>. </mixed-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Atici</surname><given-names>SF</given-names></name>
<name><surname>Ansari</surname><given-names>R</given-names></name>
<name><surname>Allareddy</surname><given-names>V</given-names></name>
<name><surname>Suhaym</surname><given-names>O</given-names></name>
<name><surname>Cetin</surname><given-names>AE</given-names></name>
<name><surname>Elnagar</surname><given-names>MH</given-names></name>
</person-group><article-title>AggregateNet: a deep learning model for automated classification of cervical vertebrae maturation stages</article-title><source>Orthod Craniofac Res</source><year>2023</year><volume>26 Suppl 1</volume><fpage>111</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1111/ocr.12644</pub-id><pub-id pub-id-type="pmid">36855827</pub-id>
</element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Khazaei</surname><given-names>M</given-names></name>
<name><surname>Mollabashi</surname><given-names>V</given-names></name>
<name><surname>Khotanlou</surname><given-names>H</given-names></name>
<name><surname>Farhadian</surname><given-names>M</given-names></name>
</person-group><article-title>Automatic determination of pubertal growth spurts based on the cervical vertebral maturation staging using deep convolutional neural networks</article-title><source>J World Fed Orthod</source><year>2023</year><volume>12</volume><issue>2</issue><fpage>56</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/j.ejwf.2023.02.003</pub-id><pub-id pub-id-type="pmid">36890034</pub-id>
</element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>K&#x000f6;k</surname><given-names>H</given-names></name>
<name><surname>&#x00130;zgi</surname><given-names>MS</given-names></name>
<name><surname>Ac&#x00131;lar</surname><given-names>AM</given-names></name>
</person-group><article-title>Evaluation of the artificial neural network and Naive Bayes models trained with vertebra ratios for growth and development determination</article-title><source>Turk J Orthod</source><year>2021</year><volume>34</volume><issue>1</issue><fpage>2</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.5152/TurkJOrthod.2020.20059</pub-id><pub-id pub-id-type="pmid">33828872</pub-id>
</element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Houston</surname><given-names>WJ</given-names></name>
</person-group><article-title>Relationships between skeletal maturity estimated from hand-wrist radiographs and the timing of the adolescent growth spurt</article-title><source>Eur J Orthod</source><year>1980</year><volume>2</volume><issue>2</issue><fpage>81</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1093/ejo/2.2.81</pub-id><pub-id pub-id-type="pmid">6935063</pub-id>
</element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>&#x0015e;atir</surname><given-names>S</given-names></name>
<name><surname>B&#x000fc;y&#x000fc;k&#x000e7;avu&#x0015f;</surname><given-names>MH</given-names></name>
<name><surname>Sari</surname><given-names>&#x000d6;F</given-names></name>
<name><surname>&#x000c7;imen</surname><given-names>T</given-names></name>
</person-group><article-title>A novel approach to radiographic detection of growth development period with hand-wrist radiographs: a preliminary study with ImageJ imaging software</article-title><source>Orthod Craniofac Res</source><year>2023</year><volume>26</volume><issue>1</issue><fpage>100</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1111/ocr.12584</pub-id><pub-id pub-id-type="pmid">35506492</pub-id>
</element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kim</surname><given-names>DW</given-names></name>
<name><surname>Kim</surname><given-names>J</given-names></name>
<name><surname>Kim</surname><given-names>T</given-names></name>
<name><surname>Kim</surname><given-names>T</given-names></name>
<name><surname>Kim</surname><given-names>YJ</given-names></name>
<name><surname>Song</surname><given-names>IS</given-names></name>
<etal/>
</person-group><article-title>Prediction of hand-wrist maturation stages based on cervical vertebrae images using artificial intelligence</article-title><source>Orthod Craniofac Res</source><year>2021</year><volume>24 Suppl 2</volume><fpage>68</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1111/ocr.12514</pub-id><pub-id pub-id-type="pmid">34405944</pub-id>
</element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Akay</surname><given-names>G</given-names></name>
<name><surname>Akcayol</surname><given-names>MA</given-names></name>
<name><surname>&#x000d6;zdem</surname><given-names>K</given-names></name>
<name><surname>G&#x000fc;ng&#x000f6;r</surname><given-names>K</given-names></name>
</person-group><article-title>Deep convolutional neural network-the evaluation of cervical vertebrae maturation</article-title><source>Oral Radiol</source><year>2023</year><volume>39</volume><issue>4</issue><fpage>629</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1007/s11282-023-00678-7</pub-id><pub-id pub-id-type="pmid">36894716</pub-id>
</element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Amasya</surname><given-names>H</given-names></name>
<name><surname>Cesur</surname><given-names>E</given-names></name>
<name><surname>Y&#x00131;ld&#x00131;r&#x00131;m</surname><given-names>D</given-names></name>
<name><surname>Orhan</surname><given-names>K</given-names></name>
</person-group><article-title>Validation of cervical vertebral maturation stages: artificial intelligence vs human observer visual analysis</article-title><source>Am J Orthod Dentofacial Orthop</source><year>2020</year><volume>158</volume><issue>6</issue><fpage>e173</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.ajodo.2020.08.014</pub-id><pub-id pub-id-type="pmid">33250108</pub-id>
</element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Seo</surname><given-names>H</given-names></name>
<name><surname>Hwang</surname><given-names>J</given-names></name>
<name><surname>Jung</surname><given-names>YH</given-names></name>
<name><surname>Lee</surname><given-names>E</given-names></name>
<name><surname>Nam</surname><given-names>OH</given-names></name>
<name><surname>Shin</surname><given-names>J</given-names></name>
</person-group><article-title>Deep focus approach for accurate bone age estimation from lateral cephalogram</article-title><source>J Dent Sci</source><year>2023</year><volume>18</volume><issue>1</issue><fpage>34</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.jds.2022.07.018</pub-id><pub-id pub-id-type="pmid">36643224</pub-id>
</element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Amasya</surname><given-names>H</given-names></name>
<name><surname>Yildirim</surname><given-names>D</given-names></name>
<name><surname>Aydogan</surname><given-names>T</given-names></name>
<name><surname>Kemaloglu</surname><given-names>N</given-names></name>
<name><surname>Orhan</surname><given-names>K</given-names></name>
</person-group><article-title>Cervical vertebral maturation assessment on lateral cephalometric radiographs using artificial intelligence: comparison of machine learning classifier models</article-title><source>Dentomaxillofac Radiol</source><year>2020</year><volume>49</volume><issue>5</issue><fpage>20190441</fpage><pub-id pub-id-type="doi">10.1259/dmfr.20190441</pub-id><pub-id pub-id-type="pmid">32105499</pub-id>
</element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xie</surname><given-names>L</given-names></name>
<name><surname>Tang</surname><given-names>W</given-names></name>
<name><surname>Izadikhah</surname><given-names>I</given-names></name>
<name><surname>Chen</surname><given-names>X</given-names></name>
<name><surname>Zhao</surname><given-names>Z</given-names></name>
<name><surname>Zhao</surname><given-names>Y</given-names></name>
<etal/>
</person-group><article-title>Intelligent quantitative assessment of skeletal maturation based on multi-stage model: a retrospective cone-beam CT study of cervical vertebrae</article-title><source>Oral Radiol</source><year>2022</year><volume>38</volume><issue>3</issue><fpage>378</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1007/s11282-021-00566-y</pub-id><pub-id pub-id-type="pmid">34554389</pub-id>
</element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xie</surname><given-names>L</given-names></name>
<name><surname>Tang</surname><given-names>W</given-names></name>
<name><surname>Izadikhah</surname><given-names>I</given-names></name>
<name><surname>Zhao</surname><given-names>Z</given-names></name>
<name><surname>Zhao</surname><given-names>Y</given-names></name>
<name><surname>Li</surname><given-names>H</given-names></name>
<etal/>
</person-group><article-title>Development of a multi-stage model for intelligent and quantitative appraising of skeletal maturity using cervical vertebras cone-beam CT images of Chinese girls</article-title><source>Int J Comput Assist Radiol Surg</source><year>2022</year><volume>17</volume><issue>4</issue><fpage>761</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1007/s11548-021-02550-7</pub-id><pub-id pub-id-type="pmid">34982398</pub-id>
</element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>K&#x000f6;k</surname><given-names>H</given-names></name>
<name><surname>Izgi</surname><given-names>MS</given-names></name>
<name><surname>Acilar</surname><given-names>AM</given-names></name>
</person-group><article-title>Determination of growth and development periods in orthodontics with artificial neural network</article-title><source>Orthod Craniofac Res</source><year>2021</year><volume>24 Suppl 2</volume><fpage>76</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1111/ocr.12443</pub-id><pub-id pub-id-type="pmid">33232582</pub-id>
</element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Azarbakhsh</surname><given-names>G</given-names></name>
<name><surname>Iranparvar</surname><given-names>P</given-names></name>
<name><surname>Tehranchi</surname><given-names>A</given-names></name>
<name><surname>Moshfeghi</surname><given-names>M</given-names></name>
</person-group><article-title>Relationship of vitamin D deficiency with cervical vertebral maturation and dental age in adolescents: a cross-sectional study</article-title><source>Int J Dent</source><year>2022</year><volume>2022</volume><fpage>7762873</fpage><pub-id pub-id-type="doi">10.1155/2022/7762873</pub-id><pub-id pub-id-type="pmid">36457845</pub-id>
</element-citation></ref></ref-list></back></article>