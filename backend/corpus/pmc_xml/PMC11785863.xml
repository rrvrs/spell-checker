<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Insights Imaging</journal-id><journal-id journal-id-type="iso-abbrev">Insights Imaging</journal-id><journal-title-group><journal-title>Insights into Imaging</journal-title></journal-title-group><issn pub-type="epub">1869-4101</issn><publisher><publisher-name>Springer Vienna</publisher-name><publisher-loc>Vienna</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39890713</article-id><article-id pub-id-type="pmc">PMC11785863</article-id><article-id pub-id-type="publisher-id">1908</article-id><article-id pub-id-type="doi">10.1186/s13244-025-01908-8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Attitudes of radiologists and interns toward the adoption of GPT-like technologies: a National Survey Study in China</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Xia</surname><given-names>Tianyi</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Zhang</surname><given-names>Shijun</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Ben</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Lei</surname><given-names>Ying</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Xiao</surname><given-names>Zebin</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Bingwei</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Zha</surname><given-names>Junhao</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Yu</surname><given-names>Yaoyao</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Wu</surname><given-names>Zhijun</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Lu</surname><given-names>Chunqiang</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Tang</surname><given-names>Tianyu</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Song</surname><given-names>Yang</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Yuancheng</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5041-7865</contrib-id><name><surname>Ju</surname><given-names>Shenghong</given-names></name><address><email>jsh@seu.edu.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04ct4d772</institution-id><institution-id institution-id-type="GRID">grid.263826.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1761 0489</institution-id><institution>Nurturing Center of Jiangsu Province for State Laboratory of AI Imaging &#x00026; Interventional Radiology (Southeast University), Department of Radiology, Zhongda Hospital, </institution><institution>Medical School of Southeast University, </institution></institution-wrap>Nanjing, China </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00b30xv10</institution-id><institution-id institution-id-type="GRID">grid.25879.31</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8972</institution-id><institution>Department of Biomedical Sciences, </institution><institution>University of Pennsylvania, </institution></institution-wrap>Philadelphia, PA USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04ct4d772</institution-id><institution-id institution-id-type="GRID">grid.263826.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1761 0489</institution-id><institution>Department of Epidemiology and Biostatistics, School of Public Health, </institution><institution>Southeast University, </institution></institution-wrap>Nanjing, China </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.519526.c</institution-id><institution>MR Research Collaboration Team, </institution><institution>Siemens Healthineers Ltd., </institution></institution-wrap>Shanghai, China </aff></contrib-group><pub-date pub-type="epub"><day>31</day><month>1</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>31</day><month>1</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>12</month><year>2025</year></pub-date><volume>16</volume><elocation-id>30</elocation-id><history><date date-type="received"><day>29</day><month>12</month><year>2024</year></date><date date-type="accepted"><day>20</day><month>1</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Objectives</title><p id="Par1">To investigate the attitudes of Chinese radiologists or interns towards generative pre-trained (GPT)-like technologies.</p></sec><sec><title>Methods</title><p id="Par2">A prospective survey was distributed to 1339 Chinese radiologists or interns via an online platform from October 2023 to May 2024. The questionnaire covered respondent characteristics, opinions on using GPT-like technologies (in clinical practice, training and education, environment and regulation, and development trends), and their attitudes toward these technologies. Logistic regression was conducted to identify underlying factors associated with the attitude.</p></sec><sec><title>Results</title><p id="Par3">After quality control, 1289 respondents (median age, 37.0 years [IQR, 31.0&#x02013;44.0 years]; 813 males) were surveyed. Most of the respondents (<italic>n</italic>&#x02009;=&#x02009;1223, 94.9%) supported adoption of GPT-like technologies. Based on the acceptance level of GPT-like technologies, the respondents were 3 (0.2%), 29 (2.2%), 352 (27.3%), 677 (52.5%), and 228 (17.7%) from low to high acceptance degrees. Multivariable analysis revealed significant associations between positive attitudes towards GPT-like technologies and their acceptance: writing papers and language polishing (odds ratio [OR]&#x02009;=&#x02009;1.99; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), influence of colleagues using such technologies (OR&#x02009;=&#x02009;1.77; <italic>p</italic>&#x02009;=&#x02009;0.007), government regulation introduction (OR&#x02009;=&#x02009;2.25; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), and enhancement of decision support capabilities (OR&#x02009;=&#x02009;2.67; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Sensitivity analyses confirmed these results for different acceptance thresholds (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p></sec><sec><title>Conclusions</title><p id="Par4">Chinese radiologists or interns generally support GPT-like technologies due to their potential capabilities in clinical practice, medical education, and scientific research. They also emphasize the need for regulatory oversight and remain optimistic about their future medical applications.</p></sec><sec><title>Critical relevance statement</title><p id="Par5">This study highlights the broad support among Chinese radiologists for GPT-like technologies, emphasizing their potential to enhance clinical decision-making, streamline medical education, and improve research efficiency, while underscoring the need for regulatory oversight.</p></sec><sec><title>Key Points</title><p id="Par6">
<list list-type="bullet"><list-item><p id="Par7">The impact of GPT-like technologies on the radiology field is unclear.</p></list-item><list-item><p id="Par8">Most Chinese radiologists express the supportive adoption of GPT-like technologies.</p></list-item><list-item><p id="Par9">GPT-like technologies&#x02019; capabilities at research and clinic prompt the attitude.</p></list-item></list>
</p></sec><sec><title>Graphical Abstract</title><p id="Par10">
<graphic position="anchor" xlink:href="13244_2025_1908_Figa_HTML" id="d33e290"/>
</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Radiologists</kwd><kwd>Attitude</kwd><kwd>Surveys and questionnaires</kwd><kwd>Natural language processing</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>823B2040</award-id><award-id>92359304</award-id><award-id>82330060</award-id><award-id>82427803</award-id><award-id>82371940</award-id><principal-award-recipient><name><surname>Xia</surname><given-names>Tianyi</given-names></name><name><surname>Lu</surname><given-names>Chunqiang</given-names></name><name><surname>Ju</surname><given-names>Shenghong</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; European Society of Radiology (ESR) 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par14">The series of ChatGPT (e.g., GPT-3.5 and GPT-4) and other tools based on large language models (LLMs) have initiated the latest wave of chatbots, impacting numerous industries. These powerful chatbots, designed to interpret, generate, and effectively converse with humans, are referred to as GPT (generative pre-trained)-like technologies, such as ChatGPT, Claude, and Google Bard. The development and refining of LLMs have also significantly impacted the field of healthcare [<xref ref-type="bibr" rid="CR1">1</xref>]. The potential applications of GPT-like technologies in healthcare have garnered significant attention, particularly in areas such as scientific writing and medical education [<xref ref-type="bibr" rid="CR2">2</xref>&#x02013;<xref ref-type="bibr" rid="CR4">4</xref>].</p><p id="Par15">Healthcare is inundated with large amounts of free-text reports, such as radiological reports, which place a significant burden on radiologists. The inconsistencies in style and structure result in variability and complexity in radiological reports, hindering effective communication of information among various medical departments [<xref ref-type="bibr" rid="CR5">5</xref>]. GPT-like technologies have shown great potential in structuring and correcting errors in free-text radiological reports and providing therapeutic suggestions through these reports [<xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR9">9</xref>]. Recently, positive conclusions regarding the detection of radiological findings in chest radiographs using GPT-4 with vision capabilities have demonstrated its immense potential in the department of radiology [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>]. Therefore, GPT-like technologies have the potential to support clinical workflow, scientific research, and educational applications in the field of radiology [<xref ref-type="bibr" rid="CR3">3</xref>].</p><p id="Par16">However, ChatGPT-like technologies have not been universally successful across all domains. Some studies indicate that, while GPT-4 demonstrated moderate agreement with human-assigned breast nodule categories, it still produced a high percentage of discordant results, potentially impacting clinical decision-making [<xref ref-type="bibr" rid="CR12">12</xref>]. Furthermore, while GPT-like models excelled in text-based tasks, issues such as repeatability, demographic biases, and challenges in interpreting radiologic images persisted [<xref ref-type="bibr" rid="CR13">13</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref>]. These limitations underscored critical areas for improvement, highlighting the need for further development before clinical implementation.</p><p id="Par17">The rapid growth of interest in GPT-like technologies in healthcare raised several challenges, particularly regarding ethical concerns and potential risks building on this controversial evidence, such as misdiagnosis or missed diagnoses [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Currently, the acceptance and understanding of GPT-like technologies among radiologists are still unclear and need further investigation, which may influence the future deployment of these technologies in the field of radiology. The Zhongda Radiology Alliance, established in 2019, is a collaborative network of radiology academic centers. As of the time of our survey, it includes 264 hospitals across 31 of China&#x02019;s 34 provinces. Conducting this survey within the framework of the Zhongda Radiology Alliance ensures a highly representative sample of the Chinese radiology community.</p><p id="Par18">Therefore, our study aimed to conduct a comprehensive national survey to elucidate the attitudes and possible influencing factors of Chinese radiologists or interns regarding the use of GPT-like technologies in their clinical practice, medical education, and scientific research.</p></sec><sec id="Sec2" sec-type="materials|methods"><title>Materials and methods</title><p id="Par19">This cross-sectional study was approved by the research ethics board and informed consent was acquired from all participants. The study was conducted in accordance with both the Declarations of Helsinki and Istanbul. This study adheres to the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) reporting guideline.</p><sec id="Sec3"><title>Survey time and procedure</title><p id="Par20">The survey was conducted from October 2023 to May 2024. Questionnaires were distributed to members of the Zhongda Radiology Alliance via the survey platform <italic>Wenjuanxing</italic> (<ext-link ext-link-type="uri" xlink:href="https://www.wjx.cn/">https://www.wjx.cn/</ext-link>) in China. The questionnaires were forwarded to radiologists or interns willing to participate through the directors of the department of radiology. Standard instructions for the questionnaire survey were provided, and appointed people were assigned to be responsible for the distribution, and quality control of the questionnaires. The questionnaires were anonymous, and all items were mandatory to complete.</p></sec><sec id="Sec4"><title>Questionnaire formulation and survey respondents</title><p id="Par21">The questionnaire was designed after repeated discussions and revisions by hospital management experts, senior radiology experts, and artificial intelligence (AI) algorithm experts (the questionnaire was detailed in Supplemental Materials). The questionnaire comprised three parts. Part-A: basic information included gender, age, province of workplace, hospital level, working history, professional title, scientific research pressure, experience with GPT-like technologies, familiarity with AI, and familiarity with GPT-like technologies. Part B: options on GPT-like technologies, in which the respondents rated their opinion on a Likert scale from 1 (very poor) to 5 (very good) concerning GPT-like technologies in clinical practice (10 items), training and education (9 items), environment and regulation (6 items), and development trends (5 items). Besides, Part C consisted of 2 key questions: 1. Without considering policies and costs, would you be willing to try or continue using GPT-like technologies? (would not; would); and 2. Would you be willing to try or continue using GPT-like technologies? (definitely would not; probably would not; neutral; probably would; definitely would).</p><p id="Par22">All participants completed the survey anonymously without the collection of any identifiers. The respondents were radiologists with registered physician qualifications or interns majoring in radiology in mainland China. A total of 1340 respondents were members of the Zhongda Radiology Alliance from 197 hospitals. For quality control, we empirically excluded the 50 respondents who completed the questionnaire in less than 3&#x02009;min (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). The primary outcome of this study was attitudes toward the adoption of GPT-like technologies, and the secondary outcome was to explore the factors that affect the attitudes.<fig id="Fig1"><label>Fig. 1</label><caption><p>The process and analysis of the survey study</p></caption><graphic xlink:href="13244_2025_1908_Fig1_HTML" id="d33e407"/></fig></p></sec><sec id="Sec5"><title>Statistical analysis</title><p id="Par23">Results conforming to a normal distribution were expressed as mean and standard deviation, while categorical data were presented as frequencies and percentages. Results conforming to a non-normal distribution and ordered categorical data were expressed as the median and interquartile range (IQR). The Mann&#x02013;Whitney <italic>U</italic>-test, or Chi-square test was performed based on the variable type. Correlations between ordered categorical variables were assessed using Spearman correlation analysis. Univariable and multivariable logistic regression was conducted to identify independent factors, presented with odds ratios (OR) and 95% confidence interval (CI). Variables with a <italic>p</italic> value&#x02009;&#x0003c;&#x02009;0.1 and potential bias in the univariate logistic regression analysis were included in the multivariable analysis. The multivariable logistic regression analysis was applied to identify factors associated with radiologists&#x02019; attitudes toward the acceptance of GPT-like technologies, using the minimum value of the Akaike Information Criterion. Additionally, stratified analysis was performed as a sensitivity analysis to control the effect of confounders with potential bias.</p><p id="Par24">For sensitivity analysis, we re-divided the acceptance level of GPT-like technologies into two groups: 1&#x02013;3 degrees vs 4&#x02013;5 degrees, and 1&#x02013;4 degrees vs 5 degrees. Multivariable logistic regression analysis was performed as described above for overall items and each of the four dimensions: clinical practice, training and education, environment and regulation, and development tendency. All <italic>p</italic> values were two-sided, and significance was set at <italic>p</italic> value&#x02009;&#x0003c;&#x02009;0.05. Survey data were analyzed using SPSS statistical software version 27.0 (IBM).</p></sec></sec><sec id="Sec6" sec-type="results"><title>Results</title><sec id="Sec7"><title>Characteristics of the respondents</title><p id="Par25">The study ultimately enrolled 1289 respondents after excluding 50 respondents due to quality control. All respondents completed the survey, and the response rate reached 96.3% without 50 unqualified questionnaires. The respondents were from 197 hospitals in 27 provinces, with a median age of 37.0 years (IQR, 31.0&#x02013;44.0 years) and a median working history of 12 years (IQR, 7&#x02013;21 years). Among them, 813 were males. A majority of respondents (1066, 82.7%) were from tertiary hospitals. The professional titles were distributed as follows: 438 (34.0%) were associate chief or chief radiologists, 508 (39.4%) were attending radiologists, and 343 (26.6%) were interns or residents. Notably, 125 respondents (9.7%) reported prior experience with GPT-like technologies. Respondents experiencing greater scientific research pressure (<italic>p</italic>&#x02009;=&#x02009;0.03), having a longer working history (<italic>p</italic>&#x02009;=&#x02009;0.04), or holding higher professional titles (<italic>p</italic>&#x02009;=&#x02009;0.02) were more likely to try and continue using GPT-like technologies. One thousand two hundred twenty-three (94.9%) respondents expressed support for GPT-like technologies (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2A</xref>). Based on the acceptance level, the respondents were distributed as 3 (0.2%), 29 (2.2%), 352 (27.3%), 677 (52.5%), and 228 (17.7%) from low to high acceptance degrees of GPT-like technologies (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2B</xref>). Detailed characteristics of the respondents are provided in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>.<fig id="Fig2"><label>Fig. 2</label><caption><p>Bar graphs depicting respondents&#x02019; attitudes toward the adoption of GPT-like technologies based on two key questions (Supplemental Materials). <bold>A</bold> represents attitudes categorized into two categories, while <bold>B</bold> represents attitudes based on a 5-point ordinal scale. GPT, generative pre-trained</p></caption><graphic xlink:href="13244_2025_1908_Fig2_HTML" id="d33e464"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Characteristics of the respondents (<italic>n</italic>&#x02009;=&#x02009;1289)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Characteristics</th><th>Respondents (<italic>n</italic>&#x02009;=&#x02009;1289)</th><th>Opponents (<italic>n</italic>&#x02009;=&#x02009;66)</th><th>Supporters (<italic>n</italic>&#x02009;=&#x02009;1223)</th><th><italic>p</italic> value</th></tr></thead><tbody><tr><td>Sex</td><td/><td/><td/><td>0.53</td></tr><tr><td>&#x02003;Female</td><td>476 (36.9)</td><td>22 (33.3)</td><td>454 (37.1)</td><td/></tr><tr><td>&#x02003;Male</td><td>813 (63.1)</td><td>44 (66.7)</td><td>769 (62.9)</td><td/></tr><tr><td>Age (years)<sup>*</sup></td><td>37.0 (31.0&#x02013;44.0)</td><td>35.0 (29.8&#x02013;40.0)</td><td>37.0 (31.0&#x02013;44.0)</td><td>0.051<sup>&#x02020;</sup></td></tr><tr><td>Region</td><td/><td/><td/><td>0.42</td></tr><tr><td>&#x02003;Northeast</td><td>59 (4.6)</td><td>3 (4.5)</td><td>56 (4.6)</td><td/></tr><tr><td>&#x02003;North</td><td>136 (10.6)</td><td>9 (13.6)</td><td>127 (10.4)</td><td/></tr><tr><td>&#x02003;East</td><td>459 (35.6)</td><td>15 (22.7)</td><td>444 (36.3)</td><td/></tr><tr><td>&#x02003;Southern</td><td>30 (2.3)</td><td>1 (1.5)</td><td>29 (2.4)</td><td/></tr><tr><td>&#x02003;Central</td><td>158 (12.3)</td><td>11 (16.7)</td><td>147 (12)</td><td/></tr><tr><td>&#x02003;Northwest</td><td>58 (4.5)</td><td>3 (4.5)</td><td>55 (4.5)</td><td/></tr><tr><td>&#x02003;Southwest</td><td>389 (30.2)</td><td>24 (36.4)</td><td>365 (29.8)</td><td/></tr><tr><td>Hospital level</td><td/><td/><td/><td>0.13</td></tr><tr><td>&#x02003;Tertiary</td><td>1066 (82.7)</td><td>50 (75.8)</td><td>1016 (83.1)</td><td/></tr><tr><td>&#x02003;Others</td><td>223 (17.3)</td><td>16 (24.2)</td><td>207 (16.9)</td><td/></tr><tr><td>Working history (years)<sup>*</sup></td><td>12.0 (7.0&#x02013;21.0)</td><td>10.0 (6.0&#x02013;17.0)</td><td>12.0 (7.0&#x02013;21.0)</td><td>0.04<sup>&#x02020;</sup></td></tr><tr><td>Professional title</td><td/><td/><td/><td>0.02<sup>&#x02020;</sup></td></tr><tr><td>&#x02003;Intern or resident</td><td>343 (26.6)</td><td>23 (34.8)</td><td>320 (26.2)</td><td/></tr><tr><td>&#x02003;Attending</td><td>508 (39.4)</td><td>29 (43.9)</td><td>479 (39.2)</td><td/></tr><tr><td>&#x02003;Associate chief or chief</td><td>438 (34.0)</td><td>14 (21.2)</td><td>424 (34.7)</td><td/></tr><tr><td>Academic pressure</td><td/><td/><td/><td>0.24<sup>&#x02020;</sup></td></tr><tr><td>&#x02003;None</td><td>269 (20.9)</td><td>21 (31.8)</td><td>248 (20.3)</td><td/></tr><tr><td>&#x02003;Mild</td><td>249 (19.3)</td><td>7 (10.6)</td><td>242 (19.8)</td><td/></tr><tr><td>&#x02003;Moderate</td><td>367 (28.5)</td><td>21 (31.8)</td><td>346 (28.3)</td><td/></tr><tr><td>&#x02003;Moderately severe</td><td>186 (14.4)</td><td>6 (9.1)</td><td>180 (14.7)</td><td/></tr><tr><td>&#x02003;Severe</td><td>218 (16.9)</td><td>11 (16.7)</td><td>207 (16.9)</td><td/></tr><tr><td>Used experience with GPT-like technologies</td><td/><td/><td/><td>0.86</td></tr><tr><td>&#x02003;Yes</td><td>125 (9.7)</td><td>6 (9.1)</td><td>119 (9.7)</td><td/></tr><tr><td>&#x02003;No</td><td>1164 (90.3)</td><td>60 (90.9)</td><td>1104 (90.3)</td><td/></tr><tr><td>Knowledge of NLP or AI technologies</td><td/><td/><td/><td>0.27<sup>&#x02020;</sup></td></tr><tr><td>&#x02003;No understanding</td><td>110 (8.5)</td><td>9 (13.6)</td><td>101 (8.3)</td><td/></tr><tr><td>&#x02003;Limited understanding</td><td>291 (22.6)</td><td>16 (24.2)</td><td>275 (22.5)</td><td/></tr><tr><td>&#x02003;Basic understanding</td><td>425 (33.0)</td><td>19 (28.8)</td><td>406 (33.2)</td><td/></tr><tr><td>&#x02003;Good understanding</td><td>456 (35.4)</td><td>22 (33.3)</td><td>434 (35.5)</td><td/></tr><tr><td>&#x02003;Excellent understanding</td><td>7 (0.5)</td><td>0 (0.0)</td><td>7 (0.6)</td><td/></tr><tr><td>Knowledge of GPT-like technologies</td><td/><td/><td/><td>0.29<sup>&#x02020;</sup></td></tr><tr><td>&#x02003;No understanding</td><td>218 (16.9)</td><td>16 (24.2)</td><td>202 (16.5)</td><td/></tr><tr><td>&#x02003;Limited understanding</td><td>556 (43.1)</td><td>24 (36.4)</td><td>532 (43.5)</td><td/></tr><tr><td>&#x02003;Basic understanding</td><td>427 (33.1)</td><td>25 (37.9)</td><td>402 (32.9)</td><td/></tr><tr><td>&#x02003;Good understanding</td><td>62 (4.8)</td><td>0 (0.0)</td><td>62 (5.1)</td><td/></tr><tr><td>&#x02003;Excellent understanding</td><td>26 (2.0)</td><td>1 (1.5)</td><td>25 (2.0)</td><td/></tr><tr><td>Acceptance level of GPT-like technologies</td><td/><td/><td/><td>&#x0003c;&#x02009;0.001<sup>&#x02020;</sup></td></tr><tr><td>&#x02003;Definitely would not</td><td>3 (0.2)</td><td>3 (4.5)</td><td>0 (0.0)</td><td/></tr><tr><td>&#x02003;Probably would not</td><td>29 (2.2)</td><td>8 (12.1)</td><td>21 (1.7)</td><td/></tr><tr><td>&#x02003;Neutral</td><td>352 (27.3)</td><td>45 (68.2)</td><td>307 (25.1)</td><td/></tr><tr><td>&#x02003;Probably would</td><td>677 (52.5)</td><td>10 (15.2)</td><td>667 (54.5)</td><td/></tr><tr><td>&#x02003;Definitely would</td><td>228 (17.7)</td><td>0 (0.0)</td><td>228 (18.6)</td><td/></tr></tbody></table><table-wrap-foot><p>Unless otherwise specified, data are numbers of patients, with percentages in parentheses</p><p><italic>AI</italic> artificial intelligence, <italic>GPT</italic> generative pre-trained, <italic>NLP</italic> natural language processing</p><p><sup>*</sup> Data are medians, with IQRs in parentheses</p><p><sup>&#x02020;</sup>
<italic>p</italic> value calculated by Mann&#x02013;Whitney <italic>U</italic>-test</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec8"><title>Attitudes of the respondents toward the acceptance of GPT-like technologies</title><p id="Par26">The distribution of responses to 30 questions (Q1&#x02013;Q30) from Part B of the questionnaire, which pertains to the attitudes of respondents towards GPT-like technologies, is presented in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>. The majority of items showed a clear trend where most respondents chose either a positive response (4&#x02013;5 degrees) or a neutral response (3 degrees), indicating overall optimistic opinions regarding the potential capabilities of GPT-like technologies. Differences in attitudes towards GPT-like technologies between the opponents and supporters were observed in most items from Part B (Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>). Additionally, correlation analysis showed positive correlations between a majority of items and attitudes toward GPT-like technologies (Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">2</xref>).<fig id="Fig3"><label>Fig. 3</label><caption><p>The acceptance of GPT-like technologies distribution of respondents&#x02019; answers to questions 1&#x02013;30 from Part B of the questionnaire. Bar graphs show a positive trend where the majority of respondents chose a positive or neutral response (3&#x02013;5 degrees) at most items. Details of the questions can be found in Supplemental Materials. GPT, generative pre-trained</p></caption><graphic xlink:href="13244_2025_1908_Fig3_HTML" id="d33e1027"/></fig></p><p id="Par27">Univariable binary logistic regression analysis comprehensively assessed the possible factors associated with radiologists&#x02019; acceptance of GPT-like technologies. Our findings revealed that a longer working history was significantly associated with higher acceptance rates (OR&#x02009;=&#x02009;1.03; 95% CI: 1.00, 1.06; <italic>p</italic>&#x02009;=&#x02009;0.03), indicating that more experienced radiologists may be more willing to adopt GPT-like technologies. Furthermore, the univariable analysis showed that respondents&#x02019; positive attitudes towards GPT-like technologies were influenced by optimistic opinions in the four dimensions of clinical practice, training and education, environment and regulation, and development tendency (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>).<table-wrap id="Tab2"><label>Table 2</label><caption><p>Binary logistic regression analysis of variables for the association with acceptance of GPT-like technologies (<italic>n</italic>&#x02009;=&#x02009;1289)</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Factors<sup>*</sup></th><th colspan="2">Univariable analysis</th><th colspan="2">Multivariable analysis</th></tr><tr><th>OR (95% CI)</th><th><italic>p</italic> value</th><th>OR (95% CI)</th><th><italic>p</italic> value</th></tr></thead><tbody><tr><td>Age (years)</td><td>1.03 (0.99, 1.06)</td><td>0.06</td><td/><td/></tr><tr><td>Working history (years)</td><td>1.03 (1.00, 1.06)</td><td>0.03</td><td/><td/></tr><tr><td>Q1 (Assisting in writing radiological reports)</td><td>1.78 (1.27, 2.47)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q2 (Improving doctor-patient communication)</td><td>1.35 (0.99, 1.83)</td><td>0.06</td><td/><td/></tr><tr><td>Q3 (Improving patient triage and treatment)</td><td>1.61 (1.19, 2.17)</td><td>0.002</td><td/><td/></tr><tr><td>Q4 (Impact on the radiology department)</td><td>1.70 (1.24, 2.32)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q5 (Using in emergencies)</td><td>1.65 (1.19, 2.27)</td><td>0.003</td><td/><td/></tr><tr><td>Q6 (Producing misleading diagnostic results)</td><td>1.04 (0.74, 1.47)</td><td>0.82</td><td/><td/></tr><tr><td>Q7 (Role in medical image diagnosis)</td><td>1.67 (1.22, 2.30)</td><td>0.002</td><td/><td/></tr><tr><td>Q8 (Providing personalized treatment advice)</td><td>1.58 (1.15, 2.17)</td><td>0.005</td><td/><td/></tr><tr><td>Q9 (Reducing the radiological reporting writing time)</td><td>1.67 (1.18, 2.34)</td><td>0.004</td><td/><td/></tr><tr><td>Q10 (Improving efficiency in radiology emergency shifts)</td><td>2.16 (1.56, 2.99)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q11 (Accurate medical information)</td><td>1.87 (1.21, 2.89)</td><td>0.005</td><td/><td/></tr><tr><td>Q12 (Diagnostic advice in rare or complex cases)</td><td>1.35 (1.01, 1.81)</td><td>0.045</td><td/><td/></tr><tr><td>Q13 (Improving radiology education effectiveness)</td><td>1.72 (1.23, 2.38)</td><td>0.001</td><td/><td/></tr><tr><td>Q14 (Writing papers and language polishing)</td><td>3.36 (2.56, 4.41)</td><td>&#x0003c;&#x02009;0.001</td><td>1.99 (1.34, 2.95)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>Q15 (Designing research topics)</td><td>2.62 (2.01, 3.42)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q16 (Designing patents)</td><td>2.30 (1.79, 2.96)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q17 (Editing research and statistics code)</td><td>2.65 (2.03, 3.46)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q18 (Enhancing disease understanding)</td><td>3.99 (2.87, 5.54)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q19 (GPT-like tech training in medical education)</td><td>2.69 (2.04, 3.56)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q20 (Leading to medical disputes)</td><td>0.90 (0.69, 1.17)</td><td>0.43</td><td/><td/></tr><tr><td>Q21 (Threat to radiologists&#x02019; jobs)</td><td>1.11 (0.85, 1.46)</td><td>0.44</td><td/><td/></tr><tr><td>Q22 (Privacy leak of patients)</td><td>1.03 (0.77, 1.37)</td><td>0.87</td><td/><td/></tr><tr><td>Q23 (Effect of colleagues using)</td><td>3.30 (2.47, 4.41)</td><td>&#x0003c;&#x02009;0.001</td><td>1.77 (1.17, 2.68)</td><td>0.007</td></tr><tr><td>Q24 (Introducing regulation from the government)</td><td>3.65 (2.66, 5.02)</td><td>&#x0003c;&#x02009;0.001</td><td>2.25 (1.56, 3.22)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>Q25 (Supervising in medicine)</td><td>1.79 (1.34, 2.35)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q26 (Widely used in hospitals in the future)</td><td>1.74 (1.26, 2.41)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>Q27 (Impact on doctors&#x02019; employment)</td><td>1.19 (0.91, 1.56)</td><td>0.20</td><td/><td/></tr><tr><td>Q28 (Application in the medicine in next decade)</td><td>1.56 (1.17, 2.08)</td><td>0.003</td><td/><td/></tr><tr><td>Q29 (Enhancing decision support capabilities)</td><td>5.01 (3.40, 7.36)</td><td>&#x0003c;&#x02009;0.001</td><td>2.67 (1.58, 4.49)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>Q30 (Application in the medical industry)</td><td>3.95 (2.67, 5.84)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr></tbody></table><table-wrap-foot><p>Unless otherwise specified, Data in parentheses are 95% CIs. The multivariable analysis included variables with a <italic>p</italic> value&#x02009;&#x0003c;&#x02009;0.1 and potential bias (used experience with GPT-like technologies, knowledge of NLP/AI technologies and GPT-like technologies)</p><p><italic>AI</italic> artificial intelligence, <italic>CI</italic> confidence interval, <italic>GPT</italic> generative pre-trained, <italic>NLP</italic> natural language processing, <italic>OR</italic> odds ratio</p><p><sup>*</sup> Summary of the item are shown in parentheses, the details of the items can be found in the Supplementary File</p></table-wrap-foot></table-wrap></p><p id="Par28">After adjusting other factors with <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.1, the multivariable binary logistic regression analysis identified several key questions associated with the acceptance of GPT-like technologies: Q14 (Writing papers and language polishing) (OR&#x02009;=&#x02009;1.99; 95% CI: 1.34, 2.95; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), Q23 (Effect of colleagues using) (OR&#x02009;=&#x02009;1.77; 95% CI: 1.17, 2.68; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.007), Q24 (Introducing regulation from the government) (OR&#x02009;=&#x02009;2.25; 95% CI: 1.56, 3.22; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), and Q29 (Enhancing decision support capabilities) (OR&#x02009;=&#x02009;2.67; 95% CI: 1.58, 4.49; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Figure&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> displays a histogram comparing responses to these four questions between supporters and opponents of GPT-like technologies.<fig id="Fig4"><label>Fig. 4</label><caption><p>Bar graphs show the cumulative percentage of respondents&#x02019; answers to questions 14, 23, 24, and 29. As the response level increases to these questions, the support tendency for GPT-like technologies increases (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Details of questions 14, 23, 24, and 29 can be found in Supplemental Materials. GPT, generative pre-trained</p></caption><graphic xlink:href="13244_2025_1908_Fig4_HTML" id="d33e1431"/></fig></p><p id="Par29">To more accurately describe the acceptance of GPT-like technologies, we included two questions with 2 and 5 categories for acceptance level. The relationship between these two key questions is shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> and Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Sensitivity analyses were conducted to gain deeper insights into the factors associated with acceptance level. Regardless of whether the acceptance was categorized as 1&#x02013;3 degrees vs 4&#x02013;5 degrees or 1&#x02013;4 degrees vs 5 degrees, the four items (Q14, Q23, Q24, and Q29) were still the independent factors associated with higher acceptance levels in multivariable analysis (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) (Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>). Given the experience of use experience of GPT-like technologies and the level of knowledge about AI and GPT-like technologies, there may be potential bias. In the subgroup analysis, all four items (Q14, Q23, Q24, and Q29) demonstrated a significant positive association across all groups, as detailed in Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref>.<fig id="Fig5"><label>Fig. 5</label><caption><p>Bar graphs show the cumulative percentage between the key questions about the acceptance and acceptance level of GPT-like technologies (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). GPT, generative pre-trained</p></caption><graphic xlink:href="13244_2025_1908_Fig5_HTML" id="d33e1463"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>Binary logistic regression analysis of variables for the association with an acceptance level of GPT-like technologies at questions 14, 23, 24, and 29 (<italic>n</italic>&#x02009;=&#x02009;1289)</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Factors<sup>*</sup></th><th colspan="4">Acceptance level (1&#x02013;3 degrees vs 4&#x02013;5 degrees)</th><th colspan="4">Acceptance level (1&#x02013;4 degrees vs 5 degrees)</th></tr><tr><th colspan="2">Univariable analysis</th><th colspan="2">Multivariable analysis</th><th colspan="2">Univariable analysis</th><th colspan="2">Multivariable analysis</th></tr><tr><th>OR (95% CI)</th><th><italic>p</italic> value</th><th>OR (95% CI)</th><th><italic>p</italic> value</th><th>OR (95% CI)</th><th><italic>p</italic> value</th><th>OR (95% CI)</th><th><italic>p</italic> value</th></tr></thead><tbody><tr><td>Q14</td><td>5.07 (4.05, 6.35)</td><td>&#x0003c;&#x02009;0.001</td><td>1.84 (1.41, 2.41)</td><td>&#x0003c;&#x02009;0.001</td><td>9.27 (6.51, 13.21)</td><td>&#x0003c;&#x02009;0.001</td><td>2.02 (1.35, 3.03)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>Q23</td><td>17.00 (12.59, 22.97)</td><td>&#x0003c;&#x02009;0.001</td><td>8.47 (6.17, 11.61)</td><td>&#x0003c;&#x02009;0.001</td><td>25.50 (17.58, 36.99)</td><td>&#x0003c;&#x02009;0.001</td><td>12.50 (8.30, 18.84)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>Q24</td><td>3.94 (3.18, 4.87)</td><td>&#x0003c;&#x02009;0.001</td><td>2.11 (1.61, 2.78)</td><td>&#x0003c;&#x02009;0.001</td><td>5.64 (4.25, 7.47)</td><td>&#x0003c;&#x02009;0.001</td><td>1.92 (1.33, 2.77)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>Q29</td><td>6.21 (4.86, 7.94)</td><td>&#x0003c;&#x02009;0.001</td><td>2.50 (1.84, 3.41)</td><td>&#x0003c;&#x02009;0.001</td><td>7.75 (5.70, 10.53)</td><td>&#x0003c;&#x02009;0.001</td><td>2.11 (1.45, 3.06)</td><td>&#x0003c;&#x02009;0.001</td></tr></tbody></table><table-wrap-foot><p>Unless otherwise specified, Data in parentheses are 95% CIs</p><p><italic>CI</italic> confidence interval, <italic>GPT</italic> generative pre-trained, <italic>OR</italic> odds ratio</p><p><sup>*</sup> The details of questions 14, 23, 24, and 29 can be found in the Supplementary File</p></table-wrap-foot></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Binary logistic regression analysis of variables for the association with acceptance of GPT-like technologies at questions 14, 23, 24, and 29 in different subgroups (<italic>n</italic>&#x02009;=&#x02009;1289)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Subgroup</th><th>Q14 OR (95% CI)</th><th>Q23 OR (95% CI)</th><th>Q24 OR (95% CI)</th><th>Q29 OR (95% CI)</th></tr></thead><tbody><tr><td colspan="5">Used experience with GPT-like technologies</td></tr><tr><td>&#x02003;Yes</td><td>3.36 (1.28, 8.82)</td><td>2.63 (1.07, 6.49)</td><td>3.61 (1.35, 9.66)</td><td>6.61 (1.65, 26.55)</td></tr><tr><td>&#x02003;No</td><td>3.36 (2.53, 4.47)</td><td>3.38 (2.49, 4.60)</td><td>3.66 (2.62, 5.12)</td><td>4.88 (3.27, 7.29)</td></tr><tr><td colspan="5">Knowledge of NLP or AI technologies</td></tr><tr><td>&#x02003;No to limited understanding</td><td>3.60 (2.25, 5.77)</td><td>3.15 (1.95, 5.09)</td><td>3.01 (1.80, 5.04)</td><td>4.39 (2.34, 8.14)</td></tr><tr><td>&#x02003;Basic to excellent understanding</td><td>3.23 (2.30, 4.52)</td><td>3.37 (2.34, 4.85)</td><td>4.05 (2.70, 6.07)</td><td>5.37 (3.28, 8.81)</td></tr><tr><td colspan="5">Knowledge of GPT-like technologies</td></tr><tr><td>&#x02003;No to limited understanding</td><td>3.62 (2.50, 5.24)</td><td>3.28 (2.28, 4.72)</td><td>2.94 (1.89, 4.56)</td><td>4.92 (2.98, 8.12)</td></tr><tr><td>&#x02003;Basic to excellent understanding</td><td>3.07 (2.04, 4.61)</td><td>3.36 (2.07, 5.44)</td><td>4.68 (2.90, 7.57)</td><td>5.14 (2.81, 9.43)</td></tr></tbody></table><table-wrap-foot><p>Unless otherwise specified, Data in parentheses are 95% CIs</p><p><italic>AI</italic> artificial intelligence, <italic>CI</italic> confidence interval, <italic>GPT</italic> generative pre-trained, <italic>NLP</italic> natural language processing, <italic>OR</italic> odds ratio</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec9"><title>The main factors affecting the attitude toward the acceptance of GPT-like technologies in each dimension</title><p id="Par30">To further elucidate the multi-faceted views of radiologists&#x02019; attitudes toward GPT-like technologies, we conducted a multivariable logistic regression analysis to identify factors significantly associated with acceptance and different levels of acceptance across four dimensions. Table&#x000a0;<xref rid="Tab5" ref-type="table">5</xref> shows the independent factors affecting the acceptance of GPT-like technologies in each dimension.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Binary logistic regression analysis of variables for the association with acceptance of GPT-like technologies based on each dimension (<italic>n</italic>&#x02009;=&#x02009;1289)</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Factors<sup>*</sup></th><th colspan="2">Acceptance (no vs yes)</th><th colspan="2">Acceptance level (1&#x02013;3 degrees vs 4&#x02013;5 degrees)</th><th colspan="2">Acceptance level (1&#x02013;4 degrees vs 5 degrees)</th></tr><tr><th>OR (95% CI)</th><th><italic>p</italic> value</th><th>OR (95% CI)</th><th><italic>p</italic> value</th><th>OR (95% CI)</th><th><italic>p</italic> value</th></tr></thead><tbody><tr><td colspan="7">Clinical practice</td></tr><tr><td>&#x02003;Q7 (Role in medical image diagnosis)</td><td/><td/><td>1.27 (1.03, 1.56)</td><td>0.02</td><td/><td/></tr><tr><td>&#x02003;Q9 (Reducing the radiology reporting writing time)</td><td/><td/><td/><td/><td>1.49 (1.14, 1.95)</td><td>0.003</td></tr><tr><td>&#x02003;Q10 (Improving efficiency in radiology emergency shifts)</td><td>2.16 (1.56, 2.99)</td><td>&#x0003c;&#x02009;0.001</td><td>1.74 (1.43, 2.11)</td><td>&#x0003c;&#x02009;0.001</td><td>1.45 (1.12, 1.88)</td><td>0.005</td></tr><tr><td colspan="7">Training and education</td></tr><tr><td>&#x02003;Q14 (Writing papers and language polishing)</td><td>2.39 (1.71, 3.32)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/><td>2.94 (1.93, 4.94)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>&#x02003;Q15 (Designing research topics)</td><td/><td/><td>1.53 (1.13, 2.07)</td><td>0.005</td><td/><td/></tr><tr><td>&#x02003;Q16 (Designing patents)</td><td/><td/><td>1.86 (1.37, 2.53)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td>&#x02003;Q18 (Enhancing disease understanding)</td><td>2.36 (1.56, 3.57)</td><td>&#x0003c;&#x02009;0.001</td><td>7.67 (5.58, 10.56)</td><td>&#x0003c;&#x02009;0.001</td><td>5.90 (3.92, 8.90)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>&#x02003;Q19 (GPT-like tech training in medical education)</td><td>1.50 (1.05, 2.14)</td><td>0.03</td><td>2.02 (1.54, 2.64)</td><td>&#x0003c;&#x02009;0.001</td><td>3.65 (2.41, 5.54)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td colspan="7">Environment and regulation</td></tr><tr><td>&#x02003;Q23 (Effect of colleagues using)</td><td>2.66 (1.91, 3.70)</td><td>&#x0003c;&#x02009;0.001</td><td>12.84 (9.42, 17.50)</td><td>&#x0003c;&#x02009;0.001</td><td>19.19 (13.06, 28.18)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>&#x02003;Q24 (Introducing regulation from the government)</td><td>2.61 (1.85, 3.68)</td><td>&#x0003c;&#x02009;0.001</td><td>1.99 (1.51, 2.62)</td><td>&#x0003c;&#x02009;0.001</td><td>2.41 (1.71, 3.41)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>&#x02003;Q25 (Supervising in medicine)</td><td/><td/><td>1.50 (1.23, 1.84)</td><td>&#x0003c;&#x02009;0.001</td><td/><td/></tr><tr><td colspan="7">Development tendency</td></tr><tr><td>&#x02003;Q28 (Application in the medicine in next decade)</td><td/><td/><td>1.38 (1.16, 1.65)</td><td>&#x0003c;&#x02009;0.001</td><td>1.46 (1.17, 1.82)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>&#x02003;Q29 (Enhancing radiologists&#x02019; decision support capabilities)</td><td>4.45 (2.94, 6.75)</td><td>&#x0003c;&#x02009;0.001</td><td>4.21 (3.28, 5.42)</td><td>&#x0003c;&#x02009;0.001</td><td>4.47 (3.21, 6.23)</td><td>&#x0003c;&#x02009;0.001</td></tr><tr><td>&#x02003;Q30 (Application in the medical industry)</td><td>2.53 (1.69, 3.77)</td><td>&#x0003c;&#x02009;0.001</td><td>5.48 (3.81, 7.89)</td><td>&#x0003c;&#x02009;0.001</td><td>6.83 (4.66, 10.03)</td><td>&#x0003c;&#x02009;0.001</td></tr></tbody></table><table-wrap-foot><p>Unless otherwise specified, Data in parentheses are 95% CIs</p><p><italic>CI</italic> confidence interval, <italic>GPT</italic> generative pre-trained, <italic>OR</italic> odds ratio</p><p><sup>*</sup> Summary of the item are shown in parentheses, the details of the items can be found in the Supplementary File</p></table-wrap-foot></table-wrap></p><p id="Par31">In the dimension of clinical practice, radiologists&#x02019; opinions on the role of GPT-like technologies in medical image diagnosis (OR&#x02009;=&#x02009;1.27; <italic>p</italic>&#x02009;=&#x02009;0.02) and their ability to reduce radiology report writing time (OR&#x02009;=&#x02009;1.49; <italic>p</italic>&#x02009;=&#x02009;0.003) were associated with higher levels of acceptance of GPT-like technologies. Notably, positive opinions on improving efficiency in radiology emergency shifts demonstrated the strongest association with the acceptance of GPT-like technologies (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05).</p><p id="Par32">Regarding training and education, enhancing disease understanding of GPT-like technologies (OR&#x02009;=&#x02009;2.36; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and incorporating GPT-like technologies training in medical education (OR&#x02009;=&#x02009;1.50; <italic>p</italic>&#x02009;=&#x02009;0.03) were strongly related to acceptance. Besides, the capability of GPT-like technologies in writing papers and language polishing, designing research topics, and designing patents were also potential factors contributing to positive attitudes toward GPT-like technologies (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05).</p><p id="Par33">For environment and regulation, the influence of colleagues using GPT-like technologies (OR&#x02009;=&#x02009;2.66; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and the introduction of government regulation for GPT-like technologies (OR&#x02009;=&#x02009;2.61; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) were the most significant factors for a positive attitude. Supervising in healthcare also showed significance in the analysis of acceptance level (1&#x02013;3 degrees vs 4&#x02013;5 degrees) (OR&#x02009;=&#x02009;1.50; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p><p id="Par34">Concerning the dimension of development tendency, positive opinions on the enhancement of decision support capabilities by GPT-like technologies and their application in the medical industry were the most influential factors for respondents&#x02019; positive attitude towards trying or continuing to use the GPT-like technologies (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p></sec></sec><sec id="Sec10" sec-type="discussion"><title>Discussion</title><p id="Par35">GPT-like technologies have experienced rapid growth and garnered significant attention in radiology [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]. The advent of GPT has infused new energy into the field of radiology, but it has also raised new concerns, making radiologists&#x02019; opinions on these technologies crucial. Our study conducted a national survey of Chinese radiologists and interns at the Zhongda Radiology Alliance with a 96.3% response rate, revealing that the majority of the 1223 respondents (94.9% of 1289) from 197 hospitals in 27 provinces expressed support for trying or continuing to use GPT-like technologies. Furthermore, we identified several factors significantly associated with the acceptance of GPT-like technologies, including writing papers and language polishing, the effect of colleagues using such technologies, introducing regulation from the government, and enhancing decision support capabilities (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p><p id="Par36">The Zhongda Radiology Alliance offered a unique advantage for this survey, as it spans a wide geographic area and includes a diverse range of hospitals across China. The alliance provided a high representation of the radiology community. This diversity ensured that the findings reflected the perspectives of radiologists from various settings, making the results more generalizable. The increasing demand for imaging examinations has outpaced the availability of skilled radiologists, intensifying the workload and increasing the likelihood of errors in radiology [<xref ref-type="bibr" rid="CR18">18</xref>]. Previous studies have shown that integrating GPT-like technologies into clinical practice has the potential to structure and detect errors in radiological reports with a high cost-benefit ratio [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>]. In the clinical practice dimension, respondents who believed GPT-like technologies could enhance medical image diagnosis and reduce report writing time were more likely to accept them (<italic>p</italic>&#x02009;=&#x02009;0.02&#x02013;0.003). Additionally, their potential to improve efficiency during radiology emergency shifts was crucial to acceptance (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05). Another study reported that GPT-4 achieved an accuracy of 0.88 in assessing clinical acuity in the department of emergency, compared to human accuracy of 0.86 [<xref ref-type="bibr" rid="CR19">19</xref>]. The strong association between the belief in improved decision support (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and the acceptance of GPT-like technologies underscores their critical role in clinical judgment and decision-making. Analyses of LLMs have concluded that these models can provide appropriate imaging examination suggestions and aid in surgical decision-making [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR20">20</xref>].</p><p id="Par37">The integration of GPT-like technologies into medical education and scientific research presents a transformative opportunity for radiologists [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]. In a survey study, over two-thirds of 263 medical students agreed on the need for AI to be included in medical training [<xref ref-type="bibr" rid="CR21">21</xref>]. Focusing on the education dimension, our study demonstrated a positive association with the high acceptance level of GPT-like technologies, particularly in writing papers and language polishing, designing research topics and patents, and enhancing disease understanding (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05). Recently, the use of tools based on LLMs for polishing scientific work has become acceptable, though it raises dilemmas regarding originality and inexpressiveness [<xref ref-type="bibr" rid="CR1">1</xref>]. These tools have also been used to assess the risk of bias in randomized clinical trials, achieving high correct assessment rates [<xref ref-type="bibr" rid="CR22">22</xref>]. However, recent studies have also revealed limitations of GPT-like technologies in terms of general performance in radiological knowledge [<xref ref-type="bibr" rid="CR23">23</xref>]. Indeed, respondents expressed significant concern about the accuracy of medical information provided by these technologies (<italic>p</italic>&#x02009;=&#x02009;0.005 in univariable analysis). Training in GPT-like technologies within medical education was identified as an important factor associated with a positive attitude (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.03). However, the performance of ChatGPT-like technologies at direct imaging interpretation may not be as accurate as expected [<xref ref-type="bibr" rid="CR12">12</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref>]. This could pose risks to both education and clinical practice, potentially increasing the likelihood of errors and negatively impacting patient care.</p><p id="Par38">Additionally, GPT-like technologies introduce a set of challenges that must be addressed to ensure their responsible and effective use, such as medical malpractice liability, privacy, and others [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. Legal regulation is a key challenge for LLMs. Our results show that government regulations were strongly associated with tool acceptance (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), highlighting the need for developer-regulator collaboration. Additionally, the influence of colleagues using GPT-like technologies was a major factor in fostering a positive attitude (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Future regulations for LLMs remain an unmet need and should aim to strike a balance between promoting efficiency and mitigating potential risks, with a focus on flexible, forward-looking frameworks that safeguard both societal and individual interests [<xref ref-type="bibr" rid="CR24">24</xref>]. In our study, respondents expressed a moderately optimistic opinion about the future medical application of GPT-like technologies. A 2021 survey revealed that only 48% (501 of 1041) of radiologists had a positive attitude toward AI, which contrasts with our findings in China [<xref ref-type="bibr" rid="CR25">25</xref>]. This discrepancy may arise from differences in survey populations or the focus on GPT-like technologies in our study. Additionally, recent AI integration in radiology may have reduced workload, enhancing radiologists&#x02019; confidence.</p><p id="Par39">There were several limitations in this study. First, it is a cross-sectional study, and the participants were members of the Zhongda Radiology Alliance, which may not be representative of radiologists worldwide. None of the respondents were engaged in ultrasound diagnosis. Second, only 125 (9.7%) of the 1289 respondents had prior experience with GPT-like technologies, and most respondents may have had an inaccurate understanding of these technologies due to a lack of direct experience. Third, the survey was conducted over seven months and did not focus on a specific GPT-like tool. Thus, it is important to interpret the results with caution.</p></sec><sec id="Sec11" sec-type="conclusion"><title>Conclusions</title><p id="Par40">Our study highlights that most radiologists or interns in mainland China display a favorable attitude toward incorporating GPT-like technologies into their clinical practice and research. This favorable attitude is driven by the popularity and superior capabilities of GPT-like technologies for scientific writing and decision support. Additionally, the establishment of sound regulations emerges as a pivotal factor in the application of GPT-like technologies in radiology.</p></sec><sec id="Sec12" sec-type="supplementary-material"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="13244_2025_1908_MOESM1_ESM.docx"><caption><p>ELECTRONIC SUPPLEMENTARY MATERIAL</p></caption></media></supplementary-material>
</p></sec></body><back><glossary><title>Abbreviations</title><def-list><def-item><term>AI</term><def><p id="Par11">Artificial intelligence</p></def></def-item><def-item><term>GPT</term><def><p id="Par12">Generative pre-trained</p></def></def-item><def-item><term>LLM</term><def><p id="Par13">Large language model</p></def></def-item></def-list></glossary><fn-group><fn><p><bold>Publisher&#x02019;s Note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>Tianyi Xia and Shijun Zhang contributed equally to this work.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1186/s13244-025-01908-8.</p></sec><ack><title>Acknowledgements</title><p>We express our gratitude to the members of the Zhongda Radiology Alliance for participating in this survey.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>T.X. and S.Z. contributed equally to the design of the work and were responsible for the data analyses and the first draft of the paper. B.Z. and Y.L were responsible for the data collection and cleaning. Z.X., Y.S., and B.C. were responsible for the statistical advice and questionnaire design. J.Z., Y.Y., Z.W. were response for the questionnaire distribution and article modification. C.L. was responsible for making the figures. T.T., Y.W., and S.J. were responsible for study supervision and quality control. All the authors read and approved the final manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>This study has received funding from the National Natural Science Foundation of China (NSFC, no. 823B2040, 92359304, 82330060, 82427803, and 82371940).</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>The related data can be obtained by contacting the corresponding author upon reasonable request.</p></notes><notes><title>Declarations</title><notes id="FPar1"><title>Ethics approval and consent to participate</title><p id="Par41">The Institutional Review Board of Shanghai General Hospital approved this prospective study (Medical ethics number: 2024ZDSYLL274-P01). Written informed consent was obtained from all subjects in this study.</p></notes><notes id="FPar2"><title>Consent for publication</title><p id="Par42">Not applicable.</p></notes><notes id="FPar3" notes-type="COI-statement"><title>Competing interests</title><p id="Par43">Y.S. is affiliated with Siemens Healthineers Ltd. The remaining authors declare that they have no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Thirunavukarasu</surname><given-names>AJ</given-names></name><name><surname>Ting</surname><given-names>DSJ</given-names></name><name><surname>Elangovan</surname><given-names>K</given-names></name><name><surname>Gutierrez</surname><given-names>L</given-names></name><name><surname>Tan</surname><given-names>TF</given-names></name><name><surname>Ting</surname><given-names>DSW</given-names></name></person-group><article-title>Large language models in medicine</article-title><source>Nat Med</source><year>2023</year><volume>29</volume><fpage>1930</fpage><lpage>1940</lpage><pub-id pub-id-type="doi">10.1038/s41591-023-02448-8</pub-id><pub-id pub-id-type="pmid">37460753</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW (2023) Large language models in medicine. Nat Med 29:1930&#x02013;1940<pub-id pub-id-type="pmid">37460753</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Kataoka</surname><given-names>Y</given-names></name><name><surname>So</surname><given-names>R</given-names></name></person-group><article-title>Benefits, limits, and risks of GPT-4 as an AI Chatbot for medicine</article-title><source>N Engl J Med</source><year>2023</year><volume>388</volume><fpage>2399</fpage><pub-id pub-id-type="doi">10.1056/NEJMc2305286</pub-id><pub-id pub-id-type="pmid">37342939</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Kataoka Y, So R (2023) Benefits, limits, and risks of GPT-4 as an AI Chatbot for medicine. N Engl J Med 388:2399<pub-id pub-id-type="pmid">37342939</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Lecler</surname><given-names>A</given-names></name><name><surname>Duron</surname><given-names>L</given-names></name><name><surname>Soyer</surname><given-names>P</given-names></name></person-group><article-title>Revolutionizing radiology with GPT-based models: current applications, future possibilities and limitations of ChatGPT</article-title><source>Diagn Interv Imaging</source><year>2023</year><volume>104</volume><fpage>269</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1016/j.diii.2023.02.003</pub-id><pub-id pub-id-type="pmid">36858933</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Lecler A, Duron L, Soyer P (2023) Revolutionizing radiology with GPT-based models: current applications, future possibilities and limitations of ChatGPT. Diagn Interv Imaging 104:269&#x02013;274<pub-id pub-id-type="pmid">36858933</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Bhayana</surname><given-names>R</given-names></name></person-group><article-title>Chatbots and large language models in radiology: a practical primer for clinical and research applications</article-title><source>Radiology</source><year>2024</year><volume>310</volume><fpage>e232756</fpage><pub-id pub-id-type="doi">10.1148/radiol.232756</pub-id><pub-id pub-id-type="pmid">38226883</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Bhayana R (2024) Chatbots and large language models in radiology: a practical primer for clinical and research applications. Radiology 310:e232756<pub-id pub-id-type="pmid">38226883</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>LH</given-names></name><name><surname>Panicek</surname><given-names>DM</given-names></name><name><surname>Berk</surname><given-names>AR</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Hricak</surname><given-names>H</given-names></name></person-group><article-title>Improving communication of diagnostic radiology findings through structured reporting</article-title><source>Radiology</source><year>2011</year><volume>260</volume><fpage>174</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1148/radiol.11101913</pub-id><pub-id pub-id-type="pmid">21518775</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Schwartz LH, Panicek DM, Berk AR, Li Y, Hricak H (2011) Improving communication of diagnostic radiology findings through structured reporting. Radiology 260:174&#x02013;181<pub-id pub-id-type="pmid">21518775</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Bhayana</surname><given-names>R</given-names></name><name><surname>Nanda</surname><given-names>B</given-names></name><name><surname>Dehkharghanian</surname><given-names>T</given-names></name><etal/></person-group><article-title>Large language models for automated synoptic reports and resectability categorization in pancreatic cancer</article-title><source>Radiology</source><year>2024</year><volume>311</volume><fpage>e233117</fpage><pub-id pub-id-type="doi">10.1148/radiol.233117</pub-id><pub-id pub-id-type="pmid">38888478</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Bhayana R, Nanda B, Dehkharghanian T et al (2024) Large language models for automated synoptic reports and resectability categorization in pancreatic cancer. Radiology 311:e233117<pub-id pub-id-type="pmid">38888478</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Lehnen</surname><given-names>NC</given-names></name><name><surname>Dorn</surname><given-names>F</given-names></name><name><surname>Wiest</surname><given-names>IC</given-names></name><etal/></person-group><article-title>Data extraction from free-text reports on mechanical thrombectomy in acute ischemic stroke using ChatGPT: a retrospective analysis</article-title><source>Radiology</source><year>2024</year><volume>311</volume><fpage>e232741</fpage><pub-id pub-id-type="doi">10.1148/radiol.232741</pub-id><pub-id pub-id-type="pmid">38625006</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Lehnen NC, Dorn F, Wiest IC et al (2024) Data extraction from free-text reports on mechanical thrombectomy in acute ischemic stroke using ChatGPT: a retrospective analysis. Radiology 311:e232741<pub-id pub-id-type="pmid">38625006</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>LC</given-names></name><name><surname>Truhn</surname><given-names>D</given-names></name><name><surname>Busch</surname><given-names>F</given-names></name><etal/></person-group><article-title>Leveraging GPT-4 for post hoc transformation of free-text radiology reports into structured reporting: a multilingual feasibility study</article-title><source>Radiology</source><year>2023</year><volume>307</volume><fpage>e230725</fpage><pub-id pub-id-type="doi">10.1148/radiol.230725</pub-id><pub-id pub-id-type="pmid">37014240</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Adams LC, Truhn D, Busch F et al (2023) Leveraging GPT-4 for post hoc transformation of free-text radiology reports into structured reporting: a multilingual feasibility study. Radiology 307:e230725<pub-id pub-id-type="pmid">37014240</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Gertz</surname><given-names>RJ</given-names></name><name><surname>Dratsch</surname><given-names>T</given-names></name><name><surname>Bunck</surname><given-names>AC</given-names></name><etal/></person-group><article-title>Potential of GPT-4 for detecting errors in radiology reports: implications for reporting accuracy</article-title><source>Radiology</source><year>2024</year><volume>311</volume><fpage>e232714</fpage><pub-id pub-id-type="doi">10.1148/radiol.232714</pub-id><pub-id pub-id-type="pmid">38625012</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Gertz RJ, Dratsch T, Bunck AC et al (2024) Potential of GPT-4 for detecting errors in radiology reports: implications for reporting accuracy. Radiology 311:e232714<pub-id pub-id-type="pmid">38625012</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Suh</surname><given-names>PS</given-names></name><name><surname>Shim</surname><given-names>WH</given-names></name><name><surname>Suh</surname><given-names>CH</given-names></name><etal/></person-group><article-title>Comparing diagnostic accuracy of radiologists versus GPT-4V and gemini pro vision using image inputs from diagnosis please cases</article-title><source>Radiology</source><year>2024</year><volume>312</volume><fpage>e240273</fpage><pub-id pub-id-type="doi">10.1148/radiol.240273</pub-id><pub-id pub-id-type="pmid">38980179</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Suh PS, Shim WH, Suh CH et al (2024) Comparing diagnostic accuracy of radiologists versus GPT-4V and gemini pro vision using image inputs from diagnosis please cases. Radiology 312:e240273<pub-id pub-id-type="pmid">38980179</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Ong</surname><given-names>H</given-names></name><name><surname>Kennedy</surname><given-names>P</given-names></name><etal/></person-group><article-title>Evaluating GPT-V4 (GPT-4 with vision) on detection of radiologic findings on chest radiographs</article-title><source>Radiology</source><year>2024</year><volume>311</volume><fpage>e233270</fpage><pub-id pub-id-type="doi">10.1148/radiol.233270</pub-id><pub-id pub-id-type="pmid">38713028</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Zhou Y, Ong H, Kennedy P et al (2024) Evaluating GPT-V4 (GPT-4 with vision) on detection of radiologic findings on chest radiographs. Radiology 311:e233270<pub-id pub-id-type="pmid">38713028</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Cozzi</surname><given-names>A</given-names></name><name><surname>Pinker</surname><given-names>K</given-names></name><name><surname>Hidber</surname><given-names>A</given-names></name><etal/></person-group><article-title>BI-RADS category assignments by GPT-3.5, GPT-4, and google bard: a multilanguage study</article-title><source>Radiology</source><year>2024</year><volume>311</volume><fpage>e232133</fpage><pub-id pub-id-type="doi">10.1148/radiol.232133</pub-id><pub-id pub-id-type="pmid">38687216</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Cozzi A, Pinker K, Hidber A et al (2024) BI-RADS category assignments by GPT-3.5, GPT-4, and google bard: a multilanguage study. Radiology 311:e232133<pub-id pub-id-type="pmid">38687216</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Hayden</surname><given-names>N</given-names></name><name><surname>Gilbert</surname><given-names>S</given-names></name><name><surname>Poisson</surname><given-names>LM</given-names></name><name><surname>Griffith</surname><given-names>B</given-names></name><name><surname>Klochko</surname><given-names>C</given-names></name></person-group><article-title>Performance of GPT-4 with vision on text- and image-based ACR diagnostic radiology in-training examination questions</article-title><source>Radiology</source><year>2024</year><volume>312</volume><fpage>e240153</fpage><pub-id pub-id-type="doi">10.1148/radiol.240153</pub-id><pub-id pub-id-type="pmid">39225605</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Hayden N, Gilbert S, Poisson LM, Griffith B, Klochko C (2024) Performance of GPT-4 with vision on text- and image-based ACR diagnostic radiology in-training examination questions. Radiology 312:e240153<pub-id pub-id-type="pmid">39225605</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Santomartino</surname><given-names>SM</given-names></name><name><surname>Zech</surname><given-names>JR</given-names></name><name><surname>Hall</surname><given-names>K</given-names></name><name><surname>Jeudy</surname><given-names>J</given-names></name><name><surname>Parekh</surname><given-names>V</given-names></name><name><surname>Yi</surname><given-names>PH</given-names></name></person-group><article-title>Evaluating the performance and bias of natural language processing tools in labeling chest radiograph reports</article-title><source>Radiology</source><year>2024</year><volume>313</volume><fpage>e232746</fpage><pub-id pub-id-type="doi">10.1148/radiol.232746</pub-id><pub-id pub-id-type="pmid">39436298</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Santomartino SM, Zech JR, Hall K, Jeudy J, Parekh V, Yi PH (2024) Evaluating the performance and bias of natural language processing tools in labeling chest radiograph reports. Radiology 313:e232746<pub-id pub-id-type="pmid">39436298</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>SH</given-names></name><name><surname>Huynh</surname><given-names>K</given-names></name><name><surname>Cortes</surname><given-names>G</given-names></name><etal/></person-group><article-title>Testing the ability and limitations of ChatGPT to generate differential diagnoses from transcribed radiologic findings</article-title><source>Radiology</source><year>2024</year><volume>313</volume><fpage>e232346</fpage><pub-id pub-id-type="doi">10.1148/radiol.232346</pub-id><pub-id pub-id-type="pmid">39404623</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Sun SH, Huynh K, Cortes G et al (2024) Testing the ability and limitations of ChatGPT to generate differential diagnoses from transcribed radiologic findings. Radiology 313:e232346<pub-id pub-id-type="pmid">39404623</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Mesko</surname><given-names>B</given-names></name><name><surname>Topol</surname><given-names>EJ</given-names></name></person-group><article-title>The imperative for regulatory oversight of large language models (or generative AI) in healthcare</article-title><source>NPJ Digital Med</source><year>2023</year><volume>6</volume><fpage>120</fpage><pub-id pub-id-type="doi">10.1038/s41746-023-00873-0</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Mesko B, Topol EJ (2023) The imperative for regulatory oversight of large language models (or generative AI) in healthcare. NPJ Digital Med 6:120</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Ong</surname><given-names>JCL</given-names></name><name><surname>Chang</surname><given-names>SY</given-names></name><name><surname>William</surname><given-names>W</given-names></name><etal/></person-group><article-title>Ethical and regulatory challenges of large language models in medicine</article-title><source>Lancet Digital Health</source><year>2024</year><volume>6</volume><fpage>e428</fpage><lpage>e432</lpage><pub-id pub-id-type="doi">10.1016/S2589-7500(24)00061-X</pub-id><pub-id pub-id-type="pmid">38658283</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Ong JCL, Chang SY, William W et al (2024) Ethical and regulatory challenges of large language models in medicine. Lancet Digital Health 6:e428&#x02013;e432<pub-id pub-id-type="pmid">38658283</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>R</given-names></name><name><surname>Waite</surname><given-names>S</given-names></name><name><surname>Bruno</surname><given-names>MA</given-names></name><etal/></person-group><article-title>Mandating limits on workload, duty, and speed in radiology</article-title><source>Radiology</source><year>2022</year><volume>304</volume><fpage>274</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1148/radiol.212631</pub-id><pub-id pub-id-type="pmid">35699581</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Alexander R, Waite S, Bruno MA et al (2022) Mandating limits on workload, duty, and speed in radiology. Radiology 304:274&#x02013;282<pub-id pub-id-type="pmid">35699581</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>CYK</given-names></name><name><surname>Zack</surname><given-names>T</given-names></name><name><surname>Miao</surname><given-names>BY</given-names></name><etal/></person-group><article-title>Use of a large language model to assess clinical acuity of adults in the emergency department</article-title><source>JAMA Netw Open</source><year>2024</year><volume>7</volume><fpage>e248895</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.8895</pub-id><pub-id pub-id-type="pmid">38713466</pub-id>
</element-citation><mixed-citation id="mc-CR19" publication-type="journal">Williams CYK, Zack T, Miao BY et al (2024) Use of a large language model to assess clinical acuity of adults in the emergency department. JAMA Netw Open 7:e248895<pub-id pub-id-type="pmid">38713466</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Gertz</surname><given-names>RJ</given-names></name><name><surname>Bunck</surname><given-names>AC</given-names></name><name><surname>Lennartz</surname><given-names>S</given-names></name><etal/></person-group><article-title>GPT-4 for automated determination of radiological study and protocol based on radiology request forms: a feasibility study</article-title><source>Radiology</source><year>2023</year><volume>307</volume><fpage>e230877</fpage><pub-id pub-id-type="doi">10.1148/radiol.230877</pub-id><pub-id pub-id-type="pmid">37310247</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Gertz RJ, Bunck AC, Lennartz S et al (2023) GPT-4 for automated determination of radiological study and protocol based on radiology request forms: a feasibility study. Radiology 307:e230877<pub-id pub-id-type="pmid">37310247</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto Dos Santos</surname><given-names>D</given-names></name><name><surname>Giese</surname><given-names>D</given-names></name><name><surname>Brodehl</surname><given-names>S</given-names></name><etal/></person-group><article-title>Medical students&#x02019; attitude towards artificial intelligence: a multicentre survey</article-title><source>Eur Radiol</source><year>2019</year><volume>29</volume><fpage>1640</fpage><lpage>1646</lpage><pub-id pub-id-type="doi">10.1007/s00330-018-5601-1</pub-id><pub-id pub-id-type="pmid">29980928</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Pinto Dos Santos D, Giese D, Brodehl S et al (2019) Medical students&#x02019; attitude towards artificial intelligence: a multicentre survey. Eur Radiol 29:1640&#x02013;1646<pub-id pub-id-type="pmid">29980928</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Lai</surname><given-names>H</given-names></name><name><surname>Ge</surname><given-names>L</given-names></name><name><surname>Sun</surname><given-names>M</given-names></name><etal/></person-group><article-title>Assessing the risk of bias in randomized clinical trials with large language models</article-title><source>JAMA Netw Open</source><year>2024</year><volume>7</volume><fpage>e2412687</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.12687</pub-id><pub-id pub-id-type="pmid">38776081</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Lai H, Ge L, Sun M et al (2024) Assessing the risk of bias in randomized clinical trials with large language models. JAMA Netw Open 7:e2412687<pub-id pub-id-type="pmid">38776081</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Bhayana</surname><given-names>R</given-names></name><name><surname>Krishna</surname><given-names>S</given-names></name><name><surname>Bleakney</surname><given-names>RR</given-names></name></person-group><article-title>Performance of ChatGPT on a radiology board-style examination: insights into current strengths and limitations</article-title><source>Radiology</source><year>2023</year><volume>307</volume><fpage>e230582</fpage><pub-id pub-id-type="doi">10.1148/radiol.230582</pub-id><pub-id pub-id-type="pmid">37191485</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Bhayana R, Krishna S, Bleakney RR (2023) Performance of ChatGPT on a radiology board-style examination: insights into current strengths and limitations. Radiology 307:e230582<pub-id pub-id-type="pmid">37191485</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Freyer</surname><given-names>O</given-names></name><name><surname>Wiest</surname><given-names>IC</given-names></name><name><surname>Kather</surname><given-names>JN</given-names></name><name><surname>Gilbert</surname><given-names>S</given-names></name></person-group><article-title>A future role for health applications of large language models depends on regulators enforcing safety standards</article-title><source>Lancet Digital Health</source><year>2024</year><volume>6</volume><fpage>e662</fpage><lpage>e672</lpage><pub-id pub-id-type="doi">10.1016/S2589-7500(24)00124-9</pub-id><pub-id pub-id-type="pmid">39179311</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Freyer O, Wiest IC, Kather JN, Gilbert S (2024) A future role for health applications of large language models depends on regulators enforcing safety standards. Lancet Digital Health 6:e662&#x02013;e672<pub-id pub-id-type="pmid">39179311</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Huisman</surname><given-names>M</given-names></name><name><surname>Ranschaert</surname><given-names>E</given-names></name><name><surname>Parker</surname><given-names>W</given-names></name><etal/></person-group><article-title>An international survey on AI in radiology in 1,041 radiologists and radiology residents part 1: fear of replacement, knowledge, and attitude</article-title><source>Eur Radiol</source><year>2021</year><volume>31</volume><fpage>7058</fpage><lpage>7066</lpage><pub-id pub-id-type="doi">10.1007/s00330-021-07781-5</pub-id><pub-id pub-id-type="pmid">33744991</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Huisman M, Ranschaert E, Parker W et al (2021) An international survey on AI in radiology in 1,041 radiologists and radiology residents part 1: fear of replacement, knowledge, and attitude. Eur Radiol 31:7058&#x02013;7066<pub-id pub-id-type="pmid">33744991</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>