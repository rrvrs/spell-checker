<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006218</article-id><article-id pub-id-type="pmc">PMC11860131</article-id><article-id pub-id-type="doi">10.3390/s25040990</article-id><article-id pub-id-type="publisher-id">sensors-25-00990</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Helicopter Turboshaft Engines&#x02019; Neural Network System for Monitoring Sensor Failures</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8009-5254</contrib-id><name><surname>Vladov</surname><given-names>Serhii</given-names></name><xref rid="af1-sensors-25-00990" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-7365-8888</contrib-id><name><surname>&#x0015a;cis&#x00142;o</surname><given-names>&#x00141;ukasz</given-names></name><xref rid="af2-sensors-25-00990" ref-type="aff">2</xref><xref rid="c1-sensors-25-00990" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1473-406X</contrib-id><name><surname>Szczepanik-&#x0015a;cis&#x00142;o</surname><given-names>Nina</given-names></name><xref rid="af3-sensors-25-00990" ref-type="aff">3</xref><xref rid="af4-sensors-25-00990" ref-type="aff">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0907-3682</contrib-id><name><surname>Sachenko</surname><given-names>Anatoliy</given-names></name><xref rid="af5-sensors-25-00990" ref-type="aff">5</xref><xref rid="af6-sensors-25-00990" ref-type="aff">6</xref></contrib><contrib contrib-type="author"><name><surname>Perzy&#x00144;ski</surname><given-names>Tomasz</given-names></name><xref rid="af6-sensors-25-00990" ref-type="aff">6</xref></contrib><contrib contrib-type="author"><name><surname>Vasylenko</surname><given-names>Viktor</given-names></name><xref rid="af1-sensors-25-00990" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-6417-3689</contrib-id><name><surname>Vysotska</surname><given-names>Victoria</given-names></name><xref rid="af7-sensors-25-00990" ref-type="aff">7</xref><xref rid="af8-sensors-25-00990" ref-type="aff">8</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Kim</surname><given-names>Jongmyon</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-00990"><label>1</label>Kharkiv National University of Internal Affairs, 27, L. Landau Avenue, 61080 Kharkiv, Ukraine; <email>serhii.vladov@univd.edu.ua</email> (S.V.); <email>vasylenko_viktor@ukr.net</email> (V.V.)</aff><aff id="af2-sensors-25-00990"><label>2</label>Faculty of Electrical and Computer Engineering, Cracow University of Technology, 24, Warszawska, 31-155 Cracow, Poland</aff><aff id="af3-sensors-25-00990"><label>3</label>Faculty of Environmental Engineering and Energy, Cracow University of Technology, 24, Warszawska, 31-155 Cracow, Poland; <email>nina.szczepanik@pk.edu.pl</email></aff><aff id="af4-sensors-25-00990"><label>4</label>CERN, European Organization for Nuclear Research, 1, Esplanade des Particules, 1211 Geneva 23, Switzerland</aff><aff id="af5-sensors-25-00990"><label>5</label>Research Institute for Intelligent Computer Systems, West Ukrainian National University, 11, Lvivska Street, 46009 Ternopil, Ukraine; <email>as@wunu.edu.ua</email></aff><aff id="af6-sensors-25-00990"><label>6</label>Faculty of Transport, Electrical Engineering and Computer Science, Casimir Pulaski Radom University, 26-600 Radom, Poland</aff><aff id="af7-sensors-25-00990"><label>7</label>Information Systems and Networks Department, Lviv Polytechnic National University, 12, Bandera Street, 79013 Lviv, Ukraine; <email>victoria.a.vysotska@lpnu.ua</email></aff><aff id="af8-sensors-25-00990"><label>8</label>Institute of Computer Science, Osnabr&#x000fc;ck University, 1, Friedrich-Janssen-Street, 49076 Osnabr&#x000fc;ck, Germany</aff><author-notes><corresp id="c1-sensors-25-00990"><label>*</label>Correspondence: <email>lscislo@pk.edu.pl</email></corresp></author-notes><pub-date pub-type="epub"><day>07</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>990</elocation-id><history><date date-type="received"><day>17</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>27</day><month>1</month><year>2025</year></date><date date-type="accepted"><day>04</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>An effective neural network system for monitoring sensors in helicopter turboshaft engines has been developed based on a hybrid architecture combining LSTM and GRU. This system enables sequential data processing while ensuring high accuracy in anomaly detection. Using recurrent layers (LSTM/GRU) is critical for dependencies among data time series analysis and identification, facilitating key information retention from previous states. Modules such as SensorFailClean and SensorFailNorm implement adaptive discretization and quantisation techniques, enhancing the data input quality and contributing to more accurate predictions. The developed system demonstrated anomaly detection accuracy at 99.327% after 200 training epochs, with a reduction in loss from 2.5 to 0.5%, indicating stability in anomaly processing. A training algorithm incorporating temporal regularization and a combined optimization method (SGD with RMSProp) accelerated neural network convergence, reducing the training time to 4 min and 13 s while achieving an accuracy of 0.993. Comparisons with alternative methods indicate superior performance for the proposed approach across key metrics, including accuracy at 0.993 compared to 0.981 and 0.982. Computational experiments confirmed the presence of the highly correlated sensor and demonstrated the method&#x02019;s effectiveness in fault detection, highlighting the system&#x02019;s capability to minimize omissions.</p></abstract><kwd-group><kwd>sensor failures</kwd><kwd>neural network system</kwd><kwd>helicopter turboshaft engines</kwd><kwd>sensors</kwd><kwd>recurrent layers</kwd><kwd>approximation</kwd><kwd>anomaly detection</kwd></kwd-group><funding-group><funding-statement>This research received no external funding.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-00990"><title>1. Introduction</title><p>In modern aviation engineering, reliability and operational safety in helicopter turboshaft engines (TEs) require continuous monitoring and improvement. Sensors installed in helicopter TE systems play a vital role in monitoring their technical condition, enabling the timely detection of anomalies and malfunctions [<xref rid="B1-sensors-25-00990" ref-type="bibr">1</xref>,<xref rid="B2-sensors-25-00990" ref-type="bibr">2</xref>]. However, sensor data (telemetry) are subject to various external and internal influences [<xref rid="B3-sensors-25-00990" ref-type="bibr">3</xref>], potentially leading to measurement errors or data loss. In this context, the development of intelligent control and diagnostic systems capable of identifying sensor anomalies and restoring lost data has become increasingly relevant. One promising solution involves implementing neural network control systems to analyze incoming sensor signals, detect deviations from normal conditions, and predict potential failures in helicopter TEs [<xref rid="B4-sensors-25-00990" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-00990" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-00990" ref-type="bibr">6</xref>]. Based on deep learning methods, such systems can adapt to changing engine operating conditions and learn from historical data.</p><p>The development of helicopter TE sensor failure neural network control systems is driven by the need to enhance automation in diagnostics, improve the aviation systems reliability, and minimize the risks associated with engine failures. Using modern machine learning technologies to analyze sensor data opens new possibilities for creating more resilient and efficient control systems, significantly enhancing the safety and operational effectiveness of helicopters.</p><p>Numerous recent studies have focused on developing intelligent systems for monitoring and diagnosing helicopter TE sensors. Many of these systems are based on neural network approaches, which have demonstrated high efficiency in detecting faults and the capability of systems to predict technical conditions [<xref rid="B7-sensors-25-00990" ref-type="bibr">7</xref>,<xref rid="B8-sensors-25-00990" ref-type="bibr">8</xref>]. One primary research direction is the use of recurrent neural networks, particularly Long Short-Term Memory (LSTM) networks, for analyzing sensor time series data [<xref rid="B9-sensors-25-00990" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-00990" ref-type="bibr">10</xref>,<xref rid="B11-sensors-25-00990" ref-type="bibr">11</xref>]. These models can identify hidden patterns in data and accurately predict anomalous events.</p><p>Hybrid models, combining neural networks with fuzzy logic methods and decision support systems, are also actively researched [<xref rid="B12-sensors-25-00990" ref-type="bibr">12</xref>,<xref rid="B13-sensors-25-00990" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-00990" ref-type="bibr">14</xref>]. Such approaches account for uncertainties and noise in the data, which is crucial for aviation systems, where measurement accuracy can be affected by external factors like vibrations or changing operating conditions. Research [<xref rid="B15-sensors-25-00990" ref-type="bibr">15</xref>,<xref rid="B16-sensors-25-00990" ref-type="bibr">16</xref>] indicates that hybrid neural network systems significantly improve diagnostic reliability and accuracy compared to traditional methods, such as statistical models and simple threshold-based anomaly detection techniques.</p><p>Innovative frameworks such as optimized extreme learning machines (ELMs) [<xref rid="B17-sensors-25-00990" ref-type="bibr">17</xref>] demonstrate high speed and reliability in structural damage identification. Their application in helicopter TE diagnostics enables accurate damage detection while minimizing computational costs and data processing time [<xref rid="B18-sensors-25-00990" ref-type="bibr">18</xref>]. In the equipment condition prediction field, the integration of convolutional neural networks (CNNs) with bidirectional LSTM models (DBLSTMs) is promising [<xref rid="B19-sensors-25-00990" ref-type="bibr">19</xref>,<xref rid="B20-sensors-25-00990" ref-type="bibr">20</xref>]. Such approaches are used, for example, for the long-term prediction of a component&#x02019;s remaining service life [<xref rid="B21-sensors-25-00990" ref-type="bibr">21</xref>], including batteries [<xref rid="B22-sensors-25-00990" ref-type="bibr">22</xref>], indicating their potential in complex systems in aviation technical conditions for predicting and diagnosing tasks. These achievements provide the basis for the development of adaptive training algorithms capable of taking into account changing operating conditions and data uncertainties, which are especially important for complex aviation systems.</p><p>Additionally, adaptive training algorithms contribute development significantly to sensor monitoring systems advancements [<xref rid="B23-sensors-25-00990" ref-type="bibr">23</xref>,<xref rid="B24-sensors-25-00990" ref-type="bibr">24</xref>]. These algorithms can update parameters in real time, allowing for self-learning and adaptation to changes in engine performance or component behaviour [<xref rid="B25-sensors-25-00990" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-00990" ref-type="bibr">26</xref>,<xref rid="B27-sensors-25-00990" ref-type="bibr">27</xref>], making them more effective in dynamic operating environments. Comparative studies show that helicopter TE adaptive neural network sensor monitoring systems deliver faster and more accurate results, which are crucial for preventing critical failures and enhancing flight safety.</p><p>Despite the progress in helicopter TE development for neural network-based sensor monitoring systems [<xref rid="B28-sensors-25-00990" ref-type="bibr">28</xref>,<xref rid="B29-sensors-25-00990" ref-type="bibr">29</xref>], essential challenges that limit their application remain. The primary challenge is the model&#x02019;s insufficient robustness to noise and interference caused by vibrations, temperature changes, and pressure fluctuations. It can lead to false alarms or missed faults in real-world conditions. Additionally, many current systems overlook helicopter TE physical models, relying solely on sensor data, which reduces diagnostic accuracy, especially in non-standard operating modes. Integrating physical models could significantly enhance prediction accuracy.</p><p>Thus, new approaches that combine neural network technologies with hypothesis generation and validation methods for sensor data correlation and plausibility are needed based on helicopter TE physical models and design features. This would improve diagnostic accuracy and reliability, especially in noisy environments, and provide a deeper understanding of engine processes, critical for enhancing helicopter operations safety and efficiency.</p><p><bold>The research aim</bold> is to develop a method for detecting helicopter TE sensor faults and identifying telemetry segments with errors using neural network technologies, which can efficiently recognize and classify situations even with incomplete or ambiguous data. Computation speed is increased through the use of modern cluster setups. The <bold>research object</bold> is helicopter TE sensor fault detection systems, their processes, and their characteristics. The <bold>research subject</bold> involves methods and tools for detecting helicopter TE sensor faults during flight operations. The proposed monitoring system operates as follows:
<list list-type="bullet"><list-item><p>All sensor readings are recorded in a database;</p></list-item><list-item><p>A second assessment is conducted;</p></list-item><list-item><p>A model of the current state of the monitored equipment is built;</p></list-item><list-item><p>Simulated values are stored in the database;</p></list-item><list-item><p>Information regarding detected faults is relayed to the human operator.</p></list-item></list></p></sec><sec id="sec2-sensors-25-00990"><title>2. Materials and Methods</title><sec id="sec2dot1-sensors-25-00990"><title>2.1. Statement of the Problem</title><p>This article addresses the sensor system monitoring challenge under interference by proposing and testing hypotheses on the correlation and plausibility of the readings based on helicopter TE physical models and design features. The data for the research, as well as the necessary equipment (computer equipment, helicopter TE) were obtained from the Ministry of Internal Affairs of Ukraine (Kyiv, Ukraine). The complexity of the helicopter TE detecting sensor failures and malfunctions arises from the lack of telemetry data containing examples of various faults and the inability to conduct large-scale experiments. The only viable approach is formulating and testing hypotheses using heuristic models considering helicopter TE design characteristics and the positioning of control elements. An engine transition to operational modes (nominal, cruise I, cruise II, and emergency) typically changes other sensor readings. Assuming that functional sensors exhibit stable correlation in their readings, a sharp decrease in such correlation during engine operation may signal a potential fault. The monitoring is based on the following hypotheses:</p><statement><label><bold>Hypothesis</bold>&#x000a0;<bold>1.</bold></label><p>
<italic toggle="yes">Due to the helicopter TE design features, functional sensors exhibit stable correlations with each other.</italic>
</p></statement><statement><label><bold>Hypothesis</bold>&#x000a0;<bold>2.</bold></label><p>
<italic toggle="yes">Anomalies contradicting the helicopter TE design features and models are categorized as faults or interferences.</italic>
</p></statement><p>Here, <italic toggle="yes">X<sub>i</sub></italic>(<italic toggle="yes">t</italic>) represents the <italic toggle="yes">i</italic>-th functional sensor readings at time <italic toggle="yes">t</italic>, and <italic toggle="yes">X<sub>j</sub></italic>(<italic toggle="yes">t</italic>) represents the readings of another functional <italic toggle="yes">j</italic>-th sensor. Hypothesis 1 states that functional sensors maintain a stable correlation between their readings.<disp-formula>Corr(<italic toggle="yes">X<sub>i</sub></italic>(<italic toggle="yes">t</italic>), <italic toggle="yes">X<sub>j</sub></italic>(<italic toggle="yes">t</italic>)) &#x02248; <italic toggle="yes">&#x003c1;<sub>ij</sub></italic>, &#x02200;<italic toggle="yes">i</italic>, <italic toggle="yes">j</italic> &#x02208; {1, 2,&#x02026;, <italic toggle="yes">N</italic>}, <italic toggle="yes">t</italic> &#x02208; <italic toggle="yes">T</italic>,<label>(1)</label></disp-formula>
where <italic toggle="yes">&#x003c1;<sub>ij</sub></italic> represents the correlation coefficient between the sensor <italic toggle="yes">i</italic>-th and sensor <italic toggle="yes">j</italic>-th readings, <italic toggle="yes">N</italic> is the sensor&#x02019;s total number, and <italic toggle="yes">T</italic> is the time interval.</p><p>Fault monitoring can be performed based on the sharp change condition in the correlation coefficient between sensors. If a sudden change in correlation is observed between the sensor pair <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>, the following is obtained:<disp-formula>&#x00394;Corr(<italic toggle="yes">X<sub>i</sub></italic>(<italic toggle="yes">t</italic>), <italic toggle="yes">X<sub>j</sub></italic>(<italic toggle="yes">t</italic>)) &#x02223;Corr(<italic toggle="yes">X<sub>i</sub></italic>(<italic toggle="yes">t</italic>), <italic toggle="yes">X<sub>j</sub></italic>(<italic toggle="yes">t</italic>)) &#x02212; <italic toggle="yes">&#x003c1;<sub>ij</sub></italic>&#x02223; &#x0003e; <italic toggle="yes">&#x003f5;</italic>,<label>(2)</label></disp-formula>
where <italic toggle="yes">&#x003f5;</italic> is the threshold value at which a malfunction or failure is assumed.</p><p>Suppose the engine transitions from one operational mode to another (nominal to emergency mode). In that case, the sensor reading&#x02019;s dependency on the operational mode <italic toggle="yes">R<sub>k</sub></italic> can be assumed (where <italic toggle="yes">k</italic> represents the mode number):<disp-formula><italic toggle="yes">X<sub>i</sub></italic>(<italic toggle="yes">t</italic>) = <italic toggle="yes">f<sub>i</sub></italic>(<italic toggle="yes">R<sub>k</sub></italic>(<italic toggle="yes">t</italic>)) + <italic toggle="yes">&#x003b5;<sub>i</sub></italic>(<italic toggle="yes">t</italic>),<label>(3)</label></disp-formula>
where <italic toggle="yes">f<sub>i</sub></italic>(<italic toggle="yes">R<sub>k</sub></italic>(<italic toggle="yes">t</italic>)) represents a function that describes the sensor reading&#x02019;s dependency on the operational mode, and <italic toggle="yes">&#x003b5;<sub>i</sub></italic>(<italic toggle="yes">t</italic>) represents noise or measurement error.</p><p>Hypothesis 2 asserts that anomalies not conforming to the helicopter TE model or design features are considered faults or interferences. To address this, an error function <italic toggle="yes">&#x003b4;<sub>i</sub></italic>(<italic toggle="yes">t</italic>) can be introduced for the <italic toggle="yes">i</italic>-th sensor, indicating the actual data&#x02019;s deviation from expected values:<disp-formula><italic toggle="yes">&#x003b4;<sub>i</sub></italic>(<italic toggle="yes">t</italic>) = |<italic toggle="yes">X<sub>i</sub></italic>(<italic toggle="yes">t</italic>) &#x02212; <italic toggle="yes">f<sub>i</sub></italic>(<italic toggle="yes">R<sub>k</sub></italic>(<italic toggle="yes">t</italic>))| &#x0003e; <italic toggle="yes">&#x003b1;</italic>,<label>(4)</label></disp-formula>
where <italic toggle="yes">&#x003b1;</italic> is the acceptable error; if the error <italic toggle="yes">&#x003b4;<sub>i</sub></italic>(<italic toggle="yes">t</italic>) exceeds the threshold <italic toggle="yes">&#x003b1;</italic>, a failure is recorded.</p><p>The total error use is proposed to evaluate the overall condition across a sensor group:<disp-formula id="FD1-sensors-25-00990"><label>(5)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#x02206;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>If &#x00394;(<italic toggle="yes">t</italic>) &#x0003e; <italic toggle="yes">&#x003b2;</italic>, where <italic toggle="yes">&#x003b2;</italic> is the threshold value, it is considered that a malfunction has occurred in the sensor system.</p></sec><sec id="sec2dot2-sensors-25-00990"><title>2.2. Proposed Method</title><sec id="sec2dot2dot1-sensors-25-00990"><title>2.2.1. Development of the First Hypothesis Testing Method</title><p>To test the first hypothesis, a programme was developed that preprocessed the readings from helicopter TE sensors to check for a pairwise presence and triple correlations between the sensor readings. Data from six sensors measuring the following parameters were used: the gas-generator rotor r.p.m. (<italic toggle="yes">n<sub>TC</sub></italic>), free turbine rotor speed (<italic toggle="yes">n<sub>FT</sub></italic>), gas temperature before the compressor turbine (<inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>), oil temperature at the engine inlet (<italic toggle="yes">T<sub>oil</sub></italic>), oil pressure at the engine outlet (<italic toggle="yes">P<sub>oil</sub></italic>), and main rotor speed (<italic toggle="yes">n<sub>rs</sub></italic>). Based on the recorded sensor readings, all possible pair (<italic toggle="yes">a</italic>, <italic toggle="yes">b</italic>) and triple (<italic toggle="yes">a</italic>, <italic toggle="yes">b</italic>, <italic toggle="yes">c</italic>) combinations of <italic toggle="yes">k</italic> sensors were generated. The pairwise number and triple combinations are calculated as follows:<disp-formula id="FD2-sensors-25-00990"><label>(6)</label><mml:math id="mm3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>To enhance signal quality, an adaptive discretization method is applied as follows:<disp-formula id="FD3-sensors-25-00990"><label>(7)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where Var(<italic toggle="yes">x<sub>i</sub></italic>) is the variance in the <italic toggle="yes">t<sub>i</sub></italic> vicinity, and <italic toggle="yes">&#x003b3;</italic> is the adaptive discretization coefficient.</p><p>The <italic toggle="yes">x<sub>i</sub></italic> values quantization is performed to reduce noise and improve measurement accuracy:<disp-formula id="FD4-sensors-25-00990"><label>(8)</label><mml:math id="mm5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02206;</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>&#x000b7;</mml:mo><mml:mo>&#x02206;</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where round (&#x02022;) is the rounding function, and &#x00394; is the quantization step chosen based on signal statistics.</p><p>Wavelet transformation is applied to detect hidden patterns in the data. Appropriate basis wavelets <italic toggle="yes">&#x003c8;</italic>(<italic toggle="yes">t</italic>) are selected for signal decomposition. Discrete wavelet transformation (DWT) is applied to the signals to obtain their time&#x02013;frequency representation:<disp-formula id="FD5-sensors-25-00990"><label>(9)</label><mml:math id="mm6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mo>&#x0221e;</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x0221e;</mml:mo></mml:mrow></mml:munderover><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x000b7;</mml:mo><mml:mi>&#x003c8;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">x</italic>(<italic toggle="yes">u</italic>) is the original signal and <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c8;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is the basis of the wavelet with scale <italic toggle="yes">&#x003c4;</italic> and shift <italic toggle="yes">t</italic>.</p><p>The obtained wavelet coefficients detect hidden patterns and anomalies in the data. Specifically, abnormal regions are identified when the wavelet coefficient values exceed a certain threshold. Correlation coefficients are computed for each sensor combination using both traditional methods and methods based on the enhanced data:
<list list-type="order"><list-item><p>The rank difference di is determined for the comparable values of each pair.</p></list-item><list-item><p>The rank correlation coefficients are calculated using the following expression:
<disp-formula id="FD6-sensors-25-00990"><label>(10)</label><mml:math id="mm8" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>6</mml:mn><mml:mo>&#x000b7;</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> represents the squared rank difference sum <italic toggle="yes">s</italic>, and <italic toggle="yes">p</italic> is the paired observations number.</p></list-item><list-item><p>A sliding window is applied to analyze the data time series and calculate correlation coefficients at each window position. The window size is varied, and optimization methods are employed to determine the optimal window size that maximizes the average correlation coefficient for the combination. The arithmetic mean correlation is calculated as follows:
<disp-formula id="FD7-sensors-25-00990"><label>(11)</label><mml:math id="mm10" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>&#x000b7;</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">S</italic> represents the number of window positions, and <italic toggle="yes">r<sub>j</sub></italic> denotes the correlation coefficient for the <italic toggle="yes">j</italic>-th position.</p></list-item></list></p><p>The adaptive discretization and quantization implementation, combined with wavelet transformation, significantly enhances signal quality and reveals hidden patterns. The results of Hypothesis 1 with experimental verification are presented in <xref rid="sec3dot2-sensors-25-00990" ref-type="sec">Section 3.2</xref>.</p></sec><sec id="sec2dot2dot2-sensors-25-00990"><title>2.2.2. Development of the Second Hypothesis Testing Method</title><p>When addressing the task of fault detection using the parameter of the gas-generator rotor r.p.m. <italic toggle="yes">n<sub>TC</sub></italic>, it is assumed that a measurement is recorded for the <italic toggle="yes">n<sub>TC</sub></italic> parameter <italic toggle="yes">x<sub>i</sub></italic> at time <italic toggle="yes">t<sub>i</sub></italic>, creating a data array <bold>X</bold> = {<italic toggle="yes">x</italic><sub>1</sub>, <italic toggle="yes">x</italic><sub>2</sub>, &#x02026;, <italic toggle="yes">x<sub>n</sub></italic>}, where <italic toggle="yes">n</italic> represents the total number of the readings, which may include false changes in range due to noise.</p><p>Initially, adaptive discretization is applied to enhance signal quality (7), followed by the quantization of values <italic toggle="yes">x<sub>i</sub></italic> to reduce noise and improve measurement accuracy (8). Subsequently, the actual value is calculated using a degree <italic toggle="yes">d</italic> of the polynomial that approximates the helicopter TE&#x02019;s true characteristics while ignoring sensor faults:<disp-formula><italic toggle="yes">P</italic>(<italic toggle="yes">t</italic>) = <italic toggle="yes">a</italic><sub>0</sub> + <italic toggle="yes">a</italic><sub>1</sub>&#x000b7;<italic toggle="yes">t</italic> + <italic toggle="yes">a</italic><sub>2</sub>&#x000b7;<italic toggle="yes">t</italic><sup>2</sup> + &#x022ef; + <italic toggle="yes">a<sub>d</sub></italic>&#x000b7;<italic toggle="yes">t<sup>d</sup></italic>,<label>(12)</label></disp-formula>
where <italic toggle="yes">a</italic><sub>0</sub>, <italic toggle="yes">a</italic><sub>1</sub>, &#x02026;, <italic toggle="yes">a<sub>d</sub></italic> represent the polynomial coefficients.</p><p>The coefficients <italic toggle="yes">a<sub>j</sub></italic> are determined using the least squares method, expressed as follows:<disp-formula id="FD8-sensors-25-00990"><label>(13)</label><mml:math id="mm11" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The assumption regarding a fault is based on a significant deviation between measured data <italic toggle="yes">x<sub>i</sub></italic> and approximated values <italic toggle="yes">P</italic>(<italic toggle="yes">t<sub>i</sub></italic>). For instance, a sharp change in readings followed by a return to the original value may indicate interference or a fault, as this does not align with the helicopter TE operational dynamics and the helicopter flight. Such anomalous data must be identified and corrected. The following expression can be used to assess deviations:<disp-formula id="FD9-sensors-25-00990"><label>(14)</label><mml:math id="mm12" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The use of the polynomial for approximating readings enables the identification and exclusion of faults caused by interference. The challenge in data processing and polynomial selection lies in the outlier&#x02019;s presence, which must be accounted for in the polynomial coefficients. The polynomial degree is determined through a measured and reconstructed data stepwise approximation.</p><p>The algorithm&#x02019;s first step assigns a specific weight to all readings. This step identifies moments in time (readings) where actual data significantly deviate from the reconstructed polynomial. Readings with sharp changes are assigned a lower weight to minimize their impact on the polynomial:<disp-formula id="FD10-sensors-25-00990"><label>(15)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">k</italic> is the sensitivity coefficient. Based on the new weights, the polynomial is re-selected as follows:<disp-formula id="FD11-sensors-25-00990"><label>(16)</label><mml:math id="mm14" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In the second step, deviation analysis is conducted. A threshold value for deviation &#x00394; is introduced, determined by the helicopter TE design features. The data are considered anomalous if the deviation exceeds the threshold value &#x00394; (<italic toggle="yes">Dev<sub>i</sub></italic> &#x0003e; &#x00394;).</p><p>In the third step, the points have redistributed weights, and the polynomial is refitted. This process enhances the accuracy of sensor reading interpolation.</p><p>The results of Hypothesis 2 with experimental verification are presented in <xref rid="sec3dot2-sensors-25-00990" ref-type="sec">Section 3.2</xref>.</p></sec></sec><sec id="sec2dot3-sensors-25-00990"><title>2.3. Development of a Neural Network System</title><p>The research presents an algorithm for processing input data (see <xref rid="sensors-25-00990-f001" ref-type="fig">Figure 1</xref>), which enables sensor readings and correlations to be predicted based on known data [<xref rid="B30-sensors-25-00990" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-00990" ref-type="bibr">31</xref>]. Fault locations are identified by comparing actual and predicted correlation values. If the prediction error exceeds a specified threshold, a fault is recorded. The proposed input data processing algorithm consists of the following:<list list-type="order"><list-item><p>The clean_parser module (data_parser) sends telemetry data intended for smoothing to the Sensor_Fail_Clean module (sensor_fail) in the Input channel.</p></list-item><list-item><p>The norm_parser module (data_parser) sends telemetry data designated for normalization to the SensorFailNorm module (sensor_fail) in the Input channel.</p></list-item><list-item><p>The Sensor_Fail_Clean module (sensor_fail) smooths data, performs adaptive discretization and quantization and sends the results to the Data_Retriever module (data_retriver) in the Input_Train channel.</p></list-item><list-item><p>The Sensor_Fail_Norm module (sensor_fail) normalizes telemetry data and sends them to the Data_Retriever module (data_retriver) in the Input_Detect channel.</p></list-item><list-item><p>The Data_Retriever module (data_retriver) performs the following:
<list list-type="bullet"><list-item><p>Determines sensor groups with maximum correlation based on data from the Input_Train channel;</p></list-item><list-item><p>Computes correlation values from the Input_Detect channel;</p></list-item><list-item><p>Identifies prediction errors in correlations.</p></list-item></list></p></list-item><list-item><p>The Recorder module (export_jpeg) receives graphical results from the Input channel and saves them.</p></list-item></list></p><p>To implement this algorithm, the research proposes a recurrent neural network (RNN) utilizing LSTM (Long Short-Term Memory) [<xref rid="B32-sensors-25-00990" ref-type="bibr">32</xref>] and GRU (Gated Recurrent Unit) [<xref rid="B33-sensors-25-00990" ref-type="bibr">33</xref>] mechanisms, which represent enhanced versions of standard RNNs (<xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>). The main idea behind this architecture is its ability to efficiently process temporal data sequences, making it ideally suited for analyzing telemetry data and forecasting correlations.</p><p>In the proposed neural network, input layers receive data (Clean Parser and Norm Parser), where recurrent layers process the data by performing smoothing, normalization, and correlation analysis (Sensor_Fail_Clean and Sensor_Fail_Norm); extraction layers identify correlations and errors (Data_Retriver); and the output layer stores the resulting diagrams (Recorder).</p><p>The Clean Parser layer (data_parser) is the input layer responsible for receiving telemetry data that require smoothing. The data are transmitted to the Sensor_Fail_Clean module through the Input channel. The network&#x02019;s input layer accepts data for smoothing and forwards them for adaptive processing.</p><p>The Norm Parser layer (data_parser) is the input layer, which operates similarly, but the data are directed to normalization in the Sensor_Fail_Norm module through the Input channel. Here, the input layer receives data for normalization and forwards them for further processing.</p><p>The Sensor_Fail_Clean layer (sensor_fail) is the recurrent layer + adaptive processing, which processes telemetry data for smoothing using adaptive discretization and quantization, then transmits the results to the next module via the Input_Train channel.</p><p>The Sensor_Fail_Norm layer (sensor_fail) is the recurrent layer + normalization, which normalizes telemetry data. Like the previous module, it is a recurrent layer with added data normalization functionality, passing the data to the next module through the Input_Detect channel.</p><p>The Data_Retriver layer (data_retriver) is the feature extraction layer + correlation calculation and is responsible for data processing, identifying sensor groups with maximum correlation, and predicting correlation errors. It is a recurrent layer with an attention mechanism for extracting significant temporal correlations. It identifies sensor groups with the highest correlation based on Input_Train data, calculates the correlation from Input_Detect data, and predicts correlation errors.</p><p>The Recorder layer (export_jpeg) is the output layer that finalizes the algorithm by saving the correlation analysis results in the diagram.</p><p>Recurrent layers (LSTM/GRU) process sequential data, such as the sensor telemetry time series. LSTM and GRU can retain important information about previous states in memory, allowing them to predict future values more accurately, detect dependencies in the data, such as correlations, and predict errors. These layer&#x02019;s main advantage is their ability to address the vanishing or exploding gradient problem, which often occurs in standard RNNs, especially when working with long sequences.</p><p>The Data_Retriver module employs an attention mechanism that focuses on the essential parts of the input data, ignoring less significant ones. It is critical for correlation analysis tasks, as it is necessary to identify key dependencies between sensors in large datasets. The attention mechanism helps the model detect key time points and sensors with high correlations, contributing to more accurate predictions and error localization.</p><p>In the Sensor_Fail_Clean and Sensor_Fail_Norm modules, adaptive discretization and quantization allow the data processing parameters to be dynamically adjusted according to their properties. This architecture is essential for preprocessing data before passing them to the recurrent layers.</p><p>The Data_Retriver module also implements mechanisms for feature extraction, such as correlation calculations and identifying sensor groups with the highest correlation. This part is responsible for detecting significant relations in the data, which is a critical task in telemetry analysis.</p><p>A training algorithm for the proposed recurrent neural network (RNN) was developed based on LSTM or GRU. It includes time-dependent regularization, adaptive gradient correction, and an optimized method that combines stochastic gradient descent (SGD) and RMSProp properties [<xref rid="B34-sensors-25-00990" ref-type="bibr">34</xref>,<xref rid="B35-sensors-25-00990" ref-type="bibr">35</xref>]. This algorithm considers temporal dependencies and ensures more accurate weight updates, accelerating convergence and enhancing resistance to vanishing gradient problems.</p><p>The target function minimizes the prediction error for temporal sequential data <italic toggle="yes">x</italic><sup>(<italic toggle="yes">t</italic>)</sup>. It is assumed that <italic toggle="yes">y</italic><sup>(<italic toggle="yes">t</italic>)</sup> represents the valid values, while <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> represents the model predictions. The loss function defines the error at time <italic toggle="yes">t</italic>:<disp-formula id="FD12-sensors-25-00990"><label>(17)</label><mml:math id="mm16" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The complete loss function for the entire sequence is expressed as follows:<disp-formula id="FD13-sensors-25-00990"><label>(18)</label><mml:math id="mm17" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>&#x000b7;</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In traditional RNNs, gradient issues are often caused by excessively large or small weight values. Time-dependent regularization was introduced to address this, which adaptively adjusts the regularization coefficient based on time <italic toggle="yes">t</italic> during training. L2 regularization with parameter <italic toggle="yes">&#x003bb;</italic><sup>(<italic toggle="yes">t</italic>)</sup> is applied as follows:<disp-formula id="FD14-sensors-25-00990"><label>(19)</label><mml:math id="mm18" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>&#x003bb;</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003bb;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">&#x003bb;</italic><sub>0</sub> is the initial regularization coefficient, and <italic toggle="yes">&#x003b1;</italic> is the regularization decay rate. It reduces the regularization effect in later training stages when network weights stabilize. To counter vanishing gradients, gradient correction is introduced based on the predicted gradient amplitude <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and the actual value <italic toggle="yes">g<sub>t</sub></italic>. If the difference between the predicted and actual gradient is too significant, the following correction is applied:<disp-formula id="FD15-sensors-25-00990"><label>(20)</label><mml:math id="mm20" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003f5;</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">&#x003f5;</italic> is a small positive number to prevent the division by zero, allowing the network to avoid abrupt gradient changes and improving training stability.</p><p>An optimization method combining RMSProp with stochastic gradient descent (SGD) is employed for more efficient weight updates. It helps account for gradient moments and accelerates convergence during training. The weight update uses an expression with an adaptive training rate as follows:<disp-formula id="FD16-sensors-25-00990"><label>(21)</label><mml:math id="mm21" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003f5;</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">g<sub>t</sub></italic> is the current gradient value, <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the exponentially weighted average squared gradient, <italic toggle="yes">&#x003f5;</italic> is a small positive number to prevent division by zero, and <italic toggle="yes">&#x003b7;<sub>t</sub></italic> is the adaptive training rate, defined as follows:<disp-formula id="FD17-sensors-25-00990"><label>(22)</label><mml:math id="mm23" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">&#x003b7;</italic><sub>0</sub> represents the initial training rate, <italic toggle="yes">&#x003b2;</italic> denotes the training rate decay parameter, and <italic toggle="yes">t</italic> indicates the current iteration number.</p><p>The update for the exponentially weighted average squared gradient is performed as follows:<disp-formula id="FD18-sensors-25-00990"><label>(23)</label><mml:math id="mm24" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b2;</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x000b7;</mml:mo><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The training algorithm employs an attention mechanism that assists the model in focusing on significant temporal moments. Attention is calculated as follows:<disp-formula id="FD19-sensors-25-00990"><label>(24)</label><mml:math id="mm25" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mi>d</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">h<sub>t</sub></italic> represents hidden states at time <italic toggle="yes">t</italic>, <italic toggle="yes">W<sub>a</sub></italic> denotes the trainable attention matrix, <italic toggle="yes">h<sub>s</sub></italic> signifies hidden states from previous time steps, and <italic toggle="yes">d</italic> indicates the hidden state dimensionality. The attention mechanism assists in highlighting the most crucial time steps for the current moment in training, enhancing the model&#x02019;s ability to handle long sequences.</p><p>The developed algorithm outperforms traditional error backpropagation methods due to an adaptive training rate that automatically adjusts based on task complexity, thereby accelerating convergence and avoiding local minima. The gradient correction mechanism prevents abrupt weight changes, enhancing training stability. Control over the mean squared gradient allows for more precise weight updates, while the attention mechanism improves performance with a long time series by focusing on significant moments. These enhancements expedite convergence, reduce computational costs, and increase resilience against vanishing gradients.</p></sec></sec><sec id="sec3-sensors-25-00990"><title>3. Case Study</title><sec id="sec3dot1-sensors-25-00990"><title>3.1. Results from the Preliminary Processing of Input Data and Testing Proposed Hypotheses</title><p>The research&#x02019;s experimental parameters include the initial learning rate (<italic toggle="yes">&#x003b7;</italic><sub>0</sub> = 0.01) chosen to ensure the model&#x02019;s smooth convergence in training and minimize weight oscillations in early stages, and the training rate decay parameter (<italic toggle="yes">&#x003b2;</italic> = 0.9) allows the training rate to undergo adaptive reduction as the model stabilizes, reducing the overfitting risk. The hidden state dimension (<italic toggle="yes">d</italic> = 128) ensures complex time-efficient processing dependencies with reasonable computational load. Time dependence regularization, including the initial regularization coefficient (<italic toggle="yes">&#x003bb;</italic><sub>0</sub> = 0.01) and the decay coefficient (<italic toggle="yes">&#x003b1;</italic>), reduces the overfitting and improves the model convergence effect in the late stages. A hybrid method combining SGD and RMSProp is used to optimize the gradient step, which contributes to more robust and faster convergence, especially in the presence of extended data sequences. The correlation threshold (<italic toggle="yes">&#x003f5;</italic> = 0.025) is empirically determined based on helicopter TE characteristics to effectively identify faults while minimizing false alarms. These parameters ensure the model&#x02019;s high accuracy and robustness under noisy and complex time dependencies, which is confirmed by the experimental results.</p><p>To conduct the computational experiment, data were collected during TV3-117 turboshaft engine (TE) flight tests aboard the Mi-8MTV helicopter using an onboard control system (recording occurred over a 320-s interval from an actual flight with a 1.0-s sampling period [<xref rid="B36-sensors-25-00990" ref-type="bibr">36</xref>]). It is essential to mention that the flight data were acquired following an official request from the author&#x02019;s team to the Ministry of Internal Affairs of Ukraine as part of the research project titled &#x0201c;Theoretical and applied aspects of the development of the aviation sphere&#x0201d;, which is state-registered in Ukraine under No. 0123U104884. Using the obtained data, a time series diagram for the parameters <italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, and <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> (recorded onboard the helicopter through sensors D-2M, D-1M, and 14 dual thermocouples T-101, respectively [<xref rid="B28-sensors-25-00990" ref-type="bibr">28</xref>]) is reconstructed (<xref rid="sensors-25-00990-f003" ref-type="fig">Figure 3</xref>). The TV3-117 TE parameter dynamics reflect the time series shape complexity (<xref rid="sensors-25-00990-f003" ref-type="fig">Figure 3</xref>), and the curves indicate the necessity to consider the parameter values and accumulate information in the model&#x02019;s memory.</p><p>In <xref rid="sensors-25-00990-f003" ref-type="fig">Figure 3</xref>, an increase in parameters is observed in the interval from 21 to 62 s, approximately 1.5 to 1.8 times, which is associated with the engine&#x02019;s transient operating mode. As mentioned in the introduction, about 85% of the time, the engine operates in steady modes and operates around 15% of the time in transient modes.</p><p>Time series are extracted from flight data by extracting successive values of the recorded parameters (<italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, and <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>) within each time interval. These data represent discrete measurements that can be interpreted as the time series recording parameter changes over the flight dynamics. Time series are normalized using the <italic toggle="yes">z</italic>-transformation method, where, for the <italic toggle="yes">x<sub>t</sub></italic> series, each value is transformed according to the following expression: <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">x<sub>t</sub></italic> is the time series value at time <italic toggle="yes">t</italic>, <italic toggle="yes">&#x003bc;</italic> is the series&#x02019; mean value, and <italic toggle="yes">&#x003c3;</italic> is the series&#x02019; standard deviation. This method transforms the data so that their distribution has zero mean and unit variance, which helps to eliminate the scale differences between the influence of different parameters and further improves the analysis efficiency and application of machine learning models.</p><p>Thus, according to [<xref rid="B36-sensors-25-00990" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-00990" ref-type="bibr">37</xref>,<xref rid="B38-sensors-25-00990" ref-type="bibr">38</xref>], 256 values for <italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, and <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> were selected (<xref rid="sensors-25-00990-f003" ref-type="fig">Figure 3</xref>, <xref rid="sensors-25-00990-t001" ref-type="table">Table 1</xref>).</p><p>This size of the training dataset is justified as it provides sufficient coverage of possible variations in helicopter TE parameters, allowing the neural network to train effectively and accurately control engine sensor operations in actual flight conditions. Additionally, a sample of 256 values is adequate to meet the conditions for normal distribution, which is critical for the training dataset&#x02019;s statistical significance and reliability when applying a neural network for monitoring helicopter TE sensors.</p><p>To verify the training dataset&#x02019;s homogeneity, as outlined in [<xref rid="B39-sensors-25-00990" ref-type="bibr">39</xref>,<xref rid="B40-sensors-25-00990" ref-type="bibr">40</xref>], a value of <italic toggle="yes">&#x003c7;</italic><sup>2</sup> = 24.915 was calculated, which is less than the critical value <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> = 27.683 with degrees of freedom <italic toggle="yes">df</italic> = 13 and a significance level of <italic toggle="yes">&#x003b1;</italic> = 0.01, indicating homogeneity based on the Fisher&#x02013;Pearson criterion. The training dataset (<italic toggle="yes">N</italic> = 256) was split into two subsets of 128 elements each. According to [<xref rid="B41-sensors-25-00990" ref-type="bibr">41</xref>,<xref rid="B42-sensors-25-00990" ref-type="bibr">42</xref>], the Fisher&#x02013;Snedecor test yielded a value of <italic toggle="yes">F</italic> = 5.565, which is below the critical value <italic toggle="yes">F<sub>critical</sub></italic> = 5.74, further confirming homogeneity under the Fisher&#x02013;Snedecor criterion. A cluster analysis was conducted to assess the representativeness of the training and test sets as per [<xref rid="B43-sensors-25-00990" ref-type="bibr">43</xref>,<xref rid="B44-sensors-25-00990" ref-type="bibr">44</xref>,<xref rid="B45-sensors-25-00990" ref-type="bibr">45</xref>]. Based on the data presented in <xref rid="sensors-25-00990-t001" ref-type="table">Table 1</xref>, the training and test sets were split in a 2:1 ratio (172 and 84 elements). Cluster analysis identified eight classes, confirming the representativeness of both the training and test sets (<xref rid="sensors-25-00990-f004" ref-type="fig">Figure 4</xref>). The optimal sizes are as follows: the training set has 256 elements, the validation set has 172, and the test set has 84.</p><p>To justify the process ergodicity, the Slutsky condition was tested, which states that the autocovariance function of an ergodic process should approach zero as the lag increases [<xref rid="B46-sensors-25-00990" ref-type="bibr">46</xref>,<xref rid="B47-sensors-25-00990" ref-type="bibr">47</xref>]. The research results confirm the hypothesis regarding the observed processes&#x02019; ergodicity. The analysis diagrams for the parameters <italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, and <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> are shown in <xref rid="sensors-25-00990-f005" ref-type="fig">Figure 5</xref>.</p></sec><sec id="sec3dot2-sensors-25-00990"><title>3.2. Results of Hypotheses 1 and 2 Confirmation</title><p>To confirm Hypothesis 1, a computational experiment was conducted to identify interconnected sets of sensors based on telemetry file data, with the results presented in <xref rid="sensors-25-00990-t002" ref-type="table">Table 2</xref>.</p><p>The correlation coefficient values of 0.876 for two sensors (<italic toggle="yes">n<sub>TC</sub></italic> and <italic toggle="yes">n<sub>FT</sub></italic>) and 0.913 for three sensors (<italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic> and <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>) confirm a strong and stable correlation among these parameters, suggesting that adequately functioning sensors exhibit consistent interdependencies due to the helicopter TE&#x02019;s inherent design characteristics. The moderate correlation coefficient of 0.754 for five sensors (<italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">T<sub>oil</sub></italic> and <italic toggle="yes">P<sub>oil</sub></italic>) and 0.735 for six sensors (<italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">T<sub>oil</sub></italic>, <italic toggle="yes">P<sub>oil</sub></italic> and <italic toggle="yes">n<sub>rs</sub></italic>) demonstrates a slight reduction in correlation as more sensors are added. However, the overall trend supports the hypothesis that functioning sensors are structurally designed to correlate under operational conditions. The correlation analysis further validates the hypothesis by showing that sensor readings maintain robust relations, even when subjected to varying operational parameters, reinforcing the sensor&#x02019;s performance reliability and predictability in helicopter TE systems. A decrease in correlation coefficients by an average of 23.7% was detected when noise was introduced into sensor readings, indicating their sensitivity to external influences. The results also confirmed the system&#x02019;s response to simulated device failure, reflecting altered dynamics in correlations between parameters.</p><p>To confirm Hypothesis 2, the fault detection issue was considered using the <italic toggle="yes">n<sub>TC</sub></italic> parameter as an example. An <italic toggle="yes">n<sub>TC</sub></italic> recording was generated and linked to a time scale in the measurement channel. The measurements formed in this manner created an array that also contained false information regarding changes in the <italic toggle="yes">n<sub>TC</sub></italic> due to the noise influence. Next, the actual value was calculated using an approximating polynomial that considered the helicopter TE&#x02019;s fundamental characteristics while &#x0201c;ignoring&#x0201d; the presence of a sensor&#x02019;s fault caused by interference. The fault assumption is based on the fact that sensor readings may not comply with the physical laws governing the helicopter TE&#x02019;s operation. For instance, a sudden change in the range sensor reading followed by a return to the initial position indicates noise presence or a sensor fault, as this does not align with the helicopter TE&#x02019;s operational dynamics. Such readings must be recognized and corrected by filtering out the noise. <xref rid="sensors-25-00990-f006" ref-type="fig">Figure 6</xref> illustrates a short-term disturbance effect on the range characteristic, allowing for the fault&#x02019;s presence and visual observation.</p><p>As the experimental research result, &#x00394; = 0.025 was accepted. In <xref rid="sensors-25-00990-f007" ref-type="fig">Figure 7</xref>, the sensor readings are shown in black; the data restored by the polynomial are presented in light blue; and the moments when the measured value deviations exceeded the allowable threshold are marked in red. The sensor failure occurred at 102 s, after which the sensor began providing inadequate readings.</p><p>The point weights are redistributed in the third step, and the polynomial is recalculated using the developed neural network (<xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>). This approach enhances the accuracy of sensor reading&#x02019;s interpolation. The neural network&#x02019;s output is shown in <xref rid="sensors-25-00990-f008" ref-type="fig">Figure 8</xref>, where the <italic toggle="yes">n<sub>TC</sub></italic> sensor&#x02019;s actual readings are marked in black, and the restored values, based on the analysis of readings and fault detection, are displayed in blue.</p></sec><sec id="sec3dot3-sensors-25-00990"><title>3.3. Results from Solving the Fault Detection Problem Using the Correlation Dependency Analysis Method</title><p>A computational experiment was conducted using a developed semi-physical simulation stand (SPSS) (<xref rid="sensors-25-00990-f009" ref-type="fig">Figure 9</xref>) designed to simulate helicopter TE parameters in real time and model their operating modes across various altitudes and flight speeds. The SPSS also interacts with upper-level systems via data channels, tests the automatic control, monitoring, and diagnostic system (ACMDS), and addresses other tasks [<xref rid="B48-sensors-25-00990" ref-type="bibr">48</xref>,<xref rid="B49-sensors-25-00990" ref-type="bibr">49</xref>,<xref rid="B50-sensors-25-00990" ref-type="bibr">50</xref>]. <xref rid="sensors-25-00990-f009" ref-type="fig">Figure 9</xref> illustrates the interaction between the neural network and the SPSS. The helicopter TE model operates in two-time cycles, each executed on a separate CPU core (for the computational experiment in this study, an AMD Ryzen 5 5600 processor with 3.5 GHz, six cores, and 12 threads, Germany, Dresden, was used).</p><p>The high-priority cycle processes data from the SPSS and runs the neural network, while the lower-priority cycle sends the results back to the SPSS, ensuring real-time operation. The SPSS functions within the Matlab Simulink R2014b graphical environment (version 2014b), where data exchange channels, a fuel valve emulator, a visualization system, and other components are implemented (<xref rid="sensors-25-00990-f010" ref-type="fig">Figure 10</xref>). The neural network is integrated into Simulink using built-in tools, facilitating seamless model implementation [<xref rid="B50-sensors-25-00990" ref-type="bibr">50</xref>].</p><p>The semi-physical modelling stand diagram, developed in MATLAB Simulink R2014b (<xref rid="sensors-25-00990-f010" ref-type="fig">Figure 10</xref>), is a complex system that includes input, computational and output modules. Input signals are formed in data generation blocks that model physical processes or external influences and can also come from sensors or real devices. These signals are transmitted through multiplexers, which combine them into a vector for processing. The diagram&#x02019;s central part contains computational modules that include the control object&#x02019;s models, calculation and filtering algorithms, and control and feedback subsystems. The system&#x02019;s dynamics are modelled, taking into account the object&#x02019;s parameters, and the feedback blocks are corrected based on the output parameter&#x02019;s deviations from the specified values. The diagram also contains modules for storing intermediate results and constant parameters, presented in the memory blocks and constants formed, which allow the system to be adapted to changing conditions or simulation scenarios. Logical switches and control blocks enable operating modes and switch signal processing trajectories to be set. The output data are sent to visualization units such as graphical interfaces or data logging tools and can also be transmitted to real devices for control or analysis.</p><p>If the neural network module operates correctly, three graphical files can be generated: a diagram for the set <italic toggle="yes">n<sub>TC</sub></italic> and <italic toggle="yes">n<sub>FT</sub></italic>; a diagram for the set <italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, and <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>; and a diagram for the set <italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">T<sub>oil</sub></italic>, <italic toggle="yes">P<sub>oil</sub></italic> and <italic toggle="yes">n<sub>rs</sub></italic>. These diagrams are shown in <xref rid="sensors-25-00990-f011" ref-type="fig">Figure 11</xref>, <xref rid="sensors-25-00990-f012" ref-type="fig">Figure 12</xref> and <xref rid="sensors-25-00990-f013" ref-type="fig">Figure 13</xref>, where the neural network prediction errors are represented in blue, and Spearman&#x02019;s rank correlation [<xref rid="B51-sensors-25-00990" ref-type="bibr">51</xref>,<xref rid="B52-sensors-25-00990" ref-type="bibr">52</xref>] predictions for the sensor set are shown in red. The testing results are presented in <xref rid="sensors-25-00990-f014" ref-type="fig">Figure 14</xref> and <xref rid="sensors-25-00990-t003" ref-type="table">Table 3</xref>.</p><p><xref rid="sensors-25-00990-t003" ref-type="table">Table 3</xref> demonstrates a significant reduction in computation time as the number of cores and threads increases, with the relative time improving up to six times when using all 12 threads. However, the performance gains diminish as the core and thread count increase beyond eight, suggesting a levelling effect in efficiency improvements. The results enable research in the time series value approximation field, opening opportunities for more accurate dynamic process modelling and analysis.</p></sec><sec id="sec3dot4-sensors-25-00990"><title>3.4. Results from Time Series Value Approximation</title><p>In the computational experiment&#x02019;s next stage, the approximation task of time series values under the sensor failure conditions is addressed (<xref rid="sensors-25-00990-f015" ref-type="fig">Figure 15</xref>). The input data consist of readings from six sensors and their corresponding time values (<xref rid="sensors-25-00990-t004" ref-type="table">Table 4</xref>). The input data processing algorithm is represented as follows:<list list-type="bullet"><list-item><p>Step 1. The Data_Retriever module (data_retriver) sends telemetry data to the Sensor_Fail module (sensor_fail) via the Input channel;</p></list-item><list-item><p>Step 2. The Sensor_Fail module (sensor_fail) processes the telemetry data and transfers an image showing both raw and smoothed telemetry data to the Recorder module (export_jpeg);</p></list-item><list-item><p>Step 3. The Recorder module (export_jpeg) saves the generated images.</p></list-item></list></p><p><xref rid="sensors-25-00990-f016" ref-type="fig">Figure 16</xref> shows the detected sensor failures (visually undetectable). The implementation of the Sensor_Fail module does not support the processing of parallel input data at this stage. During SPSS testing (<xref rid="sensors-25-00990-f010" ref-type="fig">Figure 10</xref>) using a single unit, the results presented in <xref rid="sensors-25-00990-t005" ref-type="table">Table 5</xref> were obtained.</p></sec><sec id="sec3dot5-sensors-25-00990"><title>3.5. Results of Neural Network Quality Assessment</title><p>An evaluation of the developed neural network (<xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>) performance was conducted using key quality metrics such as accuracy, loss, precision, recall, the F1-metric [<xref rid="B53-sensors-25-00990" ref-type="bibr">53</xref>,<xref rid="B54-sensors-25-00990" ref-type="bibr">54</xref>,<xref rid="B55-sensors-25-00990" ref-type="bibr">55</xref>], and AUC-ROC [<xref rid="B56-sensors-25-00990" ref-type="bibr">56</xref>,<xref rid="B57-sensors-25-00990" ref-type="bibr">57</xref>]. These metrics allow the model to undergo a comprehensive assessment to make accurate predictions, minimize errors, correctly identify relevant instances, and maintain a balance between precision and recall. The F1-metric offers insight into the precision and recall harmonic mean, while AUC-ROC measures the model&#x02019;s capability to distinguish between classes across different thresholds, ensuring robustness in various operational scenarios. These metrics are calculated according to the following expressions [<xref rid="B53-sensors-25-00990" ref-type="bibr">53</xref>,<xref rid="B55-sensors-25-00990" ref-type="bibr">55</xref>,<xref rid="B56-sensors-25-00990" ref-type="bibr">56</xref>]:<disp-formula id="FD20-sensors-25-00990"><label>(25)</label><mml:math id="mm40" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>&#x000b7;</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:mn>1</mml:mn><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000b7;</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>A</mml:mi><mml:mi>U</mml:mi><mml:mi>C</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>R</mml:mi><mml:mi>O</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In this context, <italic toggle="yes">y<sub>i</sub></italic> represents the actual label for the <italic toggle="yes">i</italic>-th instance, while <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> stands for the predicted label produced by the model for that same instance. <italic toggle="yes">N</italic> indicates the total count of examples in the dataset (whether for the training or validation dataset), and the indicator function <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mrow><mml:mn mathvariant="bold">1</mml:mn><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> returns a value of 1 if the true and predicted labels are equal and returns a value of 0 otherwise. In the context of fault detection and sensor data restoration, <italic toggle="yes">TP</italic> (True Positive) refers to cases when a fault was correctly identified, and the sensor recorded erroneous values. <italic toggle="yes">TN</italic> (True Negative) signifies instances where the system correctly recognized the absence of faults, and the sensor readings were accurate. <italic toggle="yes">FP</italic> (False Positive) describes situations where the system mistakenly detected a fault, though the sensor data were correct. <italic toggle="yes">FN</italic> (False Negative) represents cases where a fault was present, but the system failed to detect it. <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula> (True Positive Rate) measures the proportion of correctly identified faults from all actual faults, while <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula> (False Positive Rate) indicates the false alarm proportion when the system wrongly identified faults.</p><p><xref rid="sensors-25-00990-f017" ref-type="fig">Figure 17</xref> and <xref rid="sensors-25-00990-f018" ref-type="fig">Figure 18</xref> show accuracy and loss metrics diagrams. The developed neural network (<xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>) accuracy metric reaches 99.327% after 200 training epochs to solve the fault detection in sensor-recorded values during the restoring task. This high performance demonstrates the model&#x02019;s effectiveness in identifying anomalies and restoring correct data under varying conditions. The loss of the developed neural network (<xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>) decreases from 2.5 to 0.5% after 200 training epochs to solve the fault detection in sensor-recorded values during the restoring task. This loss reduction reflects the network&#x02019;s improved accuracy and stability in handling sensor data anomalies.</p><p>The developed neural network achieved a precision score of 0.987, a recall score of 1.0, and an F1-score of 0.993 in the sensor-recorded values during the fault detection and restoring task. These metrics indicate high accuracy and reliability in identifying faults while maintaining zero False Negatives. The F1-score demonstrates the model&#x02019;s balanced performance in precision and recall terms.</p><p>The obtained results were compared (<xref rid="sensors-25-00990-t006" ref-type="table">Table 6</xref> and <xref rid="sensors-25-00990-t007" ref-type="table">Table 7</xref>, <xref rid="sensors-25-00990-f019" ref-type="fig">Figure 19</xref> and <xref rid="sensors-25-00990-f020" ref-type="fig">Figure 20</xref>) with two alternative approaches: approach 1 is a method for restoring lost information when sensors fail using an auto-associative neural network (autoencoder) [<xref rid="B37-sensors-25-00990" ref-type="bibr">37</xref>], and approach 2 is a neural network system for predicting anomalous data based on the SARIMAX model with LSTM blocks [<xref rid="B58-sensors-25-00990" ref-type="bibr">58</xref>].</p><p>The comparative results reveal that the proposed approach outperforms both alternative methods in terms of accuracy (0.993 vs. 0.981 and 0.982), precision (0.987 vs. 0.980 and 0.979), and F1-score (0.993 vs. 0.988 and 0.989). Notably, all approaches achieved the same recall score of 1.0, indicating that they effectively detected all actual faults. However, the superior accuracy and precision of the proposed method underscore its potential for enhanced reliability in fault detection and the restoration of values in helicopter TE sensor systems.</p><p>The monitoring system successfully detected 99 cases of real sensor failures, which indicates its ability to record significant deviations in readings. These could be failures such as mechanical damage to the rotors (D-2M and D-1M sensors), electromagnetic interference or component wear, and incorrect temperature measurements due to damage to the thermocouple (T-101 sensor). However, 13 real failures remained unnoticed. These cases are likely due to minor parameter deviations or complex defects that the system erroneously classified as normal. At the same time, the system gave 289 False Positives, erroneously classifying normal readings as failures. This may be due to their high sensitivity to noise, measurement errors or inadequate classification thresholds. This situation leads to an increase in the number of false alarms.</p><p>To improve the system&#x02019;s performance, it is necessary to optimize the data processing algorithms, including noise filtering, threshold adjustment, and refinement of the model to detect subtle faults. It is also recommended that individual fault types for each sensor are analyzed to understand which faults the system ignores or misclassifies. It will improve the classification accuracy and reduce both False Positives and False Negatives, which is critical to ensuring the helicopter TE&#x02019;s reliability.</p><p>The comparative analysis based on AUC-ROC metrics (<xref rid="sensors-25-00990-f020" ref-type="fig">Figure 20</xref>) demonstrates that the proposed approach achieves a superior AUC-ROC score of 0.823, outperforming both alternative methods, which scored 0.818 each. This improvement is accompanied by an actual positive rate of 0.822, indicating a robust capability to identify actual faults while maintaining a low False Positive rate of 0.0111. The lower number of False Negatives (13) further highlights the proposed method&#x02019;s effectiveness in minimizing missed detections compared to alternative approaches.</p><p>To evaluate the proposed approach&#x02019;s effectiveness in efficiency terms, this research utilizes the <italic toggle="yes">Efficiency</italic> metric, which incorporates both prediction accuracy and the resources consumed during training and/or inference. This metric can represent the relationship between accuracy and resource usage (such as computational power or time). Here, <italic toggle="yes">Acc</italic><sub>1</sub>, <italic toggle="yes">Acc</italic><sub>2</sub>, and <italic toggle="yes">Acc</italic><sub>3</sub> signify the three neural network accuracies under comparison (the proposed neural network (<xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>), the auto-associative neural network (autoencoder) [<xref rid="B37-sensors-25-00990" ref-type="bibr">37</xref>], and the SARIMAX model with LSTM blocks [<xref rid="B58-sensors-25-00990" ref-type="bibr">58</xref>]), while <italic toggle="yes">Res</italic><sub>1</sub>, <italic toggle="yes">Res</italic><sub>2</sub>, and <italic toggle="yes">Res</italic><sub>3</sub> represent the resources employed (in this investigation, the training time parameter was adopted, as both networks were evaluated under an identical memory capacity of 32 GB DDR-4). The resource efficiency (<xref rid="sensors-25-00990-t008" ref-type="table">Table 8</xref> and <xref rid="sensors-25-00990-f021" ref-type="fig">Figure 21</xref>) is then calculated using the following expression:<disp-formula id="FD22-sensors-25-00990"><label>(26)</label><mml:math id="mm45" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>E</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>E</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The comparison results indicate that the proposed approach achieves an accuracy of 0.993 while maintaining a training time of 4 min and 13 s, resulting in a resource efficiency metric of 0.00392. In contrast, Alternative Approach 1 demonstrates an accuracy of 0.981 with a longer training duration of 5 min and 43 s, yielding an efficiency value of 0.00288. Similarly, Alternative Approach 2 achieves an accuracy of 0.982 with a training time of 4 min and 46 s, resulting in a resource efficiency metric of 0.00343.</p><p>All three approaches demonstrate optimal and efficient performance for implementation onboard a helicopter. However, the proposed approach exhibits a slight accuracy and resource efficiency advantage, making it the preferred choice for real-time applications in this context.</p></sec></sec><sec sec-type="discussion" id="sec4-sensors-25-00990"><title>4. Discussion</title><p>This article presents a neural network system for monitoring helicopter TE sensors (see <xref rid="sensors-25-00990-f001" ref-type="fig">Figure 1</xref>). The developed system includes the following modules: the clean_parser module sends telemetry data for smoothing to the Sensor_Fail_Clean module via the Input channel; the norm_parser module transfers data for normalization to the Sensor_Fail_Norm module through the Input channel; the Sensor_Fail_Clean module smooths the data, performs adaptive discretization and quantization, and then passes it to the Data_Retriever module through the Input_Train channel; and the Sensor_Fail_Norm module normalizes the data and sends it to the same module via the Input_Detect channel. The Data_Retriever module identifies sensor groups with maximum correlation using data from Input_Train, calculates correlations from Input_Detect, and detects predicted errors. The Recorder module saves the diagrams of the results obtained through the Input channel. This system is implemented as a hybrid LSTM/GRU neural network (see <xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>). The recurrent layers (LSTM/GRU) process sequential data, such as telemetry time series, retaining key information about previous states for more accurate prediction and dependency identification, including correlations and forecast errors. Their advantage is that they overcome the vanishing or exploding gradient problem, especially when working with long sequences. The Data_Retriever module uses an attention mechanism to focus on significant parts of the data, which is crucial for correlation analysis, highlighting critical dependencies between sensors. The Sensor_Fail_Clean and Sensor_Fail_Norm modules apply adaptive discretization and quantization for dynamic processing parameter adjustments, improving data quality before feeding this into the recurrent layers. The Data_Retriever model also performs correlation calculations and identifies sensor groups with the highest correlation, which is essential for telemetry analysis.</p><p>An algorithm for training the proposed neural network based on a hybrid LSTM/GRU architecture (see <xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>) has been developed, incorporating temporal regularization, adaptive gradient correction, and a combined optimization method that integrates stochastic gradient descent (SGD) with RMSProp (17)&#x02013;(24). This algorithm accounts for temporal dependencies in the data, enabling more accurate weight updates, which accelerate convergence and enhance resistance to vanishing gradients (17)&#x02013;(24).</p><p>Based on the helicopter TE and its structural features, the computational experiment focuses on solving sensor system monitoring tasks under interference conditions by forming and testing hypotheses regarding correlation and data reliability. The monitoring process considers Hypotheses 1 and 2 (1)&#x02013;(5).</p><p>The developed methods for testing Hypotheses 1 and 2 include a comprehensive approach to analyzing sensor readings for detecting correlations and identifying failures. The first method (6)&#x02013;(11) focuses on testing the hypothesis regarding the pairwise presence and triple correlations between readings from various helicopter TE sensors. It involves adaptive discretization, signal quantization, and analysis using discrete wavelet transform, which helps reveal hidden patterns and anomalies. Correlation coefficients are also calculated using sliding windows to find optimal sensor combinations with the highest correlation. The second method (12)&#x02013;(16) targets failure detection in individual sensor readings, such as compressor turbine rotor speed, by approximating actual characteristics with a polynomial. Anomalies are identified based on significant deviations between the measured data and approximated values. It allows interference to be filtered out and measurement accuracy to be improved through polynomial recalibration, considering the weights for each point.</p><p>The computational experiment used data recorded during TV3-117 engine flight tests on a Mi-8MTV helicopter through the onboard monitoring system. The recordings were made over 320 s of actual flight, with a sampling interval of 1 s (see <xref rid="sensors-25-00990-f003" ref-type="fig">Figure 3</xref>). The engine parameter dynamics revealed the time series complexity, and the nature of the curves highlighted the need to account for parameters and accumulate information in the model&#x02019;s memory for accurate analysis. Based on the collected data, a training dataset was created (see <xref rid="sensors-25-00990-t001" ref-type="table">Table 1</xref>), with its uniformity confirmed by Fisher&#x02013;Pearson and Fisher&#x02013;Snedecor criteria and its representativeness validated by cluster analysis (see <xref rid="sensors-25-00990-f004" ref-type="fig">Figure 4</xref>).</p><p>To confirm Hypothesis 1, a computational experiment was conducted to identify interrelated sets of sensors based on telemetry data (see <xref rid="sensors-25-00990-t002" ref-type="table">Table 2</xref>). The experiment revealed the highly correlated sensor&#x02019;s presence, a reduction in correlation when interference was introduced, and the system&#x02019;s response to simulated failures. Based on these results, Hypothesis 1 was validated.</p><p>To confirm Hypothesis 2, an experiment was conducted to detect failures using the gas-generator rotor r.p.m. parameter as an example (see <xref rid="sensors-25-00990-f006" ref-type="fig">Figure 6</xref>). The measured data, including false changes caused by interference, were analyzed using an approximating polynomial obtained through traditional methods (e.g., least squares method) (see <xref rid="sensors-25-00990-f007" ref-type="fig">Figure 7</xref>) and the proposed neural network (see <xref rid="sensors-25-00990-f008" ref-type="fig">Figure 8</xref>). The polynomial accounts for the helicopter TE&#x02019;s characteristics and ignores sensor failures. A failure is detected if sensor readings do not match the helicopter TE operation dynamics, such as sharp changes and returns to initial values. The experiment confirmed the method&#x02019;s effectiveness, applying a threshold value of &#x00394; = 0.025. Data correction was improved by redistributing weights and using the neural network, which increased the accuracy of reading interpolation.</p><p>The developed system is implemented as an SPSS (see <xref rid="sensors-25-00990-f009" ref-type="fig">Figure 9</xref>), designed to simulate helicopter TE parameters and model their operating modes across an altitude range and flight speeds. The SPSS was implemented in the Matlab Simulink graphical environment, where data exchange channels, a fuel metering unit simulator, a visualization system, and other components were integrated (see <xref rid="sensors-25-00990-f010" ref-type="fig">Figure 10</xref>). The trained neural network was integrated into Simulink using built-in tools, simplifying the model&#x02019;s implementation. The system&#x02019;s performance, using an AMD Ryzen 5 5600 processor with six cores and 12 threads, was confirmed by output graphical files (see <xref rid="sensors-25-00990-f011" ref-type="fig">Figure 11</xref>, <xref rid="sensors-25-00990-f012" ref-type="fig">Figure 12</xref> and <xref rid="sensors-25-00990-f013" ref-type="fig">Figure 13</xref>). However, performance gains decreased as the number and threads of the core exceeded eight, indicating a levelling effect on efficiency improvement (see <xref rid="sensors-25-00990-f014" ref-type="fig">Figure 14</xref> and <xref rid="sensors-25-00990-t003" ref-type="table">Table 3</xref>).</p><p>The task of approximating time series values recorded by helicopter TE sensors was solved in this research (see <xref rid="sensors-25-00990-f015" ref-type="fig">Figure 15</xref>). The neural network system from successfully identified segments where the recorded parameter data were anomalous (see <xref rid="sensors-25-00990-f016" ref-type="fig">Figure 16</xref>).</p><p>The effectiveness of the developed neural network system was evaluated using traditional quality metrics. The designed neural network (see <xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>) achieved an accuracy of 99.327% after 200 training epochs for detecting and restoring faults based on sensor data (see <xref rid="sensors-25-00990-f017" ref-type="fig">Figure 17</xref>). This high performance demonstrates the model&#x02019;s effectiveness in identifying anomalies and restoring correct data under various conditions. The network&#x02019;s loss decreased from 2.5 to 0.5% (see <xref rid="sensors-25-00990-f018" ref-type="fig">Figure 18</xref>) over the same period, reflecting improved accuracy and stability when processing anomalies in sensor data. The developed neural network showed precision at 0.987, recall at 1.0, and F1-score at 0.993, indicating high accuracy and reliability in identifying faults without False Negatives. The F1-score also highlighted the model&#x02019;s balanced performance in the precision and recall terms.</p><p>The obtained results were compared (see <xref rid="sensors-25-00990-t006" ref-type="table">Table 6</xref> and <xref rid="sensors-25-00990-t007" ref-type="table">Table 7</xref> and <xref rid="sensors-25-00990-f019" ref-type="fig">Figure 19</xref>) with two alternative approaches: 1 is a method for restoring lost information during sensor failures using an auto-associative neural network (autoencoder), and 2 is a neural network for predicting anomalous data based on the SARIMAX model with LSTM blocks. The comparative analysis showed that the proposed approach outperformed both alternative methods in accuracy (0.993 vs. 0.981 and 0.982), precision (0.987 vs. 0.980 and 0.979), and F1-score (0.993 vs. 0.988 and 0.989). In contrast, all approaches demonstrated the same recall value of 1.0, confirming their ability to detect all actual failures effectively. Analysis based on AUC-ROC metrics (see <xref rid="sensors-25-00990-f020" ref-type="fig">Figure 20</xref> and <xref rid="sensors-25-00990-t007" ref-type="table">Table 7</xref>) also revealed that the proposed method achieved an AUC-ROC of 0.823, surpassing both alternative methods with a score of 0.818. At the same time, the valid positive rate stood at 0.822, with a low False Positive rate of 0.0111. The False Negative number (13) highlights the proposed approach&#x02019;s effectiveness in minimizing misses compared to alternative approaches. An efficiency metric assessed the proposed approach&#x02019;s effectiveness, considering prediction accuracy and the resources spent during training and/or inference. The comparison results (see <xref rid="sensors-25-00990-t008" ref-type="table">Table 8</xref> and <xref rid="sensors-25-00990-f021" ref-type="fig">Figure 21</xref>) indicate that the proposed method achieved an accuracy of 0.993 with a training time of 4 min and 13 s, resulting in a resource efficiency value of 0.00392. In contrast, Alternative Approach 1 showed an accuracy of 0.981 with a longer training time of 5 min and 43 s, yielding an efficiency value of 0.00288, while Alternative Approach 2 achieved an accuracy of 0.982 with a training time of 4 min and 46 s, leading to a resource efficiency metric of 0.00343. All three approaches demonstrated optimal and adequate performance for implementation on board a helicopter; however, the proposed method holds a slight advantage in accuracy and resource efficiency, making it the preferred choice for real-time applications.</p><p>The developed experimental complex (see <xref rid="sensors-25-00990-f009" ref-type="fig">Figure 9</xref> and <xref rid="sensors-25-00990-f010" ref-type="fig">Figure 10</xref>) addresses tasks such as interpolating numerical series from sensor readings using the least squares method, predicting values from numerical series using a hybrid LSTM/GRU neural network architecture (see <xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>), as well as monitoring and diagnosing helicopter TE sensors. All tasks were tested with consideration for parallel processing on a cluster setup, receiving data for processing at a rate of 256 Kbps. <xref rid="sensors-25-00990-t009" ref-type="table">Table 9</xref> presents the results for various tasks performed by the experimental complex based on (see <xref rid="sensors-25-00990-f009" ref-type="fig">Figure 9</xref> and <xref rid="sensors-25-00990-f010" ref-type="fig">Figure 10</xref>), tested on a node with a performance of 7.0 GFLOPS. The proposed methods for increasing performance involve installing graphics processors for parallel data processing and deploying a high-speed switching network for information exchange between nodes in the cluster system.</p><p>The proposed algorithm outperforms other methods by combining advanced approaches aimed at improving the model&#x02019;s performance and accuracy. Using a hybrid architecture based on LSTM and GRU, it can efficiently process time series data such as telemetry while preserving key information about previous states. It ensures the more accurate detection of dependencies between sensor readings and anomaly detection. By using adaptive optimization methods such as a combination of stochastic gradient descent (SGD) with RMSProp, the proposed algorithm takes into account data temporal dependencies, accelerates convergence, and minimizes the vanishing gradients problem, which is especially important when working with long sequences.</p><p>The built-in attention mechanism in the Data_Retriever module improves model performance by focusing on the data&#x02019;s most significant parts. It allows for the identification of critical dependencies between sensor readings and increases the accuracy of correlation analysis. The Sensor_Fail_Clean and Sensor_Fail_Norm modules provide data preprocessing, including adaptive discretization and quantization, which improves the quality of input data and minimizes the impact of noise and interference. This preliminary data improvement can help reduce errors and enhance model stability.</p><p>A comparison with alternative methods such as autoencoders and SARIMAX models showed that the proposed algorithm achieved higher accuracy (0.993 vs. 0.981 and 0.982), with a shorter training time (4 min 13 s vs. 5:43 and 4:46) and better resource efficiency. This was achieved through a balanced training approach that included temporal regularization, adaptive gradient correction, and optimized data processing mechanisms. Such characteristics make the proposed method preferable for real-world applications, especially in settings requiring high reliability and minimal computational costs.</p><p>In this research, the developed neural network-based system for monitoring helicopter TE sensors demonstrates significant efficiency in detecting anomalies and restoring data; however, the research results have certain limitations. The model&#x02019;s accuracy in real-time conditions may vary depending on the quality of input data and the presence of interference, potentially reducing the prediction&#x02019;s reliability. The adaptive discretization and quantization algorithms used for data processing may be sensitive to changes in operational conditions, requiring additional parameter adjustments. Furthermore, while the applied validation methods show high accuracy, they are limited to the specific conditions under which the experiments were conducted. They may not always directly apply to other engine models or various helicopter types. Implementing this system on processors with limited computational capacity could affect data processing speed, which is critical in dynamic flight conditions, where data acquisition and processing delays may compromise safety levels.</p><p>In this research, an efficient neural network-based system for monitoring helicopter TE sensors was developed. Still, several areas for future research could significantly expand its functionality and improve diagnostic accuracy. Integrating deep learning methods, such as convolutional neural networks (CNNs) [<xref rid="B59-sensors-25-00990" ref-type="bibr">59</xref>,<xref rid="B60-sensors-25-00990" ref-type="bibr">60</xref>,<xref rid="B61-sensors-25-00990" ref-type="bibr">61</xref>], should be considered for processing multidimensional data and enhancing anomaly detection under complex interference conditions, which could improve prediction accuracy and system adaptability to different operational scenarios. Incorporating active training mechanisms [<xref rid="B62-sensors-25-00990" ref-type="bibr">62</xref>,<xref rid="B63-sensors-25-00990" ref-type="bibr">63</xref>,<xref rid="B64-sensors-25-00990" ref-type="bibr">64</xref>] and online adaptation [<xref rid="B65-sensors-25-00990" ref-type="bibr">65</xref>,<xref rid="B66-sensors-25-00990" ref-type="bibr">66</xref>] could allow the system to train from new data in real time, increasing its resilience to changing working conditions and enhancing the model&#x02019;s generalization ability. The third direction involves using ensemble training methods [<xref rid="B67-sensors-25-00990" ref-type="bibr">67</xref>,<xref rid="B68-sensors-25-00990" ref-type="bibr">68</xref>] to combine predictions from multiple models, potentially reducing variability and increasing prediction reliability. Moreover, the development of the neural network system (<xref rid="sensors-25-00990-f002" ref-type="fig">Figure 2</xref>) brings further improvements, including the directions presented in <xref rid="sensors-25-00990-t010" ref-type="table">Table 10</xref>.</p><p>In addition, the algorithm&#x02019;s performance may be degraded under extreme conditions, such as sudden changes in environmental parameters, strong vibrations, or temperature variations, which may increase noise in the data or change the sensor&#x02019;s characteristic signals. These factors may complicate fault identification and increase the number of False Positives. For example, 289 False Positives, in which normal values were incorrectly classified as faults, indicate the system&#x02019;s high sensitivity to deviations in the data, including noise or minor parameter fluctuations. This situation may occur due to insufficient data filtering, too-strict trigger thresholds, or incorrectly configured classification criteria. This leads to an increased workload for system operators as a large number of false alarms must be checked, which complicates the operation and reduces the efficiency of the system in real time. Future work should consider the ability to adapt the model to extreme conditions, for example, by expanding the training set with data collected in different operating modes and implementing noise-robustness techniques, such as more complex filters or improved attention mechanisms to focus on critical data features.</p><p>Additionally, exploring methods for interpreting and explaining model decisions [<xref rid="B69-sensors-25-00990" ref-type="bibr">69</xref>,<xref rid="B70-sensors-25-00990" ref-type="bibr">70</xref>,<xref rid="B71-sensors-25-00990" ref-type="bibr">71</xref>] appears promising, as this could improve trust in the results and provide operators with valuable recommendations for decision-making based on data analysis. Furthermore, implementing a monitoring system using drones [<xref rid="B72-sensors-25-00990" ref-type="bibr">72</xref>] or mobile platforms [<xref rid="B73-sensors-25-00990" ref-type="bibr">73</xref>] for automatic data collection in hard-to-reach areas [<xref rid="B74-sensors-25-00990" ref-type="bibr">74</xref>] could improve telemetry quality and broaden the system&#x02019;s applicability in various conditions [<xref rid="B75-sensors-25-00990" ref-type="bibr">75</xref>,<xref rid="B76-sensors-25-00990" ref-type="bibr">76</xref>]. There are plans to explore the developed system with other equipment and components onboard the helicopter [<xref rid="B77-sensors-25-00990" ref-type="bibr">77</xref>,<xref rid="B78-sensors-25-00990" ref-type="bibr">78</xref>,<xref rid="B79-sensors-25-00990" ref-type="bibr">79</xref>] to create a comprehensive system for controlling operational status and safety [<xref rid="B73-sensors-25-00990" ref-type="bibr">73</xref>,<xref rid="B74-sensors-25-00990" ref-type="bibr">74</xref>,<xref rid="B75-sensors-25-00990" ref-type="bibr">75</xref>,<xref rid="B76-sensors-25-00990" ref-type="bibr">76</xref>,<xref rid="B77-sensors-25-00990" ref-type="bibr">77</xref>], significantly enhancing reliability [<xref rid="B78-sensors-25-00990" ref-type="bibr">78</xref>,<xref rid="B79-sensors-25-00990" ref-type="bibr">79</xref>,<xref rid="B80-sensors-25-00990" ref-type="bibr">80</xref>,<xref rid="B81-sensors-25-00990" ref-type="bibr">81</xref>,<xref rid="B82-sensors-25-00990" ref-type="bibr">82</xref>,<xref rid="B83-sensors-25-00990" ref-type="bibr">83</xref>] and flight safety [<xref rid="B84-sensors-25-00990" ref-type="bibr">84</xref>,<xref rid="B85-sensors-25-00990" ref-type="bibr">85</xref>,<xref rid="B86-sensors-25-00990" ref-type="bibr">86</xref>,<xref rid="B87-sensors-25-00990" ref-type="bibr">87</xref>].</p></sec><sec sec-type="conclusions" id="sec5-sensors-25-00990"><title>5. Conclusions</title><p>The developed hybrid neural network model, combining LSTM/GRU architectures, adaptive learning rates, and attention mechanisms, represents an innovative approach in the field of monitoring helicopter turboshaft engine sensors. This combination allows the efficient processing of sequential data and significantly improves the accuracy of anomaly detection, which is especially important for ensuring the helicopter turboshaft engine&#x02019;s safety and reliability. The use of recurrent layers (LSTM/GRU) provides vital information about previous state preservation, which is critical for time series analysis and identifying dependencies in the data.</p><p>The Sensor_Fail_Clean and Sensor_Fail_Norm modules, implementing data-adaptive discretization and quantization, can improve the input data quality transmitted to the neural network, which, in turn, contributes to more accurate prediction and analysis. The effectiveness of the proposed model was confirmed by high accuracy in detecting anomalies and restoring data, with a result of 99.327% accuracy after 200 training epochs, which indicates the system&#x02019;s stability even when processing abnormal situations.</p><p>The developed neural network system for helicopter turboshaft engine sensors demonstrates high accuracy in anomaly detection and data restoration, achieving 99.327% accuracy after 200 training epochs. Network loss decreases from 2.5 to 0.5%, indicating improved stability when processing anomalies.</p><p>Developed a training algorithm that includes time regularization and optimization methods (SGD combined with RMSProp), which accelerates the convergence of neural networks, enhances resistance to gradient-vanishing problems, and improves training efficiency and model stability to a certain extent. This is evidenced by the reduction in the training time to 4 min and 13 s with an accuracy of 0.993.</p><p>When compared to alternative methods (auto-associative neural network and SARIMAX model with LSTM), the proposed method outperforms across all key metrics: accuracy is 0.993 versus 0.981 and 0.982, precision is 0.987 versus 0.980 and 0.979, and F1-score is 0.993 versus 0.988 and 0.989, confirming its superiority in fault detection and restoration.</p><p>Our computational experiments confirmed the hypothesis on highly correlated sensors and the method&#x02019;s effectiveness in detecting failures, as demonstrated by 13 False Negatives recorded during rotor compressor speed analysis, highlights the system&#x02019;s ability to minimize missed detections.</p></sec></body><back><ack><title>Acknowledgments</title><p>This research was supported by the Ministry of Internal Affairs of Ukraine as &#x0201c;Theoretical and applied aspects of the aviation sphere development&#x0201d; under Project No. 0123U104884.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, S.V., A.S. and V.V. (Victoria Vysotska); methodology, S.V. and V.V. (Victoria Vysotska) and T.P.; software, &#x00141;.&#x0015a;., N.S.-&#x0015a;., A.S., T.P. and V.V. (Victoria Vysotska); validation, &#x00141;.&#x0015a;., A.S. and V.V. (Viktor Vasylenko); formal analysis, S.V.; investigation, &#x00141;.&#x0015a;. and N.S.-&#x0015a;.; resources, &#x00141;.&#x0015a;., N.S.-&#x0015a;., A.S., T.P. and V.V. (Viktor Vasylenko); data curation, S.V., N.S.-&#x0015a;., A.S., T.P. and V.V. (Victoria Vysotska); writing&#x02014;original draft preparation, S.V.; writing&#x02014;review and editing, &#x00141;.&#x0015a;., N.S.-&#x0015a;., A.S., T.P. and V.V. (Viktor Vasylenko); visualization, &#x00141;.&#x0015a;., N.S.-&#x0015a;., A.S., T.P. and V.V. (Victoria Vysotska); supervision, &#x00141;.&#x0015a;., N.S.-&#x0015a;., A.S. and V.V. (Viktor Vasylenko); project administration, V.V. (Viktor Vasylenko); funding acquisition, &#x00141;.&#x0015a;. and N.S.-&#x0015a;. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data are contained within the article.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-00990"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cheng</surname><given-names>K.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Yang</surname><given-names>X.</given-names></name>
<name><surname>Zhang</surname><given-names>K.</given-names></name>
<name><surname>Liu</surname><given-names>F.</given-names></name>
</person-group><article-title>An Intelligent Online Fault Diagnosis System for Gas Turbine Sensors Based on Unsupervised Learning Method LOF and KELM</article-title><source>Sens. Actuators A Phys.</source><year>2024</year><volume>365</volume><fpage>114872</fpage><pub-id pub-id-type="doi">10.1016/j.sna.2023.114872</pub-id></element-citation></ref><ref id="B2-sensors-25-00990"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dutta</surname><given-names>R.</given-names></name>
<name><surname>Kandath</surname><given-names>H.</given-names></name>
<name><surname>Jayavelu</surname><given-names>S.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Sundaram</surname><given-names>S.</given-names></name>
<name><surname>Pack</surname><given-names>D.</given-names></name>
</person-group><article-title>A decentralised learning strategy to restore connectivity during multi-agent formation control</article-title><source>Neurocomputing</source><year>2023</year><volume>520</volume><fpage>33</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2022.11.054</pub-id></element-citation></ref><ref id="B3-sensors-25-00990"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Khan</surname><given-names>A.Q.</given-names></name>
<name><surname>El Jaouhari</surname><given-names>S.</given-names></name>
<name><surname>Tamani</surname><given-names>N.</given-names></name>
<name><surname>Mroueh</surname><given-names>L.</given-names></name>
</person-group><article-title>Knowledge-Based Anomaly Detection: Survey, Challenges, and Future Directions</article-title><source>Eng. Appl. Artif. Intell.</source><year>2024</year><volume>136</volume><fpage>108996</fpage><pub-id pub-id-type="doi">10.1016/j.engappai.2024.108996</pub-id></element-citation></ref><ref id="B4-sensors-25-00990"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lyu</surname><given-names>K.</given-names></name>
<name><surname>Tan</surname><given-names>X.</given-names></name>
<name><surname>Liu</surname><given-names>G.</given-names></name>
<name><surname>Zhao</surname><given-names>C.</given-names></name>
</person-group><article-title>Sensor Selection of Helicopter Transmission Systems Based on Physical Model and Sensitivity Analysis</article-title><source>Chin. J. Aeronaut.</source><year>2014</year><volume>27</volume><fpage>643</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1016/j.cja.2014.04.025</pub-id></element-citation></ref><ref id="B5-sensors-25-00990"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pang</surname><given-names>S.</given-names></name>
<name><surname>Li</surname><given-names>Q.</given-names></name>
<name><surname>Ni</surname><given-names>B.</given-names></name>
</person-group><article-title>Improved nonlinear MPC for aircraft gas turbine engine based on semi-alternative optimisation strategy</article-title><source>Aerosp. Sci. Technol.</source><year>2021</year><volume>118</volume><fpage>106983</fpage><pub-id pub-id-type="doi">10.1016/j.ast.2021.106983</pub-id></element-citation></ref><ref id="B6-sensors-25-00990"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Alozie</surname><given-names>O.</given-names></name>
<name><surname>Li</surname><given-names>Y.-G.</given-names></name>
<name><surname>Wu</surname><given-names>X.</given-names></name>
<name><surname>Shong</surname><given-names>X.</given-names></name>
<name><surname>Ren</surname><given-names>W.</given-names></name>
</person-group><article-title>An Adaptive Model-Based Framework for Prognostics of Gas Path Faults in Aircraft Gas Turbine Engines</article-title><source>Int. J. Progn. Health Manag.</source><year>2019</year><volume>10</volume><fpage>2728</fpage><pub-id pub-id-type="doi">10.36001/ijphm.2019.v10i2.2728</pub-id></element-citation></ref><ref id="B7-sensors-25-00990"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kumar</surname><given-names>S.R.</given-names></name>
<name><surname>Devakumar</surname><given-names>J.</given-names></name>
</person-group><article-title>Recurrent Neural Network Based Sensor Fault Detection and Isolation for Nonlinear Systems: Application in PWR</article-title><source>Prog. Nucl. Energy</source><year>2023</year><volume>163</volume><fpage>104836</fpage><pub-id pub-id-type="doi">10.1016/j.pnucene.2023.104836</pub-id></element-citation></ref><ref id="B8-sensors-25-00990"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Skarka</surname><given-names>W.</given-names></name>
<name><surname>Nalepa</surname><given-names>R.</given-names></name>
<name><surname>Musik</surname><given-names>R.</given-names></name>
</person-group><article-title>Integrated Aircraft Design System Based on Generative Modelling</article-title><source>Aerospace</source><year>2023</year><volume>10</volume><elocation-id>677</elocation-id><pub-id pub-id-type="doi">10.3390/aerospace10080677</pub-id></element-citation></ref><ref id="B9-sensors-25-00990"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Boujamza</surname><given-names>A.</given-names></name>
<name><surname>Lissane Elhaq</surname><given-names>S.</given-names></name>
</person-group><article-title>Attention-Based LSTM for Remaining Useful Life Estimation of Aircraft Engines</article-title><source>IFAC-Pap.</source><year>2022</year><volume>55</volume><fpage>450</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1016/j.ifacol.2022.07.353</pub-id></element-citation></ref><ref id="B10-sensors-25-00990"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Khattak</surname><given-names>W.R.</given-names></name>
<name><surname>Salman</surname><given-names>A.</given-names></name>
<name><surname>Ghafoor</surname><given-names>S.</given-names></name>
<name><surname>Latif</surname><given-names>S.</given-names></name>
</person-group><article-title>Multi-Modal LSTM Network for Anomaly Prediction in Piston Engine Aircraft</article-title><source>Heliyon</source><year>2024</year><volume>10</volume><fpage>e25120</fpage><pub-id pub-id-type="doi">10.1016/j.heliyon.2024.e25120</pub-id><pub-id pub-id-type="pmid">38317899</pub-id>
</element-citation></ref><ref id="B11-sensors-25-00990"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>D.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>C.</given-names></name>
<name><surname>Duan</surname><given-names>Y.</given-names></name>
</person-group><article-title>Recent advances in sensor fault diagnosis: A review</article-title><source>Sens. Actuators A Phys.</source><year>2020</year><volume>309</volume><fpage>111990</fpage><pub-id pub-id-type="doi">10.1016/j.sna.2020.111990</pub-id></element-citation></ref><ref id="B12-sensors-25-00990"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shen</surname><given-names>Y.</given-names></name>
<name><surname>Khorasani</surname><given-names>K.</given-names></name>
</person-group><article-title>Hybrid Multi-Mode Machine Learning-Based Fault Diagnosis Strategies with Application to Aircraft Gas Turbine Engines</article-title><source>Neural Netw.</source><year>2020</year><volume>130</volume><fpage>126</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2020.07.001</pub-id><pub-id pub-id-type="pmid">32673847</pub-id>
</element-citation></ref><ref id="B13-sensors-25-00990"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Sarwar</surname><given-names>U.</given-names></name>
<name><surname>Muhammad</surname><given-names>M.</given-names></name>
<name><surname>Mokhtar</surname><given-names>A.A.</given-names></name>
<name><surname>Khan</surname><given-names>R.</given-names></name>
<name><surname>Behrani</surname><given-names>P.</given-names></name>
<name><surname>Kaka</surname><given-names>S.</given-names></name>
</person-group><article-title>Hybrid Intelligence for Enhanced Fault Detection and Diagnosis for Industrial Gas Turbine Engine</article-title><source>Results Eng.</source><year>2024</year><volume>21</volume><fpage>101841</fpage><pub-id pub-id-type="doi">10.1016/j.rineng.2024.101841</pub-id></element-citation></ref><ref id="B14-sensors-25-00990"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Sina Tayarani-Bathaie</surname><given-names>S.</given-names></name>
<name><surname>Sadough Vanini</surname><given-names>Z.N.</given-names></name>
<name><surname>Khorasani</surname><given-names>K.</given-names></name>
</person-group><article-title>Dynamic neural network-based fault diagnosis of gas turbine engines</article-title><source>Neurocomputing</source><year>2014</year><volume>125</volume><fpage>153</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2012.06.050</pub-id></element-citation></ref><ref id="B15-sensors-25-00990"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>B.</given-names></name>
<name><surname>Zhao</surname><given-names>Y.-P.</given-names></name>
<name><surname>Chen</surname><given-names>Y.-B.</given-names></name>
</person-group><article-title>Unilateral Alignment Transfer Neural Network for Fault Diagnosis of Aircraft Engine</article-title><source>Aerosp. Sci. Technol.</source><year>2021</year><volume>118</volume><fpage>107031</fpage><pub-id pub-id-type="doi">10.1016/j.ast.2021.107031</pub-id></element-citation></ref><ref id="B16-sensors-25-00990"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shuai</surname><given-names>M.</given-names></name>
<name><surname>Yafeng</surname><given-names>W.</given-names></name>
<name><surname>Hua</surname><given-names>Z.</given-names></name>
<name><surname>Linfeng</surname><given-names>G.</given-names></name>
</person-group><article-title>Parameter Modelling of Fleet Gas Turbine Engines Using Gated Recurrent Neural Networks</article-title><source>J. Phys. Conf. Ser.</source><year>2023</year><volume>2472</volume><fpage>012012</fpage><pub-id pub-id-type="doi">10.1088/1742-6596/2472/1/012012</pub-id></element-citation></ref><ref id="B17-sensors-25-00990"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Menga</surname><given-names>N.</given-names></name>
<name><surname>Mothakani</surname><given-names>A.</given-names></name>
<name><surname>De Giorgi</surname><given-names>M.G.</given-names></name>
<name><surname>Przysowa</surname><given-names>R.</given-names></name>
<name><surname>Ficarella</surname><given-names>A.</given-names></name>
</person-group><article-title>Extreme Learning Machine-Based Diagnostics for Component Degradation in a Microturbine</article-title><source>Energies</source><year>2022</year><volume>15</volume><elocation-id>7304</elocation-id><pub-id pub-id-type="doi">10.3390/en15197304</pub-id></element-citation></ref><ref id="B18-sensors-25-00990"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xu</surname><given-names>M.</given-names></name>
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Liu</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>M.</given-names></name>
<name><surname>Geng</surname><given-names>J.</given-names></name>
<name><surname>Wu</surname><given-names>Y.</given-names></name>
<name><surname>Song</surname><given-names>Z.</given-names></name>
</person-group><article-title>An Improved Hybrid Modeling Method Based on Extreme Learning Machine for Gas Turbine Engine</article-title><source>Aerosp. Sci. Technol.</source><year>2020</year><volume>107</volume><fpage>106333</fpage><pub-id pub-id-type="doi">10.1016/j.ast.2020.106333</pub-id></element-citation></ref><ref id="B19-sensors-25-00990"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Nguyen</surname><given-names>T.-P.</given-names></name>
<name><surname>Yeh</surname><given-names>C.-T.</given-names></name>
<name><surname>Cho</surname><given-names>M.-Y.</given-names></name>
<name><surname>Chang</surname><given-names>C.-L.</given-names></name>
<name><surname>Chen</surname><given-names>M.-J.</given-names></name>
</person-group><article-title>Convolutional Neural Network Bidirectional Long Short-Term Memory to Online Classify the Distribution Insulator Leakage Currents</article-title><source>Electr. Power Syst. Res.</source><year>2022</year><volume>208</volume><fpage>107923</fpage><pub-id pub-id-type="doi">10.1016/j.epsr.2022.107923</pub-id></element-citation></ref><ref id="B20-sensors-25-00990"><label>20.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Eapen</surname><given-names>J.</given-names></name>
<name><surname>Bein</surname><given-names>D.</given-names></name>
<name><surname>Verma</surname><given-names>A.</given-names></name>
</person-group><article-title>Novel Deep Learning Model with CNN and Bi-Directional LSTM for Improved Stock Market Index Prediction</article-title><source>Proceedings of the 2019 IEEE 9th Annual Computing and Communication Workshop and Conference (CCWC)</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>7&#x02013;9 January 2019</conf-date><fpage>0264</fpage><lpage>0270</lpage><pub-id pub-id-type="doi">10.1109/ccwc.2019.8666592</pub-id></element-citation></ref><ref id="B21-sensors-25-00990"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shan</surname><given-names>L.</given-names></name>
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Tang</surname><given-names>M.</given-names></name>
<name><surname>Yang</surname><given-names>M.</given-names></name>
<name><surname>Bai</surname><given-names>X.</given-names></name>
</person-group><article-title>CNN-BiLSTM Hybrid Neural Networks with Attention Mechanism for Well Log Prediction</article-title><source>J. Pet. Sci. Eng.</source><year>2021</year><volume>205</volume><fpage>108838</fpage><pub-id pub-id-type="doi">10.1016/j.petrol.2021.108838</pub-id></element-citation></ref><ref id="B22-sensors-25-00990"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Sun</surname><given-names>S.</given-names></name>
<name><surname>Sun</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Zhou</surname><given-names>Z.</given-names></name>
<name><surname>Cai</surname><given-names>W.</given-names></name>
</person-group><article-title>Prediction of Battery SOH by CNN-BiLSTM Network Fused with Attention Mechanism</article-title><source>Energies</source><year>2022</year><volume>15</volume><elocation-id>4428</elocation-id><pub-id pub-id-type="doi">10.3390/en15124428</pub-id></element-citation></ref><ref id="B23-sensors-25-00990"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lee</surname><given-names>H.</given-names></name>
<name><surname>Li</surname><given-names>G.</given-names></name>
<name><surname>Rai</surname><given-names>A.</given-names></name>
<name><surname>Chattopadhyay</surname><given-names>A.</given-names></name>
</person-group><article-title>Health Monitoring Framework for Aircraft Engine System Using Deep Neural Network</article-title><source>Proc. Annu. Conf. PHM Soc.</source><year>2019</year><volume>11</volume><fpage>869</fpage><pub-id pub-id-type="doi">10.36001/phmconf.2019.v11i1.869</pub-id></element-citation></ref><ref id="B24-sensors-25-00990"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fentaye</surname><given-names>A.D.</given-names></name>
<name><surname>Zaccaria</surname><given-names>V.</given-names></name>
<name><surname>Kyprianidis</surname><given-names>K.</given-names></name>
</person-group><article-title>Aircraft Engine Performance Monitoring and Diagnostics Based on Deep Convolutional Neural Networks</article-title><source>Machines</source><year>2021</year><volume>9</volume><elocation-id>337</elocation-id><pub-id pub-id-type="doi">10.3390/machines9120337</pub-id></element-citation></ref><ref id="B25-sensors-25-00990"><label>25.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>J.</given-names></name>
<name><surname>Bai</surname><given-names>J.</given-names></name>
<name><surname>Liu</surname><given-names>S.</given-names></name>
</person-group><article-title>Real-Time Monitoring of Aircraft Engines Using a Feedforward Deep Neural Network</article-title><source>Proceedings of the 6th China Aeronautical Science and Technology Conference</source><comment>Lecture Notes in Mechanical Engineering</comment><publisher-name>Springer</publisher-name><publisher-loc>Singapore</publisher-loc><year>2023</year><volume>Volume 3</volume><fpage>390</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1007/978-981-99-8861-7_40</pub-id></element-citation></ref><ref id="B26-sensors-25-00990"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Melnychenko</surname><given-names>O.</given-names></name>
<name><surname>Scislo</surname><given-names>L.</given-names></name>
<name><surname>Savenko</surname><given-names>O.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Radiuk</surname><given-names>P.</given-names></name>
</person-group><article-title>Intelligent Integrated System for Fruit Detection Using Multi-UAV Imaging and Deep Learning</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>1913</elocation-id><pub-id pub-id-type="doi">10.3390/s24061913</pub-id><pub-id pub-id-type="pmid">38544178</pub-id>
</element-citation></ref><ref id="B27-sensors-25-00990"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fesenko</surname><given-names>H.</given-names></name>
<name><surname>Illiashenko</surname><given-names>O.</given-names></name>
<name><surname>Kharchenko</surname><given-names>V.</given-names></name>
<name><surname>Leichenko</surname><given-names>K.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Scislo</surname><given-names>L.</given-names></name>
</person-group><article-title>Methods and Software Tools for Reliable Operation of Flying LiFi Networks in Destruction Conditions</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>5707</elocation-id><pub-id pub-id-type="doi">10.3390/s24175707</pub-id><pub-id pub-id-type="pmid">39275618</pub-id>
</element-citation></ref><ref id="B28-sensors-25-00990"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Scislo</surname><given-names>L.</given-names></name>
<name><surname>Sokurenko</surname><given-names>V.</given-names></name>
<name><surname>Muzychuk</surname><given-names>O.</given-names></name>
<name><surname>Vysotska</surname><given-names>V.</given-names></name>
<name><surname>Osadchy</surname><given-names>S.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
</person-group><article-title>Neural Network Signal Integration from Thermogas-Dynamic Parameter Sensors for Helicopters Turboshaft Engines at Flight Operation Conditions</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>4246</elocation-id><pub-id pub-id-type="doi">10.3390/s24134246</pub-id><pub-id pub-id-type="pmid">39001025</pub-id>
</element-citation></ref><ref id="B29-sensors-25-00990"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shabbir</surname><given-names>W.</given-names></name>
<name><surname>Li</surname><given-names>A.</given-names></name>
<name><surname>Cui</surname><given-names>Y.</given-names></name>
</person-group><article-title>Neural Network-Based Sensor Fault Estimation and Active Fault-Tolerant Control for Uncertain Nonlinear Systems</article-title><source>J. Frankl. Inst.</source><year>2023</year><volume>360</volume><fpage>2678</fpage><lpage>2701</lpage><pub-id pub-id-type="doi">10.1016/j.jfranklin.2022.12.044</pub-id></element-citation></ref><ref id="B30-sensors-25-00990"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lin</surname><given-names>L.</given-names></name>
<name><surname>Wu</surname><given-names>J.</given-names></name>
<name><surname>Fu</surname><given-names>S.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
<name><surname>Tong</surname><given-names>C.</given-names></name>
<name><surname>Zu</surname><given-names>L.</given-names></name>
</person-group><article-title>Channel Attention &#x00026; Temporal Attention Based Temporal Convolutional Network: A Dual Attention Framework for Remaining Useful Life Prediction of the Aircraft Engines</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102372</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102372</pub-id></element-citation></ref><ref id="B31-sensors-25-00990"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xiao</surname><given-names>D.</given-names></name>
<name><surname>Lin</surname><given-names>Z.</given-names></name>
<name><surname>Yu</surname><given-names>A.</given-names></name>
<name><surname>Tang</surname><given-names>K.</given-names></name>
<name><surname>Xiao</surname><given-names>H.</given-names></name>
</person-group><article-title>Data-Driven Method Embedded Physical Knowledge for Entire Lifecycle Degradation Monitoring in Aircraft Engines</article-title><source>Reliab. Eng. Syst. Saf.</source><year>2024</year><volume>247</volume><fpage>110100</fpage><pub-id pub-id-type="doi">10.1016/j.ress.2024.110100</pub-id></element-citation></ref><ref id="B32-sensors-25-00990"><label>32.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Bruneo</surname><given-names>D.</given-names></name>
<name><surname>De Vita</surname><given-names>F.</given-names></name>
</person-group><article-title>On the Use of LSTM Networks for Predictive Maintenance in Smart Industries</article-title><source>Proceedings of the 2019 IEEE International Conference on Smart Computing (SMARTCOMP)</source><conf-loc>Washington, DC, USA</conf-loc><conf-date>12&#x02013;15 June 2019</conf-date><fpage>241</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1109/SMARTCOMP.2019.00059</pub-id></element-citation></ref><ref id="B33-sensors-25-00990"><label>33.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>P.</given-names></name>
<name><surname>Niu</surname><given-names>W.</given-names></name>
</person-group><article-title>Applications of LSTM Model for Aeroengine Forecasting</article-title><source>Proceedings of the 2020 7th International Conference on Dependable Systems and Their Applications (DSA)</source><conf-loc>Xi&#x02019;an, China</conf-loc><conf-date>28&#x02013;29 November 2020</conf-date><fpage>168</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1109/dsa51864.2020.00030</pub-id></element-citation></ref><ref id="B34-sensors-25-00990"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>X.</given-names></name>
<name><surname>Gupta</surname><given-names>L.</given-names></name>
</person-group><article-title>Training LSTMS with Circular-Shift Epochs for Accurate Event Forecasting in Imbalanced Time Series</article-title><source>Expert Syst. Appl.</source><year>2024</year><volume>238</volume><fpage>121701</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2023.121701</pub-id></element-citation></ref><ref id="B35-sensors-25-00990"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yu</surname><given-names>W.</given-names></name>
<name><surname>Gonzalez</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
</person-group><article-title>Fast Training of Deep LSTM Networks with Guaranteed Stability for Nonlinear System Modeling</article-title><source>Neurocomputing</source><year>2021</year><volume>422</volume><fpage>85</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2020.09.030</pub-id></element-citation></ref><ref id="B36-sensors-25-00990"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Banasik</surname><given-names>A.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Kempa</surname><given-names>W.M.</given-names></name>
<name><surname>Sokurenko</surname><given-names>V.</given-names></name>
<name><surname>Muzychuk</surname><given-names>O.</given-names></name>
<name><surname>Pikiewicz</surname><given-names>P.</given-names></name>
<name><surname>Molga</surname><given-names>A.</given-names></name>
<name><surname>Vysotska</surname><given-names>V.</given-names></name>
</person-group><article-title>Intelligent Method of Identifying the Nonlinear Dynamic Model for Helicopter Turboshaft Engines</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>6488</elocation-id><pub-id pub-id-type="doi">10.3390/s24196488</pub-id><pub-id pub-id-type="pmid">39409532</pub-id>
</element-citation></ref><ref id="B37-sensors-25-00990"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Yakovliev</surname><given-names>R.</given-names></name>
<name><surname>Vysotska</surname><given-names>V.</given-names></name>
<name><surname>Nazarkevych</surname><given-names>M.</given-names></name>
<name><surname>Lytvyn</surname><given-names>V.</given-names></name>
</person-group><article-title>The Method of Restoring Lost Information from Sensors Based on Auto-Associative Neural Networks</article-title><source>Appl. Syst. Innov.</source><year>2024</year><volume>7</volume><elocation-id>53</elocation-id><pub-id pub-id-type="doi">10.3390/asi7030053</pub-id></element-citation></ref><ref id="B38-sensors-25-00990"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Scislo</surname><given-names>L.</given-names></name>
<name><surname>Sokurenko</surname><given-names>V.</given-names></name>
<name><surname>Muzychuk</surname><given-names>O.</given-names></name>
<name><surname>Vysotska</surname><given-names>V.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Yurko</surname><given-names>A.</given-names></name>
</person-group><article-title>Helicopter Turboshaft Engines&#x02019; Gas Generator Rotor R.P.M. Neuro-Fuzzy Onboard Controller Development</article-title><source>Energies</source><year>2024</year><volume>17</volume><elocation-id>4033</elocation-id><pub-id pub-id-type="doi">10.3390/en17164033</pub-id></element-citation></ref><ref id="B39-sensors-25-00990"><label>39.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Balakrishnan</surname><given-names>N.</given-names></name>
<name><surname>Voinov</surname><given-names>V.</given-names></name>
<name><surname>Nikulin</surname><given-names>M.S.</given-names></name>
</person-group><article-title>Chapter 2&#x02014;Pearson&#x02019;s Sum and Pearson-Fisher Test</article-title><source>Chi-Squared Goodness of Fit Tests with Applications</source><person-group person-group-type="editor">
<name><surname>Balakrishnan</surname><given-names>N.</given-names></name>
<name><surname>Voinov</surname><given-names>V.</given-names></name>
<name><surname>Nikulin</surname><given-names>M.S.</given-names></name>
</person-group><publisher-name>Academic Press</publisher-name><publisher-loc>Waltham, MA, USA</publisher-loc><year>2013</year><fpage>11</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-397194-4.00002-8</pub-id></element-citation></ref><ref id="B40-sensors-25-00990"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kim</surname><given-names>H.-Y.</given-names></name>
</person-group><article-title>Statistical Notes for Clinical Researchers: Chi-Squared Test and Fisher&#x02019;s Exact Test</article-title><source>Restor. Dent. Endod.</source><year>2017</year><volume>42</volume><fpage>152</fpage><pub-id pub-id-type="doi">10.5395/rde.2017.42.2.152</pub-id><pub-id pub-id-type="pmid">28503482</pub-id>
</element-citation></ref><ref id="B41-sensors-25-00990"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Avram</surname><given-names>F.</given-names></name>
<name><surname>Leonenko</surname><given-names>N.N.</given-names></name>
<name><surname>&#x00160;uvak</surname><given-names>N.</given-names></name>
</person-group><article-title>Hypothesis testing for Fisher&#x02013;Snedecor diffusion</article-title><source>J. Stat. Plan. Inference</source><year>2012</year><volume>142</volume><fpage>2308</fpage><lpage>2321</lpage><pub-id pub-id-type="doi">10.1016/j.jspi.2012.02.055</pub-id></element-citation></ref><ref id="B42-sensors-25-00990"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Stefanovic</surname><given-names>C.M.</given-names></name>
<name><surname>Armada</surname><given-names>A.G.</given-names></name>
<name><surname>Costa-Perez</surname><given-names>X.</given-names></name>
</person-group><article-title>Second Order Statistics of -Fisher-Snedecor Distribution and Their Application to Burst Error Rate Analysis of Multi-Hop Communications</article-title><source>IEEE Open J. Commun. Soc.</source><year>2022</year><volume>3</volume><fpage>2407</fpage><lpage>2424</lpage><pub-id pub-id-type="doi">10.1109/OJCOMS.2022.3224835</pub-id></element-citation></ref><ref id="B43-sensors-25-00990"><label>43.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Lytvyn</surname><given-names>V.</given-names></name>
<name><surname>Dudyk</surname><given-names>D.</given-names></name>
<name><surname>Peleshchak</surname><given-names>I.</given-names></name>
<name><surname>Peleshchak</surname><given-names>R.</given-names></name>
<name><surname>Pukach</surname><given-names>P.</given-names></name>
</person-group><article-title>Influence of the Number of Neighbours on the Clustering Metric by Oscillatory Chaotic Neural Network with Dipole Synaptic Connections</article-title><source>Proceedings of the 8th International Conference on Computational Linguistics and Intelligent Systems (COLINS-2024)</source><conf-loc>Lviv, Ukraine</conf-loc><conf-date>12&#x02013;13 April 2024</conf-date><fpage>24</fpage><lpage>34</lpage><comment>Available online: <ext-link xlink:href="https://ceur-ws.org/Vol-3664/paper3.pdf" ext-link-type="uri">https://ceur-ws.org/Vol-3664/paper3.pdf</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-14">(accessed on 14 November 2024)</date-in-citation></element-citation></ref><ref id="B44-sensors-25-00990"><label>44.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Hu</surname><given-names>Z.</given-names></name>
<name><surname>Kashyap</surname><given-names>E.</given-names></name>
<name><surname>Tyshchenko</surname><given-names>O.K.</given-names></name>
</person-group><article-title>GEOCLUS: A Fuzzy-Based Learning Algorithm for Clustering Expression Datasets</article-title><source>Advances in Computer Science for Engineering and Education</source><comment>Lecture Notes on Data Engineering and Communications Technologies</comment><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2022</year><volume>Volume 134</volume><fpage>337</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1007/978-3-031-04812-8_29</pub-id></element-citation></ref><ref id="B45-sensors-25-00990"><label>45.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Yakovliev</surname><given-names>R.</given-names></name>
<name><surname>Hubachov</surname><given-names>O.</given-names></name>
<name><surname>Rud</surname><given-names>J.</given-names></name>
</person-group><article-title>Neuro-Fuzzy System for Detection Fuel Consumption of Helicopters Turboshaft Engines</article-title><source>Proceedings of the ITTAP&#x02019;2023: 3rd International Workshop on Information Technologies: Theoretical and Applied Problems, Ternopil, Ukraine</source><conf-loc>Opole, Poland</conf-loc><conf-date>22&#x02013;24 November 2023</conf-date><fpage>55</fpage><lpage>72</lpage><comment>Available online: <ext-link xlink:href="https://ceur-ws.org/Vol-3628/paper5.pdf" ext-link-type="uri">https://ceur-ws.org/Vol-3628/paper5.pdf</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-21">(accessed on 21 November 2024)</date-in-citation></element-citation></ref><ref id="B46-sensors-25-00990"><label>46.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Shmelov</surname><given-names>Y.</given-names></name>
<name><surname>Yakovliev</surname><given-names>R.</given-names></name>
<name><surname>Petchenko</surname><given-names>M.</given-names></name>
</person-group><article-title>Helicopters Turboshaft Engines Parameters Identification Using Neural Network Technologies Based on the Kalman Filter</article-title><source>Information and Communication Technologies in Education, Research, and Industrial Applications</source><comment>Communications in Computer and Information Science</comment><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2023</year><volume>Volume 1980</volume><fpage>82</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1007/978-3-031-48325-7_7</pub-id></element-citation></ref><ref id="B47-sensors-25-00990"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cherrat</surname><given-names>E.M.</given-names></name>
<name><surname>Alaoui</surname><given-names>R.</given-names></name>
<name><surname>Bouzahir</surname><given-names>H.</given-names></name>
</person-group><article-title>Score fusion of finger vein and face for human recognition based on convolutional neural network model</article-title><source>Int. J. Comput.</source><year>2020</year><volume>19</volume><fpage>11</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.47839/ijc.19.1.1688</pub-id></element-citation></ref><ref id="B48-sensors-25-00990"><label>48.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Komar</surname><given-names>M.</given-names></name>
<name><surname>Golovko</surname><given-names>V.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Bezobrazov</surname><given-names>S.</given-names></name>
</person-group><article-title>Intelligent system for detection of networking intrusion</article-title><source>Proceedings of the 6th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems</source><conf-loc>Prague, Czech Republic</conf-loc><conf-date>15&#x02013;17 September 2011</conf-date><fpage>374</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1109/IDAACS.2011.6072777</pub-id></element-citation></ref><ref id="B49-sensors-25-00990"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kuznetsov</surname><given-names>A.V.</given-names></name>
<name><surname>Makaryants</surname><given-names>G.M.</given-names></name>
</person-group><article-title>Micro Gas Turbine Engine Imitation Model</article-title><source>Aerosp. Mech. Eng.</source><year>2017</year><volume>16</volume><fpage>65</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.18287/2541-7533-2017-16-2-65-74</pub-id></element-citation></ref><ref id="B50-sensors-25-00990"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Sokurenko</surname><given-names>V.</given-names></name>
<name><surname>Muzychuk</surname><given-names>O.</given-names></name>
<name><surname>Vysotska</surname><given-names>V.</given-names></name>
</person-group><article-title>Helicopters Turboshaft Engines Neural Network Modeling under Sensor Failure</article-title><source>J. Sens. Actuator Netw.</source><year>2024</year><volume>13</volume><elocation-id>66</elocation-id><pub-id pub-id-type="doi">10.3390/jsan13050066</pub-id></element-citation></ref><ref id="B51-sensors-25-00990"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vlasenko</surname><given-names>D.</given-names></name>
<name><surname>Inkarbaieva</surname><given-names>O.</given-names></name>
<name><surname>Peretiatko</surname><given-names>M.</given-names></name>
<name><surname>Kovalchuk</surname><given-names>D.</given-names></name>
<name><surname>Sereda</surname><given-names>O.</given-names></name>
</person-group><article-title>Helicopter Radio System for Low Altitudes and Flight Speed Measuring with Pulsed Ultra-Wideband Stochastic Sounding Signals and Artificial Intelligence Elements</article-title><source>Radioelectron. Comput. Syst.</source><year>2023</year><volume>3</volume><fpage>48</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.32620/reks.2023.3.05</pub-id></element-citation></ref><ref id="B52-sensors-25-00990"><label>52.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Babichev</surname><given-names>S.</given-names></name>
<name><surname>Krejci</surname><given-names>J.</given-names></name>
<name><surname>Bicanek</surname><given-names>J.</given-names></name>
<name><surname>Lytvynenko</surname><given-names>V.</given-names></name>
</person-group><article-title>Gene expression sequences clustering based on the internal and external clustering quality criteria</article-title><source>Proceedings of the 2017 12th International Scientific and Technical Conference on Computer Sciences and Information Technologies (CSIT)</source><conf-loc>Lviv, Ukraine</conf-loc><conf-date>5&#x02013;8 September 2017</conf-date><pub-id pub-id-type="doi">10.1109/STC-CSIT.2017.8098744</pub-id></element-citation></ref><ref id="B53-sensors-25-00990"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pasieka</surname><given-names>M.</given-names></name>
<name><surname>Grzesik</surname><given-names>N.</given-names></name>
<name><surname>Ku&#x0017a;ma</surname><given-names>K.</given-names></name>
</person-group><article-title>Simulation modeling of fuzzy logic controller for aircraft engines</article-title><source>Int. J. Comput.</source><year>2017</year><volume>16</volume><fpage>27</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.47839/ijc.16.1.868</pub-id></element-citation></ref><ref id="B54-sensors-25-00990"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Rusyn</surname><given-names>B.</given-names></name>
<name><surname>Lutsyk</surname><given-names>O.</given-names></name>
<name><surname>Kosarevych</surname><given-names>R.</given-names></name>
<name><surname>Kapshii</surname><given-names>O.</given-names></name>
<name><surname>Karpin</surname><given-names>O.</given-names></name>
<name><surname>Maksymyuk</surname><given-names>T.</given-names></name>
<name><surname>Gazda</surname><given-names>J.</given-names></name>
</person-group><article-title>Rethinking Deep CNN Training: A Novel Approach for Quality-Aware Dataset Optimization</article-title><source>IEEE Access</source><year>2024</year><volume>12</volume><fpage>137427</fpage><lpage>137438</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2024.3414651</pub-id></element-citation></ref><ref id="B55-sensors-25-00990"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Semenov</surname><given-names>A.</given-names></name>
<name><surname>Baraban</surname><given-names>S.</given-names></name>
<name><surname>Kovtun</surname><given-names>V.</given-names></name>
<name><surname>Baraban</surname><given-names>M.</given-names></name>
<name><surname>Arseniuk</surname><given-names>I.</given-names></name>
<name><surname>Rudyk</surname><given-names>A.</given-names></name>
</person-group><article-title>Development and Validation of a Mathematical Model for Pyroelectric Temperature Measurement Sensors for Application in Mobile Robotic Systems</article-title><source>Electronics</source><year>2024</year><volume>13</volume><elocation-id>3173</elocation-id><pub-id pub-id-type="doi">10.3390/electronics13163173</pub-id></element-citation></ref><ref id="B56-sensors-25-00990"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Anfilets</surname><given-names>S.</given-names></name>
<name><surname>Bezobrazov</surname><given-names>S.</given-names></name>
<name><surname>Golovko</surname><given-names>V.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Komar</surname><given-names>M.</given-names></name>
<name><surname>Dolny</surname><given-names>R.</given-names></name>
<name><surname>Kasyanik</surname><given-names>V.</given-names></name>
<name><surname>Bykovyy</surname><given-names>P.</given-names></name>
<name><surname>Mikhno</surname><given-names>E.</given-names></name>
<name><surname>Osolinskyi</surname><given-names>O.</given-names></name>
</person-group><article-title>Deep multilayer neural network for predicting the winner of football matches</article-title><source>Int. J. Comput.</source><year>2020</year><volume>19</volume><fpage>70</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.31891/1727-6209/2020/19/1-70-77</pub-id></element-citation></ref><ref id="B57-sensors-25-00990"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Morozov</surname><given-names>V.V.</given-names></name>
<name><surname>Kalnichenko</surname><given-names>O.V.</given-names></name>
<name><surname>Mezentseva</surname><given-names>O.O.</given-names></name>
</person-group><article-title>The method of interaction modeling on basis of deep learning the neural networks in complex IT-projects</article-title><source>Int. J. Comput.</source><year>2020</year><volume>19</volume><fpage>88</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.47839/ijc.19.1.1697</pub-id></element-citation></ref><ref id="B58-sensors-25-00990"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Vysotska</surname><given-names>V.</given-names></name>
<name><surname>Sokurenko</surname><given-names>V.</given-names></name>
<name><surname>Muzychuk</surname><given-names>O.</given-names></name>
<name><surname>Nazarkevych</surname><given-names>M.</given-names></name>
<name><surname>Lytvyn</surname><given-names>V.</given-names></name>
</person-group><article-title>Neural Network System for Predicting Anomalous Data in Applied Sensor Systems</article-title><source>Appl. Syst. Innov.</source><year>2024</year><volume>7</volume><elocation-id>88</elocation-id><pub-id pub-id-type="doi">10.3390/asi7050088</pub-id></element-citation></ref><ref id="B59-sensors-25-00990"><label>59.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Paliy</surname><given-names>I.</given-names></name>
<name><surname>Sachenko</surname><given-names>A.</given-names></name>
<name><surname>Koval</surname><given-names>V.</given-names></name>
<name><surname>Kurylyak</surname><given-names>Y.</given-names></name>
</person-group><article-title>Approach to Face Recognition Using Neural Networks</article-title><source>Proceedings of the 2005 IEEE Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications</source><conf-loc>Sofia, Bulgaria</conf-loc><conf-date>5&#x02013;7 September 2005</conf-date><fpage>112</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1109/IDAACS.2005.282951</pub-id></element-citation></ref><ref id="B60-sensors-25-00990"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Paraschos</surname><given-names>P.D.</given-names></name>
<name><surname>Gasteratos</surname><given-names>A.C.</given-names></name>
<name><surname>Koulouriotis</surname><given-names>D.E.</given-names></name>
</person-group><article-title>Deep Learning Model for Optimizing Control and Planning in Stochastic Manufacturing Environments</article-title><source>Expert Syst. Appl.</source><year>2024</year><volume>257</volume><fpage>125075</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2024.125075</pub-id></element-citation></ref><ref id="B61-sensors-25-00990"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mirbagheri</surname><given-names>S.M.</given-names></name>
<name><surname>Derakhshandeh</surname><given-names>S.Y.</given-names></name>
<name><surname>Rohani</surname><given-names>R.</given-names></name>
<name><surname>Basiri</surname><given-names>M.E.</given-names></name>
</person-group><article-title>A New Hybrid Approach for Cold Load Restoration Using Deep Learning</article-title><source>Electr. Power Syst. Res.</source><year>2024</year><volume>234</volume><fpage>110517</fpage><pub-id pub-id-type="doi">10.1016/j.epsr.2024.110517</pub-id></element-citation></ref><ref id="B62-sensors-25-00990"><label>62.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>Q.</given-names></name>
<name><surname>Han</surname><given-names>S.</given-names></name>
<name><surname>El-Meligy</surname><given-names>M.A.</given-names></name>
<name><surname>Tlija</surname><given-names>M.</given-names></name>
</person-group><article-title>Active Control Vibrations of Aircraft Wings under Dynamic Loading: Introducing PSO-GWO Algorithm to Predict Dynamical Information</article-title><source>Aerosp. Sci. Technol.</source><year>2024</year><volume>153</volume><fpage>109430</fpage><pub-id pub-id-type="doi">10.1016/j.ast.2024.109430</pub-id></element-citation></ref><ref id="B63-sensors-25-00990"><label>63.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Abdelkader</surname><given-names>S.M.</given-names></name>
<name><surname>Kinga</surname><given-names>S.</given-names></name>
<name><surname>Ebinyu</surname><given-names>E.</given-names></name>
<name><surname>Amissah</surname><given-names>J.</given-names></name>
<name><surname>Mugerwa</surname><given-names>G.</given-names></name>
<name><surname>Taha</surname><given-names>I.B.M.</given-names></name>
<name><surname>Mansour</surname><given-names>D.-E.A.</given-names></name>
</person-group><article-title>Advancements in Data-Driven Voltage Control in Active Distribution Networks: A Comprehensive Review</article-title><source>Results Eng.</source><year>2024</year><volume>23</volume><fpage>102741</fpage><pub-id pub-id-type="doi">10.1016/j.rineng.2024.102741</pub-id></element-citation></ref><ref id="B64-sensors-25-00990"><label>64.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Qin</surname><given-names>Z.-C.</given-names></name>
<name><surname>Xin</surname><given-names>Y.</given-names></name>
</person-group><article-title>Data-Driven H&#x0221e; Vibration Control Design and Verification for an Active Suspension System with Unknown Pseudo-Drift Dynamics</article-title><source>Commun. Nonlinear Sci. Numer. Simul.</source><year>2023</year><volume>125</volume><fpage>107397</fpage><pub-id pub-id-type="doi">10.1016/j.cnsns.2023.107397</pub-id></element-citation></ref><ref id="B65-sensors-25-00990"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ignatyev</surname><given-names>D.I.</given-names></name>
<name><surname>Shin</surname><given-names>H.-S.</given-names></name>
<name><surname>Tsourdos</surname><given-names>A.</given-names></name>
</person-group><article-title>Sparse Online Gaussian Process Adaptation for Incremental Backstepping Flight Control</article-title><source>Aerosp. Sci. Technol.</source><year>2023</year><volume>136</volume><fpage>108157</fpage><pub-id pub-id-type="doi">10.1016/j.ast.2023.108157</pub-id></element-citation></ref><ref id="B66-sensors-25-00990"><label>66.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Teutsch</surname><given-names>J.</given-names></name>
<name><surname>Ellmaier</surname><given-names>S.</given-names></name>
<name><surname>Kerz</surname><given-names>S.</given-names></name>
<name><surname>Wollherr</surname><given-names>D.</given-names></name>
<name><surname>Leibold</surname><given-names>M.</given-names></name>
</person-group><article-title>An Online Adaptation Strategy for Direct Data-Driven Control</article-title><source>IFAC-Pap.</source><year>2023</year><volume>56</volume><fpage>644</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1016/j.ifacol.2023.10.1640</pub-id></element-citation></ref><ref id="B67-sensors-25-00990"><label>67.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fan</surname><given-names>J.</given-names></name>
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Zou</surname><given-names>Y.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Sun</surname><given-names>W.</given-names></name>
</person-group><article-title>Improving Policy Training for Autonomous Driving through Randomized Ensembled Double Q-Learning with Transformer Encoder Feature Evaluation</article-title><source>Appl. Soft Comput.</source><year>2024</year><volume>167</volume><fpage>112386</fpage><pub-id pub-id-type="doi">10.1016/j.asoc.2024.112386</pub-id></element-citation></ref><ref id="B68-sensors-25-00990"><label>68.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Leal</surname><given-names>D.V.</given-names></name>
<name><surname>Araujo</surname><given-names>I.F.</given-names></name>
<name><surname>da Silva</surname><given-names>A.J.</given-names></name>
</person-group><article-title>Training and Meta-Training an Ensemble of Binary Neural Networks with Quantum Computing</article-title><source>Neurocomputing</source><year>2024</year><volume>572</volume><fpage>127169</fpage><pub-id pub-id-type="doi">10.1016/j.neucom.2023.127169</pub-id></element-citation></ref><ref id="B69-sensors-25-00990"><label>69.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Park</surname><given-names>J.-H.</given-names></name>
<name><surname>Ju</surname><given-names>Y.-J.</given-names></name>
<name><surname>Lee</surname><given-names>S.-W.</given-names></name>
</person-group><article-title>Explaining Generative Diffusion Models via Visual Analysis for Interpretable Decision-Making Process</article-title><source>Expert Syst. Appl.</source><year>2024</year><volume>248</volume><fpage>123231</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2024.123231</pub-id></element-citation></ref><ref id="B70-sensors-25-00990"><label>70.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Materassi</surname><given-names>D.</given-names></name>
<name><surname>Warnick</surname><given-names>S.</given-names></name>
<name><surname>Rojas</surname><given-names>C.</given-names></name>
<name><surname>Schoukens</surname><given-names>M.</given-names></name>
<name><surname>Cross</surname><given-names>E.</given-names></name>
</person-group><article-title>Explaining Complex Systems: A Tutorial on Transparency and Interpretability in Machine Learning Models (Part I)</article-title><source>IFAC-Pap.</source><year>2024</year><volume>58</volume><fpage>492</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1016/j.ifacol.2024.08.577</pub-id></element-citation></ref><ref id="B71-sensors-25-00990"><label>71.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mariotti</surname><given-names>E.</given-names></name>
<name><surname>Alonso Moral</surname><given-names>J.M.</given-names></name>
<name><surname>Gatt</surname><given-names>A.</given-names></name>
</person-group><article-title>Exploring the Balance between Interpretability and Performance with Carefully Designed Constrainable Neural Additive Models</article-title><source>Inf. Fusion</source><year>2023</year><volume>99</volume><fpage>101882</fpage><pub-id pub-id-type="doi">10.1016/j.inffus.2023.101882</pub-id></element-citation></ref><ref id="B72-sensors-25-00990"><label>72.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>De la Fuente</surname><given-names>R.</given-names></name>
<name><surname>Aguayo</surname><given-names>M.M.</given-names></name>
<name><surname>Contreras-Bolton</surname><given-names>C.</given-names></name>
</person-group><article-title>An Optimisation-Based Approach for an Integrated Forest Fire Monitoring System with Multiple Technologies and Surveillance Drones</article-title><source>Eur. J. Oper. Res.</source><year>2024</year><volume>313</volume><fpage>435</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1016/j.ejor.2023.08.008</pub-id></element-citation></ref><ref id="B73-sensors-25-00990"><label>73.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Callisto De Donato</surname><given-names>M.</given-names></name>
<name><surname>Corradini</surname><given-names>F.</given-names></name>
<name><surname>Fornari</surname><given-names>F.</given-names></name>
<name><surname>Re</surname><given-names>B.</given-names></name>
</person-group><article-title>SAFE: An ICT Platform for Supporting Monitoring, Localization and Rescue Operations in Case of Earthquake</article-title><source>Internet Things</source><year>2024</year><volume>27</volume><fpage>101273</fpage><pub-id pub-id-type="doi">10.1016/j.iot.2024.101273</pub-id></element-citation></ref><ref id="B74-sensors-25-00990"><label>74.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hu</surname><given-names>D.</given-names></name>
<name><surname>Gan</surname><given-names>V.J.L.</given-names></name>
<name><surname>Wang</surname><given-names>T.</given-names></name>
<name><surname>Ma</surname><given-names>L.</given-names></name>
</person-group><article-title>Multi-Agent Robotic System (MARS) for UAV-UGV Path Planning and Automatic Sensory Data Collection in Cluttered Environments</article-title><source>Build. Environ.</source><year>2022</year><volume>221</volume><fpage>109349</fpage><pub-id pub-id-type="doi">10.1016/j.buildenv.2022.109349</pub-id></element-citation></ref><ref id="B75-sensors-25-00990"><label>75.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ha</surname><given-names>D.W.</given-names></name>
<name><surname>Noh</surname><given-names>H.W.</given-names></name>
<name><surname>Koo</surname><given-names>T.H.</given-names></name>
<name><surname>Ko</surname><given-names>R.K.</given-names></name>
<name><surname>Seo</surname><given-names>Y.M.</given-names></name>
</person-group><article-title>Experimental Study on the Liquid Hydrogen Zero Boil-off in a Liquefaction System with an Automatic Control Technology</article-title><source>Int. J. Hydrogen Energy</source><year>2024</year><volume>83</volume><fpage>933</fpage><lpage>945</lpage><pub-id pub-id-type="doi">10.1016/j.ijhydene.2024.07.167</pub-id></element-citation></ref><ref id="B76-sensors-25-00990"><label>76.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fathi</surname><given-names>M.</given-names></name>
<name><surname>Bolandi</surname><given-names>H.</given-names></name>
</person-group><article-title>Unsupervised Optimal Model Bank for Multiple Model Control Systems: Genetic-Based Automatic Clustering Approach</article-title><source>Heliyon</source><year>2024</year><volume>10</volume><fpage>e25986</fpage><pub-id pub-id-type="doi">10.1016/j.heliyon.2024.e25986</pub-id><pub-id pub-id-type="pmid">38390058</pub-id>
</element-citation></ref><ref id="B77-sensors-25-00990"><label>77.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wu</surname><given-names>J.</given-names></name>
<name><surname>Sun</surname><given-names>C.</given-names></name>
<name><surname>Zhang</surname><given-names>C.</given-names></name>
<name><surname>Chen</surname><given-names>X.</given-names></name>
<name><surname>Yan</surname><given-names>R.</given-names></name>
</person-group><article-title>Deep Clustering Variational Network for Helicopter Regime Recognition in HUMS</article-title><source>Aerosp. Sci. Technol.</source><year>2022</year><volume>124</volume><fpage>107553</fpage><pub-id pub-id-type="doi">10.1016/j.ast.2022.107553</pub-id></element-citation></ref><ref id="B78-sensors-25-00990"><label>78.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yang</surname><given-names>X.</given-names></name>
<name><surname>Garratt</surname><given-names>M.</given-names></name>
<name><surname>Pota</surname><given-names>H.</given-names></name>
</person-group><article-title>Flight Validation of a Feedforward Gust-Attenuation Controller for an Autonomous Helicopter</article-title><source>Robot. Auton. Syst.</source><year>2011</year><volume>59</volume><fpage>1070</fpage><lpage>1079</lpage><pub-id pub-id-type="doi">10.1016/j.robot.2011.08.004</pub-id></element-citation></ref><ref id="B79-sensors-25-00990"><label>79.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Di Rito</surname><given-names>G.</given-names></name>
<name><surname>Schettini</surname><given-names>F.</given-names></name>
</person-group><article-title>Impacts of Safety on the Design of Light Remotely-Piloted Helicopter Flight Control Systems</article-title><source>Reliab. Eng. Syst. Saf.</source><year>2016</year><volume>149</volume><fpage>121</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1016/j.ress.2015.12.012</pub-id></element-citation></ref><ref id="B80-sensors-25-00990"><label>80.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>N&#x000e6;vestad</surname><given-names>T.-O.</given-names></name>
<name><surname>Bye</surname><given-names>R.J.</given-names></name>
<name><surname>Antonsen</surname><given-names>S.</given-names></name>
<name><surname>Berge</surname><given-names>S.H.</given-names></name>
<name><surname>Hesjevoll</surname><given-names>I.S.</given-names></name>
<name><surname>Elvebakk</surname><given-names>B.</given-names></name>
</person-group><article-title>Examining the Most Accident-Prone Sector within Commercial Aviation: Why Do Accidents with Light Inland Helicopters Occur, and How Can We Improve Safety?</article-title><source>Saf. Sci.</source><year>2021</year><volume>139</volume><fpage>105235</fpage><pub-id pub-id-type="doi">10.1016/j.ssci.2021.105235</pub-id></element-citation></ref><ref id="B81-sensors-25-00990"><label>81.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chud&#x000fd;</surname><given-names>P.</given-names></name>
<name><surname>Tomczyk</surname><given-names>A.</given-names></name>
<name><surname>Rzucidlo</surname><given-names>P.</given-names></name>
</person-group><article-title>Safety Enhanced Digital Flight Control System</article-title><source>Aircr. Eng. Aerosp. Technol.</source><year>2009</year><volume>81</volume><fpage>416</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1108/00022660910983699</pub-id></element-citation></ref><ref id="B82-sensors-25-00990"><label>82.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Aziz</surname><given-names>A.</given-names></name>
<name><surname>Mad Sariff</surname><given-names>E.S.</given-names></name>
<name><surname>Shamsudheen</surname><given-names>I.</given-names></name>
<name><surname>Abd Jamil</surname><given-names>R.</given-names></name>
<name><surname>Abu Zarim</surname><given-names>M.A.U.A.</given-names></name>
</person-group><article-title>The Effect of Emergency Floatation System (EFS) on Helicopter Stability during Ditching</article-title><source>Transp. Eng.</source><year>2023</year><volume>14</volume><fpage>100206</fpage><pub-id pub-id-type="doi">10.1016/j.treng.2023.100206</pub-id></element-citation></ref><ref id="B83-sensors-25-00990"><label>83.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dery</surname><given-names>M.</given-names></name>
<name><surname>Hustuit</surname><given-names>J.</given-names></name>
<name><surname>Boschert</surname><given-names>G.</given-names></name>
<name><surname>Wish</surname><given-names>J.</given-names></name>
</person-group><article-title>Results and Recommendations from the Helicopter EMS Pilot Safety Survey 2005</article-title><source>Air Med. J.</source><year>2007</year><volume>26</volume><fpage>38</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1016/j.amj.2006.08.002</pub-id><pub-id pub-id-type="pmid">17210492</pub-id>
</element-citation></ref><ref id="B84-sensors-25-00990"><label>84.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yanagawa</surname><given-names>Y.</given-names></name>
<name><surname>Omori</surname><given-names>K.</given-names></name>
<name><surname>Nagasawa</surname><given-names>H.</given-names></name>
<name><surname>Takeuchi</surname><given-names>I.</given-names></name>
<name><surname>Jitsuiki</surname><given-names>K.</given-names></name>
<name><surname>Kondo</surname><given-names>A.</given-names></name>
<name><surname>Ohsaka</surname><given-names>H.</given-names></name>
<name><surname>Ishikawa</surname><given-names>K.</given-names></name>
</person-group><article-title>Using a Doctor Helicopter to Transport Medical Staff Only Without Air Evacuation for an Intoxicated Patient to Ensure Aviation Safety</article-title><source>Air Med. J.</source><year>2018</year><volume>37</volume><fpage>218</fpage><pub-id pub-id-type="doi">10.1016/j.amj.2018.04.005</pub-id><pub-id pub-id-type="pmid">29935695</pub-id>
</element-citation></ref><ref id="B85-sensors-25-00990"><label>85.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>de Voogt</surname><given-names>A.</given-names></name>
<name><surname>Nero</surname><given-names>K.</given-names></name>
</person-group><article-title>Technical Failures in Helicopters: Non-Powerplant-Related Accidents</article-title><source>Safety</source><year>2023</year><volume>9</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.3390/safety9010010</pub-id></element-citation></ref><ref id="B86-sensors-25-00990"><label>86.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>de Voogt</surname><given-names>A.</given-names></name>
<name><surname>St. Amour</surname><given-names>E.</given-names></name>
</person-group><article-title>Safety of Twin-Engine Helicopters: Risks and Operational Specificity</article-title><source>Saf. Sci.</source><year>2021</year><volume>136</volume><fpage>105169</fpage><pub-id pub-id-type="doi">10.1016/j.ssci.2021.105169</pub-id></element-citation></ref><ref id="B87-sensors-25-00990"><label>87.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Vladov</surname><given-names>S.</given-names></name>
<name><surname>Shmelov</surname><given-names>Y.</given-names></name>
<name><surname>Yakovliev</surname><given-names>R.</given-names></name>
<name><surname>Petchenko</surname><given-names>M.</given-names></name>
<name><surname>Drozdova</surname><given-names>S.</given-names></name>
</person-group><article-title>Helicopters Turboshaft Engines Parameters Identification at Flight Modes Using Neural Networks</article-title><source>Proceedings of the IEEE 17th International Conference on Computer Science and Information Technologies (CSIT)</source><conf-loc>Lviv, Ukraine</conf-loc><conf-date>10&#x02013;12 November 2022</conf-date><fpage>5</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1109/CSIT56902.2022.10000444</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-00990-f001"><label>Figure 1</label><caption><p>The proposed algorithm block diagram.</p></caption><graphic xlink:href="sensors-25-00990-g001" position="float"/></fig><fig position="float" id="sensors-25-00990-f002"><label>Figure 2</label><caption><p>The proposed neural network structural diagram.</p></caption><graphic xlink:href="sensors-25-00990-g002" position="float"/></fig><fig position="float" id="sensors-25-00990-f003"><label>Figure 3</label><caption><p>Time series of the TV3-117 turboshaft engine parameter dynamics using digitized oscillograms, where (<bold>a</bold>) is the gas-generator rotor r.p.m.; (<bold>b</bold>) is the free turbine rotor speed; and (<bold>c</bold>) is the gas temperature in front of the compressor turbine.</p></caption><graphic xlink:href="sensors-25-00990-g003" position="float"/></fig><fig position="float" id="sensors-25-00990-f004"><label>Figure 4</label><caption><p>Cluster analysis results: (<bold>a</bold>) training dataset; (<bold>b</bold>) test dataset.</p></caption><graphic xlink:href="sensors-25-00990-g004" position="float"/></fig><fig position="float" id="sensors-25-00990-f005"><label>Figure 5</label><caption><p>The autocovariance function diagram: (<bold>a</bold>) the gas-generator rotor r.p.m.; (<bold>b</bold>) the free turbine rotor speed; (<bold>c</bold>) the gas temperature in front of the compressor turbine.</p></caption><graphic xlink:href="sensors-25-00990-g005" position="float"/></fig><fig position="float" id="sensors-25-00990-f006"><label>Figure 6</label><caption><p>The diagram fragment shows readings from the gas-generator rotor r.p.m.</p></caption><graphic xlink:href="sensors-25-00990-g006" position="float"/></fig><fig position="float" id="sensors-25-00990-f007"><label>Figure 7</label><caption><p>The diagram fragment shows readings from the gas-generator rotor r.p.m. considering the sensor malfunctions.</p></caption><graphic xlink:href="sensors-25-00990-g007" position="float"/></fig><fig position="float" id="sensors-25-00990-f008"><label>Figure 8</label><caption><p>The diagram fragment shows readings from the gas-generator rotor r.p.m. considering the sensor readings restored without failures.</p></caption><graphic xlink:href="sensors-25-00990-g008" position="float"/></fig><fig position="float" id="sensors-25-00990-f009"><label>Figure 9</label><caption><p>Structure for integrating the helicopter turboshaft engine model with the developed semi-physical simulation stand.</p></caption><graphic xlink:href="sensors-25-00990-g009" position="float"/></fig><fig position="float" id="sensors-25-00990-f010"><label>Figure 10</label><caption><p>Overview illustrating the interaction between the proposed neural network and the developed semi-physical simulation stand within the Matlab Simulink R2014b environment.</p></caption><graphic xlink:href="sensors-25-00990-g010" position="float"/></fig><fig position="float" id="sensors-25-00990-f011"><label>Figure 11</label><caption><p>The diagram for the set <italic toggle="yes">n<sub>TC</sub></italic> and <italic toggle="yes">n<sub>FT</sub></italic>.</p></caption><graphic xlink:href="sensors-25-00990-g011" position="float"/></fig><fig position="float" id="sensors-25-00990-f012"><label>Figure 12</label><caption><p>The diagram for the set with <italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, and <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></caption><graphic xlink:href="sensors-25-00990-g012" position="float"/></fig><fig position="float" id="sensors-25-00990-f013"><label>Figure 13</label><caption><p>The diagram for the set with <italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, <inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">T<sub>oil</sub></italic>, <italic toggle="yes">P<sub>oil</sub></italic>, and <inline-formula><mml:math id="mm477" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></caption><graphic xlink:href="sensors-25-00990-g013" position="float"/></fig><fig position="float" id="sensors-25-00990-f014"><label>Figure 14</label><caption><p>The diagram illustrating the acceleration in computation as the number of threads increases: (red curve) the linear regression model; (blue curve) the obtained values on the AMD Ryzen 5 5600 3.5 GHz processor, 6 cores, 12 threads.</p></caption><graphic xlink:href="sensors-25-00990-g014" position="float"/></fig><fig position="float" id="sensors-25-00990-f015"><label>Figure 15</label><caption><p>The proposed algorithm&#x02019;s block diagram for solving the approximating the time series values task.</p></caption><graphic xlink:href="sensors-25-00990-g015" position="float"/></fig><fig position="float" id="sensors-25-00990-f016"><label>Figure 16</label><caption><p>The results of approximating time series values under the sensor failure conditions task: (<bold>a</bold>) Gas generator rotor speed sensor; (<bold>b</bold>) Free turbine rotor speed sensor; (<bold>c</bold>) Gas temperature in front of the compressor turbine sensor; (<bold>d</bold>) Engine inlet oil temperature sensor; (<bold>e</bold>) oil pressure at engine outlet sensor; (<bold>f</bold>) The main rotor rotational speed sensor.</p></caption><graphic xlink:href="sensors-25-00990-g016a" position="float"/><graphic xlink:href="sensors-25-00990-g016b" position="float"/></fig><fig position="float" id="sensors-25-00990-f017"><label>Figure 17</label><caption><p>Accuracy metric diagram.</p></caption><graphic xlink:href="sensors-25-00990-g017" position="float"/></fig><fig position="float" id="sensors-25-00990-f018"><label>Figure 18</label><caption><p>Loss metric diagram.</p></caption><graphic xlink:href="sensors-25-00990-g018" position="float"/></fig><fig position="float" id="sensors-25-00990-f019"><label>Figure 19</label><caption><p>Comparative analysis results.</p></caption><graphic xlink:href="sensors-25-00990-g019" position="float"/></fig><fig position="float" id="sensors-25-00990-f020"><label>Figure 20</label><caption><p>The AUC-ROC curve: (<bold>a</bold>) the proposed approach; (<bold>b</bold>) Alternative approach 1; and (<bold>c</bold>) Alternative approach 2.</p></caption><graphic xlink:href="sensors-25-00990-g020" position="float"/></fig><fig position="float" id="sensors-25-00990-f021"><label>Figure 21</label><caption><p>Comparative analysis results: (<bold>a</bold>) accuracy metric; (<bold>b</bold>) training rate metric; and (<bold>c</bold>) efficiency metric.</p></caption><graphic xlink:href="sensors-25-00990-g021" position="float"/></fig><table-wrap position="float" id="sensors-25-00990-t001"><object-id pub-id-type="pii">sensors-25-00990-t001_Table 1</object-id><label>Table 1</label><caption><p>The training dataset fragment obtained during flight tests for the TV3-117 engine.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Value</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">40</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">94</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">158</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">209</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">235</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">256</th></tr></thead><tbody><tr><td align="center" valign="top" rowspan="1" colspan="1">
<italic toggle="yes">n<sub>TC</sub></italic>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.685</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.971</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.902</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.903</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.911</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.740</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.823</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">
<italic toggle="yes">n<sub>FT</sub></italic>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.531</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.986</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.745</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.752</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.761</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.454</td><td align="center" valign="top" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.505</td></tr><tr><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm48" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.487</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.979</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.711</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.721</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.723</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.518</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.521</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t002"><object-id pub-id-type="pii">sensors-25-00990-t002_Table 2</object-id><label>Table 2</label><caption><p>Calculation results for correlation coefficients among sensor sets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sensor Sets</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Correlation Coefficient Values</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Title 3</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">n<sub>TC</sub></italic> and <italic toggle="yes">n<sub>FT</sub></italic></td><td align="center" valign="middle" rowspan="1" colspan="1">0.876</td><td align="center" valign="middle" rowspan="1" colspan="1">Strong positive correlation</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic> and <inline-formula><mml:math id="mm499" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.913</td><td align="center" valign="middle" rowspan="1" colspan="1">The robust positive correlation</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1"><italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, <inline-formula><mml:math id="mm500" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">T<sub>oil</sub></italic> and <italic toggle="yes">P<sub>oil</sub></italic></td><td align="center" valign="middle" rowspan="1" colspan="1">0.754</td><td align="center" valign="middle" rowspan="1" colspan="1">Moderate positive correlation</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><italic toggle="yes">n<sub>TC</sub></italic>, <italic toggle="yes">n<sub>FT</sub></italic>, <inline-formula><mml:math id="mm5000" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">T<sub>oil</sub></italic>, <italic toggle="yes">P<sub>oil</sub></italic> and <italic toggle="yes">n<sub>rs</sub></italic></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.735</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Moderate positive correlation</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t003"><object-id pub-id-type="pii">sensors-25-00990-t003_Table 3</object-id><label>Table 3</label><caption><p>Testing results for the developed system (see <xref rid="sensors-25-00990-f010" ref-type="fig">Figure 10</xref>) on an AMD Ryzen 5 5600 processor with 3.5 GHz, 6 cores, and 12 threads.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Cores Number</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Threads Number</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Time, s</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Relative Time, s</th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">363.73</td><td align="center" valign="middle" rowspan="1" colspan="1">1.000</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">191.17</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.644</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">138.23</td><td align="center" valign="middle" rowspan="1" colspan="1">2.711</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">113.94</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.226</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">96.18</td><td align="center" valign="middle" rowspan="1" colspan="1">3.835</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.88</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.108</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">80.92</td><td align="center" valign="middle" rowspan="1" colspan="1">4.218</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">73.16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.332</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">70.24</td><td align="center" valign="middle" rowspan="1" colspan="1">4.425</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">63.11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.875</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">55.63</td><td align="center" valign="middle" rowspan="1" colspan="1">5.218</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50.02</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6.000</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t004"><object-id pub-id-type="pii">sensors-25-00990-t004_Table 4</object-id><label>Table 4</label><caption><p>The input data description (fragment).</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Time</th><th colspan="6" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Sensor Parameter</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">n<sub>TC</sub></italic>
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">n<sub>FT</sub></italic>
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">*</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">T<sub>oil</sub></italic>
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">P<sub>oil</sub></italic>
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">n<sub>rs</sub></italic>
</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">80</td><td align="center" valign="middle" rowspan="1" colspan="1">0.876</td><td align="center" valign="middle" rowspan="1" colspan="1">0.765</td><td align="center" valign="middle" rowspan="1" colspan="1">0.742</td><td align="center" valign="middle" rowspan="1" colspan="1">1.000</td><td align="center" valign="middle" rowspan="1" colspan="1">1.000</td><td align="center" valign="middle" rowspan="1" colspan="1">0.998</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">90</td><td align="center" valign="middle" rowspan="1" colspan="1">0.876</td><td align="center" valign="middle" rowspan="1" colspan="1">0.765</td><td align="center" valign="middle" rowspan="1" colspan="1">0.738</td><td align="center" valign="middle" rowspan="1" colspan="1">0.999</td><td align="center" valign="middle" rowspan="1" colspan="1">1.000</td><td align="center" valign="middle" rowspan="1" colspan="1">0.998</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">0.885</td><td align="center" valign="middle" rowspan="1" colspan="1">0.801</td><td align="center" valign="middle" rowspan="1" colspan="1">0.750</td><td align="center" valign="middle" rowspan="1" colspan="1">0.999</td><td align="center" valign="middle" rowspan="1" colspan="1">0.999</td><td align="center" valign="middle" rowspan="1" colspan="1">0.997</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">110</td><td align="center" valign="middle" rowspan="1" colspan="1">0.883</td><td align="center" valign="middle" rowspan="1" colspan="1">0.803</td><td align="center" valign="middle" rowspan="1" colspan="1">0.753</td><td align="center" valign="middle" rowspan="1" colspan="1">1.000</td><td align="center" valign="middle" rowspan="1" colspan="1">0.999</td><td align="center" valign="middle" rowspan="1" colspan="1">0.999</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">120</td><td align="center" valign="middle" rowspan="1" colspan="1">0.887</td><td align="center" valign="middle" rowspan="1" colspan="1">0.797</td><td align="center" valign="middle" rowspan="1" colspan="1">0.744</td><td align="center" valign="middle" rowspan="1" colspan="1">1.000</td><td align="center" valign="middle" rowspan="1" colspan="1">1.000</td><td align="center" valign="middle" rowspan="1" colspan="1">0.999</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02026;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02026;</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">320</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.792</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.541</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.570</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.998</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.999</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.997</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t005"><object-id pub-id-type="pii">sensors-25-00990-t005_Table 5</object-id><label>Table 5</label><caption><p>The semi-physical simulation stands the test results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Telemetry File Name</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Telemetry Readings Numbers</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Processing Time, s</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">N17.dat</td><td align="center" valign="middle" rowspan="1" colspan="1">2560</td><td align="center" valign="middle" rowspan="1" colspan="1">17.342</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">N18.dat</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3240</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">17.342</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t006"><object-id pub-id-type="pii">sensors-25-00990-t006_Table 6</object-id><label>Table 6</label><caption><p>Comparative analysis results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Metric</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Proposed Approach</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Alternative Approach 1</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Alternative Approach 2</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy</td><td align="center" valign="top" rowspan="1" colspan="1">0.993</td><td align="center" valign="middle" rowspan="1" colspan="1">0.981</td><td align="center" valign="top" rowspan="1" colspan="1">0.982</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Precision</td><td align="center" valign="top" rowspan="1" colspan="1">0.987</td><td align="center" valign="middle" rowspan="1" colspan="1">0.980</td><td align="center" valign="top" rowspan="1" colspan="1">0.979</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Recall</td><td align="center" valign="top" rowspan="1" colspan="1">1.0</td><td align="center" valign="middle" rowspan="1" colspan="1">1.0</td><td align="center" valign="top" rowspan="1" colspan="1">1.0</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F1-score</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">0.993</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.988</td><td align="center" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">0.989</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t007"><object-id pub-id-type="pii">sensors-25-00990-t007_Table 7</object-id><label>Table 7</label><caption><p>Comparative analysis results (AUC-ROC analysis).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Metric</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Proposed Approach</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Alternative Approach 1</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Alternative Approach 2</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">True Positives</td><td align="center" valign="middle" rowspan="1" colspan="1">99</td><td align="center" valign="middle" rowspan="1" colspan="1">99</td><td align="center" valign="middle" rowspan="1" colspan="1">98</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">True Negatives</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">False Positives</td><td align="center" valign="middle" rowspan="1" colspan="1">289</td><td align="center" valign="middle" rowspan="1" colspan="1">288</td><td align="center" valign="middle" rowspan="1" colspan="1">285</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">False Negatives</td><td align="center" valign="middle" rowspan="1" colspan="1">13</td><td align="center" valign="middle" rowspan="1" colspan="1">15</td><td align="center" valign="middle" rowspan="1" colspan="1">18</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">True Positive Rate</td><td align="center" valign="middle" rowspan="1" colspan="1">0.822</td><td align="center" valign="middle" rowspan="1" colspan="1">0.819</td><td align="center" valign="middle" rowspan="1" colspan="1">0.818</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">False Positive Rate</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0111</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0113</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0112</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">False Negative Rate</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0099</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0101</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0101</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AUC-ROC</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.823</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.818</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.818</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t008"><object-id pub-id-type="pii">sensors-25-00990-t008_Table 8</object-id><label>Table 8</label><caption><p>Comparative analysis results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Metric</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Proposed Approach</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Alternative Approach 1</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Alternative Approach 2</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Accuracy (<italic toggle="yes">Acc</italic>)</td><td align="center" valign="top" rowspan="1" colspan="1">0.993</td><td align="center" valign="middle" rowspan="1" colspan="1">0.981</td><td align="center" valign="top" rowspan="1" colspan="1">0.982</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Training rate (<italic toggle="yes">Res</italic>)</td><td align="center" valign="top" rowspan="1" colspan="1">4 min 13 s <break/>(253 s)</td><td align="center" valign="top" rowspan="1" colspan="1">5 min 43 s <break/>(343 s)</td><td align="center" valign="middle" rowspan="1" colspan="1">4 min 46 s <break/>(286 s)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Efficiency</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00392</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00288</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00343</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t009"><object-id pub-id-type="pii">sensors-25-00990-t009_Table 9</object-id><label>Table 9</label><caption><p>Comparative analysis results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Task</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Processing Time, s</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Required Performance Estimation, GFLOPS</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Monitoring the helicopter TE sensor system under interference conditions.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0165</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.107</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Ensuring stable operation despite external noise.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Restoring regular sensor readings for helicopter TE.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0045</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.219</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Effective correction of incorrect data</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prediction for a numerical series value.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0050</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.674</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Enabling accurate forecasting based on historical data.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Total</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.026</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7.0</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The developed system demonstrates robust performance, ensuring stable operation under interference, the effective correction of erroneous data, and accurate predicting based on historical trends, making it highly reliable for real-time applications.</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-00990-t010"><object-id pub-id-type="pii">sensors-25-00990-t010_Table 10</object-id><label>Table 10</label><caption><p>The developed neural network system&#x02019; proposed further improvements.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Improvement Proposed</th><th align="center" valign="top" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Improve the data preprocessing mechanism.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Develop more adaptive discretization and quantization algorithms to better account for input data features such as noise or outliers;</p></list-item><list-item><p>Include additional data cleaning methods, such as outlier filtering, using statistical or machine learning methods.</p></list-item></list>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The network architecture optimization is improved.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Investigate the Transformer&#x02019;s possibility for time series processing, which can outperform LSTM/GRU when working with long sequences due to the attention mechanism;</p></list-item><list-item><p>Add additional regularization layers, such as Dropout or Batch Normalization, to improve the model&#x02019;s resistance to overfitting.</p></list-item></list>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The correlation analysis accuracy is improved.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Implement dynamic attention mechanisms that automatically identify key time points and sensors with maximum correlation;</p></list-item><list-item><p>Use advanced methods of correlation analysis, including nonlinear dependencies, such as mutual information.</p></list-item></list>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Expanding network functionality.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Add the ability to predict not only correlations but also other dependencies, such as time lags or trends;</p></list-item><list-item><p>Integrate anomaly models based on autoencoders for more accurate fault detection.</p></list-item></list>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Training optimization.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Develop a hybrid optimizer that combines features of Adam and RMSProp to update weights more accurately and speed up convergence;</p></list-item><list-item><p>Include mechanisms for early stopping and dynamic changes in the training rate based on validation metrics.</p></list-item></list>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The system&#x02019;s interpretability is improved.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Develop visualization modules that display not only the correlation results but also the training dynamics, weights, and activation distribution.</p></list-item><list-item><p>Implement network decision explanation tools, such as SHAP or LIME, to analyze the individual input contribution.</p></list-item></list>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Modular integration.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>Develop the ability to integrate the system with real devices and cloud platforms for real-time data processing.</p></list-item><list-item><p>Create an API for easy interaction with external modules, such as control systems or analytical platforms.</p></list-item></list>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Scalability and resilience.</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<list list-type="order"><list-item><p>The computing resources used are optimized, for example, by parallelizing calculations on GPUs or TPUs.</p></list-item><list-item><p>Add mechanisms to check and recover from failures to improve the system&#x02019;s reliability.</p></list-item></list>
</td></tr></tbody></table></table-wrap></floats-group></article>