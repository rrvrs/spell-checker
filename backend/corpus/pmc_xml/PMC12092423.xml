<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="brief-report"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40400741</article-id><article-id pub-id-type="pmc">PMC12092423</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2025.1498958</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Brief Research Report</subject></subj-group></subj-group></article-categories><title-group><article-title>Agentive linguistic framing affects responsibility assignments toward AIs and their creators</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Petersen</surname><given-names>Dawson</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2847804/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Almor</surname><given-names>Amit</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/1455/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Linguistics Program, University of South Carolina</institution>, <addr-line>Columbia, SC</addr-line>, <country>United States</country></aff><aff id="aff2"><sup>2</sup><institution>Department of Psychology, University of South Carolina</institution>, <addr-line>Columbia, SC</addr-line>, <country>United States</country></aff><author-notes><fn fn-type="edited-by" id="fn0001"><p>Edited by: Adriana Salatino, Royal Military Academy, Belgium</p></fn><fn fn-type="edited-by" id="fn0002"><p>Reviewed by: Isabella Poggi, Roma Tre University, Italy</p><p>Simona Collina, Suor Orsola Benincasa University, Italy</p></fn><corresp id="c001">*Correspondence: Dawson Petersen, <email>DHP1@email.sc.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>07</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>16</volume><elocation-id>1498958</elocation-id><history><date date-type="received"><day>19</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>13</day><month>3</month><year>2025</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2025 Petersen and Almor.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Petersen and Almor</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Tech companies often use agentive language to describe their AIs (e.g., The Google Blog claims that, &#x0201c;Gemini can understand, explain and generate high-quality code,&#x0201d;). Psycholinguistic research has shown that violating animacy hierarchies by putting a nonhuman in this agentive subject position (i.e., grammatical metaphor) influences readers to perceive it as a causal agent. However, it is not yet known how this affects readers&#x02019; responsibility assignments toward AIs or the companies that make them. Furthermore, it is not known whether this effect relies on psychological anthropomorphism, or a more limited set of linguistic causal schemas. We investigated these questions by having participants read a short vignette in which &#x0201c;Dr. AI&#x0201d; gave dangerous health advice in one of two framing conditions (AI as Agent vs. AI as Instrument). Participants then rated how responsible the AI, the company, and the patients were for the outcome, and their own AI experience. We predicted that participants would assign more responsibility to the AI in the Agent condition, and that lower AI experience participants would assign higher responsibility to the AI because they would be more likely to anthropomorphize it. The results confirmed these predictions; we found an interaction between linguistic framing condition and AI experience such that lower AI experience participants assigned higher responsibility to the AI in the Agent condition than in the Instrument condition (<italic>z</italic>&#x0202f;=&#x0202f;2.13, <italic>p</italic>&#x0202f;=&#x0202f;0.032) while higher AI experience participants did not. Our findings suggest that the effects of agentive linguistic framing toward non-humans are decreased by domain experience because it decreases anthropomorphism.</p></abstract><kwd-group><kwd>linguistic framing</kwd><kwd>grammatical metaphor</kwd><kwd>agency</kwd><kwd>anthropomorphism</kwd><kwd>AI</kwd></kwd-group><funding-group><funding-statement>The author(s) declare that financial support was received for the research and/or publication of this article. This work was partially supported by the National Science Foundation Linguistics Program Doctoral Dissertation Research Improvement Grant (Award # 2416612), the University of South Carolina Office of the Vice President for Research SPARC Graduate Research Grant Program, and the Russell J. and Dorothy S. Bilinski Dissertation Fellowship.</funding-statement></funding-group><counts><fig-count count="4"/><table-count count="2"/><equation-count count="0"/><ref-count count="40"/><page-count count="8"/><word-count count="5911"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Cognitive Science</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1"><label>1</label><title>Introduction</title><p>Linguists have long argued that the subject position of transitive clauses carries proto-agentive entailments &#x02013; e.g., volition, sentience, causativity, etc. (<xref rid="ref9" ref-type="bibr">Dowty, 1991</xref>). These entailments not only affect sentence processing, but also influence the situation models that hearers construct. For example, cross-linguistic differences in how frequently speakers of different languages use agentive language to describe accidents has been shown to predict how well participants remember the agent of accidental events (<xref rid="ref14" ref-type="bibr">Fausey and Boroditsky, 2010</xref>; <xref rid="ref15" ref-type="bibr">Fausey et al., 2011</xref>). The choice of grammatical subject, specifically, has been shown to affect readers&#x02019; perceptions of agency and responsibility. Unaccusative transitivity alternations (e.g., &#x0201c;the boy broke the window&#x0201d; vs. &#x0201c;the window broke&#x0201d;) allow speakers to choose whether or not to assign an agent for a specific event (<xref rid="ref13" ref-type="bibr">Fausey and Boroditsky, 2011</xref>). Speakers are able to use these subtle syntactic alternations to manipulate the interpretive framework adopted by their hearers, without substantially altering propositional content (<xref rid="ref36" ref-type="bibr">Thibodeau and Boroditsky, 2011</xref>; <xref rid="ref25" ref-type="bibr">McGlynn and McGlone, 2019</xref>; <xref rid="ref10" ref-type="bibr">Dragojevic et al., 2014</xref>). Psycholinguistic research has shown a linguistic framing effect in which the assignment of grammatical agency influences the situation models that readers construct in text interpretation. For example, <xref rid="ref13" ref-type="bibr">Fausey and Boroditsky (2011)</xref> showed participants texts containing the sentences in (1) and (2).</p><list list-type="simple"><list-item><p>(1) As Mrs. Smith reached to grab the napkin, she toppled the candle and ignited the whole tablecloth too!</p></list-item><list-item><p>(2) As Mrs. Smith reached to grab the napkin, the candle toppled and the whole tablecloth ignited too!</p></list-item></list><p>The sentences in (1) and (2) describe the same situation, but they differ in how they assign grammatical agency. In (1), Mrs. Smith is the agent of the transitive verb &#x0201c;topple.&#x0201d; In (2), after an unaccusative transition, the verb does not have an agent (though the reader can still infer that Mrs. Smith was the cause of the toppling). As predicted, <xref rid="ref13" ref-type="bibr">Fausey and Boroditsky (2011)</xref> found that participants who read (1) assigned higher blame and financial liability to Mrs. Smith compared to participants who read (2). This finding has since been replicated by <xref rid="ref38" ref-type="bibr">Tonkovi&#x00107; et al. (2022)</xref>.</p><p>Notably, English allows speakers to violate the animacy hierarchy (<xref rid="ref26" ref-type="bibr">Minkoff, 2000</xref>) by assigning this grammatical agency to inanimate entities in a phenomenon known as grammatical metaphor (<xref rid="ref8" ref-type="bibr">Devrim, 2015</xref>). In these structures, an inanimate entity is not only the grammatical subject but also the agent of a transitive verb. For example, consider the sentences in (3) and (4).</p><list list-type="simple"><list-item><p>(3) Doctors saved many lives by using Scan AI&#x02122; to identify early-stage cancer.</p></list-item><list-item><p>(4) Scan AI&#x02122; saved many lives by enabling doctors to identify early-stage cancer.</p></list-item></list><p>The sentences in (3) and (4) describe the same situation. However, they differ in how they assign grammatical agency. In (3), the agency for &#x0201c;saving lives&#x0201d; is assigned to the doctors while in (4) that agency is assigned to the inanimate AI. The use of grammatical metaphor has been shown to increase the responsibility assigned to radon gas (<xref rid="ref10" ref-type="bibr">Dragojevic et al., 2014</xref>) and obesity (<xref rid="ref25" ref-type="bibr">McGlynn and McGlone, 2019</xref>), to make educational materials about viruses more persuasive (<xref rid="ref24" ref-type="bibr">McGlone et al., 2012</xref>), and to change how much autonomous behavior participants assign to unknown objects (<xref rid="ref12" ref-type="bibr">Fausey and Boroditsky, 2007</xref>).</p><p>The effects of grammatical metaphor are uniquely interesting in the context of AI. During the deep-learning AI boom of the early 2020s, it became increasingly clear that people are highly prone to perceiving and interacting with AIs, and especially chatbots, as humanlike agents (i.e., anthropomorphizing them, <xref rid="ref27" ref-type="bibr">Mitchell and Krakauer, 2023</xref>)&#x02014;with some journalists and developers even going so far as to argue that LLMs are conscious agents (<xref rid="ref37" ref-type="bibr">Tiku, 2022</xref>; <xref rid="ref31" ref-type="bibr">Schwitzgebel and Shevlin, 2023</xref>). Of course, AI anthropomorphism is not new. Indeed, since <xref rid="ref40" ref-type="bibr">Weizenbaum&#x02019;s (1966)</xref> simple ELIZA chatbot, it has been known that people tend to assume that chatbots know more than they really do and are more capable than they really are (i.e., the ELIZA Effect, <xref rid="ref19" ref-type="bibr">Hofstadter, 1995</xref>). However, the explosion of AI technology has seen AI developers frequently describe their models using agentive linguistic framing as in (5)&#x02013;(7).</p><list list-type="simple"><list-item><p>(5) ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers (<xref rid="ref28" ref-type="bibr">Open AI, 2022</xref>).</p></list-item><list-item><p>(6) Copilot promises to unlock productivity for everyone (<xref rid="ref33" ref-type="bibr">Spataro, 2023</xref>).</p></list-item><list-item><p>(7) Gemini can understand, explain and generate high-quality code (<xref rid="ref29" ref-type="bibr">Pichai and Hassabis, 2023</xref>).</p></list-item></list><p>AI anthropomorphism provides a unique opportunity to better understand the effects of grammatical metaphor. More specifically, while it has been shown that grammatical metaphor causes readers to derive proto-agentive entailments about non-humans, it is not clear whether it involves actually anthropomorphizing the target or if it relies on more limited linguistic causal schemas. The prevalence of AI anthropomorphism creates an opportunity answer this important theoretical question. If the effect of grammatical metaphor relies on anthropomorphism, we would expect factors that predict anthropomorphism (namely, domain experience and anthropomorphic disposition) to interact with a linguistic framing manipulation to produce a stronger effect.</p><p>Theories of anthropomorphism suggest that AI anthropomorphism may be a result of the difficulty people have building mechanistic mental models of AI (<xref rid="ref11" ref-type="bibr">Epley et al., 2007</xref>; <xref rid="ref6" ref-type="bibr">Dennett, 1987</xref>). According to <xref rid="ref11" ref-type="bibr">Epley et al.&#x02019;s (2007)</xref> three-factor theory and <xref rid="ref6" ref-type="bibr">Dennett&#x02019;s (1987)</xref> intentional stance approach, anthropomorphism can serve as a predictive strategy for interacting with unpredictable entities. In other words, treating an AI as an agent (with goals, beliefs, and means-end rationality) provides a framework for people to reason about an otherwise abstract system. Therefore, these accounts of anthropomorphism predict that experience with AI will moderate anthropomorphism because participants with more AI experience will find AI more predictable and so they will not need to rely on an agency framework to understand its behavior.</p><p>This further suggests that domain experience with AI could provide an &#x0201c;inoculating&#x0201d; effect against agentive linguistic framing. Because people with low AI experience do not have a robust mental model of how it works, they should be more likely to adopt the mental model suggested by the linguistic framing (i.e., adopting an anthropomorphic mental model when the AI is framed agentively and a mechanistic one when it is framed as a tool). In contrast, people with high AI experience already have a mental model of AI, and as a result, they should not only be less likely anthropomorphize to begin with, but they should also be less affected by the linguistic framing. If such an interaction were found, it would provide evidence that the effects of grammatical metaphor rely on the rich representations of agency and intention involved in anthropomorphism, not just linguistic causal schemas.</p><p>Recent work on the effects of linguistic framing on perceptions of robots provides preliminary evidence that such an inoculating effect exists. <xref rid="ref21" ref-type="bibr">Kopp et al. (2022)</xref> found that factory workers perceived robots as more humanlike when they were described anthropomorphically (e.g., &#x0201c;[The robot] <italic>Paul waits patiently</italic> during employees&#x02019; lunch break&#x0201d;) as opposed to non-anthropomorphically (e.g., &#x0201c;[The robot] <italic>UR-5</italic> is <italic>switched to idle mode</italic> during employees&#x02019; lunch break&#x0201d;). However, <xref rid="ref22" ref-type="bibr">Kopp et al. (2023)</xref> failed to replicate this effect with technology students. <xref rid="ref22" ref-type="bibr">Kopp et al. (2023)</xref> suggest that this failure may be due to the students&#x02019; higher level of experience with robots; however, they note that the two studies utilized somewhat different experimental methods. As such, it is not clear whether domain experience modulates the effects of agentive linguistic framing as is predicted by theories of anthropomorphism.</p><p>Not only is there theoretical value to better understanding grammatical metaphor and its relationship to AI anthropomorphism, these questions also raise legal implications. Previous studies overwhelmingly focused on how grammatical metaphor affects participants&#x02019; perceptions technology, but they have not examined how grammatical metaphor affects participants&#x02019; perceptions of the technology&#x02019;s creators. However, this is an issue of great practical importance. Some companies have already tried to argue that they are not legally responsible for information produced by their AIs (see <xref rid="ref16" ref-type="bibr">Garcia, 2024</xref>), and if, as previous research suggests, linguistic framing can cause people to see AIs as responsible agents, they are likely to see the companies which create and deploy those AIs as less responsible.</p><p>In light of these issues, the current study investigates the interaction between agentive linguistic framing and domain experience with AI on participants&#x02019; responsibility assignments both to AIs and to the companies that create them. Specifically, we predict that (1) participants with lower AI experience will rate the AI as more responsible than participants with higher AI experience; (2) when the AI is framed as an agent, participants will rate it as more responsible and the company that made it as less responsible than when it is framed as a tool; and (3) participants with lower AI experience will be more affected by the linguistic framing manipulation than participants with higher AI experience.</p></sec><sec sec-type="materials|methods" id="sec2"><label>2</label><title>Materials and methods</title><p>We tested these hypotheses using a judgment priming paradigm in which participants first read a short vignette in one of two linguistic framing conditions (Agent vs. Instrument) and then made judgments about it. The vignette (see <xref rid="tab1" ref-type="table">Table 1</xref>) described how an AI language model &#x0201c;Dr. A.I.&#x0201d; gave dangerous health advice causing many patients to be hospitalized. The linguistic framing manipulation was achieved using grammatical metaphor (i.e., making the AI the grammatical subject of transitive clauses) as well as active/passive voice shifts. The two versions of the vignette were otherwise identical. After reading the vignette, participants were asked to rate on a scale from 1 to 100: (1) to what extent the AI, the company that created it, and the patients were each responsible for the outcome, and (2) how much experience they had with AI. Finally, participants completed the Individual Differences in Anthropomorphism Questionnaire (IDAQ) (<xref rid="ref39" ref-type="bibr">Waytz et al., 2010</xref>), and then were asked to retell the story from the vignette in as much detail as they could remember. This recall data was used to ensure that participants read and understood the vignette in sufficient detail. The full survey is available through the OSF repository.</p><table-wrap position="float" id="tab1"><label>Table 1</label><caption><p>The agent and instrument condition vignettes.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Agent condition</th><th align="left" valign="top" rowspan="1" colspan="1">Instrument condition</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">In 2023, <underline>an A.I. language model called "Dr. A.I." captured</underline> widespread attention after being released by a tech company called Health A.I. Dr. A.I. <underline>tried to</underline> provide accurate, tailored medical advice based on what it knew about users' symptoms and medical histories. However, in 2024, <underline>Dr. A.I. made an error when it recommended a dangerous home cure for a common cold.</underline> Several people who followed this advice were hospitalized, and one person died. The families of the people who were hospitalized are preparing a large lawsuit against Health A.I.</td><td align="left" valign="top" rowspan="1" colspan="1">In 2023, <underline>a tech company called Health A.I. captured</underline> widespread attention after they created an A.I. language model called "Dr. A.I." Dr. A.I. <underline>was designed to</underline> provide accurate, tailored medical advice based on the company's data about users' symptoms and medical histories. However, in 2024, <underline>a recommendation for a dangerous home cure for a common cold was generated by Dr A.I.</underline> Several people who followed this advice were hospitalized, and one person died. The families of the people who were hospitalized are preparing a large lawsuit against Health A.I.</td></tr></tbody></table><table-wrap-foot><p>Key differences between the two versions are underlined here for clarity, but were not visible to participants.</p></table-wrap-foot></table-wrap><p>We recruited 157 participants from psychology and linguistics classes at the University of South Carolina. Of these, 35 were excluded for failure to complete the study or failure to recall the key details of the vignette, resulting in a final sample size of 122. Participants were considered to not recall key details if they wrote that they did not remember, or if they grossly misremembered the main characters and events of the story&#x02014;especially if it was not clear that they realized an AI was involved (e.g., &#x0201c;An online Dr. passed out a medication,&#x0201d; &#x0201c;The company failed in the aspect of a home invasion&#x0201d;). Participants who merely mixed up the names of the company and the AI were not excluded.</p></sec><sec sec-type="results" id="sec3"><label>3</label><title>Results</title><p>The data were analyzed in R 4.3.0 (<xref rid="ref30" ref-type="bibr">R Core Team, 2023</xref>). Participants generally rated themselves as having low AI experience, with self-rated experience falling into a heavily right-skewed distribution (<italic>M</italic>&#x0202f;=&#x0202f;19.8, <italic>SD</italic>&#x0202f;=&#x0202f;24.6, <italic>Median</italic>&#x0202f;=&#x0202f;10, <italic>Mode</italic>&#x0202f;=&#x0202f;0). As expected, experience was negatively correlated with AI responsibility assignments (<italic>R</italic>&#x0202f;=&#x0202f;&#x02212;0.29, <italic>p</italic>&#x0202f;=&#x0202f;0.001), but had no correlation with company (<italic>R</italic>&#x0202f;=&#x0202f;&#x02212;0.03, <italic>p</italic>&#x0202f;=&#x0202f;0.728) or patient responsibility assignments (<italic>R</italic>&#x0202f;=&#x0202f;0.02, <italic>p</italic>&#x0202f;=&#x0202f;0.819). Overall, participants assigned the most responsibility to the company (<italic>M</italic>&#x0202f;=&#x0202f;70, <italic>SD</italic>&#x0202f;=&#x0202f;23), followed by the AI (<italic>M</italic>&#x0202f;=&#x0202f;49, <italic>SD</italic>&#x0202f;=&#x0202f;35), and the least to the patients (<italic>M</italic>&#x0202f;=&#x0202f;43, <italic>SD</italic>&#x0202f;=&#x0202f;26). However, responsibility assignments toward all three targets were non-normally distributed. Responsibility assignments toward the company showed a strong leftward skew with a primary mode of 100 (<italic>frequency</italic>&#x0202f;=&#x0202f;18) and a secondary mode of 50 (<italic>frequency</italic>&#x0202f;=&#x0202f;16). Responsibility assignments toward the AI were trimodal with a primary mode of 0 (<italic>frequency</italic>&#x0202f;=&#x0202f;16), and secondary modes of 50 (<italic>frequency</italic>&#x0202f;=&#x0202f;12) and 100 (<italic>frequency</italic>&#x0202f;=&#x0202f;11). Responsibility assignments toward the patients were trimodally distributed and had an overall rightward skew, with a primary mode of 50 (<italic>frequency</italic>&#x0202f;=&#x0202f;12) and secondary modes of 70 (<italic>frequency</italic>&#x0202f;=&#x0202f;10) and 10 (<italic>frequency</italic>&#x0202f;=&#x0202f;9). Additional descriptive statistics are available in <xref rid="tab2" ref-type="table">Table 2</xref>.</p><table-wrap position="float" id="tab2"><label>Table 2</label><caption><p>The mean, median, and standard deviations of participants&#x02019; responsibility ratings toward the company, the AI, and the patients, by condition and quartile of AI experience.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Group</th><th align="center" valign="top" rowspan="1" colspan="1">n</th><th align="center" valign="top" rowspan="1" colspan="1">Mean</th><th align="center" valign="top" rowspan="1" colspan="1">Median</th><th align="center" valign="top" rowspan="1" colspan="1">Mode(s) [<italic>frequency</italic>]</th><th align="center" valign="top" rowspan="1" colspan="1">SD</th></tr></thead><tbody><tr><td align="left" valign="bottom" colspan="6" rowspan="1">Company responsibility ratings</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Agent condition</td><td align="center" valign="bottom" rowspan="1" colspan="1">57</td><td align="center" valign="bottom" rowspan="1" colspan="1">72.07</td><td align="center" valign="bottom" rowspan="1" colspan="1">72</td><td align="center" valign="bottom" rowspan="1" colspan="1">100[<italic>f</italic> =&#x0202f;8]</td><td align="center" valign="bottom" rowspan="1" colspan="1">22.04</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Instrument condition</td><td align="center" valign="bottom" rowspan="1" colspan="1">65</td><td align="center" valign="bottom" rowspan="1" colspan="1">69.29</td><td align="center" valign="bottom" rowspan="1" colspan="1">71</td><td align="center" valign="bottom" rowspan="1" colspan="1">50[<italic>f</italic> =&#x0202f;12] 100[<italic>f</italic> =&#x0202f;10]</td><td align="center" valign="bottom" rowspan="1" colspan="1">23.38</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">First quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">31</td><td align="center" valign="bottom" rowspan="1" colspan="1">70.06</td><td align="center" valign="bottom" rowspan="1" colspan="1">71</td><td align="center" valign="bottom" rowspan="1" colspan="1">100[<italic>f</italic> =&#x0202f;5]</td><td align="center" valign="bottom" rowspan="1" colspan="1">22.38</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Second quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">31</td><td align="center" valign="bottom" rowspan="1" colspan="1">69.67</td><td align="center" valign="bottom" rowspan="1" colspan="1">70</td><td align="center" valign="bottom" rowspan="1" colspan="1">50[<italic>f</italic> =&#x0202f;5]</td><td align="center" valign="bottom" rowspan="1" colspan="1">22.80</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Third quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">30</td><td align="center" valign="bottom" rowspan="1" colspan="1">76.77</td><td align="center" valign="bottom" rowspan="1" colspan="1">80.5</td><td align="center" valign="bottom" rowspan="1" colspan="1">100[<italic>f</italic> =&#x0202f;7]</td><td align="center" valign="bottom" rowspan="1" colspan="1">21.62</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Fourth quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">30</td><td align="center" valign="bottom" rowspan="1" colspan="1">65.9</td><td align="center" valign="bottom" rowspan="1" colspan="1">70</td><td align="center" valign="bottom" rowspan="1" colspan="1">50[<italic>f</italic> =&#x0202f;4]</td><td align="center" valign="bottom" rowspan="1" colspan="1">23.80</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Overall</td><td align="center" valign="bottom" rowspan="1" colspan="1">122</td><td align="center" valign="bottom" rowspan="1" colspan="1">70.59</td><td align="center" valign="bottom" rowspan="1" colspan="1">71</td><td align="center" valign="bottom" rowspan="1" colspan="1">100[<italic>f</italic> =&#x0202f;18]<break/>50[<italic>f</italic> =&#x0202f;16]</td><td align="center" valign="bottom" rowspan="1" colspan="1">22.82</td></tr><tr><td align="left" valign="middle" colspan="6" rowspan="1">AI responsibility ratings</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Agent condition</td><td align="center" valign="bottom" rowspan="1" colspan="1">57</td><td align="center" valign="bottom" rowspan="1" colspan="1">49.89</td><td align="center" valign="bottom" rowspan="1" colspan="1">50</td><td align="center" valign="bottom" rowspan="1" colspan="1">0[<italic>f</italic> =10]</td><td align="center" valign="bottom" rowspan="1" colspan="1">37.01</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Instrument condition</td><td align="center" valign="bottom" rowspan="1" colspan="1">65</td><td align="center" valign="bottom" rowspan="1" colspan="1">49.14</td><td align="center" valign="bottom" rowspan="1" colspan="1">50</td><td align="center" valign="bottom" rowspan="1" colspan="1">0[<italic>f</italic> =10]<break/>50[<italic>f</italic> =10]</td><td align="center" valign="bottom" rowspan="1" colspan="1">32.66</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">First quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">31</td><td align="center" valign="bottom" rowspan="1" colspan="1">59.64</td><td align="center" valign="bottom" rowspan="1" colspan="1">70</td><td align="center" valign="bottom" rowspan="1" colspan="1">100[<italic>f</italic> =5]<break/>80[<italic>f</italic> =4]<break/>0[<italic>f</italic> =4]</td><td align="center" valign="bottom" rowspan="1" colspan="1">34.44</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Second quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">31</td><td align="center" valign="bottom" rowspan="1" colspan="1">54.06</td><td align="center" valign="bottom" rowspan="1" colspan="1">50</td><td align="center" valign="bottom" rowspan="1" colspan="1">50[<italic>f</italic> =5]</td><td align="center" valign="bottom" rowspan="1" colspan="1">32.54</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Third quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">30</td><td align="center" valign="bottom" rowspan="1" colspan="1">49.93</td><td align="center" valign="bottom" rowspan="1" colspan="1">52.5</td><td align="center" valign="bottom" rowspan="1" colspan="1">0[<italic>f</italic> =&#x0202f;6]</td><td align="center" valign="bottom" rowspan="1" colspan="1">37.56</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Fourth quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">30</td><td align="center" valign="bottom" rowspan="1" colspan="1">33.83</td><td align="center" valign="bottom" rowspan="1" colspan="1">36.5</td><td align="center" valign="bottom" rowspan="1" colspan="1">0[<italic>f</italic> =7]</td><td align="center" valign="bottom" rowspan="1" colspan="1">29.67</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Overall</td><td align="center" valign="bottom" rowspan="1" colspan="1">122</td><td align="center" valign="bottom" rowspan="1" colspan="1">49.49</td><td align="center" valign="bottom" rowspan="1" colspan="1">50</td><td align="center" valign="bottom" rowspan="1" colspan="1">0[<italic>f</italic> =16]<break/>50[<italic>f</italic> =12]<break/>100[<italic>f</italic> =&#x0202f;11]</td><td align="center" valign="bottom" rowspan="1" colspan="1">34.62</td></tr><tr><td align="left" valign="bottom" colspan="6" rowspan="1">Patient responsibility ratings</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Agent condition</td><td align="center" valign="bottom" rowspan="1" colspan="1">57</td><td align="center" valign="bottom" rowspan="1" colspan="1">42.82</td><td align="center" valign="bottom" rowspan="1" colspan="1">41</td><td align="center" valign="bottom" rowspan="1" colspan="1">70[<italic>f</italic> =&#x0202f;5]</td><td align="center" valign="bottom" rowspan="1" colspan="1">27.18</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Instrument condition</td><td align="center" valign="bottom" rowspan="1" colspan="1">65</td><td align="center" valign="bottom" rowspan="1" colspan="1">42.09</td><td align="center" valign="bottom" rowspan="1" colspan="1">47</td><td align="center" valign="bottom" rowspan="1" colspan="1">50[<italic>f</italic> =&#x0202f;10]</td><td align="center" valign="bottom" rowspan="1" colspan="1">24.79</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">First quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">31</td><td align="center" valign="bottom" rowspan="1" colspan="1">45.19</td><td align="center" valign="bottom" rowspan="1" colspan="1">50</td><td align="center" valign="bottom" rowspan="1" colspan="1">0[<italic>f</italic> =&#x0202f;4]<break/>50[<italic>f</italic> =&#x0202f;4]</td><td align="center" valign="bottom" rowspan="1" colspan="1">25.50</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Second quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">31</td><td align="center" valign="bottom" rowspan="1" colspan="1">33.64</td><td align="center" valign="bottom" rowspan="1" colspan="1">30</td><td align="center" valign="bottom" rowspan="1" colspan="1">5[<italic>f</italic> =&#x0202f;4]</td><td align="center" valign="bottom" rowspan="1" colspan="1">27.51</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Third quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">30</td><td align="center" valign="bottom" rowspan="1" colspan="1">43.77</td><td align="center" valign="bottom" rowspan="1" colspan="1">44</td><td align="center" valign="bottom" rowspan="1" colspan="1">10[<italic>f</italic> =&#x0202f;4]<break/>70[<italic>f</italic> =&#x0202f;4]</td><td align="center" valign="bottom" rowspan="1" colspan="1">26.24</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Fourth quartile of AI experience</td><td align="center" valign="bottom" rowspan="1" colspan="1">30</td><td align="center" valign="bottom" rowspan="1" colspan="1">47.33</td><td align="center" valign="bottom" rowspan="1" colspan="1">48.5</td><td align="center" valign="bottom" rowspan="1" colspan="1">20[<italic>f</italic> =&#x0202f;3]<break/>30[<italic>f</italic> =&#x0202f;3]<break/>50[<italic>f</italic> =&#x0202f;3]</td><td align="center" valign="bottom" rowspan="1" colspan="1">22.83</td></tr><tr><td align="left" valign="bottom" rowspan="1" colspan="1">Overall</td><td align="center" valign="bottom" rowspan="1" colspan="1">122</td><td align="center" valign="bottom" rowspan="1" colspan="1">42.43</td><td align="center" valign="bottom" rowspan="1" colspan="1">42.5</td><td align="center" valign="bottom" rowspan="1" colspan="1">50[<italic>f</italic> =&#x0202f;12]<break/>70[<italic>f</italic> =&#x0202f;10]<break/>10[<italic>f</italic> =&#x0202f;9]</td><td align="center" valign="bottom" rowspan="1" colspan="1">25.82</td></tr></tbody></table><table-wrap-foot><p>Note that these measures of central tendency are not highly informative due to the non-normal distribution of the data (see <xref rid="fig1" ref-type="fig">Figures 1</xref>&#x02013;<xref rid="fig3" ref-type="fig">3</xref>).</p></table-wrap-foot></table-wrap><sec id="sec4"><label>3.1</label><title>Main analysis</title><p>Mean differences between the two framing conditions were not observed in responsibility ratings (see <xref rid="tab2" ref-type="table">Table 2</xref>). However, these measures of central tendency are not highly informative because of the non-normal distributions of the rating data. Furthermore, standard operations such taking the natural log were not able to sufficiently normalize the responsibility rating data for parametric analysis. Therefore, we analyzed the responsibility rating data using cumulative link regression models (<xref rid="ref1" ref-type="bibr">Agresti, 2012</xref>) implemented with the <italic>ordinal</italic> package 4.1 (<xref rid="ref4" ref-type="bibr">Christensen, 2022</xref>) in R. The responsibility assigned to the AI, the company, and the patients were each modeled separately as dependent variables. For each dependent variable, condition (Agent vs. Instrument), log self-rated AI experience, and participants&#x02019; IDAQ scores were considered as predictors. Alternative models were compared using Akaike&#x02019;s information criterion (AIC) (<xref rid="ref2" ref-type="bibr">Akaike, 2011</xref>), and optimal models were selected.</p><p>For AI responsibility, the optimal model included only the interaction between condition and AI experience. IDAQ scores failed to improve model fit (<italic>p</italic>&#x0202f;=&#x0202f;0.169). We found a main effect of AI experience (<italic>z</italic>&#x0202f;=&#x0202f;&#x02212;3.68, <italic>p</italic>&#x0202f;&#x0003c;&#x0202f;0.001) such that participants with less AI experience assigned more responsibility to the AI and an interaction between framing condition and AI experience (<italic>z</italic>&#x0202f;=&#x0202f;2.13, <italic>p</italic>&#x0202f;=&#x0202f;0.032) such that low AI experience participants assigned more responsibility to the AI in the Agent condition than the Instrument condition, while high AI experience participants did not (illustrated in <xref rid="fig1" ref-type="fig">Figure 1</xref>). The main effect of framing condition was only marginally significant (<italic>z</italic>&#x0202f;=&#x0202f;&#x02212;1.86, <italic>p</italic>&#x0202f;=&#x0202f;0.06).</p><fig position="float" id="fig1"><label>Figure 1</label><caption><p>Density plots of the responsibility assigned to the AI in the agent <bold>(A)</bold> and instrument <bold>(B)</bold> conditions by participants with different levels of self-rated AI experience&#x02014;low in light/gold (below the mean, <italic>n</italic>&#x0202f;=&#x0202f;80) and high in dark/green (above the mean, <italic>n</italic>&#x0202f;=&#x0202f;42). Note that AI experience was analyzed as a continuous variable, although it is displayed as a categorical variable here for the purpose of data visualization. Medians for each group are shown by the dashed lines.</p></caption><graphic xlink:href="fpsyg-16-1498958-g001" position="float"/></fig><p>For company responsibility, once again the optimal model included only the interaction between condition and AI experience, and IDAQ scores failed to improve model fit (<italic>p</italic>&#x0202f;=&#x0202f;0.559). We found a main effect of condition (<italic>z</italic>&#x0202f;=&#x0202f;&#x02212;2.01, <italic>p</italic>&#x0202f;=&#x0202f;0.036) such that participants in the Agent condition assigned less responsibility to the company than participants in the Instrument condition, and an interaction between condition and AI experience (<italic>z</italic>&#x0202f;=&#x0202f;2.42, <italic>p</italic>&#x0202f;=&#x0202f;0.015) such that the main effect of condition was stronger for participants with high AI experience (illustrated in <xref rid="fig2" ref-type="fig">Figure 2</xref>).</p><fig position="float" id="fig2"><label>Figure 2</label><caption><p>Density plots of the responsibility assigned to the company in the agent <bold>(A)</bold> and instrument <bold>(B)</bold> conditions by participants with different levels of self-rated AI experience&#x02014;low in light/gold (below the mean, <italic>n</italic>&#x0202f;=&#x0202f;80) and high in dark/green (above the mean, <italic>n</italic>&#x0202f;=&#x0202f;42). Note that AI experience was analyzed as a continuous variable, although it is displayed as a categorical variable here for the purpose of data visualization. Medians for each group are shown by the dashed lines.</p></caption><graphic xlink:href="fpsyg-16-1498958-g002" position="float"/></fig><p>For patient responsibility, the optimal model included only AI experience. However, we found no significant effect of AI experience in that model. Indeed, even using maximal models of patient responsibility assignments, we did not find any significant main effects or interactions between our predictors (illustrated in <xref rid="fig3" ref-type="fig">Figure 3</xref>).</p><fig position="float" id="fig3"><label>Figure 3</label><caption><p>Density plots of the responsibility assigned to the patients in the agent <bold>(A)</bold> and instrument <bold>(B)</bold> conditions by participants with different levels of self-rated AI experience&#x02014;low in light/gold (below the mean, <italic>n</italic>&#x0202f;=&#x0202f;80) and high in dark/green (above the mean, <italic>n</italic>&#x0202f;=&#x0202f;42). Note that AI experience was analyzed as a continuous variable, although it is displayed as a categorical variable here for the purpose of data visualization. Medians for each group are shown by the dashed lines.</p></caption><graphic xlink:href="fpsyg-16-1498958-g003" position="float"/></fig></sec><sec id="sec5"><label>3.2</label><title>Effect size stabilization analysis</title><p>Because we did not have an <italic>a priori</italic> expectation of effect size, we were not able to perform an <italic>a priori</italic> power analysis to select an appropriate sample size. Therefore, in order to determine whether or not our experiment was sufficiently powered to detect real effects in the population, we performed an effect size stabilization analysis, following the approach endorsed by <xref rid="ref3" ref-type="bibr">Anderson et al. (2022)</xref>. Anderson et al. showed that if one continuously calculates model effect size as participants are added to the sample, data collection can be safely ended when the effect size stabilizes without the introduction of statistical bias (i.e., p-hacking). In other words, when the effect size stabilizes, it likely represents the true effect size in the population.</p><p>Because the ordinal cumulative link models which we used output log likelihoods, the most natural measures of effect size are Pseudo R<sup>2</sup> measures such as Cox and Snell (<xref rid="ref5" ref-type="bibr">Cox and Snell, 2018</xref>). Therefore, we reperformed our analysis of the responsibility assignments to the AI, and then we computed Cox and Snell each time a new datapoint was added to the sample using the <italic>rcompanion</italic> package 2.5.0 (<xref rid="ref23" ref-type="bibr">Mangiafico, 2017</xref>). The results (see <xref rid="fig4" ref-type="fig">Figure 4</xref>) show that the effect size had changed minimally (less than +/&#x02212; 0.02) for fifteen consecutive participants when we stopped data collection at n&#x0202f;=&#x0202f;122. Therefore, we conclude, following <xref rid="ref3" ref-type="bibr">Anderson et al. (2022)</xref>, that this sample size was sufficient to detect the approximate true effect size in the population.</p><fig position="float" id="fig4"><label>Figure 4</label><caption><p>Pseudo R<sup>2</sup> measure of effect size (Cox and Snell) by the number of subjects included in the analysis of the responsibility assigned to the AI. The results show that Cox and Snell stabilized at <italic>R<sup>2</sup></italic>&#x0202f;=&#x0202f;~0.12 when data collection was stopped at <italic>n</italic>&#x0202f;=&#x0202f;122.</p></caption><graphic xlink:href="fpsyg-16-1498958-g004" position="float"/></fig></sec></sec><sec sec-type="discussion" id="sec6"><label>4</label><title>Discussion</title><p>Overall, our findings are generally consistent with our hypotheses. Firstly, we found that, as predicted by theories of anthropomorphism such as <xref rid="ref11" ref-type="bibr">Epley et al. (2007)</xref> and <xref rid="ref6" ref-type="bibr">Dennett (1987)</xref>, participants with lower AI experience assigned higher responsibility to the AI than participants with higher AI experience. Secondly, we found a linguistic framing effect such that assigning grammatical agency to the AI resulted in higher responsibility assignments to the AI and lower responsibility assignments to the company that created it. Crucially, these linguistic framing effects were dependent on AI experience. Specifically, we found that only lower AI experience participants assigned higher responsibility to the AI in the Agent condition compared to the Instrument condition, while higher AI experience participants showed the opposite trend. This finding provides evidence that domain experience can indeed have an inoculating effect against the linguistic framing effects of grammatical metaphor. In turn, this provides evidence that the effects of grammatical metaphor involve anthropomorphism, as domain experience would not be expected to modulate the effects of grammatical metaphor if they occurred only at the level of linguistic causal schemas. Instead, this finding provides additional evidence that the effects of grammatical metaphor occur in more general processes of situation model construction, as has been argued by <xref rid="ref13" ref-type="bibr">Fausey and Boroditsky (2011)</xref> to be the case for other types of agentive linguistic framing.</p><p>Interestingly, however, we did not find any effects of the IDAQ (<xref rid="ref39" ref-type="bibr">Waytz et al., 2010</xref>) on AI responsibility assignments. This finding runs contrary to the predictions of <xref rid="ref11" ref-type="bibr">Epley et al.&#x02019;s (2007)</xref> three-factor theory; however, it replicates the findings of previous studies (e.g., <xref rid="ref34" ref-type="bibr">Tahiroglu and Taylor, 2019</xref>; <xref rid="ref20" ref-type="bibr">Hortensius et al., 2021</xref>) which found that the IDAQ is a poor predictor of participants&#x02019; tendency to make anthropomorphic attributions about specific situations. Taken together, these findings suggest that more generalized anthropomorphic beliefs (as measured by the IDAQ) may not strongly influence more particularized anthropomorphic attributions (e.g., contextual, causal explanations of behavior, <xref rid="ref18" ref-type="bibr">Hilton, 2007</xref>). This finding is further congruent with <xref rid="ref35" ref-type="bibr">Thellman and Ziemke (2019)</xref> position that anthropomorphic attributions are ontologically non-committal. In other words, people can adopt anthropomorphic causal explanations of an inanimate entity&#x02019;s behavior, even when these explanations contradict their explicit beliefs about its abilities.</p><p>Additionally, we found that all participants assigned less responsibility to the company in the AI as Agent condition than in the AI as Instrument condition, regardless of experience level. This stands in contrast to our finding that AI experience decreased the effects of agentive linguistic framing on AI responsibility assignments. Not only was this not the case for company responsibility assignments, we even found that the framing effect was stronger for higher experience participants than for lower experience ones. This finding has both theoretical and practical implications. Firstly, it helps us to better understand the involvement of anthropomorphism in the effects of grammatical metaphor. It shows that the higher experience participants did form different causal situation models as a result of the grammatical metaphor, and therefore, suggests that they inhibited their responsibility assignments to the AI in the Agent condition because they were unwilling to anthropomorphize it. If this is the case, it complicates the picture somewhat regarding the inoculating effect of experience that we have proposed&#x02014;as AI experience appears to only inoculate against one of the effects of the grammatical metaphor (higher responsibility to the AI) and not the other (lower responsibility to the creator). The practical upshot of this is that people with high AI experience may still be easily manipulated by grammatical metaphor to perceive tech companies as less responsible for their AIs&#x02019; behavior.</p><p>One important limitation of this study, however, is the range of experience levels included in our sample. Our sample was composed primarily of first- and second-year undergraduate students with generally low self-rated AI experience (<italic>M</italic>&#x0202f;=&#x0202f;19.8, <italic>SD</italic>&#x0202f;=&#x0202f;24.6, <italic>Median</italic>&#x0202f;=&#x0202f;10, <italic>Mode</italic>&#x0202f;=&#x0202f;0). Although we found interesting differences between higher and lower experience participants within this range, further work is required to understand how these effects appear in truly high experience participants within the general population (e.g., tech workers, computer scientists, etc.). If the relationship between linguistic framing and AI experience is in someway nonlinear, we may find that such individuals behave quite differently from the higher experience participants within our sample.</p><p>Our results further raise questions regarding how specific properties of AI systems (and interaction with them) affects participants&#x02019; agency assignments. One particularly interesting factor is language use. <xref rid="ref40" ref-type="bibr">Weizenbaum&#x02019;s (1966)</xref> ELIZA effect suggests that AI language use has powerful effects on users&#x02019; perceptions of its agency. If this is indeed the case, we may find that participants respond differently to chatbots (e.g., &#x0201c;Dr. A.I.&#x0201d;) compared to AIs used for image recognition/generation, driving, financial analysis etc.&#x02014;despite the similarities in the underlying technology. Such research should further seek to understand how interaction with language AIs affects users&#x02019; perceptions. For example, restricting a chatbot&#x02019;s ability to use first-person pronouns (&#x0201c;I,&#x0201d; &#x0201c;my,&#x0201d; etc.) may significantly decrease users&#x02019; perception of its agency.</p><p>Finally, our findings have important practical and ethical implications for how we talk about AI. They show that linguistically framing AIs as agents influences lower experience people to anthropomorphize the AIs and influences all people to consider the companies which create them less responsible for their mistakes. Historically, authors disagree as to the extent to which such anthropomorphism of AI is desirable (<xref rid="ref7" ref-type="bibr">Deshpande et al., 2023</xref>) or dangerous (<xref rid="ref17" ref-type="bibr">Hasan, 2023</xref>), and indeed, some AI researchers even advocate including anthropomorphic features to increase user trust in the AI (<xref rid="ref32" ref-type="bibr">Song and Luximon, 2020</xref>). Given our findings, we argue that encouraging the anthropomorphism of AI by using agentive linguistic framing is dangerous as it can cause even experienced individuals to fail to hold AI companies accountable when their creations cause harm.</p></sec></body><back><sec sec-type="data-availability" id="sec7"><title>Data availability statement</title><p>The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession number(s) can be found at: <ext-link xlink:href="https://doi.org/10.17605/OSF.IO/7MGEV" ext-link-type="uri">https://doi.org/10.17605/OSF.IO/7MGEV</ext-link>.</p></sec><sec sec-type="ethics-statement" id="sec8"><title>Ethics statement</title><p>The studies involving humans were approved by the University of South Carolina Institutional Review Board. The studies were conducted in accordance with the local legislation and institutional requirements. The ethics committee/institutional review board waived the requirement of written informed consent for participation from the participants or the participants&#x02019; legal guardians/next of kin because it was an exempt approved study with no risk of harm to subjects.</p></sec><sec sec-type="author-contributions" id="sec9"><title>Author contributions</title><p>DP: Conceptualization, Formal analysis, Investigation, Methodology, Visualization, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. AA: Conceptualization, Formal analysis, Methodology, Supervision, Writing &#x02013; review &#x00026; editing.</p></sec><sec sec-type="COI-statement" id="sec11"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type="disclaimer" id="sec12"><title>Publisher&#x02019;s note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><ref-list><title>References</title><ref id="ref1"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Agresti</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <source>Categorical data analysis</source>. <publisher-loc>Hoboken, New Jersey</publisher-loc>: <publisher-name>John Wiley &#x00026; Sons</publisher-name>.</mixed-citation></ref><ref id="ref2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akaike</surname><given-names>H.</given-names></name></person-group> (<year>2011</year>). <article-title>Akaike&#x02019;s information criterion</article-title>. <source>Int. Encycl. Stat. Sci.</source>
<fpage>25</fpage>. doi: <pub-id pub-id-type="doi">10.1007/978-3-642-04898-2_110</pub-id></mixed-citation></ref><ref id="ref3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>R. B.</given-names></name><name><surname>Crawford</surname><given-names>J. C.</given-names></name><name><surname>Bailey</surname><given-names>M. H.</given-names></name></person-group> (<year>2022</year>). <article-title>Biasing the input: a yoked-scientist demonstration of the distorting effects of optional stopping on Bayesian inference</article-title>. <source>Behav. Res. Methods</source>. <volume>54</volume>, <fpage>1</fpage>&#x02013;<lpage>17</lpage>. doi: <pub-id pub-id-type="doi">10.3758/s13428-021-01618-1</pub-id><pub-id pub-id-type="pmid">34085234</pub-id>
</mixed-citation></ref><ref id="ref4"><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>R.</given-names></name></person-group> (<year>2022</year>). <source>Ordinal &#x02013; regression models for ordinal data</source>. <comment>R package version 2023.12&#x02013;4.1. Available online at:</comment>
<ext-link xlink:href="https://CRAN.R-project.org/package=ordinal" ext-link-type="uri">https://CRAN.R-project.org/package=ordinal</ext-link>.</mixed-citation></ref><ref id="ref5"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>D. R.</given-names></name><name><surname>Snell</surname><given-names>E. J.</given-names></name></person-group> (<year>2018</year>). <source>Analysis of binary data</source>. (<italic>2nd Ed</italic>.) <publisher-loc>Boca Raton, FL</publisher-loc>: <publisher-name>Taylor &#x00026; Francis</publisher-name>.</mixed-citation></ref><ref id="ref6"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dennett</surname><given-names>D. C.</given-names></name></person-group> (<year>1987</year>). <source>The intentional stance</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="ref7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deshpande</surname><given-names>A.</given-names></name><name><surname>Rajpurohit</surname><given-names>T.</given-names></name><name><surname>Narasimhan</surname><given-names>K.</given-names></name><name><surname>Kalyan</surname><given-names>A.</given-names></name></person-group> (<year>2023</year>). <article-title>Anthropomorphization of AI: opportunities and risks</article-title>. <source>CS ArXiv preprint.</source>
<volume>10.48550/arXiv</volume>:<fpage>2305.14784</fpage>.</mixed-citation></ref><ref id="ref8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devrim</surname><given-names>D. Y.</given-names></name></person-group> (<year>2015</year>). <article-title>Grammatical metaphor: what do we mean? What exactly are we researching?</article-title>
<source>Funct. Linguist.</source>
<volume>2</volume>:<fpage>3</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s40554-015-0016-7</pub-id></mixed-citation></ref><ref id="ref9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dowty</surname><given-names>D.</given-names></name></person-group> (<year>1991</year>). <article-title>Thematic proto-roles and argument selection</article-title>. <source>Language</source>
<volume>67</volume>, <fpage>547</fpage>&#x02013;<lpage>619</lpage>. doi: <pub-id pub-id-type="doi">10.1353/lan.1991.0021</pub-id></mixed-citation></ref><ref id="ref10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dragojevic</surname><given-names>M.</given-names></name><name><surname>Bell</surname><given-names>R. A.</given-names></name><name><surname>McGlone</surname><given-names>M. S.</given-names></name></person-group> (<year>2014</year>). <article-title>Giving radon gas life through language: effects of linguistic agency assignment in health messages about inanimate threats</article-title>. <source>J. Lang. Soc. Psychol.</source>
<volume>33</volume>, <fpage>89</fpage>&#x02013;<lpage>98</lpage>. doi: <pub-id pub-id-type="doi">10.1177/0261927X13495738</pub-id></mixed-citation></ref><ref id="ref11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epley</surname><given-names>N.</given-names></name><name><surname>Waytz</surname><given-names>A.</given-names></name><name><surname>Cacioppo</surname><given-names>J. T.</given-names></name></person-group> (<year>2007</year>). <article-title>On seeing human: a three-factor theory of anthropomorphism</article-title>. <source>Psychol. Rev.</source>
<volume>114</volume>, <fpage>864</fpage>&#x02013;<lpage>886</lpage>. doi: <pub-id pub-id-type="doi">10.1037/0033-295X.114.4.864</pub-id>, PMID: <pub-id pub-id-type="pmid">17907867</pub-id>
</mixed-citation></ref><ref id="ref12"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fausey</surname><given-names>C. M.</given-names></name><name><surname>Boroditsky</surname><given-names>L.</given-names></name></person-group> (<year>2007</year>). <article-title>Language changes causal attributions about agents and objects</article-title>. <conf-name>Proceedings of the 29th Annual Conference of the Cognitive Science Society</conf-name>. <volume>29</volume>.</mixed-citation></ref><ref id="ref13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fausey</surname><given-names>C. M.</given-names></name><name><surname>Boroditsky</surname><given-names>L.</given-names></name></person-group> (<year>2011</year>). <article-title>Subtle linguistic cues influence perceived blame and financial liability</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>17</volume>, <fpage>644</fpage>&#x02013;<lpage>650</lpage>. doi: <pub-id pub-id-type="doi">10.3758/PBR.17.5.644</pub-id>, PMID: <pub-id pub-id-type="pmid">21037161</pub-id>
</mixed-citation></ref><ref id="ref14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fausey</surname><given-names>C. M.</given-names></name><name><surname>Boroditsky</surname><given-names>L.</given-names></name></person-group> (<year>2010</year>). <article-title>Who dunnit? Cross-linguistic differences in eye-witness memory</article-title>. <source>Psychon. Bull. Rev.</source>
<volume>18</volume>, <fpage>150</fpage>&#x02013;<lpage>157</lpage>. doi: <pub-id pub-id-type="doi">10.3758/s13423-010-0021-5</pub-id>, PMID: <pub-id pub-id-type="pmid">21327361</pub-id>
</mixed-citation></ref><ref id="ref15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fausey</surname><given-names>C. M.</given-names></name><name><surname>Long</surname><given-names>B. L.</given-names></name><name><surname>Inamori</surname><given-names>A.</given-names></name><name><surname>Boroditsky</surname><given-names>L.</given-names></name></person-group> (<year>2011</year>). <article-title>Constructing agency: the role of language</article-title>. <source>Front. Psychol.</source>
<volume>1</volume>:<fpage>162</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fpsyg.2010.00162</pub-id>, PMID: <pub-id pub-id-type="pmid">21833227</pub-id>
</mixed-citation></ref><ref id="ref16"><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Garcia</surname><given-names>M.</given-names></name></person-group> (<year>2024</year>). <article-title>What air Canada lost in &#x02018;remarkable&#x02019; lying AI chatbot case</article-title>. <source>Forbes</source> Available online at: <ext-link xlink:href="https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/" ext-link-type="uri">https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/</ext-link> (Accessed March 31, 2025).</mixed-citation></ref><ref id="ref17"><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Hasan</surname><given-names>A.</given-names></name></person-group> (<year>2023</year>) <source>Why you are (probably) anthropomorphizing AI (short version)</source>. <comment>PhilArchive preprint</comment>.</mixed-citation></ref><ref id="ref18"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hilton</surname><given-names>D.</given-names></name></person-group> (<year>2007</year>). &#x0201c;<article-title>Causal explanation: from social perception to knowledge-based causal attribution</article-title>&#x0201d; in <source>Social psychology: handbook of basic principles</source>. eds. <person-group person-group-type="editor"><name><surname>Kruglanski</surname><given-names>A. W.</given-names></name><name><surname>Higgins</surname><given-names>E. T.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>The Guilford Press</publisher-name>), <fpage>232</fpage>&#x02013;<lpage>253</lpage>.</mixed-citation></ref><ref id="ref19"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hofstadter</surname><given-names>D. R.</given-names></name></person-group> (<year>1995</year>). <source>Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Basic Books</publisher-name>.</mixed-citation></ref><ref id="ref20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hortensius</surname><given-names>R.</given-names></name><name><surname>Kent</surname><given-names>M.</given-names></name><name><surname>Darda</surname><given-names>K. M.</given-names></name><name><surname>Jastrzab</surname><given-names>L.</given-names></name><name><surname>Koldewyn</surname><given-names>K.</given-names></name><name><surname>Ramsey</surname><given-names>R.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Exploring the relationship between anthropomorphism and theory-of-mind in brain and behaviour</article-title>. <source>Hum. Brain Mapp.</source>
<volume>42</volume>, <fpage>4224</fpage>&#x02013;<lpage>4241</lpage>. doi: <pub-id pub-id-type="doi">10.1002/hbm.25542</pub-id>, PMID: <pub-id pub-id-type="pmid">34196439</pub-id>
</mixed-citation></ref><ref id="ref21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopp</surname><given-names>T.</given-names></name><name><surname>Baumgartner</surname><given-names>M.</given-names></name><name><surname>Kinkel</surname><given-names>S.</given-names></name></person-group> (<year>2022</year>). <article-title>How linguistic framing affects factory workers&#x02019; initial trust in collaborative robots: the interplay between anthropomorphism and technological replacement</article-title>. <source>Int. J. Hum. Comput. Stud.</source>
<volume>158</volume>:<fpage>102730</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ijhcs.2021.102730</pub-id></mixed-citation></ref><ref id="ref22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopp</surname><given-names>T.</given-names></name><name><surname>Baumgartner</surname><given-names>M.</given-names></name><name><surname>Kinkel</surname><given-names>S.</given-names></name></person-group> (<year>2023</year>). <article-title>&#x0201c;It&#x02019;s not Paul, it&#x02019;s a robot&#x0201d;: the impact of linguistic framing and the evolution of trust and distrust in a collaborative robot during a human-robot interaction</article-title>. <source>Int. J. Hum. Comput. Stud.</source>
<volume>178</volume>:<fpage>103095</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ijhcs.2023.103095</pub-id></mixed-citation></ref><ref id="ref23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mangiafico</surname><given-names>S.</given-names></name></person-group> (<year>2017</year>). <article-title>Package &#x02018;rcompanion&#x02019;</article-title>. <source>Cran Repos</source>
<volume>20</volume>, <fpage>1</fpage>&#x02013;<lpage>71</lpage>. doi: <pub-id pub-id-type="doi">10.32614/CRAN.package.rcompanion</pub-id></mixed-citation></ref><ref id="ref24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGlone</surname><given-names>M. S.</given-names></name><name><surname>Bell</surname><given-names>R. A.</given-names></name><name><surname>Zaitchik</surname><given-names>S. T.</given-names></name><name><surname>McGlynn</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>Don&#x02019;t let the flu catch you: agency assignment in printed educational materials about the H1N1 influenza virus</article-title>. <source>J. Health Commun.</source>
<volume>18</volume>, <fpage>740</fpage>&#x02013;<lpage>756</lpage>. doi: <pub-id pub-id-type="doi">10.1080/10810730.2012.727950</pub-id>, PMID: <pub-id pub-id-type="pmid">23216010</pub-id>
</mixed-citation></ref><ref id="ref25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGlynn</surname><given-names>J.</given-names></name><name><surname>McGlone</surname><given-names>M. S.</given-names></name></person-group> (<year>2019</year>). <article-title>Desire or disease? Framing obesity to influence attributions of responsibility and policy support</article-title>. <source>Health Commun.</source>
<volume>34</volume>, <fpage>689</fpage>&#x02013;<lpage>701</lpage>. doi: <pub-id pub-id-type="doi">10.1080/10410236.2018.1431025</pub-id>, PMID: <pub-id pub-id-type="pmid">29388801</pub-id>
</mixed-citation></ref><ref id="ref26"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Minkoff</surname><given-names>S.</given-names></name></person-group> (<year>2000</year>). &#x0201c;<article-title>Animacy hierarchies and sentence processing</article-title>&#x0201d; in <source>The syntax of verb initial languages</source>. eds. <person-group person-group-type="editor"><name><surname>Carnie</surname><given-names>A.</given-names></name><name><surname>Laoghaire</surname><given-names>D.</given-names></name><name><surname>Guilfoyle</surname><given-names>E.</given-names></name></person-group> (<publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>).</mixed-citation></ref><ref id="ref27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>M.</given-names></name><name><surname>Krakauer</surname><given-names>D. C.</given-names></name></person-group> (<year>2023</year>). <article-title>The debate over understanding in AI&#x02019;s large language models</article-title>. <source>Proc. Natl. Acad. Sci.</source>
<volume>120</volume>:<fpage>e2215907120</fpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.2215907120</pub-id>, PMID: <pub-id pub-id-type="pmid">36943882</pub-id>
</mixed-citation></ref><ref id="ref28"><mixed-citation publication-type="book"><person-group person-group-type="author"><collab id="coll1">Open AI</collab></person-group>. (<year>2022</year>). <source>Introducing ChatGPT</source>. <publisher-name>Open AI</publisher-name>. Available online at: <ext-link xlink:href="https://openai.com/index/chatgpt/" ext-link-type="uri">https://openai.com/index/chatgpt/</ext-link> (Accessed March 31, 2025).</mixed-citation></ref><ref id="ref29"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pichai</surname><given-names>S.</given-names></name><name><surname>Hassabis</surname><given-names>D.</given-names></name></person-group> (<year>2023</year>). <source>Introducing Gemini: Our largest and most capable AI model</source>. <publisher-name>Google The Keyword</publisher-name>. Available online at: <ext-link xlink:href="https://blog.google/technology/ai/google-gemini-ai/#sundar-note" ext-link-type="uri">https://blog.google/technology/ai/google-gemini-ai/#sundar-note</ext-link> (Accessed March 31, 2025).</mixed-citation></ref><ref id="ref30"><mixed-citation publication-type="book"><person-group person-group-type="author"><collab id="coll2">R Core Team</collab></person-group> (<year>2023</year>). <source>R: a language and environment for statistical computing</source>. <publisher-name>R Foundation for Statistical Computing</publisher-name>, <publisher-loc>Vienna</publisher-loc>. Available online at: <ext-link xlink:href="https://www.R-project.org/" ext-link-type="uri">https://www.R-project.org/</ext-link> (Accessed April 1, 2023).</mixed-citation></ref><ref id="ref31"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schwitzgebel</surname><given-names>E.</given-names></name><name><surname>Shevlin</surname><given-names>H.</given-names></name></person-group> (<year>2023</year>). <source>Opinion: is it time to start considering personhood rights for AI chatbots?</source>
<publisher-name>Los Angeles Times</publisher-name>. Available online at: <ext-link xlink:href="https://www.latimes.com/opinion/story/2023-03-05/chatgpt-ai-feelings-consciousness-rights" ext-link-type="uri">https://www.latimes.com/opinion/story/2023-03-05/chatgpt-ai-feelings-consciousness-rights</ext-link> (Accessed March 31, 2025).</mixed-citation></ref><ref id="ref32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>Y.</given-names></name><name><surname>Luximon</surname><given-names>Y.</given-names></name></person-group> (<year>2020</year>). <article-title>Trust in AI agent: a systematic review of facial anthropomorphic trustworthiness for social robot design</article-title>. <source>Sensors</source>
<volume>20</volume>:<fpage>5087</fpage>. doi: <pub-id pub-id-type="doi">10.3390/s20185087</pub-id>, PMID: <pub-id pub-id-type="pmid">32906760</pub-id>
</mixed-citation></ref><ref id="ref33"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Spataro</surname><given-names>J.</given-names></name></person-group> (<year>2023</year>). <source>Introducing Microsoft 365 copilot &#x02013; Your copilot for work</source>. <publisher-name>Official Microsoft Blog</publisher-name>. Available online at: <ext-link xlink:href="https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/" ext-link-type="uri">https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/</ext-link> (Accessed March 31, 2025).</mixed-citation></ref><ref id="ref34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tahiroglu</surname><given-names>D.</given-names></name><name><surname>Taylor</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>Anthropomorphism, social understanding, and imaginary companions</article-title>. <source>Br. J. Dev. Psychol.</source>
<volume>37</volume>, <fpage>284</fpage>&#x02013;<lpage>299</lpage>. doi: <pub-id pub-id-type="doi">10.1111/bjdp.12272</pub-id>, PMID: <pub-id pub-id-type="pmid">30460701</pub-id>
</mixed-citation></ref><ref id="ref35"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Thellman</surname><given-names>S.</given-names></name><name><surname>Ziemke</surname><given-names>T</given-names></name></person-group>. (<year>2019</year>). <article-title>The intentional stance toward robots: conceptual and methodological considerations</article-title>. <conf-name>Proceedings of the 41st Annual Conference of the Cognitive Science Society</conf-name>. <fpage>1097</fpage>&#x02013;<lpage>1103</lpage>.</mixed-citation></ref><ref id="ref36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thibodeau</surname><given-names>P. H.</given-names></name><name><surname>Boroditsky</surname><given-names>L.</given-names></name></person-group> (<year>2011</year>). <article-title>Metaphors we think with: the role of metaphor in reasoning</article-title>. <source>PLoS One</source>
<volume>6</volume>:<fpage>e16782</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0016782</pub-id>, PMID: <pub-id pub-id-type="pmid">21373643</pub-id>
</mixed-citation></ref><ref id="ref37"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tiku</surname><given-names>N.</given-names></name></person-group> (<year>2022</year>). <source>The Google engineer who thinks the company&#x02019;s AI has come to life</source>. <publisher-name>The Washington Post</publisher-name>. Available online at: <ext-link xlink:href="https://www.washingtonpost.com/podcasts/post-reports/the-google-engineer-who-thinks-its-ai-has-come-alive/" ext-link-type="uri">https://www.washingtonpost.com/podcasts/post-reports/the-google-engineer-who-thinks-its-ai-has-come-alive/</ext-link> (Accessed March 31, 2025).</mixed-citation></ref><ref id="ref38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tonkovi&#x00107;</surname><given-names>M.</given-names></name><name><surname>Vla&#x00161;i&#x0010d;ek</surname><given-names>D.</given-names></name><name><surname>Duman&#x0010d;i&#x00107;</surname><given-names>F.</given-names></name></person-group> (<year>2022</year>). <article-title>Preregistered direct replication of the linguistic frame effect on perceived blame and financial liability</article-title>. <source>Leg. Criminol. Psychol.</source>
<volume>27</volume>, <fpage>354</fpage>&#x02013;<lpage>369</lpage>. doi: <pub-id pub-id-type="doi">10.1111/lcrp.12219</pub-id></mixed-citation></ref><ref id="ref39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waytz</surname><given-names>A.</given-names></name><name><surname>Cacioppo</surname><given-names>J.</given-names></name><name><surname>Epley</surname><given-names>N.</given-names></name></person-group> (<year>2010</year>). <article-title>Who sees human? The stability and importance of individual differences in anthropomorphism</article-title>. <source>Perspect. Psychol. Sci.</source>
<volume>5</volume>, <fpage>219</fpage>&#x02013;<lpage>232</lpage>. doi: <pub-id pub-id-type="doi">10.1177/1745691610369336</pub-id>, PMID: <pub-id pub-id-type="pmid">24839457</pub-id>
</mixed-citation></ref><ref id="ref40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weizenbaum</surname><given-names>J.</given-names></name></person-group> (<year>1966</year>). <article-title>ELIZA &#x02013; a computer program for the study of natural language communication between man and machine</article-title>. <source>Commun. ACM</source>
<volume>9</volume>, <fpage>36</fpage>&#x02013;<lpage>45</lpage>. doi: <pub-id pub-id-type="doi">10.1145/365153.365168</pub-id></mixed-citation></ref></ref-list></back></article>