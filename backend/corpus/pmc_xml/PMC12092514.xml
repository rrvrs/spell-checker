<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Psychon Bull Rev</journal-id><journal-id journal-id-type="iso-abbrev">Psychon Bull Rev</journal-id><journal-title-group><journal-title>Psychonomic Bulletin &#x00026; Review</journal-title></journal-title-group><issn pub-type="ppub">1069-9384</issn><issn pub-type="epub">1531-5320</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>New York</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39497006</article-id><article-id pub-id-type="pmc">PMC12092514</article-id>
<article-id pub-id-type="publisher-id">2605</article-id><article-id pub-id-type="doi">10.3758/s13423-024-02605-1</article-id><article-categories><subj-group subj-group-type="heading"><subject>Brief Report</subject></subj-group></article-categories><title-group><article-title>Visual statistical learning requires attention</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0262-3573</contrib-id><name><surname>Duncan</surname><given-names>Dock H.</given-names></name><address><email>D.H.Duncan@vu.nl</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>van Moorselaar</surname><given-names>Dirk</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Theeuwes</surname><given-names>Jan</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/008xxew50</institution-id><institution-id institution-id-type="GRID">grid.12380.38</institution-id><institution-id institution-id-type="ISNI">0000 0004 1754 9227</institution-id><institution>Department of Experimental and Applied Psychology, </institution><institution>Vrije Universiteit Amsterdam, </institution></institution-wrap>Amsterdam, the Netherlands </aff><aff id="Aff2"><label>2</label>Institute Brain and Behavior Amsterdam (iBBA), Amsterdam, the Netherlands </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/019yg0716</institution-id><institution-id institution-id-type="GRID">grid.410954.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 2237 5901</institution-id><institution>William James Center for Research, ISPA-Instituto Universitario, </institution></institution-wrap>Lisbon, Portugal </aff></contrib-group><pub-date pub-type="epub"><day>4</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>4</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2025</year></pub-date><volume>32</volume><issue>3</issue><fpage>1240</fpage><lpage>1253</lpage><history><date date-type="accepted"><day>19</day><month>10</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Statistical learning is a person&#x02019;s ability to automatically learn environmental regularities through passive exposure. Since the earliest studies of statistical learning in infants, it has been debated exactly how &#x0201c;passive&#x0201d; this learning can be (i.e., whether attention is needed for learning to occur). In Experiment <xref rid="Sec2" ref-type="sec">1</xref> of the current study, participants performed a serial feature search task where they searched for a target shape among heterogenous nontarget shapes. Unbeknownst to the participants, one of these nontarget shapes was presented much more often in location. Even though the regularity concerned a nonsalient, nontarget item that did not receive any attentional priority during search, participants still learned its regularity (responding faster when it was presented at this high-probability location). While this may suggest that not much, if any, attention is needed for learning to occur, follow-up experiments showed that if an attentional strategy (i.e., color subset search or exogenous cueing) effectively prevents attention from being directed to this critical regularity, incidental learning is no longer observed. We conclude that some degree of attention to a regularity is needed for visual statistical learning to occur.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Statistical learning</kwd><kwd>Attention</kwd><kwd>Visual search</kwd><kwd>Distractor suppression</kwd><kwd>Feature guided search</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>H2020 European Research Council</institution></institution-wrap></funding-source><award-id>833029 &#x02013; [LEARNATTEND]</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>406.21.GO.034</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Psychonomic Society, Inc. 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Our past experiences guide future behavior. In the case of attention, previous selection experiences allow the extraction and learning of regularities present in a display; a process often referred to as visual statistical learning (VSL). Statistical learning is thought to be a fundamental cognitive mechanism underlying human procedural learning (Frost et al., <xref ref-type="bibr" rid="CR34">2019</xref>; Turk-Browne, <xref ref-type="bibr" rid="CR89">2012</xref>); and in the case of attention, VSL enables observers to extract the distributional properties from sensory input across space and time, making it possible to adapt attentional selection priorities to the regularities present in the environment (Frost et al., <xref ref-type="bibr" rid="CR33">2015</xref>; Theeuwes et al., <xref ref-type="bibr" rid="CR84">2022</xref>). VSL can be labelled as a &#x0201c;selection history&#x0201d; effect, which makes up the modern conceptualization of the attention system along with the observer&#x02019;s top-down goals and the current scene&#x02019;s bottom-up saliency characteristics (Anderson et al., <xref ref-type="bibr" rid="CR2">2021</xref>; Awh et al., <xref ref-type="bibr" rid="CR4">2012</xref>; Failing &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR25">2018</xref>; Theeuwes, <xref ref-type="bibr" rid="CR80">2018</xref>, <xref ref-type="bibr" rid="CR81">2019</xref>).</p><p id="Par3">Paradigms such as contextual cuing (whereby search for a target is more efficient when displays have been previously searched; Chun, <xref ref-type="bibr" rid="CR11">2000</xref>; Chun &#x00026; Jiang, <xref ref-type="bibr" rid="CR12">1998</xref>, <xref ref-type="bibr" rid="CR13">2003</xref>; Goujon et al., <xref ref-type="bibr" rid="CR39">2015</xref>), probability cuing (where search is much faster when targets appear more often in high-probability locations in space; Duncan, Theeuwes, et al., <xref ref-type="bibr" rid="CR22">2023a</xref>; Ferrante et al., <xref ref-type="bibr" rid="CR30">2018</xref>; Geng &#x00026; Behrmann, <xref ref-type="bibr" rid="CR36">2005</xref>; Huang et al., <xref ref-type="bibr" rid="CR43">2022</xref>; Jiang et al., <xref ref-type="bibr" rid="CR48">2013</xref>), and object-based learning (Jeong &#x00026; Cho, <xref ref-type="bibr" rid="CR45">2024</xref>; van Moorselaar &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR94">2023</xref>, <xref ref-type="bibr" rid="CR95">2024</xref>) have demonstrated how the visual system leverages its experience to encode environmental regularities and improve visual search. These paradigms demonstrate that participants implicitly encode the statistical properties of their search target, and provide the basis for the once common stance that VSL only occurs for task relevant items (Turk-Browne, <xref ref-type="bibr" rid="CR89">2012</xref>; Turk-Browne et al., <xref ref-type="bibr" rid="CR90">2005</xref>; Vadillo et al., <xref ref-type="bibr" rid="CR91">2020</xref>).</p><p id="Par4">However, recent results have demonstrated that learning can also occur for task-irrelevant distractors that capture attention in an exogenous (bottom-up) way (Failing, Wang, et al., <xref ref-type="bibr" rid="CR27">2019b</xref>; Gao &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR35">2020</xref>; Goschy et al., <xref ref-type="bibr" rid="CR38">2014</xref>; van Moorselaar &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR93">2022</xref>; Wang &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR100">2018a</xref>). This learning is expressed via learned suppression of this distracting input and runs counter to previous claims that learning can only occur for stimuli that are task relevant, demonstrating instead that VSL is more ubiquitous than previously thought (see Theeuwes et al., <xref ref-type="bibr" rid="CR84">2022</xref>, for a review). Furthermore, VSL has also been shown to persist (though hindered in some cases) despite high working memory load (Gao &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR35">2020</xref>; Gim&#x000e9;nez-Fern&#x000e1;ndez et al., <xref ref-type="bibr" rid="CR37">2023</xref>; Manginelli et al., <xref ref-type="bibr" rid="CR60">2013</xref>; Vickery et al., <xref ref-type="bibr" rid="CR98">2010</xref>; Won &#x00026; Jiang, <xref ref-type="bibr" rid="CR107">2015</xref>; but see Amsalem et al., <xref ref-type="bibr" rid="CR1">2023</xref>), a process known to interfere with attentional processing (Awh &#x00026; Jonides, <xref ref-type="bibr" rid="CR5">2001</xref>; Cowan et al., <xref ref-type="bibr" rid="CR17">2005</xref>; Theeuwes et al., <xref ref-type="bibr" rid="CR83">2009</xref>). Such results lay the foundation upon which some claim that VSL is an entirely attention-independent mechanism (Hansmann-Roth et al., <xref ref-type="bibr" rid="CR40">2021</xref>; Jiang &#x00026; Leung, <xref ref-type="bibr" rid="CR47">2005</xref>).</p><p id="Par5">When discussing the role of attention in VSL, one should consider that attention control has traditionally been characterized as resulting from the dynamic interplay between the physical properties of the object (bottom-up attention) and the goals of the observer (top-down attention). Importantly, if a solitary item is presented on a uniform background then bottom-up attention, the visual systems attraction to salient events, will automatically be directed towards this item. Consequently, shape or sequence learning experiments where single items are successively presented on the screen are inherently ill-suited to investigate whether learning requires attention. Instead, to rule out a role of bottom-up attention, the experimental design needs to incorporate multi-item arrays such that the object that contains the regularity no longer pops out in the scene. By contrast, goal-directed top-down attention describes how the attentional system selects task-relevant features and orients attention towards potential targets. While it has been convincingly demonstrated that VSL does not require top-down attention to occur (Duncan &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR21">2020</xref>; Turatto et al., <xref ref-type="bibr" rid="CR88">2018</xref>), these experiments did not set out to also control the influence of bottom-up attention, leaving open the possibility that observed learning was driven by exogenous capture and precluding the conclusion that VSL can occur in the total absence of attention. Furthermore, several studies have shown that VSL effects scale with the degree of top-down attention directed to the regularities (Duncan &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR21">2020</xref>; Jiang &#x00026; Chun, <xref ref-type="bibr" rid="CR46">2001</xref>; Musz et al., <xref ref-type="bibr" rid="CR63">2015</xref>), necessitating experimental designs that are sensitive to small effect sizes if these effects are to be studied adequately (Brysbaert, <xref ref-type="bibr" rid="CR9">2019</xref>).</p><p id="Par6">To investigate the influence of attention on VSL, special care must be taken to design an experiment that controls both the top-down and bottom-up attention attraction to an embedded regularity in a task. To achieve this, we used a visual search task (Fig. <xref rid="Fig1" ref-type="fig">1</xref>) in which observers had to search for a specific target shape (e.g., a square) among heterogeneous nontarget shapes (e.g., diamonds, hexagons), a task design that mitigates the influence of bottom-up attention by making all search items equally salient (Egeth et al., <xref ref-type="bibr" rid="CR24">1984</xref>; Leber &#x00026; Egeth, <xref ref-type="bibr" rid="CR55">2006</xref>). Crucially, rather than having a regularity related to the search target or a singleton distractor, as has previously been done in visual search studies (Jiang et al., <xref ref-type="bibr" rid="CR48">2013</xref>; Wang &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR100">2018a</xref>), one of the nontarget, nonsalient shapes appeared instead more often in one location during training. This shape should have received very little, if any, attentional priority, making it a prime candidate to study the role of attention and statistical learning. Following an initial training phase, in which this spatial regularity was present, during a subsequent testing phase, all shapes appeared in each location with equal likelihood and participants now had to search for the shape that previously had a high-probability location. It has been demonstrated previously that VSL effects persist for a period before extinction (Duncan &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR21">2020</xref>; Jiang et al., <xref ref-type="bibr" rid="CR48">2013</xref>; Sauter et al., <xref ref-type="bibr" rid="CR72">2019</xref>), meaning that if learning had occurred in the training phase, an effect of shape location should also be observed in this testing phase when the target shape appeared at its previously high-probability location. This design allowed us to examine whether observers can learn regularities regarding nonsalient nontarget shapes or alternatively, as suggested by some (Anderson et al., <xref ref-type="bibr" rid="CR2">2021</xref>; Theeuwes et al., <xref ref-type="bibr" rid="CR84">2022</xref>), that such learning is restricted to singletons that are salient enough to summon attention on every trial.<fig id="Fig1"><label>Fig. 1</label><caption><p>Example training and test displays with high-probability location indicated. (Left) Example training and test target shape identities are examples only; target identities assigned randomly at the beginning of the experiment for each participant. Participants&#x02019; task were to find this shape target on every trial and report whether the grey line within this shape was oriented horizontally or vertically. After three blocks (training), participants&#x02019; search target was changed to a different shape and were given the exact same task for an additional two blocks (testing). The shape that would be the search target during the testing display was presented more frequently at one location during training (its high-probability location) but equally frequently at all locations during testing. Note also that colored circles were not present in the actual experiment; participants only saw green shapes on a black background. (Right) Visualization of the spatial distribution of training and testing targets during the training phase of the experiment. Note that while the training target appeared at each of the six locations the same number of times, the testing target had an imbalanced spatial distribution. During the test phase, the test target appeared with equal likelihood at each of the six possible locations, thus mirroring the spatial distribution of the training target during the training phase. (Color figure online)</p></caption><graphic xlink:href="13423_2024_2605_Fig1_HTML" id="MO1"/></fig></p><p id="Par7">To foreshadow the results, in Experiment <xref rid="Sec2" ref-type="sec">1</xref> it was found that observers can also learn regularities regarding nonsalient, nontarget shapes, providing another striking example of the visual system&#x02019;s sensitivity to regularities within the environment. Yet while the experimental design precluded a role of bottom-up attention, it is premature to conclude that VSL can occur in the absence of attention based on these findings as alternative explanations, such as serial search transiently directing attention towards this regularity, or nonzero attentional allocation towards this regularity due to shared color features, prohibits this conclusion. In a pair of follow-up experiments using color subset search (Experiment <xref rid="Sec8" ref-type="sec">2</xref>) and exogenous cueing (Experiment <xref rid="Sec14" ref-type="sec">3</xref>), we show that when attentional strategies successfully prevent attention from being directed towards shape regularity during training, incidental learning ceases to occur. This highlights the essential role that attention plays in statistical learning.</p></sec><sec id="Sec2"><title>Experiment 1</title><sec id="Sec3"><title>Method</title><sec id="Sec4"><title>Participants</title><p id="Par8">Following an extensive pilot experiment, main effects of nontarget shape location were expected to be roughly <italic>d</italic> = 0.29 in training and testing phases. Given this target, we chose a sample size of 120 participants for this experiment, which represented an 85% confidence for detecting effects as low as <italic>d</italic> = 0.29 (preregistrations &#x00026; pilot study: <ext-link ext-link-type="uri" xlink:href="https://osf.io/q3ubp">https://osf.io/q3ubp</ext-link>).</p><p id="Par9">One hundred and twenty-one anonymous, na&#x000ef;ve participants (45 women, median age = 30 years, an additional participant was recruited due to an error in counterbalancing; additional demographic information for this and later experiments is available in the OSF repository at <ext-link ext-link-type="uri" xlink:href="https://osf.io/5vbzp/">https://osf.io/5vbzp/</ext-link>) were recruited through the website Prolific (<ext-link ext-link-type="uri" xlink:href="http://www.prolific.co">www.prolific.co</ext-link>). To pass prescreening for this experiment, participants should have completed at least ten experiments previously and had a total approval rate of no less than 99%. Participants additionally could not have participated in any of the labs previous experiments using similar paradigms. The experiment was approved by the Ethical Review Committee of the Faculty of Behavioral and Movement Sciences of Vrije Universiteit Amsterdam, and all participants indicated their informed consent prior to the experiment. The experiment lasted approximately 35 min, and participants were compensated with &#x000a3;4.50. Participant data were excluded and replaced if their accuracy or average reaction time was 2.5 standard deviations (<italic>SD</italic>s) away from the group average accuracy. The data from two participants were replaced in this way due to low accuracies and two for slow reaction times. Trials with reaction times more than two standard deviations from each participant&#x02019;s mean reaction time were additionally removed (&#x0003c;1% of all trials). Incorrect trials were also excluded from the final analysis (8% of all trials).</p></sec><sec id="Sec5"><title>Design and procedure</title><p id="Par10">All experimental code and stimuli are available online at (<ext-link ext-link-type="uri" xlink:href="https://osf.io/5vbzp/">https://osf.io/5vbzp/</ext-link>). Participants accessed the experiment using their personal computers via the experiment hosting website JATOS (Lange et al., <xref ref-type="bibr" rid="CR53">2015</xref>) after recruitment on Prolific. The experiment was created using OpenSesame (Math&#x000f4;t et al., <xref ref-type="bibr" rid="CR61">2012</xref>) with JavaScript. The experiment, which started with 24 practice trials, comprised five blocks: three for training and two for testing.</p><p id="Par11">Our experiment design used a feature search task where participants searched for a set target among heterogeneous distractors (Bacon &#x00026; Egeth, <xref ref-type="bibr" rid="CR6">1994</xref>; Stilwell &#x00026; Gaspelin, <xref ref-type="bibr" rid="CR76">2021</xref>; Theeuwes, <xref ref-type="bibr" rid="CR79">2004</xref>). Each trial started with a jittered fixation dot (500&#x02013;750 ms), followed by the appearance of a ring of six unique green shapes (square, diamond, rhombus, trapezoid, pentagon, hexagon), each with a grey line either tilted horizontally or vertically embedded within (three horizontals and three verticals on each trial). Participants were randomly assigned a target shape at the beginning of the experiment and had to report the orientation of the embedded line within this shape using the left and up arrow keys on their keyboard. Search arrays remained on-screen for 2,000 ms or until participants provided a response. Participants received feedback via the fixation dot (blinking green for correct or red for incorrect). Critically, unbeknownst to the participants, during practice and training, one of the five nontarget shapes appeared disproportionately often in one location (50% of trials, location counterbalanced across participants). The target appeared equally across all locations.</p><p id="Par12">After three training blocks, participants received a new search target for the remaining two testing blocks. This target shape was always the shape that previously had a spatial regularity in the training phase. In the test phase, all shapes appeared with equal probability across all locations. Participants were informed before training that they would be given a new search target at some point in the experiment but were not told the shape this second target would be. Following testing, to assess awareness, participants were asked whether they noticed a regularity among the nontarget shapes and to identify its high-probability location. If a participant both indicated that they noticed a regularity and were able to correctly identify the shapes high-probability location, the participant was labelled as being aware.</p></sec></sec><sec id="Sec6"><title>Results</title><p id="Par13">We first investigated whether participants were significantly faster when the regular shape was at its high-probability location during training. Such a finding has been reported for salient, pop-out distractor singletons regardless of whether participants search for unique elements (the so-called singleton detection mode) or search for a specific target (feature search mode; Wang &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR101">2018b</xref>). In the training phase, if the same suppression effect was at play, then we would expect to see faster reaction times when the regular distractor appeared at its high-probability location, and slower reaction times when the target did. Yet, for the testing phase, experimental predictions are less clear. If participants are able to learn the nonsalient distractor&#x02019;s regularity in training, when this distractor switched to being the target, this may either lead impaired performance at the previous high-probability location (because this location is still suppressed) or enhancement (because participants generally expect the shape to be there, with no regard to its role as a target or distractor).</p><p id="Par14">Even though in the current experiment the critical distractor was not salient, there was still a reliable speedup effect when the nontarget shape was present at its high-probability location relative to its low-probability location, <italic>t</italic>(120) = 3.15, <italic>p</italic> = .002, <italic>d</italic> = 0.287 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A). When the target shape was presented at this high-probability location, there was a trend toward slower responses, but it was not statistically significant, <italic>t</italic>(120) = 1.89, <italic>p</italic> = .062 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). Having established sensitivity to the nontarget shape's regularity during training, we examined if this learning affected selection during the test phase when participants had to find the shape that previously possessed a spatial regularity. A significant slowdown occurred when the new target shape was at its previously high-probability location, <italic>t</italic>(120) = 2.72, <italic>p</italic> = .008, <italic>d</italic> = 0.247 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>C).<xref ref-type="fn" rid="Fn1">1</xref><fig id="Fig2"><label>Fig. 2</label><caption><p>Stimuli and results of Experiment <xref rid="Sec2" ref-type="sec">1</xref>. <bold>A</bold>. Left: Reaction times when a nonsalient nontarget shape appeared at its high-probability location (hp) versus another low-probability location (lp). Error bars are adjusted for within-subject comparisons (Cousineau et al., <xref ref-type="bibr" rid="CR16">2021</xref>). Right: Individual participant speedup scores, calculated by subtracting each participant&#x02019;s average reaction time on HP trials from their mean reaction time on LP trials. Dots indicate individual participant&#x02019;s scores. Colors indicate different high-probability locations (hp_loc; legend on bottom left. 0 indicates top screen location, numbers count clockwise from there). Notches in boxplot indicate 95% confidence interval of mean. <bold>B.</bold> Participant means and speedup effect when targets are presented at the high-probability distractor location. Note that targets appeared at each of the six locations equally frequently. <bold>C.</bold> Reaction times and speedup effect when targets present at their previously high-probability location during the testing phase of the experiment. Note that target presentation rates were equalized in the testing phase of the experiment; any effect observed must be a carryover from the training phase of the experiment. **<italic>p</italic> &#x0003c; .01. (Color figure online)</p></caption><graphic xlink:href="13423_2024_2605_Fig2_HTML" id="MO2"/></fig></p><p id="Par15">Among 49 participants who reported noticing the nontarget shape&#x02019;s regularity, only 10 correctly identified the high-probability location (chance level = 8). Including awareness as an additional factor did not yield significant interactions in the analyses of variance (all <italic>F</italic> values &#x0003c; 1), and results remained consistent when excluding these participants.</p></sec><sec id="Sec7"><title>Discussion</title><p id="Par16">Despite the nontarget shapes being nonsalient and task irrelevant, participants nevertheless were sensitive to the embedded regularity.<xref ref-type="fn" rid="Fn2">2</xref> During training, they were faster when the regular nontarget shape was at its high-probability location. In addition, in the testing phase when this nontarget shape became the target, they were consistently slower when it appeared at its old high-probability location. This suggests that participants learned to avoid this location during training when it had the nontarget shape, and this bias persisted during testing, resulting in exaggerated negative shape priming at that location (DeSchepper &#x00026; Treisman, <xref ref-type="bibr" rid="CR18">1996</xref>).</p><p id="Par17">It has been proposed that VSL typically involves weight changes in the priority map, leading to proactive suppression or enhancement of certain locations based on their likelihood of containing a distractor or target (Duncan, van Moorselaar et al., <xref ref-type="bibr" rid="CR23">2023b</xref>; Ferrante et al., <xref ref-type="bibr" rid="CR30">2018</xref>; Huang et al., <xref ref-type="bibr" rid="CR42">2021</xref>, <xref ref-type="bibr" rid="CR43">2022</xref>). Per this explanation, it is possible that participants learned that a particular location was associated with a certain irrelevant shape and avoided orienting attention to this location. However, inconsistent with this explanation, during training, target processing at the high-probability distractor location was not reliably impaired (although a numerical trend in this direction should be noted). An alternative possibility is that rather than proactively suppressing this location, participants instead may have more quickly disengaged from stimuli in this location (Di Caro et al., <xref ref-type="bibr" rid="CR19">2019</xref>; Sauter et al., <xref ref-type="bibr" rid="CR73">2021</xref>; Wang et al., <xref ref-type="bibr" rid="CR103">2019</xref>). This disengagement would then appear closely linked to feature identity, where participants were better able to disengage from a certain distractor identity at a certain location in space.</p><p id="Par18">While the results of Experiment <xref rid="Sec2" ref-type="sec">1</xref> seem to offer a striking example of VSL without attention, several task features make it tenuous to claim that attention was never directed towards the nontarget shape with a regularity. Firstly, the search target and regular distractor shared the fundamental feature of color, meaning that the nontarget distractor may have still attracted some nonzero level of attentional processing (Forschack et al., <xref ref-type="bibr" rid="CR31">2017</xref>; Saenz et al., <xref ref-type="bibr" rid="CR68">2002</xref>; St&#x000f6;rmer &#x00026; Alvarez, <xref ref-type="bibr" rid="CR78">2014</xref>; Treue &#x00026; Trujillo, <xref ref-type="bibr" rid="CR87">1999</xref>). Secondly, in feature search tasks, it is debated whether participants use parallel or serial search for target shapes in displays inducing the feature search mode (Leber &#x00026; Egeth, <xref ref-type="bibr" rid="CR55">2006</xref>; Liesefeld et al., <xref ref-type="bibr" rid="CR58">2016</xref>; Liesefeld &#x00026; M&#x000fc;ller, <xref ref-type="bibr" rid="CR57">2019</xref>; Theeuwes, <xref ref-type="bibr" rid="CR79">2004</xref>, <xref ref-type="bibr" rid="CR82">2023</xref>; Wang &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR102">2020</xref>). If serial search is used, then participants would randomly scan across items in the scene until the target is found (Jonides &#x00026; Yantis, <xref ref-type="bibr" rid="CR50">1988</xref>; Wolfe, <xref ref-type="bibr" rid="CR105">1994</xref>, <xref ref-type="bibr" rid="CR106">2021</xref>), a strategy that would lead to transient orienting of focused (top-down) attention towards the shapes with a spatial regularity. This incidental attentional orienting might then be sufficient for statistical learning to occur. Experiment <xref rid="Sec8" ref-type="sec">2</xref> was designed to test this alternative hypothesis; during training, half of the shapes were colored red and the other half green. Previous research has shown that during serial search, participants can direct attention selectively to one target-matching color (Egeth et al., <xref ref-type="bibr" rid="CR24">1984</xref>; Kaptein et al., <xref ref-type="bibr" rid="CR51">1995</xref>; Lien et al., <xref ref-type="bibr" rid="CR56">2021</xref>; Nakayama &#x00026; Silverman, <xref ref-type="bibr" rid="CR64">1986</xref>) ignoring colors of a nonmatching set. Critically, we made sure that the shape containing the regularity and the search target never had the same color, ensuring that selective attention would never be directed towards the subset of elements that contained the regularity during training (for a similar approach, see Jiang &#x00026; Leung, <xref ref-type="bibr" rid="CR47">2005</xref>; Vadillo et al., <xref ref-type="bibr" rid="CR91">2020</xref>). This design allowed us to investigate whether the learning observed in Experiment <xref rid="Sec2" ref-type="sec">1</xref> can be attributed to the occasional direction of attention towards the regularity due to the use of a serial search strategy.</p></sec></sec><sec id="Sec8"><title>Experiment 2</title><sec id="Sec9"><title>Method</title><sec id="Sec10"><title>Participants</title><p id="Par19">Experiment <xref rid="Sec8" ref-type="sec">2</xref> was preregistered following reasonable expectations derived from Experiment <xref rid="Sec2" ref-type="sec">1</xref> (<ext-link ext-link-type="uri" xlink:href="https://osf.io/xg6cn">https://osf.io/xg6cn</ext-link>). A total of 121 new anonymous, na&#x000ef;ve participants (median age = 32, 31 women) were again recruited through Prolific using the same screening criteria and run using the same online test hosting platform JATOS. Four participants were excluded and replaced in this experiment for low accuracies, and three for slow average reaction times using the same criteria as in Experiment <xref rid="Sec2" ref-type="sec">1</xref> (2.5 <italic>SD</italic>s from group mean).</p></sec><sec id="Sec11"><title>Design and procedure</title><p id="Par20">Experiment <xref rid="Sec8" ref-type="sec">2</xref> matched the procedure of Experiment <xref rid="Sec2" ref-type="sec">1</xref>, except for one key difference: At the beginning of the experiment, three shapes were randomly chosen to be presented in the color red, and three to be presented in the color green (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A). These shapes remained the same color for the entire experiment. Similar to Experiment <xref rid="Sec2" ref-type="sec">1</xref>, the target during training was selected at random; however, it was additionally controlled such that the nontarget shape with a spatial regularity was a different color (e.g., if the target was red, the shape with a spatial regularity would be green). This meant that participants switched from searching from a target of one color to another color when moving from the training phase to the testing phase, where the shape with a regularity became the new search target. Each location was further controlled such that they contained a green shape on 50% of the trials and a red shape on 50% of the trials.<fig id="Fig3"><label>Fig. 3</label><caption><p>Stimuli and results of Experiment <xref rid="Sec8" ref-type="sec">2</xref>. <bold>A</bold>. Example of the two-color feature search task. The task in Experiment <xref rid="Sec8" ref-type="sec">2</xref> was identical to Experiment <xref rid="Sec2" ref-type="sec">1</xref>, except that two shape colors were used and the search target in the training and testing phases always had a different color feature. <bold>B</bold>. Left: Mean reaction times when the nonsalient nontarget shape was at its high-probability location. Error bars are adjusted for within-subject comparisons (Cousineau et al., <xref ref-type="bibr" rid="CR16">2021</xref>). Right: Individual participant speedup scores, calculated by subtracting each participant&#x02019;s average reaction time on HP trials from their mean reaction time on LP trials. Dots indicate individual participant scores; colors indicate different high-probability locations (legend on bottom right). Notches in boxplot indicate 95% confidence interval of mean. <bold>C.</bold> Participant means and speedup effect when targets are presented at the high-probability distractor location. <bold>D.</bold> Reaction times and speedup effect when targets present at their previously high-probability location during the testing phase of the experiment. (Color figure online)</p></caption><graphic xlink:href="13423_2024_2605_Fig3_HTML" id="MO3"/></fig></p></sec></sec><sec id="Sec12"><title>Results</title><p id="Par21">As in Experiment <xref rid="Sec2" ref-type="sec">1</xref>, incorrect trials were excluded (5% of total trials), and trials which were more than two standard deviations faster or slower than the individual participants mean reaction time were also excluded (&#x0003c;1% total trials). Counter to Experiment <xref rid="Sec2" ref-type="sec">1</xref>, there now was no evidence that participants were significantly faster when the nontarget shape appeared in its high-probability locations in this version of the experiment (<italic>t</italic> &#x0003c; 1; Fig. <xref rid="Fig3" ref-type="fig">3</xref>B) nor when targets appeared at this high-probability distractor location (<italic>t</italic> &#x0003c; 1; Fig. <xref rid="Fig3" ref-type="fig">3</xref>C). In line with these null findings, in the testing phase there was no evidence that participants were significantly slower when the new search target appeared at its previous high-probability location (<italic>t</italic> &#x0003c; 1; Fig. <xref rid="Fig3" ref-type="fig">3</xref>D).</p><p id="Par22">To solidify our null findings, an additional Bayesian analysis was run for our three conditions of interest testing for evidence for a null distribution (BF<sub>10</sub>) using the default settings of the statistical analysis program JASP (Wagenmakers et al., <xref ref-type="bibr" rid="CR99">2018</xref>). Strong evidence for the null was found in all three of our conditions of interest (BF<sub>01</sub> = 9.897; BF<sub>01</sub> = 9.868, &#x00026; BF<sub>01</sub> = 9.643, respectively; analysis file can be viewed at <ext-link ext-link-type="uri" xlink:href="https://osf.io/5vbzp/">https://osf.io/5vbzp/</ext-link>) providing significant evidence that reaction times did not vary based on the position of the regular shape during training or after it became the search target in the testing phase.</p><p id="Par23">While a similar number of participants answered yes when asked if they noticed a regularity to one of the shape stimuli (39), only three participants were able to select the correct high-probability location. Again, their data did not significantly influence any of the previous analyses (all <italic>F</italic> values &#x0003c; 1).</p></sec><sec id="Sec13"><title>Discussion</title><p id="Par24">While the results of Experiment <xref rid="Sec2" ref-type="sec">1</xref> seemed to indicate that statistical learning during visual search is also observed when the item with a spatial regularity never captured attention in either a top-down or bottom-up way, in Experiment <xref rid="Sec8" ref-type="sec">2</xref>, where the nontarget shape was rendered in a task-irrelevant color, no signs of learning were observed. Together these findings demonstrate that while statistical learning of nonsalient shapes can occur when they are incidentally attended (because they share a task-relevant feature), such learning is absent when attention is allocated elsewhere. Thus, some degree of attention to the critical regularity is needed for VSL to occur.</p><p id="Par25">A classic indicator of serial search is a monotonic increase in search times as the number of items in a search display increases (Theeuwes, <xref ref-type="bibr" rid="CR79">2004</xref>; Treisman &#x00026; Sato, <xref ref-type="bibr" rid="CR86">1990</xref>; Wolfe, <xref ref-type="bibr" rid="CR105">1994</xref>). Consistent with this claim, the mean RT in Experiment <xref rid="Sec8" ref-type="sec">2</xref> (~950 ms), where search could be limited to on average two items (between 1 and 3 items) was markedly reduced relative to Experiment <xref rid="Sec2" ref-type="sec">1</xref> (~1,140 ms), where search had to discriminate on average 3.5 items (between 1 and 6 items). This monotonic decrease indicates that a serial search strategy was used to perform the task; a condition in which ignoring off-color distractors is highly efficient (Egeth et al., <xref ref-type="bibr" rid="CR24">1984</xref>; Kaptein et al., <xref ref-type="bibr" rid="CR51">1995</xref>; Theeuwes, <xref ref-type="bibr" rid="CR82">2023</xref>). Furthermore, VSL effects having been demonstrated in the past for searches as low as two items (van Moorselaar et al., <xref ref-type="bibr" rid="CR96">2020</xref>; van Moorselaar &#x00026; Slagter, <xref ref-type="bibr" rid="CR92">2019</xref>), meaning there is no a priori reason that participants should not have been able to learn spatial regularities in a three-item experiment rather than a six-item experiment. Together with previous findings, it becomes clear that VSL can occur if regularities receive either top-down or bottom-up attention (or both), but crucially here it is shown that when stimuli receive neither, learning is not found.</p><p id="Par26">While the current results show that statistical regularities regarding specific items are not learned when these items are filtered out by using attentional strategies, color subset selective search that we used here is just one method out of excluding a specific set of items. To expand on these results, in Experiment <xref rid="Sec14" ref-type="sec">3</xref> we used exogenous cueing to direct attention away from the items that contained the regularity.</p></sec></sec><sec id="Sec14"><title>Experiment 3</title><sec id="Sec15"><title>Method</title><sec id="Sec16"><title>Participants</title><p id="Par27">The preregistration for Experiment <xref rid="Sec14" ref-type="sec">3</xref> can be viewed online (<ext-link ext-link-type="uri" xlink:href="https://osf.io/kyd94">https://osf.io/kyd94</ext-link>). Unlike Experiments <xref rid="Sec2" ref-type="sec">1</xref> and <xref rid="Sec8" ref-type="sec">2</xref>, Experiment <xref rid="Sec14" ref-type="sec">3</xref> utilized a Bayesian stopping rule (Rouder, <xref ref-type="bibr" rid="CR67">2014</xref>) whereby results were monitored during data acquisition, and once a certain level of evidence (as measured by Bayes factors) was recorded, data collection was stopped. As per the preregistration, data collection continued until a Bayes factor (B<sub>01</sub>) of 6 was recorded for our critical analysis of interest (reaction times between HP and LP target trials in the testing phase). Using this rule, 85 participants&#x02019; data were collected (median age = 28, 41 women) using the same methods and prescreening criteria as in Experiments <xref rid="Sec2" ref-type="sec">1</xref> and <xref rid="Sec8" ref-type="sec">2</xref>. In this dataset, four participants were excluded for low accuracies and two for slow reaction times using the same criteria as in Experiment <xref rid="Sec2" ref-type="sec">1</xref> (2.5 <italic>SD</italic>s from group mean).</p></sec><sec id="Sec17"><title>Design and procedure</title><p id="Par28">Experiment <xref rid="Sec14" ref-type="sec">3</xref> exactly mirrored the design of Experiment <xref rid="Sec2" ref-type="sec">1</xref> except for two new features. First, during training, immediately before trial onset, an exogenous cue could appear indicating with 100% validity where the search target was about to be displayed (Fig. <xref rid="Fig4" ref-type="fig">4</xref>A). This exogenous cue was presented on 75% of trials. Importantly, on no-cue trials, a subset of trials was selected such that the target and regular distractor appeared at each location the same number of times, implying that the regularity was only present in those trials in which the cue was presented. The cue was only shown during the training phase of the experiment, meaning all trials in the testing phase were no-cue trials. Additionally, on each trial, shapes were rendered in a random color, indicating that unlike in Experiments <xref rid="Sec2" ref-type="sec">1</xref> and <xref rid="Sec8" ref-type="sec">2</xref>, the search template was color neutral (for a similar design, see Kim et al., <xref ref-type="bibr" rid="CR52">2023</xref>, Experiment <xref rid="Sec2" ref-type="sec">1</xref>).<fig id="Fig4"><label>Fig. 4</label><caption><p>Stimuli and results of Experiment <xref rid="Sec14" ref-type="sec">3</xref>. <bold>A.</bold> Example of the experimental procedure including the pretrial cue. The task in Experiment <xref rid="Sec14" ref-type="sec">3</xref> was identical to Experiment <xref rid="Sec2" ref-type="sec">1</xref>, except that during the training phase, immediately before search array onset, an exogenous cue would be presented for 150 ms. This cue was present on 75% of trials and had 100% validity. Importantly, on the 25% of the trials in which no cue was presented, trials were selected such that the target and distractors were equally present at all locations. In this way, on trials in which participants were compelled to carry out serial search, there was no spatial regularity to be learned. Search displays remained on screen until a response was provided or 2,000 ms expired. <bold>B.</bold> Mean reaction times during training when the nonsalient nontarget shape was at its high-probability (orange) or a low-probability (blue) location, separated between trials in which the cue was present or absent. Error bars are adjusted for within-subject comparisons (Cousineau et al., <xref ref-type="bibr" rid="CR16">2021</xref>). <bold>C.</bold> Participant mean reaction time when the search target was presented at the high-probability distractor location, again separated between cue and no-cue trials. <bold>D.</bold> Left: Reaction times&#x000a0;during the testing phase&#x000a0;when&#x000a0;the target&#x000a0;happens to be presented at the location that was a&#x000a0;high-probability location during the&#x000a0;training phase. Right: Individual participant speedup scores, calculated by subtracting each participant&#x02019;s average reaction time on HP trials from their mean reaction time on LP trials. Dots indicate individual participant scores; colors indicate each participant&#x02019;s high-probability location condition (legend on bottom right; 0 indicated top of screen and progresses clockwise). (Color figure online)</p></caption><graphic xlink:href="13423_2024_2605_Fig4_HTML" id="MO4"/></fig></p></sec></sec><sec id="Sec18"><title>Results</title><p id="Par29">As in previous experiments, incorrect trials were excluded (5% of total trials) and trials which were more than two standard deviations faster or slower than the individual participants mean reaction time were also excluded (&#x0003c;1% total trials). Given an optional stopping rule was utilized, the reporting of frequentist statistics would be inappropriate (Sanborn &#x00026; Hills, <xref ref-type="bibr" rid="CR71">2014</xref>) and so only Bayesian analyses are reported here. For the training phase analysis, a Bayesian repeated-measures analysis of variance (rANOVA) taking cue present/absent and high/low probability distractor conditions as factors and reaction time as the dependent measure selected the best performing model to be one with only a main effect of cue presence. This cue-only model strongly outperformed the second-best model: one with cue and distractor location effects but no interaction (BF<sub>01</sub> = 6.7; Fig. <xref rid="Fig4" ref-type="fig">4</xref>B) indicating that participants effectively used the cue to improve their reaction times but were unable to utilize the distractor information in the same way as was previously observed in Experiment <xref rid="Sec2" ref-type="sec">1</xref>. A similar pattern was found when analyzing the target location during training, with a cue-only model outperforming a second-best cue + distractor location model (BF<sub>01</sub> = 6.3; Fig. <xref rid="Fig4" ref-type="fig">4</xref>C). The primary analysis of interest in this experiment was how reaction times would differ during the testing phase where the target appeared at its previously high-probability distractor location. As per the preregistration, a Bayesian <italic>t</italic> test strongly favored the null hypothesis (BF<sub>01</sub> = 6.05, Fig. <xref rid="Fig4" ref-type="fig">4</xref>D; for analysis file of all the above analyses, see <ext-link ext-link-type="uri" xlink:href="https://osf.io/depfg">https://osf.io/depfg</ext-link>). Similar to Experiment <xref rid="Sec8" ref-type="sec">2</xref>, the current results show no evidence of learning when attention is effectively shielded from a visual regularity.</p><p id="Par30">Once again, only a small subset of the participants that reported noticing the regularity (34) were actually able to report where the previous high-probability location was (6). Again, their data did not significantly influence the previous analyses (all <italic>F</italic> values &#x0003c; 1).</p></sec></sec><sec id="Sec19"><title>General discussion</title><p id="Par31">The present study was designed to investigate whether statistical learning would continue to adjust attentional priorities when the embedded regularity across visual searches would receive neither top-down nor bottom-up attention. For this purpose, a nonsalient shape within a heterogeneous search display appeared with a higher probability at a given location in the search display. In Experiment <xref rid="Sec2" ref-type="sec">1</xref> it was found that search was facilitated when the regular item appeared at its high-probability location, seemingly suggesting learning with neither top-down nor bottom-up attention. However, the experimental design left open the possibility that the regular distractor was occasionally transiently attended due to its shared low-level features (i.e., color) with the search target. To control for this possibility, in Experiment <xref rid="Sec8" ref-type="sec">2</xref> the colors of the search items were manipulated such that during training the nonsalient distractor with a spatial regularity was a different color than the current search target. After having eliminated the possibility that attention would randomly be oriented towards the regular distractor, there was no longer any hint of learning, indicating that statistical learning requires at least some attention to the critical regularity. Following up on this result, Experiment <xref rid="Sec14" ref-type="sec">3</xref> replicated the results of Experiment <xref rid="Sec8" ref-type="sec">2</xref> but using a different attentional guidance technique, thereby demonstrating that the null effect was not specific to color-subset search. Specifically, exogenous cuing was used to effectively direct participants&#x02019; attention away from the distractor regularity during training. Importantly, while previous work has robustly demonstrated that top-down attention can directly affect the expression of statistical learning effects (Dolci et al., <xref ref-type="bibr" rid="CR20">2023</xref>; Richter &#x00026; de Lange, <xref ref-type="bibr" rid="CR66">2019</xref>), no studies have yet definitively shown whether attention is needed for the learning of the regularities themselves. Using this alternate attentional manipulation, the same null effect was observed as in Experiment <xref rid="Sec8" ref-type="sec">2</xref>, demonstrating the generality of the finding.</p><p id="Par32">Several influential theories on the mechanisms underlying statistical learning have theorized that attention is a necessary component for learning to occur (Anderson et al., <xref ref-type="bibr" rid="CR2">2021</xref>; Theeuwes et al., <xref ref-type="bibr" rid="CR84">2022</xref>). This question poses theoretical consequences for the larger concept of statistical learning in distinguishing it from low level phenomena such as habituation and neural adaptation, which are essentially attention free (Larsson &#x00026; Smith, <xref ref-type="bibr" rid="CR54">2012</xref>; Maffei et al., <xref ref-type="bibr" rid="CR59">1973</xref>; Vautin &#x00026; Berkley, <xref ref-type="bibr" rid="CR97">1977</xref>). The current results are consistent with these theories, demonstrating that attention is indeed a crucial ingredient for statistical learning. While the current findings convincingly demonstrate that VSL is no longer observed when the regularity receives neither top-down nor bottom-up attention, the fact that learning was observed when only controlling for bottom-up attention highlights the visual system&#x02019;s remarkable sensitivity to regularities within the environment. Whereas previous studies demonstrating statistical distractor learning already demonstrated that VSL is more ubiquitous than previously thought (see Theeuwes et al., <xref ref-type="bibr" rid="CR84">2022</xref>, for a review), the current findings take this one step further: showing that even a minimally, transiently attended stimulus can entrain some form of learning. Furthermore, the benefits observed in the training phase reversed in the testing phase, slowing reaction times when the previously regular item became the search target. This effect did not generalize to the training target, indicating that the test target shape itself was processed worse at its high-probability location (though a trend towards training target suppression was also found). These results agree nicely with a series of experiments by Failing, Feldmann-W&#x000fc;stefeld et al. (<xref ref-type="bibr" rid="CR26">2019a</xref>), Failing, Wang et al. (<xref ref-type="bibr" rid="CR27">2019b</xref>) where it was shown that both feature and spatial distractor regularities could be simultaneously learned and interacted, where certain feature-defined distractors were better suppressed at their high-probability locations. The current results support such a feature&#x02013;space binding in statistical learning where rather than improving search efficiency by blindly suppressing one region of space, the processing of distracting features themselves were affected at suppressed regions. Additionally, the current study is another in a growing collection of studies showing feature-based statistical learning of either distractor (Kim et al., <xref ref-type="bibr" rid="CR52">2023</xref>; Ogden et al., <xref ref-type="bibr" rid="CR65">2023</xref>; Stilwell et al., <xref ref-type="bibr" rid="CR77">2019</xref>; Won &#x00026; Geng, <xref ref-type="bibr" rid="CR108">2020</xref>) or target features (Conn et al., <xref ref-type="bibr" rid="CR14">2020</xref>; Sha et al., <xref ref-type="bibr" rid="CR75">2017</xref>; Wang et al., <xref ref-type="bibr" rid="CR104">2023</xref>) in visual search tasks.</p><p id="Par33">Together, these experiments elucidate the interaction of attention and statistical learning, which has been a question of interest since early work by Saffran and colleague&#x02019;s demonstrated the seemingly automatic ability of infants to learn grammatical regularities (Saffran et al., <xref ref-type="bibr" rid="CR69">1996</xref>, <xref ref-type="bibr" rid="CR70">1997</xref>). Since then, a wealth of evidence has provided conflicting proof for both camps, with compelling demonstrations of the need for attention for visual learning to occur (Jiang &#x00026; Chun, <xref ref-type="bibr" rid="CR46">2001</xref>; Turk-Browne et al., <xref ref-type="bibr" rid="CR90">2005</xref>; Vadillo et al., <xref ref-type="bibr" rid="CR91">2020</xref>) or for the opposite&#x02014;the presence of VSL without attention (Duncan &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR21">2020</xref>; Jiang &#x00026; Leung, <xref ref-type="bibr" rid="CR47">2005</xref>; Musz et al., <xref ref-type="bibr" rid="CR63">2015</xref>; Turatto et al., <xref ref-type="bibr" rid="CR88">2018</xref>). Several works in particular warrant highlighting: The seminal work of Turk-Browne et al. (<xref ref-type="bibr" rid="CR90">2005</xref>) suggested that participants could only learn regularities related to task-relevant stimuli using a triplet learning paradigm. Their results were challenged, however, by subsequent replications which showed that if a larger sample was collected, learning could also be observed for task-irrelevant items (Campbell et al., <xref ref-type="bibr" rid="CR10">2012</xref>; Musz et al., <xref ref-type="bibr" rid="CR63">2015</xref>). Importantly, this learning is likely due to attention being drawn towards the items in an exogenous way as they were presented alone on the screen, agreeing with recent results that suggest bottom-up attention is sufficient for learning to occur (Duncan &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR21">2020</xref>; Turatto et al., <xref ref-type="bibr" rid="CR88">2018</xref>; Won &#x00026; Geng, <xref ref-type="bibr" rid="CR108">2020</xref>). Baker et al. (<xref ref-type="bibr" rid="CR7">2004</xref>) cleverly demonstrated the role of attention in shape-pair learning. Connecting shapes with a bar, thus evoking object-based attention, led to shape contingency learning, while no pair learning occurred when shapes were disconnected. However, post hoc testing revealed participants&#x02019; explicit knowledge of shape contingencies, presenting a challenge to generalizing their results to other VSL tasks which are often seen as implicit (e.g., learned distractor suppression). Furthermore, it is known that bottom-up-driven learning effect sizes are reliably smaller than when top-down attention is used (Duncan &#x00026; Theeuwes, <xref ref-type="bibr" rid="CR21">2020</xref>; Jiang &#x00026; Chun, <xref ref-type="bibr" rid="CR46">2001</xref>; Musz et al., <xref ref-type="bibr" rid="CR63">2015</xref>), and given their already barely detectable reported effect sizes, it is unclear if evidence of learning of the unattended regularities would be found in a larger sample (Brysbaert, <xref ref-type="bibr" rid="CR9">2019</xref>). Finally, in contextual cuing the work of Jiang and Chun (<xref ref-type="bibr" rid="CR46">2001</xref>) showed that participants could use the global configuration of a display when it predicted target location only when these repeated contexts were presented in a task-relevant color. These results, however, were later challenged by the first author of the original paper in a new design demonstrating that participants could in fact learn this ignored spatial context as well (Jiang &#x00026; Leung, <xref ref-type="bibr" rid="CR47">2005</xref>), thereby supporting the opposite attention-independent perspective on statistical learning. This conflict as well as difficulties in replicating these results (Vadillo et al., <xref ref-type="bibr" rid="CR91">2020</xref>), and recent questions about what is learned in contextual cuing (Meyen et al., <xref ref-type="bibr" rid="CR62">2023</xref>; Seitz et al., <xref ref-type="bibr" rid="CR74">2023</xref>) make the results of these studies difficult to interpret.</p><p id="Par34">In the current study, by carefully controlling the influence of both top-down and bottom-up attention in a large sample size sensitive to small effects, the concerns which have impacted previous studies were addressed. The results of these experiments ultimately support the assertion that VSL depends on attention to occur. It is important to note that the current results demonstrate attention dependent learning on one form of VSL, but caution should be taken in generalizing these findings to other, non-VSL modalities as there is considerable debate whether the diverse family of statistical learning paradigms all originate from one domain-general statistical learning mechanism (Arciuli, <xref ref-type="bibr" rid="CR3">2017</xref>; Conway, <xref ref-type="bibr" rid="CR15">2020</xref>; Frost et al., <xref ref-type="bibr" rid="CR33">2015</xref>). Furthermore, work in nonvisual domains have been highly mixed in regard to the influence of attention on statistical learning, with both audio statistical learning (Batterink &#x00026; Paller, <xref ref-type="bibr" rid="CR8">2019</xref>; Fernandes et al., <xref ref-type="bibr" rid="CR28">2010</xref>; Saffran et al., <xref ref-type="bibr" rid="CR70">1997</xref>; Toro et al., <xref ref-type="bibr" rid="CR85">2005</xref>) and haptic statistical learning (Frensch et al., <xref ref-type="bibr" rid="CR32">1998</xref>; Horv&#x000e1;th et al., <xref ref-type="bibr" rid="CR41">2020</xref>; Janacsek &#x00026; Nemeth, <xref ref-type="bibr" rid="CR44">2013</xref>; Jim&#x000e9;nez &#x00026; Mendez, <xref ref-type="bibr" rid="CR49">1999</xref>) showing mixed results in often underpowered studies (Brysbaert, <xref ref-type="bibr" rid="CR9">2019</xref>). Additionally, there is debate whether VSL paradigms also differ in fundamental mechanisms within the visual domain (Ferrante et al., <xref ref-type="bibr" rid="CR29">2018</xref>, <xref ref-type="bibr" rid="CR30">2023</xref>), leaving open whether the same attention-dependent mechanisms observed here would be in place for, for instance, target contingency learning. Thus, there remains clear motivation to further study the role of attention in other statistical learning paradigms. In sum, the current findings highlight the profound interplay between attention and learning, and support the broader assertion that attention is a fundamental filter through which information must pass to be learned.</p></sec></body><back><fn-group><fn id="Fn1"><label>1</label><p id="Par40">For the sake of consistency with the statistical approach used in Experiments <xref rid="Sec8" ref-type="sec">2</xref> &#x00026; <xref rid="Sec14" ref-type="sec">3</xref>, the Bayes factors (BF<sub>10</sub>) for the above reported effects were 7.881, 0.455, and 3.452 for the distractor effect in training (Fig. <xref rid="Fig1" ref-type="fig">1</xref>A), target effect in training (Fig. <xref rid="Fig1" ref-type="fig">1</xref>B), and target effect in testing (Fig. <xref rid="Fig1" ref-type="fig">1</xref>C), respectively.</p></fn><fn id="Fn2"><label>2</label><p id="Par41">Note that these results are an exact replication of an unregistered pilot experiment included in the OSF archive.</p></fn><fn><p><bold>Public Significance Statement </bold></p><p>Procedural learning is a powerful form of &#x0201c;learning by doing&#x0201d; that greatly influences human behavior. Underlying this form of learning is the brain&#x02019;s ability to implicitly encode regularities in its environment (called statistical learning), which is thought to be a fundamental mechanism by which procedural learning occurs. It has been debated how important attention is for statistical learning to occur, with some claiming that we can learn through mere passive exposure with no attention whatsoever. In the current study, we show that when an experiment properly controls for the various forms of attention (exogenous and endogenous), ensuring no attention is directed to visual stimuli with a regularity, then learning does not occur. These findings highlight the crucial role attention plays in learning, demonstrate that attention is a filter that information must pass through to be learned, and emphasize that attentional engagement is an important consideration to improve learning outcomes.</p></fn><fn><p><bold>Publisher's note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><sec id="FPar1"><title>Author notes</title><p id="Par35">The data and analysis script are available online at (<ext-link ext-link-type="uri" xlink:href="https://osf.io/5vbzp/">https://osf.io/5vbzp/</ext-link>).</p></sec></ack><notes notes-type="author-contribution"><title>Authors contributions</title><p>Idea by D.H.D. and J.T. Data and experiment programmed, collected, and analyzed by D.H.D. Manuscript written by D.H.D., D.v.M, and J.T.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>J.T. was supported by a European Research Council (ERC) advanced grant [833029&#x02013;LEARNATTEND] and an Nederlandse Organisatie voor Wetenschappelijk Onderzoek (NWO) SSH Open Competition Behaviour and Education grant [406.21.GO.034].</p></notes><notes notes-type="data-availability"><title>Data Availability</title><p> All anonymized experiment data, experiment script, analysis code, and preregistrations are available online (<ext-link ext-link-type="uri" xlink:href="https://osf.io/5vbzp/">https://osf.io/5vbzp/</ext-link>).</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>This is stated in the open practice statement.</p></notes><notes><title>Declarations</title><notes id="FPar2" notes-type="COI-statement"><title>Conflict of interest</title><p id="Par36">The authors declare no conflicts of interest.</p></notes><notes id="FPar3"><title>Ethics approval</title><p id="Par37">This is listed in the Methods section.</p></notes><notes id="FPar4"><title>Consent to participate</title><p id="Par38">This is stated in the methods section.</p></notes><notes id="FPar5"><title>Consent for publication</title><p id="Par39">All authors give their consent to publish this manuscript in Psychonomic Bulletin and Review.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Amsalem</surname><given-names>N</given-names></name><name><surname>Sahar</surname><given-names>T</given-names></name><name><surname>Makovski</surname><given-names>T</given-names></name></person-group><article-title>The effect of load on spatial statistical learning</article-title><source>Scientific Reports</source><year>2023</year><volume>13</volume><issue>1</issue><fpage>11701</fpage><pub-id pub-id-type="pmid">37474550</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Amsalem, N., Sahar, T., &#x00026; Makovski, T. (2023). The effect of load on spatial statistical learning. <italic>Scientific Reports,</italic><italic>13</italic>(1), 11701.<pub-id pub-id-type="pmid">37474550</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>BA</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Kim</surname><given-names>AJ</given-names></name><name><surname>Liao</surname><given-names>M-R</given-names></name><name><surname>Mrkonja</surname><given-names>L</given-names></name><name><surname>Clement</surname><given-names>A</given-names></name><name><surname>Gr&#x000e9;goire</surname><given-names>L</given-names></name></person-group><article-title>The past, present, and future of selection history</article-title><source>Neuroscience &#x00026; Biobehavioral Reviews</source><year>2021</year><volume>130</volume><fpage>326</fpage><lpage>350</lpage><pub-id pub-id-type="pmid">34499927</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Anderson, B. A., Kim, H., Kim, A. J., Liao, M.-R., Mrkonja, L., Clement, A., &#x00026; Gr&#x000e9;goire, L. (2021). The past, present, and future of selection history. <italic>Neuroscience &#x00026; Biobehavioral Reviews,</italic><italic>130</italic>, 326&#x02013;350.<pub-id pub-id-type="pmid">34499927</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Arciuli</surname><given-names>J</given-names></name></person-group><article-title>The multi-component nature of statistical learning</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><year>2017</year><volume>372</volume><issue>1711</issue><fpage>20160058</fpage></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Arciuli, J. (2017). The multi-component nature of statistical learning. <italic>Philosophical Transactions of the Royal Society B: Biological Sciences,</italic><italic>372</italic>(1711), 20160058.</mixed-citation></citation-alternatives></ref><ref id="CR4"><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Awh</surname><given-names>E</given-names></name><name><surname>Belopolsky</surname><given-names>AV</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Top-down versus bottom-up attentional control: A failed theoretical dichotomy</article-title><source>Trends in Cognitive Sciences</source><year>2012</year><volume>16</volume><issue>8</issue><fpage>437</fpage><lpage>443</lpage><pub-id pub-id-type="pmid">22795563</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Awh, E., Belopolsky, A. V., &#x00026; Theeuwes, J. (2012). Top-down versus bottom-up attentional control: A failed theoretical dichotomy. <italic>Trends in Cognitive Sciences,</italic><italic>16</italic>(8), 437&#x02013;443.<pub-id pub-id-type="pmid">22795563</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Awh</surname><given-names>E</given-names></name><name><surname>Jonides</surname><given-names>J</given-names></name></person-group><article-title>Overlapping mechanisms of attention and spatial working memory</article-title><source>Trends in Cognitive Sciences</source><year>2001</year><volume>5</volume><issue>3</issue><fpage>119</fpage><lpage>126</lpage><pub-id pub-id-type="pmid">11239812</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Awh, E., &#x00026; Jonides, J. (2001). Overlapping mechanisms of attention and spatial working memory. <italic>Trends in Cognitive Sciences,</italic><italic>5</italic>(3), 119&#x02013;126.<pub-id pub-id-type="pmid">11239812</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Bacon</surname><given-names>WF</given-names></name><name><surname>Egeth</surname><given-names>HE</given-names></name></person-group><article-title>Overriding stimulus-driven attentional capture</article-title><source>Perception &#x00026; Psychophysics</source><year>1994</year><volume>55</volume><issue>5</issue><fpage>485</fpage><lpage>496</lpage><pub-id pub-id-type="pmid">8008550</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Bacon, W. F., &#x00026; Egeth, H. E. (1994). Overriding stimulus-driven attentional capture. <italic>Perception &#x00026; Psychophysics,</italic><italic>55</italic>(5), 485&#x02013;496.<pub-id pub-id-type="pmid">8008550</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>CI</given-names></name><name><surname>Olson</surname><given-names>CR</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name></person-group><article-title>Role of attention and perceptual grouping in visual statistical learning</article-title><source>Psychological Science</source><year>2004</year><volume>15</volume><issue>7</issue><fpage>460</fpage><lpage>466</lpage><pub-id pub-id-type="pmid">15200630</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Baker, C. I., Olson, C. R., &#x00026; Behrmann, M. (2004). Role of attention and perceptual grouping in visual statistical learning. <italic>Psychological Science,</italic><italic>15</italic>(7), 460&#x02013;466.<pub-id pub-id-type="pmid">15200630</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Batterink</surname><given-names>LJ</given-names></name><name><surname>Paller</surname><given-names>KA</given-names></name></person-group><article-title>Statistical learning of speech regularities can occur outside the focus of attention</article-title><source>Cortex</source><year>2019</year><volume>115</volume><fpage>56</fpage><lpage>71</lpage><pub-id pub-id-type="pmid">30771622</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Batterink, L. J., &#x00026; Paller, K. A. (2019). Statistical learning of speech regularities can occur outside the focus of attention. <italic>Cortex,</italic><italic>115</italic>, 56&#x02013;71.<pub-id pub-id-type="pmid">30771622</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Brysbaert</surname><given-names>M</given-names></name></person-group><article-title>How many participants do we have to include in properly powered experiments? A tutorial of power analysis with reference tables</article-title><source>Journal of Cognition</source><year>2019</year><volume>2</volume><issue>1</issue><fpage>16</fpage><pub-id pub-id-type="doi">10.5334/joc.72</pub-id><pub-id pub-id-type="pmid">31517234</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Brysbaert, M. (2019). How many participants do we have to include in properly powered experiments? A tutorial of power analysis with reference tables. <italic>Journal of Cognition,</italic><italic>2</italic>(1), 16. 10.5334/joc.72<pub-id pub-id-type="pmid">31517234</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>KL</given-names></name><name><surname>Zimerman</surname><given-names>S</given-names></name><name><surname>Healey</surname><given-names>MK</given-names></name><name><surname>Lee</surname><given-names>M</given-names></name><name><surname>Hasher</surname><given-names>L</given-names></name></person-group><article-title>Age differences in visual statistical learning</article-title><source>Psychology and Aging</source><year>2012</year><volume>27</volume><issue>3</issue><fpage>650</fpage><lpage>656</lpage><pub-id pub-id-type="pmid">22251380</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Campbell, K. L., Zimerman, S., Healey, M. K., Lee, M., &#x00026; Hasher, L. (2012). Age differences in visual statistical learning. <italic>Psychology and Aging,</italic><italic>27</italic>(3), 650&#x02013;656.<pub-id pub-id-type="pmid">22251380</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><article-title>Contextual cueing of visual attention</article-title><source>Trends in Cognitive Sciences</source><year>2000</year><volume>4</volume><issue>5</issue><fpage>170</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01476-5</pub-id><pub-id pub-id-type="pmid">10782102</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Chun, M. M. (2000). Contextual cueing of visual attention. <italic>Trends in Cognitive Sciences,</italic><italic>4</italic>(5), 170&#x02013;178. 10.1016/S1364-6613(00)01476-5<pub-id pub-id-type="pmid">10782102</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><article-title>Contextual cueing: Implicit learning and memory of visual context guides spatial attention</article-title><source>Cognitive Psychology</source><year>1998</year><volume>36</volume><issue>1</issue><fpage>28</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1006/cogp.1998.0681</pub-id><pub-id pub-id-type="pmid">9679076</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Chun, M. M., &#x00026; Jiang, Y. (1998). Contextual cueing: Implicit learning and memory of visual context guides spatial attention. <italic>Cognitive Psychology,</italic><italic>36</italic>(1), 28&#x02013;71. 10.1006/cogp.1998.0681<pub-id pub-id-type="pmid">9679076</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><article-title>Implicit, long-term spatial contextual memory</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><year>2003</year><volume>29</volume><issue>2</issue><fpage>224</fpage><pub-id pub-id-type="pmid">12696811</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Chun, M. M., &#x00026; Jiang, Y. (2003). Implicit, long-term spatial contextual memory. <italic>Journal of Experimental Psychology: Learning, Memory, and Cognition,</italic><italic>29</italic>(2), 224.<pub-id pub-id-type="pmid">12696811</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Conn</surname><given-names>KM</given-names></name><name><surname>Becker</surname><given-names>MW</given-names></name><name><surname>Ravizza</surname><given-names>SM</given-names></name></person-group><article-title>Persistent guidance of attention in visual statistical learning</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2020</year><volume>46</volume><issue>7</issue><fpage>681</fpage><lpage>696</lpage><pub-id pub-id-type="pmid">32271078</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Conn, K. M., Becker, M. W., &#x00026; Ravizza, S. M. (2020). Persistent guidance of attention in visual statistical learning. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>46</italic>(7), 681&#x02013;696.<pub-id pub-id-type="pmid">32271078</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>CM</given-names></name></person-group><article-title>How does the brain learn environmental structure? Ten core principles for understanding the neurocognitive mechanisms of statistical learning</article-title><source>Neuroscience &#x00026; Biobehavioral Reviews</source><year>2020</year><volume>112</volume><fpage>279</fpage><lpage>299</lpage><pub-id pub-id-type="pmid">32018038</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Conway, C. M. (2020). How does the brain learn environmental structure? Ten core principles for understanding the neurocognitive mechanisms of statistical learning. <italic>Neuroscience &#x00026; Biobehavioral Reviews,</italic><italic>112</italic>, 279&#x02013;299.<pub-id pub-id-type="pmid">32018038</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Cousineau</surname><given-names>D</given-names></name><name><surname>Goulet</surname><given-names>M-A</given-names></name><name><surname>Harding</surname><given-names>B</given-names></name></person-group><article-title>Summary plots with adjusted error bars: The <italic>superb</italic> framework with an implementation in R</article-title><source>Advances in Methods and Practices in Psychological Science</source><year>2021</year><volume>4</volume><issue>3</issue><fpage>25152459211035109</fpage><pub-id pub-id-type="doi">10.1177/25152459211035109</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Cousineau, D., Goulet, M.-A., &#x00026; Harding, B. (2021). Summary plots with adjusted error bars: The <italic>superb</italic> framework with an implementation in R. <italic>Advances in Methods and Practices in Psychological Science,</italic><italic>4</italic>(3), 25152459211035108. 10.1177/25152459211035109</mixed-citation></citation-alternatives></ref><ref id="CR17"><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N</given-names></name><name><surname>Elliott</surname><given-names>EM</given-names></name><name><surname>Scott Saults</surname><given-names>J</given-names></name><name><surname>Morey</surname><given-names>CC</given-names></name><name><surname>Mattox</surname><given-names>S</given-names></name><name><surname>Hismjatullina</surname><given-names>A</given-names></name><name><surname>Conway</surname><given-names>ARA</given-names></name></person-group><article-title>On the capacity of attention: Its estimation and its role in working memory and cognitive aptitudes</article-title><source>Cognitive Psychology</source><year>2005</year><volume>51</volume><issue>1</issue><fpage>42</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2004.12.001</pub-id><pub-id pub-id-type="pmid">16039935</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Cowan, N., Elliott, E. M., Scott Saults, J., Morey, C. C., Mattox, S., Hismjatullina, A., &#x00026; Conway, A. R. A. (2005). On the capacity of attention: Its estimation and its role in working memory and cognitive aptitudes. <italic>Cognitive Psychology,</italic><italic>51</italic>(1), 42&#x02013;100. 10.1016/j.cogpsych.2004.12.001<pub-id pub-id-type="pmid">16039935</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>DeSchepper</surname><given-names>B</given-names></name><name><surname>Treisman</surname><given-names>A</given-names></name></person-group><article-title>Visual memory for novel shapes: Implicit coding without attention</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><year>1996</year><volume>22</volume><issue>1</issue><fpage>27</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.22.1.27</pub-id><pub-id pub-id-type="pmid">8648288</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">DeSchepper, B., &#x00026; Treisman, A. (1996). Visual memory for novel shapes: Implicit coding without attention. <italic>Journal of Experimental Psychology: Learning, Memory, and Cognition,</italic><italic>22</italic>(1), 27&#x02013;47. 10.1037/0278-7393.22.1.27<pub-id pub-id-type="pmid">8648288</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Di Caro</surname><given-names>V</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name><name><surname>Della Libera</surname><given-names>C</given-names></name></person-group><article-title>Suppression history of distractor location biases attentional and oculomotor control</article-title><source>Visual Cognition</source><year>2019</year><volume>27</volume><issue>2</issue><fpage>142</fpage><lpage>157</lpage></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Di Caro, V., Theeuwes, J., &#x00026; Della Libera, C. (2019). Suppression history of distractor location biases attentional and oculomotor control. <italic>Visual Cognition,</italic><italic>27</italic>(2), 142&#x02013;157.</mixed-citation></citation-alternatives></ref><ref id="CR20"><mixed-citation publication-type="other">Dolci, C., Boehler, C. N., Santandrea, E., Dewulf, A., Ben-Hamed, S., Macaluso, E., ...., &#x00026; Rashal, E. (2023). Integrated effects of top-down attention and statistical learning during visual search: An EEG study. <italic>Attention, Perception, &#x00026; Psychophysics, 85, </italic>1819&#x02013;1833. 10.3758/s13414-023-02728-y</mixed-citation></ref><ref id="CR21"><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>DH</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Statistical learning in the absence of explicit top-down attention</article-title><source>Cortex</source><year>2020</year><volume>131</volume><fpage>54</fpage><lpage>65</lpage><pub-id pub-id-type="pmid">32801075</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Duncan, D. H., &#x00026; Theeuwes, J. (2020). Statistical learning in the absence of explicit top-down attention. <italic>Cortex,</italic><italic>131</italic>, 54&#x02013;65.<pub-id pub-id-type="pmid">32801075</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>DH</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name><name><surname>van Moorselaar</surname><given-names>D</given-names></name></person-group><article-title>The electrophysiological markers of statistically learned attentional enhancement: Evidence for a saliency-based mechanism</article-title><source>Journal of Cognitive Neuroscience</source><year>2023</year><volume>35</volume><issue>12</issue><fpage>2110</fpage><lpage>2125</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_02066</pub-id><pub-id pub-id-type="pmid">37801336</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Duncan, D. H., Theeuwes, J., &#x00026; van Moorselaar, D. (2023a). The electrophysiological markers of statistically learned attentional enhancement: Evidence for a saliency-based mechanism. <italic>Journal of Cognitive Neuroscience,</italic><italic>35</italic>(12), 2110&#x02013;2125. 10.1162/jocn_a_02066<pub-id pub-id-type="pmid">37801336</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>DH</given-names></name><name><surname>van Moorselaar</surname><given-names>D</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Pinging the brain to reveal the hidden attentional priority map using encephalography</article-title><source>Nature Communications</source><year>2023</year><volume>14</volume><issue>1</issue><fpage>1</fpage><pub-id pub-id-type="doi">10.1038/s41467-023-40405-8</pub-id></element-citation><mixed-citation id="mc-CR23" publication-type="journal">Duncan, D. H., van Moorselaar, D., &#x00026; Theeuwes, J. (2023b). Pinging the brain to reveal the hidden attentional priority map using encephalography. <italic>Nature Communications,</italic><italic>14</italic>(1), 1. 10.1038/s41467-023-40405-8</mixed-citation></citation-alternatives></ref><ref id="CR24"><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Egeth</surname><given-names>HE</given-names></name><name><surname>Virzi</surname><given-names>RA</given-names></name><name><surname>Garbart</surname><given-names>H</given-names></name></person-group><article-title>Searching for conjunctively defined targets</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>1984</year><volume>10</volume><issue>1</issue><fpage>32</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.10.1.32</pub-id><pub-id pub-id-type="pmid">6242762</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Egeth, H. E., Virzi, R. A., &#x00026; Garbart, H. (1984). Searching for conjunctively defined targets. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>10</italic>(1), 32&#x02013;39. 10.1037/0096-1523.10.1.32<pub-id pub-id-type="pmid">6242762</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Failing</surname><given-names>M</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Selection history: How reward modulates selectivity of visual attention</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2018</year><volume>25</volume><issue>2</issue><fpage>514</fpage><lpage>538</lpage><pub-id pub-id-type="pmid">28986770</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Failing, M., &#x00026; Theeuwes, J. (2018). Selection history: How reward modulates selectivity of visual attention. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>25</italic>(2), 514&#x02013;538.<pub-id pub-id-type="pmid">28986770</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Failing</surname><given-names>M</given-names></name><name><surname>Feldmann-W&#x000fc;stefeld</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Olivers</surname><given-names>C</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Statistical regularities induce spatial as well as feature-specific suppression</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2019</year><volume>45</volume><issue>10</issue><fpage>1291</fpage><lpage>1303</lpage><pub-id pub-id-type="doi">10.1037/xhp0000660</pub-id><pub-id pub-id-type="pmid">31157536</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Failing, M., Feldmann-W&#x000fc;stefeld, T., Wang, B., Olivers, C., &#x00026; Theeuwes, J. (2019a). Statistical regularities induce spatial as well as feature-specific suppression. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>45</italic>(10), 1291&#x02013;1303. 10.1037/xhp0000660<pub-id pub-id-type="pmid">31157536</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Failing</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Spatial suppression due to statistical regularities is driven by distractor suppression not by target activation</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2019</year><volume>81</volume><fpage>1405</fpage><lpage>1414</lpage></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Failing, M., Wang, B., &#x00026; Theeuwes, J. (2019b). Spatial suppression due to statistical regularities is driven by distractor suppression not by target activation. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>81</italic>, 1405&#x02013;1414.</mixed-citation></citation-alternatives></ref><ref id="CR28"><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandes</surname><given-names>T</given-names></name><name><surname>Kolinsky</surname><given-names>R</given-names></name><name><surname>Ventura</surname><given-names>P</given-names></name></person-group><article-title>The impact of attention load on the use of statistical information and coarticulation as speech segmentation cues</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2010</year><volume>72</volume><issue>6</issue><fpage>1522</fpage><lpage>1532</lpage></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Fernandes, T., Kolinsky, R., &#x00026; Ventura, P. (2010). The impact of attention load on the use of statistical information and coarticulation as speech segmentation cues. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>72</italic>(6), 1522&#x02013;1532.</mixed-citation></citation-alternatives></ref><ref id="CR29"><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrante</surname><given-names>O</given-names></name><name><surname>Patacca</surname><given-names>A</given-names></name><name><surname>Di Caro</surname><given-names>V</given-names></name><name><surname>Della Libera</surname><given-names>C</given-names></name><name><surname>Santandrea</surname><given-names>E</given-names></name><name><surname>Chelazzi</surname><given-names>L</given-names></name></person-group><article-title>Altering spatial priority maps via statistical learning of target selection and distractor filtering</article-title><source>Cortex</source><year>2018</year><volume>102</volume><fpage>67</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2017.09.027</pub-id><pub-id pub-id-type="pmid">29096874</pub-id>
</element-citation><mixed-citation id="mc-CR29" publication-type="journal">Ferrante, O., Patacca, A., Di Caro, V., Della Libera, C., Santandrea, E., &#x00026; Chelazzi, L. (2018). Altering spatial priority maps via statistical learning of target selection and distractor filtering. <italic>Cortex,</italic><italic>102</italic>, 67&#x02013;95. 10.1016/j.cortex.2017.09.027<pub-id pub-id-type="pmid">29096874</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR30"><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrante</surname><given-names>O</given-names></name><name><surname>Chelazzi</surname><given-names>L</given-names></name><name><surname>Santandrea</surname><given-names>E</given-names></name></person-group><article-title>Statistical learning of target and distractor spatial probability shape a common attentional priority computation</article-title><source>Cortex</source><year>2023</year><volume>169</volume><fpage>95</fpage><lpage>117</lpage><pub-id pub-id-type="pmid">37866062</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Ferrante, O., Chelazzi, L., &#x00026; Santandrea, E. (2023). Statistical learning of target and distractor spatial probability shape a common attentional priority computation. <italic>Cortex,</italic><italic>169</italic>, 95&#x02013;117.<pub-id pub-id-type="pmid">37866062</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Forschack</surname><given-names>N</given-names></name><name><surname>Andersen</surname><given-names>SK</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>MM</given-names></name></person-group><article-title>Global enhancement but local suppression in feature-based attention</article-title><source>Journal of Cognitive Neuroscience</source><year>2017</year><volume>29</volume><issue>4</issue><fpage>619</fpage><lpage>627</lpage><pub-id pub-id-type="pmid">27897668</pub-id>
</element-citation><mixed-citation id="mc-CR31" publication-type="journal">Forschack, N., Andersen, S. K., &#x00026; M&#x000fc;ller, M. M. (2017). Global enhancement but local suppression in feature-based attention. <italic>Journal of Cognitive Neuroscience,</italic><italic>29</italic>(4), 619&#x02013;627.<pub-id pub-id-type="pmid">27897668</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR32"><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Frensch</surname><given-names>PA</given-names></name><name><surname>Lin</surname><given-names>J</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name></person-group><article-title>Learning versus behavioral expression of the learned: The effects of a secondary tone-counting task on implicit learning in the serial reaction task</article-title><source>Psychological Research</source><year>1998</year><volume>61</volume><fpage>83</fpage><lpage>98</lpage></element-citation><mixed-citation id="mc-CR32" publication-type="journal">Frensch, P. A., Lin, J., &#x00026; Buchner, A. (1998). Learning versus behavioral expression of the learned: The effects of a secondary tone-counting task on implicit learning in the serial reaction task. <italic>Psychological Research,</italic><italic>61</italic>, 83&#x02013;98.</mixed-citation></citation-alternatives></ref><ref id="CR33"><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Frost</surname><given-names>R</given-names></name><name><surname>Armstrong</surname><given-names>BC</given-names></name><name><surname>Siegelman</surname><given-names>N</given-names></name><name><surname>Christiansen</surname><given-names>MH</given-names></name></person-group><article-title>Domain generality versus modality specificity: The paradox of statistical learning</article-title><source>Trends in Cognitive Sciences</source><year>2015</year><volume>19</volume><issue>3</issue><fpage>117</fpage><lpage>125</lpage><pub-id pub-id-type="pmid">25631249</pub-id>
</element-citation><mixed-citation id="mc-CR33" publication-type="journal">Frost, R., Armstrong, B. C., Siegelman, N., &#x00026; Christiansen, M. H. (2015). Domain generality versus modality specificity: The paradox of statistical learning. <italic>Trends in Cognitive Sciences,</italic><italic>19</italic>(3), 117&#x02013;125.<pub-id pub-id-type="pmid">25631249</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR34"><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name><surname>Frost</surname><given-names>R</given-names></name><name><surname>Armstrong</surname><given-names>BC</given-names></name><name><surname>Christiansen</surname><given-names>MH</given-names></name></person-group><article-title>Statistical learning research: A critical review and possible new directions</article-title><source>Psychological Bulletin</source><year>2019</year><volume>145</volume><issue>12</issue><fpage>1128</fpage><lpage>1153</lpage><pub-id pub-id-type="doi">10.1037/bul0000210</pub-id><pub-id pub-id-type="pmid">31580089</pub-id>
</element-citation><mixed-citation id="mc-CR34" publication-type="journal">Frost, R., Armstrong, B. C., &#x00026; Christiansen, M. H. (2019). Statistical learning research: A critical review and possible new directions. <italic>Psychological Bulletin,</italic><italic>145</italic>(12), 1128&#x02013;1153. 10.1037/bul0000210<pub-id pub-id-type="pmid">31580089</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR35"><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Learning to suppress a distractor is not affected by working memory load</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2020</year><volume>27</volume><issue>1</issue><fpage>96</fpage><lpage>104</lpage><pub-id pub-id-type="pmid">31797259</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Gao, Y., &#x00026; Theeuwes, J. (2020). Learning to suppress a distractor is not affected by working memory load. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>27</italic>(1), 96&#x02013;104.<pub-id pub-id-type="pmid">31797259</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Geng</surname><given-names>JJ</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name></person-group><article-title>Spatial probability as an attentional cue in visual search</article-title><source>Perception &#x00026; Psychophysics</source><year>2005</year><volume>67</volume><issue>7</issue><fpage>1252</fpage><lpage>1268</lpage><pub-id pub-id-type="pmid">16502846</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal">Geng, J. J., &#x00026; Behrmann, M. (2005). Spatial probability as an attentional cue in visual search. <italic>Perception &#x00026; Psychophysics,</italic><italic>67</italic>(7), 1252&#x02013;1268.<pub-id pub-id-type="pmid">16502846</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name><surname>Gim&#x000e9;nez-Fern&#x000e1;ndez</surname><given-names>T</given-names></name><name><surname>Vicente-Conesa</surname><given-names>F</given-names></name><name><surname>Luque</surname><given-names>D</given-names></name><name><surname>Vadillo</surname><given-names>MA</given-names></name></person-group><article-title>The role of working memory in probabilistic cuing of visual search</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><year>2023</year><volume>49</volume><issue>7</issue><fpage>1019</fpage><lpage>1032</lpage><pub-id pub-id-type="doi">10.1037/xlm0001193</pub-id><pub-id pub-id-type="pmid">36326649</pub-id>
</element-citation><mixed-citation id="mc-CR37" publication-type="journal">Gim&#x000e9;nez-Fern&#x000e1;ndez, T., Vicente-Conesa, F., Luque, D., &#x00026; Vadillo, M. A. (2023). The role of working memory in probabilistic cuing of visual search. <italic>Journal of Experimental Psychology: Learning, Memory, and Cognition,</italic><italic>49</italic>(7), 1019&#x02013;1032. 10.1037/xlm0001193<pub-id pub-id-type="pmid">36326649</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR38"><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name><surname>Goschy</surname><given-names>H</given-names></name><name><surname>Bakos</surname><given-names>S</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>HJ</given-names></name><name><surname>Zehetleitner</surname><given-names>M</given-names></name></person-group><article-title>Probability cueing of distractor locations: Both intertrial facilitation and statistical learning mediate interference reduction</article-title><source>Frontiers in Psychology</source><year>2014</year><volume>5</volume><fpage>1195</fpage><pub-id pub-id-type="pmid">25414676</pub-id>
</element-citation><mixed-citation id="mc-CR38" publication-type="journal">Goschy, H., Bakos, S., M&#x000fc;ller, H. J., &#x00026; Zehetleitner, M. (2014). Probability cueing of distractor locations: Both intertrial facilitation and statistical learning mediate interference reduction. <italic>Frontiers in Psychology,</italic><italic>5</italic>, 1195.<pub-id pub-id-type="pmid">25414676</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR39"><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name><surname>Goujon</surname><given-names>A</given-names></name><name><surname>Didierjean</surname><given-names>A</given-names></name><name><surname>Thorpe</surname><given-names>S</given-names></name></person-group><article-title>Investigating implicit statistical learning mechanisms through contextual cueing</article-title><source>Trends in Cognitive Sciences</source><year>2015</year><volume>19</volume><issue>9</issue><fpage>524</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.07.009</pub-id><pub-id pub-id-type="pmid">26255970</pub-id>
</element-citation><mixed-citation id="mc-CR39" publication-type="journal">Goujon, A., Didierjean, A., &#x00026; Thorpe, S. (2015). Investigating implicit statistical learning mechanisms through contextual cueing. <italic>Trends in Cognitive Sciences,</italic><italic>19</italic>(9), 524&#x02013;533. 10.1016/j.tics.2015.07.009<pub-id pub-id-type="pmid">26255970</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR40"><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name><surname>Hansmann-Roth</surname><given-names>S</given-names></name><name><surname>Kristj&#x000e1;nsson</surname><given-names>&#x000c1;</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name><name><surname>Chetverikov</surname><given-names>A</given-names></name></person-group><article-title>Dissociating implicit and explicit ensemble representations reveals the limits of visual perception and the richness of behavior</article-title><source>Scientific Reports</source><year>2021</year><volume>11</volume><issue>1</issue><fpage>1</fpage><pub-id pub-id-type="doi">10.1038/s41598-021-83358-y</pub-id><pub-id pub-id-type="pmid">33414495</pub-id>
</element-citation><mixed-citation id="mc-CR40" publication-type="journal">Hansmann-Roth, S., Kristj&#x000e1;nsson, &#x000c1;., Whitney, D., &#x00026; Chetverikov, A. (2021). Dissociating implicit and explicit ensemble representations reveals the limits of visual perception and the richness of behavior. <italic>Scientific Reports,</italic><italic>11</italic>(1), 1. 10.1038/s41598-021-83358-y<pub-id pub-id-type="pmid">33414495</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR41"><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name><surname>Horv&#x000e1;th</surname><given-names>K</given-names></name><name><surname>T&#x000f6;r&#x000f6;k</surname><given-names>C</given-names></name><name><surname>Pesthy</surname><given-names>O</given-names></name><name><surname>Nemeth</surname><given-names>D</given-names></name><name><surname>Janacsek</surname><given-names>K</given-names></name></person-group><article-title>Divided attention does not affect the acquisition and consolidation of transitional probabilities</article-title><source>Scientific Reports</source><year>2020</year><volume>10</volume><issue>1</issue><fpage>22450</fpage><pub-id pub-id-type="pmid">33384423</pub-id>
</element-citation><mixed-citation id="mc-CR41" publication-type="journal">Horv&#x000e1;th, K., T&#x000f6;r&#x000f6;k, C., Pesthy, O., Nemeth, D., &#x00026; Janacsek, K. (2020). Divided attention does not affect the acquisition and consolidation of transitional probabilities. <italic>Scientific Reports,</italic><italic>10</italic>(1), 22450.<pub-id pub-id-type="pmid">33384423</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR42"><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Vilotijevi&#x00107;</surname><given-names>A</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name><name><surname>Donk</surname><given-names>M</given-names></name></person-group><article-title>Proactive distractor suppression elicited by statistical regularities in visual search</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2021</year><volume>28</volume><issue>3</issue><fpage>918</fpage><lpage>927</lpage><pub-id pub-id-type="pmid">33620698</pub-id>
</element-citation><mixed-citation id="mc-CR42" publication-type="journal">Huang, C., Vilotijevi&#x00107;, A., Theeuwes, J., &#x00026; Donk, M. (2021). Proactive distractor suppression elicited by statistical regularities in visual search. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>28</italic>(3), 918&#x02013;927.<pub-id pub-id-type="pmid">33620698</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR43"><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>C</given-names></name><name><surname>Donk</surname><given-names>M</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Proactive enhancement and suppression elicited by statistical regularities in visual search</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2022</year><volume>48</volume><issue>5</issue><fpage>443</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/xhp0001002</pub-id><pub-id pub-id-type="pmid">35324244</pub-id>
</element-citation><mixed-citation id="mc-CR43" publication-type="journal">Huang, C., Donk, M., &#x00026; Theeuwes, J. (2022). Proactive enhancement and suppression elicited by statistical regularities in visual search. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>48</italic>(5), 443&#x02013;457. 10.1037/xhp0001002<pub-id pub-id-type="pmid">35324244</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR44"><citation-alternatives><element-citation id="ec-CR44" publication-type="journal"><person-group person-group-type="author"><name><surname>Janacsek</surname><given-names>K</given-names></name><name><surname>Nemeth</surname><given-names>D</given-names></name></person-group><article-title>Implicit sequence learning and working memory: Correlated or complicated?</article-title><source>Cortex</source><year>2013</year><volume>49</volume><issue>8</issue><fpage>2001</fpage><lpage>2006</lpage><pub-id pub-id-type="pmid">23541152</pub-id>
</element-citation><mixed-citation id="mc-CR44" publication-type="journal">Janacsek, K., &#x00026; Nemeth, D. (2013). Implicit sequence learning and working memory: Correlated or complicated? <italic>Cortex,</italic><italic>49</italic>(8), 2001&#x02013;2006.<pub-id pub-id-type="pmid">23541152</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR45"><mixed-citation publication-type="other">Jeong, J., &#x00026; Cho, Y. S. (2024). Object-based suppression in target search but not in distractor inhibition. <italic>Attention, Perception, &#x00026; Psychophysics</italic>, 1&#x02013;27.</mixed-citation></ref><ref id="CR46"><citation-alternatives><element-citation id="ec-CR46" publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><article-title>Selective attention modulates implicit learning</article-title><source>The Quarterly Journal of Experimental Psychology: Section A</source><year>2001</year><volume>54</volume><issue>4</issue><fpage>1105</fpage><lpage>1124</lpage></element-citation><mixed-citation id="mc-CR46" publication-type="journal">Jiang, Y., &#x00026; Chun, M. M. (2001). Selective attention modulates implicit learning. <italic>The Quarterly Journal of Experimental Psychology: Section A,</italic><italic>54</italic>(4), 1105&#x02013;1124.</mixed-citation></citation-alternatives></ref><ref id="CR47"><citation-alternatives><element-citation id="ec-CR47" publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Leung</surname><given-names>AW</given-names></name></person-group><article-title>Implicit learning of ignored visual context</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2005</year><volume>12</volume><issue>1</issue><fpage>100</fpage><lpage>106</lpage><pub-id pub-id-type="pmid">15948286</pub-id>
</element-citation><mixed-citation id="mc-CR47" publication-type="journal">Jiang, Y., &#x00026; Leung, A. W. (2005). Implicit learning of ignored visual context. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>12</italic>(1), 100&#x02013;106.<pub-id pub-id-type="pmid">15948286</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR48"><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>YV</given-names></name><name><surname>Swallow</surname><given-names>KM</given-names></name><name><surname>Rosenbaum</surname><given-names>GM</given-names></name><name><surname>Herzig</surname><given-names>C</given-names></name></person-group><article-title>Rapid acquisition but slow extinction of an attentional bias in space</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2013</year><volume>39</volume><issue>1</issue><fpage>87</fpage><pub-id pub-id-type="pmid">22428675</pub-id>
</element-citation><mixed-citation id="mc-CR48" publication-type="journal">Jiang, Y. V., Swallow, K. M., Rosenbaum, G. M., &#x00026; Herzig, C. (2013). Rapid acquisition but slow extinction of an attentional bias in space. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>39</italic>(1), 87.<pub-id pub-id-type="pmid">22428675</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR49"><citation-alternatives><element-citation id="ec-CR49" publication-type="journal"><person-group person-group-type="author"><name><surname>Jim&#x000e9;nez</surname><given-names>L</given-names></name><name><surname>Mendez</surname><given-names>C</given-names></name></person-group><article-title>Which attention is needed for implicit sequence learning?</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><year>1999</year><volume>25</volume><issue>1</issue><fpage>236</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.25.1.236</pub-id></element-citation><mixed-citation id="mc-CR49" publication-type="journal">Jim&#x000e9;nez, L., &#x00026; Mendez, C. (1999). Which attention is needed for implicit sequence learning? <italic>Journal of Experimental Psychology: Learning, Memory, and Cognition,</italic><italic>25</italic>(1), 236&#x02013;259. 10.1037/0278-7393.25.1.236</mixed-citation></citation-alternatives></ref><ref id="CR50"><citation-alternatives><element-citation id="ec-CR50" publication-type="journal"><person-group person-group-type="author"><name><surname>Jonides</surname><given-names>J</given-names></name><name><surname>Yantis</surname><given-names>S</given-names></name></person-group><article-title>Uniqueness of abrupt visual onset in capturing attention</article-title><source>Perception &#x00026; Psychophysics</source><year>1988</year><volume>43</volume><issue>4</issue><fpage>346</fpage><lpage>354</lpage><pub-id pub-id-type="pmid">3362663</pub-id>
</element-citation><mixed-citation id="mc-CR50" publication-type="journal">Jonides, J., &#x00026; Yantis, S. (1988). Uniqueness of abrupt visual onset in capturing attention. <italic>Perception &#x00026; Psychophysics,</italic><italic>43</italic>(4), 346&#x02013;354.<pub-id pub-id-type="pmid">3362663</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR51"><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name><surname>Kaptein</surname><given-names>NA</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name><name><surname>Van der Heijden</surname><given-names>A</given-names></name></person-group><article-title>Search for a conjunctively defined target can be selectively limited to a color-defined subset of elements</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>1995</year><volume>21</volume><issue>5</issue><fpage>1053</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.21.5.1053</pub-id></element-citation><mixed-citation id="mc-CR51" publication-type="journal">Kaptein, N. A., Theeuwes, J., &#x00026; Van der Heijden, A. (1995). Search for a conjunctively defined target can be selectively limited to a color-defined subset of elements. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>21</italic>(5), 1053&#x02013;1069. 10.1037/0096-1523.21.5.1053</mixed-citation></citation-alternatives></ref><ref id="CR52"><citation-alternatives><element-citation id="ec-CR52" publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Ogden</surname><given-names>A</given-names></name><name><surname>Anderson</surname><given-names>BA</given-names></name></person-group><article-title>Statistical learning of distractor shape modulates attentional capture</article-title><source>Vision Research</source><year>2023</year><volume>202</volume><fpage>108155</fpage><pub-id pub-id-type="pmid">36417810</pub-id>
</element-citation><mixed-citation id="mc-CR52" publication-type="journal">Kim, H., Ogden, A., &#x00026; Anderson, B. A. (2023). Statistical learning of distractor shape modulates attentional capture. <italic>Vision Research,</italic><italic>202</italic>, 108155.<pub-id pub-id-type="pmid">36417810</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR53"><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name><surname>Lange</surname><given-names>K</given-names></name><name><surname>K&#x000fc;hn</surname><given-names>S</given-names></name><name><surname>Filevich</surname><given-names>E</given-names></name></person-group><article-title>"Just Another Tool for Online Studies&#x0201d;(JATOS): An easy solution for setup and management of web servers supporting online studies</article-title><source>PloS One</source><year>2015</year><volume>10</volume><issue>6</issue><fpage>e0130834</fpage><pub-id pub-id-type="pmid">26114751</pub-id>
</element-citation><mixed-citation id="mc-CR53" publication-type="journal">Lange, K., K&#x000fc;hn, S., &#x00026; Filevich, E. (2015). "Just Another Tool for Online Studies&#x0201d;(JATOS): An easy solution for setup and management of web servers supporting online studies. <italic>PloS One,</italic><italic>10</italic>(6), e0130834.<pub-id pub-id-type="pmid">26114751</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR54"><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name><surname>Larsson</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>AT</given-names></name></person-group><article-title>fMRI repetition suppression: Neuronal adaptation or stimulus expectation?</article-title><source>Cerebral Cortex</source><year>2012</year><volume>22</volume><issue>3</issue><fpage>567</fpage><lpage>576</lpage><pub-id pub-id-type="pmid">21690262</pub-id>
</element-citation><mixed-citation id="mc-CR54" publication-type="journal">Larsson, J., &#x00026; Smith, A. T. (2012). fMRI repetition suppression: Neuronal adaptation or stimulus expectation? <italic>Cerebral Cortex,</italic><italic>22</italic>(3), 567&#x02013;576.<pub-id pub-id-type="pmid">21690262</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR55"><citation-alternatives><element-citation id="ec-CR55" publication-type="journal"><person-group person-group-type="author"><name><surname>Leber</surname><given-names>AB</given-names></name><name><surname>Egeth</surname><given-names>HE</given-names></name></person-group><article-title>It&#x02019;s under control: Top-down search strategies can override attentional capture</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2006</year><volume>13</volume><fpage>132</fpage><lpage>138</lpage><pub-id pub-id-type="pmid">16724780</pub-id>
</element-citation><mixed-citation id="mc-CR55" publication-type="journal">Leber, A. B., &#x00026; Egeth, H. E. (2006). It&#x02019;s under control: Top-down search strategies can override attentional capture. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>13</italic>, 132&#x02013;138.<pub-id pub-id-type="pmid">16724780</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR56"><mixed-citation publication-type="other">Lien, M.-C., Ruthruff, E., &#x00026; Hauck, C. (2021). On preventing attention capture: Is singleton suppression actually singleton suppression? <italic>Psychological Research</italic>, 1&#x02013;14.10.1007/s00426-021-01599-y Advance online publication.</mixed-citation></ref><ref id="CR57"><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name><surname>Liesefeld</surname><given-names>HR</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>HJ</given-names></name></person-group><article-title>Distractor handling via dimension weighting</article-title><source>Current Opinion in Psychology</source><year>2019</year><volume>29</volume><fpage>160</fpage><lpage>167</lpage><pub-id pub-id-type="pmid">30954779</pub-id>
</element-citation><mixed-citation id="mc-CR57" publication-type="journal">Liesefeld, H. R., &#x00026; M&#x000fc;ller, H. J. (2019). Distractor handling via dimension weighting. <italic>Current Opinion in Psychology,</italic><italic>29</italic>, 160&#x02013;167.<pub-id pub-id-type="pmid">30954779</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR58"><citation-alternatives><element-citation id="ec-CR58" publication-type="journal"><person-group person-group-type="author"><name><surname>Liesefeld</surname><given-names>HR</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>HJ</given-names></name><name><surname>Zehetleitner</surname><given-names>M</given-names></name></person-group><article-title>Search efficiency as a function of target saliency: The transition from inefficient to efficient search and beyond</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2016</year><volume>42</volume><issue>6</issue><fpage>821</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1037/xhp0000156</pub-id><pub-id pub-id-type="pmid">26727018</pub-id>
</element-citation><mixed-citation id="mc-CR58" publication-type="journal">Liesefeld, H. R., Moran, R., Usher, M., M&#x000fc;ller, H. J., &#x00026; Zehetleitner, M. (2016). Search efficiency as a function of target saliency: The transition from inefficient to efficient search and beyond. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>42</italic>(6), 821&#x02013;836. 10.1037/xhp0000156<pub-id pub-id-type="pmid">26727018</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR59"><citation-alternatives><element-citation id="ec-CR59" publication-type="journal"><person-group person-group-type="author"><name><surname>Maffei</surname><given-names>L</given-names></name><name><surname>Fiorentini</surname><given-names>A</given-names></name><name><surname>Bisti</surname><given-names>S</given-names></name></person-group><article-title>Neural correlate of perceptual adaptation to gratings</article-title><source>Science</source><year>1973</year><volume>182</volume><issue>4116</issue><fpage>1036</fpage><lpage>1038</lpage><pub-id pub-id-type="pmid">4748674</pub-id>
</element-citation><mixed-citation id="mc-CR59" publication-type="journal">Maffei, L., Fiorentini, A., &#x00026; Bisti, S. (1973). Neural correlate of perceptual adaptation to gratings. <italic>Science,</italic><italic>182</italic>(4116), 1036&#x02013;1038.<pub-id pub-id-type="pmid">4748674</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR60"><citation-alternatives><element-citation id="ec-CR60" publication-type="journal"><person-group person-group-type="author"><name><surname>Manginelli</surname><given-names>AA</given-names></name><name><surname>Langer</surname><given-names>N</given-names></name><name><surname>Klose</surname><given-names>D</given-names></name><name><surname>Pollmann</surname><given-names>S</given-names></name></person-group><article-title>Contextual cueing under working memory load: Selective interference of visuospatial load with expression of learning</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2013</year><volume>75</volume><fpage>1103</fpage><lpage>1117</lpage></element-citation><mixed-citation id="mc-CR60" publication-type="journal">Manginelli, A. A., Langer, N., Klose, D., &#x00026; Pollmann, S. (2013). Contextual cueing under working memory load: Selective interference of visuospatial load with expression of learning. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>75</italic>, 1103&#x02013;1117.</mixed-citation></citation-alternatives></ref><ref id="CR61"><citation-alternatives><element-citation id="ec-CR61" publication-type="journal"><person-group person-group-type="author"><name><surname>Math&#x000f4;t</surname><given-names>S</given-names></name><name><surname>Schreij</surname><given-names>D</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>OpenSesame: An open-source, graphical experiment builder for the social sciences</article-title><source>Behavior Research Methods</source><year>2012</year><volume>44</volume><issue>2</issue><fpage>314</fpage><lpage>324</lpage><pub-id pub-id-type="pmid">22083660</pub-id>
</element-citation><mixed-citation id="mc-CR61" publication-type="journal">Math&#x000f4;t, S., Schreij, D., &#x00026; Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. <italic>Behavior Research Methods,</italic><italic>44</italic>(2), 314&#x02013;324.<pub-id pub-id-type="pmid">22083660</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR62"><mixed-citation publication-type="other">Meyen, S., Vadillo, M. A., von Luxburg, U., &#x00026; Franz, V. H. (2023). No evidence for contextual cueing beyond explicit recognition. <italic>Psychonomic Bulletin &#x00026; Review</italic>, 1&#x02013;24. 10.3758/s13423-023-02358-3. Advance online publication.</mixed-citation></ref><ref id="CR63"><citation-alternatives><element-citation id="ec-CR63" publication-type="journal"><person-group person-group-type="author"><name><surname>Musz</surname><given-names>E</given-names></name><name><surname>Weber</surname><given-names>MJ</given-names></name><name><surname>Thompson-Schill</surname><given-names>SL</given-names></name></person-group><article-title>Visual statistical learning is not reliably modulated by selective attention to isolated events</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2015</year><volume>77</volume><issue>1</issue><fpage>78</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.3758/s13414-014-0757-5</pub-id></element-citation><mixed-citation id="mc-CR63" publication-type="journal">Musz, E., Weber, M. J., &#x00026; Thompson-Schill, S. L. (2015). Visual statistical learning is not reliably modulated by selective attention to isolated events. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>77</italic>(1), 78&#x02013;96. 10.3758/s13414-014-0757-5</mixed-citation></citation-alternatives></ref><ref id="CR64"><citation-alternatives><element-citation id="ec-CR64" publication-type="journal"><person-group person-group-type="author"><name><surname>Nakayama</surname><given-names>K</given-names></name><name><surname>Silverman</surname><given-names>GH</given-names></name></person-group><article-title>Serial and parallel processing of visual feature conjunctions</article-title><source>Nature</source><year>1986</year><volume>320</volume><issue>6059</issue><fpage>264</fpage><lpage>265</lpage><pub-id pub-id-type="pmid">3960106</pub-id>
</element-citation><mixed-citation id="mc-CR64" publication-type="journal">Nakayama, K., &#x00026; Silverman, G. H. (1986). Serial and parallel processing of visual feature conjunctions. <italic>Nature,</italic><italic>320</italic>(6059), 264&#x02013;265.<pub-id pub-id-type="pmid">3960106</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR65"><citation-alternatives><element-citation id="ec-CR65" publication-type="journal"><person-group person-group-type="author"><name><surname>Ogden</surname><given-names>A</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Anderson</surname><given-names>BA</given-names></name></person-group><article-title>Combined influence of valence and statistical learning on the control of attention II: Evidence from within-domain additivity</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2023</year><volume>85</volume><issue>2</issue><fpage>277</fpage><lpage>283</lpage></element-citation><mixed-citation id="mc-CR65" publication-type="journal">Ogden, A., Kim, H., &#x00026; Anderson, B. A. (2023). Combined influence of valence and statistical learning on the control of attention II: Evidence from within-domain additivity. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>85</italic>(2), 277&#x02013;283.</mixed-citation></citation-alternatives></ref><ref id="CR66"><citation-alternatives><element-citation id="ec-CR66" publication-type="journal"><person-group person-group-type="author"><name><surname>Richter</surname><given-names>D</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><article-title>Statistical learning attenuates visual activity only for attended stimuli</article-title><source>Elife</source><year>2019</year><volume>8</volume><fpage>e47869</fpage><pub-id pub-id-type="pmid">31442202</pub-id>
</element-citation><mixed-citation id="mc-CR66" publication-type="journal">Richter, D., &#x00026; de Lange, F. P. (2019). Statistical learning attenuates visual activity only for attended stimuli. <italic>Elife,</italic><italic>8</italic>, e47869.<pub-id pub-id-type="pmid">31442202</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR67"><citation-alternatives><element-citation id="ec-CR67" publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>JN</given-names></name></person-group><article-title>Optional stopping: No problem for Bayesians</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2014</year><volume>21</volume><fpage>301</fpage><lpage>308</lpage><pub-id pub-id-type="pmid">24659049</pub-id>
</element-citation><mixed-citation id="mc-CR67" publication-type="journal">Rouder, J. N. (2014). Optional stopping: No problem for Bayesians. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>21</italic>, 301&#x02013;308.<pub-id pub-id-type="pmid">24659049</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR68"><citation-alternatives><element-citation id="ec-CR68" publication-type="journal"><person-group person-group-type="author"><name><surname>Saenz</surname><given-names>M</given-names></name><name><surname>Buracas</surname><given-names>GT</given-names></name><name><surname>Boynton</surname><given-names>GM</given-names></name></person-group><article-title>Global effects of feature-based attention in human visual cortex</article-title><source>Nature Neuroscience</source><year>2002</year><volume>5</volume><issue>7</issue><fpage>631</fpage><lpage>632</lpage><pub-id pub-id-type="pmid">12068304</pub-id>
</element-citation><mixed-citation id="mc-CR68" publication-type="journal">Saenz, M., Buracas, G. T., &#x00026; Boynton, G. M. (2002). Global effects of feature-based attention in human visual cortex. <italic>Nature Neuroscience,</italic><italic>5</italic>(7), 631&#x02013;632.<pub-id pub-id-type="pmid">12068304</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR69"><citation-alternatives><element-citation id="ec-CR69" publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><article-title>Statistical learning by 8-month-old infants</article-title><source>Science</source><year>1996</year><volume>274</volume><issue>5294</issue><fpage>1926</fpage><lpage>1928</lpage><pub-id pub-id-type="pmid">8943209</pub-id>
</element-citation><mixed-citation id="mc-CR69" publication-type="journal">Saffran, J. R., Aslin, R. N., &#x00026; Newport, E. L. (1996). Statistical learning by 8-month-old infants. <italic>Science,</italic><italic>274</italic>(5294), 1926&#x02013;1928.<pub-id pub-id-type="pmid">8943209</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR70"><citation-alternatives><element-citation id="ec-CR70" publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Tunick</surname><given-names>RA</given-names></name><name><surname>Barrueco</surname><given-names>S</given-names></name></person-group><article-title>Incidental language learning: Listening (and learning) out of the corner of your ear</article-title><source>Psychological Science</source><year>1997</year><volume>8</volume><issue>2</issue><fpage>101</fpage><lpage>105</lpage></element-citation><mixed-citation id="mc-CR70" publication-type="journal">Saffran, J. R., Newport, E. L., Aslin, R. N., Tunick, R. A., &#x00026; Barrueco, S. (1997). Incidental language learning: Listening (and learning) out of the corner of your ear. <italic>Psychological Science,</italic><italic>8</italic>(2), 101&#x02013;105.</mixed-citation></citation-alternatives></ref><ref id="CR71"><citation-alternatives><element-citation id="ec-CR71" publication-type="journal"><person-group person-group-type="author"><name><surname>Sanborn</surname><given-names>AN</given-names></name><name><surname>Hills</surname><given-names>TT</given-names></name></person-group><article-title>The frequentist implications of optional stopping on Bayesian hypothesis tests</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2014</year><volume>21</volume><fpage>283</fpage><lpage>300</lpage><pub-id pub-id-type="pmid">24101570</pub-id>
</element-citation><mixed-citation id="mc-CR71" publication-type="journal">Sanborn, A. N., &#x00026; Hills, T. T. (2014). The frequentist implications of optional stopping on Bayesian hypothesis tests. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>21</italic>, 283&#x02013;300.<pub-id pub-id-type="pmid">24101570</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR72"><citation-alternatives><element-citation id="ec-CR72" publication-type="journal"><person-group person-group-type="author"><name><surname>Sauter</surname><given-names>M</given-names></name><name><surname>Liesefeld</surname><given-names>HR</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>HJ</given-names></name></person-group><article-title>Learning to suppress salient distractors in the target dimension: Region-based inhibition is persistent and transfers to distractors in a nontarget dimension</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><year>2019</year><volume>45</volume><issue>11</issue><fpage>2080</fpage><lpage>2097</lpage><pub-id pub-id-type="doi">10.1037/xlm0000691</pub-id><pub-id pub-id-type="pmid">30688477</pub-id>
</element-citation><mixed-citation id="mc-CR72" publication-type="journal">Sauter, M., Liesefeld, H. R., &#x00026; M&#x000fc;ller, H. J. (2019). Learning to suppress salient distractors in the target dimension: Region-based inhibition is persistent and transfers to distractors in a nontarget dimension. <italic>Journal of Experimental Psychology: Learning, Memory, and Cognition,</italic><italic>45</italic>(11), 2080&#x02013;2097. 10.1037/xlm0000691<pub-id pub-id-type="pmid">30688477</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR73"><citation-alternatives><element-citation id="ec-CR73" publication-type="journal"><person-group person-group-type="author"><name><surname>Sauter</surname><given-names>M</given-names></name><name><surname>Hanning</surname><given-names>NM</given-names></name><name><surname>Liesefeld</surname><given-names>HR</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>HJ</given-names></name></person-group><article-title>Post-capture processes contribute to statistical learning of distractor locations in visual search</article-title><source>Cortex</source><year>2021</year><volume>135</volume><fpage>108</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2020.11.016</pub-id><pub-id pub-id-type="pmid">33360756</pub-id>
</element-citation><mixed-citation id="mc-CR73" publication-type="journal">Sauter, M., Hanning, N. M., Liesefeld, H. R., &#x00026; M&#x000fc;ller, H. J. (2021). Post-capture processes contribute to statistical learning of distractor locations in visual search. <italic>Cortex,</italic><italic>135</italic>, 108&#x02013;126. 10.1016/j.cortex.2020.11.016<pub-id pub-id-type="pmid">33360756</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR74"><citation-alternatives><element-citation id="ec-CR74" publication-type="journal"><person-group person-group-type="author"><name><surname>Seitz</surname><given-names>W</given-names></name><name><surname>Zinchenko</surname><given-names>A</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>HJ</given-names></name><name><surname>Geyer</surname><given-names>T</given-names></name></person-group><article-title>Contextual cueing of visual search reflects the acquisition of an optimal, one-for-all oculomotor scanning strategy</article-title><source>Communications Psychology</source><year>2023</year><volume>1</volume><issue>1</issue><fpage>20</fpage><pub-id pub-id-type="pmid">39242890</pub-id>
</element-citation><mixed-citation id="mc-CR74" publication-type="journal">Seitz, W., Zinchenko, A., M&#x000fc;ller, H. J., &#x00026; Geyer, T. (2023). Contextual cueing of visual search reflects the acquisition of an optimal, one-for-all oculomotor scanning strategy. <italic>Communications Psychology,</italic><italic>1</italic>(1), 20.<pub-id pub-id-type="pmid">39242890</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR75"><citation-alternatives><element-citation id="ec-CR75" publication-type="journal"><person-group person-group-type="author"><name><surname>Sha</surname><given-names>LZ</given-names></name><name><surname>Remington</surname><given-names>RW</given-names></name><name><surname>Jiang</surname><given-names>YV</given-names></name></person-group><article-title>Short-term and long-term attentional biases to frequently encountered target features</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2017</year><volume>79</volume><fpage>1311</fpage><lpage>1322</lpage></element-citation><mixed-citation id="mc-CR75" publication-type="journal">Sha, L. Z., Remington, R. W., &#x00026; Jiang, Y. V. (2017). Short-term and long-term attentional biases to frequently encountered target features. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>79</italic>, 1311&#x02013;1322.</mixed-citation></citation-alternatives></ref><ref id="CR76"><citation-alternatives><element-citation id="ec-CR76" publication-type="journal"><person-group person-group-type="author"><name><surname>Stilwell</surname><given-names>BT</given-names></name><name><surname>Gaspelin</surname><given-names>N</given-names></name></person-group><article-title>Attentional suppression of highly salient color singletons</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2021</year><volume>47</volume><issue>10</issue><fpage>1313</fpage><pub-id pub-id-type="pmid">34766817</pub-id>
</element-citation><mixed-citation id="mc-CR76" publication-type="journal">Stilwell, B. T., &#x00026; Gaspelin, N. (2021). Attentional suppression of highly salient color singletons. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>47</italic>(10), 1313.<pub-id pub-id-type="pmid">34766817</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR77"><citation-alternatives><element-citation id="ec-CR77" publication-type="journal"><person-group person-group-type="author"><name><surname>Stilwell</surname><given-names>BT</given-names></name><name><surname>Bahle</surname><given-names>B</given-names></name><name><surname>Vecera</surname><given-names>SP</given-names></name></person-group><article-title>Feature-based statistical regularities of distractors modulate attentional capture</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2019</year><volume>45</volume><issue>3</issue><fpage>419</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1037/xhp0000613</pub-id><pub-id pub-id-type="pmid">30802131</pub-id>
</element-citation><mixed-citation id="mc-CR77" publication-type="journal">Stilwell, B. T., Bahle, B., &#x00026; Vecera, S. P. (2019). Feature-based statistical regularities of distractors modulate attentional capture. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>45</italic>(3), 419&#x02013;433. 10.1037/xhp0000613<pub-id pub-id-type="pmid">30802131</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR78"><citation-alternatives><element-citation id="ec-CR78" publication-type="journal"><person-group person-group-type="author"><name><surname>St&#x000f6;rmer</surname><given-names>VS</given-names></name><name><surname>Alvarez</surname><given-names>GA</given-names></name></person-group><article-title>Feature-based attention elicits surround suppression in feature space</article-title><source>Current Biology</source><year>2014</year><volume>24</volume><issue>17</issue><fpage>1985</fpage><lpage>1988</lpage><pub-id pub-id-type="pmid">25155510</pub-id>
</element-citation><mixed-citation id="mc-CR78" publication-type="journal">St&#x000f6;rmer, V. S., &#x00026; Alvarez, G. A. (2014). Feature-based attention elicits surround suppression in feature space. <italic>Current Biology,</italic><italic>24</italic>(17), 1985&#x02013;1988.<pub-id pub-id-type="pmid">25155510</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR79"><citation-alternatives><element-citation id="ec-CR79" publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Top-down search strategies cannot override attentional capture</article-title><source>Psychonomic Bulletin and Review</source><year>2004</year><volume>11</volume><issue>1</issue><fpage>65</fpage><lpage>70</lpage><pub-id pub-id-type="pmid">15116988</pub-id>
</element-citation><mixed-citation id="mc-CR79" publication-type="journal">Theeuwes, J. (2004). Top-down search strategies cannot override attentional capture. <italic>Psychonomic Bulletin and Review,</italic><italic>11</italic>(1), 65&#x02013;70.<pub-id pub-id-type="pmid">15116988</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR80"><citation-alternatives><element-citation id="ec-CR80" publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Visual selection: Usually fast and automatic; seldom slow and volitional</article-title><source>Journal of Cognition</source><year>2018</year><volume>1</volume><issue>1</issue><fpage>29</fpage><pub-id pub-id-type="doi">10.5334/joc.13</pub-id><pub-id pub-id-type="pmid">31517202</pub-id>
</element-citation><mixed-citation id="mc-CR80" publication-type="journal">Theeuwes, J. (2018). Visual selection: Usually fast and automatic; seldom slow and volitional. <italic>Journal of Cognition,</italic><italic>1</italic>(1), 29. 10.5334/joc.13<pub-id pub-id-type="pmid">31517202</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR81"><citation-alternatives><element-citation id="ec-CR81" publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Goal-driven, stimulus-driven, and history-driven selection</article-title><source>Current Opinion in Psychology</source><year>2019</year><volume>29</volume><fpage>97</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.copsyc.2018.12.024</pub-id><pub-id pub-id-type="pmid">30711911</pub-id>
</element-citation><mixed-citation id="mc-CR81" publication-type="journal">Theeuwes, J. (2019). Goal-driven, stimulus-driven, and history-driven selection. <italic>Current Opinion in Psychology,</italic><italic>29</italic>, 97&#x02013;101. 10.1016/j.copsyc.2018.12.024<pub-id pub-id-type="pmid">30711911</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR82"><mixed-citation publication-type="other">Theeuwes, J. (2023). The attentional capture debate: When can we avoid salient distractors and when not? <italic>Journal of Cognition</italic>.10.5334/joc.251</mixed-citation></ref><ref id="CR83"><citation-alternatives><element-citation id="ec-CR83" publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name><name><surname>Belopolsky</surname><given-names>A</given-names></name><name><surname>Olivers</surname><given-names>CNL</given-names></name></person-group><article-title>Interactions between working memory, attention and eye movements</article-title><source>Acta Psychologica</source><year>2009</year><volume>132</volume><issue>2</issue><fpage>106</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.actpsy.2009.01.005</pub-id><pub-id pub-id-type="pmid">19233340</pub-id>
</element-citation><mixed-citation id="mc-CR83" publication-type="journal">Theeuwes, J., Belopolsky, A., &#x00026; Olivers, C. N. L. (2009). Interactions between working memory, attention and eye movements. <italic>Acta Psychologica,</italic><italic>132</italic>(2), 106&#x02013;114. 10.1016/j.actpsy.2009.01.005<pub-id pub-id-type="pmid">19233340</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR84"><citation-alternatives><element-citation id="ec-CR84" publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J</given-names></name><name><surname>Bogaerts</surname><given-names>L</given-names></name><name><surname>van Moorselaar</surname><given-names>D</given-names></name></person-group><article-title>What to expect where and when: How statistical learning drives visual selection</article-title><source>Trends in Cognitive Sciences.</source><year>2022</year><volume>26</volume><issue>10</issue><fpage>860</fpage><lpage>872</lpage><pub-id pub-id-type="pmid">35840476</pub-id>
</element-citation><mixed-citation id="mc-CR84" publication-type="journal">Theeuwes, J., Bogaerts, L., &#x00026; van Moorselaar, D. (2022). What to expect where and when: How statistical learning drives visual selection. <italic>Trends in Cognitive Sciences.,</italic><italic>26</italic>(10), 860&#x02013;872.<pub-id pub-id-type="pmid">35840476</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR85"><citation-alternatives><element-citation id="ec-CR85" publication-type="journal"><person-group person-group-type="author"><name><surname>Toro</surname><given-names>JM</given-names></name><name><surname>Sinnett</surname><given-names>S</given-names></name><name><surname>Soto-Faraco</surname><given-names>S</given-names></name></person-group><article-title>Speech segmentation by statistical learning depends on attention</article-title><source>Cognition</source><year>2005</year><volume>97</volume><issue>2</issue><fpage>B25</fpage><lpage>B34</lpage><pub-id pub-id-type="pmid">16226557</pub-id>
</element-citation><mixed-citation id="mc-CR85" publication-type="journal">Toro, J. M., Sinnett, S., &#x00026; Soto-Faraco, S. (2005). Speech segmentation by statistical learning depends on attention. <italic>Cognition,</italic><italic>97</italic>(2), B25&#x02013;B34.<pub-id pub-id-type="pmid">16226557</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR86"><citation-alternatives><element-citation id="ec-CR86" publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>A</given-names></name><name><surname>Sato</surname><given-names>S</given-names></name></person-group><article-title>Conjunction search revisited</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>1990</year><volume>16</volume><issue>3</issue><fpage>459</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.16.3.459</pub-id><pub-id pub-id-type="pmid">2144564</pub-id>
</element-citation><mixed-citation id="mc-CR86" publication-type="journal">Treisman, A., &#x00026; Sato, S. (1990). Conjunction search revisited. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>16</italic>(3), 459&#x02013;478. 10.1037/0096-1523.16.3.459<pub-id pub-id-type="pmid">2144564</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR87"><citation-alternatives><element-citation id="ec-CR87" publication-type="journal"><person-group person-group-type="author"><name><surname>Treue</surname><given-names>S</given-names></name><name><surname>Trujillo</surname><given-names>JCM</given-names></name></person-group><article-title>Feature-based attention influences motion processing gain in macaque visual cortex</article-title><source>Nature</source><year>1999</year><volume>399</volume><issue>6736</issue><fpage>575</fpage><lpage>579</lpage><pub-id pub-id-type="pmid">10376597</pub-id>
</element-citation><mixed-citation id="mc-CR87" publication-type="journal">Treue, S., &#x00026; Trujillo, J. C. M. (1999). Feature-based attention influences motion processing gain in macaque visual cortex. <italic>Nature,</italic><italic>399</italic>(6736), 575&#x02013;579.<pub-id pub-id-type="pmid">10376597</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR88"><citation-alternatives><element-citation id="ec-CR88" publication-type="journal"><person-group person-group-type="author"><name><surname>Turatto</surname><given-names>M</given-names></name><name><surname>Bonetti</surname><given-names>F</given-names></name><name><surname>Pascucci</surname><given-names>D</given-names></name><name><surname>Chelazzi</surname><given-names>L</given-names></name></person-group><article-title>Desensitizing the attention system to distraction while idling: A new latent learning phenomenon in the visual attention domain</article-title><source>Journal of Experimental Psychology: General</source><year>2018</year><volume>147</volume><issue>12</issue><fpage>1827</fpage><lpage>1850</lpage><pub-id pub-id-type="doi">10.1037/xge0000503</pub-id><pub-id pub-id-type="pmid">30359073</pub-id>
</element-citation><mixed-citation id="mc-CR88" publication-type="journal">Turatto, M., Bonetti, F., Pascucci, D., &#x00026; Chelazzi, L. (2018). Desensitizing the attention system to distraction while idling: A new latent learning phenomenon in the visual attention domain. <italic>Journal of Experimental Psychology: General,</italic><italic>147</italic>(12), 1827&#x02013;1850. 10.1037/xge0000503<pub-id pub-id-type="pmid">30359073</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR89"><citation-alternatives><element-citation id="ec-CR89" publication-type="book"><person-group person-group-type="author"><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Dodd</surname><given-names>MD</given-names></name><name><surname>Flowers</surname><given-names>JH</given-names></name></person-group><article-title>Statistical learning and its consequences</article-title><source>The influence of attention, learning, and motivation on visual search</source><year>2012</year><publisher-name>Springer Business</publisher-name><fpage>117</fpage><lpage>146</lpage></element-citation><mixed-citation id="mc-CR89" publication-type="book">Turk-Browne, N. B. (2012). Statistical learning and its consequences. In M. D. Dodd &#x00026; J. H. Flowers (Eds.), <italic>The influence of attention, learning, and motivation on visual search</italic> (pp. 117&#x02013;146). Springer Business.</mixed-citation></citation-alternatives></ref><ref id="CR90"><citation-alternatives><element-citation id="ec-CR90" publication-type="journal"><person-group person-group-type="author"><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Jung&#x000e9;</surname><given-names>JA</given-names></name><name><surname>Scholl</surname><given-names>BJ</given-names></name></person-group><article-title>The automaticity of visual statistical learning</article-title><source>Journal of Experimental Psychology: General</source><year>2005</year><volume>134</volume><issue>4</issue><fpage>552</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.134.4.552</pub-id><pub-id pub-id-type="pmid">16316291</pub-id>
</element-citation><mixed-citation id="mc-CR90" publication-type="journal">Turk-Browne, N. B., Jung&#x000e9;, J. A., &#x00026; Scholl, B. J. (2005). The automaticity of visual statistical learning. <italic>Journal of Experimental Psychology: General,</italic><italic>134</italic>(4), 552&#x02013;564. 10.1037/0096-3445.134.4.552<pub-id pub-id-type="pmid">16316291</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR91"><citation-alternatives><element-citation id="ec-CR91" publication-type="journal"><person-group person-group-type="author"><name><surname>Vadillo</surname><given-names>MA</given-names></name><name><surname>Gim&#x000e9;nez-Fern&#x000e1;ndez</surname><given-names>T</given-names></name><name><surname>Aivar</surname><given-names>MP</given-names></name><name><surname>Cubillas</surname><given-names>CP</given-names></name></person-group><article-title>Ignored visual context does not induce latent learning</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2020</year><volume>27</volume><issue>3</issue><fpage>512</fpage><lpage>519</lpage><pub-id pub-id-type="doi">10.3758/s13423-020-01722-x</pub-id><pub-id pub-id-type="pmid">32162205</pub-id>
</element-citation><mixed-citation id="mc-CR91" publication-type="journal">Vadillo, M. A., Gim&#x000e9;nez-Fern&#x000e1;ndez, T., Aivar, M. P., &#x00026; Cubillas, C. P. (2020). Ignored visual context does not induce latent learning. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>27</italic>(3), 512&#x02013;519. 10.3758/s13423-020-01722-x<pub-id pub-id-type="pmid">32162205</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR92"><citation-alternatives><element-citation id="ec-CR92" publication-type="journal"><person-group person-group-type="author"><name><surname>van Moorselaar</surname><given-names>D</given-names></name><name><surname>Slagter</surname><given-names>HA</given-names></name></person-group><article-title>Learning what is irrelevant or relevant: Expectations facilitate distractor inhibition and target facilitation through distinct neural mechanisms</article-title><source>Journal of Neuroscience</source><year>2019</year><volume>39</volume><issue>35</issue><fpage>6953</fpage><lpage>6967</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0593-19.2019</pub-id><pub-id pub-id-type="pmid">31270162</pub-id>
</element-citation><mixed-citation id="mc-CR92" publication-type="journal">van Moorselaar, D., &#x00026; Slagter, H. A. (2019). Learning what is irrelevant or relevant: Expectations facilitate distractor inhibition and target facilitation through distinct neural mechanisms. <italic>Journal of Neuroscience,</italic><italic>39</italic>(35), 6953&#x02013;6967. 10.1523/JNEUROSCI.0593-19.2019<pub-id pub-id-type="pmid">31270162</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR93"><citation-alternatives><element-citation id="ec-CR93" publication-type="journal"><person-group person-group-type="author"><name><surname>van Moorselaar</surname><given-names>D</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Spatial suppression due to statistical regularities in a visual detection task</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2022</year><volume>84</volume><issue>2</issue><fpage>450</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.3758/s13414-021-02330-0</pub-id></element-citation><mixed-citation id="mc-CR93" publication-type="journal">van Moorselaar, D., &#x00026; Theeuwes, J. (2022). Spatial suppression due to statistical regularities in a visual detection task. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>84</italic>(2), 450&#x02013;458. 10.3758/s13414-021-02330-0</mixed-citation></citation-alternatives></ref><ref id="CR94"><citation-alternatives><element-citation id="ec-CR94" publication-type="journal"><person-group person-group-type="author"><name><surname>van Moorselaar</surname><given-names>D</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Statistical learning within objects</article-title><source>Psychological Science</source><year>2023</year><volume>34</volume><issue>4</issue><fpage>501</fpage><lpage>511</lpage><pub-id pub-id-type="doi">10.1177/09567976231154804</pub-id><pub-id pub-id-type="pmid">36882101</pub-id>
</element-citation><mixed-citation id="mc-CR94" publication-type="journal">van Moorselaar, D., &#x00026; Theeuwes, J. (2023). Statistical learning within objects. <italic>Psychological Science,</italic><italic>34</italic>(4), 501&#x02013;511. 10.1177/09567976231154804<pub-id pub-id-type="pmid">36882101</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR95"><mixed-citation publication-type="other">van Moorselaar, D., &#x00026; Theeuwes, J. (2024). Spatial transfer of object-based statistical learning. <italic>Attention, Perception, &#x00026; Psychophysics</italic>, 1&#x02013;8. Advance online publication. 10.3758/s13414-024-02852-3. Advance online publication.</mixed-citation></ref><ref id="CR96"><citation-alternatives><element-citation id="ec-CR96" publication-type="journal"><person-group person-group-type="author"><name><surname>van Moorselaar</surname><given-names>D</given-names></name><name><surname>Lampers</surname><given-names>E</given-names></name><name><surname>Cordesius</surname><given-names>E</given-names></name><name><surname>Slagter</surname><given-names>HA</given-names></name></person-group><article-title>Neural mechanisms underlying expectation-dependent inhibition of distracting information</article-title><source>Elife</source><year>2020</year><volume>9</volume><fpage>e61048</fpage><pub-id pub-id-type="pmid">33320084</pub-id>
</element-citation><mixed-citation id="mc-CR96" publication-type="journal">van Moorselaar, D., Lampers, E., Cordesius, E., &#x00026; Slagter, H. A. (2020). Neural mechanisms underlying expectation-dependent inhibition of distracting information. <italic>Elife,</italic><italic>9</italic>, e61048.<pub-id pub-id-type="pmid">33320084</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR97"><citation-alternatives><element-citation id="ec-CR97" publication-type="journal"><person-group person-group-type="author"><name><surname>Vautin</surname><given-names>R</given-names></name><name><surname>Berkley</surname><given-names>M</given-names></name></person-group><article-title>Responses of single cells in cat visual cortex to prolonged stimulus movement: Neural correlates of visual aftereffects</article-title><source>Journal of Neurophysiology</source><year>1977</year><volume>40</volume><issue>5</issue><fpage>1051</fpage><lpage>1065</lpage><pub-id pub-id-type="pmid">903797</pub-id>
</element-citation><mixed-citation id="mc-CR97" publication-type="journal">Vautin, R., &#x00026; Berkley, M. (1977). Responses of single cells in cat visual cortex to prolonged stimulus movement: Neural correlates of visual aftereffects. <italic>Journal of Neurophysiology,</italic><italic>40</italic>(5), 1051&#x02013;1065.<pub-id pub-id-type="pmid">903797</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR98"><citation-alternatives><element-citation id="ec-CR98" publication-type="journal"><person-group person-group-type="author"><name><surname>Vickery</surname><given-names>TJ</given-names></name><name><surname>Sussman</surname><given-names>RS</given-names></name><name><surname>Jiang</surname><given-names>YV</given-names></name></person-group><article-title>Spatial context learning survives interference from working memory load</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2010</year><volume>36</volume><issue>6</issue><fpage>1358</fpage><lpage>1371</lpage><pub-id pub-id-type="doi">10.1037/a0020558</pub-id><pub-id pub-id-type="pmid">20853996</pub-id>
</element-citation><mixed-citation id="mc-CR98" publication-type="journal">Vickery, T. J., Sussman, R. S., &#x00026; Jiang, Y. V. (2010). Spatial context learning survives interference from working memory load. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>36</italic>(6), 1358&#x02013;1371. 10.1037/a0020558<pub-id pub-id-type="pmid">20853996</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR99"><mixed-citation publication-type="other">Wagenmakers, E.-J., Love, J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., ..., &#x00026; Boutin, B. (2018). Bayesian inference for psychology. Part II: Example applications with JASP. <italic>Psychonomic Bulletin &#x00026; Review</italic>, <italic>25</italic>, 58&#x02013;76.</mixed-citation></ref><ref id="CR100"><citation-alternatives><element-citation id="ec-CR100" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Statistical regularities modulate attentional capture</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2018</year><volume>44</volume><issue>1</issue><fpage>13</fpage><lpage>17</lpage><pub-id pub-id-type="pmid">29309194</pub-id>
</element-citation><mixed-citation id="mc-CR100" publication-type="journal">Wang, B., &#x00026; Theeuwes, J. (2018a). Statistical regularities modulate attentional capture. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>44</italic>(1), 13&#x02013;17.<pub-id pub-id-type="pmid">29309194</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR101"><citation-alternatives><element-citation id="ec-CR101" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Statistical regularities modulate attentional capture independent of search strategy</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2018</year><volume>80</volume><fpage>1763</fpage><lpage>1774</lpage></element-citation><mixed-citation id="mc-CR101" publication-type="journal">Wang, B., &#x00026; Theeuwes, J. (2018b). Statistical regularities modulate attentional capture independent of search strategy. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>80</italic>, 1763&#x02013;1774.</mixed-citation></citation-alternatives></ref><ref id="CR102"><citation-alternatives><element-citation id="ec-CR102" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Salience determines attentional orienting in visual selection</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2020</year><volume>46</volume><issue>10</issue><fpage>1051</fpage><lpage>1057</lpage><pub-id pub-id-type="doi">10.1037/xhp0000796</pub-id><pub-id pub-id-type="pmid">32757594</pub-id>
</element-citation><mixed-citation id="mc-CR102" publication-type="journal">Wang, B., &#x00026; Theeuwes, J. (2020). Salience determines attentional orienting in visual selection. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>46</italic>(10), 1051&#x02013;1057. 10.1037/xhp0000796<pub-id pub-id-type="pmid">32757594</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR103"><citation-alternatives><element-citation id="ec-CR103" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Samara</surname><given-names>I</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><article-title>Statistical regularities bias overt attention</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2019</year><volume>81</volume><issue>6</issue><fpage>1813</fpage><lpage>1821</lpage><pub-id pub-id-type="doi">10.3758/s13414-019-01708-5</pub-id></element-citation><mixed-citation id="mc-CR103" publication-type="journal">Wang, B., Samara, I., &#x00026; Theeuwes, J. (2019). Statistical regularities bias overt attention. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>81</italic>(6), 1813&#x02013;1821. 10.3758/s13414-019-01708-5</mixed-citation></citation-alternatives></ref><ref id="CR104"><citation-alternatives><element-citation id="ec-CR104" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Cong</surname><given-names>SH</given-names></name><name><surname>Woodman</surname><given-names>GF</given-names></name></person-group><article-title>Statistical learning speeds visual search: More efficient selection, or faster response?</article-title><source>Journal of Experimental Psychology: General</source><year>2023</year><volume>152</volume><issue>6</issue><fpage>1723</fpage><lpage>1734</lpage><pub-id pub-id-type="doi">10.1037/xge0001353</pub-id><pub-id pub-id-type="pmid">36701525</pub-id>
</element-citation><mixed-citation id="mc-CR104" publication-type="journal">Wang, S., Cong, S. H., &#x00026; Woodman, G. F. (2023). Statistical learning speeds visual search: More efficient selection, or faster response? <italic>Journal of Experimental Psychology: General,</italic><italic>152</italic>(6), 1723&#x02013;1734. 10.1037/xge0001353<pub-id pub-id-type="pmid">36701525</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR105"><citation-alternatives><element-citation id="ec-CR105" publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname><given-names>JM</given-names></name></person-group><article-title>Guided Search 2.0: A revised model of visual search</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>1994</year><volume>1</volume><issue>2</issue><fpage>202</fpage><lpage>238</lpage><pub-id pub-id-type="pmid">24203471</pub-id>
</element-citation><mixed-citation id="mc-CR105" publication-type="journal">Wolfe, J. M. (1994). Guided Search 2.0: A revised model of visual search. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>1</italic>(2), 202&#x02013;238.<pub-id pub-id-type="pmid">24203471</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR106"><citation-alternatives><element-citation id="ec-CR106" publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname><given-names>JM</given-names></name></person-group><article-title>Guided Search 6.0: An updated model of visual search</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2021</year><volume>28</volume><issue>4</issue><fpage>1060</fpage><lpage>1092</lpage><pub-id pub-id-type="pmid">33547630</pub-id>
</element-citation><mixed-citation id="mc-CR106" publication-type="journal">Wolfe, J. M. (2021). Guided Search 6.0: An updated model of visual search. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>28</italic>(4), 1060&#x02013;1092.<pub-id pub-id-type="pmid">33547630</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR107"><citation-alternatives><element-citation id="ec-CR107" publication-type="journal"><person-group person-group-type="author"><name><surname>Won</surname><given-names>B-Y</given-names></name><name><surname>Jiang</surname><given-names>YV</given-names></name></person-group><article-title>Spatial working memory interferes with explicit, but not probabilistic cuing of spatial attention</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><year>2015</year><volume>41</volume><issue>3</issue><fpage>787</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1037/xlm0000040</pub-id><pub-id pub-id-type="pmid">25401460</pub-id>
</element-citation><mixed-citation id="mc-CR107" publication-type="journal">Won, B.-Y., &#x00026; Jiang, Y. V. (2015). Spatial working memory interferes with explicit, but not probabilistic cuing of spatial attention. <italic>Journal of Experimental Psychology: Learning, Memory, and Cognition,</italic><italic>41</italic>(3), 787&#x02013;806. 10.1037/xlm0000040<pub-id pub-id-type="pmid">25401460</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR108"><citation-alternatives><element-citation id="ec-CR108" publication-type="journal"><person-group person-group-type="author"><name><surname>Won</surname><given-names>B-Y</given-names></name><name><surname>Geng</surname><given-names>JJ</given-names></name></person-group><article-title>Passive exposure attenuates distraction during visual search</article-title><source>Journal of Experimental Psychology: General</source><year>2020</year><volume>149</volume><issue>10</issue><fpage>1987</fpage><lpage>1995</lpage><pub-id pub-id-type="pmid">32250138</pub-id>
</element-citation><mixed-citation id="mc-CR108" publication-type="journal">Won, B.-Y., &#x00026; Geng, J. J. (2020). Passive exposure attenuates distraction during visual search. <italic>Journal of Experimental Psychology: General,</italic><italic>149</italic>(10), 1987&#x02013;1995.<pub-id pub-id-type="pmid">32250138</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>