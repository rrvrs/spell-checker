<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Med Internet Res</journal-id><journal-id journal-id-type="iso-abbrev">J Med Internet Res</journal-id><journal-id journal-id-type="publisher-id">JMIR</journal-id><journal-title-group><journal-title>Journal of Medical Internet Research</journal-title></journal-title-group><issn pub-type="ppub">1439-4456</issn><issn pub-type="epub">1438-8871</issn><publisher><publisher-name>JMIR Publications</publisher-name><publisher-loc>Toronto, Canada</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39671571</article-id><article-id pub-id-type="pmc">PMC11681292</article-id><article-id pub-id-type="publisher-id">v26i1e51409</article-id><article-id pub-id-type="doi">10.2196/51409</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group><subj-group subj-group-type="article-type"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>Longitudinal Model Shifts of Machine Learning&#x02013;Based Clinical Risk Prediction Models: Evaluation Study of Multiple Use Cases Across Different Hospitals</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>de Azevedo Cardoso</surname><given-names>Taiane</given-names></name></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Duan</surname><given-names>Shao-Bin</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Ghasemi</surname><given-names>Peyman</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Mayampurath</surname><given-names>Anoop</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Rosenberg</surname><given-names>Michael</given-names></name></contrib></contrib-group><contrib-group><contrib id="contrib1" contrib-type="author" equal-contrib="yes"><name><surname>Cabanillas Silva</surname><given-names>Patricia</given-names></name><degrees>MSc</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7509-721X</contrib-id></contrib><contrib id="contrib2" contrib-type="author" equal-contrib="yes"><name><surname>Sun</surname><given-names>Hong</given-names></name><degrees>PhD</degrees><xref rid="aff2" ref-type="aff">2</xref><xref rid="aff3" ref-type="aff">3</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7112-5420</contrib-id></contrib><contrib id="contrib3" contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Rezk</surname><given-names>Mohamed</given-names></name><degrees>PhD</degrees><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1866-8645</contrib-id><xref rid="aff1" ref-type="aff">1</xref><address><institution>Dedalus HealthCare</institution><addr-line>Roderveldlaan 2</addr-line><addr-line>Antwerp, 2600</addr-line><country>Belgium</country><phone>32 0784244010</phone><email>mohamed.rezk@dedalus.com</email></address></contrib><contrib id="contrib4" contrib-type="author"><name><surname>Roccaro-Waldmeyer</surname><given-names>Diana M</given-names></name><degrees>PhD</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-4401-1567</contrib-id></contrib><contrib id="contrib5" contrib-type="author"><name><surname>Fliegenschmidt</surname><given-names>Janis</given-names></name><degrees>BSc, MD</degrees><xref rid="aff4" ref-type="aff">4</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7396-5677</contrib-id></contrib><contrib id="contrib6" contrib-type="author"><name><surname>Hulde</surname><given-names>Nikolai</given-names></name><degrees>MD, PhD</degrees><xref rid="aff4" ref-type="aff">4</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5070-0249</contrib-id></contrib><contrib id="contrib7" contrib-type="author"><name><surname>von Dossow</surname><given-names>Vera</given-names></name><degrees>MD, PhD, Prof Dr</degrees><xref rid="aff4" ref-type="aff">4</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2540-7080</contrib-id></contrib><contrib id="contrib8" contrib-type="author"><name><surname>Meesseman</surname><given-names>Laurent</given-names></name><degrees>MD</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3761-9822</contrib-id></contrib><contrib id="contrib9" contrib-type="author"><name><surname>Depraetere</surname><given-names>Kristof</given-names></name><degrees>MSc</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3859-3791</contrib-id></contrib><contrib id="contrib10" contrib-type="author"><name><surname>Stieg</surname><given-names>Joerg</given-names></name><degrees>MSc</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-2128-4017</contrib-id></contrib><contrib id="contrib11" contrib-type="author"><name><surname>Szymanowsky</surname><given-names>Ralph</given-names></name><degrees>MSc</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3765-5794</contrib-id></contrib><contrib id="contrib12" contrib-type="author"><name><surname>Dahlweid</surname><given-names>Fried-Michael</given-names></name><degrees>MD, PhD</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5416-9915</contrib-id></contrib></contrib-group><aff id="aff1">
<label>1</label>
<institution>Dedalus HealthCare</institution>
<addr-line>Antwerp</addr-line>
<country>Belgium</country>
</aff><aff id="aff2">
<label>2</label>
<institution>Provincial Key Laboratory of Multimodal Perceiving and Intelligent Systems</institution>
<institution>Jiaxing University</institution>
<addr-line>Jiaxing</addr-line>
<country>China</country>
</aff><aff id="aff3">
<label>3</label>
<institution>Engineering Research Center of Intelligent Human Health Situation Awareness of Zhejiang Province</institution>
<institution>Jiaxing University</institution>
<addr-line>Jiaxing</addr-line>
<country>China</country>
</aff><aff id="aff4">
<label>4</label>
<institution>Institute of Anaesthesiology and Pain Therapy</institution>
<institution>Heart and Diabetes Centre North Rhine Westphalia</institution>
<institution>University Hospital of Ruhr-University Bochum</institution>
<addr-line>Bad Oeynhausen</addr-line>
<country>Germany</country>
</aff><author-notes><corresp>Corresponding Author: Mohamed Rezk <email>mohamed.rezk@dedalus.com</email></corresp></author-notes><pub-date pub-type="collection"><year>2024</year></pub-date><pub-date pub-type="epub"><day>13</day><month>12</month><year>2024</year></pub-date><volume>26</volume><elocation-id>e51409</elocation-id><history><date date-type="received"><day>3</day><month>8</month><year>2023</year></date><date date-type="rev-request"><day>5</day><month>11</month><year>2023</year></date><date date-type="rev-recd"><day>30</day><month>1</month><year>2024</year></date><date date-type="accepted"><day>16</day><month>10</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9;Patricia Cabanillas Silva, Hong Sun, Mohamed Rezk, Diana M Roccaro-Waldmeyer, Janis Fliegenschmidt, Nikolai Hulde, Vera von Dossow, Laurent Meesseman, Kristof Depraetere, Joerg Stieg, Ralph Szymanowsky, Fried-Michael Dahlweid. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 13.12.2024.</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link xlink:href="https://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research (ISSN 1438-8871), is properly cited. The complete bibliographic information, a link to the original publication on <ext-link xlink:href="https://www.jmir.org/" ext-link-type="uri">https://www.jmir.org/</ext-link>, as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:href="https://www.jmir.org/2024/1/e51409"/><abstract><sec sec-type="background"><title>Background</title><p>In recent years, machine learning (ML)&#x02013;based models have been widely used in clinical domains to predict clinical risk events. However, in production, the performances of such models heavily rely on changes in the system and data. The dynamic nature of the system environment, characterized by continuous changes, has significant implications for prediction models, leading to performance degradation and reduced clinical efficacy. Thus, monitoring model shifts and evaluating their impact on prediction models are of utmost importance.</p></sec><sec sec-type="objective"><title>Objective</title><p>This study aimed to assess the impact of a model shift on ML-based prediction models by evaluating 3 different use cases&#x02014;delirium, sepsis, and acute kidney injury (AKI)&#x02014;from 2 hospitals (M and H) with different patient populations and investigate potential model deterioration during the COVID-19 pandemic period.</p></sec><sec sec-type="methods"><title>Methods</title><p>We trained prediction models using retrospective data from earlier years and examined the presence of a model shift using data from more recent years. We used the area under the receiver operating characteristic curve (AUROC) to evaluate model performance and analyzed the calibration curves over time. We also assessed the influence on clinical decisions by evaluating the alert rate, the rates of over- and underdiagnosis, and the decision curve.</p></sec><sec sec-type="results"><title>Results</title><p>The 2 data sets used in this study contained 189,775 and 180,976 medical cases for hospitals M and H, respectively. Statistical analyses (<italic>Z</italic> test) revealed no significant difference (<italic>P</italic>&#x0003e;.05) between the AUROCs from the different years for all use cases and hospitals. For example, in hospital M, AKI did not show a significant difference between 2020 (AUROC=0.898) and 2021 (AUROC=0.907, Z=&#x02013;1.171, <italic>P</italic>=.242). Similar results were observed in both hospitals and for all use cases (sepsis and delirium) when comparing all the different years. However, when evaluating the calibration curves at the 2 hospitals, model shifts were observed for the delirium and sepsis use cases but not for AKI. Additionally, to investigate the clinical utility of our models, we performed decision curve analysis (DCA) and compared the results across the different years. A pairwise nonparametric statistical comparison showed no differences in the net benefit at the probability thresholds of interest (<italic>P</italic>&#x0003e;.05). The comprehensive evaluations performed in this study ensured robust model performance of all the investigated models across the years. Moreover, neither performance deteriorations nor alert surges were observed during the COVID-19 pandemic period.</p></sec><sec sec-type="conclusions"><title>Conclusions</title><p>Clinical risk prediction models were affected by the dynamic and continuous evolution of clinical practices and workflows. The performance of the models evaluated in this study appeared stable when assessed using AUROCs, showing no significant variations over the years. Additional model shift investigations suggested that a calibration shift was present for certain use cases (delirium and sepsis). However, these changes did not have any impact on the clinical utility of the models based on DCA. Consequently, it is crucial to closely monitor data changes and detect possible model shifts, along with their potential influence on clinical decision-making.</p></sec></abstract><kwd-group><kwd>model shift</kwd><kwd>model monitoring</kwd><kwd>prediction models</kwd><kwd>acute kidney injury</kwd><kwd>AKI</kwd><kwd>sepsis</kwd><kwd>delirium</kwd><kwd>decision curve analysis</kwd><kwd>DCA</kwd></kwd-group></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><p>In recent years, machine learning (ML) algorithms for clinical risk predictions have emerged as a promising tool and have been widely used in health care applications [<xref rid="ref1" ref-type="bibr">1</xref>-<xref rid="ref5" ref-type="bibr">5</xref>]. However, most of such applications have been developed and evaluated on retrospective data [<xref rid="ref6" ref-type="bibr">6</xref>,<xref rid="ref7" ref-type="bibr">7</xref>], and their performance in live clinical settings remains understudied.</p><p>Wu et al [<xref rid="ref8" ref-type="bibr">8</xref>] highlighted the importance of evaluating artificial intelligence (AI)&#x02013;based medical devices with live clinical settings over different sites to address the shortcomings, such as overfitting to training data and bias against underrepresented subgroups. The evaluation of models&#x02019; performances in live clinical settings is drawing more attention and is becoming more adopted in the field [<xref rid="ref9" ref-type="bibr">9</xref>,<xref rid="ref10" ref-type="bibr">10</xref>]. In our previous paper, we investigated clinical risk prediction models for heterogeneous patient populations from different hospitals and across different clinical use cases: delirium, sepsis, and acute kidney injury (AKI). By evaluating these models in both retrospective [<xref rid="ref7" ref-type="bibr">7</xref>] and live clinical settings [<xref rid="ref11" ref-type="bibr">11</xref>], we demonstrated that the diversity in patient populations translates into improved generalizability and a more comprehensive understanding [<xref rid="ref11" ref-type="bibr">11</xref>]. A cohort study was also carried out to evaluate the clinical usefulness of our delirium prediction model [<xref rid="ref12" ref-type="bibr">12</xref>]. These results led to a later review to conclude that our approach demonstrates the best clinical utility and highest performance when evaluated beyond the development setting [<xref rid="ref13" ref-type="bibr">13</xref>].</p><p>However, even when evaluated in clinical settings, there remains a critical challenge that poses a significant threat to the reliability and performance of these models, which is the phenomenon of model shift [<xref rid="ref14" ref-type="bibr">14</xref>-<xref rid="ref16" ref-type="bibr">16</xref>]. Most ML-based prediction models use ML algorithms that leverage statistical methods to learn from clinical data. When clinical prediction models are deployed in nonstationary clinical environments [<xref rid="ref17" ref-type="bibr">17</xref>], model deteriorations are observed over time in response to the dynamic nature of clinical environments [<xref rid="ref18" ref-type="bibr">18</xref>]. The effectiveness and generalizability of ML-based clinical risk prediction models are greatly impacted when in such situations. As an example, during the COVID-19 pandemic, the alert rate of a sepsis prediction model was reported as more than double compared to that preceding the COVID-19 pandemic. As a consequence, the hospital had to shut down the prediction service [<xref rid="ref19" ref-type="bibr">19</xref>,<xref rid="ref20" ref-type="bibr">20</xref>].</p><p>This study intended to evaluate the model shift in ML-based clinical risk prediction models. Following the work of our previous study [<xref rid="ref7" ref-type="bibr">7</xref>,<xref rid="ref11" ref-type="bibr">11</xref>], we aimed to generalize our findings by applying the investigation to the delirium, sepsis, and AKI use cases at 1 community hospital and 1 specialized hospital. In this study, we used retrospective data to train different prediction models on clinical data from earlier years and then evaluated the model shift, as well as its impact on clinical decision-making, on data from later years, thus mimicking the situation of deploying prediction models in the real world. The evaluation covered periods preceding and during the COVID-19 pandemic, which allowed us to evaluate the impact of COVID-19. We investigated the impact of a model shift on model performance, model calibration, and clinical decisions. To the best of our knowledge, this is the first report that evaluated the impact of a model shift on such a scale.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Ethical Considerations</title><p>In accordance with Article 15.1 of the Professional Code for Healthcare Professionals of Germany, ethical approval is only required if human body materials are used or if the used data can be traced to a particular individual [<xref rid="ref21" ref-type="bibr">21</xref>]. As no personal data were collected for this project and all used data were anonymized in compliance with the ethical and data protection obligations established by the European Commission [<xref rid="ref22" ref-type="bibr">22</xref>], consultation or evaluation by an ethics committee was not required.</p></sec><sec><title>Study Design</title><p>We used a scalable method development approach to generate clinical risk prediction models for various conditions at 2 German hospitals, the Medius Klinik N&#x000fc;rtingen and the Herz- und Diabeteszentrum Nordrhein-Westfalen Bad Oeynhausen, referred to as hospitals M and H, respectively. Our previous investigations showed that our models&#x02019; performance from live clinical workflows did not deteriorate compared to retrospective data. For instance, when comparing the area under the receiver operating characteristic curve (AUROC) on average across the 3 use cases and hospitals from live clinical workflows to that from retrospective data, the AUROC decreased slightly by 0.6 percentage points (from 94.8% to 94.2% at discharge) [<xref rid="ref7" ref-type="bibr">7</xref>,<xref rid="ref11" ref-type="bibr">11</xref>]. This study incorporated patient data from 2009 to 2021, which included demographic information, such as age and sex; clinical information, such as laboratory results; clinical notes, such as admission letters or nursing notes; vital signs; historical records; and medication. Tables S1 and S2 in <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref> provide an overview of data characteristics over the years for the 2 hospitals, respectively. We focused on 3 clinical use cases: delirium, sepsis, and AKI. <xref rid="table1" ref-type="table">Table 1</xref> displays the incidence of each condition at each hospital.</p><table-wrap position="float" id="table1"><label>Table 1</label><caption><p>Incidence for each use case in both hospitals.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="250" span="1"/><col width="250" span="1"/><col width="250" span="1"/><col width="250" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Hospital</td><td rowspan="1" colspan="1">AKI<sup>a</sup> incidence (%)</td><td rowspan="1" colspan="1">Delirium incidence (%)</td><td rowspan="1" colspan="1">Sepsis incidence (%)</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">M</td><td rowspan="1" colspan="1">16.41</td><td rowspan="1" colspan="1">2.22</td><td rowspan="1" colspan="1">1.50</td></tr><tr valign="top"><td rowspan="1" colspan="1">H</td><td rowspan="1" colspan="1">23.35</td><td rowspan="1" colspan="1">1.15</td><td rowspan="1" colspan="1">2.13</td></tr></tbody></table><table-wrap-foot><fn id="table1fn1"><p><sup>a</sup>AKI: acute kidney injury.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>Analysis and Evaluation</title><p>We performed analyses and evaluations from different perspectives to systematically assess the model shift and its impact. <xref rid="figure1" ref-type="fig">Figure 1</xref> provides an overview of these steps: First, we conducted a comprehensive analysis of the source data to detect any changes in them over time. Second, we evaluated the performance of the prediction model to determine whether there was any deterioration. Third, we examined any potential shift in the calibration curves. Lastly, we performed a decision analysis to determine whether there was a decline in clinical decision-making.</p><fig position="float" id="figure1"><label>Figure 1</label><caption><p>Overview of the investigation methodology.</p></caption><graphic xlink:href="jmir_v26i1e51409_fig1" position="float"/></fig></sec><sec><title>Data Source</title><p>As clinical prediction models may be negatively impacted by changes in clinical settings over time [<xref rid="ref18" ref-type="bibr">18</xref>], one of the first steps in avoiding a model shift is to analyze the source data and look for changes in them. First, we looked at the number of samples per year, as this could drastically change. Second, it was important to track the incidence of the condition over the years as it could have been altered due to modifications in the coding system, the hospital protocol, or the appearance of new risk factors that cause an increase in incidence&#x02014;for example, SARS-Cov2 as a risk factor for sepsis [<xref rid="ref23" ref-type="bibr">23</xref>]. Third, it was necessary to closely examine data set characteristics. Among the key points were gender distribution over time, the availability of features throughout the years, and the length of observations and patient stay over the years.</p></sec><sec><title>Model Development</title><p>The prediction model design, data preparation, and training were implemented in an automated pipeline that provided a standardized method to install, configure, and execute the data preparation process, model training, and evaluation on a deployment-specific system. The automated pipeline started with source data analysis to detect abnormalities in the source data. It also automatically adapted the hyperparameters for the model training process. Risk prediction models were then generated based on the hospital data with such an automated pipeline and, therefore, calibrated with the electronic health record (EHR) data of the hospital. The generated models were automatically evaluated, and acceptance criteria were verified throughout the evaluation procedure.</p><p>Before data preparation, we applied the following inclusion criteria: (1) patients should be 18 years or older and must have a birth year available; (2) medical cases should contain information about the gender, the department, and the reason for admission; and (3) stay in the hospital should be for a maximum of 90 days. Next, input features were generated using a common data preparation pipeline, which used all the available data generated during the patient&#x02019;s stay. The features came from structured data, such as laboratory results, vital signs, and historical records, along with unstructured data, such as clinical notes. Details about the number of features used by the model for both hospitals are provided in Table S3 in <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref>.</p><p>For preparing unstructured features, we developed a natural language processing (NLP) pipeline in 2 steps. The initial step involved using a trained TinyBERT model to perform named entity recognition (NER) on clinical text data, identifying disorders and clinical findings. The extracted entities were then passed as an input to a named entity normalization (NEN) model [<xref rid="ref24" ref-type="bibr">24</xref>]. The NEN model maps the extracted entities to the <italic>German Modification of the International Statistical Classification of Diseases and Related Health Problems, Tenth Revision</italic> (ICD-10-GM) codes. This 2-step process enhances the precision of information extraction and ensures a consistent representation of clinical concepts. (For more details, see the <italic>NLP Models</italic> section in <xref rid="app2" ref-type="supplementary-material">Multimedia Appendix 2</xref>). The labels for sepsis and delirium were assigned according to the ICD-10-GM codes at discharge. The AKI labels were assigned based on the Kidney Disease Improving Global Outcomes (KDIGO) criteria [<xref rid="ref25" ref-type="bibr">25</xref>].</p><p>To ensure the reliability of the study, the data sets were strictly split into training and evaluation sets at the patient level. Additionally, approximately 10% of the training set was exclusively reserved for validation, calibration, and threshold selection. The training set for hospital H included data from 2017 to 2018, while that for hospital M comprised data from 2009 to 2017. Consequently, the evaluation set contained the most recent years, spanning from 2019 for hospital H and from 2018 for hospital M. The choice of these specific years was due to differences in incidence across the years because of mislabeling (for more details, see data source analysis in the <italic>Results</italic> section).</p><p>All the available information belonging to the same hospital stay was first aggregated to obtain a complete training record. Additionally, to mitigate the situation where the model was requested to generate predictions with limited information available, we applied data augmentation in the training set to generate a partial record. The partial data were constructed based on subsets of features of the original record and, combined with the complete record, enhanced the robustness of the clinical risk prediction model. Nevertheless, it is important to note that this approach was applied only to the training data, while the test set remained unmodified to reflect the real-life distribution of the population. The impact of this data augmentation was evaluated in our previous work [<xref rid="ref7" ref-type="bibr">7</xref>], where the performance 24 hours/1 day/the next day after admission showed an improvement of around 4% in the AUROC. Furthermore, to avoid potential biases due to high class imbalance, the controls were downsampled to a 1:5 case:control ratio before training. More detailed information about the model development approach can be found in our previous paper [<xref rid="ref7" ref-type="bibr">7</xref>].</p><p>Next, a clinical risk prediction model was trained separately for each condition (sepsis, delirium, and AKI) and each hospital (M and H), applying a standard model training methodology using/on transformer models [<xref rid="ref26" ref-type="bibr">26</xref>]. As a result, we obtained 6 independent models. For the model training process, the previously mentioned features were used as inputs and the labels as targets of the model. However, it is important to note that certain features exhibited unreasonably strong correlations with the condition. Consequently, these features, identified as leaking features, were removed from the training data. Roughly, 2 categories of leaking features were considered: reverse causal correlations, which correspond to features that typically occur after onset (or clinical suspicion), and strong cofounders, such as the presence of specific but unrelated lab tests only taken in a high-risk population. The list of these features, defined by in-house clinical professionals, can be found in Table S4 in <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref>.</p></sec><sec><title>Model Performance</title><p>A common pitfall of clinical prediction models is that their performance can deteriorate over time. Therefore, a key aspect to explore is the ability of the model to discriminate and sustain its performance over time. There are different metrics that can be used (eg, accuracy, sensitivity, specificity, precision) to evaluate a model&#x02019;s performance. In this study, we applied 2 methods to investigate the performance of a model: first, the AUROC, as it is an assessment metric that remains unaffected by incidence or threshold selection, and second, the calibration shift, which is the disagreement between the predicted probability and the observed number of events.</p><p>To detect a calibration shift, a well-calibrated model that makes probabilistic predictions that match real-world probabilities is required. There are several methodologies for calibrating a model, such as Platt scaling [<xref rid="ref27" ref-type="bibr">27</xref>], isotonic regression [<xref rid="ref28" ref-type="bibr">28</xref>], and temperature scaling (which is a single-parameter variant of Platt scaling) [<xref rid="ref29" ref-type="bibr">29</xref>], among others. In this study, we used Platt scaling, which is more suitable for small data sets (like our sepsis and delirium data sets). Additionally, for plotting the calibration graph, we used a quantile binning approach, where each bin has the same number of samples, which reduces the noise in the curve by preventing different bins from having an unbalanced number of samples. There is no 1 unique way to measure the calibration of predictive models. Although some methods are frequently used and have specific strengths, all have limitations [<xref rid="ref30" ref-type="bibr">30</xref>]. In this analysis, we focused on 2 metrics: expected calibration error (ECE) and maximum calibration error (MCE). The ECE measures the weighted mean absolute difference between confidence and accuracy, while the MCE measures the maximum difference between average confidence and accuracy across bins. In both metrics, larger values indicate greater miscalibration.</p><p>We generated calibration curves for each year within the test set , which allowed us to more easily detect a calibration shift by identifying deviations between the different curves. We observed calibration shifts for sepsis and delirium but not for AKI. Consequently, we expanded our experiments to assess whether the shift was related to the intrinsic nature of different conditions and also whether it was related to other factors, such as data size or incidence. Although other factors can contribute to the presence or absence of a shift, we investigated how the former 2 impacted the results in AKI, as no evidence of a shift was observed for this condition. Furthermore, the AKI use case exhibited a larger sample size and a higher incidence rate compared to the other 2 use cases. This provided us with an opportunity to conduct the following experiments: First, we randomly downsampled the AKI data set to assess the shift on different data scales. Second, we artificially reduced the incidence rate of AKI in the testing and calibration data sets to match the delirium incidence rate. These experiments aimed to assess the influence of both data size and incidence rate on the outcomes and whether the observed shift in sepsis and delirium is a consequence of a lower data size or incidence.</p></sec><sec><title>Decision Evaluation</title><p>The system calculated predictions throughout the hospitalization, and when a threshold was reached, an alert was shown. An alert may appear as soon as the patient is registered in the system if their past medical history is predictive enough. We conceptually created 5 categories (instead of the typical 4):</p><list list-type="bullet"><list-item><p>True negative (TN; control): an alert is not shown correctly.</p></list-item><list-item><p>False positive (FP; control): an alert is incorrectly shown at some point during the stay.</p></list-item><list-item><p>False negative (FN; case): an alert is incorrectly not shown at all, although the patient has developed the condition at some point during the stay.</p></list-item><list-item><p>True positive (TP; case): an alert is correctly shown before onset.</p></list-item><list-item><p>Arguably FN/TP (case): an alert is correctly shown but not strictly before onset. The risk prediction is then diagnostic rather than strictly predictive, similar to other risk scores, such as the Confusion Assessment Method for the Intensive Care Unit (CAM-ICU) or Delirium Observation Scaling (DOS).</p></list-item></list><p>A severe limitation of ICD codes is that they convey no information about the time of onset of a condition. We were, therefore, unable to distinguish between the last 2 groups, so we evaluated the occurrence of an alert at any time from admission until discharge (as opposed to no alert at all) and compared this alert rate to the finally assigned diagnosis.</p><p>Model performance evaluation normally focuses on discrimination metrics; however, it does not assess whether the risk model enhances clinical decision-making. Accordingly, we undertook an investigation to determine the potential impact on decision-making over time by analyzing alert rates and over- and underdiagnosis rates and performing decision curve analysis (DCA). First, we investigated whether there was any increase or decrease in alert rates across the years. Second, we examined the changes in over- and underdiagnosis rates. Overdiagnosis refers to overtreatment without any discernible benefit to the patient, which typically occurs in sensitive models, and is defined as the false-positive rate (FPR). Underdiagnosis, in contrast, refers to a failure to correctly diagnose a condition and is defined as the false-negative rate (FNR) [<xref rid="ref31" ref-type="bibr">31</xref>,<xref rid="ref32" ref-type="bibr">32</xref>]. The FPR and FNR are affected by threshold selection. Thus, in the pursuit of achieving an equilibrium between these 2 metrics, our threshold selection approach consisted of selecting a threshold that minimized the difference between under- and overdiagnosis rates. This threshold selection was performed in an independent set (10% of the training set) and after calibrating the model. Lastly, we performed DCA, where we assessed whether the benefit of using our model to make a clinical decision decreased over time. DCA allows us to evaluate and compare the clinical utility of predictive models using nonparametric statistical methods [<xref rid="ref33" ref-type="bibr">33</xref>,<xref rid="ref34" ref-type="bibr">34</xref>]. This method illustrates the net benefit related to a specific decision strategy across a spectrum of probabilities. Its application ensures that clinical decisions are not solely reliant on discriminative metrics but also consider the potential harms and benefits associated with such decisions. The net benefit is calculated according to the following formula:</p><disp-formula>
<graphic xlink:href="jmir_v26i1e51409_fig5.jpg" position="float"/>
</disp-formula><p>where N is the total number of predictions and is the threshold probability.</p></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Data Source Analysis</title><p>The data sets used in this study contained 189,775 and 180,976 medical cases for hospitals M and H, respectively. The distribution and characteristics of the data sets for both hospitals are shown in Tables S1 and S2 in <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref>. Hospital M is a community hospital, while hospital H is a specialized center for diabetes and heart disease, with a high volume of cardiac surgery and invasive, transcatheter procedures and intensive care. The 2 data sets exhibit common characteristics with respect to an increasing trend in the length of stay, resulting in a greater number of features and longer observations, and consistency in the proportion of women and men throughout the years (Tables S1 and S2 in <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref>). However, it is important to note that there are some differences between the 2 data sets or different use cases. For instance, medication was not available as a feature until 2016 in hospital M and until 2018 in hospital H. Moreover, the incidence of sepsis and delirium in earlier years was lower than in later years, with a more notable disparity observed in delirium at hospital H. The increase in the delirium incidence rate is coincident with extensive efforts to improve the recognition and treatment of delirium. Based on these findings, we decided to use only data from the most recent years, specifically from 2017 for hospital H. This decision was made to mitigate the potential influence of mislabeling arising from the data source. Medical cases whose admission date was earlier than 2017 were removed. The real-life incidence for the validation and evaluation test was therefore not affected. As aforementioned, the case:control balance for the training data set was set to 1:5.</p></sec><sec><title>Model Performance</title><p>The performance of the clinical risk prediction model was evaluated at the end of the patient&#x02019;s hospital stay due to the lack of the time of onset and to avoid inconsistencies when the predictions were evaluated.</p><sec><title>Performance Evaluation</title><p>Model evaluation results are presented in <xref rid="table2" ref-type="table">Tables 2</xref> and <xref rid="table3" ref-type="table">3</xref> by showing AUROC and area under the precision recall curve (AUPRC) values. The AUPRC is a relevant metric when dealing with imbalanced data and detecting positive samples are of greater interest and concern. However, as the AUPRC is highly influenced by incidence, the model was evaluated based on the AUROC, which, in contrast to other metrics, such as sensitivity, specificity, precision, and the AUPRC, is independent of the threshold and incidence. Thus, it allowed us to compare model performance across different years. <xref rid="table2" ref-type="table">Table 2</xref> shows that AUROC values remained stable for the 2 use cases at hospital M, with mean 90.37% (SD 0.32%), mean 96.95% (SD 0.50%), and mean 95.92% (SD 0.41%) for AKI, delirium, and sepsis, respectively. Similarly, <xref rid="table3" ref-type="table">Table 3</xref> presents the values for hospital H, and the values for AKI, delirium, and sepsis were mean 91.25% (SD 0.29%), mean 94.24% (SD 0.44%), and mean 97.95% (SD 0.41%), respectively.</p><table-wrap position="float" id="table2"><label>Table 2</label><caption><p>Model performance and incidence in the test set of hospital M.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="30" span="1"/><col width="370" span="1"/><col width="150" span="1"/><col width="150" span="1"/><col width="150" span="1"/><col width="150" span="1"/><thead><tr valign="top"><td colspan="2" rowspan="1">Use case and metrics</td><td colspan="4" rowspan="1">Years</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">2018</td><td rowspan="1" colspan="1">2019</td><td rowspan="1" colspan="1">2020</td><td rowspan="1" colspan="1">2021</td></tr></thead><tbody><tr valign="top"><td colspan="6" rowspan="1">
<bold>AKI<sup>a</sup></bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Incidence (%)</td><td rowspan="1" colspan="1">14.57</td><td rowspan="1" colspan="1">14.81</td><td rowspan="1" colspan="1">14.95</td><td rowspan="1" colspan="1">17.64</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Alert rate (%)</td><td rowspan="1" colspan="1">22.36</td><td rowspan="1" colspan="1">22.62</td><td rowspan="1" colspan="1">23.48</td><td rowspan="1" colspan="1">26.56</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUROC<sup>b</sup> (%)</td><td rowspan="1" colspan="1">90.54</td><td rowspan="1" colspan="1">90.40</td><td rowspan="1" colspan="1">89.84</td><td rowspan="1" colspan="1">90.69</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUPRC<sup>c</sup> (%)</td><td rowspan="1" colspan="1">65.48</td><td rowspan="1" colspan="1">65.87</td><td rowspan="1" colspan="1">64.99</td><td rowspan="1" colspan="1">71.01</td></tr><tr valign="top"><td colspan="6" rowspan="1">
<bold>Delirium</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Incidence (%)</td><td rowspan="1" colspan="1">2.18</td><td rowspan="1" colspan="1">1.92</td><td rowspan="1" colspan="1">3.17</td><td rowspan="1" colspan="1">2.63</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Alert rate (%)</td><td rowspan="1" colspan="1">10.75</td><td rowspan="1" colspan="1">11.61</td><td rowspan="1" colspan="1">13.44</td><td rowspan="1" colspan="1">15.37</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUROC (%)</td><td rowspan="1" colspan="1">97.55</td><td rowspan="1" colspan="1">96.86</td><td rowspan="1" colspan="1">97.21</td><td rowspan="1" colspan="1">96.18</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUPRC (%)</td><td rowspan="1" colspan="1">42.93</td><td rowspan="1" colspan="1">34.94</td><td rowspan="1" colspan="1">51.26</td><td rowspan="1" colspan="1">40.89</td></tr><tr valign="top"><td colspan="6" rowspan="1">
<bold>Sepsis</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Incidence (%)</td><td rowspan="1" colspan="1">1.67</td><td rowspan="1" colspan="1">1.49</td><td rowspan="1" colspan="1">1.24</td><td rowspan="1" colspan="1">1.66</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Alert rate (%)</td><td rowspan="1" colspan="1">11.86</td><td rowspan="1" colspan="1">13.12</td><td rowspan="1" colspan="1">14.65</td><td rowspan="1" colspan="1">17.17</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUROC (%)</td><td rowspan="1" colspan="1">96.29</td><td rowspan="1" colspan="1">96.37</td><td rowspan="1" colspan="1">95.45</td><td rowspan="1" colspan="1">95.55</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUPRC (%)</td><td rowspan="1" colspan="1">40.98</td><td rowspan="1" colspan="1">32.85</td><td rowspan="1" colspan="1">34.14</td><td rowspan="1" colspan="1">39.81</td></tr></tbody></table><table-wrap-foot><fn id="table2fn1"><p><sup>a</sup>AKI: acute kidney injury.</p></fn><fn id="table2fn2"><p><sup>b</sup>AUROC: area under the receiver operating characteristic curve.</p></fn><fn id="table2fn3"><p><sup>c</sup>AUPRC: area under the precision recall curve.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="table3"><label>Table 3</label><caption><p>Model performance and incidence in the test set of hospital H.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="30" span="1"/><col width="220" span="1"/><col width="250" span="1"/><col width="250" span="1"/><col width="250" span="1"/><thead><tr valign="top"><td colspan="2" rowspan="1">Use case and metrics</td><td colspan="3" rowspan="1">Years</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">2019</td><td rowspan="1" colspan="1">2020</td><td rowspan="1" colspan="1">2021</td></tr></thead><tbody><tr valign="top"><td colspan="5" rowspan="1">
<bold>AKI<sup>a</sup></bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Incidence (%)</td><td rowspan="1" colspan="1">25.22</td><td rowspan="1" colspan="1">25.98</td><td rowspan="1" colspan="1">25.58</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Alert rate (%)</td><td rowspan="1" colspan="1">32.70</td><td rowspan="1" colspan="1">34.36</td><td rowspan="1" colspan="1">32.76</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUROC<sup>b</sup> (%)</td><td rowspan="1" colspan="1">90.83</td><td rowspan="1" colspan="1">91.51</td><td rowspan="1" colspan="1">91.40</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUPRC<sup>c</sup> (%)</td><td rowspan="1" colspan="1">80.58</td><td rowspan="1" colspan="1">82.59</td><td rowspan="1" colspan="1">81.71</td></tr><tr valign="top"><td colspan="5" rowspan="1">
<bold>Delirium</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Incidence (%)</td><td rowspan="1" colspan="1">3.25</td><td rowspan="1" colspan="1">3.26</td><td rowspan="1" colspan="1">2.86</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Alert rate (%)</td><td rowspan="1" colspan="1">20.56</td><td rowspan="1" colspan="1">21.25</td><td rowspan="1" colspan="1">20.46</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUROC (%)</td><td rowspan="1" colspan="1">94.70</td><td rowspan="1" colspan="1">94.39</td><td rowspan="1" colspan="1">93.64</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUPRC (%)</td><td rowspan="1" colspan="1">37.32</td><td rowspan="1" colspan="1">34.43</td><td rowspan="1" colspan="1">30.91</td></tr><tr valign="top"><td colspan="5" rowspan="1">
<bold>Sepsis</bold>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Incidence (%)</td><td rowspan="1" colspan="1">3.70</td><td rowspan="1" colspan="1">3.86</td><td rowspan="1" colspan="1">3.89</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Alert rate (%)</td><td rowspan="1" colspan="1">12.82</td><td rowspan="1" colspan="1">12.47</td><td rowspan="1" colspan="1">12.79</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUROC (%)</td><td rowspan="1" colspan="1">97.37</td><td rowspan="1" colspan="1">98.12</td><td rowspan="1" colspan="1">98.35</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">AUPRC (%)</td><td rowspan="1" colspan="1">73.63</td><td rowspan="1" colspan="1">77.04</td><td rowspan="1" colspan="1">77.78</td></tr></tbody></table><table-wrap-foot><fn id="table3fn1"><p><sup>a</sup>AKI: acute kidney injury.</p></fn><fn id="table3fn2"><p><sup>b</sup>AUROC: area under the receiver operating characteristic curve.</p></fn><fn id="table3fn3"><p><sup>c</sup>AUPRC: area under the precision recall curve.</p></fn></table-wrap-foot></table-wrap><p>These findings indicate low variations in the performance metrics; moreover, statistical tests were conducted to discern whether the variations in performance metrics over the years were statistically significant. First, we computed the SEs of the AUROCs using Hanley and McNeil&#x02019;s method [<xref rid="ref35" ref-type="bibr">35</xref>]. Next, we performed a <italic>Z</italic> test to assess whether there were significant differences between different AUROCs. We did not observe any significant differences between the AUROCs across the different years for all use cases and all hospitals (<italic>P</italic>&#x0003e;.05). Detailed results are presented in Tables S5 and S6 in <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref>. These results demonstrate that the model&#x02019;s performance did not exhibit persistent deterioration over time at either hospital.</p></sec><sec><title>Calibration Curve Analysis</title><p>In addition to the evaluation of the AUROC, which reflects model performance, we also investigated whether there was any potential shift in model calibration. <xref rid="figure2" ref-type="fig">Figure 2</xref> shows the calibration curves, as well as their corresponding ECE and MCE values. <xref rid="figure2" ref-type="fig">Figure 2</xref>a displays the calibration curves of the 2 use cases at hospitals M and H, respectively. The curves before calibration indicated that the averaged predicted risks were higher than the observed event rate, which means our models overestimated the risk. Consequently, we calibrated our models by applying the Platt scaling method [<xref rid="ref27" ref-type="bibr">27</xref>]. The curves after calibration showed that the predicted risks better matched the observed positive ratio.</p><fig position="float" id="figure2"><label>Figure 2</label><caption><p>Calibration curves and corresponding ECE and MCE values: (a) calibration curves for each use case and year before and after calibration, with 95% CIs; (b) ECE values across the years for each use case; and (c) MCE values over the years for the 3 use cases. AKI: acute kidney injury; ECE: expected calibration error; MCE: maximum calibration error.</p></caption><graphic xlink:href="jmir_v26i1e51409_fig2" position="float"/></fig><p>To better quantify the quality of the calibration curves, corresponding ECE (<xref rid="figure2" ref-type="fig">Figure 2</xref>b) and MCE (<xref rid="figure2" ref-type="fig">Figure 2</xref>c) values were generated for each calibrated curve. The error graphs did not show a clear increase in the shift across the evaluated years for any of the use cases at both hospitals, although small fluctuations were observed in the ECE and MCE curves in the delirium use case at hospital M. Furthermore, <xref rid="figure2" ref-type="fig">Figure 2</xref>a demonstrates that unlike the AKI use case, the sepsis and delirium use cases exhibited a calibration shift at hospital M, with the curves deviating from the diagonal line for higher probabilities. At hospital H, there was no evident calibration shift for both AKI and delirium use cases, although a slight shift was observed in its sepsis model.</p><p>Given the observed calibration shifts in sepsis and delirium, in contrast to the stability in AKI, we extended our investigations to examine whether the observed shift was intricately associated with inherent characteristics of the distinct conditions or whether it was influenced by other factors, such as variation in data size or incidence rates. Our results demonstrated that reducing the data size or incidence rates did not result in a calibration shift, and therefore, the observed calibration shift in sepsis and delirium could be use case specific or influenced by other factors (see <xref rid="app2" ref-type="supplementary-material">Multimedia Appendix 2</xref> for more details).</p></sec></sec><sec><title>Decision Evaluation</title><p>The last evaluation focused on decision-making analysis. We first assessed the alert rates, that is, the number of alerts triggered when the predicted probability exceeds the predefined threshold. We observed a slight increase over the years for all 3 use cases, even though the AUROC and the incidence remained similar at hospital M (see <xref rid="table2" ref-type="table">Table 2</xref>). However, we did not observe a similar increase at hospital H (see <xref rid="table3" ref-type="table">Table 3</xref>), where both incidence and alert rates remained stable.</p><p>The over- and underdiagnosis rates were further evaluated based on the correctness of an alert. The thresholds selected from the threshold selection set (10% of the training set) at hospital M were 19.97, 2.40, and 2.67 for AKI, delirium, and sepsis, respectively, and at hospital H were 23.13, 2.79, and 2.93, respectively. <xref rid="figure3" ref-type="fig">Figure 3</xref> shows the under- and overdiagnosis rates for the test sets from the 3 use cases on a yearly basis at both hospital M and hospital H. At hospital M, we also observed that although the underdiagnosis rate remained stable over the years, there were clear trends of an increase in the overdiagnosis rate in all 3 use cases. Such an increase in overdiagnosis is in line with the increase in the alert rate and is likely associated with the increased number of observations in patient records (Tables S1 and S2 in <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref>), as observed in the data analysis. The maximum deviation of the under- and overdiagnosis curves was around 5% in overdiagnosis on sepsis observed at hospital M, which aligns with the fact that the alert rate also increased. Such an increase is partially in line with the report that the alert rate of sepsis prediction models increased during the COVID-19 pandemic [<xref rid="ref19" ref-type="bibr">19</xref>,<xref rid="ref20" ref-type="bibr">20</xref>]. However, in this investigation, the trend of such an increase started before the pandemic.</p><p>At hospital H, there were more fluctuations in the underdiagnosis rate. The 3 use cases behaved differently, hindering generalization. Although the number of observations in patient records also increased yearly at hospital H, in contrast to hospital M, its overdiagnosis rates remained stable for all 3 use cases. Furthermore, the underdiagnosis rate of sepsis decreased during the COVID-19 pandemic, while its overdiagnosis rate remained stable. This indicates that the performance of the sepsis prediction model at hospital H improved during the COVID-19 pandemic, which contradicts the findings of hospital M, as well as other reports [<xref rid="ref19" ref-type="bibr">19</xref>,<xref rid="ref20" ref-type="bibr">20</xref>].</p><p>In summary, the 2 hospitals behave differently in terms of over- and underdiagnosis rates. Therefore, site-specific monitoring schemes are required to detect such changes. Consequently, given the difficulty in determining whether a model shift occurred based solely on the under- and overdiagnosis rates, we additionally performed DCA to test for any changes in the clinical utility of the models.</p><p>To examine the potential impact of the model on decision-making over time, DCA was performed for each distinct year and use case. The net benefit was calculated across the full range of probability thresholds. However, the lower range of the probability thresholds is more relevant to clinicians as, arguably, most clinicians would agree that the medical and financial consequences of delirium, sepsis, and AKI outweigh the nuisance to the user and the cost and inconvenience of preventive measures and closer monitoring. It is necessary to find the optimal threshold that has a good balance between FPs and FNs to prevent the excessive generation of unnecessary alerts, which can lead to user desensitization and decreased responsiveness. Additionally, it is important to highlight that the initial position of the decision curves (threshold=0) is notably affected by the incidence rate of the particular use case. Therefore, to ensure that the differences between the curves did not stem from different incidence rates, we standardized the incidence rate across the years by augmenting the incidence of the years that had lower rates until a uniform incidence was achieved across all years.</p><p>Figure S1 in <xref rid="app2" ref-type="supplementary-material">Multimedia Appendix 2</xref> and <xref rid="figure4" ref-type="fig">Figure 4</xref> show the decision curves for hospitals M and H, respectively, for each year across the 2 use cases. To test whether there was a significant difference in the decision-making between the years, we performed a pairwise nonparametric statistical comparison between the decision curves from 2 individual years for all possible year pairs [<xref rid="ref33" ref-type="bibr">33</xref>,<xref rid="ref34" ref-type="bibr">34</xref>]. For all the use cases and hospitals, we did not find any significant difference between any of the years (all <italic>P</italic>&#x0003e;.05) at the thresholds of interest. These results demonstrated that the model did not experience a degradation in clinical utility across the years.</p><fig position="float" id="figure3"><label>Figure 3</label><caption><p>Under- and overdiagnosis rates across years in hospitals M and H. AKI: acute kidney injury.</p></caption><graphic xlink:href="jmir_v26i1e51409_fig3" position="float"/></fig><fig position="float" id="figure4"><label>Figure 4</label><caption><p>Decision curves for hospital M. Colored dotted lines show the net benefit of alerting all patients, gray lines represent the benefit of not alerting any patient, and colored solid lines show the net benefit of using the model on each of the years in the test. AKI: acute kidney injury.</p></caption><graphic xlink:href="jmir_v26i1e51409_fig4" position="float"/></fig></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Principal Findings</title><p>This paper evaluated the impact of a model shift on ML-based clinical risk prediction models. There was no significant model shift in the period under this investigation. The models&#x02019; performances remained stable for all the 3 use cases, and there were no significant differences in the AUROCs between the years. Nevertheless, analysis of the calibration curves revealed a calibration shift in some use cases. The calibration curves of AKI were more stable compared to those for the delirium and sepsis prediction models at both hospitals in this study. No calibration shift was observed for AKI, even when the size of the sample and the rate of incidence were downscaled. These results suggest an intrinsic difference among the different use cases. Lastly, with respect to the interpretation of the predictions, the rate of alerts and overdiagnosis behaved differently across different hospitals: they consistently increased in the 3 use cases at hospital M and remained stable at hospital H. Furthermore, the examination of DCA results revealed a consistent pattern where the models exhibited no deterioration over time, affirming the stability of their clinical utility and decision-making.</p><p>These findings suggest that relying solely on AUROCs, the commonly used metric for assessing the performance of clinical risk prediction models, is inadequate in capturing the impact of a model shift. It is, therefore, essential to use comprehensive evaluations, such as calibration curve analysis, alert rate monitoring, and DCA, to promptly detect any kind of model shift. Additionally, recalibrating the model when the calibration curve significantly deviates from the diagonal may offer a viable solution without necessitating complete model retraining. This approach is effective because the chosen probability calibration approach does not affect the evaluation metrics as AUROCs or AUPRCs. However, in other situations where the performance or clinical usefulness of the model has deteriorated, retraining the model would be necessary. Furthermore, this study revealed that the potential impact of a model shift cannot be easily generalized, as the evaluations exhibited diverse behaviors across different use cases and hospitals. Therefore, implementing proper model calibration is crucial to avoid undesirable consequences, such as a significant increase in the alert rate [<xref rid="ref19" ref-type="bibr">19</xref>,<xref rid="ref20" ref-type="bibr">20</xref>].</p></sec><sec><title>Comparison With Prior Works</title><p>Previous research that investigated model shifts in the clinical domain often worked with a single use case at a single site. For instance, Davis et al [<xref rid="ref14" ref-type="bibr">14</xref>] examined data shift scenarios in AKI risk prediction with 1 data set. Similarly, Minne et al [<xref rid="ref15" ref-type="bibr">15</xref>] used a single data set to evaluate the effect of temporal changes on mortality prediction performance. Therefore, later studies have argued that the focus on developing new models in the clinical domain should introduce more heterogeneity in model development and model evaluation [<xref rid="ref16" ref-type="bibr">16</xref>]. The study presented in this paper leveraged 2 large data sets from different hospitals and investigated 3 distinct use cases, thereby enhancing the generalizability of the findings. Furthermore, although previous studies [<xref rid="ref14" ref-type="bibr">14</xref>,<xref rid="ref15" ref-type="bibr">15</xref>] have focused on analyzing model drift in terms of performance, this study extended the evaluation to a broader set of metrics, assessing the evolution of clinical utility of the model over time. This approach significantly enhances the heterogeneity and robustness of the evaluation.</p></sec><sec><title>Motivations</title><p>ML-based prediction models are often closely tied to the system environment in which the models undergo training. After the models are deployed as real-world applications, their performance may deteriorate over time when the system experiences changes in its environment. The consequences of such changes largely impact the reliability of ML-based prediction models. Although the dynamic nature of the system is inevitable, timely detection of its impact is, therefore, of utmost importance to prevent model deterioration when it is used in clinical settings. This study aimed to investigate various approaches for monitoring the implications of model shifts by examining diverse use cases across different types of hospitals.</p></sec><sec><title>Strengths</title><p>This study performed comprehensive evaluations of model behaviors over a 4-year period. The evaluation was not limited to model performance, also assessing the consequence of the model shift on clinical decision-making. Such detailed evaluations were performed on 3 different use cases at both a specialized hospital and a generalized hospital so as to better generalize the findings of our study. To the best of our knowledge, this study is the first report to investigate the consequences of a model shift on such a comprehensive level and scale.</p></sec><sec><title>Limitations</title><p>This study has some limitations. First, the study was performed on retrospective data to simulate how prediction models would behave over time after they were trained. Evaluating model behavior in real-world clinical settings would provide more valuable insights. Second, the cause of the calibration shift observed on the delirium and sepsis use cases was not thoroughly analyzed in this study. We hypothesized that such a difference may be related to the different labeling strategies: the delirium and sepsis use cases were labeled with discharge ICD codes, while the AKI use case was labeled with the KDIGO algorithm. The use of ICD codes is imperfect owing to inevitable variations and inconsistencies in coding practice. However, lacking standard criteria for diagnosis, the use of such codes is an established method for retrospective identification [<xref rid="ref36" ref-type="bibr">36</xref>]. Discharge ICD codes are likely more vulnerable to changes in coding policies, while diagnostic algorithms, such as KDIGO, that rely on lab values are less likely to change over time.</p></sec><sec><title>Future Directions</title><p>This study evaluated the impact of a model shift on ML-based clinical risk prediction models. As a future step, we plan to conduct the discussed evaluations on our prediction models after they are deployed in live EHR systems. In addition, we will further investigate the different behaviors of calibration curves between the AKI use case and the other 2 use cases. Specifically, we aim to explore the influence of various labeling policies on these behaviors.</p><p>Including retrospective data from earlier years may help build a more reliable model with more training samples; however, it may also increase the risk of data shift. We will further investigate how to make a good trade-off when selecting training data, thus significantly influencing the development of a good prediction model, while minimizing the model shift.</p></sec><sec><title>Conclusion</title><p>This study performed evaluations across different hospitals to investigate the impact of model shifts on various ML-based risk prediction models. Although the metrics of AUROCs remained stable for the evaluated use cases over the years, the analysis of calibration curves varied across certain use cases (ie, delirium and sepsis) at different hospitals. However, upon conducting more in-depth investigations using DCA, it was confirmed that these variations did not have any impact on the clinical utility of the models, as there was no evident degradation in their decision-making capabilities. Moreover, the COVID-19 pandemic has the potential to alter clinical diagnosis and treatment patterns over the long term. So, to obtain a more complete understanding of this impact in prediction models, a future study incorporating additional years of data would be highly valuable. As a summary, these findings suggest the need for appropriate monitoring schemes and timely model calibrations following the deployment of prediction models.</p></sec></sec></body><back><ack><p>The authors would like to acknowledge the Herz- und Diabeteszentrum Nordrhein-Westfalen Bad Oeynhausen and the Medius Kliniken N&#x000fc;rtingen for assisting with model training, calibration, and evaluation with their retrospective data. The authors would also like to thank Martijn Vanbiervliet, Jos De Baerdemaeker, Patrick Deutschmann, and Harsh Grover for their support in preparing the software environment for this study.</p><p>JF, NH, and VvD received funding from the ARGUS project (grant 100126059) from the Ruhr-Universit&#x000e4;t Bochum. Authors from Dedalus received funding from the European Union&#x02019;s Horizon 2020 projects GenoMed4All (Genomics and Personalized Medicine for All Though Artificial Intelligence in Haematological Diseases; grant 101017549) and PERSIST (Patients-Centered Survivorship Care Plan After Cancer Treatments Based on Big Data and Artificial Intelligence Technologies; grant 875406).</p></ack><fn-group><fn fn-type="con"><p>Authors' Contributions: PCS, HS, and MR conceptualized the study and designed the evaluation methods. DMR provided input to consolidate the study. HS, MR, and PCS performed model preparation and performance evaluation. PCS performed source data analysis. PCS and MR performed statistical curve calibration and analysis. LM, JF, NH, and VvD provided evaluations from the clinical perspective. RS, JS, KD, and MD coordinated resources to perform the evaluation. HS and PCS wrote the original draft, MR prepared the results, HS made summarizations, and DMR and JF proofread the paper. JF, MD, and LM provided input as medical editors. All authors reviewed and edited the manuscript critically and have approved its final version.</p></fn><fn fn-type="COI-statement"><p>Conflicts of Interest: None declared.</p></fn></fn-group><app-group><supplementary-material id="app1" position="float" content-type="local-data"><label>Multimedia Appendix 1</label><p>Data characteristics in hospitals H and M for each year, number of features used in hospitals H and M, leaking features, and <italic>Z</italic> test results for hospitals H and M.</p><media xlink:href="jmir_v26i1e51409_app1.docx" xlink:title="DOCX File , 27 KB" id="d100e1223" position="anchor"/></supplementary-material><supplementary-material id="app2" position="float" content-type="local-data"><label>Multimedia Appendix 2</label><p>Decision and calibration curve analysis results.</p><media xlink:href="jmir_v26i1e51409_app2.docx" xlink:title="DOCX File , 1309 KB" id="d100e1227" position="anchor"/></supplementary-material></app-group><glossary><title>Abbreviations</title><def-list><def-item><term id="abb1">AKI</term><def><p>acute kidney injury</p></def></def-item><def-item><term id="abb2">AUPRC</term><def><p>area under the precision recall curve</p></def></def-item><def-item><term id="abb3">AUROC</term><def><p>area under the receiver operating characteristic curve</p></def></def-item><def-item><term id="abb4">DCA</term><def><p>decision curve analysis</p></def></def-item><def-item><term id="abb5">ECE</term><def><p>expected calibration error</p></def></def-item><def-item><term id="abb6">EHR</term><def><p>electronic health record</p></def></def-item><def-item><term id="abb7">FN</term><def><p>false negative</p></def></def-item><def-item><term id="abb8">FNR</term><def><p>false-negative rate</p></def></def-item><def-item><term id="abb9">FP</term><def><p>false positive</p></def></def-item><def-item><term id="abb10">FPR</term><def><p>false-positive rate</p></def></def-item><def-item><term id="abb11">ICD-10-GM</term><def><p>German Modification of the International Statistical Classification of Diseases and Related Health Problems, Tenth Revision</p></def></def-item><def-item><term id="abb12">KDIGO</term><def><p>Kidney Disease Improving Global Outcomes</p></def></def-item><def-item><term id="abb13">MCE</term><def><p>maximum calibration error</p></def></def-item><def-item><term id="abb14">ML</term><def><p>machine learning</p></def></def-item><def-item><term id="abb15">NEN</term><def><p>named entity normalization</p></def></def-item><def-item><term id="abb16">NER</term><def><p>named entity recognition</p></def></def-item><def-item><term id="abb17">NLP</term><def><p>natural language processing</p></def></def-item><def-item><term id="abb18">TN</term><def><p>true negative</p></def></def-item><def-item><term id="abb19">TP</term><def><p>true positive</p></def></def-item></def-list></glossary><notes><sec sec-type="data-availability"><title>Data Availability</title><p>Due to commercial restrictions, legal obligations, and data protection, data/code availability is not applicable to this paper.</p></sec></notes><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cutillo</surname><given-names>CM</given-names></name><name><surname>Sharma</surname><given-names>KR</given-names></name><name><surname>Foschini</surname><given-names>L</given-names></name><name><surname>Kundu</surname><given-names>S</given-names></name><name><surname>Mackintosh</surname><given-names>M</given-names></name><name><surname>Mandl</surname><given-names>KD</given-names></name><collab>MI in Healthcare Workshop Working Group</collab></person-group><article-title>Machine intelligence in healthcare-perspectives on trustworthiness, explainability, usability, and transparency</article-title><source>NPJ Digit Med</source><year>2020</year><month>03</month><day>26</day><volume>3</volume><issue>1</issue><fpage>47</fpage><comment>
<ext-link xlink:href="https://doi.org/10.1038/s41746-020-0254-2" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1038/s41746-020-0254-2</pub-id><pub-id pub-id-type="medline">32258429</pub-id><pub-id pub-id-type="pii">254</pub-id><!--<pub-id pub-id-type="pmcid">PMC7099019</pub-id>--><pub-id pub-id-type="pmid">32258429</pub-id>
</element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteva</surname><given-names>A</given-names></name><name><surname>Robicquet</surname><given-names>A</given-names></name><name><surname>Ramsundar</surname><given-names>B</given-names></name><name><surname>Kuleshov</surname><given-names>V</given-names></name><name><surname>DePristo</surname><given-names>M</given-names></name><name><surname>Chou</surname><given-names>K</given-names></name><name><surname>Cui</surname><given-names>C</given-names></name><name><surname>Corrado</surname><given-names>G</given-names></name><name><surname>Thrun</surname><given-names>S</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name></person-group><article-title>A guide to deep learning in healthcare</article-title><source>Nat Med</source><year>2019</year><month>01</month><day>7</day><volume>25</volume><issue>1</issue><fpage>24</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1038/s41591-018-0316-z</pub-id><pub-id pub-id-type="medline">30617335</pub-id><pub-id pub-id-type="pii">10.1038/s41591-018-0316-z</pub-id><pub-id pub-id-type="pmid">30617335</pub-id>
</element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldstein</surname><given-names>BA</given-names></name><name><surname>Navar</surname><given-names>AM</given-names></name><name><surname>Pencina</surname><given-names>MJ</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><article-title>Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review</article-title><source>J Am Med Inform Assoc</source><year>2017</year><month>01</month><volume>24</volume><issue>1</issue><fpage>198</fpage><lpage>208</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/27189013" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1093/jamia/ocw042</pub-id><pub-id pub-id-type="medline">27189013</pub-id><pub-id pub-id-type="pii">ocw042</pub-id><!--<pub-id pub-id-type="pmcid">PMC5201180</pub-id>--><pub-id pub-id-type="pmid">27189013</pub-id>
</element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajkomar</surname><given-names>A</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name><name><surname>Kohane</surname><given-names>I</given-names></name></person-group><article-title>Machine learning in medicine</article-title><source>N Engl J Med</source><year>2019</year><month>04</month><day>04</day><volume>380</volume><issue>14</issue><fpage>1347</fpage><lpage>1358</lpage><pub-id pub-id-type="doi">10.1056/nejmra1814259</pub-id><pub-id pub-id-type="pmid">30943338</pub-id>
</element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Topol</surname><given-names>EJ</given-names></name></person-group><article-title>High-performance medicine: the convergence of human and artificial intelligence</article-title><source>Nat Med</source><year>2019</year><month>01</month><day>7</day><volume>25</volume><issue>1</issue><fpage>44</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/s41591-018-0300-7</pub-id><pub-id pub-id-type="medline">30617339</pub-id><pub-id pub-id-type="pii">10.1038/s41591-018-0300-7</pub-id><pub-id pub-id-type="pmid">30617339</pub-id>
</element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajkomar</surname><given-names>A</given-names></name><name><surname>Oren</surname><given-names>E</given-names></name><name><surname>Chen</surname><given-names>K</given-names></name><name><surname>Dai</surname><given-names>AM</given-names></name><name><surname>Hajaj</surname><given-names>N</given-names></name><name><surname>Hardt</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>PJ</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Marcus</surname><given-names>J</given-names></name><name><surname>Sun</surname><given-names>M</given-names></name><name><surname>Sundberg</surname><given-names>P</given-names></name><name><surname>Yee</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Flores</surname><given-names>G</given-names></name><name><surname>Duggan</surname><given-names>GE</given-names></name><name><surname>Irvine</surname><given-names>J</given-names></name><name><surname>Le</surname><given-names>Q</given-names></name><name><surname>Litsch</surname><given-names>K</given-names></name><name><surname>Mossin</surname><given-names>A</given-names></name><name><surname>Tansuwan</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Wexler</surname><given-names>J</given-names></name><name><surname>Wilson</surname><given-names>J</given-names></name><name><surname>Ludwig</surname><given-names>D</given-names></name><name><surname>Volchenboum</surname><given-names>SL</given-names></name><name><surname>Chou</surname><given-names>K</given-names></name><name><surname>Pearson</surname><given-names>M</given-names></name><name><surname>Madabushi</surname><given-names>S</given-names></name><name><surname>Shah</surname><given-names>NH</given-names></name><name><surname>Butte</surname><given-names>AJ</given-names></name><name><surname>Howell</surname><given-names>MD</given-names></name><name><surname>Cui</surname><given-names>C</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name></person-group><article-title>Scalable and accurate deep learning with electronic health records</article-title><source>NPJ Digit Med</source><year>2018</year><month>5</month><day>8</day><volume>1</volume><issue>1</issue><fpage>18</fpage><comment>
<ext-link xlink:href="https://doi.org/10.1038/s41746-018-0029-1" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1038/s41746-018-0029-1</pub-id><pub-id pub-id-type="medline">31304302</pub-id><pub-id pub-id-type="pii">29</pub-id><!--<pub-id pub-id-type="pmcid">PMC6550175</pub-id>--><pub-id pub-id-type="pmid">31304302</pub-id>
</element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Depraetere</surname><given-names>K</given-names></name><name><surname>Meesseman</surname><given-names>L</given-names></name><name><surname>De Roo</surname><given-names>J</given-names></name><name><surname>Vanbiervliet</surname><given-names>M</given-names></name><name><surname>De Baerdemaeker</surname><given-names>J</given-names></name><name><surname>Muys</surname><given-names>H</given-names></name><name><surname>von Dossow</surname><given-names>V</given-names></name><name><surname>Hulde</surname><given-names>N</given-names></name><name><surname>Szymanowsky</surname><given-names>R</given-names></name></person-group><article-title>A scalable approach for developing clinical risk prediction applications in different hospitals</article-title><source>J Biomed Inform</source><year>2021</year><month>06</month><volume>118</volume><fpage>103783</fpage><comment>
<ext-link xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S1532-0464(21)00112-X" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.jbi.2021.103783</pub-id><pub-id pub-id-type="medline">33887456</pub-id><pub-id pub-id-type="pii">S1532-0464(21)00112-X</pub-id><pub-id pub-id-type="pmid">33887456</pub-id>
</element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>E</given-names></name><name><surname>Wu</surname><given-names>K</given-names></name><name><surname>Daneshjou</surname><given-names>R</given-names></name><name><surname>Ouyang</surname><given-names>D</given-names></name><name><surname>Ho</surname><given-names>DE</given-names></name><name><surname>Zou</surname><given-names>J</given-names></name></person-group><article-title>How medical AI devices are evaluated: limitations and recommendations from an analysis of FDA approvals</article-title><source>Nat Med</source><year>2021</year><month>04</month><volume>27</volume><issue>4</issue><fpage>582</fpage><lpage>584</lpage><pub-id pub-id-type="doi">10.1038/s41591-021-01312-x</pub-id><pub-id pub-id-type="medline">33820998</pub-id><pub-id pub-id-type="pii">10.1038/s41591-021-01312-x</pub-id><pub-id pub-id-type="pmid">33820998</pub-id>
</element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname><given-names>KE</given-names></name><name><surname>Adams</surname><given-names>R</given-names></name><name><surname>Parent</surname><given-names>C</given-names></name><name><surname>Soleimani</surname><given-names>H</given-names></name><name><surname>Sridharan</surname><given-names>A</given-names></name><name><surname>Johnson</surname><given-names>L</given-names></name><name><surname>Hager</surname><given-names>DN</given-names></name><name><surname>Cosgrove</surname><given-names>SE</given-names></name><name><surname>Markowski</surname><given-names>A</given-names></name><name><surname>Klein</surname><given-names>EY</given-names></name><name><surname>Chen</surname><given-names>ES</given-names></name><name><surname>Saheed</surname><given-names>MO</given-names></name><name><surname>Henley</surname><given-names>M</given-names></name><name><surname>Miranda</surname><given-names>S</given-names></name><name><surname>Houston</surname><given-names>K</given-names></name><name><surname>Linton</surname><given-names>RC</given-names></name><name><surname>Ahluwalia</surname><given-names>AR</given-names></name><name><surname>Wu</surname><given-names>AW</given-names></name><name><surname>Saria</surname><given-names>S</given-names></name></person-group><article-title>Factors driving provider adoption of the TREWS machine learning-based early warning system and its effects on sepsis treatment timing</article-title><source>Nat Med</source><year>2022</year><month>07</month><day>21</day><volume>28</volume><issue>7</issue><fpage>1447</fpage><lpage>1454</lpage><pub-id pub-id-type="doi">10.1038/s41591-022-01895-z</pub-id><pub-id pub-id-type="medline">35864251</pub-id><pub-id pub-id-type="pii">10.1038/s41591-022-01895-z</pub-id><pub-id pub-id-type="pmid">35864251</pub-id>
</element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jauk</surname><given-names>S</given-names></name><name><surname>Kramer</surname><given-names>D</given-names></name><name><surname>Gro&#x000df;auer</surname><given-names>B</given-names></name><name><surname>Rienm&#x000fc;ller</surname><given-names>S</given-names></name><name><surname>Avian</surname><given-names>A</given-names></name><name><surname>Berghold</surname><given-names>A</given-names></name><name><surname>Leodolter</surname><given-names>W</given-names></name><name><surname>Schulz</surname><given-names>S</given-names></name></person-group><article-title>Risk prediction of delirium in hospitalized patients using machine learning: an implementation and prospective evaluation study</article-title><source>J Am Med Inform Assoc</source><year>2020</year><month>07</month><day>01</day><volume>27</volume><issue>9</issue><fpage>1383</fpage><lpage>1392</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/32968811" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1093/jamia/ocaa113</pub-id><pub-id pub-id-type="medline">32968811</pub-id><pub-id pub-id-type="pii">5910737</pub-id><!--<pub-id pub-id-type="pmcid">PMC7647341</pub-id>--><pub-id pub-id-type="pmid">32968811</pub-id>
</element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Depraetere</surname><given-names>K</given-names></name><name><surname>Meesseman</surname><given-names>L</given-names></name><name><surname>Cabanillas Silva</surname><given-names>P</given-names></name><name><surname>Szymanowsky</surname><given-names>R</given-names></name><name><surname>Fliegenschmidt</surname><given-names>J</given-names></name><name><surname>Hulde</surname><given-names>N</given-names></name><name><surname>von Dossow</surname><given-names>V</given-names></name><name><surname>Vanbiervliet</surname><given-names>M</given-names></name><name><surname>De Baerdemaeker</surname><given-names>J</given-names></name><name><surname>Roccaro-Waldmeyer</surname><given-names>DM</given-names></name><name><surname>Stieg</surname><given-names>J</given-names></name><name><surname>Dom&#x000ed;nguez Hidalgo</surname><given-names>M</given-names></name><name><surname>Dahlweid</surname><given-names>F</given-names></name></person-group><article-title>Machine learning&#x02013;based prediction models for different clinical risks in different hospitals: evaluation of live performance</article-title><source>J Med Internet Res</source><year>2022</year><month>06</month><day>07</day><volume>24</volume><issue>6</issue><fpage>e34295</fpage><comment>
<ext-link xlink:href="https://www.jmir.org/2022/6/e34295/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/34295</pub-id><pub-id pub-id-type="medline">35502887</pub-id><pub-id pub-id-type="pii">v24i6e34295</pub-id><!--<pub-id pub-id-type="pmcid">PMC9214618</pub-id>--><pub-id pub-id-type="pmid">35502887</pub-id>
</element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fliegenschmidt</surname><given-names>J</given-names></name><name><surname>Hulde</surname><given-names>N</given-names></name><name><surname>Preising</surname><given-names>M</given-names></name><name><surname>Ruggeri</surname><given-names>S</given-names></name><name><surname>Szymanowsky</surname><given-names>R</given-names></name><name><surname>Meesseman</surname><given-names>L</given-names></name><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Dahlweid</surname><given-names>M</given-names></name><name><surname>van Dossow</surname><given-names>V</given-names></name></person-group><article-title>Leveraging artificial intelligence for the management of postoperative delirium following cardiac surgery</article-title><source>Eur J Anaesthesiol Intensive Care</source><year>2022</year><month>12</month><day>8</day><volume>1</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1097/EA9.0000000000000010</pub-id></element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strating</surname><given-names>T</given-names></name><name><surname>Shafiee Hanjani</surname><given-names>L</given-names></name><name><surname>Tornvall</surname><given-names>I</given-names></name><name><surname>Hubbard</surname><given-names>R</given-names></name><name><surname>Scott</surname><given-names>I</given-names></name></person-group><article-title>Navigating the machine learning pipeline: a scoping review of inpatient delirium prediction models</article-title><source>BMJ Health Care Inform</source><year>2023</year><month>07</month><volume>30</volume><issue>1</issue><fpage>1</fpage><lpage>8</lpage><comment>
<ext-link xlink:href="https://informatics.bmj.com/lookup/pmidlookup?view=long&#x00026;pmid=37407226" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1136/bmjhci-2023-100767</pub-id><pub-id pub-id-type="medline">37407226</pub-id><pub-id pub-id-type="pii">bmjhci-2023-100767</pub-id><!--<pub-id pub-id-type="pmcid">PMC10335592</pub-id>--></element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>SE</given-names></name><name><surname>Lasko</surname><given-names>TA</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Siew</surname><given-names>ED</given-names></name><name><surname>Matheny</surname><given-names>ME</given-names></name></person-group><article-title>Calibration drift in regression and machine learning models for acute kidney injury</article-title><source>J Am Med Inform Assoc</source><year>2017</year><month>11</month><day>01</day><volume>24</volume><issue>6</issue><fpage>1052</fpage><lpage>1061</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/28379439" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1093/jamia/ocx030</pub-id><pub-id pub-id-type="medline">28379439</pub-id><pub-id pub-id-type="pii">3096776</pub-id><!--<pub-id pub-id-type="pmcid">PMC6080675</pub-id>--><pub-id pub-id-type="pmid">28379439</pub-id>
</element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Minne</surname><given-names>L</given-names></name><name><surname>Eslami</surname><given-names>S</given-names></name><name><surname>de Keizer</surname><given-names>N</given-names></name><name><surname>de Jonge</surname><given-names>E</given-names></name><name><surname>de Rooij</surname><given-names>SE</given-names></name><name><surname>Abu-Hanna</surname><given-names>A</given-names></name></person-group><article-title>Effect of changes over time in the performance of a customized SAPS-II model on the quality of care assessment</article-title><source>Intensive Care Med</source><year>2012</year><month>01</month><volume>38</volume><issue>1</issue><fpage>40</fpage><lpage>46</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/22042520" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1007/s00134-011-2390-2</pub-id><pub-id pub-id-type="medline">22042520</pub-id><!--<pub-id pub-id-type="pmcid">PMC3233667</pub-id>--><pub-id pub-id-type="pmid">22042520</pub-id>
</element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Calster</surname><given-names>B</given-names></name><name><surname>Steyerberg</surname><given-names>EW</given-names></name><name><surname>Wynants</surname><given-names>L</given-names></name><name><surname>van Smeden</surname><given-names>M</given-names></name></person-group><article-title>There is no such thing as a validated prediction model</article-title><source>BMC Med</source><year>2023</year><month>02</month><day>24</day><volume>21</volume><issue>1</issue><fpage>70</fpage><comment>
<ext-link xlink:href="https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-023-02779-w" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1186/s12916-023-02779-w</pub-id><pub-id pub-id-type="medline">36829188</pub-id><pub-id pub-id-type="pii">10.1186/s12916-023-02779-w</pub-id><!--<pub-id pub-id-type="pmcid">PMC9951847</pub-id>--><pub-id pub-id-type="pmid">36829188</pub-id>
</element-citation></ref><ref id="ref17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janssen</surname><given-names>KJM</given-names></name><name><surname>Moons</surname><given-names>KGM</given-names></name><name><surname>Kalkman</surname><given-names>CJ</given-names></name><name><surname>Grobbee</surname><given-names>DE</given-names></name><name><surname>Vergouwe</surname><given-names>Y</given-names></name></person-group><article-title>Updating methods improved the performance of a clinical prediction model in new patients</article-title><source>J Clin Epidemiol</source><year>2008</year><month>01</month><volume>61</volume><issue>1</issue><fpage>76</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1016/j.jclinepi.2007.04.018</pub-id><pub-id pub-id-type="medline">18083464</pub-id><pub-id pub-id-type="pii">S0895-4356(07)00213-2</pub-id><pub-id pub-id-type="pmid">18083464</pub-id>
</element-citation></ref><ref id="ref18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>SE</given-names></name><name><surname>Greevy</surname><given-names>RA</given-names></name><name><surname>Lasko</surname><given-names>TA</given-names></name><name><surname>Walsh</surname><given-names>CG</given-names></name><name><surname>Matheny</surname><given-names>ME</given-names></name></person-group><article-title>Detection of calibration drift in clinical prediction models to inform model updating</article-title><source>J Biomed Inform</source><year>2020</year><month>12</month><volume>112</volume><fpage>103611</fpage><comment>
<ext-link xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S1532-0464(20)30239-2" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.jbi.2020.103611</pub-id><pub-id pub-id-type="medline">33157313</pub-id><pub-id pub-id-type="pii">S1532-0464(20)30239-2</pub-id><!--<pub-id pub-id-type="pmcid">PMC8627243</pub-id>--><pub-id pub-id-type="pmid">33157313</pub-id>
</element-citation></ref><ref id="ref19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finlayson</surname><given-names>SG</given-names></name><name><surname>Subbaswamy</surname><given-names>A</given-names></name><name><surname>Singh</surname><given-names>K</given-names></name><name><surname>Bowers</surname><given-names>J</given-names></name><name><surname>Kupke</surname><given-names>A</given-names></name><name><surname>Zittrain</surname><given-names>J</given-names></name><name><surname>Kohane</surname><given-names>IS</given-names></name><name><surname>Saria</surname><given-names>S</given-names></name></person-group><article-title>The clinician and dataset shift in artificial intelligence</article-title><source>N Engl J Med</source><year>2021</year><month>07</month><day>15</day><volume>385</volume><issue>3</issue><fpage>283</fpage><lpage>286</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/34260843" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1056/NEJMc2104626</pub-id><pub-id pub-id-type="medline">34260843</pub-id><!--<pub-id pub-id-type="pmcid">PMC8665481</pub-id>--><pub-id pub-id-type="pmid">34260843</pub-id>
</element-citation></ref><ref id="ref20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>A</given-names></name><name><surname>Cao</surname><given-names>J</given-names></name><name><surname>Lyons</surname><given-names>PG</given-names></name><name><surname>Dutta</surname><given-names>S</given-names></name><name><surname>Major</surname><given-names>VJ</given-names></name><name><surname>&#x000d6;tles</surname><given-names>E</given-names></name><name><surname>Singh</surname><given-names>K</given-names></name></person-group><article-title>Quantification of sepsis model alerts in 24 US Hospitals before and during the COVID-19 pandemic</article-title><source>JAMA Netw Open</source><year>2021</year><month>11</month><day>01</day><volume>4</volume><issue>11</issue><fpage>e2135286</fpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/34797372" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2021.35286</pub-id><pub-id pub-id-type="medline">34797372</pub-id><pub-id pub-id-type="pii">2786356</pub-id><!--<pub-id pub-id-type="pmcid">PMC8605481</pub-id>--><pub-id pub-id-type="pmid">34797372</pub-id>
</element-citation></ref><ref id="ref21"><label>21</label><element-citation publication-type="webpage"><article-title>(Model) professional code* for physicians in Germany -MBO-&#x000c4; 1997 - **The resolutions of the 124st German Medical Assembly 2021 in Berlin</article-title><source>German Medical Association</source><year>2021</year><date-in-citation content-type="access-date">2024-03-12</date-in-citation><comment>
<ext-link xlink:href="https://www.bundesaerztekammer.de/fileadmin/user_upload/BAEK/Themen/Internationales/Model-Professional_Code_for_Physicians_124_DAET_210505.pdf" ext-link-type="uri">https://www.bundesaerztekammer.de/fileadmin/user_upload/BAEK/Themen/Internationales/Model-Professional_Code_for_Physicians_124_DAET_210505.pdf</ext-link>
</comment></element-citation></ref><ref id="ref22"><label>22</label><element-citation publication-type="webpage"><article-title>Ethics and data protection</article-title><source>European Commission</source><year>2021</year><date-in-citation content-type="access-date">2024-12-03</date-in-citation><comment>
<ext-link xlink:href="https://ec.europa.eu/info/funding-tenders/opportunities/docs/2021-2027/horizon/guidance/ethics-and-data-protection_he_en.pdf" ext-link-type="uri">https://ec.europa.eu/info/funding-tenders/opportunities/docs/2021-2027/horizon/guidance/ethics-and-data-protection_he_en.pdf</ext-link>
</comment></element-citation></ref><ref id="ref23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>da Silva Ramos</surname><given-names>FJ</given-names></name><name><surname>de Freitas</surname><given-names>FGR</given-names></name><name><surname>Machado</surname><given-names>FR</given-names></name></person-group><article-title>Sepsis in patients hospitalized with coronavirus disease 2019: how often and how severe?</article-title><source>Curr Opin Crit Care</source><year>2021</year><month>10</month><day>01</day><volume>27</volume><issue>5</issue><fpage>474</fpage><lpage>479</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/34292175" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1097/MCC.0000000000000861</pub-id><pub-id pub-id-type="medline">34292175</pub-id><pub-id pub-id-type="pii">00075198-202110000-00005</pub-id><!--<pub-id pub-id-type="pmcid">PMC8452249</pub-id>--><pub-id pub-id-type="pmid">34292175</pub-id>
</element-citation></ref><ref id="ref24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sung</surname><given-names>M</given-names></name><name><surname>Jeon</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Kang</surname><given-names>J</given-names></name></person-group><article-title>Biomedical entity representations with synonym marginalization</article-title><source>arXiv:200500239 [cs]</source><comment>
<ext-link xlink:href="http://arxiv.org/abs/2005.00239" ext-link-type="uri"/>
</comment><comment>Preprint posted online 2020</comment><pub-id pub-id-type="doi">10.18653/v1/2020.acl-main.335</pub-id></element-citation></ref><ref id="ref25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khwaja</surname><given-names>A</given-names></name></person-group><article-title>KDIGO clinical practice guidelines for acute kidney injury</article-title><source>Nephron Clin Pract</source><year>2012</year><month>8</month><day>7</day><volume>120</volume><issue>4</issue><fpage>c179</fpage><lpage>c184</lpage><comment>
<ext-link xlink:href="https://doi.org/10.1159/000339789" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1159/000339789</pub-id><pub-id pub-id-type="medline">22890468</pub-id><pub-id pub-id-type="pii">000339789</pub-id><pub-id pub-id-type="pmid">22890468</pub-id>
</element-citation></ref><ref id="ref26"><label>26</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>L</given-names></name><name><surname>Gomez</surname><given-names>AN</given-names></name><name><surname>Kaiser</surname><given-names>&#x00141;</given-names></name><name><surname>Polosukhin</surname><given-names>I</given-names></name></person-group><article-title>Attention is all you need</article-title><year>2017</year><conf-name>NIPS 2017: 31st Conference on Neural Information Processing Systems</conf-name><conf-date>December 4-9, 2017</conf-date><conf-loc>Long Beach, CA</conf-loc></element-citation></ref><ref id="ref27"><label>27</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Platt</surname><given-names>J</given-names></name></person-group><article-title>Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</article-title><source>Advances in Large Margin Classifiers</source><year>1999</year><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name><fpage>61</fpage><lpage>74</lpage></element-citation></ref><ref id="ref28"><label>28</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zadrozny</surname><given-names>B</given-names></name><name><surname>Elkan</surname><given-names>C</given-names></name></person-group><article-title>Transforming classifier scores into accurate multiclass probability estimates</article-title><year>2002</year><conf-name>Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</conf-name><conf-date>July 23-26, 2002</conf-date><conf-loc>Edmonton, Alberta</conf-loc><publisher-loc>USA</publisher-loc><publisher-name>Association for Computing Machinery</publisher-name><pub-id pub-id-type="doi">10.1145/775047.775151</pub-id></element-citation></ref><ref id="ref29"><label>29</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>C</given-names></name><name><surname>Pleiss</surname><given-names>G</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Weinberger</surname><given-names>K</given-names></name></person-group><article-title>On calibration of modern neural networks</article-title><year>2017</year><conf-name>ICML'17: 34th International Conference on Machine Learning</conf-name><conf-date>August 6-11, 2017</conf-date><conf-loc>Sydney, NSW</conf-loc><fpage>1321</fpage><lpage>1330</lpage><comment>
<ext-link xlink:href="https://proceedings.mlr.press/v70/guo17a.html" ext-link-type="uri"/>
</comment></element-citation></ref><ref id="ref30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Macheret</surname><given-names>F</given-names></name><name><surname>Gabriel</surname><given-names>RA</given-names></name><name><surname>Ohno-Machado</surname><given-names>L</given-names></name></person-group><article-title>A tutorial on calibration measurements and calibration models for clinical prediction models</article-title><source>J Am Med Inform Assoc</source><year>2020</year><month>04</month><day>01</day><volume>27</volume><issue>4</issue><fpage>621</fpage><lpage>633</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/32106284" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1093/jamia/ocz228</pub-id><pub-id pub-id-type="medline">32106284</pub-id><pub-id pub-id-type="pii">5762806</pub-id><!--<pub-id pub-id-type="pmcid">PMC7075534</pub-id>--><pub-id pub-id-type="pmid">32106284</pub-id>
</element-citation></ref><ref id="ref31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Luo</surname><given-names>Y</given-names></name></person-group><article-title>Improving fairness in the prediction of heart failure length of stay and mortality by integrating social determinants of health</article-title><source>Circ: Heart Failure</source><year>2022</year><month>11</month><volume>15</volume><issue>11</issue><fpage>e009473</fpage><pub-id pub-id-type="doi">10.1161/circheartfailure.122.009473</pub-id><pub-id pub-id-type="pmid">36378761</pub-id>
</element-citation></ref><ref id="ref32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seyyed-Kalantari</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>McDermott</surname><given-names>MBA</given-names></name><name><surname>Chen</surname><given-names>IY</given-names></name><name><surname>Ghassemi</surname><given-names>M</given-names></name></person-group><article-title>Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations</article-title><source>Nat Med</source><year>2021</year><month>12</month><day>10</day><volume>27</volume><issue>12</issue><fpage>2176</fpage><lpage>2182</lpage><pub-id pub-id-type="doi">10.1038/s41591-021-01595-0</pub-id><pub-id pub-id-type="pmid">34893776</pub-id>
</element-citation></ref><ref id="ref33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>AJ</given-names></name><name><surname>van Calster</surname><given-names>B</given-names></name><name><surname>Steyerberg</surname><given-names>EW</given-names></name></person-group><article-title>A simple, step-by-step guide to interpreting decision curve analysis</article-title><source>Diagn Progn Res</source><year>2019</year><month>10</month><day>04</day><volume>3</volume><issue>1</issue><fpage>18</fpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/31592444" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1186/s41512-019-0064-7</pub-id><pub-id pub-id-type="medline">31592444</pub-id><pub-id pub-id-type="pii">64</pub-id><!--<pub-id pub-id-type="pmcid">PMC6777022</pub-id>--><pub-id pub-id-type="pmid">31592444</pub-id>
</element-citation></ref><ref id="ref34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Rousson</surname><given-names>V</given-names></name><name><surname>Lee</surname><given-names>W</given-names></name><name><surname>Ferdynus</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Qian</surname><given-names>X</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><collab>written on behalf of AME Big-Data Clinical Trial Collaborative Group</collab></person-group><article-title>Decision curve analysis: a technical note</article-title><source>Ann Transl Med</source><year>2018</year><month>08</month><volume>6</volume><issue>15</issue><fpage>308</fpage><lpage>308</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/30211196" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.21037/atm.2018.07.02</pub-id><pub-id pub-id-type="medline">30211196</pub-id><pub-id pub-id-type="pii">atm-06-15-308</pub-id><!--<pub-id pub-id-type="pmcid">PMC6123195</pub-id>--><pub-id pub-id-type="pmid">30211196</pub-id>
</element-citation></ref><ref id="ref35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanley</surname><given-names>JA</given-names></name><name><surname>McNeil</surname><given-names>BJ</given-names></name></person-group><article-title>The meaning and use of the area under a receiver operating characteristic (ROC) curve</article-title><source>Radiology</source><year>1982</year><month>04</month><volume>143</volume><issue>1</issue><fpage>29</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1148/radiology.143.1.7063747</pub-id><pub-id pub-id-type="medline">7063747</pub-id><pub-id pub-id-type="pmid">7063747</pub-id>
</element-citation></ref><ref id="ref36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rothman</surname><given-names>M</given-names></name><name><surname>Levy</surname><given-names>M</given-names></name><name><surname>Dellinger</surname><given-names>R</given-names></name><name><surname>Jones</surname><given-names>S</given-names></name><name><surname>Fogerty</surname><given-names>R</given-names></name><name><surname>Voelker</surname><given-names>K</given-names></name><name><surname>Gross</surname><given-names>B</given-names></name><name><surname>Marchetti</surname><given-names>A</given-names></name><name><surname>Beals</surname><given-names>IJ</given-names></name></person-group><article-title>Sepsis as 2 problems: identifying sepsis at admission and predicting onset in the hospital using an electronic medical record-based acuity score</article-title><source>J Crit Care</source><year>2017</year><month>04</month><volume>38</volume><fpage>237</fpage><lpage>244</lpage><comment>
<ext-link xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0883-9441(16)30277-5" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.jcrc.2016.11.037</pub-id><pub-id pub-id-type="medline">27992851</pub-id><pub-id pub-id-type="pii">S0883-9441(16)30277-5</pub-id><pub-id pub-id-type="pmid">27992851</pub-id>
</element-citation></ref></ref-list></back></article>