<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006418</article-id><article-id pub-id-type="pmc">PMC11859420</article-id><article-id pub-id-type="doi">10.3390/s25041189</article-id><article-id pub-id-type="publisher-id">sensors-25-01189</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Cross-Machine Intelligent Fault Diagnosis Method with Small and Imbalanced Data Based on the ResFCN Deep Transfer Learning Model</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Juanru</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af1-sensors-25-01189" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Yuan</surname><given-names>Mei</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><xref rid="af1-sensors-25-01189" ref-type="aff">1</xref><xref rid="af2-sensors-25-01189" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Cui</surname><given-names>Yiwen</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="af1-sensors-25-01189" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Cui</surname><given-names>Jin</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af1-sensors-25-01189" ref-type="aff">1</xref><xref rid="c1-sensors-25-01189" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Li</surname><given-names>Yongbo</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Wang</surname><given-names>Teng</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Noman</surname><given-names>Khandaker</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Li</surname><given-names>Bing</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01189"><label>1</label>School of Automation Science and Electrical Engineering, Beihang University, Beijing 100191, China; <email>audrey_zhao@buaa.edu.cn</email> (J.Z.); <email>yuanm@buaa.edu.cn</email> (M.Y.); <email>zy2343223@buaa.edu.cn</email> (Y.C.)</aff><aff id="af2-sensors-25-01189"><label>2</label>Ningbo Institute of Technology, Beihang University, Ningbo 315000, China</aff><author-notes><corresp id="c1-sensors-25-01189"><label>*</label>Correspondence: <email>jincui@buaa.edu.cn</email></corresp></author-notes><pub-date pub-type="epub"><day>15</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1189</elocation-id><history><date date-type="received"><day>14</day><month>1</month><year>2025</year></date><date date-type="rev-recd"><day>10</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>13</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Intelligent fault diagnosis (IFD) for mechanical equipment based on small and imbalanced datasets has been widely studied in recent years, with transfer learning emerging as one of the most promising approaches. Existing transfer learning-based IFD methods typically use data from different operating conditions of the same equipment as the source and target domains for the transfer learning process. However, in practice, it is often challenging to find identical equipment to obtain source domain data when diagnosing faults in the target equipment. These strict assumptions pose significant limitations on the application of IFD techniques in real-world industrial settings. Furthermore, the temporal characteristics of time-series monitoring data are often inadequately considered in existing methods. In this paper, we propose a cross-machine IFD method based on a residual full convolutional neural network (ResFCN) transfer learning model, which leverages the time-series features of monitoring data. By incorporating sliding window (SW)-based data segmentation, network pretraining, and model fine-tuning, the proposed method effectively exploits fault-associated general features in the source domain and learns domain-specific patterns that better align with the target domain, ultimately achieving accurate fault diagnosis for the target equipment. We design and implement three sets of experiments using two widely used public datasets. The results demonstrate that the proposed method outperforms existing approaches in terms of fault diagnosis accuracy and robustness.</p></abstract><kwd-group><kwd>deep transfer learning</kwd><kwd>small and imbalanced data</kwd><kwd>intelligent fault diagnosis</kwd><kwd>feature adaption</kwd><kwd>fully convolutional neural network</kwd></kwd-group><funding-group><award-group><funding-source>Data-Driven Trusted Service Collaboration and Precision Forecasting in Multi-Chain Networks of Parts Supply Chain. National Key Research and Development Program of China</funding-source><award-id>2022YFB3305603</award-id></award-group><funding-statement>This research was funded by Grant No.: 2022YFB3305603, Project Name: Data-Driven Trusted Service Collaboration and Precision Forecasting in Multi-Chain Networks of Parts Supply Chain. National Key Research and Development Program of China.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01189"><title>1. Introduction</title><p>Fault diagnosis plays a crucial role in the health management of mechanical equipment [<xref rid="B1-sensors-25-01189" ref-type="bibr">1</xref>,<xref rid="B2-sensors-25-01189" ref-type="bibr">2</xref>]. With the rapid development of machine learning, particularly deep learning, intelligent fault diagnosis (IFD) has become an important topic in the engineering field [<xref rid="B3-sensors-25-01189" ref-type="bibr">3</xref>,<xref rid="B4-sensors-25-01189" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-01189" ref-type="bibr">5</xref>]. Data-driven IFD methods can automatically extract meaningful features from monitoring data [<xref rid="B6-sensors-25-01189" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-01189" ref-type="bibr">7</xref>], establishing a link between these features and the equipment&#x02019;s health status. This allows users to make timely maintenance decisions [<xref rid="B8-sensors-25-01189" ref-type="bibr">8</xref>,<xref rid="B9-sensors-25-01189" ref-type="bibr">9</xref>], leading to reduced downtime, lower maintenance costs, and fewer failures, thus minimizing economic losses [<xref rid="B10-sensors-25-01189" ref-type="bibr">10</xref>] while achieving a balance between equipment reliability and cost efficiency [<xref rid="B11-sensors-25-01189" ref-type="bibr">11</xref>].</p><p>In general, achieving high-precision IFD with deep learning requires two key assumptions: a large amount of labeled data from both normal and fault conditions [<xref rid="B12-sensors-25-01189" ref-type="bibr">12</xref>], and data for training and testing that come from the same distribution [<xref rid="B13-sensors-25-01189" ref-type="bibr">13</xref>]. However, in practical engineering scenarios, machines typically operate under normal conditions, with limited fault data available [<xref rid="B14-sensors-25-01189" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-01189" ref-type="bibr">15</xref>]. In addition, variations in operating conditions and environmental factors result in differences in data distribution [<xref rid="B16-sensors-25-01189" ref-type="bibr">16</xref>], making it difficult to create an ideal dataset for model training [<xref rid="B17-sensors-25-01189" ref-type="bibr">17</xref>]. When the diagnostic model is trained on limited fault data, its ability to generalize is reduced, which leads to lower accuracy and poor fault identification performance [<xref rid="B18-sensors-25-01189" ref-type="bibr">18</xref>]. As a result, IFD in real-world applications often involves small and imbalanced datasets (S&#x00026;I-IFD) [<xref rid="B19-sensors-25-01189" ref-type="bibr">19</xref>,<xref rid="B20-sensors-25-01189" ref-type="bibr">20</xref>], where only a small number of fault samples are used to train the model for accurate fault identification.</p><p>Transfer learning has emerged as a key technique for addressing the S&#x00026;I-IFD problem [<xref rid="B21-sensors-25-01189" ref-type="bibr">21</xref>]. Qian et al. [<xref rid="B22-sensors-25-01189" ref-type="bibr">22</xref>] proposed a transfer learning method that leverages large amounts of balanced data from the source domain to assist target domain data, which are often limited and imbalanced. The main idea of transfer learning is to make full use of the large amount of balanced data collected from the source domain to assist the target domain data [<xref rid="B23-sensors-25-01189" ref-type="bibr">23</xref>], which include few data and are imbalanced, for training to achieve fault diagnosis. Specifically, the source and target domains have different data distributions but contain similar information about faults, and transfer learning can improve fault diagnosis accuracy by reducing the differences between the source and target domains and learning valid information. Qin et al. [<xref rid="B24-sensors-25-01189" ref-type="bibr">24</xref>] investigated cross-domain fault diagnosis of rolling bearings and introduced a transfer learning method based on similar distribution adaptation, effectively addressing the distribution differences between the source and target domains. Additionally, Zhu et al. [<xref rid="B25-sensors-25-01189" ref-type="bibr">25</xref>] proposed a transfer learning approach that incorporates a refined pseudo-labeling mechanism, effectively improving fault diagnosis accuracy and robustness under varying working conditions. In this paper, the data obtained in the laboratory correspond to the source domain data and the real data to be diagnosed in the industrial environment correspond to the target domain data.</p><p>In industrial environments, it is often difficult to obtain sufficient data from the same equipment under varying conditions. To address this, many studies have utilized large amounts of fault-related data collected in laboratory settings, where damage is manually induced to simulate faults. These datasets, while balanced and containing valuable diagnostic information, often differ significantly from real-world data due to variations in equipment type, sensor placement, and operating conditions. Despite these differences, the internal composition, fault types, and failure mechanisms of the equipment remain similar, making it a valuable task to explore and transfer the features and information contained in laboratory data to real-world scenarios.</p><p>In recent years, deep learning has demonstrated a stronger ability for adaptive feature extraction [<xref rid="B26-sensors-25-01189" ref-type="bibr">26</xref>], significantly reducing the complexity of feature learning. As illustrated in <xref rid="sensors-25-01189-f001" ref-type="fig">Figure 1</xref>, the hierarchical nature of deep learning allows the initial layers of the model to extract shallow, general features, while the deeper layers are increasingly focused on learning task-specific features [<xref rid="B27-sensors-25-01189" ref-type="bibr">27</xref>]. This hierarchical structure makes deep learning models highly transferable. Several deep transfer learning methods have been proposed to address the S&#x00026;I-IFD problem [<xref rid="B28-sensors-25-01189" ref-type="bibr">28</xref>]. For instance, Li et al. [<xref rid="B29-sensors-25-01189" ref-type="bibr">29</xref>] proposed a dynamic weight aggregation deep continuous transfer learning network for fault diagnosis in rotating machinery, while Wu et al. [<xref rid="B30-sensors-25-01189" ref-type="bibr">30</xref>] introduced a multi-source domain adversarial migratory learning network, guided by conditional distribution, for fault diagnosis in rolling bearings.</p><p>Although the transfer learning methods mentioned above have addressed the issue of cross-domain fault diagnosis to some extent, they are primarily limited to cases where data are obtained from the same equipment under different operating conditions or locations. In real-world industrial settings, the target domain data for diagnosis are typically small and imbalanced, and it is often difficult to obtain data from the same equipment under alternative conditions. As a result, the aforementioned transfer learning methods have certain limitations. To overcome this, some studies have focused on generating large datasets of fault-related data in laboratory settings, where damage is intentionally induced, and then using these data for fault diagnosis. While the working conditions, size, and model of the laboratory equipment may differ from the actual equipment, the internal components, failure types, and causes of failure are often similar. Therefore, leveraging large, publicly available, and well-balanced laboratory datasets to explore the features and information they contain, and transferring this knowledge to the actual equipment, presents a valuable opportunity for enhancing intelligent fault diagnosis.</p><p>At the same time, data for fault diagnosis are usually time-series data with time-correlated properties. Unlike other types of data, there is a correlation between successive values in time-series data. Additionally, unlike two-dimensional images, time-series data contain only a single time dimension. Therefore, fault diagnosis requires the careful selection of an appropriate model and the application of methods that can effectively leverage this temporal correlation.</p><p>Additionally, fault diagnosis data are typically time-series data with strong temporal correlations. Unlike two-dimensional image data, time-series data exhibit dependencies between successive time points and contain only one time dimension. Existing methods often overlook this temporal nature, directly applying transfer strategies developed for image data. This highlights the need for methods that can effectively leverage the temporal characteristics of fault diagnosis data to enhance diagnostic accuracy.</p><p>Inspired by the above ideas, this paper proposes an S&#x00026;I-IFD method based on deep transfer learning. The method leverages large and balanced equipment monitoring data obtained from laboratory settings to assist small and imbalanced monitoring data in real scenarios, building an accurate intelligent diagnosis model to achieve fault identification in real-world applications. The proposed method consists of three parts: data segmentation based on sliding window (SW), network pre-training based on residual fully convolutional networks (ResFCNs), and transfer learning. SW-based data segmentation makes full use of the temporal characteristics of the data, and the number of samples of different classes is initially balanced through the adjustment of parameters to obtain more balanced samples for subsequent feature extraction of the deep network. The ResFCN effectively extracts and mines multi-scale temporal features with the help of source domain data. Transfer learning uses a small amount of target domain data to fine-tune the pre-trained model, enabling it to learn personalized features that better match the target domain while incorporating general features from the source domain. In addition, the performance of the proposed method is evaluated using two publicly available datasets. Its effectiveness and advantages are demonstrated through a comprehensive comparison with several existing methods in related fields. The main contributions of this paper can be summarized as follows:<list list-type="order"><list-item><p>A novel method is proposed for solving the S&#x00026;I-IFD problem, enabling accurate fault diagnosis in real-world scenarios by leveraging large and balanced laboratory data to assist small and imbalanced real-world data. Unlike existing methods, this work addresses the larger gap between source and target domains, making it more challenging and valuable for practical applications.</p></list-item><list-item><p>The method employs data segmentation techniques and network models tailored to the temporal characteristics of fault diagnosis data. It bridges the gap between source and target domain data, effectively extracting and combining the general features from the source domain with the specific features of the target domain, making full use of the available information.</p></list-item><list-item><p>Experiments were conducted using two publicly available datasets, and the results demonstrate the method&#x02019;s effectiveness and accuracy. Two sets of comparative experiments were designed to further highlight the method&#x02019;s superiority over various existing approaches.</p></list-item></list></p><p>The rest of the paper is organized as follows. <xref rid="sec2-sensors-25-01189" ref-type="sec">Section 2</xref> reviews related research. <xref rid="sec3-sensors-25-01189" ref-type="sec">Section 3</xref> presents the proposed method in detail. A series of experiments are described in <xref rid="sec4-sensors-25-01189" ref-type="sec">Section 4</xref>, followed by a discussion of the results. Finally, conclusions are drawn in <xref rid="sec5-sensors-25-01189" ref-type="sec">Section 5</xref>.</p></sec><sec id="sec2-sensors-25-01189"><title>2. Related Works</title><sec id="sec2dot1-sensors-25-01189"><title>2.1. Fully Convolutional Network</title><p>In response to the limitations of CNNs in fine-grained image segmentation, fully convolutional networks (FCNs) were proposed in 2015 to address pixel-level image classification [<xref rid="B31-sensors-25-01189" ref-type="bibr">31</xref>]. FCNs have demonstrated impressive performance and quality. In an FCN, each output pixel serves as a classifier corresponding to the receptive field, enabling semantic segmentation based on class annotations during pixel-by-pixel training. Unlike traditional CNNs, FCNs can accept input images of arbitrary size while preserving the spatial information in the original input.</p><p>Given the capabilities of FCNs, some researchers have applied them to time-series data. For example, Park et al. [<xref rid="B32-sensors-25-01189" ref-type="bibr">32</xref>] proposed an end-to-end arrhythmia classification system using an LSTM-FCN model, while Wang et al. [<xref rid="B33-sensors-25-01189" ref-type="bibr">33</xref>] used an asymptotic fuzzy polynomial neural network constructed with a FCN to significantly improve the modeling accuracy of time-series datasets.</p><p>The standard structure of an FCN typically consists of a convolutional layer and a fully connected layer. The convolutional layer contains multiple convolutional kernels, each with associated weights and biases. Each neuron in the convolutional layer is connected to neurons in the previous layer within a local region, where the size of the region depends on the convolutional kernel. Assuming layer <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> is the convolutional layer and the input is <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>O</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, the output of the convolutional layer <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>O</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is shown in Equation (1).<disp-formula id="FD1-sensors-25-01189"><label>(1)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>O</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>I</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mi>O</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02217;</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:math></inline-formula> is the number of input neurons at layer <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are the height and width of the convolution kernel at layer <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively, <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the coordinates of the feature map, <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the coordinates of the weights, <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> represent the weights and biases at layer <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, subscripts <inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> represent the positions of the input neurons and the output neurons positions, respectively, and <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the activation function.</p><p>Each node in the fully connected layer is connected to all nodes in the previous layer. Let the weight of the <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> layer be <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, then the output <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> of the fully connected layer is shown in Equation (2).<disp-formula id="FD2-sensors-25-01189"><label>(2)</label><mml:math id="mm19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>I</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:math></inline-formula> denotes the number of input neurons of the <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> fully connected layer, <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the bias of the <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> layer, and the subscripts <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> have the same meaning as the convolutional layer.</p></sec><sec id="sec2dot2-sensors-25-01189"><title>2.2. S&#x00026;I-IFD Based on Transfer Learning</title><p>In intelligent fault diagnosis, classifier design is a crucial step as its performance directly impacts diagnostic accuracy. When training data are limited and imbalanced, classifiers often suffer from overfitting, which reduces classification accuracy. Transfer learning-based methods can improve classification performance by pre-training the classifier using data from other sources.</p><p>Parametric transfer learning is a key approach in deep neural networks, where source domain data are used to train a base model. The structure and parameters of this pre-trained model are then reused and fine-tuned with target domain data to construct a new, specialized network. This approach has been widely adopted and typically falls into two main strategies. The first strategy involves freezing all layers of the pre-trained model before the classifier and updating only the classifier parameters during training with the target domain data. For instance, Zhou et al. [<xref rid="B34-sensors-25-01189" ref-type="bibr">34</xref>] proposed a knowledge-based U-Net and migration learning method for automatic boundary segmentation. Chen et al. [<xref rid="B35-sensors-25-01189" ref-type="bibr">35</xref>] introduced a deep migration learning framework based on feature decomposition for concrete dam deformation prediction, while Li et al. [<xref rid="B36-sensors-25-01189" ref-type="bibr">36</xref>] applied migration learning to predict remaining life under unknown degradation data.</p></sec></sec><sec sec-type="methods" id="sec3-sensors-25-01189"><title>3. Methodology</title><p>In this section, the proposed S&#x00026;I-IFD model is introduced in detail, including the network structure, main components, and transfer strategy.</p><sec id="sec3dot1-sensors-25-01189"><title>3.1. Problem Description</title><p>The proposed S&#x00026;I-IFD model addresses the challenges encountered in real-world fault diagnosis scenarios. In industrial environments, data are typically imbalanced, with a larger proportion of normal data and fewer fault-related instances. As a result, intelligent diagnostic models trained on such data often suffer from underfitting or overfitting, leading to significant reductions in diagnostic accuracy. On the other hand, balanced datasets rich in fault-related information can be obtained in laboratory settings, such as through the manual induction of damage. While the internal mechanisms and failure modes of equipment in both environments are similar, differences in the working conditions, size, and model of the equipment lead to data distributions that are similar but not identical.</p><p>In this diagnostic scenario, we are given the source domain dataset <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:mrow><mml:mfenced><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mi>s</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mi>s</mml:mi></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{"><mml:mrow><mml:mfenced><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msup></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mo>&#x0211d;</mml:mo><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> carries the class label <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from the source domain <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mi>s</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> is the number of classes. Similarly, the target domain dataset <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:mrow><mml:mfenced><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{"><mml:mrow><mml:mfenced><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mo>&#x0211d;</mml:mo><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> carries the class labels <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from the target domain <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. The source domain data are balanced and the target domain data are imbalanced, that is, the target domain has more data of normal classes and fewer data of faulty classes. It is assumed that <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mi>s</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> have the same fault characteristics but follow different data distributions. In this paper, the data obtained in the laboratory correspond to the source domain data and the real data to be diagnosed in the industrial environment correspond to the target domain data. The goal of this study is to use the given data to learn the same features between the two domains, to reduce the distribution differences, and to use the learned features to predict the labels of the target domain data. In particular, the diagnostic scenario is defined as follows.</p><list list-type="order"><list-item><p>The equipment to be diagnosed shares the same fault categories as the laboratory equipment, with similar but not identical bearing types and operating conditions.</p></list-item><list-item><p>A large number of labeled samples are available for each category in the laboratory data, which can be used for the initial training of the diagnostic model.</p></list-item><list-item><p>The real-world training data exhibit class imbalance, with more normal data and fewer faulty instances.</p></list-item></list></sec><sec id="sec3dot2-sensors-25-01189"><title>3.2. Overall Flow of the Diagnostic Framework</title><p>The proposed method consists of three main components: sliding window (SW)-based data segmentation, which balances the data distribution and preserves temporal correlations; network pre-training using the ResFCN, which extracts general features from the source domain data; and transfer learning, which fine-tunes the pre-trained model to adapt to the specific characteristics of the target domain. This method effectively bridges the gap between the source and target domains, enabling accurate fault diagnosis even when the target domain data are small and imbalanced.</p><p>The deep transfer learning method proposed in this study to address the S&#x00026;I-IFD problem is illustrated in <xref rid="sensors-25-01189-f002" ref-type="fig">Figure 2</xref>. Unlike traditional fault diagnosis methods, this approach uses industrial data as the target domain and laboratory data as the source domain to aid in training intelligent diagnostic models. This method overcomes the limitations of small and imbalanced data in the target domain, enabling more effective handling of the S&#x00026;I-IFD problem.</p><p>The whole S&#x00026;I-IFD process can be divided into four steps:</p><p>Step 1: Data Segmentation. The time-series data from both the source and target domains are divided into samples of equal length using the sliding window method. To address the class imbalance in the target domain, different sliding window step sizes are applied to balance the number of samples for each class.</p><p>Step 2: Network Pre-training. The source domain data are split into training and validation sets. The ResFCN deep network model is then trained using the source domain training set and validated with the source domain validation set to ensure the accuracy of the pre-trained model.</p><p>Step 3: Model Transfer. Based on the transfer strategy, the pre-trained model is fine-tuned using the target domain training data to adapt it for S&#x00026;I-IFD tasks.</p><p>Step 4: Model Testing. The trained S&#x00026;I-IFD model is evaluated by classifying the target domain test data.</p></sec><sec id="sec3dot3-sensors-25-01189"><title>3.3. Data Segmentation</title><p>Sensor data collected in industrial environments are typically time-series data. Before applying neural networks for deep feature extraction, data segmentation methods are often employed to divide the data into time segments of a specific length. It is important to note that any missing data or anomalies should be addressed through appropriate data cleaning before this step. One commonly used method for segmentation is the sliding window (SW), which has been widely applied in pattern recognition and other tasks. The two key parameters in SW are the sliding window width <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and the sliding step <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. As shown in <xref rid="sensors-25-01189-f003" ref-type="fig">Figure 3</xref>, the sliding window width represents the segmentation length, while the sliding step indicates the length of each movement of the window during data reading.</p><p>In this study, the sliding window width d&#x02081; is set to 100, which corresponds to 0.01 s based on the sampling rate of 10 kHz. This value is chosen to ensure that sufficient temporal information is captured for feature extraction. The sliding step d<sub>2</sub> is determined to balance the trade-off between computational efficiency and the number of samples.</p><p>Therefore, for a time series of length <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula>, segmented by a window width of <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and step of <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the number of samples <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> can be obtained as shown in Equation (3), where [ . ] is the rounding function.<disp-formula id="FD3-sensors-25-01189"><label>(3)</label><mml:math id="mm43" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>For a fixed time series, the narrower the width of the window and the smaller the step size, the greater the number of samples obtained by segmentation, so the number of samples can be adjusted by adjusting these two parameters. Since the data in the target domain present an imbalanced state, the window width is kept constant and different step lengths are chosen for different classes of data so as to balance the number of samples from different classes and facilitate the feature extraction of the subsequent deep network. Since the data in the target domain present an imbalanced state, the window width is kept constant at 100 (0.01 s), and different step lengths are chosen for different classes of data to balance the number of samples from different classes and facilitate the feature extraction of the subsequent deep network.</p></sec><sec id="sec3dot4-sensors-25-01189"><title>3.4. Network Pre-Training</title><p>The method proposed in this study uses the residual FCN (ResFCN) model to address the S&#x00026;I-IFD problem. FCNs are known for their robustness in handling time-series data, and the deep ResFCN network developed in the study presented herein excels in feature extraction and transferability, providing a strong foundation for subsequent transfer learning. In deep neural networks, the shallow layers typically extract broad, macroscopic features, while the deeper layers focus on more task-specific features. However, features extracted in the shallow layers can overwhelm deeper layers, reducing their ability to extract meaningful information and potentially hindering the model&#x02019;s performance. To address this, we incorporate a residual module that facilitates better integration of shallow features into deeper layers, thus mitigating issues like gradient vanishing and explosion and slowing down overfitting.</p><p>A schematic diagram of the ResFCN structure is shown in <xref rid="sensors-25-01189-f004" ref-type="fig">Figure 4</xref>. The model takes a variable-length time series as input and outputs a class prediction for the data. The input layer is followed by three hidden layers, each performing a series of three operations: convolution, batch normalization, and activation.</p><p>The method proposed in this study leverages the residual FCN (ResFCN) model to address the S&#x00026;I-IFD problem. FCNs are known for their robustness in time-series tasks, and the deep ResFCN network developed in the study presented herein offers strong feature extraction capabilities and high transferability, which enhances subsequent transfer learning. In deep neural networks, shallow layers typically extract broad, macroscopic features, while deeper layers focus on more specific features. However, the shallow-layer features can sometimes overwhelm the deeper layers, as shown in Equation (4), reducing their impact and impairing the model&#x02019;s ability to extract useful information. To address this, we introduce a residual module that effectively integrates shallow features into the deeper layers, mitigating issues like gradient vanishing and explosion and slowing down overfitting.<disp-formula id="FD4-sensors-25-01189"><label>(4)</label><mml:math id="mm44" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi mathvariant="script">B</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Subsequently, the variance of each training batch data is found according to Equation (5).<disp-formula id="FD5-sensors-25-01189"><label>(5)</label><mml:math id="mm45" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi mathvariant="script">B</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi mathvariant="script">B</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Then, the training data of the batch are normalized according to Equation (6) using the obtained mean and variance to obtain a <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> normal distribution, where <inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:mi>&#x003f5;</mml:mi></mml:mrow></mml:math></inline-formula> is the tiny positive number used to avoid the divisor being zero.<disp-formula id="FD6-sensors-25-01189"><label>(6)</label><mml:math id="mm48" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi mathvariant="script">B</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi mathvariant="script">B</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>&#x003f5;</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Finally, scale transformation and offset are performed according to Equation (7) so that the normalized <inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is restricted to be under the normal distribution.<disp-formula id="FD7-sensors-25-01189"><label>(7)</label><mml:math id="mm50" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>BN</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003b2;</mml:mi></mml:mrow></mml:msub><mml:mfenced><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The specific hyperparameters of the three convolutional layers are shown in <xref rid="sensors-25-01189-t001" ref-type="table">Table 1</xref>. This is followed by a pooling layer, which performs a global averaging operation, that is, the results of the previous layer are averaged over the time axis. The pooling layer combines the statistical feature values of multiple pixels in the pooled region instead of using the value of each pixel, which makes the pooling unit less than the detection unit and thus reduces the computational burden. Also, since the next layer of the pooling layer is a fully connected layer, this reduces the input size, thus serving to improve statistical efficiency and reduce the storage requirements for parameters. The output layer uses SoftMax to perform the classification and the number of neurons in this layer is equal to the number of classes <inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula>. Also, the residual structure is used in hidden layer 1 and hidden layer 3 to prevent gradient disappearance, gradient explosion, and overfitting while better preserving the shallow features. Thus, the output of hidden layer 3 <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is shown in Equation (8), where <inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the output of hidden layer 1 and <inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the output of the BN layer in hidden layer 3.<disp-formula id="FD8-sensors-25-01189"><label>(8)</label><mml:math id="mm55" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In the network pre-training phase, the source domain dataset is first divided into a training set and a validation set. A smaller number of epochs is initially selected, and the network is trained using the training set. The validation set is then input into the trained model for evaluation. If the accuracy meets the required threshold, the pre-training process is complete. Otherwise, the model is retrained using the training set until the desired accuracy is achieved. By choosing a small number of epochs, overfitting is avoided during the training process. This gradual training ensures that the pre-trained network reaches an optimal state, neither underfitting nor overfitting, thereby improving generalization and enabling the accurate extraction of fault-related features from the source domain.</p><p>The proposed method involves multiple preprocessing steps and transfer learning processes, which may increase computational overhead. To address this issue, the computational complexity of the ResFCN model and the associated preprocessing steps is analyzed. Preprocessing mainly includes standardizing the time-series data and preparing the source and target datasets for transfer learning. These steps have a complexity that is linear with respect to the size of the dataset, <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mfenced><mml:mi>n</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm57" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> is the number of data points in the time series. The computational complexity of the ResFCN model depends on the number of convolutional layers, the number of filters, and the length of the input time series. For each convolutional layer, the complexity is approximately <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> is the filter length, <inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> is the input sequence length, and <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula> is the number of filters. Based on the hyperparameters in <xref rid="sensors-25-01189-t001" ref-type="table">Table 1</xref>, the complexities of the three convolutional layers are <inline-formula><mml:math id="mm62" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>8</mml:mn><mml:mo>&#x022c5;</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mn>128</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm63" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>&#x022c5;</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mn>256</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo>&#x022c5;</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mn>128</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In addition, the global average pooling layer has a complexity of <inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mfenced><mml:mi>m</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, as it only averages the values along the time axis, while the Softmax layer has a complexity of <inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mfenced><mml:mi>c</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> is the number of classes. In summary, the overall complexity of the ResFCN model is primarily determined by the convolutional layers, with a complexity of <inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The use of residual structures and the global average pooling layer reduces the computational burden to some extent while improving the training efficiency and feature extraction capability of the model. Furthermore, the pretraining process in transfer learning adopts a small number of epochs, which further reduces the computational overhead, ensuring that the model achieves high performance while maintaining manageable computational complexity.</p></sec><sec id="sec3dot5-sensors-25-01189"><title>3.5. Transfer Strategy</title><p>Since the distribution of the source and target domain data differ significantly, the pre-trained model cannot be directly applied to the intelligent diagnosis of the target domain data. To address this, this paper uses a transfer learning approach to fine-tune the pre-trained model with a small amount of target domain data, extracting cross-domain invariants and ultimately achieving intelligent fault diagnosis</p><p>The schematic diagram of transfer learning is shown in <xref rid="sensors-25-01189-f005" ref-type="fig">Figure 5</xref>. First, the pre-training model is obtained by training with the source domain data. Then, the softmax layer of the pre-trained neural network is removed and replaced with another softmax layer with the number of neurons equal to the number of classes in the target domain. The added softmax layer is randomly initialized using Glorot&#x02019;s uniform initialization method. Glorot&#x02019;s uniform distributes the data uniformly over the interval <inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, with limit taking the value shown in Equation (9). Using this model as a base, it is retrained on <inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>.<disp-formula id="FD9-sensors-25-01189"><label>(9)</label><mml:math id="mm71" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>q</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mfenced><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>6</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the number of input neurons and <inline-formula><mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the number of output neurons.</p><p>To improve learning and prevent the model from stalling, a callback function is employed to monitor the loss changes during training. When learning stagnates, reducing the learning rate by a factor of 2&#x02013;10 can help the model tune more accurately and improve performance. We set the change in learning rate to be triggered when <inline-formula><mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> epochs pass without any improvement in model performance. As shown in Equation (10), at each change, the learning rate becomes f times the previous one, with a lower bound of <inline-formula><mml:math id="mm75" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.<disp-formula id="FD10-sensors-25-01189"><label>(10)</label><mml:math id="mm76" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mo>&#x02217;</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The quantity used to measure the model performance is the cross-entropy loss, which portrays the distance between two probability distributions. Let there be <inline-formula><mml:math id="mm77" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> labeled samples and <inline-formula><mml:math id="mm78" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> classes, and the output of the neural network corresponding to each sample <inline-formula><mml:math id="mm79" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is <inline-formula><mml:math id="mm80" overflow="scroll"><mml:mrow><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, which represents the probability that <inline-formula><mml:math id="mm81" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> belongs to each class in the predicted outcome. Then, the formula of cross entropy loss is shown in Equation (11), where <inline-formula><mml:math id="mm82" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is a symbolic function, and the true class of sample <inline-formula><mml:math id="mm83" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is taken as 1 if it is equal to <inline-formula><mml:math id="mm84" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>, otherwise it is taken as 0.<disp-formula id="FD11-sensors-25-01189"><label>(11)</label><mml:math id="mm85" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mi>log</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>To ensure the model&#x02019;s convergence, in this study, we adjust the parameters of the entire network rather than just those of the final softmax layer. This approach leads to a more significant improvement in diagnostic accuracy for the target domain compared to simply initializing all the weights.</p></sec></sec><sec id="sec4-sensors-25-01189"><title>4. Experiments</title><sec id="sec4dot1-sensors-25-01189"><title>4.1. Dataset and S&#x00026;I-IFD Scenario Description</title><p>In this study, we used bearing data to demonstrate the usability and accuracy of the proposed S&#x00026;I-IFD method. The source domain data, representing laboratory data, and the target domain data, representing real equipment data, are derived from two different publicly available bearing datasets that are widely used in research in this field, ensuring the authenticity and accuracy of the data. The details are as follows:</p><p>The source domain data were obtained from the Bearing Data Center at Case Western Reserve University (CWRU) [<xref rid="B37-sensors-25-01189" ref-type="bibr">37</xref>]. These data consist of acceleration signals measured at the drive-side and fan-side bearing positions under four different motor loads, with sampling frequencies of 12 kHz and 48 kHz. For this study, three types of data (normal condition, inner race fault, and outer race fault) with a sampling frequency of 48 kHz were selected, and the appropriate data length was chosen for the experiment. The specific parameters are shown in <xref rid="sensors-25-01189-t002" ref-type="table">Table 2</xref>.</p><p>The target domain data were obtained from the Paderborn University (PU) Bearing Data Center [<xref rid="B38-sensors-25-01189" ref-type="bibr">38</xref>]. These data were collected from the vibration signal of the bearing seat using a piezoelectric accelerometer with a sampling frequency of 64 kHz. In this study, three types of data (normal condition, inner race fault, and outer race fault) were selected. The training data consist of 10 times the normal data compared to the fault data, and the test data are set to the same length. The specific parameters are shown in <xref rid="sensors-25-01189-t003" ref-type="table">Table 3</xref>.</p><p>In the S&#x00026;I-IFD experiment, we constructed a model based on the CWRU dataset (source domain) and transferred it to the PU dataset (target domain). The time waveforms and fast Fourier transform (FFT) spectra of the three types of signals in both the source and target domains are shown in <xref rid="sensors-25-01189-f006" ref-type="fig">Figure 6</xref>, <xref rid="sensors-25-01189-f007" ref-type="fig">Figure 7</xref> and <xref rid="sensors-25-01189-f008" ref-type="fig">Figure 8</xref>. From a fault classification perspective, distinguishing between normal, inner race fault, and outer race fault is challenging, particularly because the FFT spectra of inner and outer race faults are very similar, making fault diagnosis difficult. From the standpoint of data similarity between the source and target domains, the data distributions in both the time and frequency domains are significantly different. It is challenging to find correlations between the source and target domains when comparing them intuitively in these domains, which makes transfer learning difficult. This experiment will demonstrate that the proposed diagnostic method can effectively leverage fault-related information across the two domains.</p><p>The application of the sliding window (SW) method significantly enhances the correlation between the source and target domains by segmenting the time-series data into uniform samples. This segmentation not only balances the data distribution in the target domain but also highlights shared temporal and spectral features between the two domains. For example, as shown in <xref rid="sensors-25-01189-f006" ref-type="fig">Figure 6</xref>, <xref rid="sensors-25-01189-f007" ref-type="fig">Figure 7</xref> and <xref rid="sensors-25-01189-f008" ref-type="fig">Figure 8</xref>, SW-based segmentation reduces the overlap between the inner and outer race fault spectra, making it easier to distinguish between fault types. This improvement in feature separability is critical for the subsequent transfer learning process, as it ensures that the pre-trained model can effectively adapt to the target domain data.</p></sec><sec id="sec4dot2-sensors-25-01189"><title>4.2. S&#x00026;I-IFD Experimental Procedure and Results</title><p>In this section, the usability and accuracy of the S&#x00026;I-IFD method proposed in this paper are investigated using source and target domain data.</p><sec id="sec4dot2dot1-sensors-25-01189"><title>4.2.1. Experimental Procedure</title><p>Using the method proposed in <xref rid="sec3-sensors-25-01189" ref-type="sec">Section 3</xref>, S&#x00026;I-IFD model training is completed using the source domain data aided by the target domain training data. The specific steps and related parameters are as follows.</p><p>Step 1: Data Segmentation. The data for each class in both the source and target domains are partitioned into equal-length samples using the sliding window (SW) method. The sliding window width is set to 100, and the sliding step and the number of samples after segmentation are shown in <xref rid="sensors-25-01189-t004" ref-type="table">Table 4</xref>. The table presents the data in the following order: (normal condition, inner race fault, and outer race fault).</p><p>Step 2: Network Pre-training. The source domain samples are split into a training set and a validation set with a 9:1 ratio. The training set is used to train the ResFCN model for a specified number of epochs, resulting in a pre-trained model. The validation set is then used to verify the model&#x02019;s performance. If the model&#x02019;s accuracy on the validation set exceeds the predefined critical accuracy threshold, training stops; otherwise, training continues. The hyperparameters used during training are listed in <xref rid="sensors-25-01189-t005" ref-type="table">Table 5</xref>.</p><p>Step 3: Model Transfer. The softmax layer of the pre-trained model is removed and replaced with a new one, initialized randomly using Glorot&#x02019;s uniform initialization method. The target domain training samples are then fed into the initialized model, and transfer learning is applied according to the transfer strategy to obtain the final S&#x00026;I-IFD model. To enhance learning, a callback function monitors loss changes, and when 50 epochs pass without improvement in model performance, the learning rate is halved, with a lower bound of 0.001.</p><p>Step 4: Model Testing. The trained S&#x00026;I-IFD model is tested by inputting the target domain test samples. The predicted values are compared with the actual values to calculate the model&#x02019;s accuracy and generate the confusion matrix.</p><p>Experimental Setup. The experiments were developed in Python. The equipment used consists of a PC with an Intel Core i7-8565U CPU (1.80 GHz), 4 GB of RAM, and an NVIDIA GeForce MX230 graphics card.</p></sec><sec id="sec4dot2dot2-sensors-25-01189"><title>4.2.2. Results and Analysis</title><p>The curves of training loss, training accuracy, and learning rate during transfer learning are shown in <xref rid="sensors-25-01189-f009" ref-type="fig">Figure 9</xref>. At the beginning of the transfer learning process, the model&#x02019;s accuracy on the target domain is low, and the loss is high due to the significant difference between the source and target domain data. As training progresses, the accuracy on the training set improves and stabilizes around 1 after approximately 500 epochs, indicating that the model has become well-suited for fault diagnosis in the target domain. As training continues, the learning rate is reduced by half whenever the model&#x02019;s performance stagnates, facilitating further fine-tuning.</p><p>This study visualizes the diagnostic results using a confusion matrix. In the confusion matrix chart, rows correspond to predicted classification, columns correspond to true classification, diagonal lines correspond to observations for correct classification, and off-diagonal lines correspond to observations for incorrect classification, and percentages of the number of observations and a total number of observations are shown in each cell. The rightmost column of the chart shows the percentages of all examples for all categories for both correct and incorrect classifications. The bottom row of the chart shows the percentage of all examples belonging to each category that were correctly and incorrectly categorized. The cell at the bottom right of the graph shows the overall accuracy.</p><p>We define that for each class of sample, the following four classification cases exist: positive samples predicted by the model as positive (True Positive), negative samples predicted by the model as positive (False Positive), positive samples predicted by the model as negative (False Negative), and negative samples predicted by the model as negative (True Negative). Therefore, we use the accuracy, precision, recall, and F1-score as the evaluation metrics of the classification results. As shown in Equation (12), the accuracy reflects the classifier&#x02019;s ability to determine the entire sample. As shown in Equations (13)&#x02013;(15), the precision indicates the proportion of true positive samples among the positive examples determined by the classifier, the recall indicates the proportion of correctly determined positive examples to the total positive examples, and the F1-score is a summed average of the precision and recall. The performance of the classifier on the entire dataset is also evaluated by macro-average, as shown in Equations (16)&#x02013;(18), which is a weighted average of the precision, recall, and F1-score for each degradation state.</p><p>To ensure the generalizability and reliability of the experimental results, the experiments were repeated 10 times and the model was evaluated using the average of the 10 experiments.<disp-formula id="FD13-sensors-25-01189"><label>(12)</label><mml:math id="mm87" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>l</mml:mi><mml:mi>y</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD14-sensors-25-01189"><label>(13)</label><mml:math id="mm88" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD15-sensors-25-01189"><label>(14)</label><mml:math id="mm89" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD16-sensors-25-01189"><label>(15)</label><mml:math id="mm90" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD17-sensors-25-01189"><label>(16)</label><mml:math id="mm91" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mi>Macro</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>avg</mml:mi><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD18-sensors-25-01189"><label>(17)</label><mml:math id="mm92" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi>Macro</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>avg</mml:mi><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD19-sensors-25-01189"><label>(18)</label><mml:math id="mm93" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mi>Macro</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>avg</mml:mi><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mi>F</mml:mi></mml:mstyle><mml:msub><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The confusion matrix of the experimental results is shown in <xref rid="sensors-25-01189-f010" ref-type="fig">Figure 10</xref>, while the accuracy, precision, recall, and F1-score are presented in <xref rid="sensors-25-01189-t006" ref-type="table">Table 6</xref>. We can see that the method proposed in this study uses source domain data to assist in training with small and imbalanced training data in the target domain, and the final classification accuracy of the model obtained is 98.43%. In the classification of each state, all the data of the normal condition are correctly classified, and 96.86% and 98.43% of the data of each of the two fault states are correctly classified, and the classification accuracy of each state is above 97%. This indicates that the method proposed in this study can use a large amount of balanced source domain data to assist training in the case of small and imbalanced training data in the target domain, using a reasonable network model and an effective transfer learning method, and has good feasibility and high accuracy in the research framework proposed in this study.</p></sec></sec><sec id="sec4dot3-sensors-25-01189"><title>4.3. Comparison of the Different Steps of the S&#x00026;I-IFD Method</title><sec id="sec4dot3dot1-sensors-25-01189"><title>4.3.1. Experimental Procedure</title><p>In order to demonstrate the necessity of each step in the method proposed in this study, the results of different experiments are compared in this section by removing specific steps. There are three main steps in the method proposed in this study: data segmentation of time-series data using SW; model pre-training using source domain data; and fine-tuning of the pre-trained model using transfer learning. We removed one or two of these steps, and together with the method proposed in this study, there are six tasks, as shown in <xref rid="sensors-25-01189-t007" ref-type="table">Table 7</xref>.</p><p>Experiments for tasks 1&#x02013;6 were conducted using the same dataset and within the same computational environment. For each task, this study evaluates performance based on 13 indicators: 9 indicators related to the classification performance of each class (precision, recall, and F1-score for each of the normal condition, inner race fault, and outer race fault) and 4 overall evaluation metrics (macro-average precision, recall, and F1-score, as well as overall accuracy). To ensure the robustness of the results, 10 independent experiments were conducted for each task, and the average performance across these 10 experiments is reported.</p></sec><sec id="sec4dot3dot2-sensors-25-01189"><title>4.3.2. Results and Analysis</title><p>The results of the experiments are shown in <xref rid="sensors-25-01189-f011" ref-type="fig">Figure 11</xref> and <xref rid="sensors-25-01189-f012" ref-type="fig">Figure 12</xref>. Tasks 1 and 3 both involve training using only source domain data, and the resulting models were directly tested on the target domain data. Both tasks showed poor performance across all evaluation metrics. Specifically, when examining the accuracy, recall, and F1-score for each class, both models classified almost all data as belonging to the &#x0201c;normal&#x0201d; class, indicating that the classifiers are not suitable for the target domain. The overall accuracy for both methods was approximately 32%, demonstrating that the models hardly serve any useful classification purpose. This poor performance is attributed to the significant difference in data distribution between the source and target domains. A model trained solely on source domain data can only extract features relevant to the source domain and is unable to generalize effectively to the target domain. While both domains contain relevant fault-related features, training only on the source domain without fine-tuning on the target domain data results in models that cannot accurately diagnose faults in the target domain, highlighting the need for transfer learning. Additionally, Task 3 uses sliding window (SW) for data segmentation more than Task 1, leading to a slight improvement in accuracy, though the difference is not significant.</p><p>Tasks 5 and 6 both involve training the model with source domain data and fine-tuning it using target domain training data, followed by testing on target domain test data. These methods show much better performance, with accuracy, recall, and F1-scores for each class indicating that the models can classify the majority of the data correctly. Both tasks achieve accuracy rates exceeding 90%, demonstrating their effectiveness in performing fault diagnosis. This improved performance can be attributed to the combination of large, balanced source domain data and smaller target domain data. The use of model pre-training allows the network to capture fault-related information from the source domain, while transfer learning enables the model to adapt and find common features across the two domains, compensating for the small and imbalanced target domain data. This process also avoids the negative transfer effects caused by the differences in data distribution between the source and target domains. Task 6, which uses more SW for data segmentation than Task 5, results in an accuracy increase from 92% to 98%, further demonstrating that SW helps mitigate the impact of data imbalance and positively influences the final model&#x02019;s performance.</p><p>Overall, the results from these six tasks clearly demonstrate the necessity of the three main steps in the proposed method&#x02014;data segmentation using SW, model pre-training with source domain data, and fine-tuning with transfer learning. Each step plays a crucial role in improving the model&#x02019;s effectiveness and accuracy in fault diagnosis.</p></sec></sec><sec id="sec4dot4-sensors-25-01189"><title>4.4. Comparison with Other Relevant Research Methods</title><sec id="sec4dot4dot1-sensors-25-01189"><title>4.4.1. Experimental Procedure</title><p>In order to demonstrate the superiority of the proposed method in this study, we compared it with nine classical underlying models in related fields. Detailed descriptions of these methods and special parameter settings are as follows.</p><list list-type="order"><list-item><p>The CNN consists of a feature extractor and a label classifier and is a classical neural network. Optimization is performed using random search for relevant hyperparameters.</p></list-item><list-item><p>Long short-term memory network (LSTM) is a commonly used method in time-series data to avoid the long-term dependency problem.</p></list-item><list-item><p>ResFCN is the network model used in this study, and the experimental results using this model are used to compare whether transfer learning will result in negative transfer cases.</p></list-item><list-item><p>Deep neural networks (DNNs) are a commonly used neural network in deep learning, which are optimized using stochastic search for relevant hyperparameters.</p></list-item><list-item><p>TCA [<xref rid="B39-sensors-25-01189" ref-type="bibr">39</xref>] is a classical method in transfer learning, which adaptively draws the probability distribution of the data in the source and target domains through edge distribution, so as to achieve the transfer of the model. Here, the RBF kernel is chosen to calculate the maximum mean difference (MMD).</p></list-item><list-item><p>Balanced distribution adaptation (BDA) [<xref rid="B40-sensors-25-01189" ref-type="bibr">40</xref>] can consider both edge distribution and conditional distribution and adjust the importance of both adaptively according to the data characteristics in the source and target domains. Here, the RBF kernel is chosen to calculate the MMD.</p></list-item><list-item><p>Geodesic flow kernel (GFK) cite [<xref rid="B41-sensors-25-01189" ref-type="bibr">41</xref>] is a streaming learning method that can efficiently implement transfer between two domains.</p></list-item><list-item><p>Correlation alignment (CORAL) [<xref rid="B42-sensors-25-01189" ref-type="bibr">42</xref>] is a statistical feature alignment method that aligns the source and target domains with second-order features, thus reducing the differences in distribution.</p></list-item><list-item><p>The domain adaptive neural network (DANN) [<xref rid="B43-sensors-25-01189" ref-type="bibr">43</xref>] consists of a feature layer and a classifier layer and adds an MMD adaptation layer after the feature layer for computing the distance between the source and target domains.</p></list-item></list><p>Four of them are methods without transfer learning (CNN, LSTM, ResFCN, and DNN) and five are transfer learning methods (TCA, BDA, GFK, CORAL, DANN). For CNN, LSTM, ResFCN, and DNN, no transfer learning is performed and the models are trained directly using the target domain training data, and the trained models are tested using the target domain test data. For TCA, BDA, GFK, CORAL, and DANN, the basic network structure used is ResFCN, and the same source and target domain data are used as before. The models are trained using the source domain data, subsequently transferred to the target domain, and finally tested using the target domain test data.</p><p>For each method, this study evaluates 13 indicators. There are 9 indicators used to describe the classification of each class (precision, recall, and F1-score corresponding to each of the normal condition, inner race fault, and outer race fault), and 4 overall evaluation indicators (macro-average of precision, recall, and F1-score, and accuracy). To ensure the generalizability of the results, 10 experiments were performed for each method, and the 10 results were averaged.</p></sec><sec id="sec4dot4dot2-sensors-25-01189"><title>4.4.2. Results and Analysis</title><p><xref rid="sensors-25-01189-f013" ref-type="fig">Figure 13</xref> and <xref rid="sensors-25-01189-f014" ref-type="fig">Figure 14</xref> plot the overall comparison results of the 10 methods. As basic classifiers, the results of CNN and LSTM are similar without using transfer learning, and the accuracy of the models is 54.8% and 58.99%, respectively, with relatively low classification accuracy. ResFCN and DNN have relatively better results, with the accuracy of the models being around 71%, and the results are similar in the classification of each category. All four methods do not use source domain data but rather target domain data for training and testing. Affected by the small and imbalanced training data in the target domain, the classification effect of the model is a great limitation and the accuracy is not high.</p></sec></sec><sec id="sec4dot5-sensors-25-01189"><title>4.5. Other Transfer Scenarios</title><sec id="sec4dot5dot1-sensors-25-01189"><title>4.5.1. Experimental Procedure</title><p>To better demonstrate the generalization and scalability of the S&#x00026;I-IFD method proposed in this study, 16 different transfer scenarios were designed based on two datasets, CWRU and PU. The source data were obtained from the CWRU dataset, as shown in <xref rid="sensors-25-01189-t008" ref-type="table">Table 8</xref> for the CWRU dataset selected for this study, and they have different working conditions and sensor locations. CWRU-DE-L and CWRU-DE-H are collected by sensors at the drive end (DE) of the bearing, and CWRU-FE-L and CWRU-FE-H are collected by sensors at the fan end (FE) of the bearing. L and H are used to indicate the operating conditions of the bearings, CWRU-DE-L and CWRU-FE-L are collected at a load of 0 kW and a rotation speed of 1797 r/min, and CWRU-DE-H and CWRU-FE-H are collected at a load of 2.21 kW and a rotation speed of 1730 r/min. The target data are obtained from the PU dataset, as shown in <xref rid="sensors-25-01189-t009" ref-type="table">Table 9</xref>, and their working conditions and damage setting modes are different. The damage setting mode for PU-EE-L and PU-EE-H is manual electric engraver (EE), and the damage setting mode for PU-EDM-L and PU-EDM-H is electrical discharge machining (EDM). Similarly, L and H are used to indicate the operating conditions of the bearing. PU-EE-L and PU-EDM-L are taken at a torque of 0.1 Nm and a rotation speed of 1500 r/min, while PU-EE-H and PU-EDM-H are taken at a torque of 0.7 Nm and a rotation speed of 1500 r/min.</p><p>Therefore, 16 transfer learning tasks with different transfer scenarios were constructed, as shown in <xref rid="sensors-25-01189-t010" ref-type="table">Table 10</xref>. The source domain data of these tasks are all from the CWRU dataset and the target domain data are all from the PU dataset, and they all need to complete the fault diagnosis across working conditions and machines. The number of data samples and the selection of the number of sample points in each sample, the setting of hyperparameters, and the selection of evaluation indicators are the same as in <xref rid="sec4dot2-sensors-25-01189" ref-type="sec">Section 4.2</xref>.</p></sec><sec id="sec4dot5dot2-sensors-25-01189"><title>4.5.2. Results and Analysis</title><p>The results of the proposed method in this study on 16 transfer tasks are shown in the table. As can be seen from <xref rid="sensors-25-01189-t011" ref-type="table">Table 11</xref>, the final accuracies of all 16 tasks exceed 97% with an average accuracy of 98.43% under different transfer scenarios, despite the differences in the working conditions, sensor locations, and fault setting methods in the source and target domain data. From the accuracy, recall, and F1-score of each category, the method proposed in this study achieves relatively stable classification results in all 16 tasks, and the average value of each index is above 98%, which is already a relatively good level for a small sample fault diagnosis scenario across working conditions and machines, and the data imbalance condition reaches 10:1. This indicates that the method proposed in this study can sufficiently explore the potentially effective information contained in the small sample data to achieve accurate fault diagnosis, thus proving the usability, accuracy, and stability of the method in the bearing cross-machine fault diagnosis scenario.</p><p>In comparison, existing methods face significant challenges in addressing cross-machine small-sample and imbalanced data fault diagnosis. Traditional transfer learning methods often suffer from negative transfer due to the large discrepancies in operating conditions and structures between the source and target domains. Additionally, the severe imbalance in target domain data, where normal condition data far outnumber fault data, makes it difficult to effectively extract fault-related features, leading to biased predictions toward the majority class. The proposed method overcomes these limitations by leveraging limited target domain data and extracting meaningful cross-domain features. Through the integration of sliding window segmentation and the ResFCN model, the method achieves robust and accurate fault diagnosis in complex cross-machine scenarios, demonstrating strong adaptability and reliability.</p></sec></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-01189"><title>5. Conclusions</title><p>In this paper, we propose a new deep transfer learning method for equipment fault diagnosis. Since it is difficult to build an effective intelligent diagnosis model due to the small and imbalanced samples in real industrial scenarios, we used laboratory data with large and balanced data to assist in training. The target domain data were initially balanced using the SW-based data segmentation method. The universal features associated with faults in the source domain data are effectively mined by the ResFCN network. The pre-trained model is fine-tuned using transfer learning to learn personalized features that better match the target domain. Experimental results using two publicly available datasets show that the method can better span the data differences between the source and target domains in terms of equipment working conditions, sizes, and models and achieve effective feature extraction and high diagnostic accuracy. Compared with other popular advanced methods, this method has obvious advantages.</p><p>The limitation of this study is that the experiments used to validate the proposed method involved the use of publicly available datasets without building equipment and acquiring data in a personal laboratory. In the future, we will build complex and representative bearing equipment, acquire data, and conduct relevant theoretical studies.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, J.Z. and J.C.; methodology, J.Z. and J.C.; software, J.Z.; validation, J.C., M.Y. and Y.C.; formal analysis, J.Z.; investigation, J.Z. and J.C.; resources, M.Y. and J.C.; data curation, Y.C. and J.C.; writing&#x02014;original draft preparation, J.Z.; writing&#x02014;review and editing, J.Z., Y.C. and J.C.; visualization, J.Z.; supervision, J.C.; project administration, J.C.; funding acquisition, J.C. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data used in this study are available from two primary sources. The first dataset is the Bearing Data Center from the Case School of Engineering at Case Western Reserve University, which is accessible online at <uri xlink:href="https://engineering.case.edu/bearingdatacenter">https://engineering.case.edu/bearingdatacenter</uri>, which was accessed on 4 November 2024. The second dataset was provided by Lessmeier et al., entitled Condition Monitoring of Bearing Damage in Electromechanical Drive Systems Using Motor Current Signals of Electric Motors: A Benchmark Data Set for Data-Driven Classification [<xref rid="B38-sensors-25-01189" ref-type="bibr">38</xref>].</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01189"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jiang</surname><given-names>F.</given-names></name>
<name><surname>Lin</surname><given-names>W.</given-names></name>
<name><surname>Wu</surname><given-names>Z.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
<name><surname>Chen</surname><given-names>Z.</given-names></name>
<name><surname>Li</surname><given-names>W.</given-names></name>
</person-group><article-title>Fault Diagnosis of Gearbox Driven by Vibration Response Mechanism and Enhanced Unsupervised Domain Adaptation</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>61</volume><fpage>102460</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102460</pub-id></element-citation></ref><ref id="B2-sensors-25-01189"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Leite</surname><given-names>D.</given-names></name>
<name><surname>Andrade</surname><given-names>E.</given-names></name>
<name><surname>Rativa</surname><given-names>D.</given-names></name>
<name><surname>Maciel</surname><given-names>A.M.A.</given-names></name>
</person-group><article-title>Fault Detection and Diagnosis in Industry 4.0: A Review on Challenges and Opportunities</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>60</elocation-id><pub-id pub-id-type="doi">10.3390/s25010060</pub-id></element-citation></ref><ref id="B3-sensors-25-01189"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>S.</given-names></name>
<name><surname>Yin</surname><given-names>J.</given-names></name>
<name><surname>Hao</surname><given-names>M.</given-names></name>
<name><surname>Liang</surname><given-names>P.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Ai</surname><given-names>C.</given-names></name>
<name><surname>Jiang</surname><given-names>W.</given-names></name>
</person-group><article-title>Fault Diagnosis Study of Hydraulic Pump Based on Improved Symplectic Geometry Reconstruction Data Enhancement Method</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>61</volume><fpage>102459</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102459</pub-id></element-citation></ref><ref id="B4-sensors-25-01189"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>Z.</given-names></name>
<name><surname>Li</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
</person-group><article-title>Real-Time Online Resistance-Alteration-Based Multiple-Fault Diagnosis Framework and Implementation for Mine Ventilation Systems</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>59</volume><fpage>102305</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.102305</pub-id></element-citation></ref><ref id="B5-sensors-25-01189"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Eang</surname><given-names>C.</given-names></name>
<name><surname>Lee</surname><given-names>S.</given-names></name>
</person-group><article-title>Predictive Maintenance and Fault Detection for Motor Drive Control Systems in Industrial Robots Using CNN-RNN-Based Observers</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>25</elocation-id><pub-id pub-id-type="doi">10.3390/s25010025</pub-id></element-citation></ref><ref id="B6-sensors-25-01189"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>J.</given-names></name>
<name><surname>Yuan</surname><given-names>M.</given-names></name>
<name><surname>Cui</surname><given-names>J.</given-names></name>
<name><surname>Dong</surname><given-names>S.</given-names></name>
<name><surname>Mei</surname><given-names>S.</given-names></name>
</person-group><article-title>An Unsupervised Pairwise Comparison Learning Approach With Adaptive Network Structure for Equipment Health Quantitative Assessment</article-title><source>IEEE Sens. J.</source><year>2023</year><volume>23</volume><fpage>11978</fpage><lpage>11991</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2023.3268462</pub-id></element-citation></ref><ref id="B7-sensors-25-01189"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Alharbi</surname><given-names>F.</given-names></name>
<name><surname>Luo</surname><given-names>S.</given-names></name>
<name><surname>Alsaedi</surname><given-names>A.</given-names></name>
<name><surname>Zhao</surname><given-names>S.</given-names></name>
<name><surname>Yang</surname><given-names>G.</given-names></name>
</person-group><article-title>CASSAD: Chroma-Augmented Semi-Supervised Anomaly Detection for Conveyor Belt Idlers</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>7569</elocation-id><pub-id pub-id-type="doi">10.3390/s24237569</pub-id><pub-id pub-id-type="pmid">39686107</pub-id>
</element-citation></ref><ref id="B8-sensors-25-01189"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pu</surname><given-names>Y.</given-names></name>
<name><surname>Tang</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Wei</surname><given-names>C.</given-names></name>
<name><surname>Huang</surname><given-names>W.</given-names></name>
<name><surname>Ding</surname><given-names>X.</given-names></name>
</person-group><article-title>Single-Domain Incremental Generation Network for Machinery Intelligent Fault Diagnosis under Unknown Working Speeds</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102400</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102400</pub-id></element-citation></ref><ref id="B9-sensors-25-01189"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mei</surname><given-names>S.</given-names></name>
<name><surname>Yuan</surname><given-names>M.</given-names></name>
<name><surname>Cui</surname><given-names>J.</given-names></name>
<name><surname>Dong</surname><given-names>S.</given-names></name>
<name><surname>Zhao</surname><given-names>J.</given-names></name>
</person-group><article-title>Machinery Condition Monitoring in the Era of Industry 4.0: A Relative Degree of Contribution Feature Selection and Deep Residual Network Combined Approach</article-title><source>Comput. Ind. Eng.</source><year>2022</year><volume>168</volume><fpage>108129</fpage><pub-id pub-id-type="doi">10.1016/j.cie.2022.108129</pub-id></element-citation></ref><ref id="B10-sensors-25-01189"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>J.</given-names></name>
<name><surname>Yuan</surname><given-names>M.</given-names></name>
<name><surname>Cui</surname><given-names>J.</given-names></name>
<name><surname>Huang</surname><given-names>J.</given-names></name>
<name><surname>Zhao</surname><given-names>F.</given-names></name>
<name><surname>Dong</surname><given-names>S.</given-names></name>
<name><surname>Qu</surname><given-names>Y.</given-names></name>
</person-group><article-title>A Novel Hierarchical Training Architecture for Siamese Neural Network Based Fault Diagnosis Method under Small Sample</article-title><source>Measurement</source><year>2023</year><volume>215</volume><fpage>112851</fpage><pub-id pub-id-type="doi">10.1016/j.measurement.2023.112851</pub-id></element-citation></ref><ref id="B11-sensors-25-01189"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Gao</surname><given-names>T.</given-names></name>
<name><surname>Wu</surname><given-names>W.</given-names></name>
<name><surname>Sun</surname><given-names>Y.</given-names></name>
</person-group><article-title>Planetary Gearboxes Fault Diagnosis Based on Markov Transition Fields and SE-ResNet</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>7540</elocation-id><pub-id pub-id-type="doi">10.3390/s24237540</pub-id><pub-id pub-id-type="pmid">39686076</pub-id>
</element-citation></ref><ref id="B12-sensors-25-01189"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lu</surname><given-names>J.</given-names></name>
<name><surname>Wu</surname><given-names>W.</given-names></name>
<name><surname>Huang</surname><given-names>X.</given-names></name>
<name><surname>Yin</surname><given-names>Q.</given-names></name>
<name><surname>Yang</surname><given-names>K.</given-names></name>
<name><surname>Li</surname><given-names>S.</given-names></name>
</person-group><article-title>A Modified Active Learning Intelligent Fault Diagnosis Method for Rolling Bearings with Unbalanced Samples</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102397</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102397</pub-id></element-citation></ref><ref id="B13-sensors-25-01189"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>C.</given-names></name>
<name><surname>Shen</surname><given-names>W.</given-names></name>
</person-group><article-title>Imbalanced Domain Generalization via Semantic-Discriminative Augmentation for Intelligent Fault Diagnosis</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>59</volume><fpage>102262</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.102262</pub-id></element-citation></ref><ref id="B14-sensors-25-01189"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chang</surname><given-names>S.</given-names></name>
<name><surname>Wang</surname><given-names>L.</given-names></name>
<name><surname>Shi</surname><given-names>M.</given-names></name>
<name><surname>Zhang</surname><given-names>J.</given-names></name>
<name><surname>Yang</surname><given-names>L.</given-names></name>
<name><surname>Cui</surname><given-names>L.</given-names></name>
</person-group><article-title>Extended Attention Signal Transformer with Adaptive Class Imbalance Loss for Long-Tailed Intelligent Fault Diagnosis of Rotating Machinery</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102436</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102436</pub-id></element-citation></ref><ref id="B15-sensors-25-01189"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hu</surname><given-names>Y.</given-names></name>
<name><surname>Xie</surname><given-names>Q.</given-names></name>
<name><surname>Yang</surname><given-names>X.</given-names></name>
<name><surname>Yang</surname><given-names>H.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
</person-group><article-title>An Attention-Based Multidimensional Fault Information Sharing Framework for Bearing Fault Diagnosis</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>224</elocation-id><pub-id pub-id-type="doi">10.3390/s25010224</pub-id><pub-id pub-id-type="pmid">39797015</pub-id>
</element-citation></ref><ref id="B16-sensors-25-01189"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>D.</given-names></name>
<name><surname>Liu</surname><given-names>S.</given-names></name>
<name><surname>Miao</surname><given-names>Z.</given-names></name>
<name><surname>Zhang</surname><given-names>H.</given-names></name>
<name><surname>Dou</surname><given-names>W.</given-names></name>
</person-group><article-title>Subdomain Adaptation Joint Attention Network Enabled Two-Stage Strategy towards Few-Shot Fault Diagnosis of LRE Turbopump</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102366</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102366</pub-id></element-citation></ref><ref id="B17-sensors-25-01189"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>F.</given-names></name>
<name><surname>Zhang</surname><given-names>F.</given-names></name>
<name><surname>Geng</surname><given-names>X.</given-names></name>
<name><surname>Mu</surname><given-names>L.</given-names></name>
<name><surname>Zhang</surname><given-names>L.</given-names></name>
<name><surname>Sui</surname><given-names>Q.</given-names></name>
<name><surname>Jia</surname><given-names>L.</given-names></name>
<name><surname>Jiang</surname><given-names>M.</given-names></name>
<name><surname>Gao</surname><given-names>J.</given-names></name>
</person-group><article-title>Structural Discrepancy and Domain Adversarial Fusion Network for Cross-Domain Fault Diagnosis</article-title><source>Adv. Eng. Inform.</source><year>2023</year><volume>58</volume><fpage>102217</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.102217</pub-id></element-citation></ref><ref id="B18-sensors-25-01189"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Jiang</surname><given-names>L.</given-names></name>
<name><surname>Wang</surname><given-names>L.</given-names></name>
<name><surname>Zhang</surname><given-names>T.</given-names></name>
<name><surname>Zhang</surname><given-names>F.</given-names></name>
</person-group><article-title>A Pruned-Optimized Weighted Graph Convolutional Network for Axial Flow Pump Fault Diagnosis with Hydrophone Signals</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102365</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102365</pub-id></element-citation></ref><ref id="B19-sensors-25-01189"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>T.</given-names></name>
<name><surname>Chen</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>F.</given-names></name>
<name><surname>Zhang</surname><given-names>K.</given-names></name>
<name><surname>Lv</surname><given-names>H.</given-names></name>
<name><surname>He</surname><given-names>S.</given-names></name>
<name><surname>Xu</surname><given-names>E.</given-names></name>
</person-group><article-title>Intelligent Fault Diagnosis of Machines with Small &#x00026; Imbalanced Data: A State-of-the-Art Review and Possible Extensions</article-title><source>ISA Trans.</source><year>2022</year><volume>119</volume><fpage>152</fpage><lpage>171</lpage><pub-id pub-id-type="pmid">33736889</pub-id>
</element-citation></ref><ref id="B20-sensors-25-01189"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>S.</given-names></name>
<name><surname>Qi</surname><given-names>L.</given-names></name>
<name><surname>Shi</surname><given-names>J.</given-names></name>
<name><surname>Xiao</surname><given-names>H.</given-names></name>
<name><surname>Da</surname><given-names>B.</given-names></name>
<name><surname>Tang</surname><given-names>R.</given-names></name>
<name><surname>Zuo</surname><given-names>D.</given-names></name>
</person-group><article-title>Study on Few-Shot Fault Diagnosis Method for Marine Fuel Systems Based on DT-SViT-KNN</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.3390/s25010006</pub-id><pub-id pub-id-type="pmid">39796796</pub-id>
</element-citation></ref><ref id="B21-sensors-25-01189"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xu</surname><given-names>X.</given-names></name>
<name><surname>Bao</surname><given-names>S.</given-names></name>
<name><surname>Shao</surname><given-names>H.</given-names></name>
<name><surname>Shi</surname><given-names>P.</given-names></name>
</person-group><article-title>A Multi-Sensor Fused Incremental Broad Learning with D-S Theory for Online Fault Diagnosis of Rotating Machinery</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102419</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102419</pub-id></element-citation></ref><ref id="B22-sensors-25-01189"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Qian</surname><given-names>W.</given-names></name>
<name><surname>Li</surname><given-names>S.</given-names></name>
<name><surname>Yi</surname><given-names>P.</given-names></name>
<name><surname>Zhang</surname><given-names>K.</given-names></name>
</person-group><article-title>A Novel Transfer Learning Method for Robust Fault Diagnosis of Rotating Machines under Variable Working Conditions</article-title><source>Measurement</source><year>2019</year><volume>138</volume><fpage>514</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1016/j.measurement.2019.02.073</pub-id></element-citation></ref><ref id="B23-sensors-25-01189"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>S.</given-names></name>
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Shi</surname><given-names>T.</given-names></name>
<name><surname>Huang</surname><given-names>K.</given-names></name>
</person-group><article-title>Contrastive and Transfer Learning-Based Visual Small Component Inspection in Assembly</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>59</volume><fpage>102308</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.102308</pub-id></element-citation></ref><ref id="B24-sensors-25-01189"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Qin</surname><given-names>A.S.</given-names></name>
<name><surname>Mao</surname><given-names>H.L.</given-names></name>
<name><surname>Hu</surname><given-names>Q.</given-names></name>
</person-group><article-title>Cross-Domain Fault Diagnosis of Rolling Bearing Using Similar Features-Based Transfer Approach</article-title><source>Measurement</source><year>2021</year><volume>172</volume><fpage>108900</fpage><pub-id pub-id-type="doi">10.1016/j.measurement.2020.108900</pub-id></element-citation></ref><ref id="B25-sensors-25-01189"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhu</surname><given-names>W.</given-names></name>
<name><surname>Shi</surname><given-names>B.</given-names></name>
<name><surname>Feng</surname><given-names>Z.</given-names></name>
</person-group><article-title>A Transfer Learning Method Using High-Quality Pseudo Labels for Bearing Fault Diagnosis</article-title><source>IEEE Trans. Instrum. Meas.</source><year>2023</year><volume>72</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1109/TIM.2022.3223146</pub-id><pub-id pub-id-type="pmid">37323850</pub-id>
</element-citation></ref><ref id="B26-sensors-25-01189"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lee</surname><given-names>J.</given-names></name>
<name><surname>Heo</surname><given-names>J.</given-names></name>
<name><surname>Lee</surname><given-names>J.</given-names></name>
</person-group><article-title>Enhancement of Virtual Data Quality Using Pre-Trained Bayesian Transfer Learning under Inaccurate and Insufficient Measurement Data</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>59</volume><fpage>102241</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.102241</pub-id></element-citation></ref><ref id="B27-sensors-25-01189"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>Z.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
<name><surname>Li</surname><given-names>H.</given-names></name>
<name><surname>Tian</surname><given-names>K.</given-names></name>
<name><surname>Cheng</surname><given-names>Z.</given-names></name>
<name><surname>Chen</surname><given-names>Y.</given-names></name>
<name><surname>Wang</surname><given-names>B.</given-names></name>
</person-group><article-title>On-Line Transfer Learning for Multi-Fidelity Data Fusion with Ensemble of Deep Neural Networks</article-title><source>Adv. Eng. Inform.</source><year>2022</year><volume>53</volume><fpage>101689</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2022.101689</pub-id></element-citation></ref><ref id="B28-sensors-25-01189"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Jiang</surname><given-names>H.</given-names></name>
<name><surname>Xie</surname><given-names>M.</given-names></name>
<name><surname>Wang</surname><given-names>T.</given-names></name>
<name><surname>Wang</surname><given-names>R.</given-names></name>
<name><surname>Wu</surname><given-names>Z.</given-names></name>
</person-group><article-title>A Reinforcement Ensemble Deep Transfer Learning Network for Rolling Bearing Fault Diagnosis with Multi-Source Domains</article-title><source>Adv. Eng. Inform.</source><year>2022</year><volume>51</volume><fpage>101480</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2021.101480</pub-id></element-citation></ref><ref id="B29-sensors-25-01189"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>J.</given-names></name>
<name><surname>Huang</surname><given-names>R.</given-names></name>
<name><surname>Chen</surname><given-names>Z.</given-names></name>
<name><surname>He</surname><given-names>G.</given-names></name>
<name><surname>Gryllias</surname><given-names>K.C.</given-names></name>
<name><surname>Li</surname><given-names>W.</given-names></name>
</person-group><article-title>Deep Continual Transfer Learning with Dynamic Weight Aggregation for Fault Diagnosis of Industrial Streaming Data under Varying Working Conditions</article-title><source>Adv. Eng. Inform.</source><year>2023</year><volume>55</volume><fpage>101883</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.101883</pub-id></element-citation></ref><ref id="B30-sensors-25-01189"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wu</surname><given-names>Z.</given-names></name>
<name><surname>Jiang</surname><given-names>H.</given-names></name>
<name><surname>Liu</surname><given-names>S.</given-names></name>
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Yang</surname><given-names>W.</given-names></name>
</person-group><article-title>Conditional Distribution-Guided Adversarial Transfer Learning Network with Multi-Source Domains for Rolling Bearing Fault Diagnosis</article-title><source>Adv. Eng. Inform.</source><year>2023</year><volume>56</volume><fpage>101993</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.101993</pub-id></element-citation></ref><ref id="B31-sensors-25-01189"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shelhamer</surname><given-names>E.</given-names></name>
<name><surname>Long</surname><given-names>J.</given-names></name>
<name><surname>Darrell</surname><given-names>T.</given-names></name>
</person-group><article-title>Fully Convolutional Networks for Semantic Segmentation</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2017</year><volume>39</volume><fpage>640</fpage><lpage>651</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2016.2572683</pub-id><pub-id pub-id-type="pmid">27244717</pub-id>
</element-citation></ref><ref id="B32-sensors-25-01189"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Park</surname><given-names>J.</given-names></name>
<name><surname>Lee</surname><given-names>K.</given-names></name>
<name><surname>Park</surname><given-names>N.</given-names></name>
<name><surname>You</surname><given-names>S.C.</given-names></name>
<name><surname>Ko</surname><given-names>J.</given-names></name>
</person-group><article-title>Self-Attention LSTM-FCN Model for Arrhythmia Classification and Uncertainty Assessment</article-title><source>Artif. Intell. Med.</source><year>2023</year><volume>142</volume><fpage>102570</fpage><pub-id pub-id-type="doi">10.1016/j.artmed.2023.102570</pub-id><pub-id pub-id-type="pmid">37316094</pub-id>
</element-citation></ref><ref id="B33-sensors-25-01189"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Oh</surname><given-names>S.-K.</given-names></name>
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Fu</surname><given-names>Z.</given-names></name>
<name><surname>Pedrycz</surname><given-names>W.</given-names></name>
<name><surname>Yoon</surname><given-names>J.H.</given-names></name>
</person-group><article-title>Design of Progressive Fuzzy Polynomial Neural Networks through Gated Recurrent Unit Structure and Correlation/Probabilistic Selection Strategies</article-title><source>Fuzzy Sets Syst.</source><year>2023</year><volume>470</volume><fpage>108656</fpage><pub-id pub-id-type="doi">10.1016/j.fss.2023.108656</pub-id></element-citation></ref><ref id="B34-sensors-25-01189"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhou</surname><given-names>X.</given-names></name>
<name><surname>Shi</surname><given-names>P.</given-names></name>
<name><surname>Sheil</surname><given-names>B.</given-names></name>
<name><surname>Suryasentana</surname><given-names>S.</given-names></name>
</person-group><article-title>Knowledge-Based U-Net and Transfer Learning for Automatic Boundary Segmentation</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>59</volume><fpage>102243</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.102243</pub-id></element-citation></ref><ref id="B35-sensors-25-01189"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>X.</given-names></name>
<name><surname>Chen</surname><given-names>Z.</given-names></name>
<name><surname>Hu</surname><given-names>S.</given-names></name>
<name><surname>Gu</surname><given-names>C.</given-names></name>
<name><surname>Guo</surname><given-names>J.</given-names></name>
<name><surname>Qin</surname><given-names>X.</given-names></name>
</person-group><article-title>A Feature Decomposition-Based Deep Transfer Learning Framework for Concrete Dam Deformation Prediction with Observational Insufficiency</article-title><source>Adv. Eng. Inform.</source><year>2023</year><volume>58</volume><fpage>102175</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.102175</pub-id></element-citation></ref><ref id="B36-sensors-25-01189"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>Z.J.</given-names></name>
<name><surname>Cheng</surname><given-names>D.J.</given-names></name>
<name><surname>Zhang</surname><given-names>H.B.</given-names></name>
<name><surname>Zhou</surname><given-names>K.L.</given-names></name>
<name><surname>Wang</surname><given-names>Y.F.</given-names></name>
</person-group><article-title>Multi-Feature Spaces Cross Adaption Transfer Learning-Based Bearings Piece-Wise Remaining Useful Life Prediction under Unseen Degradation Data</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>60</volume><fpage>102413</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102413</pub-id></element-citation></ref><ref id="B37-sensors-25-01189"><label>37.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<collab>Case Western Reserve University</collab>
</person-group><article-title>Case School of Engineering, Bearing Data Center</article-title><comment>Available online: <ext-link xlink:href="https://engineering.case.edu/bearingdatacenter" ext-link-type="uri">https://engineering.case.edu/bearingdatacenter</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-04">(accessed on 4 November 2024)</date-in-citation></element-citation></ref><ref id="B38-sensors-25-01189"><label>38.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Lessmeier</surname><given-names>C.</given-names></name>
<name><surname>Kimotho</surname><given-names>J.K.</given-names></name>
<name><surname>Zimmer</surname><given-names>D.</given-names></name>
<name><surname>Sextro</surname><given-names>W.</given-names></name>
</person-group><article-title>Condition Monitoring of Bearing Damage in Electromechanical Drive Systems by Using Motor Current Signals of Electric Motors: A Benchmark Data Set for Data-Driven Classification</article-title><source>Proceedings of the European Conference of the PHM Society 2016</source><conf-loc>Bilbao, Spain</conf-loc><conf-date>5&#x02013;8 July 2016</conf-date><fpage>10236</fpage></element-citation></ref><ref id="B39-sensors-25-01189"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pan</surname><given-names>S.J.</given-names></name>
<name><surname>Tsang</surname><given-names>I.W.</given-names></name>
<name><surname>Kwok</surname><given-names>J.T.</given-names></name>
<name><surname>Yang</surname><given-names>Q.</given-names></name>
</person-group><article-title>Domain Adaptation via Transfer Component Analysis</article-title><source>IEEE Trans. Neural Netw.</source><year>2011</year><volume>22</volume><fpage>199</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1109/TNN.2010.2091281</pub-id><pub-id pub-id-type="pmid">21095864</pub-id>
</element-citation></ref><ref id="B40-sensors-25-01189"><label>40.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Chen</surname><given-names>Y.</given-names></name>
<name><surname>Hao</surname><given-names>S.</given-names></name>
<name><surname>Feng</surname><given-names>W.</given-names></name>
<name><surname>Shen</surname><given-names>Z.</given-names></name>
</person-group><article-title>Balanced Distribution Adaptation for Transfer Learning</article-title><source>Proceedings of the 2017 IEEE International Conference on Data Mining (ICDM)</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>18&#x02013;21 November 2017</conf-date><fpage>1129</fpage><lpage>1134</lpage></element-citation></ref><ref id="B41-sensors-25-01189"><label>41.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Gong</surname><given-names>B.</given-names></name>
<name><surname>Shi</surname><given-names>Y.</given-names></name>
<name><surname>Sha</surname><given-names>F.</given-names></name>
<name><surname>Grauman</surname><given-names>K.</given-names></name>
</person-group><article-title>Geodesic Flow Kernel for Unsupervised Domain Adaptation</article-title><source>Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Brussels, Belgium</conf-loc><conf-date>16&#x02013;21 June 2012</conf-date><fpage>2066</fpage><lpage>2073</lpage></element-citation></ref><ref id="B42-sensors-25-01189"><label>42.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Sun</surname><given-names>B.</given-names></name>
<name><surname>Feng</surname><given-names>J.</given-names></name>
<name><surname>Saenko</surname><given-names>K.</given-names></name>
</person-group><article-title>Return of Frustratingly Easy Domain Adaptation</article-title><comment>Available online: <ext-link xlink:href="https://arxiv.org/abs/1511.05547" ext-link-type="uri">https://arxiv.org/abs/1511.05547</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-04">(accessed on 4 November 2024)</date-in-citation></element-citation></ref><ref id="B43-sensors-25-01189"><label>43.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Ganin</surname><given-names>Y.</given-names></name>
<name><surname>Ustinova</surname><given-names>E.</given-names></name>
<name><surname>Ajakan</surname><given-names>H.</given-names></name>
<name><surname>Germain</surname><given-names>P.</given-names></name>
<name><surname>Larochelle</surname><given-names>H.</given-names></name>
<name><surname>Laviolette</surname><given-names>F.</given-names></name>
<name><surname>Marchand</surname><given-names>M.</given-names></name>
<name><surname>Lempitsky</surname><given-names>V.</given-names></name>
</person-group><article-title>Domain-Adversarial Training of Neural Networks</article-title><comment>Available online: <ext-link xlink:href="https://arxiv.org/abs/1505.07818" ext-link-type="uri">https://arxiv.org/abs/1505.07818</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-04">(accessed on 4 November 2024)</date-in-citation></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01189-f001"><label>Figure 1</label><caption><p>Transferability of deep learning: The shallow layer of the network is used to extract general information and the deep layer is used to extract specific information.</p></caption><graphic xlink:href="sensors-25-01189-g001" position="float"/></fig><fig position="float" id="sensors-25-01189-f002"><label>Figure 2</label><caption><p>The overall flow of the diagnostic framework.</p></caption><graphic xlink:href="sensors-25-01189-g002" position="float"/></fig><fig position="float" id="sensors-25-01189-f003"><label>Figure 3</label><caption><p>Schematic diagram of sliding window-based data segmentation.</p></caption><graphic xlink:href="sensors-25-01189-g003" position="float"/></fig><fig position="float" id="sensors-25-01189-f004"><label>Figure 4</label><caption><p>The schematic diagram of the residual fully convolutional network (ResFCN) structure used in the method proposed in this study. The network mainly consists of a convolutional layer, a batch normalization layer, an activation layer, a global average pooling layer, and a residual structure, which is good at extracting the potential features of the input signal.</p></caption><graphic xlink:href="sensors-25-01189-g004" position="float"/></fig><fig position="float" id="sensors-25-01189-f005"><label>Figure 5</label><caption><p>Schematic diagram of the transfer strategy used in the study. The transfer strategy is divided into three steps: step 1 is to pre-train using the source domain data to obtain the pre-trained model; step 2 is to replace the softmax layer of the pre-trained model, initialize it, and freeze all other layers; and step 3 is to train using the target domain data to obtain the intelligent diagnostic model.</p></caption><graphic xlink:href="sensors-25-01189-g005" position="float"/></fig><fig position="float" id="sensors-25-01189-f006"><label>Figure 6</label><caption><p>Signal comparison of the normal class: (<bold>a</bold>) time domain waveform in the source domain, (<bold>b</bold>) time domain waveform in the target domain, (<bold>c</bold>) FFT spectrum in the source domain, and (<bold>d</bold>) FFT spectrum in the target domain.</p></caption><graphic xlink:href="sensors-25-01189-g006" position="float"/></fig><fig position="float" id="sensors-25-01189-f007"><label>Figure 7</label><caption><p>Signal comparison of the inner race fault class: (<bold>a</bold>) time domain waveform in the source domain, (<bold>b</bold>) time domain waveform in the target domain, (<bold>c</bold>) FFT spectrum in the source domain, and (<bold>d</bold>) FFT spectrum in the target domain.</p></caption><graphic xlink:href="sensors-25-01189-g007" position="float"/></fig><fig position="float" id="sensors-25-01189-f008"><label>Figure 8</label><caption><p>Signal comparison of the outer race fault class: (<bold>a</bold>) time domain waveform in the source domain, (<bold>b</bold>) time domain waveform in the target domain, (<bold>c</bold>) FFT spectrum in the source domain, and (<bold>d</bold>) FFT spectrum in the target domain.</p></caption><graphic xlink:href="sensors-25-01189-g008" position="float"/></fig><fig position="float" id="sensors-25-01189-f009"><label>Figure 9</label><caption><p>The curves of training set loss, training set accuracy, and learning rate with the number of training sessions during transfer learning.</p></caption><graphic xlink:href="sensors-25-01189-g009" position="float"/></fig><fig position="float" id="sensors-25-01189-f010"><label>Figure 10</label><caption><p>The confusion matrix of the experimental results.</p></caption><graphic xlink:href="sensors-25-01189-g010" position="float"/></fig><fig position="float" id="sensors-25-01189-f011"><label>Figure 11</label><caption><p>Results of the 6 tasks on 9 indicators describing the classification of each category. On each indicator, the closer the point is to the center, the lower the accuracy.</p></caption><graphic xlink:href="sensors-25-01189-g011" position="float"/></fig><fig position="float" id="sensors-25-01189-f012"><label>Figure 12</label><caption><p>Results of 6 tasks on 4 macro-averages (precision, recall, F1-score, and accuracy) (in percentage).</p></caption><graphic xlink:href="sensors-25-01189-g012" position="float"/></fig><fig position="float" id="sensors-25-01189-f013"><label>Figure 13</label><caption><p>Results of the 10 methods on 9 indicators describing the classification of each category. On each indicator, the closer the point is to the center, the lower the accuracy.</p></caption><graphic xlink:href="sensors-25-01189-g013" position="float"/></fig><fig position="float" id="sensors-25-01189-f014"><label>Figure 14</label><caption><p>Results of 10 methods on 4 macro-averages (precision, recall, F1-score, and accuracy) (in percentage).</p></caption><graphic xlink:href="sensors-25-01189-g014" position="float"/></fig><table-wrap position="float" id="sensors-25-01189-t001"><object-id pub-id-type="pii">sensors-25-01189-t001_Table 1</object-id><label>Table 1</label><caption><p>Specific hyperparameters of the three convolutional layers.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Hyperparameter</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Convolutional<break/>Layer 1</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Convolutional <break/>Layer 2</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Convolutional <break/>Layer 3</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Number of filters</td><td align="center" valign="middle" rowspan="1" colspan="1">128</td><td align="center" valign="middle" rowspan="1" colspan="1">256</td><td align="center" valign="middle" rowspan="1" colspan="1">128</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Filter length</td><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Stride</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Padding</td><td colspan="3" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Preserve the convolution result at the boundary</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t002"><object-id pub-id-type="pii">sensors-25-01189-t002_Table 2</object-id><label>Table 2</label><caption><p>Parameters related to source domain data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Rotation Speed (r/min)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Load (kw)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Fault</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Fault Diameter (mm)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Data Volume</th></tr></thead><tbody><tr><td rowspan="7" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">1797</td><td rowspan="7" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Normal condition</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">\</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">62,600</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Inner race fault</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.1778</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21,200</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.3556</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21,200</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.5334</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21,200</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Outer race fault</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.1778</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21,200</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.3556</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21,200</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.5334</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21,200</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t003"><object-id pub-id-type="pii">sensors-25-01189-t003_Table 3</object-id><label>Table 3</label><caption><p>Parameters related to target domain data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Rotation Speed (r/min)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Load (kw)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Fault</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Fault Diameter (mm)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Data Volume</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Test Data <break/>Volume</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1500&#x02013;2000</td><td align="center" valign="middle" rowspan="1" colspan="1">\</td><td align="center" valign="middle" rowspan="1" colspan="1">1000&#x02013;3000</td><td align="center" valign="middle" rowspan="1" colspan="1">Normal <break/>condition</td><td align="center" valign="middle" rowspan="1" colspan="1">44,500</td><td align="center" valign="middle" rowspan="1" colspan="1">19,100</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">1500</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1</td><td align="center" valign="middle" rowspan="1" colspan="1">1000</td><td align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Inner race fault</td><td align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">4400</td><td align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">19,100</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1000</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Outer race fault</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4400</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">19,100</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t004"><object-id pub-id-type="pii">sensors-25-01189-t004_Table 4</object-id><label>Table 4</label><caption><p>The values of the sliding step <inline-formula><mml:math id="mm94" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and the number of samples $n$ after segmentation in the form of (normal condition, inner race fault, and outer race fault).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Source Domain</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Target Domain Train Dataset</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Target Domain Test Dataset</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sliding step</td><td align="center" valign="middle" rowspan="1" colspan="1">(100, 100, 100)</td><td align="center" valign="middle" rowspan="1" colspan="1">(100, 9, 9)</td><td align="center" valign="middle" rowspan="1" colspan="1">(100, 100, 100)</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Number of samples</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">(626, 626, 626)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">(445, 478, 478)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">(191, 191, 191)</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t005"><object-id pub-id-type="pii">sensors-25-01189-t005_Table 5</object-id><label>Table 5</label><caption><p>Hyperparameter settings during the training process.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Hyperparameter</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Value</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Hyperparameter</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Value</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Epochs</td><td align="center" valign="middle" rowspan="1" colspan="1">(100, 100, 100)</td><td align="center" valign="middle" rowspan="1" colspan="1">Learning rate</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Batch size</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">Loss function</td><td align="center" valign="middle" rowspan="1" colspan="1">Cross-entropy</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Optimizer</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Adam</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Critical accuracy</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.99</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t006"><object-id pub-id-type="pii">sensors-25-01189-t006_Table 6</object-id><label>Table 6</label><caption><p>The results of accuracy, precision, recall, and F1-score in the experiments.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
Precision (%)
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
Recall (%)
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
F1-Score (%)
</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Normal condition</td><td align="center" valign="middle" rowspan="1" colspan="1">98.96</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Inner Race Fault</td><td align="center" valign="middle" rowspan="1" colspan="1">98.93</td><td align="center" valign="middle" rowspan="1" colspan="1">96.86</td><td align="center" valign="middle" rowspan="1" colspan="1">97.88</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Outer Race Fault</td><td align="center" valign="middle" rowspan="1" colspan="1">97.41</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">97.92</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Macro avg</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy (%)</td><td colspan="3" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">98.43</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t007"><object-id pub-id-type="pii">sensors-25-01189-t007_Table 7</object-id><label>Table 7</label><caption><p>The six tasks resulting from the removal of one or some steps used to examine the necessity of each step of the method proposed in this paper.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Hyperparameter</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Value</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><bold>Without using SW,</bold> the original data are directly partitioned into equal-length samples. <bold>Train with source domain data</bold> and test the trained model directly with the target domain test data.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><bold>Without using SW,</bold> the original data are directly partitioned into equal-length samples. <bold>Train with the target domain training data</bold> and test the completed model directly using the target domain test data.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><bold>Use SW for data segmentation. Train with source domain data</bold> and test the completed model directly with the target domain test data.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><bold>Use SW for data segmentation. Train with the target domain training data</bold> and test the completed model directly with the target domain test data.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><bold>Without using SW,</bold> the original data are directly partitioned into equal-length samples. <bold>Train with the source domain data and fine-tune with the target domain training data,</bold> and test the fine-tuned model with the target domain test data.</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Task 6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><bold>Using SW,</bold> the original data are directly partitioned into equal-length samples. <bold>The model is trained with the source domain data and fine-tuned with the target domain training data,</bold> and the fine-tuned model is tested with the target domain test data.</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t008"><object-id pub-id-type="pii">sensors-25-01189-t008_Table 8</object-id><label>Table 8</label><caption><p>Introduction of source domain data from the CWRU dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Datasets</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Load (kW)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Rotation Speed (r/min)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sensor Position</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">1797</td><td align="center" valign="middle" rowspan="1" colspan="1">DE</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">2.21</td><td align="center" valign="middle" rowspan="1" colspan="1">1730</td><td align="center" valign="middle" rowspan="1" colspan="1">DE</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-FE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">1797</td><td align="center" valign="middle" rowspan="1" colspan="1">FE</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CWRU-FE-H</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.21</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1730</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">FE</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t009"><object-id pub-id-type="pii">sensors-25-01189-t009_Table 9</object-id><label>Table 9</label><caption><p>Introduction of target domain data from the PU dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Datasets</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Torque (Nm)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Rotation Speed (r/min)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Failure Mode</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1</td><td align="center" valign="middle" rowspan="1" colspan="1">1500</td><td align="center" valign="middle" rowspan="1" colspan="1">EE</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7</td><td align="center" valign="middle" rowspan="1" colspan="1">1500</td><td align="center" valign="middle" rowspan="1" colspan="1">EE</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-L</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1</td><td align="center" valign="middle" rowspan="1" colspan="1">1500</td><td align="center" valign="middle" rowspan="1" colspan="1">EDM</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PU-EDM-H</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.7</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1500</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EDM</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t010"><object-id pub-id-type="pii">sensors-25-01189-t010_Table 10</object-id><label>Table 10</label><caption><p>16 transfer tasks.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Task</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Source Data</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Target Data</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Task</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Source Data</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Target Data</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">T1</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">T9</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-L</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T2</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">T10</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-L</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T3</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-FE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">T11</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-FE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-L</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T4</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-FE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">T12</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-FE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-L</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T5</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">T13</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-DE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-H</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T6</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU- DE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">T14</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU- DE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-H</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T7</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-FE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EE-H</td><td align="center" valign="middle" rowspan="1" colspan="1">T15</td><td align="center" valign="middle" rowspan="1" colspan="1">CWRU-FE-L</td><td align="center" valign="middle" rowspan="1" colspan="1">PU-EDM-H</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">T8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CWRU-FE-H</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PU-EE-H</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">T16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CWRU-FE-H</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PU-EDM-H</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01189-t011"><object-id pub-id-type="pii">sensors-25-01189-t011_Table 11</object-id><label>Table 11</label><caption><p>The results of 13 indicators for 16 tasks (in percentage).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Task</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Normal Condition</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Inner Ring Fault</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Outer Ring Fault</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Macro Avg</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Accuracy</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F1-Score </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F1-Score </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F1-Score </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F1-Score</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">T1</td><td align="center" valign="middle" rowspan="1" colspan="1">8.96</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">98.93</td><td align="center" valign="middle" rowspan="1" colspan="1">96.86</td><td align="center" valign="middle" rowspan="1" colspan="1">97.88</td><td align="center" valign="middle" rowspan="1" colspan="1">97.41</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">97.92</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T2</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.69</td><td align="center" valign="middle" rowspan="1" colspan="1">96.92</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">97.93</td><td align="center" valign="middle" rowspan="1" colspan="1">98.94</td><td align="center" valign="middle" rowspan="1" colspan="1">97.38</td><td align="center" valign="middle" rowspan="1" colspan="1">98.15</td><td align="center" valign="middle" rowspan="1" colspan="1">98.27</td><td align="center" valign="middle" rowspan="1" colspan="1">98.25</td><td align="center" valign="middle" rowspan="1" colspan="1">98.26</td><td align="center" valign="middle" rowspan="1" colspan="1">98.25</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T3</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T4</td><td align="center" valign="middle" rowspan="1" colspan="1">98.41</td><td align="center" valign="middle" rowspan="1" colspan="1">97.38</td><td align="center" valign="middle" rowspan="1" colspan="1">97.89</td><td align="center" valign="middle" rowspan="1" colspan="1">96.46</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">98.20</td><td align="center" valign="middle" rowspan="1" colspan="1">97.85</td><td align="center" valign="middle" rowspan="1" colspan="1">95.29</td><td align="center" valign="middle" rowspan="1" colspan="1">96.55</td><td align="center" valign="middle" rowspan="1" colspan="1">97.58</td><td align="center" valign="middle" rowspan="1" colspan="1">97.56</td><td align="center" valign="middle" rowspan="1" colspan="1">97.55</td><td align="center" valign="middle" rowspan="1" colspan="1">97.56</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T5</td><td align="center" valign="middle" rowspan="1" colspan="1">98.39</td><td align="center" valign="middle" rowspan="1" colspan="1">95.81</td><td align="center" valign="middle" rowspan="1" colspan="1">97.08</td><td align="center" valign="middle" rowspan="1" colspan="1">97.94</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">98.70</td><td align="center" valign="middle" rowspan="1" colspan="1">96.89</td><td align="center" valign="middle" rowspan="1" colspan="1">97.91</td><td align="center" valign="middle" rowspan="1" colspan="1">97.40</td><td align="center" valign="middle" rowspan="1" colspan="1">97.74</td><td align="center" valign="middle" rowspan="1" colspan="1">97.73</td><td align="center" valign="middle" rowspan="1" colspan="1">97.73</td><td align="center" valign="middle" rowspan="1" colspan="1">97.73</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T6</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.74</td><td align="center" valign="middle" rowspan="1" colspan="1">96.41</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">97.41</td><td align="center" valign="middle" rowspan="1" colspan="1">98.40</td><td align="center" valign="middle" rowspan="1" colspan="1">96.86</td><td align="center" valign="middle" rowspan="1" colspan="1">97.63</td><td align="center" valign="middle" rowspan="1" colspan="1">98.27</td><td align="center" valign="middle" rowspan="1" colspan="1">98.25</td><td align="center" valign="middle" rowspan="1" colspan="1">98.26</td><td align="center" valign="middle" rowspan="1" colspan="1">98.25</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T7</td><td align="center" valign="middle" rowspan="1" colspan="1">98.92</td><td align="center" valign="middle" rowspan="1" colspan="1">95.81</td><td align="center" valign="middle" rowspan="1" colspan="1">97.34</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.69</td><td align="center" valign="middle" rowspan="1" colspan="1">96.46</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">98.20</td><td align="center" valign="middle" rowspan="1" colspan="1">98.11</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T8</td><td align="center" valign="middle" rowspan="1" colspan="1">99.47</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">97.93</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.44</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">98.96</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T9</td><td align="center" valign="middle" rowspan="1" colspan="1">99.47</td><td align="center" valign="middle" rowspan="1" colspan="1">97.38</td><td align="center" valign="middle" rowspan="1" colspan="1">98.41</td><td align="center" valign="middle" rowspan="1" colspan="1">99.47</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">96.95</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">98.45</td><td align="center" valign="middle" rowspan="1" colspan="1">98.63</td><td align="center" valign="middle" rowspan="1" colspan="1">98.60</td><td align="center" valign="middle" rowspan="1" colspan="1">98.60</td><td align="center" valign="middle" rowspan="1" colspan="1">98.60</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T10</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.69</td><td align="center" valign="middle" rowspan="1" colspan="1">97.42</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.18</td><td align="center" valign="middle" rowspan="1" colspan="1">98.94</td><td align="center" valign="middle" rowspan="1" colspan="1">97.91</td><td align="center" valign="middle" rowspan="1" colspan="1">98.42</td><td align="center" valign="middle" rowspan="1" colspan="1">98.44</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T11</td><td align="center" valign="middle" rowspan="1" colspan="1">97.91</td><td align="center" valign="middle" rowspan="1" colspan="1">97.91</td><td align="center" valign="middle" rowspan="1" colspan="1">97.91</td><td align="center" valign="middle" rowspan="1" colspan="1">97.89</td><td align="center" valign="middle" rowspan="1" colspan="1">97.38</td><td align="center" valign="middle" rowspan="1" colspan="1">97.64</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">99.74</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T12</td><td align="center" valign="middle" rowspan="1" colspan="1">98.91</td><td align="center" valign="middle" rowspan="1" colspan="1">95.29</td><td align="center" valign="middle" rowspan="1" colspan="1">97.07</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">95.45</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">97.17</td><td align="center" valign="middle" rowspan="1" colspan="1">98.12</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T13</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">98.39</td><td align="center" valign="middle" rowspan="1" colspan="1">95.81</td><td align="center" valign="middle" rowspan="1" colspan="1">97.08</td><td align="center" valign="middle" rowspan="1" colspan="1">96.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">97.67</td><td align="center" valign="middle" rowspan="1" colspan="1">98.10</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td><td align="center" valign="middle" rowspan="1" colspan="1">98.08</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T14</td><td align="center" valign="middle" rowspan="1" colspan="1">98.96</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.22</td><td align="center" valign="middle" rowspan="1" colspan="1">98.45</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">98.96</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">99.21</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td><td align="center" valign="middle" rowspan="1" colspan="1">99.13</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T15</td><td align="center" valign="middle" rowspan="1" colspan="1">99.47</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">97.45</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">98.71</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00</td><td align="center" valign="middle" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" rowspan="1" colspan="1">99.21</td><td align="center" valign="middle" rowspan="1" colspan="1">98.97</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">T16</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">99.48</td><td align="center" valign="middle" rowspan="1" colspan="1">97.93</td><td align="center" valign="middle" rowspan="1" colspan="1">98.95</td><td align="center" valign="middle" rowspan="1" colspan="1">98.44</td><td align="center" valign="middle" rowspan="1" colspan="1">98.94</td><td align="center" valign="middle" rowspan="1" colspan="1">97.91</td><td align="center" valign="middle" rowspan="1" colspan="1">98.42</td><td align="center" valign="middle" rowspan="1" colspan="1">98.78</td><td align="center" valign="middle" rowspan="1" colspan="1">98.78</td><td align="center" valign="middle" rowspan="1" colspan="1">98.78</td><td align="center" valign="middle" rowspan="1" colspan="1">98.78</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Macro avg</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.07</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.17</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.61</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.09</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.69</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.38</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.44</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.43</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.43</td></tr></tbody></table></table-wrap></floats-group></article>