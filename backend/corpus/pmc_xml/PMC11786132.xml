<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Med Internet Res</journal-id><journal-id journal-id-type="iso-abbrev">J Med Internet Res</journal-id><journal-id journal-id-type="publisher-id">JMIR</journal-id><journal-title-group><journal-title>Journal of Medical Internet Research</journal-title></journal-title-group><issn pub-type="ppub">1439-4456</issn><issn pub-type="epub">1438-8871</issn><publisher><publisher-name>JMIR Publications</publisher-name><publisher-loc>Toronto, Canada</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39823631</article-id><article-id pub-id-type="pmc">PMC11786132</article-id><article-id pub-id-type="publisher-id">v27i1e65434</article-id><article-id pub-id-type="doi">10.2196/65434</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group><subj-group subj-group-type="article-type"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>Explainable Predictive Model for Suicidal Ideation During COVID-19: Social Media Discourse Study</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Mavragani</surname><given-names>Amaryllis</given-names></name></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Adil</surname><given-names>Asif</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Hossain</surname><given-names>Md. Rajib</given-names></name></contrib></contrib-group><contrib-group><contrib id="contrib1" contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Bouktif</surname><given-names>Salah</given-names></name><degrees>PhD</degrees><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-8193-0546</contrib-id><xref rid="aff1" ref-type="aff">1</xref><address><institution>Department of Computer Science and Software Engineering</institution><institution>College of Information Technology</institution><institution>United Arab Emirates University</institution><addr-line>Sheikh Khalifa Bin Zayed, Asharij</addr-line><addr-line>Al Ain, Abu Dhabi, 1551</addr-line><country>United Arab Emirates</country><phone>971 507605406</phone><email>salahb@uaeu.ac.ae</email></address></contrib><contrib id="contrib2" contrib-type="author" equal-contrib="yes"><name><surname>Khanday</surname><given-names>Akib Mohi Ud Din</given-names></name><degrees>PhD, PDF</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6804-4905</contrib-id></contrib><contrib id="contrib3" contrib-type="author"><name><surname>Ouni</surname><given-names>Ali</given-names></name><degrees>PhD</degrees><xref rid="aff2" ref-type="aff">2</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4708-0362</contrib-id></contrib></contrib-group><aff id="aff1">
<label>1</label>
<institution>Department of Computer Science and Software Engineering</institution>
<institution>College of Information Technology</institution>
<institution>United Arab Emirates University</institution>
<addr-line>Al Ain, Abu Dhabi</addr-line>
<country>United Arab Emirates</country>
</aff><aff id="aff2">
<label>2</label>
<institution>Department of Software Engineering and Information Technology</institution>
<institution>&#x000c9;cole de Technologie Sup&#x000e9;rieure</institution>
<addr-line>Montreal, QC</addr-line>
<country>Canada</country>
</aff><author-notes><corresp>Corresponding Author: Salah Bouktif <email>salahb@uaeu.ac.ae</email></corresp></author-notes><pub-date pub-type="collection"><year>2025</year></pub-date><pub-date pub-type="epub"><day>17</day><month>1</month><year>2025</year></pub-date><volume>27</volume><elocation-id>e65434</elocation-id><history><date date-type="received"><day>15</day><month>8</month><year>2024</year></date><date date-type="rev-request"><day>27</day><month>9</month><year>2024</year></date><date date-type="rev-recd"><day>17</day><month>10</month><year>2024</year></date><date date-type="accepted"><day>5</day><month>12</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9;Salah Bouktif, Akib Mohi Ud Din Khanday, Ali Ouni. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 17.01.2025.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link xlink:href="https://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research (ISSN 1438-8871), is properly cited. The complete bibliographic information, a link to the original publication on <ext-link xlink:href="https://www.jmir.org/" ext-link-type="uri">https://www.jmir.org/</ext-link>, as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:href="https://www.jmir.org/2025/1/e65434"/><abstract><sec sec-type="background"><title>Background</title><p>Studying the impact of COVID-19 on mental health is both compelling and imperative for the health care system&#x02019;s preparedness development. Discovering how pandemic conditions and governmental strategies and measures have impacted mental health is a challenging task. Mental health issues, such as depression and suicidal tendency, are traditionally explored through psychological battery tests and clinical procedures. To address the stigma associated with mental illness, social media is used to examine language patterns in posts related to suicide. This strategy enhances the comprehension and interpretation of suicidal ideation. Despite easy expression via social media, suicidal thoughts remain sensitive and complex to comprehend and detect. Suicidal ideation captures the new suicidal statements used during the COVID-19 pandemic that represents a different context of expressions.</p></sec><sec sec-type="objective"><title>Objective</title><p>In this study, our aim was to detect suicidal ideation by mining textual content extracted from social media by leveraging state-of-the-art natural language processing (NLP) techniques.</p></sec><sec sec-type="methods"><title>Methods</title><p>The work was divided into 2 major phases, one to classify suicidal ideation posts and the other to extract factors that cause suicidal ideation. We proposed a hybrid deep learning&#x02013;based neural network approach (Bidirectional Encoder Representations from Transformers [BERT]+convolutional neural network [CNN]+long short-term memory [LSTM]) to classify suicidal and nonsuicidal posts. Two state-of-the-art deep learning approaches (CNN and LSTM) were combined based on features (terms) selected from term frequency&#x02013;inverse document frequency (TF-IDF), Word2vec, and BERT. Explainable artificial intelligence (XAI) was used to extract key factors that contribute to suicidal ideation in order to provide a reliable and sustainable solution.</p></sec><sec sec-type="results"><title>Results</title><p>Of 348,110 records, 3154 (0.9%) were selected, resulting in 1338 (42.4%) suicidal and 1816 (57.6%) nonsuicidal instances. The CNN+LSTM+BERT model achieved superior performance, with a precision of 94%, a recall of 95%, an <italic>F<sub>1</sub></italic>-score of 94%, and an accuracy of 93.65%.</p></sec><sec sec-type="conclusions"><title>Conclusions</title><p>Considering the dynamic nature of suicidal behavior posts, we proposed a fused architecture that captures both localized and generalized contextual information that is important for understanding the language patterns and predict the evolution of suicidal ideation over time. According to Local Interpretable Model-Agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP) XAI algorithms, there was a drift in the features during and before COVID-19. Due to the COVID-19 pandemic, new features have been added, which leads to suicidal tendencies. In the future, strategies need to be developed to combat this deadly disease.</p></sec></abstract><kwd-group><kwd>COVID-19</kwd><kwd>suicide</kwd><kwd>social networking sites</kwd><kwd>deep learning</kwd><kwd>explainable artificial intelligence</kwd><kwd>suicidal ideation</kwd><kwd>artificial intelligence</kwd><kwd>AI</kwd><kwd>social media</kwd><kwd>predictive model</kwd><kwd>mental health</kwd><kwd>pandemic</kwd><kwd>natural language processing</kwd><kwd>NLP</kwd><kwd>suicidal thought</kwd><kwd>deep neural network approach</kwd></kwd-group></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><sec><title>Overview</title><p>Mental health has become a critical area of research as societal challenges, such as pandemics, natural disasters, and economic instability, deeply affect individuals&#x02019; well-being. According to comprehensive statistics provided by the World Health Organization (WHO), the occurrence of suicide is documented to be at an average rate of 1 incident every 40 seconds [<xref rid="ref1" ref-type="bibr">1</xref>]. The report reveals that an estimated 800,000 people die by suicide annually, with suicide attempts occurring at a rate 20 times higher than that of completed suicides [<xref rid="ref2" ref-type="bibr">2</xref>]. The worldwide approximation for suicide mortality is set at around 1 million deaths per year [<xref rid="ref3" ref-type="bibr">3</xref>]. These statistics highlight suicide as the primary cause of death among young individuals, particularly among women. Contrary to an &#x0201c;all or nothing&#x0201d; perspective, a well-known book on the subject [<xref rid="ref4" ref-type="bibr">4</xref>] suggests that suicide follows a distinct process and pattern. The pattern begins with suicidal ideation and progresses toward a suicide attempt and may culminate in a completed suicide. Although not all instances of suicidal ideation lead to complete suicide, they pose a significant threat for individuals to attempt suicide. Recognition of suicidality may occur when individuals frequently discuss it with their caretakers or during interactions with psychiatrists or psychologists who inquire about their thoughts and moods. Caregivers can mitigate the risks associated with suicidality by analyzing various warning signs and implementing necessary preventive measures. However, a significant obstacle in addressing suicidality is the hesitancy of individuals to cooperate with clinicians, often influenced by the social stigma linked to mental illness. The widespread impact of stigma on suicidality affects large-scale clinical interventions for at-risk individuals. Data indicate that 36% of individuals who succumb to suicide leave behind a note [<xref rid="ref5" ref-type="bibr">5</xref>]. Research suggests that these suicide notes often signal a heightened probability of subsequent attempts that characterize greater precision after an initial failure [<xref rid="ref6" ref-type="bibr">6</xref>]. The contents of these notes frequently underscore emotions of shame and apology, hinting at a potential willingness to consider alternatives. These notes are typically discovered postcompletion or, at the least, after an attempted suicide [<xref rid="ref6" ref-type="bibr">6</xref>]. Despite efforts to screen patients, convincing individuals to undergo evaluation remains a formidable challenge in societies marked by stigma [<xref rid="ref7" ref-type="bibr">7</xref>,<xref rid="ref8" ref-type="bibr">8</xref>]. Studies highlight that people feel more at ease sharing their day-to-day experiences on online social networks (OSNs), where concerns about social stigma are less prominent [<xref rid="ref9" ref-type="bibr">9</xref>]. Recent research also suggests that monitoring social media provides an alternative and valuable opportunity to identify warning signs associated with posts from individuals at risk of suicidality [<xref rid="ref10" ref-type="bibr">10</xref>]. According to the statistics provided by the American Foundation for Suicide Prevention [<xref rid="ref11" ref-type="bibr">11</xref>], there is a rise in people with mental health conditions. As per the collaborative multiyear project &#x0201c;Suicide Prevention Now&#x0201d; [<xref rid="ref12" ref-type="bibr">12</xref>], according to statistics, in 2022, there was a significant increase in the number of people reporting mental health conditions. For instance, in 2022, 67% of American believed that they had a mental health condition at some point in their life.</p></sec><sec><title>Related Work and Background Knowledge</title><p>Mental health issues, such as depression and suicidal tendency, have traditionally been explored through psychological battery tests and clinical procedures [<xref rid="ref5" ref-type="bibr">5</xref>,<xref rid="ref13" ref-type="bibr">13</xref>]. However, to address the stigma associated with mental illness, researchers have turned to less formal platforms, such as social media, to examine language patterns in posts related to suicide. This strategy seeks to enhance the comprehension and interpretation of suicidal ideation. O&#x02019;Dea et al [<xref rid="ref14" ref-type="bibr">14</xref>] highlighted the crucial role of questionnaires in assessing a patient&#x02019;s mental state. However, with the surge in social networking sites, individuals find it more comfortable to openly express their feelings on social media platforms. Studies [<xref rid="ref13" ref-type="bibr">13</xref>,<xref rid="ref14" ref-type="bibr">14</xref>] have explored various scales used to predict depression through social media analysis. Additional research [<xref rid="ref15" ref-type="bibr">15</xref>,<xref rid="ref16" ref-type="bibr">16</xref>] has examined the topics commonly discussed by potentially suicidal individuals on social media, and the behavior of those contemplating suicide has been scrutinized in these studies. Advances in natural language processing (NLP) and machine learning techniques now allow the extraction of semantic information from social media posts, facilitating the automation of predicting suicidal content [<xref rid="ref17" ref-type="bibr">17</xref>]. Most research has focused on using binary classification mechanisms with popular algorithms, such as support vector machines (SVMs), decision trees, and ensemble learning algorithms [<xref rid="ref18" ref-type="bibr">18</xref>-<xref rid="ref21" ref-type="bibr">21</xref>]. Deep learning methods have also been used to aid in predicting suicidal ideation [<xref rid="ref22" ref-type="bibr">22</xref>,<xref rid="ref23" ref-type="bibr">23</xref>]. In <xref rid="app1" ref-type="supplementary-material">Multimedia Appendix 1</xref>, we extend the literature review where we explored relevant research works on suicidal ideation prediction (eg, [<xref rid="ref24" ref-type="bibr">24</xref>-<xref rid="ref26" ref-type="bibr">26</xref>]).</p><p>Feature selection involves identifying and selecting the most relevant attributes or features from the data. We used various feature selection and deep learning techniques, such as term frequency&#x02013;inverse document frequency (TF-IDF), Word2vec, Bidirectional Encoder Representations from Transformers (BERT), convolutional neural networks (CNNs), and long short-term memory (LSTM). The TF-IDF method involves breaking down text into tokens, calculating the term frequency (TF) to evaluate the significance of each term within a document and determining the inverse document frequency (IDF) to evaluate the uniqueness of each term across the entire data set. Word2vec learns distributed representations (word embeddings) of words based on their context in a given corpus. The resulting word vectors can be used as feature representations for various text-based tasks. Before applying Word2vec, it is essential to preprocess the text data. The Word2vec model is trained on preprocessed text data using either the Skip-gram or the Continuous Bag of Words (CBOW) architecture. We fused deep learning techniques (CNN, LSTM, BERT) in order to effectively identify suicidal ideation as posts with suicidal behavior have a dynamic nature and longer textual segments. BERT is a transformer-based model that uses self-attention mechanisms to capture contextual information. The architecture includes multiple layers of attention and feed-forward networks. BERT provides contextualized embeddings for each token in the input text. In a CNN, input data are a sequence of words or embeddings. The CNN architecture typically involves convolutional layers followed by pooling layers and fully connected layers. A CNN detects important localized features, such as word sequences, n-grams, and syntactic patterns. Each convolutional layer extracts high-level features from the text, which enables the model to capture complex patterns and semantics at different levels of granularity. It also handles input sequences of different post lengths without requiring explicit padding or truncation. LSTM networks are particularly effective for handling sequential data, such as text. LSTM networks are designed to capture long-range dependencies between words and phrases for better understanding of the context and are commonly used in text classification tasks. It propagates information over long distances in the input sequence of data. It processes input texts of different lengths without compromising performance and preserves the sequential structure and context of the posts. The methods are discussed in <xref rid="app2" ref-type="supplementary-material">Multimedia Appendix 2</xref>, which provides a theoretical and mathematical background of the deep learning approaches and feature selection methods used in this work.</p></sec><sec><title>Aims of the Study</title><p>This work aimed to identify patterns and indicators associated with suicidal ideation by leveraging machine and deep learning algorithms for social media data. The primary focus of this study was to examine the correlation between COVID-19 and the prevalence of suicidal ideation. In this work, various factors were studied related to the pandemic, such as societal, economical, and psychological factors, to detect individuals&#x02019; inclination toward suicidal thoughts due to COVID-19. Through comprehensive analysis and empirical investigations, the study sought to find the relationship between COVID-19 and suicidal ideation by detecting potential contributing factors and implications for mental health and well-being. Through rigorous analysis and modeling using deep learning methodologies, this work will contribute by finding the intersection between COVID-19 and suicide, which will be used for developing preventive interventions and support strategies to address future pandemics as well.</p><p>The study revolved around the research question of whether COVID-19 has impacted suicidal ideation. The following hypotheses were developed:</p><disp-quote><p>Null hypothesis (H0): COVID-19 has not impacted suicidal ideation, and the features (terms) used for suicidal ideation are the same as before.</p></disp-quote><disp-quote><p>Hypothesis 1 (H1): COVID-19 has impacted suicidal ideation, and the sequence of terms has changed.</p></disp-quote></sec></sec><sec sec-type="methods"><title>Methods</title><sec><title>Study Design</title><p>This work was divided into 5 phases, starting from data (suicidal posts) collection from Reddit, which is a publicly available data set. In the second phase, the data set was filtered based on various keywords. The emotions of the posts were extracted using the Natural Language Toolkit (NLTK), and the toxicity of the posts was calculated using the perspective application programming interface (API). The final corpus was used for further experimentation, and textual features were extracted using TF-IDF, Word2vec, and BERT techniques. The various classifiers were trained and tested on the filtered data set to classify the posts into 2 classes, suicidal and nonsuicidal. Another aspect of this work was explainable artificial intelligence (XAI); in this phase, 2 techniques, Local Interpretable Model-Agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP), were used to extract the most relevant keywords that trigger suicidal ideation. The study framework is depicted in <xref rid="figure1" ref-type="fig">Figure 1</xref>.</p><fig position="float" id="figure1"><label>Figure 1</label><caption><p>Framework for suicidal ideation detection in the COVID-19 era based on various filtering mechanisms. AI: artificial intelligence; BERT: Bidirectional Encoder Representations from Transformers; TF-IDF: term frequency&#x02013;inverse document frequency.</p></caption><graphic xlink:href="jmir_v27i1e65434_fig1" position="float"/></fig></sec><sec><title>Data Collection and Preparation</title><p>Data are the most important entity in all data science research. In this work, there were privacy concerns related to the data. We collected relevant data from the public data repository Kaggle, which contains suicidal posts from the social media platform Reddit. The data were categorized into 2 classes, suicidal and nonsuicidal. The data set consisted of 2 columns, one with the posts (textual) and the other with labels. We leveraged a keyword-based filtering mechanism to classify and analyze user-generated content. We established a comprehensive set of keywords associated with COVID-19 and suicidal ideation, such as &#x0201c;COVID,&#x0201d; &#x0201c;COVID-19,&#x0201d; &#x0201c;lockdown,&#x0201d; &#x0201c;quarantine,&#x0201d; and &#x0201c;coronavirus.&#x0201d; Using these keywords, a dual-layer filtering approach was implemented that categorized the posts into either COVID-19 related or not, followed by an assessment for suicidal content. For further exploration of the data, we performed emotion analysis (EA) to extract the mood of the poster. Eight different emotions were used for EA. After EA, we performed a toxicity analysis (TA) to identify toxic posts, and toxic values were associated with all the posts. We considered only negative, sad, and fearful emotions and posts that had a toxicity value greater than 0.5. In this study, we used the absolute majority (ie, a majority is when more than half of the total weighted words are toxic words). Another alternative was to use two-thirds majority; however, this was not a conservative choice because we risked having a large number of false positives. So, an absolute majority was more protective. By establishing a threshold of 0.5, a clear and straightforward benchmark was created for classifying outputs from our detection models. This threshold simplified both interpretation and implementation for detecting suicidal ideation. It also helped reduce ambiguity in the decision-making process. By doing so, we ensured that texts flagged as indicative of suicidal ideation were those with a probability score of 0.5 or higher. This minimized the risk of misinterpretation as it directed attention to those posts that met a specific criterion for concern. In addition, the empirical accuracies showed that our choice was effective in detecting suicidal ideation. After filtering the posts, we performed data cleaning and preprocessing, in which the textual data was refined using techniques such as tokenization, lemmatization, and normalization. Furthermore, irrelevant data were removed using the stop-word dictionary, and punctuation was also removed.</p></sec><sec><title>Feature Engineering and Selection</title><p>The process of selecting the most relevant and informative features from unprocessed data is known as feature engineering, and it increases the machine learning models&#x02019; effectiveness [<xref rid="ref25" ref-type="bibr">25</xref>]. To do this, raw data must be transformed into more significant features that can effectively identify underlying patterns and relationships. This approach makes use of a number of techniques, including feature extraction, feature transformation, and feature selection. Model performance can be greatly influenced by feature engineering through careful feature creation and selection. The data in this study were primarily textual, similar to behavioral analysis of internet users, with the objective of identifying COVID-19&#x02013;induced suicidal tendencies in online users. To input the data that were collected into the deep learning models, 3 basic word-embedding techniques&#x02014;TF-IDF [<xref rid="ref26" ref-type="bibr">26</xref>-<xref rid="ref28" ref-type="bibr">28</xref>], Word2vec [<xref rid="ref29" ref-type="bibr">29</xref>], and BERT [<xref rid="ref30" ref-type="bibr">30</xref>,<xref rid="ref31" ref-type="bibr">31</xref>]&#x02014;were used to identify and analyze patterns in the text-based content. Our model leveraged BERT-based architectures. These architectures are designed to capture contextual relationships between words by processing the entire sequence of words simultaneously rather than in isolation. This allows the model to understand the meaning of a word based on its surrounding context, and it significantly improves the accuracy of detecting sarcasm, idiomatic expressions, or shifts in sentiment in languages. The post length is also considered as one of the features. The extracted features were used as input to the CNN and LSTM deep learning models. When used with the CNN and LSTM models, these feature selection techniques improve performance. As mentioned before, CNNs excel at capturing localized patterns in sequential data by making them well suited for text classification, LSTM networks capture long-term dependencies and are effective for modeling sequential data with complex temporal dynamics, and BERT captures contextual relationships between words by processing the entire sequence of words simultaneously.</p></sec><sec><title>Suicide Posts&#x02019; Classification</title><p>Different classifiers are used for classifying posts into binary classes. In this work, we used multiple combinations of classifiers to predict suicidal posts. The data set we used to train our model consisted of 2 columns, text and label. The problem was formulated the same way as that by Hossain et al [<xref rid="ref32" ref-type="bibr">32</xref>] and Ji et al [<xref rid="ref33" ref-type="bibr">33</xref>]. On a corpus consisting of a set of posts <inline-graphic xlink:href="jmir_v27i1e65434_fig6.jpg"/> and labels <inline-graphic xlink:href="jmir_v27i1e65434_fig7.jpg"/>, training was provided in such a manner that the model learned from the data consisting of a set of all the engineered features and the corresponding labels that were provided in a supervised approach. The supervisory function is shown in Equation 1:</p><p>l<sub>i</sub> = fun(p<sub>i</sub>) (1)</p><p>Here, l<sub>i</sub> = 1 in the case of p<sub>i</sub> representing suicide and l<sub>i</sub> = 0 represents nonsuicide. We focused on the &#x0201c;no free lunch&#x0201d; theorem of machine learning, which suggests that no algorithm can work well for all problems. Three deep learning classification algorithms were implemented: CNN, LSTM, and BERT. These models were fused, as shown in Equation 2:</p><p>h<sub>c</sub> = CNN(X),</p><p>h<sub>l</sub> = LSTM(X),</p><p>h<sub>b</sub> = BERT(X), (2)</p><p>h<sub>m</sub> = concatenate(h<sub>c</sub>, h<sub>l</sub>, h<sub>b</sub>),</p><p>y = softmax(Wh<sub>m</sub> + b),</p><p>where X is the input data and is represented as a matrix, where each row corresponds to a data sample and each column corresponds to a feature; h<sub>c</sub> refers to feature representation by the CNN; h<sub>l</sub> refers to feature representation by the LSTM; h<sub>b</sub> refers to feature representation by BERT; h<sub>m</sub> refers to fused features obtained by concatenating h<sub>c</sub>, h<sub>l</sub>, and h<sub>b</sub>; y is the predicted class probabilities for suicidal posts; and W is the weight of fused features h<sub>m</sub>; and b is the bias of h<sub>m</sub>.</p><p>The pseudocode of the entire experiment is shown in the algorithm in <xref rid="box1" ref-type="boxed-text">Textbox 1</xref>. This algorithm outlines the steps for identifying suicidal posts in social media content during the COVID-19 pandemic. The process began with a set of posts and classified them into suicidal and nonsuicidal posts. The algorithm required input posts and ensured the output includes suicidal and nonsuicidal posts. For each post, the algorithm performed EA and TA. Posts were classified based on whether they exhibited sad or negative emotions, alongside a toxicity score above a threshold (0.5). If a post met both criteria, it was added to the final corpus, otherwise it was discarded. The algorithm then processed the remaining posts through tokenization, stop-word removal, and stemming, saving the preprocessed data in a CSV file. Features were extracted using BERT embeddings and TF-IDF, resulting in a document feature matrix. The matrix was trimmed based on minimum document frequencies and TFs to focus on significant terms. Finally, deep learning algorithms and transformers with specific hyperparameters were applied to classify the posts as either suicidal or nonsuicidal. This approach leverages deep learning techniques and NLP to effectively identify suicidal ideation in the context of COVID-19 and ultimately enhances mental health awareness and intervention strategies.</p><boxed-text id="box1" position="float"><caption><title>Pseudocode: deep learning&#x02013;based suicide behavior identification during COVID-19.</title></caption><p><bold>REQUIRE:</bold> Posts P</p><p><bold>ENSURE:</bold> Suicidal Post P<sub>s</sub> and Non-Suicidal Post P<sub>n</sub></p><p>Tokenization &#x02192; T, StopWordRemoval &#x02192; SW, Stemming &#x02192; S, Total Number of Tweets &#x02192; n</p><p>Emotion Analysis &#x02192; EA , Toxicity Analysis &#x02192; TA</p><p>Term Frequency&#x02013;Inverse Document Frequency &#x02192; TF-IDF, Word2vec &#x02192; w, BERT &#x02192; B</p><p>
<bold>
<italic>START</italic>
</bold>
</p><p>1 <bold><italic>For</italic></bold>
<italic>i from</italic> 1 <italic>to</italic> n</p><p>2 Perform EA(P[i])</p><p>3 Perform TA(P[i])</p><p>4 if (EA(P[i]==Sad/Negative &#x00026;&#x00026; TA(P[i]&#x0003e;0.5))then</p><p>5 C[i]=P[i] // final corpus</p><p>6 <bold>Else</bold></p><p>7 Discard</p><p>8 <bold><italic>End For</italic></bold></p><p>9 C[i]=T(C[i])</p><p>10 C[i] = SW(C[i])</p><p>11 C[i]= S(C[i])</p><p>12 Processed.csv= C[i] //Saving Preprocessed file as CSV</p><p>13 Features B = B(Processed)</p><p>14 Features T=TF/IDF(Processed)</p><p>15 Document Feature Matrix=Document Feature Matrix(Features T)</p><p>16 Trimmed_dfm=dfm_trim(dfm,min_docfreq,min_termfreq)</p><p>17 Final_Features T=Trimmed_dfm.Tfidf //Extracting TFIDF Features</p><p>18 Feature w=w(Processed)</p><p>19 <bold><italic>CLASSIFIER</italic></bold> (Classifier_Name, Hyperparameters, Features)</p><p>
<bold>
<italic>END</italic>
</bold>
</p></boxed-text></sec><sec><title>Explainable Artificial Intelligence</title><p>XAI holds a central role in mental health by improving the transparency and accountability of artificial intelligence (AI) systems [<xref rid="ref34" ref-type="bibr">34</xref>,<xref rid="ref35" ref-type="bibr">35</xref>]. In mental health applications, it is imperative that health care professionals and patients alike grasp and have confidence in the AI&#x02019;s decision-making procedures [<xref rid="ref36" ref-type="bibr">36</xref>]. XAI accomplishes this by furnishing explanations for AI-generated diagnoses, forecasts, and treatment recommendations. These explanations provide valuable insights into the rationale behind specific decisions, assisting clinicians and patients in gaining a deeper understanding of the logic behind mental health assessments. This transparency fosters trust and promotes collaboration between AI systems and human experts, which ultimately enhances the quality of mental health care. In addition, XAI aids in detecting and reducing biases within AI models, which ensures that mental health assessments remain impartial and unbiased, a critical aspect of delivering equitable care to diverse patient populations. XAI also contributes to the formulation of individualized treatment plans in the mental health domain. By elucidating factors influencing an individual&#x02019;s mental health condition, AI systems can customize interventions to cater to each patient&#x02019;s unique requirements. XAI also facilitates early intervention and prevention by enabling the identification of early warning signs and comprehending the interconnected elements affecting mental well-being. Empowering patients through understandable explanations increases their engagement in the treatment process, potentially leading to better outcomes. XAI serves not only as a tool for enhancing mental health care but also as a means of diminishing stigma by promoting ethical practices and propelling the field of mental health forward through data-driven insights and improved decision-making. XAI techniques are designed to make the decision-making processes of AI systems more understandable and interpretable for humans. These techniques are particularly important when AI systems make complex predictions, classifications, or recommendations in fields such as health care, finance, and autonomous vehicles, where transparency and trust are critical.</p><p>LIME generates perturbed instances (z<sub>1</sub>, z<sub>2</sub>,&#x02026;, z<sub>k</sub>) and performs predictions: f(z<sub>1</sub>), f(z<sub>2</sub>),&#x02026;, f(z<sub>k</sub>). The local linear model <inline-graphic xlink:href="jmir_v27i1e65434_fig8.jpg"/>. The objective function of LIME is calculated using Equation 3:</p><disp-formula>
<graphic xlink:href="jmir_v27i1e65434_fig9.jpg" position="float"/>
</disp-formula><p>Here, x represents the instance for which we want an explanation, z<sub>i</sub> are perturbed instances, &#x003c0;<sub>x</sub>(x,z<sub>i</sub>) is a weight, and <inline-graphic xlink:href="jmir_v27i1e65434_fig10.jpg"/> is the gradient of f at x<sub>0</sub>.</p><p>Shapley XAI has the following workings:</p><p>The Shapley value for a feature i in the context of a prediction f(x) is shown in Equation 4:</p><disp-formula>
<graphic xlink:href="jmir_v27i1e65434_fig11.jpg" position="float"/>
</disp-formula><p>Here, N is the set of all features and S is a subset of features excluding i.</p><p>Expected Shapley values are represented in Equation 5:</p><disp-formula>
<graphic xlink:href="jmir_v27i1e65434_fig12.jpg" position="float"/>
</disp-formula><p>Here, N is the number of samples from the background distribution.</p></sec><sec><title>Ethical Considerations</title><p>This research did not include any studies on human participants performed by any of the authors. However, ethical considerations of our study could be related to the use of data collected on posts on the Reddit platform, which is commonly perceived as widely public, where participants are not identifiable as no registration is required but only a pseudo name to post. Moreover, public post analysis, such as Reddit posts, is considered ethical issue free because there is no expectation of privacy as individuals are anonymous, and users understand that their posts can be reused (ie, reposted) and remain archived on the platform until deletion eventually. Hence, ethical issues of research on Reddit are resolved by the public nature of this social media platform, especially when used in academic publications.</p></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Study Details</title><p>Of 348,110 records, 3154 (0.9%) were filtered out, resulting in 1338 (42.4%) suicidal and 1816 (57.6%) nonsuicidal posts. The training data in all experiments were split in an 80:20 ratio for training and validation because empirical findings [<xref rid="ref37" ref-type="bibr">37</xref>] suggest that the performance of algorithms improves when the data set is divided in this manner. Each algorithm was tested on a distinct subset of the original data set. Our model was evaluated using various metrics to assess their performance. We discovered that the model&#x02019;s performance improved slightly as the number of training data points was raised. The method of dividing the data set into training and testing subsets has inherent problems with bias and variance. These problems arise because of the nature of the data. In machine learning, it is not necessary that the model that has been fit on training data will also work on real data. This is because real data can be different from training data. To accomplish this, we made use of the technique of k-fold cross-validation. This allowed us to ensure that the model correctly identified the patterns within the data, while minimizing noise exposure. Our model&#x02019;s validity was established by a process known as 10-fold cross-validation. Python was chosen as the language to implement algorithms for machine learning. Skicit-learn, Pandas, and NLTK are the most significant packages used in the coding process during the training of the suicide prediction model. After evaluating hybrid deep learning models, we found that BERT, when fused with CNN+LSTM, showed the best results among all hybrid deep learning models. With a precision of 94%, a recall of 95%, an <italic>F</italic><sub>1</sub>-score of 94%, and an overall accuracy of 93.65%. <xref rid="figure2" ref-type="fig">Figure 2</xref> shows the hybrid model&#x02019;s performance based on the model loss and model accuracy. <xref rid="table1" ref-type="table">Table 1</xref> depicts the classification report of all the classifiers that were used during experimentation.</p><fig position="float" id="figure2"><label>Figure 2</label><caption><p>Performance metrics showing the accuracy and loss of the best model, which combined BERT, CNN, and LSTM for enhanced prediction results. BERT: Bidirectional Encoder Representations from Transformers; CNN: convolutional neural network; LSTM: long short-term memory.</p></caption><graphic xlink:href="jmir_v27i1e65434_fig2" position="float"/></fig><table-wrap position="float" id="table1"><label>Table 1</label><caption><p>Classification report of hybrid models based on various evaluation metrics.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="290" span="1"/><col width="190" span="1"/><col width="150" span="1"/><col width="180" span="1"/><col width="190" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Classifier</td><td rowspan="1" colspan="1">Precision (%)</td><td rowspan="1" colspan="1">Recall (%)</td><td rowspan="1" colspan="1"><italic>F</italic><sub>1</sub>-score (%)</td><td rowspan="1" colspan="1">Accuracy (%)</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">TF-IDF<sup>a</sup>+CNN<sup>b</sup></td><td rowspan="1" colspan="1">76.00</td><td rowspan="1" colspan="1">80.00</td><td rowspan="1" colspan="1">78.00</td><td rowspan="1" colspan="1">78.00</td></tr><tr valign="top"><td rowspan="1" colspan="1">Word2vec+LSTM<sup>c</sup></td><td rowspan="1" colspan="1">88.00</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">88.00</td></tr><tr valign="top"><td rowspan="1" colspan="1">BERT<sup>d</sup>+CNN</td><td rowspan="1" colspan="1">69.00</td><td rowspan="1" colspan="1">66.00</td><td rowspan="1" colspan="1">67.00</td><td rowspan="1" colspan="1">64.00</td></tr><tr valign="top"><td rowspan="1" colspan="1">LSTM+BERT</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">83.00</td><td rowspan="1" colspan="1">85.00</td><td rowspan="1" colspan="1">85.00</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+LSTM</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">91.00</td></tr><tr valign="top"><td rowspan="1" colspan="1">BERT+CNN+LSTM</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">95.00</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">93.65</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+LSTM+TFIDF</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">89.00</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+LSTM+Word2vec</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+Word2vec</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">86.00</td></tr></tbody></table><table-wrap-foot><fn id="table1fn1"><p><sup>a</sup>TF-IDF: term frequency&#x02013;inverse document frequency.</p></fn><fn id="table1fn2"><p><sup>b</sup>CNN: convolutional neural network.</p></fn><fn id="table1fn3"><p><sup>c</sup>LSTM: long short-term memory.</p></fn><fn id="table1fn4"><p><sup>d</sup>BERT: Bidirectional Encoder Representations from Transformers.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>Validation</title><p>In this study, we used the 10-fold cross-validation technique to validate our proposed approach. It is a robust technique frequently used in machine learning and statistical modeling to evaluate the performance and generalization capability of predictive models. In this approach, the data set is divided into 10 equal-size segments, known as folds. Throughout each iteration, 1 fold is designated as the validation set, while the remaining 9 folds serve as the training set. This process is iterated 10 times, with each fold taking on the role of the validation set once. The 10-fold cross-validation technique has the ability to furnish a more dependable assessment of a model&#x02019;s performance in contrast to a single train-test split. By computing performance metrics across various folds and subsequently averaging them, the ambiguity in outcomes is reduced, which leads to a more consistent evaluation. In addition, it helps in dealing with bias and variance. It guarantees that every data point contributes to both training and validation processes, thereby lessening the risk of overfitting and furnishing a more precise evaluation of the model&#x02019;s capacity to generalize to new data. In this work, after performing 10-fold cross-validation, the mean accuracy was compared with the actual accuracy of the models, and it was found that there was no such difference. We concluded that the proposed approach does not suffer from over- or underfitting. The results of 10-fold cross-validation are shown in <xref rid="table2" ref-type="table">Table 2</xref> and visually represented in <xref rid="figure3" ref-type="fig">Figure 3</xref>.</p><table-wrap position="float" id="table2"><label>Table 2</label><caption><p>Results of 10-fold cross-validation, along with the calculated mean accuracy for model evaluation.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="200" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="70" span="1"/><col width="0" span="1"/><col width="100" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Classifier</td><td colspan="11" rowspan="1">Accuracy (%)</td><td rowspan="1" colspan="1">Accuracy (%), mean (SD)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Fold 1</td><td rowspan="1" colspan="1">Fold 2</td><td rowspan="1" colspan="1">Fold 3</td><td rowspan="1" colspan="1">Fold 4</td><td rowspan="1" colspan="1">Fold 5</td><td rowspan="1" colspan="1">Fold 6</td><td rowspan="1" colspan="1">Fold 7</td><td rowspan="1" colspan="1">Fold 8</td><td rowspan="1" colspan="1">Fold 9</td><td rowspan="1" colspan="1">Fold 10</td><td colspan="2" rowspan="1">
<break/>
</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">BERT<sup>a</sup>+CNN<sup>b</sup>+LSTM<sup>c</sup></td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">93.00</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">93.00</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">93.00</td><td rowspan="1" colspan="1">94.00</td><td rowspan="1" colspan="1">94.00</td><td colspan="2" rowspan="1">93.65 (0.41)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Word2vec+LSTM</td><td rowspan="1" colspan="1">88.00</td><td rowspan="1" colspan="1">88.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">87.00</td><td rowspan="1" colspan="1">85.00</td><td rowspan="1" colspan="1">88.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">88.00</td><td colspan="2" rowspan="1">88.20 (1.58)</td></tr><tr valign="top"><td rowspan="1" colspan="1">BERT+CNN</td><td rowspan="1" colspan="1">66.00</td><td rowspan="1" colspan="1">64.00</td><td rowspan="1" colspan="1">63.00</td><td rowspan="1" colspan="1">65.00</td><td rowspan="1" colspan="1">66.00</td><td rowspan="1" colspan="1">65.00</td><td rowspan="1" colspan="1">64.00</td><td rowspan="1" colspan="1">66.00</td><td rowspan="1" colspan="1">65.00</td><td rowspan="1" colspan="1">64.00</td><td colspan="2" rowspan="1">65.00 (1.00)</td></tr><tr valign="top"><td rowspan="1" colspan="1">LSTM+BERT</td><td rowspan="1" colspan="1">85.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">84.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">83.00</td><td rowspan="1" colspan="1">85.00</td><td rowspan="1" colspan="1">85.00</td><td rowspan="1" colspan="1">85.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">85.00</td><td colspan="2" rowspan="1">85.00 (0.95)</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+LSTM</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">89.00</td><td colspan="2" rowspan="1">90.20 (0.82)</td></tr><tr valign="top"><td rowspan="1" colspan="1">TF-IDF<sup>d</sup>+CNN</td><td rowspan="1" colspan="1">78.00</td><td rowspan="1" colspan="1">76.00</td><td rowspan="1" colspan="1">77.00</td><td rowspan="1" colspan="1">79.00</td><td rowspan="1" colspan="1">76.00</td><td rowspan="1" colspan="1">78.00</td><td rowspan="1" colspan="1">79.00</td><td rowspan="1" colspan="1">78.00</td><td rowspan="1" colspan="1">76.00</td><td rowspan="1" colspan="1">79.00</td><td colspan="2" rowspan="1">77.60 (1.10)</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+LSTM+TF-IDF</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">88.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">91.00</td><td colspan="2" rowspan="1">89.60 (0.82)</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+LSTM+Word2vec</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">91.00</td><td rowspan="1" colspan="1">88.00</td><td rowspan="1" colspan="1">89.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td><td rowspan="1" colspan="1">90.00</td><td colspan="2" rowspan="1">89.80 (0.82)</td></tr><tr valign="top"><td rowspan="1" colspan="1">CNN+Word2vec</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">84.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">87.00</td><td rowspan="1" colspan="1">88.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">86.00</td><td rowspan="1" colspan="1">88.00</td><td colspan="2" rowspan="1">86.70 (1.10)</td></tr></tbody></table><table-wrap-foot><fn id="table2fn1"><p><sup>a</sup>BERT: Bidirectional Encoder Representations from Transformers.</p></fn><fn id="table2fn2"><p><sup>b</sup>CNN: convolutional neural network.</p></fn><fn id="table2fn3"><p><sup>c</sup>LSTM: long short-term memory.</p></fn><fn id="table2fn4"><p><sup>d</sup>TF-IDF: term frequency&#x02013;inverse document frequency.</p></fn></table-wrap-foot></table-wrap><fig position="float" id="figure3"><label>Figure 3</label><caption><p>The 10-fold cross-validation process for evaluating model performance through systematic partitioning of the data set. BERT: Bidirectional Encoder Representations from Transformers; CNN: convolutional neural network; LSTM: long short-term memory; TF-IDF: term frequency&#x02013;inverse document frequency.</p></caption><graphic xlink:href="jmir_v27i1e65434_fig3" position="float"/></fig></sec><sec><title>Comparative Analysis of Posts Before and During COVID-19</title><p>Exploratory data analysis of both training and validation data sets was performed, and results showed that n-grams used before and during COVID-19 were different. <xref rid="figure4" ref-type="fig">Figure 4</xref> presents a comparative analysis of the n-grams used in suicidal posts during both periods. <xref rid="figure4" ref-type="fig">Figure 4</xref>a illustrates the most frequently occurring n-grams in posts related to suicidal ideation during the COVID-19 pandemic, which highlights key phrases and terms that reflect the mental health challenges faced during the crisis, while <xref rid="figure4" ref-type="fig">Figure 4</xref>b depicts the n-gram sequences identified in suicidal posts from the non&#x02013;COVID-19 era.</p><fig position="float" id="figure4"><label>Figure 4</label><caption><p>Top n-gram sequences distinguishing COVID-19&#x02013;related and non&#x02013;COVID-19&#x02013;related posts. A) Top n-gram sequence in the COVID-19 suicidal posts; B) Top n-gram sequence in the non COVID-19 suicidal posts.</p></caption><graphic xlink:href="jmir_v27i1e65434_fig4" position="float"/></fig></sec><sec><title>Explainable Artificial Intelligence Extraction</title><p>XAI showed the most important features (terms) that were used in the suicidal content during COVID-19. <xref rid="figure5" ref-type="fig">Figure 5</xref> shows a graphical representation of the features extracted by XAI:</p><list list-type="bullet"><list-item><p>&#x0201c;covid,&#x0201d; &#x0201c;covid-19&#x0201d;: These terms indicate a direct association with the COVID-19 pandemic. Individuals may express distress, anxiety, or hopelessness related to the pandemic, which can contribute to suicidal ideation.</p></list-item><list-item><p>&#x0201c;live, life&#x0201d;: These terms are broad and could encompass various aspects of an individual&#x02019;s life, such as personal relationships, work, health, or the financial situation. Expressions related to feeling overwhelmed, hopeless, or lacking purpose in life may contribute to suicidal thoughts.</p></list-item><list-item><p>&#x0201c;die,&#x0201d; &#x0201c;stop,&#x0201d; &#x0201c;myself&#x0201d;: These words directly relate to thoughts of self-harm or suicide. They indicate a strong presence of negative thoughts or intentions toward ending one&#x02019;s life.</p></list-item></list><p>XAI was used to check the impact of COVID-19 on suicidal ideation, and it can be clearly seen from the results that COVID-19&#x02013;related words were used frequently in suicidal thoughts.</p><fig position="float" id="figure5"><label>Figure 5</label><caption><p>Important features (terms) associated with suicidal posts and their relevance in predictive analysis. SHAP: Shapley Additive Explanations.</p></caption><graphic xlink:href="jmir_v27i1e65434_fig5" position="float"/></fig></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Principal Findings</title><p>The results of this study indicate significant changes in language patterns before and during the COVID-19 pandemic. Individuals used different sets of words prior to the pandemic, and the sequence of words shifted during the pandemic. In this work, we investigated the impact of the COVID-19 pandemic on suicidal ideation by proposing a null hypothesis (H<sub>0</sub>) that COVID-19 has not influenced levels of suicidal thoughts among individuals. By using the proposed methodology, our findings revealed a significant increase in suicidal ideation associated with the pandemic. The analysis showed a <italic>P</italic> value of &#x0003c;.01, which leads us to reject H<sub>0</sub> in favor of the alternative hypothesis (H<sub>1</sub>), which posited that COVID-19 has had a measurable impact on suicidal ideation. These results underscore the urgent need for mental health interventions during and after public health crises, highlighting the critical link between worldwide events and individual psychological well-being.</p></sec><sec><title>Comparative Analysis</title><p>For validating the approach, we performed comparative analysis in which we compared existing methods with our approach. The methodology described by Jung et al [<xref rid="ref38" ref-type="bibr">38</xref>] showed that Bow-Char had a maximum recall score of 0.75, closely trailed TF-IDF (SVM) with a recall of 0.70. In our approach, the recall scores ranged from 0.83 to 0.95, which are higher than existing ones. The results demonstrated that the BERT+CNN+LSTM model had the highest recall, proving its efficacy in identifying positive instances. In addition, ADA achieved the higher precision of 0.92 compared to other approaches that were proposed by Jung et al [<xref rid="ref38" ref-type="bibr">38</xref>], while our approach achieved precision values from 0.86 to 0.95. The BERT+CNN+LSTM model showed that it can minimize false positives by attaining the maximum level of accuracy. The range of accuracy attained by Jung et al [<xref rid="ref38" ref-type="bibr">38</xref>] was 65%-77%. Our proposed models, in contrast, outperformed them with accuracy scores between 0.85 and 0.9365. The best accuracy was shown by the BERT+CNN+LSTM model, demonstrating its capacity to classify most cases properly. According to Saba et al [<xref rid="ref39" ref-type="bibr">39</xref>], a recurrent neural network (RNN) performs better due to its high precision value (1), while CNN models achieve good recall values of 0.8 and CNN+SVM models achieve 91.6% accuracy. Our approach outperformed previous methods by achieving greater recall, precision, and accuracy values; the BERT+CNN+LSTM model achieved 93.65% accuracy. These findings show that the proposed method produces more accurate and reliable results.</p><p>When <italic>F</italic><sub>1</sub>-scores were examined, ADA had the highest score of 0.73 among the techniques examined by Jung et al [<xref rid="ref38" ref-type="bibr">38</xref>], while the RNN had an <italic>F</italic><sub>1</sub>-score of 0.76 and the CNN and CNN+SVM models had the highest <italic>F</italic><sub>1</sub>-scores of 0.85 and 0.90 according to Saba et al [<xref rid="ref39" ref-type="bibr">39</xref>]. Our approach outperformed in <italic>F</italic><sub>1</sub>-scores as well by achieving values ranging from 0.85 to 0.94. The best <italic>F</italic><sub>1</sub>-score was attained by the BERT+CNN+LSTM model, demonstrating its balanced precision and recall performance. The TF-IDF+CNN model outperformed Jung et al&#x02019;s [<xref rid="ref38" ref-type="bibr">38</xref>] best method in terms of recall by about 20%. Comparably, the CNN+LSTM and CNN+LSTM+Word2vec models outperformed Jung et al&#x02019;s [<xref rid="ref38" ref-type="bibr">38</xref>] optimal approach by about 15% and 14%, respectively, in terms of recall values. These notable advancements suggest that the proposed techniques are better at identifying positive samples. The accuracy of the TF-IDF+CNN model was around 21.65% greater than that of Jung et al&#x02019;s [<xref rid="ref38" ref-type="bibr">38</xref>] optimal method (TF-IDF+SVM). Similarly, accuracy gains of roughly 19% and 18% were attained by our CNN+LSTM and CNN+LSTM+Word2vec models, respectively. These improvements show that the proposed approaches have stronger categorization skills and produce results that are more accurate. Hence, we can conclude that the recall, precision, accuracy, and <italic>F</italic><sub>1</sub>-score of the proposed methods&#x02014;TF-IDF+CNN, BERT+LSTM, CNN+LSTM, and Word2vec+CNN+LSTM&#x02014;are better than existing techniques. The enhancements in performance range from 14% to 21%, highlighting the efficacy of using sophisticated methods, such as TF-IDF, CNNs, LSTM, and BERT, when examining content.</p></sec><sec><title>Limitations</title><p>We analyzed the strengths and weaknesses of each model, and it was found that the CNN effectively captured localized patterns in social media posts, such as emotional language and contextual cues indicative of suicidal ideation. Phrases such as &#x0201c;I feel hopeless&#x0201d; and &#x0201c;No one cares&#x0201d; were accurately classified as indicating suicidal ideation. However, the model struggled with understanding context, particularly when the meaning of a post depended heavily on the sequence of words rather than their individual presence. For example, the phrase &#x0201c;I just need a break&#x0201d; was incorrectly classified as nonsuicidal. In contrast, the LSTM processed sequences that made it suitable for understanding the context and flow of language over time. For example, posts beginning with &#x0201c;Things have been tough lately&#x0201d; and continued with &#x0201c;I can&#x02019;t see a way out&#x0201d; were correctly identified by the LSTM as having an evolving sentiment of despair and resulted in the correct classification of suicidal ideation. However, there is a risk of overfitting to the training data, especially if the training set is small or not diverse enough. Although the LSTM captured the emotional tone, it may have overfit to similar phrases in the training set that did not indicate suicidal ideation and resulted in false negatives. For example, &#x0201c;I can't handle this anymore, I'm just tired of fighting&#x0201d; was misclassified as nonsuicidal. BERT processes text in both directions simultaneously. This allows it to capture the full context of a word based on its surroundings, leading to better understanding and representation of meaning, but it benefits from being trained on large data sets. Since we had less data, we integrated the three algorithms (BERT, CNN, and LSTM) in our hybrid model, which helped us mitigate the individual weaknesses of each model. The CNN effectively extracted features from social media posts, the LSTM provided a contextual understanding of the text, and BERT considered the entire context of each word, which effectively disambiguated words with multiple meanings. Combining these architectures allowed us to capture both localized and generalized contextual information that is crucial for understanding the language patterns associated with suicidal behavior. By fusing these 3, our model achieved an accuracy of 93.65%.</p></sec><sec><title>Implications of the Study</title><p>The findings of this study reveal that the COVID-19 pandemic has influenced mental health. Due to the shift in language patterns, there is an increase in terms related to distress, hopelessness, and self-harm, which underscores the profound psychological impact of the pandemic. A clearer understanding of linguistic markers that may indicate heightened risk can be identified using XAI. These linguistic patterns have broader implications for early detection and intervention strategies for suicidal ideation. We suggest that language-based monitoring could serve as a tool for identifying individuals at risk. In addition, the study emphasizes the need for targeted mental health support during worldwide crises because the psychological effects of such events can lead to a lasting transformation in how individuals express their struggles. The findings suggest a critical shift toward more personalized language-based approaches to mental health care that can adapt to the unique challenges posed by worldwide events, such as the COVID-19 pandemic.</p></sec><sec><title>Conclusion</title><p>The worldwide impact of COVID-19 has had long-lasting effects on people&#x02019;s mental well-being. In this study, we collected data from Reddit posts related to COVID-19. Data were filtered using specific keywords associated with the pandemic. Through EA and TA, we understood the emotional tone and potential harm in these posts. To classify the data, hybrid deep learning classifiers were used, which fused BERT, CNN, and LSTM models. The results reveal that our BERT+CNN+LSTM model achieved the highest accuracy of 93.65%, with a precision of 94% and a recall of 95%. In the final stage, XAI techniques, such as LIME and SHAP, extracted important factors for suicidal and nonsuicidal sentiments. After integration, the fused model can effectively grasp both localized and generalized contextual characteristics that are essential for comprehending linguistic patterns linked with suicidal ideation. It manages diverse formats commonly encountered in real-world text data by accommodating varying sentence lengths and syntactic complexities. This model will equip decision makers with a deeper understanding of factors contributing to suicide risk, facilitating the development of more impactful intervention strategies. Our analysis showed that terms related to COVID-19 are often present in posts with suicidal tendencies. We plan to incorporate audio data alongside these features to enhance the prediction of suicidal ideation.</p></sec></sec></body><back><fn-group><fn fn-type="con"><p>Authors' Contributions: SB and AMUDK conceptualized the study and implemented the work. AO performed the literature review and readability analyses. AMUDK drafted the first version of the manuscript. All the authors have revised and edited the manuscript.</p></fn><fn fn-type="COI-statement"><p>Conflicts of Interest: None declared.</p></fn></fn-group><app-group><supplementary-material id="app1" position="float" content-type="local-data"><label>Multimedia Appendix 1</label><p>Detailed literature.</p><media xlink:href="jmir_v27i1e65434_app1.docx" xlink:title="DOCX File , 18 KB" id="d100e1165" position="anchor"/></supplementary-material><supplementary-material id="app2" position="float" content-type="local-data"><label>Multimedia Appendix 2</label><p>Background knowledge of various methods used.</p><media xlink:href="jmir_v27i1e65434_app2.docx" xlink:title="DOCX File , 19 KB" id="d100e1169" position="anchor"/></supplementary-material></app-group><glossary><title>Abbreviations</title><def-list><def-item><term id="abb1">AI</term><def><p>artificial intelligence</p></def></def-item><def-item><term id="abb2">BERT</term><def><p>Bidirectional Encoder Representations from Transformers</p></def></def-item><def-item><term id="abb3">CNN</term><def><p>convolutional neural network</p></def></def-item><def-item><term id="abb4">EA</term><def><p>emotion analysis</p></def></def-item><def-item><term id="abb5">LIME</term><def><p>Local Interpretable Model-Agnostic Explanations</p></def></def-item><def-item><term id="abb6">LSTM</term><def><p>long short-term memory</p></def></def-item><def-item><term id="abb7">NLP</term><def><p>natural language processing</p></def></def-item><def-item><term id="abb8">NLTK</term><def><p>Natural Language Toolkit</p></def></def-item><def-item><term id="abb9">SHAP</term><def><p>Shapley Additive Explanations</p></def></def-item><def-item><term id="abb10">SVM</term><def><p>support vector machine</p></def></def-item><def-item><term id="abb11">TA</term><def><p>toxicity analysis</p></def></def-item><def-item><term id="abb12">TF-IDF</term><def><p>term frequency&#x02013;inverse document frequency</p></def></def-item><def-item><term id="abb13">XAI</term><def><p>explainable artificial intelligence</p></def></def-item></def-list></glossary><notes><sec sec-type="data-availability"><title>Data Availability</title><p>The data used in this study are available upon request from the corresponding author.</p></sec></notes><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="webpage"><article-title>Suicide prevention</article-title><source>World Health Organization</source><date-in-citation content-type="access-date">2024-12-28</date-in-citation><comment>
<ext-link xlink:href="https://www.who.int/health-topics/suicide#tab=tab_1" ext-link-type="uri">https://www.who.int/health-topics/suicide#tab=tab_1</ext-link>
</comment></element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bilsen</surname><given-names>J</given-names></name></person-group><article-title>Suicide and youth: risk factors</article-title><source>Front Psychiatry</source><year>2018</year><volume>9</volume><fpage>540</fpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/30425663" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.3389/fpsyt.2018.00540</pub-id><pub-id pub-id-type="medline">30425663</pub-id><!--<pub-id pub-id-type="pmcid">PMC6218408</pub-id>--><pub-id pub-id-type="pmid">30425663</pub-id>
</element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>V&#x000e4;rnik</surname><given-names>P</given-names></name></person-group><article-title>Suicide in the world</article-title><source>Int J Environ Res Public Health</source><year>2012</year><month>03</month><day>02</day><volume>9</volume><issue>3</issue><fpage>760</fpage><lpage>771</lpage><comment>
<ext-link xlink:href="https://www.mdpi.com/resolver?pii=ijerph9030760" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.3390/ijerph9030760</pub-id><pub-id pub-id-type="medline">22690161</pub-id><pub-id pub-id-type="pii">ijerph9030760</pub-id><!--<pub-id pub-id-type="pmcid">PMC3367275</pub-id>--><pub-id pub-id-type="pmid">22690161</pub-id>
</element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hawton</surname><given-names>K</given-names></name><name><surname>van Heeringen</surname><given-names>K</given-names></name></person-group><source>The International Handbook of Suicide and Attempted Suicide (1st ed)</source><year>2002</year><publisher-loc>Hoboken, NJ</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shioiri</surname><given-names>T</given-names></name><name><surname>Nishimura</surname><given-names>A</given-names></name><name><surname>Akazawa</surname><given-names>K</given-names></name><name><surname>Abe</surname><given-names>R</given-names></name><name><surname>Nushida</surname><given-names>H</given-names></name><name><surname>Ueno</surname><given-names>Y</given-names></name><name><surname>Kojika-Maruyama</surname><given-names>M</given-names></name><name><surname>Someya</surname><given-names>T</given-names></name></person-group><article-title>Incidence of note-leaving remains constant despite increasing suicide rates</article-title><source>Psychiatry Clin Neurosci</source><year>2005</year><month>04</month><day>24</day><volume>59</volume><issue>2</issue><fpage>226</fpage><lpage>228</lpage><comment>
<ext-link xlink:href="https://onlinelibrary.wiley.com/doi/10.1111/j.1440-1819.2005.01364.x" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1111/j.1440-1819.2005.01364.x</pub-id><pub-id pub-id-type="medline">15823174</pub-id><pub-id pub-id-type="pii">PCN1364</pub-id><pub-id pub-id-type="pmid">15823174</pub-id>
</element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>T</given-names></name></person-group><article-title>Suicide note themes and suicide prevention</article-title><source>Int J Psychiatry Med</source><year>2003</year><month>12</month><day>01</day><volume>33</volume><issue>4</issue><fpage>323</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.2190/t210-e2v5-a5m0-qlju</pub-id><pub-id pub-id-type="pmid">15152783</pub-id>
</element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>K</given-names></name><name><surname>Cheng</surname><given-names>Q</given-names></name><name><surname>Wong</surname><given-names>PWC</given-names></name><name><surname>Yip</surname><given-names>PSF</given-names></name></person-group><article-title>Responses to a self-presented suicide attempt in social media: a social network analysis</article-title><source>Crisis</source><year>2013</year><month>01</month><day>01</day><volume>34</volume><issue>6</issue><fpage>406</fpage><lpage>412</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/23871954" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1027/0227-5910/a000221</pub-id><pub-id pub-id-type="medline">23871954</pub-id><pub-id pub-id-type="pii">20104237L7747922</pub-id><!--<pub-id pub-id-type="pmcid">PMC4119817</pub-id>--><pub-id pub-id-type="pmid">23871954</pub-id>
</element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jashinsky</surname><given-names>J</given-names></name><name><surname>Burton</surname><given-names>SH</given-names></name><name><surname>Hanson</surname><given-names>CL</given-names></name><name><surname>West</surname><given-names>J</given-names></name><name><surname>Giraud-Carrier</surname><given-names>C</given-names></name><name><surname>Barnes</surname><given-names>MD</given-names></name><name><surname>Argyle</surname><given-names>T</given-names></name></person-group><article-title>Tracking suicide risk factors through Twitter in the US</article-title><source>Crisis</source><year>2014</year><month>01</month><day>01</day><volume>35</volume><issue>1</issue><fpage>51</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1027/0227-5910/a000234</pub-id><pub-id pub-id-type="medline">24121153</pub-id><pub-id pub-id-type="pii">334K5X21L0436430</pub-id><pub-id pub-id-type="pmid">24121153</pub-id>
</element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahuja</surname><given-names>A</given-names></name><name><surname>Biesaga</surname><given-names>K</given-names></name><name><surname>Sudak</surname><given-names>D</given-names></name><name><surname>Draper</surname><given-names>J</given-names></name><name><surname>Womble</surname><given-names>A</given-names></name></person-group><article-title>Suicide on Facebook</article-title><source>J Psychiatr Pract</source><year>2014</year><month>03</month><volume>20</volume><issue>2</issue><fpage>141</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1097/01.pra.0000445249.38801.d1</pub-id><pub-id pub-id-type="medline">24638049</pub-id><pub-id pub-id-type="pii">00131746-201403000-00008</pub-id><pub-id pub-id-type="pmid">24638049</pub-id>
</element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khanday</surname><given-names>AMUD</given-names></name><name><surname>Rabani</surname><given-names>ST</given-names></name><name><surname>Khan</surname><given-names>QR</given-names></name><name><surname>Rouf</surname><given-names>N</given-names></name><name><surname>Mohi Ud Din</surname><given-names>M</given-names></name></person-group><article-title>Machine learning based approaches for detecting COVID-19 using clinical text data</article-title><source>Int J Inf Technol</source><year>2020</year><month>06</month><day>30</day><volume>12</volume><issue>3</issue><fpage>731</fpage><lpage>739</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/32838125" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1007/s41870-020-00495-9</pub-id><pub-id pub-id-type="medline">32838125</pub-id><pub-id pub-id-type="pii">495</pub-id><!--<pub-id pub-id-type="pmcid">PMC7325639</pub-id>--><pub-id pub-id-type="pmid">32838125</pub-id>
</element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="webpage"><article-title>Home</article-title><source>American Foundation for Suicide Prevention</source><date-in-citation content-type="access-date">2024-12-30</date-in-citation><comment>
<ext-link xlink:href="https://afsp.org/" ext-link-type="uri">https://afsp.org/</ext-link>
</comment></element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="webpage"><source>Suicide Prevention Now</source><date-in-citation content-type="access-date">2024-12-30</date-in-citation><comment>
<ext-link xlink:href="https://suicidepreventionnow.org/" ext-link-type="uri">https://suicidepreventionnow.org/</ext-link>
</comment></element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cash</surname><given-names>SJ</given-names></name><name><surname>Thelwall</surname><given-names>M</given-names></name><name><surname>Peck</surname><given-names>SN</given-names></name><name><surname>Ferrell</surname><given-names>JZ</given-names></name><name><surname>Bridge</surname><given-names>JA</given-names></name></person-group><article-title>Adolescent suicide statements on MySpace</article-title><source>Cyberpsychol Behav Soc Netw</source><year>2013</year><month>03</month><volume>16</volume><issue>3</issue><fpage>166</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1089/cyber.2012.0098</pub-id><pub-id pub-id-type="medline">23374167</pub-id><pub-id pub-id-type="pmid">23374167</pub-id>
</element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Dea</surname><given-names>B</given-names></name><name><surname>Larsen</surname><given-names>ME</given-names></name><name><surname>Batterham</surname><given-names>PJ</given-names></name><name><surname>Calear</surname><given-names>AL</given-names></name><name><surname>Christensen</surname><given-names>H</given-names></name></person-group><article-title>A linguistic analysis of suicide-related Twitter posts</article-title><source>Crisis</source><year>2017</year><month>09</month><volume>38</volume><issue>5</issue><fpage>319</fpage><lpage>329</lpage><pub-id pub-id-type="doi">10.1027/0227-5910/a000443</pub-id><pub-id pub-id-type="medline">28228065</pub-id><pub-id pub-id-type="pmid">28228065</pub-id>
</element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KM</given-names></name><name><surname>McLean</surname><given-names>JP</given-names></name><name><surname>Sheffield</surname><given-names>J</given-names></name></person-group><article-title>Suicidal and online: how do online behaviors inform us of this high-risk population?</article-title><source>Death Stud</source><year>2014</year><month>10</month><day>18</day><volume>38</volume><issue>6-10</issue><fpage>387</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1080/07481187.2013.768313</pub-id><pub-id pub-id-type="medline">24666145</pub-id><pub-id pub-id-type="pmid">24666145</pub-id>
</element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>De Choudhury</surname><given-names>M</given-names></name><name><surname>Gamon</surname><given-names>M</given-names></name><name><surname>Counts</surname><given-names>S</given-names></name><name><surname>Horvitz</surname><given-names>E</given-names></name></person-group><article-title>Predicting depression via social media</article-title><year>2021</year><conf-name>ICWSM-13: Seventh International AAAI Conference on Weblogs and Social Media</conf-name><conf-date>July 8-11, 2013</conf-date><conf-loc>Cambridge, MA</conf-loc><fpage>128</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1609/icwsm.v7i1.14432</pub-id></element-citation></ref><ref id="ref17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colombo</surname><given-names>GB</given-names></name><name><surname>Burnap</surname><given-names>P</given-names></name><name><surname>Hodorog</surname><given-names>A</given-names></name><name><surname>Scourfield</surname><given-names>J</given-names></name></person-group><article-title>Analysing the connectivity and communication of suicidal users on Twitter</article-title><source>Comput Commun</source><year>2016</year><month>01</month><day>01</day><volume>73</volume><issue>Pt B</issue><fpage>291</fpage><lpage>300</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/26973360" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.comcom.2015.07.018</pub-id><pub-id pub-id-type="medline">26973360</pub-id><pub-id pub-id-type="pii">S0140-3664(15)00256-X</pub-id><!--<pub-id pub-id-type="pmcid">PMC4784725</pub-id>--><pub-id pub-id-type="pmid">26973360</pub-id>
</element-citation></ref><ref id="ref18"><label>18</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Chiu</surname><given-names>D</given-names></name><name><surname>Liu</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Zhu</surname><given-names>T</given-names></name></person-group><article-title>Detecting suicidal ideation in Chinese microblogs with psychological lexicons</article-title><year>2014</year><conf-name>IEEE 11th International Conference on Ubiquitous Intelligence and Computing, IEEE 11th International Conference on Autonomic and Trusted Computing, and IEEE 14th International Conference on Scalable Computing and Communications and Its Associated Workshops</conf-name><conf-date>December 9-12, 2014</conf-date><conf-loc>Bali, Indonesia</conf-loc><pub-id pub-id-type="doi">10.1109/uic-atc-scalcom.2014.48</pub-id></element-citation></ref><ref id="ref19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Dea</surname><given-names>B</given-names></name><name><surname>Wan</surname><given-names>S</given-names></name><name><surname>Batterham</surname><given-names>PJ</given-names></name><name><surname>Calear</surname><given-names>AL</given-names></name><name><surname>Paris</surname><given-names>C</given-names></name><name><surname>Christensen</surname><given-names>H</given-names></name></person-group><article-title>Detecting suicidality on Twitter</article-title><source>Internet Interven</source><year>2015</year><month>05</month><volume>2</volume><issue>2</issue><fpage>183</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1016/j.invent.2015.03.005</pub-id></element-citation></ref><ref id="ref20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vioules</surname><given-names>MJ</given-names></name><name><surname>Moulahi</surname><given-names>B</given-names></name><name><surname>Aze</surname><given-names>J</given-names></name><name><surname>Bringay</surname><given-names>S</given-names></name></person-group><article-title>Detection of suicide-related posts in Twitter data streams</article-title><source>IBM J Res Dev</source><year>2018</year><month>1</month><day>1</day><volume>62</volume><issue>1</issue><fpage>7:1</fpage><lpage>7:12</lpage><pub-id pub-id-type="doi">10.1147/jrd.2017.2768678</pub-id></element-citation></ref><ref id="ref21"><label>21</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Noureen</surname><given-names>A</given-names></name><name><surname>Qamar</surname><given-names>U</given-names></name><name><surname>Ali</surname><given-names>M</given-names></name></person-group><article-title>Semantic analysis of social media and associated psychotic behavior</article-title><year>2017</year><conf-name>IEEE 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)</conf-name><conf-date>July 29-31, 2017</conf-date><conf-loc>Guilin, China</conf-loc><pub-id pub-id-type="doi">10.1109/fskd.2017.8393009</pub-id></element-citation></ref><ref id="ref22"><label>22</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chiroma</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Cocea</surname><given-names>M</given-names></name></person-group><article-title>Text classification for suicide-related tweets</article-title><year>2018</year><conf-name>IEEE 2018 International Conference on Machine Learning and Cybernetics (ICMLC)</conf-name><conf-date>July 15-18, 2018</conf-date><conf-loc>Chengdu, China</conf-loc><pub-id pub-id-type="doi">10.1109/icmlc.2018.8527039</pub-id></element-citation></ref><ref id="ref23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burnap</surname><given-names>P</given-names></name><name><surname>Colombo</surname><given-names>G</given-names></name><name><surname>Amery</surname><given-names>R</given-names></name><name><surname>Hodorog</surname><given-names>A</given-names></name><name><surname>Scourfield</surname><given-names>J</given-names></name></person-group><article-title>Multi-class machine classification of suicide-related communication on Twitter</article-title><source>Online Soc Netw Media</source><year>2017</year><month>08</month><volume>2</volume><fpage>32</fpage><lpage>44</lpage><comment>
<ext-link xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S2468-6964(17)30060-5" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.osnem.2017.08.001</pub-id><pub-id pub-id-type="medline">29278258</pub-id><pub-id pub-id-type="pii">S2468-6964(17)30060-5</pub-id><!--<pub-id pub-id-type="pmcid">PMC5732584</pub-id>--><pub-id pub-id-type="pmid">29278258</pub-id>
</element-citation></ref><ref id="ref24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno</surname><given-names>MA</given-names></name><name><surname>Jelenchick</surname><given-names>LA</given-names></name><name><surname>Egan</surname><given-names>KG</given-names></name><name><surname>Cox</surname><given-names>E</given-names></name><name><surname>Young</surname><given-names>H</given-names></name><name><surname>Gannon</surname><given-names>KE</given-names></name><name><surname>Becker</surname><given-names>T</given-names></name></person-group><article-title>Feeling bad on Facebook: depression disclosures by college students on a social networking site</article-title><source>Depress Anxiety</source><year>2011</year><month>06</month><day>11</day><volume>28</volume><issue>6</issue><fpage>447</fpage><lpage>455</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/21400639" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1002/da.20805</pub-id><pub-id pub-id-type="medline">21400639</pub-id><!--<pub-id pub-id-type="pmcid">PMC3110617</pub-id>--><pub-id pub-id-type="pmid">21400639</pub-id>
</element-citation></ref><ref id="ref25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chadha</surname><given-names>A</given-names></name><name><surname>Kaushik</surname><given-names>B</given-names></name></person-group><article-title>A survey on prediction of suicidal ideation using machine and ensemble learning</article-title><source>Comput J</source><year>2021</year><volume>64</volume><issue>11</issue><fpage>1617</fpage><lpage>1632</lpage><pub-id pub-id-type="doi">10.1093/comjnl/bxz120</pub-id></element-citation></ref><ref id="ref26"><label>26</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sawhney</surname><given-names>R</given-names></name><name><surname>Manchanda</surname><given-names>P</given-names></name><name><surname>Singh</surname><given-names>R</given-names></name><name><surname>Aggarwal</surname><given-names>S</given-names></name></person-group><article-title>A computational approach to feature extraction for identification of suicidal ideation in tweets</article-title><year>2018</year><conf-name>ACL 2018, Student Research Workshop</conf-name><conf-date>July 15-20, 2018</conf-date><conf-loc>Melbourne, Australia</conf-loc><fpage>91</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.18653/v1/p18-3013</pub-id></element-citation></ref><ref id="ref27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Weng</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><article-title>Feature selection for text classification: a review</article-title><source>Multimed Tools Appl</source><year>2018</year><month>5</month><day>8</day><volume>78</volume><issue>3</issue><fpage>3797</fpage><lpage>3816</lpage><pub-id pub-id-type="doi">10.1007/s11042-018-6083-5</pub-id></element-citation></ref><ref id="ref28"><label>28</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Qu</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Zou</surname><given-names>Y</given-names></name></person-group><article-title>Improvement of text feature selection method based on TF-IDF</article-title><year>2008</year><conf-name>IEEE 2008 International Seminar on Future Information Technology and Management Engineering</conf-name><conf-date>November 20, 2008</conf-date><conf-loc>Leicestershire, UK</conf-loc><fpage>79</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1109/fitme.2008.25</pub-id></element-citation></ref><ref id="ref29"><label>29</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name></person-group><article-title>Using Word2Vec to process big text data</article-title><year>2015</year><conf-name>IEEE 2015 International Conference on Big Data</conf-name><conf-date>October 29-November 1, 2015</conf-date><conf-loc>Santa Clara, CA</conf-loc><pub-id pub-id-type="doi">10.1109/bigdata.2015.7364114</pub-id></element-citation></ref><ref id="ref30"><label>30</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Agustian</surname><given-names>S</given-names></name><name><surname>Saputra</surname><given-names>R</given-names></name><name><surname>Fadhilah</surname><given-names>A</given-names></name></person-group><article-title>Feature selection with pretrained-BERT for hate speech and offensive content identification in English and Hindi languages</article-title><year>2021</year><conf-name>Forum for Information Retrieval Evaluation</conf-name><conf-date>December 13-17, 2021</conf-date><conf-loc>Gandhinagar, Gujarat, India</conf-loc><fpage>508</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.13140/RG.2.2.27831.60324</pub-id></element-citation></ref><ref id="ref31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hossain</surname><given-names>MR</given-names></name><name><surname>Hoque</surname><given-names>MM</given-names></name><name><surname>Siddique</surname><given-names>N</given-names></name><name><surname>Dewan</surname><given-names>MAA</given-names></name></person-group><article-title>AraCovTexFinder: leveraging the transformer-based language model for Arabic COVID-19 text identification</article-title><source>Eng Appl Arti Intell</source><year>2024</year><month>07</month><volume>133</volume><fpage>107987</fpage><pub-id pub-id-type="doi">10.1016/j.engappai.2024.107987</pub-id></element-citation></ref><ref id="ref32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hossain</surname><given-names>MR</given-names></name><name><surname>Hoque</surname><given-names>MM</given-names></name><name><surname>Siddique</surname><given-names>N</given-names></name><name><surname>Sarker</surname><given-names>IH</given-names></name></person-group><article-title>CovTiNet: Covid text identification network using attention-based positional embedding feature fusion</article-title><source>Neural Comput Appl</source><year>2023</year><month>03</month><day>14</day><volume>35</volume><issue>18</issue><fpage>13503</fpage><lpage>13527</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/37213320" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1007/s00521-023-08442-y</pub-id><pub-id pub-id-type="medline">37213320</pub-id><pub-id pub-id-type="pii">8442</pub-id><!--<pub-id pub-id-type="pmcid">PMC10011801</pub-id>--><pub-id pub-id-type="pmid">37213320</pub-id>
</element-citation></ref><ref id="ref33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>CP</given-names></name><name><surname>Fung</surname><given-names>S</given-names></name><name><surname>Pan</surname><given-names>S</given-names></name><name><surname>Long</surname><given-names>G</given-names></name></person-group><article-title>Supervised learning for suicidal ideation detection in online user content</article-title><source>Complexity</source><year>2018</year><month>09</month><day>09</day><volume>2018</volume><issue>1</issue><fpage>6157249</fpage><pub-id pub-id-type="doi">10.1155/2018/6157249</pub-id></element-citation></ref><ref id="ref34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>P</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Xiao</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Zhao</surname><given-names>W</given-names></name><name><surname>Hou</surname><given-names>S</given-names></name><name><surname>Wu</surname><given-names>D</given-names></name><name><surname>Ma</surname><given-names>Y</given-names></name><name><surname>Xiao</surname><given-names>J</given-names></name></person-group><article-title>Development and validation of an explainable deep learning model to predict in-hospital mortality for patients with acute myocardial infarction: algorithm development and validation study</article-title><source>J Med Internet Res</source><year>2024</year><month>05</month><day>10</day><volume>26</volume><fpage>e49848</fpage><comment>
<ext-link xlink:href="https://www.jmir.org/2024//e49848/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/49848</pub-id><pub-id pub-id-type="medline">38728685</pub-id><pub-id pub-id-type="pii">v26i1e49848</pub-id><!--<pub-id pub-id-type="pmcid">PMC11127140</pub-id>--><pub-id pub-id-type="pmid">38728685</pub-id>
</element-citation></ref><ref id="ref35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Lyu</surname><given-names>J</given-names></name><name><surname>Guo</surname><given-names>J</given-names></name><name><surname>Bao</surname><given-names>S</given-names></name><name><surname>Cheng</surname><given-names>Y</given-names></name><name><surname>Niu</surname><given-names>X</given-names></name><name><surname>Yang</surname><given-names>L</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Chi</surname><given-names>F</given-names></name><name><surname>Liang</surname><given-names>B</given-names></name><name><surname>Ren</surname><given-names>D</given-names></name></person-group><article-title>A 3D and explainable artificial intelligence model for evaluation of chronic otitis media based on temporal bone computed tomography: model development, validation, and clinical application</article-title><source>J Med Internet Res</source><year>2024</year><month>08</month><day>08</day><volume>26</volume><fpage>e51706</fpage><comment>
<ext-link xlink:href="https://www.jmir.org/2024//e51706/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/51706</pub-id><pub-id pub-id-type="medline">39116439</pub-id><pub-id pub-id-type="pii">v26i1e51706</pub-id><!--<pub-id pub-id-type="pmcid">PMC11342006</pub-id>--><pub-id pub-id-type="pmid">39116439</pub-id>
</element-citation></ref><ref id="ref36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Glaz</surname><given-names>A</given-names></name><name><surname>Haralambous</surname><given-names>Y</given-names></name><name><surname>Kim-Dufor</surname><given-names>D</given-names></name><name><surname>Lenca</surname><given-names>P</given-names></name><name><surname>Billot</surname><given-names>R</given-names></name><name><surname>Ryan</surname><given-names>TC</given-names></name><name><surname>Marsh</surname><given-names>J</given-names></name><name><surname>DeVylder</surname><given-names>J</given-names></name><name><surname>Walter</surname><given-names>M</given-names></name><name><surname>Berrouiguet</surname><given-names>S</given-names></name><name><surname>Lemey</surname><given-names>C</given-names></name></person-group><article-title>Machine learning and natural language processing in mental health: systematic review</article-title><source>J Med Internet Res</source><year>2021</year><month>05</month><day>04</day><volume>23</volume><issue>5</issue><fpage>e15708</fpage><comment>
<ext-link xlink:href="https://www.jmir.org/2021/5/e15708/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/15708</pub-id><pub-id pub-id-type="medline">33944788</pub-id><pub-id pub-id-type="pii">v23i5e15708</pub-id><!--<pub-id pub-id-type="pmcid">PMC8132982</pub-id>--><pub-id pub-id-type="pmid">33944788</pub-id>
</element-citation></ref><ref id="ref37"><label>37</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Gholamy</surname><given-names>A</given-names></name><name><surname>Kreinovich</surname><given-names>V</given-names></name><name><surname>Kosheleva</surname><given-names>O</given-names></name></person-group><article-title>Why 70/30 or 80/20 relation between training and testing sets: a pedagogical explanation</article-title><source>University of Texas at El Paso</source><year>2018</year><date-in-citation content-type="access-date">2024-12-30</date-in-citation><comment>
<ext-link xlink:href="https://www.cs.utep.edu/vladik/2018/tr18-09.pdf" ext-link-type="uri">https://www.cs.utep.edu/vladik/2018/tr18-09.pdf</ext-link>
</comment></element-citation></ref><ref id="ref38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>JS</given-names></name><name><surname>Park</surname><given-names>SJ</given-names></name><name><surname>Kim</surname><given-names>EY</given-names></name><name><surname>Na</surname><given-names>K</given-names></name><name><surname>Kim</surname><given-names>YJ</given-names></name><name><surname>Kim</surname><given-names>KG</given-names></name></person-group><article-title>Prediction models for high risk of suicide in Korean adolescents using machine learning techniques</article-title><source>PLoS One</source><year>2019</year><month>6</month><day>6</day><volume>14</volume><issue>6</issue><fpage>e0217639</fpage><comment>
<ext-link xlink:href="https://dx.plos.org/10.1371/journal.pone.0217639" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1371/journal.pone.0217639</pub-id><pub-id pub-id-type="medline">31170212</pub-id><pub-id pub-id-type="pii">PONE-D-19-00940</pub-id><!--<pub-id pub-id-type="pmcid">PMC6553749</pub-id>--><pub-id pub-id-type="pmid">31170212</pub-id>
</element-citation></ref><ref id="ref39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saba</surname><given-names>T</given-names></name><name><surname>Khan</surname><given-names>AR</given-names></name><name><surname>Abunadi</surname><given-names>I</given-names></name><name><surname>Bahaj</surname><given-names>SA</given-names></name><name><surname>Ali</surname><given-names>H</given-names></name><name><surname>Alruwaythi</surname><given-names>M</given-names></name></person-group><article-title>Arabic speech analysis for classification and prediction of mental illness due to depression using deep learning</article-title><source>Comput Intell Neurosci</source><year>2022</year><month>5</month><day>27</day><volume>2022</volume><fpage>8622022</fpage><lpage>9</lpage><comment>
<ext-link xlink:href="https://doi.org/10.1155/2022/8622022" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1155/2022/8622022</pub-id><pub-id pub-id-type="medline">35669665</pub-id><!--<pub-id pub-id-type="pmcid">PMC9166990</pub-id>--><pub-id pub-id-type="pmid">35669665</pub-id>
</element-citation></ref></ref-list></back></article>