<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006251</article-id><article-id pub-id-type="pmc">PMC11859317</article-id><article-id pub-id-type="doi">10.3390/s25041022</article-id><article-id pub-id-type="publisher-id">sensors-25-01022</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Real-Time Fish Detection System for Partially Dewatered Fish to Support Selective Fish Passage</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0003-5958-9438</contrib-id><name><surname>Gregory</surname><given-names>Jonathan</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af1-sensors-25-01022" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5546-1854</contrib-id><name><surname>Miehls</surname><given-names>Scott M.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af2-sensors-25-01022" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Eickholt</surname><given-names>Jesse L.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af1-sensors-25-01022" ref-type="aff">1</xref><xref rid="c1-sensors-25-01022" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8113-9861</contrib-id><name><surname>Zielinski</surname><given-names>Daniel P.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="af3-sensors-25-01022" ref-type="aff">3</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Bouguila</surname><given-names>Nizar</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01022"><label>1</label>Department of Computer Science, Central Michigan University, Mount Pleasant, MI 48859, USA; <email>grego3j@cmich.edu</email></aff><aff id="af2-sensors-25-01022"><label>2</label>U.S. Geological Survey, Great Lakes Science Center, Hammond Bay Biological Station, Millersburg, MI 49759, USA; <email>smiehls@usgs.gov</email></aff><aff id="af3-sensors-25-01022"><label>3</label>Great Lakes Fishery Commission, Ann Arbor, MI 48105, USA; <email>dzielinski@glfc.org</email></aff><author-notes><corresp id="c1-sensors-25-01022"><label>*</label>Correspondence: <email>eickh1jl@cmich.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>09</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1022</elocation-id><history><date date-type="received"><day>15</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>20</day><month>1</month><year>2025</year></date><date date-type="accepted"><day>04</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Recent advances in fish transportation technologies and deep machine learning-based fish classification have created an opportunity for real-time, autonomous fish sorting through a selective passage mechanism. This research presents a case study of a novel application that utilizes deep machine learning to detect partially dewatered fish exiting an Archimedes Screw Fish Lift (ASFL). A MobileNet SSD model was trained on images of partially dewatered fish volitionally passing through an ASFL. Then, this model was integrated with a network video recorder to monitor video from the ASFL. Additional models were also trained using images from a similar fish scanning device to test the feasibility of this approach for fish classification. Open source software and edge computing design principles were employed to ensure that the system is capable of fast data processing. The findings from this research demonstrate that such a system integrated with an ASFL can support real-time fish detection. This research contributes to the goal of automated data collection in a selective fish passage system and presents a viable path towards realizing optical fish sorting.</p></abstract><kwd-group><kwd>selective fish passage</kwd><kwd>object detection</kwd><kwd>edge computing</kwd><kwd>MobileNet SSD</kwd><kwd>real-time detection</kwd></kwd-group><funding-group><award-group><funding-source>Great Lakes Fishery Commission</funding-source><award-id>2023_MIE_541015</award-id></award-group><funding-statement>This work was funded by the Great Lakes Fishery Commission, grant number 2023_MIE_541015.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01022"><title>1. Introduction</title><p>The Laurentian Great Lakes and their tributaries are an extremely important economic and ecological resource for the United States of America and Canada. Not only are the Great Lakes a unique part of the cultural and geographical heritage of North America, but they also support over 1.3 million regional jobs spanning from tourism to shipping that create over USD 82 billion in wages [<xref rid="B1-sensors-25-01022" ref-type="bibr">1</xref>]. One particularly important aspect of the Great Lakes is its fisheries, which generate billions of dollars annually from both commercial and recreational fishing [<xref rid="B1-sensors-25-01022" ref-type="bibr">1</xref>]. However, threats such as the spread of invasive species and habitat loss degrade the quality of the Great Lakes and their fisheries, making Great Lakes Restoration Initiatives important from both an environmental and an economic standpoint.</p><p>The Great Lakes Restoration Initiative (GLRI), a program by the U.S. federal government for investing in protecting and revitalizing the Great Lakes, identifies two focuses for improving the health of the Great Lakes related to fisheries: (1) controlling and eradicating invasive species and (2) improving habitats for native species, particularly by increasing connectivity for these habitats [<xref rid="B2-sensors-25-01022" ref-type="bibr">2</xref>]. These two goals can be in conflict, as connecting aquatic habitats that were previously separated by artificial barriers such as dams may have the unintended consequence of allowing non-native species access to pristine habitats [<xref rid="B3-sensors-25-01022" ref-type="bibr">3</xref>]. It is therefore necessary for fishery managers to balance the desire for increased connectivity of waterways against the threats posed by non-native or invasive species, a trade-off that has been a subject of much research in recent years [<xref rid="B4-sensors-25-01022" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-01022" ref-type="bibr">5</xref>]. Selective connectivity has emerged as a class of physical, chemical, and mechanical methods to support the movement of native fishes around artificial barriers while also preventing uncontrolled passage of non-native species [<xref rid="B3-sensors-25-01022" ref-type="bibr">3</xref>,<xref rid="B6-sensors-25-01022" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-01022" ref-type="bibr">7</xref>,<xref rid="B8-sensors-25-01022" ref-type="bibr">8</xref>]. Thus, selective passage provides a solution to the &#x0201c;connectivity conundrum&#x0201d; of restoring connectivity within and between habitats of native fishes while also preventing the spread of invasive ones to protected waterways [<xref rid="B7-sensors-25-01022" ref-type="bibr">7</xref>].</p><p>Traditionally, manual trap-and-sort operations have been the only method to guarantee selective passage of desirable fish while blocking undesirable ones. This technique is not scalable and may be harmful to fish populations [<xref rid="B7-sensors-25-01022" ref-type="bibr">7</xref>]. Thus, the development of alternative methods to selectively pass fish is needed. At its core, a selective fish passage can be reduced to sort fish according to different behavioral, physiological, phenological, and morphological attributes, a task analogous to the process of single-stream recycling [<xref rid="B7-sensors-25-01022" ref-type="bibr">7</xref>]. The success of single-stream recycling is due in part to a shift away from manual sorting to automated processes, a trend that is expected to equally benefit selective fish passages. Automating fish-sorting processes&#x02014;regardless of which sortable attribute they exploit&#x02014;should increase the applicability and availability of selective fish passage technologies to waterways across the Great Lakes&#x02019; region and beyond.</p><p>Sorting fish along morphological differences holds promise for selective passage due to the diversity of body shapes exhibited among fish species. Optical sorting technologies that pair image recognition software with mechanical sorting devices (i.e., operable gates or traps) offer the potential for automated sorting for fish passages. Underwater image-based tools have started to be incorporated into fish-counting devices [<xref rid="B9-sensors-25-01022" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-01022" ref-type="bibr">10</xref>]; however, underwater image recognition can be challenging due to poor illumination or high water turbidity [<xref rid="B11-sensors-25-01022" ref-type="bibr">11</xref>]. These issues can be avoided if fish are in a partially dewatered state. An Archimedes Screw Fish Lift (ASFL) offers a simple means to capture fish and lift them out of the water for imaging. Pilot tests in a fish crowding structure demonstrated that a prototype ASFL was effective at capturing and safely lifting sucker spp. [<xref rid="B12-sensors-25-01022" ref-type="bibr">12</xref>]. Combined with an optical scanner, an ASFL system has the possibility of conducting real-time, accurate fish detection and fish species classification [<xref rid="B12-sensors-25-01022" ref-type="bibr">12</xref>].</p><p>Image-based fish classification&#x02014;including classification that distinguishes fish from other objects (single-class) and classification that distinguishes between fish species (multi-class)&#x02014;is a well-researched domain in the realm of computer vision, with both traditional and deep machine learning approaches being applied to this problem [<xref rid="B11-sensors-25-01022" ref-type="bibr">11</xref>]. As summarized in a recent survey [<xref rid="B11-sensors-25-01022" ref-type="bibr">11</xref>], traditional machine learning approaches used for fish classification include Na&#x000ef;ve Bayesian classification [<xref rid="B13-sensors-25-01022" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-01022" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-01022" ref-type="bibr">15</xref>,<xref rid="B16-sensors-25-01022" ref-type="bibr">16</xref>], support vector machine classification [<xref rid="B17-sensors-25-01022" ref-type="bibr">17</xref>,<xref rid="B18-sensors-25-01022" ref-type="bibr">18</xref>,<xref rid="B19-sensors-25-01022" ref-type="bibr">19</xref>,<xref rid="B20-sensors-25-01022" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-01022" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-01022" ref-type="bibr">22</xref>,<xref rid="B23-sensors-25-01022" ref-type="bibr">23</xref>,<xref rid="B24-sensors-25-01022" ref-type="bibr">24</xref>,<xref rid="B25-sensors-25-01022" ref-type="bibr">25</xref>], and classification by shallow neural networks [<xref rid="B26-sensors-25-01022" ref-type="bibr">26</xref>,<xref rid="B27-sensors-25-01022" ref-type="bibr">27</xref>,<xref rid="B28-sensors-25-01022" ref-type="bibr">28</xref>]. These approaches achieve some success in terms of classification accuracy, but each method requires the data to be preprocessed and input as an engineered feature vector, which is not optimal for robust classification [<xref rid="B11-sensors-25-01022" ref-type="bibr">11</xref>].</p><p>Recently, deep machine learning has emerged as a popular and effective alternative to these traditional machine learning methods, especially in the realm of image classification. Deep machine learning is distinguished from traditional machine learning in that rather than being given curated feature vectors describing data, deep machine learning models learn a robust representation of the data by mapping inputs to outputs through many layers of a deep neural network [<xref rid="B29-sensors-25-01022" ref-type="bibr">29</xref>]. Deep convolutional neural networks (CNNs) are one type of deep machine learning architecture that uses mathematical filters to learn size- and location-invariant representations of objects in images, making CNNs useful for image classification and object detection [<xref rid="B29-sensors-25-01022" ref-type="bibr">29</xref>].</p><p>Many variations of well-known deep CNN architectures such as AlexNet [<xref rid="B30-sensors-25-01022" ref-type="bibr">30</xref>], DenseNet [<xref rid="B31-sensors-25-01022" ref-type="bibr">31</xref>], Inception [<xref rid="B32-sensors-25-01022" ref-type="bibr">32</xref>], MobileNet [<xref rid="B33-sensors-25-01022" ref-type="bibr">33</xref>], ResNet [<xref rid="B34-sensors-25-01022" ref-type="bibr">34</xref>], and VGG [<xref rid="B35-sensors-25-01022" ref-type="bibr">35</xref>] have been applied to the tasks of fish identification and fish species classification. Examples of these applications include training or fine-tuning versions of these architectures for the task of fish species classification [<xref rid="B36-sensors-25-01022" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-01022" ref-type="bibr">37</xref>,<xref rid="B38-sensors-25-01022" ref-type="bibr">38</xref>,<xref rid="B39-sensors-25-01022" ref-type="bibr">39</xref>] and modifying these architectures to create new deep machine learning fish classifiers [<xref rid="B40-sensors-25-01022" ref-type="bibr">40</xref>,<xref rid="B41-sensors-25-01022" ref-type="bibr">41</xref>,<xref rid="B42-sensors-25-01022" ref-type="bibr">42</xref>,<xref rid="B43-sensors-25-01022" ref-type="bibr">43</xref>,<xref rid="B44-sensors-25-01022" ref-type="bibr">44</xref>,<xref rid="B45-sensors-25-01022" ref-type="bibr">45</xref>,<xref rid="B46-sensors-25-01022" ref-type="bibr">46</xref>,<xref rid="B47-sensors-25-01022" ref-type="bibr">47</xref>,<xref rid="B48-sensors-25-01022" ref-type="bibr">48</xref>,<xref rid="B49-sensors-25-01022" ref-type="bibr">49</xref>,<xref rid="B50-sensors-25-01022" ref-type="bibr">50</xref>,<xref rid="B51-sensors-25-01022" ref-type="bibr">51</xref>,<xref rid="B52-sensors-25-01022" ref-type="bibr">52</xref>,<xref rid="B53-sensors-25-01022" ref-type="bibr">53</xref>]. Other researchers developed custom deep CNN architectures for fish classification [<xref rid="B54-sensors-25-01022" ref-type="bibr">54</xref>,<xref rid="B55-sensors-25-01022" ref-type="bibr">55</xref>,<xref rid="B56-sensors-25-01022" ref-type="bibr">56</xref>]. Many of these deep CNN classifiers achieved strong classification accuracy, indicating the power and utility of these model architectures.</p><p>Fish classification is useful in controlled settings where it is only necessary to identify a single fish in an image. For situations where multiple fish are likely to be present or where the localization of the fish in the image is needed, it is best to use object detection algorithms. Object detection combines object identification and localization by classifying objects within an image and drawing a bounding box around individual object instances [<xref rid="B57-sensors-25-01022" ref-type="bibr">57</xref>]. As with fish classification, many different object detection models have been applied extensively to the problem of fish detection. Commonly used models include the You Only Look Once (YOLO) [<xref rid="B58-sensors-25-01022" ref-type="bibr">58</xref>] family of single-shot object detectors&#x02014;especially the YOLOv3 [<xref rid="B59-sensors-25-01022" ref-type="bibr">59</xref>], YOLOv4 [<xref rid="B60-sensors-25-01022" ref-type="bibr">60</xref>], YOLOv5 [<xref rid="B61-sensors-25-01022" ref-type="bibr">61</xref>], and YOLOv7 [<xref rid="B62-sensors-25-01022" ref-type="bibr">62</xref>] model architectures&#x02014;variants of the R-CNN two-stage object detector [<xref rid="B63-sensors-25-01022" ref-type="bibr">63</xref>], and various models built using a Single-Shot Multibox Detector (SSD) [<xref rid="B64-sensors-25-01022" ref-type="bibr">64</xref>]. Versions of these architectures have been applied to the following domains: single-class [<xref rid="B65-sensors-25-01022" ref-type="bibr">65</xref>,<xref rid="B66-sensors-25-01022" ref-type="bibr">66</xref>,<xref rid="B67-sensors-25-01022" ref-type="bibr">67</xref>,<xref rid="B68-sensors-25-01022" ref-type="bibr">68</xref>] and multi-class fish detection [<xref rid="B69-sensors-25-01022" ref-type="bibr">69</xref>,<xref rid="B70-sensors-25-01022" ref-type="bibr">70</xref>,<xref rid="B71-sensors-25-01022" ref-type="bibr">71</xref>,<xref rid="B72-sensors-25-01022" ref-type="bibr">72</xref>,<xref rid="B73-sensors-25-01022" ref-type="bibr">73</xref>]; fish detection using marine [<xref rid="B68-sensors-25-01022" ref-type="bibr">68</xref>,<xref rid="B69-sensors-25-01022" ref-type="bibr">69</xref>,<xref rid="B72-sensors-25-01022" ref-type="bibr">72</xref>,<xref rid="B74-sensors-25-01022" ref-type="bibr">74</xref>] and aquatic [<xref rid="B65-sensors-25-01022" ref-type="bibr">65</xref>,<xref rid="B66-sensors-25-01022" ref-type="bibr">66</xref>,<xref rid="B70-sensors-25-01022" ref-type="bibr">70</xref>,<xref rid="B71-sensors-25-01022" ref-type="bibr">71</xref>,<xref rid="B75-sensors-25-01022" ref-type="bibr">75</xref>] fish datasets; and detection of both watered [<xref rid="B65-sensors-25-01022" ref-type="bibr">65</xref>,<xref rid="B66-sensors-25-01022" ref-type="bibr">66</xref>,<xref rid="B67-sensors-25-01022" ref-type="bibr">67</xref>,<xref rid="B68-sensors-25-01022" ref-type="bibr">68</xref>,<xref rid="B71-sensors-25-01022" ref-type="bibr">71</xref>,<xref rid="B72-sensors-25-01022" ref-type="bibr">72</xref>,<xref rid="B76-sensors-25-01022" ref-type="bibr">76</xref>] and fully or partially dewatered fish [<xref rid="B70-sensors-25-01022" ref-type="bibr">70</xref>,<xref rid="B77-sensors-25-01022" ref-type="bibr">77</xref>,<xref rid="B78-sensors-25-01022" ref-type="bibr">78</xref>]. Although issues related to image quality and class imbalance were common themes in these studies, the abundance of high-performing fish detection models that operate on different domains demonstrates the power and applicability of these deep machine learning architectures to tasks such as fine-grained optical fish sorting and continuous data collection.</p><p>Far less research has been applied to using computer vision and deep machine learning algorithms in a selective passage system. Garavelli et al. [<xref rid="B79-sensors-25-01022" ref-type="bibr">79</xref>] used an optical sorting system to control the passage of salmon based on fish size as estimated by an image-based algorithm, but this research makes no mention of using deep machine learning to assist with this process. Eickholt et al. [<xref rid="B40-sensors-25-01022" ref-type="bibr">40</xref>] demonstrated that a VGG-based deep CNN could classify images of the Great Lakes&#x02019; fish species that were partially dewatered and passed through a Whooshh FishL&#x02122; Recognition optical scanner with an accuracy of 95%. This deep machine learning classifier could distinguish sea lamprey&#x02014;an invasive, parasitic fish whose presence in the Great Lakes motivates selective fish passage efforts by the Great Lakes Fishery Commission (GLFC) [<xref rid="B80-sensors-25-01022" ref-type="bibr">80</xref>]&#x02014;from other Great Lakes&#x02019; fish with nearly 100% accuracy [<xref rid="B40-sensors-25-01022" ref-type="bibr">40</xref>]. However, these authors remarked that this classifier was not tested for real-time fish species classification, and their model was not run using hardware that can be deployed for on-site analysis [<xref rid="B40-sensors-25-01022" ref-type="bibr">40</xref>]. Jagadeesan et al. [<xref rid="B81-sensors-25-01022" ref-type="bibr">81</xref>] investigated using edge computing to allow for real-time, on-location fish detection to monitor unintended fish passage over a river weir. Edge computing is a computing paradigm where data processing occurs at or close to the site of data collection, allowing for less latency and immediate, automated responses to triggers [<xref rid="B82-sensors-25-01022" ref-type="bibr">82</xref>]. Although Jagadeesan et al. did not discuss the applications of their system to fish sorting in a selective passage system, these researchers did present a hardware and software solution using edge computing that could be deployed for various tasks, including fish detection in a selective fish passage system and continuous data collection for fish in situ.</p><p>This research seeks to bridge the gap between past studies involving selective fish passage, autonomous fish detection, and edge computing by presenting a case study of a novel and lightweight platform that can support real-time, on-location fish detection for partially dewatered fish exiting a fish lift system. Specifically, this application uses Frigate [<xref rid="B83-sensors-25-01022" ref-type="bibr">83</xref>] network video recorder (NVR), a lightweight MobileNetv2 SSD FPN-Lite [<xref rid="B84-sensors-25-01022" ref-type="bibr">84</xref>] object detection model trained on a custom dataset, and a Coral Edge TPU USB accelerator to create a fully operational system to support real-time fish lift surveillance. This platform is based on freely available, open-source software and low-cost, commodity hardware. Applications of the platform include monitoring selective fish passage systems, collecting and filtering data from these systems, and alerting fisheries managers about fish-related events. This platform also includes an initial fish species detector that could eventually be used for fine-grained control in a selective fish passage system. This system is built with accessibility, maintainability, and scalability in mind for fishery managers, democratizing AI-assisted fishery surveillance and management even for individuals without specialized knowledge of machine learning. The data, data processing techniques, deep machine learning models, and deployable surveillance platform developed in this research advance progress towards a fully autonomous selective passage system.</p></sec><sec id="sec2-sensors-25-01022"><title>2. Materials and&#x000a0;Methods</title><sec id="sec2dot1-sensors-25-01022"><title>2.1. Study&#x000a0;Site</title><p>Video data used in this study were collected as part of a fish passage experiment conducted at the Michigan DNR salmon weir on Swan River, MI, from 23 April to 15 June 2024. Swan River is a small tributary to Lake Huron, near Rogers City, MI. The weir is located approximately 400 m upstream of the river mouth and comprises ten 1.8 m wide flow-through wire mesh screen panels.</p></sec><sec id="sec2dot2-sensors-25-01022"><title>2.2. Fish&#x000a0;Collection</title><p>A prototype fish lift consisting of an Archimedes Screw (described previously by Zielinski et al. [<xref rid="B12-sensors-25-01022" ref-type="bibr">12</xref>]) was installed at the weir and operated continuously throughout the study period. Fish captured by the lift were raised to approximately 1 m above the water. Upon exit from the upstream end of the ASFL, fish were passed over a dewatering slide made of 12 mm wide aluminum rails spaced 12 mm apart to shed most of the water before being passed through a lighted video chamber. After leaving the video chamber, the fish were captured in a 1.2 m &#x000d7; 1.2 m wire mesh holding cage. Captured fish were removed each morning at approximately 10:00 EST, identified to species, weighed, measured, and then released.</p></sec><sec id="sec2dot3-sensors-25-01022"><title>2.3. Video Data&#x000a0;Collection</title><p>The video chamber was monitored continuously via 4 cameras (8 megapixel, 2.8 mm super wide angle lens, model IP8M-T2599EW manufactured by Amcrest and made in Vietnam) positioned overhead (2 cameras) and at either side. <xref rid="sensors-25-01022-f001" ref-type="fig">Figure 1</xref> shows the view from each of these four cameras in the video chamber capturing a fish passing through from different angles. Frigate NVR version 0.12.0, a network video recorder used for surveillance and event detection, was used to capture and record the real-time streaming protocol (RTSP) video streams from all four cameras. Frigate ran on a micro factor computer with a Fedora Linux 36 operating system, a 4-core Intel Celeron J4125 CPU, and 8 GB DDR4 memory. Video captured by Frigate was saved to external solid-state hard drives.</p></sec><sec id="sec2dot4-sensors-25-01022"><title>2.4. Data&#x000a0;Curation</title><p>Clips of fish passing through the video chamber were extracted from the raw video recordings using heuristic-based video processing. A fast and simple background subtraction script was developed in Python version 3.9.19 using utilities from OpenCV [<xref rid="B85-sensors-25-01022" ref-type="bibr">85</xref>] and VidGear [<xref rid="B86-sensors-25-01022" ref-type="bibr">86</xref>] to process each video frame in less than 2 milliseconds. Background subtraction is a technique for motion detection where it is assumed that the background in a video sequence changes minimally between frames, therefore allowing moving objects to be detected as deviations from this static environment [<xref rid="B87-sensors-25-01022" ref-type="bibr">87</xref>]. A key benefit of the video capture chamber in the ASFL system is that it provides a relatively fixed backdrop, allowing a simple frame differencing approach coupled with a heuristically defined difference threshold to be used for motion detection.</p><p>This program initially yielded 120 clips across the four camera angles, resulting from 28 instances of fish passing through the ASFL video capture chamber. Subsequent analysis produced one more fish, contributing to a total of 29 fish across 124 clips. <xref rid="sensors-25-01022-t001" ref-type="table">Table 1</xref> shows the details for the fish captured and imaged by the ASFL system. The fish consist of eight species: eight common white suckers (<italic toggle="yes">Catostomus commersonii</italic>), seven steelhead (<italic toggle="yes">Oncorhynchus mykiss</italic>), seven longnose suckers (<italic toggle="yes">Catostomus catostomus</italic>), two largemouth bass (<italic toggle="yes">Micropterus salmoides</italic>), two smallmouth bass (<italic toggle="yes">Micropterus dolomieu</italic>), one rock bass (<italic toggle="yes">Ambloplites rupestris</italic>), one common carp (<italic toggle="yes">Cyprinus carpio</italic>), and one bowfin (<italic toggle="yes">Amia calva</italic>).</p><p>Frames containing a fish (that is, more than just a tail or fin) were extracted from the longer clips, resulting in 4040 images of fish. All frames were saved as 1920 &#x000d7; 1080 images. Initially, the first 1068 images of these fish were annotated by hand for a fish detection task by drawing a bounding box around the fish in the image and labeling the box with the label &#x0201c;Fish&#x0201d;. These 1068 images were experimentally considered a minimal number of fish to annotate that represented a varied sample of different fish passing through the video chamber. This manual annotation was performed using Label Studio [<xref rid="B88-sensors-25-01022" ref-type="bibr">88</xref>], an open source data annotation application. <xref rid="sensors-25-01022-f002" ref-type="fig">Figure 2</xref> shows an example of an image being annotated with this tool. The remaining 2972 images were annotated using a bootstrapping approach in which the initial 1068 annotations were used to train a machine learning annotation tool. This tool then produced annotations for the 2972 unannotated images, which were manually reviewed and re-annotated by hand if any of the annotations contained incorrect bounding boxes.</p><p>These data were extended for use in multi-class fish detection tasks by creating separate annotations that used the same bounding boxes as before but contained the individual species labels rather than simply the label &#x0201c;Fish&#x0201d;. Due to the limited number of fish from each species, this dataset from the ASFL best serves the goal of single-class fish detection. However, multi-class fish detection is possible with these data, albeit in a somewhat limited fashion.</p><p>For the generic fish detection dataset, denoted as ASFL-Single, only single-class labels (i.e., &#x0201c;Fish&#x0201d;) were used. The ASFL-Single training and independent evaluation data were determined using a random 80/20 split, respectively, of the entire dataset. These two sets are entirely discrete, meaning that no images of fish in the training set exist in the evaluation set. In total, the ASFL-Single training set contains 3276 annotations, and the evaluation set contains 764 annotations. The multi-class fish detection dataset developed for the ASFL system, denoted as ASFL-Multi, used the multi-class labels for each image (i.e., &#x0201c;common white sucker&#x0201d;, &#x0201c;longnose sucker&#x0201d;, etc.). Common carp, bowfin, and rock bass&#x02014;all species with fewer than two unique fish&#x02014;were removed from this dataset. For all remaining species of fish, each fish was randomly placed in the training or evaluation set according to an 80/20 split, with at least one fish from each species reserved for the test set. The ASFL-Multi training set contains 3183 annotations, and the evaluation set contains 594 annotations.</p><p>The ASFL-Multi dataset suffers from an insufficient number of unique fish from different species. Moreover, it lacks any examples of highly invasive species like sea lamprey (<italic toggle="yes">Petromyzon marinus</italic>) and bighead carp (<italic toggle="yes">Hypophthalmichthys nobilis</italic>). To further study the viability of using object detection for selective passage tasks, an additional dataset of partially dewatered fish from the USGS was curated. This USGS dataset is derived from images of fish passing through a Whooshh FishL&#x02122; Recognition optical scanner and contains numerous fish from a similar domain as the ASFL data [<xref rid="B40-sensors-25-01022" ref-type="bibr">40</xref>,<xref rid="B89-sensors-25-01022" ref-type="bibr">89</xref>]. This dataset contains over 5000 fish across 22 different fish species, including sea lamprey and invasive carp species [<xref rid="B89-sensors-25-01022" ref-type="bibr">89</xref>]. It should be noted that all invasive carp in this dataset were culled and then manually passed through the Whooshh scanner, whereas other species were alive while passing through the scanner. Further, all live fish captured by this scanner were manually introduced, rather than volitionally entering the scanning chamber [<xref rid="B40-sensors-25-01022" ref-type="bibr">40</xref>]. This manual intervention suggests that the fish in this dataset may have behaved differently from the fish in the ASFL dataset, which did not experience human intervention.</p><p>Fish in this USGS dataset were matched to their species labels and annotated with bounding boxes using a machine learning annotation tool bootstrapped with data from the ASFL-Single dataset. All annotations were manually reviewed, and unfit annotations were removed from the dataset. Species with fewer than 5 unique fish were also removed from the data. This process yielded a total of 9510 annotated images spanning 14 species, as shown in <xref rid="sensors-25-01022-t002" ref-type="table">Table 2</xref>. These annotations were then randomly split using an 80/20 training and evaluation split. As before, special care was taken to ensure that the training and evaluation sets contain no overlap between unique fish. The resulting dataset, called USGS-Multi, contains 7611 training annotations and 1899 evaluation annotations. Each set contains at least one unique fish from each of the species listed in <xref rid="sensors-25-01022-t002" ref-type="table">Table 2</xref>.</p><p>One final dataset, Combined-Multi, was created as a combination of the ASFL-Multi and USGS-Multi training and evaluation subsets. Since common carp are represented in the USGS-Multi training data, the frames of the single common carp from the ASFL data were added to the Combined-Multi evaluation data. Additionally, to mitigate data imbalance, only one sample of each individual fish from the USGS-Multi dataset was added to the training and evaluation sets of Combined-Multi. In total, Combined-Multi contains 7254 training samples and 1357 testing samples. A table summarizing the four datasets created in this research is given in <xref rid="sensors-25-01022-t003" ref-type="table">Table 3</xref>.</p></sec><sec id="sec2dot5-sensors-25-01022"><title>2.5. Development&#x000a0;Environment</title><p>The development environment used for model training and testing was a Len ovo Legion 5 Pro with an AMD Ryzen 7 5800h CPU, an NVIDIA RTX 3070 Mobile GPU with 8 GB of video RAM, and 32 GB of RAM. This system used Ubuntu 22.04.5 as an operating system with Python version 3.9, TensorFlow [<xref rid="B90-sensors-25-01022" ref-type="bibr">90</xref>] version 2.7, and CUDA version 12.4 installed. The TensorFlow Object Detection API [<xref rid="B91-sensors-25-01022" ref-type="bibr">91</xref>] was used to facilitate model training, fine-tuning, and evaluation.</p></sec><sec id="sec2dot6-sensors-25-01022"><title>2.6. Model&#x000a0;Construction</title><p>The base model architecture used in this research for lightweight detection was a MobileNetv2 SSD FPN-Lite 320 &#x000d7; 320 model (hereafter MobileNet SSD), which is supported by the TensorFlow Object Detection API for fast model prototyping and evaluation. MobileNet SSD achieves a benchmark of 22.2% mean average precision and can perform inference in 22 ms, which is equivalent to over 45 frames per second, making this model faster than real time [<xref rid="B92-sensors-25-01022" ref-type="bibr">92</xref>]. Moreover, the MobileNet SSD 320 &#x000d7; 320 model is easily configurable to run on the Frigate NVR system using a Coral tensor processing unit (TPU) for edge processing, making this model applicable for edge deployment scenarios. Newer object detection architectures exist, but MobileNet SSD fits the criteria set forth in this research that all components must be open source, easily modifiable, and integrable with minimal modifications with the other components of the fish capture and detection system&#x02014;namely the Frigate NVR and Coral TPU. It is important when discussing model selection that this research is primarily a case study showing the utility of this fish surveillance system, so this system must be examined as a whole, rather than a sum of parts. Other object detection architectures that are compatible with Frigate and the Coral TPU may be used, but MobileNet SSD is an effective &#x0201c;turnkey&#x0201d; object detection model for this proposed system, leading to its incorporation in this research.</p><p>The MobileNet SSD models trained in this research were configured with the same configuration and hyperparameters as the base MobileNetv2 SSD FPN-Lite 320 &#x000d7; 320 model from TensorFlow, which was pretrained on 320 &#x000d7; 320 images from the COCO 2017 dataset [<xref rid="B84-sensors-25-01022" ref-type="bibr">84</xref>]. Each model trained in this research was fine-tuned from the base model&#x02019;s detection checkpoint. This fine-tuning approach greatly reduced the amount of time and data necessary to train robust MobileNet SSD models.</p><p>All MobileNet SSD models in this study used momentum stochastic gradient descent (momentum SGD) as an optimizer with cosine decay learning rate scheduling, starting at a base learning rate of 0.08. This learning rate scheduler ensured that as training progressed, increasingly smaller updates were applied to the model, thus helping to mitigate the threat of the model overfitting over many training epochs. The classification loss used was sigmoid focal loss with parameters <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, and the localization loss used was smooth L1 loss. Both the box predictor and the underlying feature extractor used ReLU_6 activation functions. Lastly, all models were configured to train using the data augmentation strategies of random horizontal flipping and random cropping. Data augmentation regularizes a model and allows it to generalize better to unknown data by applying image transformation techniques to the training data. This generates new data that are in the same domain as the training data but have markedly different features. This also helps prevent overfitting, which is where a model learns to map its training data perfectly to the training labels but loses the ability to generalize to unseen data.</p></sec><sec id="sec2dot7-sensors-25-01022"><title>2.7. Model&#x000a0;Training</title><p>Four distinct models, termed ASFL-Single-Detect, ASFL-Multi-Detect, USGS-Multi-Detect, and Combined-Multi-Detect, were trained, with each one corresponding to one of the four datasets developed for this work. All models used 320 &#x000d7; 320 input sizes, meaning that images were resized during training to 320 &#x000d7; 320 before being sent through the detector. Loss metrics for the training data were logged to monitor the training progress. Moreover, validation data, a subset of the training data on which the model does not train, were evaluated at every 1000 epochs to monitor each model&#x02019;s performance on new data and track signs of overfitting. The number of epochs on which to train each of the four models was determined by monitoring each model&#x02019;s performance on these validation data. Owing to both the cosine decay learning rate scheduler and the carefully monitored loss data, no signs of overfitting were detected.</p></sec><sec id="sec2dot8-sensors-25-01022"><title>2.8. Model&#x000a0;Evaluation</title><p>Model evaluation was performed by running inference (i.e., generating predictions) on each model&#x02019;s respective independent evaluation dataset. In all cases, 0.4 was used as the confidence threshold by which a model would generate a prediction. The pycocotools version 2.0.7 Python library from the COCO API [<xref rid="B93-sensors-25-01022" ref-type="bibr">93</xref>] was then utilized to get statistics on each trained model&#x02019;s detection capabilities. Specifically, mAP50, or the mean average precision at an Intersection over Union of 50%, was used in this research as the main evaluation metric for object detection tasks.</p><p>Traditional precision and recall classification statistics, which only consider class labels and ignore the fitness of bounding boxes, were also calculated for every class in each model. In this research, these measurements give an indication of how well each model performs in classifying fish, which can be useful apart from bounding box detection. It is also useful to see how many predictions for each class were incorrectly matched to other classes. A confusion matrix succinctly presents these classification statistics in an <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> matrix, where <italic toggle="yes">n</italic> is the number of labels. Suppose the <italic toggle="yes">i</italic>th label in a dataset is indexed as label<sub><italic toggle="yes">i</italic></sub>, where <italic toggle="yes">i</italic> is an integer in the range <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Entries on the <italic toggle="yes">i</italic>th data row of a confusion matrix correspond to images with the ground truth label of label<sub><italic toggle="yes">i</italic></sub>, and entries in the <italic toggle="yes">j</italic>th (<inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) column of the matrix are images that were predicted with the label of label<sub><italic toggle="yes">j</italic></sub>. <xref rid="sensors-25-01022-t004" ref-type="table">Table 4</xref> shows an example confusion matrix for a three-class problem, with two added columns showing the precision and recall for each row. The format of <xref rid="sensors-25-01022-t004" ref-type="table">Table 4</xref> will be used in the following results to present these classification statistics.</p><p>After the initial metric-based evaluation, these models were adapted to run in an edge processing environment to determine their suitability for real-world deployment. Frigate NVR, running on a micro factor computer similar to the one used for data collection, was used as the video processing platform for this evaluation. A Coral Edge TPU USB Accelerator&#x02014;a small but powerful tensor processing accelerator&#x02014;allowed these fish detection models to run in real time in the Frigate application. In the absence of a live stream of the ASFL video capture chamber, Fake-RTSP-Streamer [<xref rid="B94-sensors-25-01022" ref-type="bibr">94</xref>], a video streaming simulator, was used to simulate a RTSP video stream from an IP camera. To allow the models trained in this research to run on the Coral TPU, every model was converted to a quantized tflite model with 8-bit unsigned integer weights using post-training quantization. All quantized models were then compiled to run on the Coral Edge TPU, which uses a specialized, limited operation set. Since post-training quantization with 8-bit weights may increase a model&#x02019;s speed at the cost of its performance, the mAP, precision, and recall metrics were again computed after this process to gather accurate data on how these models will perform on this edge system. The speed versus accuracy trade-offs of 8-bit integer quantization are important to consider based on the specific use cases of the model and the requirements of fishery managers. However, at least for the case of high-speed fish detection, speed was deemed a priority in this case study.</p><p>Two of these quantized models, ASFL-Single-DetectQ and Combined-Multi-DetectQ, were then tested on this simulated edge system using 7 h of streamed clips from each model&#x02019;s respective testing data sourced from the back overhead camera angle. Each video hour contained at least one fish from each model&#x02019;s evaluation set and possibly contained other fish from the training sets. Frigate enables clips from a live RTSP stream containing detections to be saved to the system, so this option was enabled to assess model performance in this simulated deployed setting. The metrics used for this test were precision and recall, where a true positive in this case is a clip of a fish that was successfully saved, a false positive is a clip containing no detections that was saved, and a false negative is a missed detection. Class-specific precision and recall were also calculated where appropriate.</p></sec></sec><sec sec-type="results" id="sec3-sensors-25-01022"><title>3. Results</title><sec id="sec3dot1-sensors-25-01022"><title>3.1. Model&#x000a0;Evaluation</title><p>The ASFL-Single-Detect fish detection model was trained for 45,000 epochs. This model achieved a mAP50 score of 0.95 on the evaluation set, as determined by the COCO API mAP50 evaluation tool (Pycocotools version 2.0.7). The full classification confusion matrix for this model is shown in <xref rid="sensors-25-01022-t005" ref-type="table">Table 5</xref>, where background (BG) indicates all parts of an image that have no annotation. This model achieved a classification precision (Pr) of 1.0 and a recall (R) of 0.96 for the only class, &#x0201c;Fish&#x0201d;.</p><p>The next model, ASFL-Multi-Detect, was also trained for 45,000 epochs. The mAP50 score for this model on its evaluation data was 0.20, and the classification statistics shown in <xref rid="sensors-25-01022-t006" ref-type="table">Table 6</xref> validate this result.</p><p>The third model, USGS-Multi-Detect, was trained for 50,000 epochs, and it achieved a mAP50 score of 0.83 on its evaluation data. The full classification confusion matrix, precision, and recall for this model are all given in <xref rid="sensors-25-01022-t007" ref-type="table">Table 7</xref>.</p><p>The final model, Combined-Multi-Detect, was trained for 50,000 epochs and achieved a mAP50 of 0.47 on its evaluation set. <xref rid="sensors-25-01022-t008" ref-type="table">Table 8</xref> shows the classification confusion matrix and precision and recall for this model.</p><p>To allow for comparison between Combined-Multi-Detect and ASFL-Multi-Detect (the two models that partially share evaluation data), Combined-Multi-Detect was also evaluated on the evaluation data from ASFL-Multi. Combined-Multi-Detect achieved a mAP50 of 0.31 on these data. <xref rid="sensors-25-01022-t009" ref-type="table">Table 9</xref> below shows the classification confusion matrix and precision and recall for Combined-Multi-Detect evaluated on the ASFL-Multi evaluation set.</p></sec><sec id="sec3dot2-sensors-25-01022"><title>3.2. Quantized Model&#x000a0;Evaluation</title><p>After each model was quantized and compiled for the Coral TPU, the mAP50 scores, classification confusion matrices, and precision and recall scores for the models were recomputed to account for any altered performance. The quantized ASFL-Single-Detect model, denoted ASFL-Single-DetectQ, was evaluated to have the same mAP50 of 0.95. ASFL-Multi-DetectQ was determined to have a mAP50 of 0.19, a modest loss of 0.01 in mean average precision. USGS-Multi-DetectQ was calculated to have a mAP50 of 0.83, the same mAP50 score as its unquantized counterpart. Finally, Combined-Multi-DetectQ achieved a mAP50 of 0.48 on the Combined-Multi evaluation dataset, a 0.01 increase in mAP. As with mAP50, the confusion matrices and precision and recall scores were similar between the unquantized models and their quantized counterparts. Therefore, for brevity, these tables are omitted but can be made available upon request.</p></sec><sec id="sec3dot3-sensors-25-01022"><title>3.3. Frigate&#x000a0;Evaluation</title><p>After quantization evaluation, ASFL-Single-DetectQ and Combined-Multi-DetectQ models were tested independently on the simulated real-time edge environment using Frigate NVR and the Coral Edge TPU. ASFL-Single-DetectQ detected and saved 10 clips, 9 of which contain unique instances of fish. In total, 10 unique fish exist in the video clips on which this model was tested, meaning that ASFL-Single-DetectQ achieved a single-class precision of 0.90 and a recall of 0.90. Combined-Multi-DetectQ detected, classified, and saved 12 clips from its testing video data, 6 of which contain fish. Since fish classification is a factor for this model, an abbreviated confusion matrix for Combined-Multi-DetectQ that contains only fish from the testing videos is given as <xref rid="sensors-25-01022-t010" ref-type="table">Table 10</xref>. In terms of single-class fish detection, since the ASFL test videos contain 9 unique fish, the Combined-Multi-DetectQ achieved a single-class precision of 0.50 and a recall of 0.67. For multi-class classification precision and recall, refer to <xref rid="sensors-25-01022-t010" ref-type="table">Table 10</xref>.</p></sec></sec><sec sec-type="discussion" id="sec4-sensors-25-01022"><title>4. Discussion</title><sec id="sec4dot1-sensors-25-01022"><title>4.1. Fish Detection&#x000a0;Advancements</title><p>The results from this case study advance efforts for real-time fish detection in multiple ways. First, even with a fairly small dataset composed of only 29 fish, this overall system shows promise in accurately and efficiently detecting fish as they pass through an ASFL-like system. Specifically, the model prototyped for single-class detection in this research, ASFL-Single-Detect, is capable of high-accuracy, generalizable fish detection. Despite the 31 missed detections on frames of fish passing through the video capture chamber, every fish in the ASFL-Single evaluation set was detected partially or fully by ASFL-Single-Detect. In a real-world context, this means that every fish would be recognized and captured by a data capture system, as the redundant frames of the fish passing through the system more than account for occasional missed detections. This claim is supported by the Frigate evaluation of ASFL-Single-DetectQ, which succeeded in detecting and isolating 9 out of the 10 fish in the videos on which it performed inference. This detector is capable of generalizing to predict close-fitting bounding boxes on completely unknown fish in irregular orientations. This is exemplified in <xref rid="sensors-25-01022-f003" ref-type="fig">Figure 3</xref>, which shows the model&#x02019;s predictions on a rock bass&#x02014;a fish species that was not represented at all in the model&#x02019;s training data&#x02014;as it flips and contorts itself through the ASFL video chamber.</p><p>Coupled with its high detection rate and tolerance to quantization, this generablizability indicates that the ASFL-Single-Detect model is well suited for autonomous video chamber monitoring and data collection. This work has shown that this model can seamlessly integrate with Frigate and the Coral Edge TPU for real-time edge data processing, meaning that it can be deployed in situ to assist with real-world fish monitoring. This model has other applications as well. Data collection and processing was the costliest phase of this research in terms of time and effort, and the data culling process using background subtraction still required extensive manual evaluation and labeling. ASFL-Single-Detect can easily automate this process. For example, in the Frigate evaluation, ASFL-Single-Detect generated 10 clips that equated to about 4 min of video from 7 h of a video stream, greatly simplifying the data culling process and reducing manual evaluation to one quick session of reviewing the culled clips. Further, while the model did fail to detect one fish in the Frigate evaluation, this is likely caused by Frigate&#x02019;s configuration, which uses its own background subtraction algorithm, frame sampling rate, and bounding box selection criteria to filter frames and decide which ones will be sent to the model for evaluation on the Coral TPU. ASFL-Single-Detect could be deployed directly to and outside of Frigate to detect fish in frames, save these frames and their associated clips, and partially annotate these images, all in one step. This autonomous data processing would prove immensely useful in collecting more fish data that can be used to train more robust models in the future.</p><p>An important conclusion from these results with the single-class fish detector is that this entire system prototyped for data collection and analysis&#x02014;the fish detection model, open source NVR, and commodity hardware combined with the ASFL system&#x02019;s lift, dewatering sled, and video chamber&#x02014;is viable and eligible for immediate deployment. By following this case study&#x02019;s experimental setup, fishery managers can replicate these results with their own data gathered in situ and build a similar surveillance platform without costly software and hardware requirements. This proof of concept in a democratized, user-friendly, and readily deployable fish collection and surveillance system has major implications for advancing fishery management and increasing the tools available for fishery managers to incorporate artificial intelligence into their management efforts. Further, by decoupling the surveillance aspects of this system from the physical ASFL device, this system can be extended beyond fishery management into other realms where it is necessary to rapidly collect data, train models, and deploy hardware for active surveillance tasks.</p><p>Second, combining the ASFL data with similar data sources was shown to be a successful way to increase model performance on multi-class fish detection despite obvious data limitations. As expected, the ASFL dataset suffers from class imbalance problems that decrease the effectiveness of ASFL-Multi-Detect for multi-class fish detection. For example, images of a singular longnose sucker that lingered in the ASFL video capture chamber make up roughly 38% of the training data. As a result, the model achieves a low mAP50 of 0.20, which would be unsuitable for real-world applications where recognizing fish is key to preventing the spread of invasive species. Moreover, the ASFL-Multi-Detect model cannot be used for any sort of invasive species detection or control, as its training data contain no examples of sea lamprey, invasive carp, or other invasive species. However, as demonstrated by USGS-Multi-Detect, which achieved a mAP50 of 0.83, a MobileNet SSD model trained on varied data representing many unique fish can lead to very accurate results, including the detection of invasive species like sea lamprey and invasive silver carp with the very high recall values of 0.95 and 0.99, respectively (see <xref rid="sensors-25-01022-t007" ref-type="table">Table 7</xref>). <xref rid="sensors-25-01022-f004" ref-type="fig">Figure 4</xref> shows an example of an invasive sea lamprey being successfully localized and classified by the USGS-Multi-Detect model. This suggests that with more and better data, ASFL-Multi-Detect may be capable of reaching a similar level of success.</p><p>The most interesting results occur when the ASFL and USGS datasets are combined. The data from the USGS dataset do not generalize well to the data from the ASFL and vice versa. However, by immunizing the dataset with enough samples from each dataset, a model trained on this combined dataset can learn a more robust representation of the classes that are shared between these two data sources. As presented in the results, when performing inference on the evaluation data from ASFL-Multi (which is a proper subset of the evaluation data for Combined-Multi), Combined-Multi-Detect achieved a mAP50 of 0.31, which is 0.11 greater than the mAP50 score for ASFL-Multi-Detect. Further, compare <xref rid="sensors-25-01022-t006" ref-type="table">Table 6</xref>, the classification confusion matrix for ASFL-Multi-Detect, with <xref rid="sensors-25-01022-t009" ref-type="table">Table 9</xref>, the classification confusion matrix for Combined-Multi-Detect evaluated on the ASFL-Multi evaluation set. Almost every category in <xref rid="sensors-25-01022-t009" ref-type="table">Table 9</xref> outperforms its counterpart in <xref rid="sensors-25-01022-t006" ref-type="table">Table 6</xref>, especially in terms of improving recall. This demonstrates that more data, even from a different data source, are helpful in increasing the model&#x02019;s performance on a target domain.</p><p>As evidenced by the Frigate evaluation, Combined-Multi-Detect is not yet strong enough to be used for pure multi-class detection tasks, as it is too prone to fish misclassifications, false negatives, and false positives that could prove disastrous in a selective passage system. Further, although this model is trained on images of invasive species passing through the Whooshh scanning system, it is untested whether this model could accurately identify invasive species passing through the ASFL system, in which fish enter volitionally, have far more agency, and move with more explosive action than in the Whooshh system. Still, as a data-gathering tool, the Combined-Multi-Detect model certainly has a utility. Moreover, this model serves as a proof of concept that (1) high-performance fish species classification is possible using images of partially dewatered fish passing through an ASFL system and that (2) combining datasets from similar detection domains is an inexpensive and effective way to bolster model performance.</p><p>It is also worthwhile to note that the fish passing through the video chamber in the ASFL system were allowed a full range of movement, meaning that for some frames captured of fish moving through the ASFL from different angles, the presentation of the fish did not contain distinguishing features. All models were evaluated on a frame-by-frame basis, meaning that the model inaccuracies may be due in part to these poor fish presentations. Therefore, a majority voting approach where a single fish passing through the ASFL is labeled according to the most prevalent predicted label across all frames of the fish captured from multiple camera angles could be utilized to improve this system&#x02019;s multi-class detection capabilities. Using such an approach, the overall classification accuracy of ASFL-Multi-Detect, for example, would be 50% (four out of eight unique fish) even with the current data limits. A composite image approach similar to the one used by [<xref rid="B40-sensors-25-01022" ref-type="bibr">40</xref>] could also be used to train models with more details about a fish passing through the ASFL. However, both of these methods would complicate both the real-time requirements of this system and the model&#x02019;s integrability with Frigate. These paths for improvement are left open, but given the current system&#x02019;s emphasis on deployability and simplicity, these techniques were not implemented in this case study.</p></sec><sec id="sec4dot2-sensors-25-01022"><title>4.2. Real-Time&#x000a0;Processing</title><p>The edge processing environment used in this research demonstrated its effectiveness as a lightweight and open source solution to selective passage monitoring and, eventually, control. With the exception of ASFL-Multi-DetectQ, the models trained in this research suffered very few performance losses as a result of being quantized and compiled to run on the Coral TPU in this environment, suggesting that most models will not suffer when they are ported onto this system. In fact, quantization appeared to boost the performance of some models, such as Combined-Multi-DetectQ, which increased its mAP50 by 0.01 after quantization. Detection on this system takes 22 ms, which is equivalent to just over 45 fps, making this system capable of real-time detection for most video feeds. This system is resource-efficient, extremely portable, capable of offline operation, and easy to configure and manage for individuals who do not have a background in software engineering. Importantly, this system can be deployed immediately using readily available commodity hardware to similar systems that use RTSP-streamed video to monitor partially dewatered fish. Although models used in custom deployments may need to be fine-tuned on specific camera angles and views, the training, evaluation, and deployment pipeline presented in this research simplifies this process, enabling fishery managers to gain more control over utilizing these technologies in emergent use cases.</p></sec><sec id="sec4dot3-sensors-25-01022"><title>4.3. Research&#x000a0;Limitations</title><p>One limitation in this study is the lack of data from different environmental conditions that adequately represent every fish species that is required for robust selective passage monitoring and control. As mentioned before, this system remains untested on tasks like classifying sea lamprey passing through the ASFL. Moreover, while the generalization capabilities of the single-class and multi-class detection models appear to be robust, only a deployment using realistic data can adequately assess this. As such, the models developed in this research should only be used for data collection and annotation. However, even then, a human-in-the-loop approach is necessary to validate model predictions and continuously improve model performance by training the model on newly discovered data. The results from this case study indicate that an iterative, bootstrapping approach for training increasingly better models is viable in this system, meaning that these limitations will subside with more experimental data collection. Further, these limitations are with the models and not the system as a whole&#x02014;that is, if comprehensive data for a specific fishery surveillance task are available, this case study suggests that this surveillance platform will perform well.</p></sec><sec id="sec4dot4-sensors-25-01022"><title>4.4. Future&#x000a0;Work</title><p>This research presents several intriguing paths for future work. First, using the models developed in this research, more data should be continuously collected from ASFL systems, annotated, and used to train new machine learning models that have a greater exposure to different species of fish, variations in lighting, and other noisy environmental conditions. Second, the close-fitting bounding boxes generated by the models in the controlled ASFL scanning environment open the possibility to developing additional software to predict and record the lengths, girths, and weights of fish passing through the ASFL. Ideally, the models developed in this research can be used not just to detect fish but eventually record fish measurements as well, extending the ASFL system to be used for autonomous fishery health monitoring in situ. Third, future research should carry out an investigation using larger, more powerful open source models than MobileNetv2 SSD FPN-Lite 320 &#x000d7; 320. MobileNetv2 SSD FPN-Lite 320 &#x000d7; 320 was chosen in this research due to its highly configurable nature, simple training pipeline, and compatibility with Frigate and the Coral TPU, which makes this model accessible for use by individuals without a background in machine learning. However, for the best model performance, newer object detection architectures should be tested and adapted for use in Frigate or used on their own in custom network video recording applications. Finally, the multi-class detection results pose the question of whether species-level classification is necessary, or if classifying similar fish based on general characteristics would be sufficient. For example, grouping common white and longnose suckers together&#x02014;fish that are quite similar in appearance and are both native to the Great Lakes&#x02014;would likely increase the mAP of the models in this research if the data are clear. Using the training pipeline and data collection paradigm presented in this research, fishery managers can create specific selective passage datasets on a case-by-case basis, granting a high degree of flexibility in multi-class fish detection.</p><p>The most exciting avenues for this research are other deployments of this system in waterways across the Great Lakes&#x02019; region and beyond. As mentioned before, fishery managers can replicate the experiments from this research and deploy similar systems without relying on advanced hardware or software engineering expertise. The open source, accessible nature of the components of this platform contribute to lowering the costs of intelligent fishery surveillance and present a simple, &#x0201c;turnkey&#x0201d; approach for similar systems to be readily deployed in the wild. It is the hope that in the spirit of this research&#x02019;s open science efforts, other researchers and fishery managers will share their data and results, contributing to a pool of knowledge that can be used to iteratively improve this system as a whole with more data and expertise.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-01022"><title>5. Conclusions</title><p>Selective fish passages, a key component of improving fishery health in the Great Lakes and beyond, can only be made scalable through the development of autonomous fish-sorting techniques. To support this goal, this case study presents an integrated, readily deployable platform for fish surveillance in an ASFL-like system. Using experimental data of partially dewatered fish exiting an Archimedes Screw Fish Lift gathered in situ, several models were developed that will be used on this platform for data collection, annotation, and fishery monitoring. These models were fine-tuned versions of a standard MobileNetv2 SSD FPN-Lite 320 &#x000d7; 320 object detection model and were trained using custom datasets of fish passing through optical scanners for the tasks of single-class and multi-class fish detection. These models were then adapted for deployment in an edge processing environment, and the two most successful models were tested on an edge processing environment for real-time data collection and annotation tasks. The results show that the models developed in this research are best used for single-class fish detection, which can be used to assist in real-time data collection efforts. Multi-class models, while showing promise, must be trained on larger datasets to gain robust detection capabilities. This research also shows that these models are easily deployable for real-time detection on an edge processing system, thus fulfilling a need in fishery monitoring. Most importantly, the components of this system interface flawlessly, providing a definitive proof of concept that this surveillance platform is viable and useful.</p><p>Moving forward, this platform will enable the collection of larger and more detailed datasets that can be used to assist with the goal of optical fish sorting in a selective passage system. Future research can build on these results and improve model performance on classifying different fish species, eventually leading to the level of sensitivity necessary for optical fish sorting. As a note of caution, fishery managers must be wary about placing too much faith in machine learning models, which are ultimately black boxes that defy explanation at times. However, as a means to autonomously gather data and impose a software-supported backstop for selective fish passage, this platform demonstrates robust detection capabilities that will only improve as its models are trained on more and better data.</p></sec></body><back><ack><title>Acknowledgments</title><p>This manuscript is Contribution 19 of FishPass. FishPass is the capstone to the 20y restoration of the Boardman (Ottaway) River, Traverse City, Michigan. The mission of FishPass is to provide up- and down-stream passage of desirable fishes while simultaneously blocking or removing undesirable fishes, thereby addressing the connectivity conundrum. We are grateful to the primary project partners: Grand Traverse Band of Ottawa and Chippewa Indians, Michigan Department of Natural Resources; U.S. Army Corps of Engineers; U.S. Fish and Wildlife Service, U.S. Geological Survey. We also extend thanks to the primary partner, the City of Traverse City. Without the city&#x02019;s support and the vision of the city commission, FishPass would not have been possible. We also thank members of the Central Applied Machine Learning Lab who assisted in developing the technologies utilized in this research. In particular, we would like to thank Jordan Leh and Zachary Partlo for assisting in coding the background subtraction pipeline, as well as Sethu Mettukulam Jagadeesan for his help in configuring the Frigate environment. Finally, we acknowledge Stephane Maillard for his review of this manuscript and his suggestions for its improvement. Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, S.M.M., J.L.E. and D.P.Z.; methodology, J.G., S.M.M. and D.P.Z.; software, J.G.; validation, J.G. and S.M.M.; formal analysis, J.G. and J.L.E.; investigation, all authors; data curation, J.G.; writing&#x02014;original draft preparation, J.G. and J.L.E.; writing&#x02014;review and editing, all authors; visualization, J.G. and S.M.M.; supervision, S.M.M. and J.L.E.; project administration, S.M.M. and D.P.Z.; funding acquisition, S.M.M. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>Datasets used in this study are available at <uri xlink:href="https://doi.org/10.17605/OSF.IO/QTRKD">https://doi.org/10.17605/OSF.IO/QTRKD</uri>. The code used in this project can be made available upon request.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01022"><label>1.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Rau</surname><given-names>E.</given-names></name>
<name><surname>Riseng</surname><given-names>C.</given-names></name>
<name><surname>Vaccaro</surname><given-names>L.</given-names></name>
<name><surname>Read</surname><given-names>J.G.</given-names></name>
</person-group><source>The Dynamic Great Lakes Economy: Employment Trends from 2009 to 2018</source><publisher-name>NOAA</publisher-name><publisher-loc>Silver Spring, MD, USA</publisher-loc><year>2020</year></element-citation></ref><ref id="B2-sensors-25-01022"><label>2.</label><element-citation publication-type="gov"><person-group person-group-type="author">
<collab>GLRI (Great Lakes Restoration Initiative)</collab>
</person-group><article-title>Great Lakes Restoration Initiative Action Plan III</article-title><year>2019</year><comment>Available online: <ext-link xlink:href="https://www.epa.gov/sites/default/files/2019-10/documents/glri-action-plan-3-201910-30pp.pdf" ext-link-type="uri">https://www.epa.gov/sites/default/files/2019-10/documents/glri-action-plan-3-201910-30pp.pdf</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-10-15">(accessed on 15 October 2024)</date-in-citation></element-citation></ref><ref id="B3-sensors-25-01022"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Rahel</surname><given-names>F.J.</given-names></name>
<name><surname>McLaughlin</surname><given-names>R.L.</given-names></name>
</person-group><article-title>Selective fragmentation and the management of fish movement across anthropogenic barriers</article-title><source>Ecol. Appl.</source><year>2018</year><volume>28</volume><fpage>2066</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1002/eap.1795</pub-id><pub-id pub-id-type="pmid">30168645</pub-id>
</element-citation></ref><ref id="B4-sensors-25-01022"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fausch</surname><given-names>K.D.</given-names></name>
<name><surname>Rieman</surname><given-names>B.E.</given-names></name>
<name><surname>Dunham</surname><given-names>J.B.</given-names></name>
<name><surname>Young</surname><given-names>M.K.</given-names></name>
<name><surname>Peterson</surname><given-names>D.P.</given-names></name>
</person-group><article-title>Invasion versus Isolation: Trade-Offs in Managing Native Salmonids with Barriers to Upstream Movement</article-title><source>Conserv. Biol.</source><year>2009</year><volume>23</volume><fpage>859</fpage><lpage>870</lpage><pub-id pub-id-type="doi">10.1111/j.1523-1739.2008.01159.x</pub-id><pub-id pub-id-type="pmid">19210302</pub-id>
</element-citation></ref><ref id="B5-sensors-25-01022"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>McLaughlin</surname><given-names>R.L.</given-names></name>
<name><surname>Smyth</surname><given-names>E.R.B.</given-names></name>
<name><surname>Castro-Santos</surname><given-names>T.</given-names></name>
<name><surname>Jones</surname><given-names>M.L.</given-names></name>
<name><surname>Koops</surname><given-names>M.A.</given-names></name>
<name><surname>Pratt</surname><given-names>T.C.</given-names></name>
<name><surname>V&#x000e9;lez-Espino</surname><given-names>L.A.</given-names></name>
</person-group><article-title>Unintended consequences and trade-offs of fish passage</article-title><source>Fish Fish.</source><year>2013</year><volume>14</volume><fpage>580</fpage><lpage>604</lpage><pub-id pub-id-type="doi">10.1111/faf.12003</pub-id></element-citation></ref><ref id="B6-sensors-25-01022"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pratt</surname><given-names>T.C.</given-names></name>
<name><surname>O&#x02019;Connor</surname><given-names>L.M.</given-names></name>
<name><surname>Hallett</surname><given-names>A.G.</given-names></name>
<name><surname>McLaughlin</surname><given-names>R.L.</given-names></name>
<name><surname>Katopodis</surname><given-names>C.</given-names></name>
<name><surname>Hayes</surname><given-names>D.B.</given-names></name>
<name><surname>Bergstedt</surname><given-names>R.A.</given-names></name>
</person-group><article-title>Balancing Aquatic Habitat Fragmentation and Control of Invasive Species: Enhancing Selective Fish Passage at Sea Lamprey Control Barriers</article-title><source>Trans. Am. Fish. Soc.</source><year>2009</year><volume>138</volume><fpage>652</fpage><lpage>665</lpage><pub-id pub-id-type="doi">10.1577/T08-118.1</pub-id></element-citation></ref><ref id="B7-sensors-25-01022"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zielinski</surname><given-names>D.P.</given-names></name>
<name><surname>McLaughlin</surname><given-names>R.L.</given-names></name>
<name><surname>Pratt</surname><given-names>T.C.</given-names></name>
<name><surname>Goodwin</surname><given-names>R.A.</given-names></name>
<name><surname>Muir</surname><given-names>A.M.</given-names></name>
</person-group><article-title>Single-Stream Recycling Inspires Selective Fish Passage Solutions for the Connectivity Conundrum in Aquatic Ecosystems</article-title><source>BioScience</source><year>2020</year><volume>70</volume><fpage>871</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1093/biosci/biaa090</pub-id><pub-id pub-id-type="pmid">33093814</pub-id>
</element-citation></ref><ref id="B8-sensors-25-01022"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kerr</surname><given-names>J.</given-names></name>
<name><surname>Vowles</surname><given-names>A.</given-names></name>
<name><surname>Crabb</surname><given-names>M.</given-names></name>
<name><surname>Kemp</surname><given-names>P.</given-names></name>
</person-group><article-title>Selective fish passage: Restoring habitat connectivity without facilitating the spread of a non-native species</article-title><source>J. Environ. Manag.</source><year>2021</year><volume>279</volume><fpage>110908</fpage><pub-id pub-id-type="doi">10.1016/j.jenvman.2020.110908</pub-id></element-citation></ref><ref id="B9-sensors-25-01022"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Atlas</surname><given-names>W.I.</given-names></name>
<name><surname>Ma</surname><given-names>S.</given-names></name>
<name><surname>Chou</surname><given-names>Y.C.</given-names></name>
<name><surname>Connors</surname><given-names>K.</given-names></name>
<name><surname>Scurfield</surname><given-names>D.</given-names></name>
<name><surname>Nam</surname><given-names>B.</given-names></name>
<name><surname>Ma</surname><given-names>X.</given-names></name>
<name><surname>Cleveland</surname><given-names>M.</given-names></name>
<name><surname>Doire</surname><given-names>J.</given-names></name>
<name><surname>Moore</surname><given-names>J.W.</given-names></name>
<etal/>
</person-group><article-title>Wild salmon enumeration and monitoring using deep learning empowered detection and tracking</article-title><source>Front. Mar. Sci.</source><year>2023</year><volume>10</volume><elocation-id>1200408</elocation-id><pub-id pub-id-type="doi">10.3389/fmars.2023.1200408</pub-id></element-citation></ref><ref id="B10-sensors-25-01022"><label>10.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<collab>Innovasea Systems Inc.</collab>
</person-group><article-title>HydroAI&#x02122;</article-title><comment>Available online: <ext-link xlink:href="https://www.innovasea.com/hydroai-fish-counting-system/" ext-link-type="uri">https://www.innovasea.com/hydroai-fish-counting-system/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-20">(accessed on 20 November 2024)</date-in-citation></element-citation></ref><ref id="B11-sensors-25-01022"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Saleh</surname><given-names>A.</given-names></name>
<name><surname>Sheaves</surname><given-names>M.</given-names></name>
<name><surname>Rahimi Azghadi</surname><given-names>M.</given-names></name>
</person-group><article-title>Computer vision and deep learning for fish classification in underwater habitats: A survey</article-title><source>Fish Fish.</source><year>2022</year><volume>23</volume><fpage>977</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1111/faf.12666</pub-id></element-citation></ref><ref id="B12-sensors-25-01022"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zielinski</surname><given-names>D.P.</given-names></name>
<name><surname>Miehls</surname><given-names>S.</given-names></name>
<name><surname>Lewandoski</surname><given-names>S.</given-names></name>
</person-group><article-title>Test of a Screw-Style Fish Lift for Introducing Migratory Fish into a Selective Fish Passage Device</article-title><source>Water</source><year>2022</year><volume>14</volume><elocation-id>2298</elocation-id><pub-id pub-id-type="doi">10.3390/w14152298</pub-id></element-citation></ref><ref id="B13-sensors-25-01022"><label>13.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Nery</surname><given-names>M.</given-names></name>
<name><surname>Machado</surname><given-names>A.</given-names></name>
<name><surname>Campos</surname><given-names>M.</given-names></name>
<name><surname>Padua</surname><given-names>F.</given-names></name>
<name><surname>Carceroni</surname><given-names>R.</given-names></name>
<name><surname>Queiroz-Neto</surname><given-names>J.</given-names></name>
</person-group><article-title>Determining the Appropriate Feature Set for Fish Classification Tasks</article-title><source>Proceedings of the XVIII Brazilian Symposium on Computer Graphics and Image Processing (SIBGRAPI&#x02019;05)</source><conf-loc>Natal, Brazil</conf-loc><conf-date>9&#x02013;12 October 2005</conf-date><fpage>173</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1109/SIBGRAPI.2005.25</pub-id></element-citation></ref><ref id="B14-sensors-25-01022"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zion</surname><given-names>B.</given-names></name>
<name><surname>Alchanatis</surname><given-names>V.</given-names></name>
<name><surname>Ostrovsky</surname><given-names>V.</given-names></name>
<name><surname>Barki</surname><given-names>A.</given-names></name>
<name><surname>Karplus</surname><given-names>I.</given-names></name>
</person-group><article-title>Real-time underwater sorting of edible fish species</article-title><source>Comput. Electron. Agric.</source><year>2007</year><volume>56</volume><fpage>34</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2006.12.007</pub-id></element-citation></ref><ref id="B15-sensors-25-01022"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zion</surname><given-names>B.</given-names></name>
<name><surname>Alchanatis</surname><given-names>V.</given-names></name>
<name><surname>Ostrovsky</surname><given-names>V.</given-names></name>
<name><surname>Barki</surname><given-names>A.</given-names></name>
<name><surname>Karplus</surname><given-names>I.</given-names></name>
</person-group><article-title>Classification of guppies&#x02019; (<italic toggle="yes">Poecilia reticulata</italic>) gender by computer vision</article-title><source>Aquac. Eng.</source><year>2008</year><volume>38</volume><fpage>97</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.aquaeng.2008.01.002</pub-id></element-citation></ref><ref id="B16-sensors-25-01022"><label>16.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kartika</surname><given-names>D.S.Y.</given-names></name>
<name><surname>Herumurti</surname><given-names>D.</given-names></name>
</person-group><article-title>Koi fish classification based on HSV color space</article-title><source>Proceedings of the 2016 International Conference on Information &#x00026; Communication Technology and Systems (ICTS)</source><conf-loc>Surabaya, Indonesia</conf-loc><conf-date>12 October 2016</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2016</year><fpage>96</fpage><lpage>100</lpage></element-citation></ref><ref id="B17-sensors-25-01022"><label>17.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Rova</surname><given-names>A.</given-names></name>
<name><surname>Mori</surname><given-names>G.</given-names></name>
<name><surname>Dill</surname><given-names>L.M.</given-names></name>
</person-group><article-title>One fish, two fish, butterfish, trumpeter: Recognizing fish in underwater video</article-title><source>Proceedings of the IAPR Conference on Machine Vision Applications, MVA 2007</source><conf-loc>Tokyo, Japan</conf-loc><conf-date>16&#x02013;18 May 2007</conf-date><fpage>404</fpage><lpage>407</lpage></element-citation></ref><ref id="B18-sensors-25-01022"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hu</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>D.</given-names></name>
<name><surname>Duan</surname><given-names>Q.</given-names></name>
<name><surname>Han</surname><given-names>Y.</given-names></name>
<name><surname>Chen</surname><given-names>G.</given-names></name>
<name><surname>Si</surname><given-names>X.</given-names></name>
</person-group><article-title>Fish species classification by color, texture and multi-class support vector machine using computer vision</article-title><source>Comput. Electron. Agric.</source><year>2012</year><volume>88</volume><fpage>133</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2012.07.008</pub-id></element-citation></ref><ref id="B19-sensors-25-01022"><label>19.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Fouad</surname><given-names>M.M.M.</given-names></name>
<name><surname>Zawbaa</surname><given-names>H.M.</given-names></name>
<name><surname>El-Bendary</surname><given-names>N.</given-names></name>
<name><surname>Hassanien</surname><given-names>A.E.</given-names></name>
</person-group><article-title>Automatic nile tilapia fish classification approach using machine learning techniques</article-title><source>Proceedings of the 13th International Conference on Hybrid Intelligent Systems (HIS 2013)</source><conf-loc>Tunis, Tunisia</conf-loc><conf-date>4&#x02013;6 December 2013</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2013</year><fpage>173</fpage><lpage>178</lpage></element-citation></ref><ref id="B20-sensors-25-01022"><label>20.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>P.X.</given-names></name>
<name><surname>Boom</surname><given-names>B.J.</given-names></name>
<name><surname>Fisher</surname><given-names>R.B.</given-names></name>
</person-group><article-title>GMM improves the reject option in hierarchical classification for fish recognition</article-title><source>Proceedings of the IEEE Winter Conference on Applications of Computer Vision</source><conf-loc>Steamboat Springs, CO, USA</conf-loc><conf-date>24&#x02013;26 March 2014</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2014</year><fpage>371</fpage><lpage>376</lpage></element-citation></ref><ref id="B21-sensors-25-01022"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chuang</surname><given-names>M.C.</given-names></name>
<name><surname>Hwang</surname><given-names>J.N.</given-names></name>
<name><surname>Williams</surname><given-names>K.</given-names></name>
</person-group><article-title>A feature learning and object recognition framework for underwater fish images</article-title><source>IEEE Trans. Image Process.</source><year>2016</year><volume>25</volume><fpage>1862</fpage><lpage>1872</lpage><pub-id pub-id-type="doi">10.1109/TIP.2016.2535342</pub-id><pub-id pub-id-type="pmid">26930683</pub-id>
</element-citation></ref><ref id="B22-sensors-25-01022"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ogunlana</surname><given-names>S.</given-names></name>
<name><surname>Olabode</surname><given-names>O.</given-names></name>
<name><surname>Oluwadare</surname><given-names>S.</given-names></name>
<name><surname>Iwasokun</surname><given-names>G.</given-names></name>
</person-group><article-title>Fish classification using support vector machine</article-title><source>Afr. J. Comput. ICT</source><year>2015</year><volume>8</volume><fpage>75</fpage><lpage>82</lpage></element-citation></ref><ref id="B23-sensors-25-01022"><label>23.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Hossain</surname><given-names>E.</given-names></name>
<name><surname>Alam</surname><given-names>S.S.</given-names></name>
<name><surname>Ali</surname><given-names>A.A.</given-names></name>
<name><surname>Amin</surname><given-names>M.A.</given-names></name>
</person-group><article-title>Fish activity tracking and species identification in underwater video</article-title><source>Proceedings of the 2016 5th International Conference on Informatics, Electronics and Vision (ICIEV)</source><conf-loc>Dhaka, Bangladesh</conf-loc><conf-date>13&#x02013;14 May 2016</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2016</year><fpage>62</fpage><lpage>66</lpage></element-citation></ref><ref id="B24-sensors-25-01022"><label>24.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>G.</given-names></name>
<name><surname>Hwang</surname><given-names>J.N.</given-names></name>
<name><surname>Williams</surname><given-names>K.</given-names></name>
<name><surname>Wallace</surname><given-names>F.</given-names></name>
<name><surname>Rose</surname><given-names>C.S.</given-names></name>
</person-group><article-title>Shrinking encoding with two-level codebook learning for fine-grained fish recognition</article-title><source>Proceedings of the 2016 ICPR 2nd Workshop on Computer Vision for Analysis of Underwater Imagery (CVAUI)</source><conf-loc>Cancun, Mexico</conf-loc><conf-date>4 December 2016</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2016</year><fpage>31</fpage><lpage>36</lpage></element-citation></ref><ref id="B25-sensors-25-01022"><label>25.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Islam</surname><given-names>M.A.</given-names></name>
<name><surname>Howlader</surname><given-names>M.R.</given-names></name>
<name><surname>Habiba</surname><given-names>U.</given-names></name>
<name><surname>Faisal</surname><given-names>R.H.</given-names></name>
<name><surname>Rahman</surname><given-names>M.M.</given-names></name>
</person-group><article-title>Indigenous fish classification of Bangladesh using hybrid features with SVM classifier</article-title><source>Proceedings of the 2019 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering (IC4ME2)</source><conf-loc>Rajshahi, Bangladesh</conf-loc><conf-date>11&#x02013;12 July 2019</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2019</year><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B26-sensors-25-01022"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Storbeck</surname><given-names>F.</given-names></name>
<name><surname>Daan</surname><given-names>B.</given-names></name>
</person-group><article-title>Fish species recognition using computer vision and a neural network</article-title><source>Fish. Res.</source><year>2001</year><volume>51</volume><fpage>11</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/S0165-7836(00)00254-X</pub-id></element-citation></ref><ref id="B27-sensors-25-01022"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Alsmadi</surname><given-names>M.K.</given-names></name>
<name><surname>Omar</surname><given-names>K.B.</given-names></name>
<name><surname>Noah</surname><given-names>S.A.M.</given-names></name>
</person-group><article-title>Fish classification based on robust features extraction from color signature using back-propagation classifier</article-title><source>J. Comput. Sci.</source><year>2011</year><volume>7</volume><fpage>52</fpage><pub-id pub-id-type="doi">10.3844/jcssp.2011.52.58</pub-id></element-citation></ref><ref id="B28-sensors-25-01022"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pornpanomchai</surname><given-names>C.</given-names></name>
<name><surname>Lurstwut</surname><given-names>B.</given-names></name>
<name><surname>Leerasakultham</surname><given-names>P.</given-names></name>
<name><surname>Kitiyanan</surname><given-names>W.</given-names></name>
</person-group><article-title>Shape-and texture-based fish image recognition system</article-title><source>Kasetsart J.-Nat. Sci.</source><year>2013</year><volume>47</volume><fpage>624</fpage><lpage>634</lpage></element-citation></ref><ref id="B29-sensors-25-01022"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>LeCun</surname><given-names>Y.</given-names></name>
<name><surname>Bengio</surname><given-names>Y.</given-names></name>
<name><surname>Hinton</surname><given-names>G.</given-names></name>
</person-group><article-title>Deep Learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id>
</element-citation></ref><ref id="B30-sensors-25-01022"><label>30.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Krizhevsky</surname><given-names>A.</given-names></name>
<name><surname>Sutskever</surname><given-names>I.</given-names></name>
<name><surname>Hinton</surname><given-names>G.E.</given-names></name>
</person-group><article-title>Imagenet classification with deep convolutional neural networks</article-title><source>Proceedings of the Advances in Neural Information Processing Systems 25 (NIPS 2012)</source><conf-loc>Lake Tahoe, NV, USA</conf-loc><conf-date>3&#x02013;6 December 2012</conf-date><volume>Volume 25</volume></element-citation></ref><ref id="B31-sensors-25-01022"><label>31.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>G.</given-names></name>
<name><surname>Liu</surname><given-names>Z.</given-names></name>
<name><surname>Van Der Maaten</surname><given-names>L.</given-names></name>
<name><surname>Weinberger</surname><given-names>K.Q.</given-names></name>
</person-group><article-title>Densely connected convolutional networks</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Honolulu, HI, USA</conf-loc><conf-date>21&#x02013;26 July 2017</conf-date><fpage>4700</fpage><lpage>4708</lpage></element-citation></ref><ref id="B32-sensors-25-01022"><label>32.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Szegedy</surname><given-names>C.</given-names></name>
<name><surname>Liu</surname><given-names>W.</given-names></name>
<name><surname>Jia</surname><given-names>Y.</given-names></name>
<name><surname>Sermanet</surname><given-names>P.</given-names></name>
<name><surname>Reed</surname><given-names>S.</given-names></name>
<name><surname>Anguelov</surname><given-names>D.</given-names></name>
<name><surname>Erhan</surname><given-names>D.</given-names></name>
<name><surname>Vanhoucke</surname><given-names>V.</given-names></name>
<name><surname>Rabinovich</surname><given-names>A.</given-names></name>
</person-group><article-title>Going deeper with convolutions</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Boston, MA, USA</conf-loc><conf-date>7&#x02013;12 June 2015</conf-date><fpage>1</fpage><lpage>9</lpage></element-citation></ref><ref id="B33-sensors-25-01022"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Howard</surname><given-names>A.G.</given-names></name>
</person-group><article-title>Mobilenets: Efficient convolutional neural networks for mobile vision applications</article-title><source>arXiv</source><year>2017</year><pub-id pub-id-type="arxiv">1704.04861</pub-id></element-citation></ref><ref id="B34-sensors-25-01022"><label>34.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>He</surname><given-names>K.</given-names></name>
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Ren</surname><given-names>S.</given-names></name>
<name><surname>Sun</surname><given-names>J.</given-names></name>
</person-group><article-title>Deep residual learning for image recognition</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>27&#x02013;30 June 2016</conf-date><fpage>770</fpage><lpage>778</lpage></element-citation></ref><ref id="B35-sensors-25-01022"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Simonyan</surname><given-names>K.</given-names></name>
<name><surname>Zisserman</surname><given-names>A.</given-names></name>
</person-group><article-title>Very deep convolutional networks for large-scale image recognition</article-title><source>arXiv</source><year>2014</year><pub-id pub-id-type="arxiv">1409.1556</pub-id></element-citation></ref><ref id="B36-sensors-25-01022"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Deka</surname><given-names>J.</given-names></name>
<name><surname>Laskar</surname><given-names>S.</given-names></name>
<name><surname>Baklial</surname><given-names>B.</given-names></name>
</person-group><article-title>Automated freshwater fish species classification using deep CNN</article-title><source>J. Inst. Eng. Ser. B</source><year>2023</year><volume>104</volume><fpage>603</fpage><lpage>621</lpage><pub-id pub-id-type="doi">10.1007/s40031-023-00883-2</pub-id></element-citation></ref><ref id="B37-sensors-25-01022"><label>37.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Jin</surname><given-names>L.</given-names></name>
<name><surname>Liang</surname><given-names>H.</given-names></name>
</person-group><article-title>Deep learning for underwater image recognition in small sample size situations</article-title><source>Proceedings of the OCEANS 2017-Aberdeen</source><conf-loc>Aberdeen, UK</conf-loc><conf-date>19&#x02013;22 June 2017</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2017</year><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B38-sensors-25-01022"><label>38.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Lan</surname><given-names>X.</given-names></name>
<name><surname>Bai</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>M.</given-names></name>
<name><surname>Li</surname><given-names>J.</given-names></name>
</person-group><article-title>Fish image classification using deep convolutional neural network</article-title><source>Proceedings of the 2020 International Conference on Computers, Information Processing and Advanced Education</source><conf-loc>Ottawa, ON, Canada</conf-loc><conf-date>16&#x02013;18 October 2020</conf-date><fpage>18</fpage><lpage>22</lpage></element-citation></ref><ref id="B39-sensors-25-01022"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hridayami</surname><given-names>P.</given-names></name>
<name><surname>Putra</surname><given-names>I.K.G.D.</given-names></name>
<name><surname>Wibawa</surname><given-names>K.S.</given-names></name>
</person-group><article-title>Fish species recognition using VGG16 deep convolutional neural network</article-title><source>J. Comput. Sci. Eng.</source><year>2019</year><volume>13</volume><fpage>124</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.5626/JCSE.2019.13.3.124</pub-id></element-citation></ref><ref id="B40-sensors-25-01022"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Eickholt</surname><given-names>J.</given-names></name>
<name><surname>Kelly</surname><given-names>D.</given-names></name>
<name><surname>Bryan</surname><given-names>J.</given-names></name>
<name><surname>Miehls</surname><given-names>S.</given-names></name>
<name><surname>Zielinski</surname><given-names>D.</given-names></name>
</person-group><article-title>Advancements towards selective barrier passage by automatic species identification: Applications of deep convolutional neural networks on images of dewatered fish</article-title><source>ICES J. Mar. Sci.</source><year>2020</year><volume>77</volume><fpage>2804</fpage><lpage>2813</lpage><pub-id pub-id-type="doi">10.1093/icesjms/fsaa150</pub-id></element-citation></ref><ref id="B41-sensors-25-01022"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ahmed</surname><given-names>M.A.</given-names></name>
<name><surname>Hossain</surname><given-names>M.S.</given-names></name>
<name><surname>Rahman</surname><given-names>W.</given-names></name>
<name><surname>Uddin</surname><given-names>A.H.</given-names></name>
<name><surname>Islam</surname><given-names>M.T.</given-names></name>
</person-group><article-title>An advanced Bangladeshi local fish classification system based on the combination of deep learning and the internet of things (IoT)</article-title><source>J. Agric. Food Res.</source><year>2023</year><volume>14</volume><fpage>100663</fpage><pub-id pub-id-type="doi">10.1016/j.jafr.2023.100663</pub-id></element-citation></ref><ref id="B42-sensors-25-01022"><label>42.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Khalifa</surname><given-names>N.E.M.</given-names></name>
<name><surname>Taha</surname><given-names>M.H.N.</given-names></name>
<name><surname>Hassanien</surname><given-names>A.E.</given-names></name>
</person-group><article-title>Aquarium family fish species identification system using deep neural networks</article-title><source>Proceedings of the International Conference on Advanced Intelligent Systems and Informatics</source><conf-loc>Cairo, Egypt</conf-loc><conf-date>1&#x02013;3 September 2018</conf-date><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2018</year><fpage>347</fpage><lpage>356</lpage></element-citation></ref><ref id="B43-sensors-25-01022"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Siddiqui</surname><given-names>S.A.</given-names></name>
<name><surname>Salman</surname><given-names>A.</given-names></name>
<name><surname>Malik</surname><given-names>M.I.</given-names></name>
<name><surname>Shafait</surname><given-names>F.</given-names></name>
<name><surname>Mian</surname><given-names>A.</given-names></name>
<name><surname>Shortis</surname><given-names>M.R.</given-names></name>
<name><surname>Harvey</surname><given-names>E.S.</given-names></name>
</person-group><article-title>Automatic fish species classification in underwater videos: Exploiting pre-trained deep neural network models to compensate for limited labelled data</article-title><source>ICES J. Mar. Sci.</source><year>2018</year><volume>75</volume><fpage>374</fpage><lpage>389</lpage><pub-id pub-id-type="doi">10.1093/icesjms/fsx109</pub-id></element-citation></ref><ref id="B44-sensors-25-01022"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Iqbal</surname><given-names>M.A.</given-names></name>
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Ali</surname><given-names>Z.A.</given-names></name>
<name><surname>Riaz</surname><given-names>S.</given-names></name>
</person-group><article-title>Automatic fish species classification using deep convolutional neural networks</article-title><source>Wirel. Pers. Commun.</source><year>2021</year><volume>116</volume><fpage>1043</fpage><lpage>1053</lpage><pub-id pub-id-type="doi">10.1007/s11277-019-06634-1</pub-id></element-citation></ref><ref id="B45-sensors-25-01022"><label>45.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Montalbo</surname><given-names>F.J.P.</given-names></name>
<name><surname>Hernandez</surname><given-names>A.A.</given-names></name>
</person-group><article-title>Classification of fish species with augmented data using deep convolutional neural network</article-title><source>Proceedings of the 2019 IEEE 9th International Conference on System Engineering and Technology (ICSET)</source><conf-loc>Shah Alam, Malaysia</conf-loc><conf-date>7 October 2019</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2019</year><fpage>396</fpage><lpage>401</lpage></element-citation></ref><ref id="B46-sensors-25-01022"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mathur</surname><given-names>M.</given-names></name>
<name><surname>Vasudev</surname><given-names>D.</given-names></name>
<name><surname>Sahoo</surname><given-names>S.</given-names></name>
<name><surname>Jain</surname><given-names>D.</given-names></name>
<name><surname>Goel</surname><given-names>N.</given-names></name>
</person-group><article-title>Crosspooled FishNet: Transfer learning based fish species classification model</article-title><source>Multimed. Tools Appl.</source><year>2020</year><volume>79</volume><fpage>31625</fpage><lpage>31643</lpage><pub-id pub-id-type="doi">10.1007/s11042-020-09371-x</pub-id></element-citation></ref><ref id="B47-sensors-25-01022"><label>47.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Shozib</surname><given-names>K.S.H.</given-names></name>
<name><surname>Kohinoor</surname><given-names>M.S.R.</given-names></name>
</person-group><article-title>Deep Learning-Based Local Fish Classification: A Comparative Study of VGG16 Models and Multiple Classifiers</article-title><source>Proceedings of the 2023 IEEE 11th Region 10 Humanitarian Technology Conference (R10-HTC)</source><conf-loc>Rajkot, India</conf-loc><conf-date>16&#x02013;18 October 2023</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2023</year><fpage>589</fpage><lpage>594</lpage></element-citation></ref><ref id="B48-sensors-25-01022"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ju</surname><given-names>Z.</given-names></name>
<name><surname>Xue</surname><given-names>Y.</given-names></name>
</person-group><article-title>Fish species recognition using an improved AlexNet model</article-title><source>Optik</source><year>2020</year><volume>223</volume><fpage>165499</fpage><pub-id pub-id-type="doi">10.1016/j.ijleo.2020.165499</pub-id></element-citation></ref><ref id="B49-sensors-25-01022"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Murugaiyan</surname><given-names>J.S.</given-names></name>
<name><surname>Palaniappan</surname><given-names>M.</given-names></name>
<name><surname>Durairaj</surname><given-names>T.</given-names></name>
<name><surname>Muthukumar</surname><given-names>V.</given-names></name>
</person-group><article-title>Fish species recognition using transfer learning techniques</article-title><source>Int. J. Adv. Intell. Inform.</source><year>2021</year><volume>7</volume><fpage>188</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.26555/ijain.v7i2.610</pub-id></element-citation></ref><ref id="B50-sensors-25-01022"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mathur</surname><given-names>M.</given-names></name>
<name><surname>Goel</surname><given-names>N.</given-names></name>
</person-group><article-title>FishResNet: Automatic fish classification approach in underwater scenario</article-title><source>SN Comput. Sci.</source><year>2021</year><volume>2</volume><fpage>273</fpage><pub-id pub-id-type="doi">10.1007/s42979-021-00614-8</pub-id></element-citation></ref><ref id="B51-sensors-25-01022"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>Z.</given-names></name>
<name><surname>Du</surname><given-names>X.</given-names></name>
<name><surname>Jin</surname><given-names>L.</given-names></name>
<name><surname>Wang</surname><given-names>S.</given-names></name>
<name><surname>Wang</surname><given-names>L.</given-names></name>
<name><surname>Liu</surname><given-names>X.</given-names></name>
</person-group><article-title>Large-scale underwater fish recognition via deep adversarial learning</article-title><source>Knowl. Inf. Syst.</source><year>2022</year><volume>64</volume><fpage>353</fpage><lpage>379</lpage><pub-id pub-id-type="doi">10.1007/s10115-021-01643-8</pub-id></element-citation></ref><ref id="B52-sensors-25-01022"><label>52.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Tamou</surname><given-names>A.B.</given-names></name>
<name><surname>Benzinou</surname><given-names>A.</given-names></name>
<name><surname>Nasreddine</surname><given-names>K.</given-names></name>
<name><surname>Ballihi</surname><given-names>L.</given-names></name>
</person-group><article-title>Transfer learning with deep convolutional neural network for underwater live fish recognition</article-title><source>Proceedings of the 2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)</source><conf-loc>Antipolis, France</conf-loc><conf-date>12&#x02013;14 December 2018</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2018</year><fpage>204</fpage><lpage>209</lpage></element-citation></ref><ref id="B53-sensors-25-01022"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Huang</surname><given-names>B.</given-names></name>
<name><surname>Chen</surname><given-names>G.</given-names></name>
<name><surname>Radenkovic</surname><given-names>M.</given-names></name>
<name><surname>Hou</surname><given-names>G.</given-names></name>
</person-group><article-title>WildFishNet: Open set wild fish recognition deep neural network with fusion activation pattern</article-title><source>IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.</source><year>2023</year><volume>16</volume><fpage>7303</fpage><lpage>7314</lpage><pub-id pub-id-type="doi">10.1109/JSTARS.2023.3299703</pub-id></element-citation></ref><ref id="B54-sensors-25-01022"><label>54.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Olsvik</surname><given-names>E.</given-names></name>
<name><surname>Trinh</surname><given-names>C.M.</given-names></name>
<name><surname>Knausg&#x000e5;rd</surname><given-names>K.M.</given-names></name>
<name><surname>Wiklund</surname><given-names>A.</given-names></name>
<name><surname>S&#x000f8;rdalen</surname><given-names>T.K.</given-names></name>
<name><surname>Kleiven</surname><given-names>A.R.</given-names></name>
<name><surname>Jiao</surname><given-names>L.</given-names></name>
<name><surname>Goodwin</surname><given-names>M.</given-names></name>
</person-group><article-title>Biometric fish classification of temperate species using convolutional neural network with squeeze-and-excitation</article-title><source>Proceedings of the Advances and Trends in Artificial Intelligence. From Theory to Practice: 32nd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2019</source><conf-loc>Graz, Austria</conf-loc><conf-date>9&#x02013;11 July 2019</conf-date><comment>Proceedings 32</comment><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2019</year><fpage>89</fpage><lpage>101</lpage></element-citation></ref><ref id="B55-sensors-25-01022"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Qiu</surname><given-names>C.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
<name><surname>Wang</surname><given-names>C.</given-names></name>
<name><surname>Yu</surname><given-names>Z.</given-names></name>
<name><surname>Zheng</surname><given-names>H.</given-names></name>
<name><surname>Zheng</surname><given-names>B.</given-names></name>
</person-group><article-title>Improving transfer learning and squeeze-and-excitation networks for small-scale fine-grained fish image classification</article-title><source>IEEE Access</source><year>2018</year><volume>6</volume><fpage>78503</fpage><lpage>78512</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2018.2885055</pub-id></element-citation></ref><ref id="B56-sensors-25-01022"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kaya</surname><given-names>V.</given-names></name>
<name><surname>Akg&#x000fc;l</surname><given-names>&#x00130;.</given-names></name>
<name><surname>Tan&#x00131;r</surname><given-names>&#x000d6;.Z.</given-names></name>
</person-group><article-title>IsVoNet8: A proposed deep learning model for classification of some fish species</article-title><source>J. Agric. Sci.</source><year>2023</year><volume>29</volume><fpage>298</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.15832/ankutbd.1031130</pub-id></element-citation></ref><ref id="B57-sensors-25-01022"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zou</surname><given-names>Z.</given-names></name>
<name><surname>Chen</surname><given-names>K.</given-names></name>
<name><surname>Shi</surname><given-names>Z.</given-names></name>
<name><surname>Guo</surname><given-names>Y.</given-names></name>
<name><surname>Ye</surname><given-names>J.</given-names></name>
</person-group><article-title>Object Detection in 20 Years: A Survey</article-title><source>Proc. IEEE</source><year>2023</year><volume>111</volume><fpage>257</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1109/JPROC.2023.3238524</pub-id></element-citation></ref><ref id="B58-sensors-25-01022"><label>58.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Redmon</surname><given-names>J.</given-names></name>
<name><surname>Divvala</surname><given-names>S.</given-names></name>
<name><surname>Girshick</surname><given-names>R.</given-names></name>
<name><surname>Farhadi</surname><given-names>A.</given-names></name>
</person-group><article-title>You Only Look Once: Unified, Real-Time Object Detection</article-title><source>Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>27&#x02013;30 June 2016</conf-date><fpage>779</fpage><lpage>788</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2016.91</pub-id></element-citation></ref><ref id="B59-sensors-25-01022"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Redmon</surname><given-names>J.</given-names></name>
</person-group><article-title>Yolov3: An incremental improvement</article-title><source>arXiv</source><year>2018</year><pub-id pub-id-type="arxiv">1804.02767</pub-id></element-citation></ref><ref id="B60-sensors-25-01022"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bochkovskiy</surname><given-names>A.</given-names></name>
<name><surname>Wang</surname><given-names>C.Y.</given-names></name>
<name><surname>Liao</surname><given-names>H.Y.M.</given-names></name>
</person-group><article-title>Yolov4: Optimal speed and accuracy of object detection</article-title><source>arXiv</source><year>2020</year><pub-id pub-id-type="arxiv">2004.10934</pub-id></element-citation></ref><ref id="B61-sensors-25-01022"><label>61.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Jocher</surname><given-names>G.</given-names></name>
</person-group><source>Ultralytics YOLOv5</source><publisher-name>Zenodo</publisher-name><publisher-loc>Gen&#x000e8;ve, Switzerland</publisher-loc><year>2020</year><pub-id pub-id-type="doi">10.5281/zenodo.3908559</pub-id></element-citation></ref><ref id="B62-sensors-25-01022"><label>62.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>C.Y.</given-names></name>
<name><surname>Bochkovskiy</surname><given-names>A.</given-names></name>
<name><surname>Liao</surname><given-names>H.Y.M.</given-names></name>
</person-group><article-title>YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</article-title><source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>17&#x02013;24 June 2023</conf-date><fpage>7464</fpage><lpage>7475</lpage></element-citation></ref><ref id="B63-sensors-25-01022"><label>63.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Girshick</surname><given-names>R.</given-names></name>
<name><surname>Donahue</surname><given-names>J.</given-names></name>
<name><surname>Darrell</surname><given-names>T.</given-names></name>
<name><surname>Malik</surname><given-names>J.</given-names></name>
</person-group><article-title>Rich feature hierarchies for accurate object detection and semantic segmentation</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Columbus, OH, USA</conf-loc><conf-date>23&#x02013;28 June 2014</conf-date><fpage>580</fpage><lpage>587</lpage></element-citation></ref><ref id="B64-sensors-25-01022"><label>64.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>W.</given-names></name>
<name><surname>Anguelov</surname><given-names>D.</given-names></name>
<name><surname>Erhan</surname><given-names>D.</given-names></name>
<name><surname>Szegedy</surname><given-names>C.</given-names></name>
<name><surname>Reed</surname><given-names>S.</given-names></name>
<name><surname>Fu</surname><given-names>C.Y.</given-names></name>
<name><surname>Berg</surname><given-names>A.C.</given-names></name>
</person-group><article-title>Ssd: Single shot multibox detector</article-title><source>Proceedings of the Computer Vision&#x02013;ECCV 2016: 14th European Conference</source><conf-loc>Amsterdam, The Netherlands</conf-loc><conf-date>11&#x02013;14 October 2016</conf-date><comment>Proceedings, Part I 14</comment><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2016</year><fpage>21</fpage><lpage>37</lpage></element-citation></ref><ref id="B65-sensors-25-01022"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>Q.</given-names></name>
<name><surname>Gong</surname><given-names>X.</given-names></name>
<name><surname>Li</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>H.</given-names></name>
<name><surname>Liu</surname><given-names>R.</given-names></name>
<name><surname>Liu</surname><given-names>D.</given-names></name>
<name><surname>Zhou</surname><given-names>R.</given-names></name>
<name><surname>Xie</surname><given-names>T.</given-names></name>
<name><surname>Fu</surname><given-names>R.</given-names></name>
<name><surname>Duan</surname><given-names>X.</given-names></name>
</person-group><article-title>A multitask model for realtime fish detection and segmentation based on YOLOv5</article-title><source>PeerJ Comput. Sci.</source><year>2023</year><volume>9</volume><fpage>e1262</fpage><pub-id pub-id-type="doi">10.7717/peerj-cs.1262</pub-id></element-citation></ref><ref id="B66-sensors-25-01022"><label>66.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Long</surname><given-names>W.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Hu</surname><given-names>L.</given-names></name>
<name><surname>Zhang</surname><given-names>J.</given-names></name>
<name><surname>Zhang</surname><given-names>C.</given-names></name>
<name><surname>Jiang</surname><given-names>L.</given-names></name>
<name><surname>Xu</surname><given-names>L.</given-names></name>
</person-group><article-title>Triple Attention Mechanism with YOLOv5s for Fish Detection</article-title><source>Fishes</source><year>2024</year><volume>9</volume><elocation-id>151</elocation-id><pub-id pub-id-type="doi">10.3390/fishes9050151</pub-id></element-citation></ref><ref id="B67-sensors-25-01022"><label>67.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Xu</surname><given-names>W.</given-names></name>
<name><surname>Matzner</surname><given-names>S.</given-names></name>
</person-group><article-title>Underwater fish detection using deep learning for water power applications</article-title><source>Proceedings of the 2018 International Conference on Computational Science and Computational Intelligence (CSCI)</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>13&#x02013;15 December 2018</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2018</year><fpage>313</fpage><lpage>318</lpage></element-citation></ref><ref id="B68-sensors-25-01022"><label>68.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Al Muksit</surname><given-names>A.</given-names></name>
<name><surname>Hasan</surname><given-names>F.</given-names></name>
<name><surname>Emon</surname><given-names>M.F.H.B.</given-names></name>
<name><surname>Haque</surname><given-names>M.R.</given-names></name>
<name><surname>Anwary</surname><given-names>A.R.</given-names></name>
<name><surname>Shatabda</surname><given-names>S.</given-names></name>
</person-group><article-title>YOLO-Fish: A robust fish detection model to detect fish in realistic underwater environment</article-title><source>Ecol. Inform.</source><year>2022</year><volume>72</volume><fpage>101847</fpage><pub-id pub-id-type="doi">10.1016/j.ecoinf.2022.101847</pub-id></element-citation></ref><ref id="B69-sensors-25-01022"><label>69.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Christensen</surname><given-names>J.H.</given-names></name>
<name><surname>Mogensen</surname><given-names>L.V.</given-names></name>
<name><surname>Galeazzi</surname><given-names>R.</given-names></name>
<name><surname>Andersen</surname><given-names>J.C.</given-names></name>
</person-group><article-title>Detection, localization and classification of fish and fish species in poor conditions using convolutional neural networks</article-title><source>Proceedings of the 2018 IEEE/OES Autonomous Underwater Vehicle Workshop (AUV)</source><conf-loc>Porto, Portugal</conf-loc><conf-date>6&#x02013;9 November 2018</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2018</year><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B70-sensors-25-01022"><label>70.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Suharto</surname><given-names>E.</given-names></name>
<name><surname>Widodo</surname><given-names>A.</given-names></name>
<name><surname>Sarwoko</surname><given-names>E.</given-names></name>
</person-group><article-title>The use of mobilenet v1 for identifying various types of freshwater fish</article-title><source>J. Phys. Conf. Ser.</source><year>2020</year><volume>1524</volume><fpage>012105</fpage><pub-id pub-id-type="doi">10.1088/1742-6596/1524/1/012105</pub-id></element-citation></ref><ref id="B71-sensors-25-01022"><label>71.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>J.</given-names></name>
<name><surname>Liu</surname><given-names>C.</given-names></name>
<name><surname>Wang</surname><given-names>L.</given-names></name>
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Li</surname><given-names>R.</given-names></name>
<name><surname>Lu</surname><given-names>X.</given-names></name>
<name><surname>Lu</surname><given-names>J.</given-names></name>
<name><surname>Shen</surname><given-names>J.</given-names></name>
</person-group><article-title>Multi-species identification and number counting of fish passing through fishway at hydropower stations with LigTraNet</article-title><source>Ecol. Inform.</source><year>2024</year><volume>82</volume><fpage>102704</fpage><pub-id pub-id-type="doi">10.1016/j.ecoinf.2024.102704</pub-id></element-citation></ref><ref id="B72-sensors-25-01022"><label>72.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Knausg&#x000e5;rd</surname><given-names>K.M.</given-names></name>
<name><surname>Wiklund</surname><given-names>A.</given-names></name>
<name><surname>S&#x000f8;rdalen</surname><given-names>T.K.</given-names></name>
<name><surname>Halvorsen</surname><given-names>K.T.</given-names></name>
<name><surname>Kleiven</surname><given-names>A.R.</given-names></name>
<name><surname>Jiao</surname><given-names>L.</given-names></name>
<name><surname>Goodwin</surname><given-names>M.</given-names></name>
</person-group><article-title>Temperate fish detection and classification: A deep learning based approach</article-title><source>Appl. Intell.</source><year>2022</year><volume>52</volume><fpage>6988</fpage><lpage>7001</lpage><pub-id pub-id-type="doi">10.1007/s10489-020-02154-9</pub-id></element-citation></ref><ref id="B73-sensors-25-01022"><label>73.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hamzaoui</surname><given-names>M.</given-names></name>
<name><surname>Ould-Elhassen Aoueileyine</surname><given-names>M.</given-names></name>
<name><surname>Romdhani</surname><given-names>L.</given-names></name>
<name><surname>Bouallegue</surname><given-names>R.</given-names></name>
</person-group><article-title>An Improved Deep Learning Model for Underwater Species Recognition in Aquaculture</article-title><source>Fishes</source><year>2023</year><volume>8</volume><elocation-id>514</elocation-id><pub-id pub-id-type="doi">10.3390/fishes8100514</pub-id></element-citation></ref><ref id="B74-sensors-25-01022"><label>74.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ben Tamou</surname><given-names>A.</given-names></name>
<name><surname>Benzinou</surname><given-names>A.</given-names></name>
<name><surname>Nasreddine</surname><given-names>K.</given-names></name>
</person-group><article-title>Multi-stream fish detection in unconstrained underwater videos by the fusion of two convolutional neural network detectors</article-title><source>Appl. Intell.</source><year>2021</year><volume>51</volume><fpage>5809</fpage><lpage>5821</lpage><pub-id pub-id-type="doi">10.1007/s10489-020-02155-8</pub-id></element-citation></ref><ref id="B75-sensors-25-01022"><label>75.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jalal</surname><given-names>A.</given-names></name>
<name><surname>Salman</surname><given-names>A.</given-names></name>
<name><surname>Mian</surname><given-names>A.</given-names></name>
<name><surname>Shortis</surname><given-names>M.</given-names></name>
<name><surname>Shafait</surname><given-names>F.</given-names></name>
</person-group><article-title>Fish detection and species classification in underwater environments using deep learning with temporal information</article-title><source>Ecol. Inform.</source><year>2020</year><volume>57</volume><fpage>101088</fpage><pub-id pub-id-type="doi">10.1016/j.ecoinf.2020.101088</pub-id></element-citation></ref><ref id="B76-sensors-25-01022"><label>76.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ben Tamou</surname><given-names>A.</given-names></name>
<name><surname>Benzinou</surname><given-names>A.</given-names></name>
<name><surname>Nasreddine</surname><given-names>K.</given-names></name>
</person-group><article-title>Live fish species classification in underwater images by using convolutional neural networks based on incremental learning with knowledge distillation loss</article-title><source>Mach. Learn. Knowl. Extr.</source><year>2022</year><volume>4</volume><fpage>753</fpage><lpage>767</lpage><pub-id pub-id-type="doi">10.3390/make4030036</pub-id></element-citation></ref><ref id="B77-sensors-25-01022"><label>77.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kuswantori</surname><given-names>A.</given-names></name>
<name><surname>Suesut</surname><given-names>T.</given-names></name>
<name><surname>Tangsrirat</surname><given-names>W.</given-names></name>
<name><surname>Schleining</surname><given-names>G.</given-names></name>
<name><surname>Nunak</surname><given-names>N.</given-names></name>
</person-group><article-title>Fish Detection and Classification for Automatic Sorting System with an Optimized YOLO Algorithm</article-title><source>Appl. Sci.</source><year>2023</year><volume>13</volume><elocation-id>3812</elocation-id><pub-id pub-id-type="doi">10.3390/app13063812</pub-id></element-citation></ref><ref id="B78-sensors-25-01022"><label>78.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ovalle</surname><given-names>J.C.</given-names></name>
<name><surname>Vilas</surname><given-names>C.</given-names></name>
<name><surname>Antelo</surname><given-names>L.T.</given-names></name>
</person-group><article-title>On the use of deep learning for fish species recognition and quantification on board fishing vessels</article-title><source>Mar. Policy</source><year>2022</year><volume>139</volume><fpage>105015</fpage><pub-id pub-id-type="doi">10.1016/j.marpol.2022.105015</pub-id></element-citation></ref><ref id="B79-sensors-25-01022"><label>79.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Garavelli</surname><given-names>L.</given-names></name>
<name><surname>Linley</surname><given-names>T.J.</given-names></name>
<name><surname>Bellgraph</surname><given-names>B.J.</given-names></name>
<name><surname>Rhode</surname><given-names>B.M.</given-names></name>
<name><surname>Janak</surname><given-names>J.M.</given-names></name>
<name><surname>Colotelo</surname><given-names>A.H.</given-names></name>
</person-group><article-title>Evaluation of passage and sorting of adult Pacific salmonids through a novel fish passage technology</article-title><source>Fish. Res.</source><year>2019</year><volume>212</volume><fpage>40</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/j.fishres.2018.12.010</pub-id></element-citation></ref><ref id="B80-sensors-25-01022"><label>80.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zielinski</surname><given-names>D.</given-names></name>
<name><surname>Freiburger</surname><given-names>C.</given-names></name>
</person-group><article-title>Advances in fish passage in the Great Lakes basin</article-title><source>J. Great Lakes Res.</source><year>2021</year><volume>47</volume><issue>(Suppl. 1)</issue><fpage>S439</fpage><lpage>S447</lpage><pub-id pub-id-type="doi">10.1016/j.jglr.2020.03.008</pub-id></element-citation></ref><ref id="B81-sensors-25-01022"><label>81.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Jagadeesan</surname><given-names>S.M.</given-names></name>
<name><surname>Leh</surname><given-names>J.</given-names></name>
<name><surname>Gregory</surname><given-names>J.</given-names></name>
<name><surname>Eickholt</surname><given-names>J.</given-names></name>
<name><surname>Zielinski</surname><given-names>D.P.</given-names></name>
</person-group><article-title>Evaluating the Effectiveness of an Object Detection Pipeline to Support Surveillance of Unintended Passage</article-title><source>Proceedings of the 2024 IEEE 3rd International Conference on Computing and Machine Intelligence (ICMI)</source><conf-loc>Mt Pleasant, MI, USA</conf-loc><conf-date>13&#x02013;14 April 2024</conf-date><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1109/ICMI60790.2024.10585634</pub-id></element-citation></ref><ref id="B82-sensors-25-01022"><label>82.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cao</surname><given-names>K.</given-names></name>
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Meng</surname><given-names>G.</given-names></name>
<name><surname>Sun</surname><given-names>Q.</given-names></name>
</person-group><article-title>An Overview on Edge Computing Research</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>85714</fpage><lpage>85728</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2991734</pub-id></element-citation></ref><ref id="B83-sensors-25-01022"><label>83.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Blackshear</surname><given-names>B.</given-names></name>
<name><surname>Mowen</surname><given-names>N.</given-names></name>
<name><surname>Hawkins</surname><given-names>J.</given-names></name>
</person-group><article-title>Frigate</article-title><year>2024</year><comment>Available online: <ext-link xlink:href="https://github.com/blakeblackshear/frigate" ext-link-type="uri">https://github.com/blakeblackshear/frigate</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-02">(accessed on 2 November 2024)</date-in-citation></element-citation></ref><ref id="B84-sensors-25-01022"><label>84.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<collab>Tensorflow</collab>
</person-group><article-title>Ssd_mobilenet_v2</article-title><year>2020</year><comment>Available online: <ext-link xlink:href="https://www.kaggle.com/models/tensorflow/ssd-mobilenet-v2/tensorFlow2/fpnlite-320x320/1?tfhub-redirect=true" ext-link-type="uri">https://www.kaggle.com/models/tensorflow/ssd-mobilenet-v2/tensorFlow2/fpnlite-320x320/1?tfhub-redirect=true</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-05-11">(accessed on 11 May 2024)</date-in-citation></element-citation></ref><ref id="B85-sensors-25-01022"><label>85.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bradski</surname><given-names>G.</given-names></name>
</person-group><article-title>The OpenCV Library</article-title><source>Dr. Dobb&#x02019;s J. Softw. Tools</source><year>2000</year><volume>25</volume><fpage>120</fpage><lpage>125</lpage></element-citation></ref><ref id="B86-sensors-25-01022"><label>86.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Thakur</surname><given-names>A.</given-names></name>
<name><surname>Papakipos</surname><given-names>Z.</given-names></name>
<name><surname>Clauss</surname><given-names>C.</given-names></name>
<name><surname>Hollinger</surname><given-names>C.</given-names></name>
<name><surname>Andolina</surname><given-names>I.M.</given-names></name>
<name><surname>Boivin</surname><given-names>V.</given-names></name>
<name><surname>Ahn</surname><given-names>K.</given-names></name>
<name><surname>freol35241</surname></name>
<name><surname>Lowe</surname><given-names>B.</given-names></name>
<name><surname>Schoentgen</surname><given-names>M.</given-names></name>
<etal/>
</person-group><source>abhiTronix/vidgear: VidGear Stable</source><comment>v0.3.2</comment><publisher-name>Zenodo</publisher-name><publisher-loc>Gen&#x000e8;ve, Switzerland</publisher-loc><year>2023</year><pub-id pub-id-type="doi">10.5281/zenodo.8332548</pub-id></element-citation></ref><ref id="B87-sensors-25-01022"><label>87.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Benezeth</surname><given-names>Y.</given-names></name>
<name><surname>Jodoin</surname><given-names>P.</given-names></name>
<name><surname>Emile</surname><given-names>B.</given-names></name>
<name><surname>Laurent</surname><given-names>H.</given-names></name>
<name><surname>Rosenberger</surname><given-names>C.</given-names></name>
</person-group><article-title>Review and Evaluation of Commonly-Implemented Background Subtraction Algorithms</article-title><source>Proceedings of the 2008 19th International Conference on Pattern Recognition</source><conf-loc>Tampa, FL, USA</conf-loc><conf-date>8&#x02013;11 December 2008</conf-date><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1109/ICPR.2008.4760998</pub-id></element-citation></ref><ref id="B88-sensors-25-01022"><label>88.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Tkachenko</surname><given-names>M.</given-names></name>
<name><surname>Malyuk</surname><given-names>M.</given-names></name>
<name><surname>Holmanyuk</surname><given-names>A.</given-names></name>
<name><surname>Liubimov</surname><given-names>N.</given-names></name>
</person-group><article-title>Label Studio: Data Labeling Software, 2020&#x02013;2024. Open Source Software</article-title><comment>Available online: <ext-link xlink:href="https://github.com/HumanSignal/label-studio" ext-link-type="uri">https://github.com/HumanSignal/label-studio</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-02">(accessed on 2 November 2024)</date-in-citation></element-citation></ref><ref id="B89-sensors-25-01022"><label>89.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Miehls</surname><given-names>S.M.</given-names></name>
<name><surname>Alger</surname><given-names>B.J.</given-names></name>
<name><surname>Buechel</surname><given-names>B.A.</given-names></name>
<name><surname>Wright</surname><given-names>C.S.</given-names></name>
<name><surname>Zielinski</surname><given-names>D.P.</given-names></name>
<name><surname>Bryan</surname><given-names>J.T.</given-names></name>
<name><surname>Becker</surname><given-names>M.M.</given-names></name>
<name><surname>Bruning</surname><given-names>T.M.</given-names></name>
<name><surname>Wickert</surname><given-names>Z.J.</given-names></name>
<name><surname>Pokorzynski</surname><given-names>R.A.</given-names></name>
</person-group><source>Image and Biometric Data for Fish from Great Lakes Tributaries Collected During Spring 2019</source><publisher-name>USGS Great Lakes Science Center</publisher-name><publisher-loc>Ann Arbor, MI, USA</publisher-loc><year>2020</year></element-citation></ref><ref id="B90-sensors-25-01022"><label>90.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Abadi</surname><given-names>M.</given-names></name>
<name><surname>Agarwal</surname><given-names>A.</given-names></name>
<name><surname>Barham</surname><given-names>P.</given-names></name>
<name><surname>Brevdo</surname><given-names>E.</given-names></name>
<name><surname>Chen</surname><given-names>Z.</given-names></name>
<name><surname>Citro</surname><given-names>C.</given-names></name>
<name><surname>Corrado</surname><given-names>G.S.</given-names></name>
<name><surname>Davis</surname><given-names>A.</given-names></name>
<name><surname>Dean</surname><given-names>J.</given-names></name>
<name><surname>Devin</surname><given-names>M.</given-names></name>
<etal/>
</person-group><article-title>TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, 2015</article-title><comment>Available online: <ext-link xlink:href="https://www.tensorflow.org" ext-link-type="uri">https://www.tensorflow.org</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-04">(accessed on 4 November 2024)</date-in-citation></element-citation></ref><ref id="B91-sensors-25-01022"><label>91.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>J.</given-names></name>
<name><surname>Rathod</surname><given-names>V.</given-names></name>
<name><surname>Sun</surname><given-names>C.</given-names></name>
<name><surname>Zhu</surname><given-names>M.</given-names></name>
<name><surname>Korattikara</surname><given-names>A.</given-names></name>
<name><surname>Fathi</surname><given-names>A.</given-names></name>
<name><surname>Fischer</surname><given-names>I.</given-names></name>
<name><surname>Wojna</surname><given-names>Z.</given-names></name>
<name><surname>Song</surname><given-names>Y.</given-names></name>
<name><surname>Guadarrama</surname><given-names>S.</given-names></name>
<etal/>
</person-group><article-title>Speed/accuracy trade-offs for modern convolutional object detectors</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Honolulu, HI, USA</conf-loc><conf-date>21&#x02013;26 July 2017</conf-date><fpage>7310</fpage><lpage>7311</lpage></element-citation></ref><ref id="B92-sensors-25-01022"><label>92.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Yu</surname><given-names>H.</given-names></name>
<name><surname>Chen</surname><given-names>C.</given-names></name>
<name><surname>Du</surname><given-names>X.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Rashwan</surname><given-names>A.</given-names></name>
<name><surname>Hou</surname><given-names>L.</given-names></name>
<name><surname>Jin</surname><given-names>P.</given-names></name>
<name><surname>Yang</surname><given-names>F.</given-names></name>
<name><surname>Liu</surname><given-names>F.</given-names></name>
<name><surname>Kim</surname><given-names>J.</given-names></name>
<etal/>
</person-group><article-title>TensorFlow Model Garden</article-title><year>2020</year><comment>Available online: <ext-link xlink:href="https://github.com/tensorflow/models" ext-link-type="uri">https://github.com/tensorflow/models</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-04">(accessed on 4 November 2024)</date-in-citation></element-citation></ref><ref id="B93-sensors-25-01022"><label>93.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Dollar</surname><given-names>P.</given-names></name>
<name><surname>Lin</surname><given-names>T.Y.</given-names></name>
<name><surname>Souri</surname><given-names>Y.</given-names></name>
<name><surname>Benenson</surname><given-names>R.</given-names></name>
<name><surname>Girshick</surname><given-names>R.</given-names></name>
<name><surname>Wu</surname><given-names>Y.</given-names></name>
<name><surname>Pepose</surname><given-names>S.</given-names></name>
<name><surname>Clauss</surname><given-names>C.</given-names></name>
<name><surname>Zagoruyko</surname><given-names>S.</given-names></name>
<name><surname>Johnqczhang</surname></name>
<etal/>
</person-group><article-title>Cocoapi</article-title><year>2020</year><comment>Available online: <ext-link xlink:href="https://github.com/cocodataset/cocoapi/tree/master" ext-link-type="uri">https://github.com/cocodataset/cocoapi/tree/master</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-04">(accessed on 4 November 2024)</date-in-citation></element-citation></ref><ref id="B94-sensors-25-01022"><label>94.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Kud</surname><given-names>I.</given-names></name>
<name><surname>Abramov</surname><given-names>O.</given-names></name>
<collab>GMetola</collab>
</person-group><article-title>Fake RTSP Stream</article-title><year>2023</year><comment>Available online: <ext-link xlink:href="https://github.com/insight-platform/Fake-RTSP-Stream" ext-link-type="uri">https://github.com/insight-platform/Fake-RTSP-Stream</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-11-12">(accessed on 12 November 2024)</date-in-citation></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01022-f001"><label>Figure 1</label><caption><p>The four camera angles in the ASFL video chamber capturing videos of a fish passing through the chamber. From the top left: Panel (<bold>a</bold>) shows the front overhead camera. Panel (<bold>b</bold>) shows the back overhead camera. Panel (<bold>c</bold>) shows the left camera. Panel (<bold>d</bold>) shows the right camera.</p></caption><graphic xlink:href="sensors-25-01022-g001" position="float"/></fig><fig position="float" id="sensors-25-01022-f002"><label>Figure 2</label><caption><p>An image containing a fish labeled by hand using Label Studio.</p></caption><graphic xlink:href="sensors-25-01022-g002" position="float"/></fig><fig position="float" id="sensors-25-01022-f003"><label>Figure 3</label><caption><p>A sequence of ASFL-Single-Detect&#x02019;s predictions on a rock bass reorienting itself while passing through the ASFL video capture chamber. From the top left: Panel (<bold>a</bold>) shows the fish is initial position. Panel (<bold>b</bold>) shows the fish launching itself into the air. Panel (<bold>c</bold>) shows the fish contorting itself in the air. Panel (<bold>d</bold>) shows the fish landing in the chamber in a new position.</p></caption><graphic xlink:href="sensors-25-01022-g003" position="float"/></fig><fig position="float" id="sensors-25-01022-f004"><label>Figure 4</label><caption><p>An image containing a sea lamprey successfully predicted by USGS-Multi-Detect.</p></caption><graphic xlink:href="sensors-25-01022-g004" position="float"/></fig><table-wrap position="float" id="sensors-25-01022-t001"><object-id pub-id-type="pii">sensors-25-01022-t001_Table 1</object-id><label>Table 1</label><caption><p>The time recorded, common name, and scientific name of fish extracted from the ASFL video chamber recordings.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Time Recorded</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Common Name</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Scientific Name</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">25 April 2024 16:54</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">25 April 2024 22:42</td><td align="left" valign="middle" rowspan="1" colspan="1">Rock Bass</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Ambloplites&#x000a0;rupestris</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">25 April 2024 22:47</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">25 April 2024 23:08</td><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;catostomus</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">25 April 2024 23:50</td><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;catostomus</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">26 April 2024 00:58</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">26 April 2024 01:04</td><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;catostomus</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">26 April 2024 01:13</td><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;catostomus</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">26 April 2024 01:37</td><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;catostomus</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">26 April 2024 22:57</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">27 April 2024 00:28</td><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;catostomus</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">27 April 2024 01:19</td><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;catostomus</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">27 April 2024 03:46</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">27 April 2024 22:15</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">27 April 2024 23:24</td><td align="left" valign="middle" rowspan="1" colspan="1">Steelhead Trout</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus&#x000a0;mykiss</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">28 April 2024 04:30</td><td align="left" valign="middle" rowspan="1" colspan="1">Steelhead Trout</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus&#x000a0;mykiss</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">29 April 2024 01:01</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">29 April 2024 23:59</td><td align="left" valign="middle" rowspan="1" colspan="1">Steelhead Trout</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus&#x000a0;mykiss</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">30 April 2024 02:49</td><td align="left" valign="middle" rowspan="1" colspan="1">Steelhead Trout</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus&#x000a0;mykiss</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">30 April 2024 18:48</td><td align="left" valign="middle" rowspan="1" colspan="1">Common Carp</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Cyprinus&#x000a0;carpio</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2 May 2024 13:38</td><td align="left" valign="middle" rowspan="1" colspan="1">Largemouth Bass</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Micropterus&#x000a0;salmoides</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2 May 2024 14:12</td><td align="left" valign="middle" rowspan="1" colspan="1">Largemouth Bass</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Micropterus&#x000a0;salmoides</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3 May 2024 02:02</td><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus&#x000a0;commersonii</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3 May 2024 19:59</td><td align="left" valign="middle" rowspan="1" colspan="1">Smallmouth Bass</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Micropterus&#x000a0;dolomieu</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4 May 2024 15:28</td><td align="left" valign="middle" rowspan="1" colspan="1">Smallmouth Bass</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Micropterus&#x000a0;dolomieu</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4 May 2024 21:44</td><td align="left" valign="middle" rowspan="1" colspan="1">Bowfin</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Amia&#x000a0;calva</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">10 May 2024 01:55</td><td align="left" valign="middle" rowspan="1" colspan="1">Steelhead Trout</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus&#x000a0;mykiss</italic>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">11 May 2024 04:27</td><td align="left" valign="middle" rowspan="1" colspan="1">Steelhead Trout</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus&#x000a0;mykiss</italic>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14 May 2024 21:00</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Steelhead Trout</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus&#x000a0;mykiss</italic>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t002"><object-id pub-id-type="pii">sensors-25-01022-t002_Table 2</object-id><label>Table 2</label><caption><p>The common names, scientific names, and counts of fish in the USGS-Multi dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Common Name</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Scientific Name</th><th align="right" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Count</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">Bighead Carp</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Hypophthalmichthys nobilis</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">32</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Common Carp</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Cyprinus carpio</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">102</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Common White Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus commersonii</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">1689</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Gar</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Lepisosteus osseus</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">34</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Longnose Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Catostomus catostomus</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">1580</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Quillback Carpsucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Carpiodes cyprinus</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">181</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Rainbow Trout</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Oncorhynchus mykiss</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">676</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Redhorse Sucker</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Moxostoma carinatum</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">81</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Sea Lamprey</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Petromyzon marinus</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">1409</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Silver Carp</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Hypophthalmichthys molitrix</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">1417</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Smallmouth Bass</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Micropterus dolomieu</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">27</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Smallmouth Buffalo</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Ictiobus bubalus</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">216</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Walleye</td><td align="left" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">Sander vitreus</italic>
</td><td align="right" valign="middle" rowspan="1" colspan="1">2034</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">White Bass</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">Morone chrysops</italic>
</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t003"><object-id pub-id-type="pii">sensors-25-01022-t003_Table 3</object-id><label>Table 3</label><caption><p>Summary of the fish detection datasets created for this research.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Dataset Name</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Source</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Task</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number of Species</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number of Annotations in Training Dataset</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number of Annotations in Evaluation Dataset</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">ASFL-Single</td><td align="center" valign="middle" rowspan="1" colspan="1">ASFL</td><td align="center" valign="middle" rowspan="1" colspan="1">Single-Class Detection (i.e., &#x0201c;Fish&#x0201d;)</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">3276</td><td align="center" valign="middle" rowspan="1" colspan="1">764</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">ASFL-Multi</td><td align="center" valign="middle" rowspan="1" colspan="1">ASFL</td><td align="center" valign="middle" rowspan="1" colspan="1">Multi-Class Detection (i.e., species label)</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">3183</td><td align="center" valign="middle" rowspan="1" colspan="1">594</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">USGS-Multi</td><td align="center" valign="middle" rowspan="1" colspan="1">USGS</td><td align="center" valign="middle" rowspan="1" colspan="1">Multi-Class Detection</td><td align="center" valign="middle" rowspan="1" colspan="1">14</td><td align="center" valign="middle" rowspan="1" colspan="1">7611</td><td align="center" valign="middle" rowspan="1" colspan="1">1899</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Combined-Multi</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">USGS &#x00026; ASFL</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Multi-Class Detection</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7254</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1357</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t004"><object-id pub-id-type="pii">sensors-25-01022-t004_Table 4</object-id><label>Table 4</label><caption><p>An example classification confusion matrix, precision (Pr), and recall (R) for a three-class problem with A, B, and C labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">True (T)\Predicted (P)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">A</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">B</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">C</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Precision (Pr)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Recall (R)</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>A</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>B</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>C</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t005"><object-id pub-id-type="pii">sensors-25-01022-t005_Table 5</object-id><label>Table 5</label><caption><p>The classification confusion matrix, precision (Pr), and recall (R) for ASFL-Single-Detect evaluated on the ASFL-Single evaluation dataset with background (BG) and Fish class labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">T\P</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Fish</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Pr</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">R</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Fish</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">31</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">733</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.96</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t006"><object-id pub-id-type="pii">sensors-25-01022-t006_Table 6</object-id><label>Table 6</label><caption><p>The classification confusion matrix, precision (Pr), and recall (R) for ASFL-Multi-Detect evaluated on the ASFL-Multi evaluation dataset with background (BG), common white sucker (CWS), longnose sucker (LNS), smallmouth bass (SMB), steelhead (STL), and largemouth bass (LB) labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">T\P</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CWS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LNS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SMB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">STL</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Pr</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">R</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CWS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">115</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.39</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.66</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LNS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">164</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">34</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">38</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.89</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.14</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SMB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">37</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>STL</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">53</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.27</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.87</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">19</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.18</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t007"><object-id pub-id-type="pii">sensors-25-01022-t007_Table 7</object-id><label>Table 7</label><caption><p>The classification confusion matrix, precision (Pr), and recall (R) for USGS-Multi-Detect evaluated on the USGS-Multi evaluation dataset with background (BG), common white sucker (CWS), longnose sucker (LNS), smallmouth bass (SMB), steelhead (STL), common carp (CC), bighead carp (BC), longnose gar (LG), quillback carpsucker (QC), redhorse sucker (RS), sea lamprey (SL), silver carp (SC), smallmouth buffalo (SB), walleye (W), and white bass (WB) labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">T\P</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CWS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LNS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SMB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">STL</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">QC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">RS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SL</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">W</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">WB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Pr</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">R</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CWS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">316</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.79</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.95</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LNS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">235</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.95</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.79</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SMB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.44</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>STL</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">148</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.99</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.97</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.90</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.40</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>QC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.94</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>RS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.50</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SL</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">245</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.95</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">297</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.99</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.99</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">44</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.96</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>W</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">379</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.96</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.91</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>WB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t008"><object-id pub-id-type="pii">sensors-25-01022-t008_Table 8</object-id><label>Table 8</label><caption><p>The classification confusion matrix, precision (Pr), and recall (R) for Combined-Multi-Detect evaluated on the Combined-Multi evaluation dataset with background (BG), common white sucker (CWS), longnose sucker (LNS), smallmouth bass (SMB), steelhead (STL), largemouth bass (LB), common carp (CC), bighead carp (BC), longnose gar (LG), quillback carpsucker (QC), redhorse sucker (RS), sea lamprey (SL), silver carp (SC), smallmouth buffalo (SB), walleye (W), and white bass (WB) labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">T\P</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CWS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LNS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SMB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">STL</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">QC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">RS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SL</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">W</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">WB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Pr</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">R</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CWS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">231</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">47</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.44</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.80</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LNS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">200</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">134</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.99</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.38</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SMB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">34</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.31</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.08</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>STL</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">108</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.47</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.96</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.30</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.04</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.33</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.50</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>QC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.75</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>RS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SL</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">127</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.99</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">123</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.98</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.98</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.88</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>W</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">34</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.98</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.72</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>WB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t009"><object-id pub-id-type="pii">sensors-25-01022-t009_Table 9</object-id><label>Table 9</label><caption><p>The classification confusion matrix, precision (Pr), and recall (R) for Combined-Multi-Detect evaluated on the ASFL-Multi evaulation set with background (BG), common white sucker (CWS), longnose sucker (LNS), smallmouth bass (SMB), steelhead (STL), and largemouth bass (LB) labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">T\P</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CWS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LNS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SMB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">STL</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Pr</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">R</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CWS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">118</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">47</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.42</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.67</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LNS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">137</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.36</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SMB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.08</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>STL</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">59</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.36</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.97</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.30</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01022-t010"><object-id pub-id-type="pii">sensors-25-01022-t010_Table 10</object-id><label>Table 10</label><caption><p>The classification confusion matrix, precision (Pr), and recall (R) for Combined-Multi-DetectQ running in the simulated edge environment on videos containing a subset of its ASFL evaluation data with background (BG), common white sucker (CWS), longnose sucker (LNS), smallmouth bass (SMB), steelhead (STL), largemouth bass (LB), and common carp (CC) labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">T\P</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">BG</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CWS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LNS</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">SMB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">STL</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CC</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Pr</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">R</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>BG</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CWS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LNS</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>SMB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>STL</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>LB</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>CC</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.00</td></tr></tbody></table></table-wrap></floats-group></article>