<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Imaging Inform Med</journal-id><journal-id journal-id-type="iso-abbrev">J Imaging Inform Med</journal-id><journal-title-group><journal-title>Journal of Imaging Informatics in Medicine</journal-title></journal-title-group><issn pub-type="ppub">2948-2925</issn><issn pub-type="epub">2948-2933</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39407048</article-id><article-id pub-id-type="pmc">PMC12092920</article-id>
<article-id pub-id-type="publisher-id">1291</article-id><article-id pub-id-type="doi">10.1007/s10278-024-01291-8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>A Machine Learning Model Based on Global Mammographic Radiomic Features Can Predict Which Normal Mammographic Cases Radiology Trainees Find Most Difficult</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2891-9217</contrib-id><name><surname>Siviengphanom</surname><given-names>Somphone</given-names></name><address><email>ssiv6387@uni.sydney.edu.au</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Brennan</surname><given-names>Patrick C.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Lewis</surname><given-names>Sarah J.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Trieu</surname><given-names>Phuong Dung</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Gandomkar</surname><given-names>Ziba</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0384j8v12</institution-id><institution-id institution-id-type="GRID">grid.1013.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 834X</institution-id><institution>Medical Image Optimisation and Perception Group, Discipline of Medical Imaging Science, Faculty of Medicine and Health, </institution><institution>Sydney School of Health Sciences, Susan Wakil Health Building D18, the University of Sydney, </institution></institution-wrap>Sydney, NSW 2006 Australia </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03t52dk35</institution-id><institution-id institution-id-type="GRID">grid.1029.a</institution-id><institution-id institution-id-type="ISNI">0000 0000 9939 5719</institution-id><institution>School of Health Sciences, </institution><institution>Western Sydney University, </institution></institution-wrap>Sydney, NSW 2751 Australia </aff></contrib-group><pub-date pub-type="epub"><day>15</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>15</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="collection"><month>6</month><year>2025</year></pub-date><volume>38</volume><issue>3</issue><fpage>1904</fpage><lpage>1913</lpage><history><date date-type="received"><day>1</day><month>6</month><year>2024</year></date><date date-type="rev-recd"><day>28</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>30</day><month>9</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; Crown 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">This study aims to investigate whether global mammographic radiomic features (GMRFs) can distinguish <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases for radiology trainees (RTs). Data from 137 RTs were analysed, with each interpreting seven educational self-assessment test sets comprising 60 cases (40 normal and 20 cancer). The study only examined normal cases. Difficulty scores were computed based on the percentage of readers who incorrectly classified each case, leading to their classification as <italic>hardest-</italic> or <italic>easiest-to-interpret</italic> based on whether their difficulty scores fell within and above the 75th or within and below the 25th percentile, respectively (resulted in 140 cases in total used). Fifty-nine <italic>low-density</italic> and 81 <italic>high-density</italic> cases were identified. Thirty-four GMRFs were extracted for each case. A random forest machine learning model was trained to differentiate between <italic>hardest-</italic> and <italic>easiest-to-interpret</italic> normal cases and validated using leave-one-out-cross-validation approach. The model&#x02019;s performance was evaluated using the area under receiver operating characteristic curve (AUC). Significant features were identified through feature importance analysis. Difference between <italic>hardest-</italic> and <italic>easiest-to-interpret</italic> cases among 34 GMRFs and in difficulty level between <italic>low-</italic> and <italic>high-density</italic> cases was tested using Kruskal&#x02013;Wallis. The model achieved AUC&#x02009;=&#x02009;0.75 with <italic>cluster prominence</italic> and <italic>range</italic> emerging as the most useful features. Fifteen GMRFs differed significantly (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05) between <italic>hardest-</italic> and <italic>easiest-to-interpret</italic> cases. Difficulty level among <italic>low-</italic> vs <italic>high-density</italic> cases did not differ significantly (<italic>p</italic>&#x02009;=&#x02009;0.12). GMRFs can predict <italic>hardest-to-interpret</italic> normal cases for RTs, underscoring the importance of GMRFs in identifying the most difficult normal cases for RTs and facilitating customised training programmes tailored to trainees&#x02019; learning needs.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Radiomics</kwd><kwd>Mammography</kwd><kwd>Difficult normal cases</kwd><kwd>Radiology trainees</kwd><kwd>Machine learning</kwd><kwd>Gist</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001171</institution-id><institution>Cancer Institute NSW</institution></institution-wrap></funding-source><award-id>2022/ECF1426</award-id><principal-award-recipient><name><surname>Gandomkar</surname><given-names>Ziba</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000925</institution-id><institution>National Health and Medical Research Council</institution></institution-wrap></funding-source><award-id>APP1162872</award-id><principal-award-recipient><name><surname>Brennan</surname><given-names>Patrick C.</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001026</institution-id><institution>National Breast Cancer Foundation</institution></institution-wrap></funding-source><award-id>IIRS-18-089</award-id><principal-award-recipient><name><surname>Brennan</surname><given-names>Patrick C.</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution>University of Sydney</institution></funding-source></award-group><open-access><p>Open Access funding enabled and organized by CAUL and its Member Institutions</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Society for Imaging Informatics in Medicine 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par16">Female breast cancer (BC) stands as one of the leading causes of cancer-related mortality worldwide [<xref ref-type="bibr" rid="CR1">1</xref>]. Mammographic screening programmes, aimed at early detection of BC, have been shown to significantly reduce BC mortality rate by up to 40% [<xref ref-type="bibr" rid="CR2">2</xref>]. However, interpreting mammograms is a challenging task susceptible to errors, and relying primarily on technological advancements is insufficient to mitigate or address these challenges [<xref ref-type="bibr" rid="CR3">3</xref>]. Previous studies have reported that correctly interpretating normal cancer-free mammograms can also be highly difficult for readers with inadequate mammographic reading experience such as radiology trainees (RTs) [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>]. The capability of readers including RTs to accurately interpret screening mammograms plays a pivotal role in the efficacy of breast screening programmes. Despite efforts to propose criteria for screen reader certification aimed at reducing diagnostic variability among readers, none of the current guidelines for these criteria serve as strong predictors of reader performance [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>]. As a result, wide inter-reader variability persists, highlighting the critical need to prioritise education and training for readers, especially for less experienced readers like RTs, in this domain [<xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR9">9</xref>]. Given that normal cases comprise over 99% of all cases in breast screening programmes [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>], along with the fact that false-positive screening results cause huge healthcare costs of nearly US$3 billion yearly (in the USA as an example) and psychological distress to patients due to unnecessary recalls involving invasive procedures [<xref ref-type="bibr" rid="CR12">12</xref>], it is imperative that education strategies are prioritised to give extra attention to normal cases.</p><p id="Par17">Studies from medical image perception and basic vision science demonstrate that exposing RTs to large mammographic normal cases via test set training programmes, often containing nearly 70% of normal cases in a test set, can enhance their expertise development in interpreting normal cases [<xref ref-type="bibr" rid="CR13">13</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref>]. Still, the present test set curation process using experts&#x02019; or individual&#x02019;s perception of case difficulty via the breast imaging and reporting data system (BI-RADS) breast density and/or benign features are unreliable predictors of normal cases&#x02019; difficulty among RTs [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR16">16</xref>&#x02013;<xref ref-type="bibr" rid="CR18">18</xref>]. Therefore, there is a strong demand for a more systematic approach of predicting RTs&#x02019; difficult normal cases so that customised mammographic training test sets for RTs can be facilitated while their false positive errors can be better monitored and improved.</p><p id="Par18">The process of interpreting medical images necessitates the development of capabilities for globally processing images. Earlier studies showed that individuals with less experience such as RTs often lack the ability to swiftly process the global clues indicative of abnormalities [<xref ref-type="bibr" rid="CR19">19</xref>]. To investigate this further, we designed an experiment protocol to gather the initial impressions of radiologists regarding the abnormality of a case, known as the gist signal [<xref ref-type="bibr" rid="CR19">19</xref>&#x02013;<xref ref-type="bibr" rid="CR21">21</xref>]. This signal not only indicates a current cancer case [<xref ref-type="bibr" rid="CR22">22</xref>] but also serves as a predictor of future BC [<xref ref-type="bibr" rid="CR21">21</xref>]. Moreover, recent research in radiomics has shown that quantitative global mammographic radiomic (or computer extract image) features align closely with the holistic perceptual information gleaned from radiologists&#x02019; rapid first impressions about the presence of an image abnormality or global gist signal [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR23">23</xref>]. This signal has proven valuable in guiding visual searches and aiding in making diagnostic decisions when interpreting challenging mammographic cases [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR24">24</xref>].</p><p id="Par19">Radiomic features capture various aspects of the mammogram, including texture, intensity, and spatial relationships, providing comprehensive information about the underlying tissue characteristics [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]. Radiomic features have been the subject of systematic investigation in previous works, where local radiomic features were utilised to identify missed mammographic masses and false positive location errors of RTs, achieving area under receiver operating characteristic curves (AUCs) from 0.59 to 0.61 and accuracies from 12 to 40%, respectively [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>]. More recent studies [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR16">16</xref>] have revealed that using global mammographic radiomic features (GMRFs), the most difficult/easiest normal cases for readers in general and experienced radiologists can be accurately predicted (AUCs of up to 0.73). However, to date, there has been no study exploring whether GMRFs can specifically predict <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases for RTs. Considering the fact that RTs are still developing their holistic processing capabilities compared to experienced radiologists [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR24">24</xref>], this paper explores whether GMRFs can serve as reliable predictors specifically for <italic>hardest-to-interpret</italic> normal cases for RTs. It also seeks to recognise if there are any specific significant GMRFs that denote the <italic>hardest-to-interpret</italic> normal cases for RTs. Knowing these could be valuable not only in the training programs&#x02019; test set curation process of most difficult normal cases for RTs but also facilitating their expertise development in recognising normal image features that could be most difficult for them often resulting in false positive errors. This is so that their specific skills in perceiving the global signature of normality can be well developed since RTs are generally not as good at recognising the normal features as compared to experienced radiologists [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR27">27</xref>].</p><p id="Par20">Furthermore, since the current approach to curating test sets relies on experts&#x02019; opinions regarding case difficulty, primarily using breast density as a surrogate metric [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR16">16</xref>&#x02013;<xref ref-type="bibr" rid="CR18">18</xref>], we also examine if a significant difference exists in difficulty level between <italic>low-density</italic> (BI-RADS category A&#x02009;=&#x02009;fatty and B&#x02009;=&#x02009;fibroglandular) and <italic>high-density</italic> (category C&#x02009;=&#x02009;heterogeneous and D&#x02009;=&#x02009;extremely dense) normal cases.</p></sec><sec id="Sec2"><title>Materials and Methods</title><sec id="Sec3"><title>Readers</title><p id="Par21">Ethical approvals of this research were acquired from the University of Sydney&#x02019;s Human Research Ethics Committee [protocol no. 2019/013 and 2017/028], which included obtained written informed consent from each reader participating in the study.</p><p id="Par22">A total of 137 Australian and New Zealand RTs who participated in the BREAST (Breastscreen REader Assessment STrategy) programme [<xref ref-type="bibr" rid="CR28">28</xref>] from 04 September 2014 to 23 February 2021 were included in the study. The mean age of the readers was 33 based on the age details provided by 116 RTs, while 21 did not provide their age details. In total, 19% of the readers engaged in the programme through a radiology/BC conference/workshop in a simulated reading room, while 81% completed the programme online through the BREAST platform (<ext-link ext-link-type="uri" xlink:href="https://breast-australia.sydney.edu.au/">https://breast-australia.sydney.edu.au/</ext-link>) at their usual clinical workplace. Reading conditions in both settings were equivalent with cases being presented on two 5-megapixel medical standard monitors including ambient light levels range of 20&#x02013;40&#x000a0;lx [<xref ref-type="bibr" rid="CR29">29</xref>]. RTs generally had less than 1&#x000a0;year experience reading mammograms (59%), read less than 20 mammographic cases per week (79%), and spent less than 4&#x000a0;hour per week reading mammograms (96%). Also, 16 readers (12%) completed a fellowship in breast imaging that lasted for 3 to 6&#x000a0;months and had any experience reading images for a national breast screening programme (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>).
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Characteristics of readers (<italic>n</italic>&#x02009;=&#x02009;137)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Mean years of age (derived from 116 radiology trainees&#x02019; age details while 21 radiology trainees did not provide their age details)</th><th align="left" colspan="2">33</th></tr><tr><th align="left"/><th align="left"><bold><italic>N</italic></bold></th><th align="left"><bold>%</bold></th></tr></thead><tbody><tr><td align="left" colspan="3"><italic>Country</italic></td></tr><tr><td align="left">Australia</td><td align="left">135</td><td align="left">99</td></tr><tr><td align="left">New Zealand</td><td align="left">2</td><td align="left">1</td></tr><tr><td align="left" colspan="3"><italic>Location at the time of engaging with the BREAST programme</italic></td></tr><tr><td align="left">At a workshop or conference</td><td align="left">26</td><td align="left">19</td></tr><tr><td align="left">At a clinic</td><td align="left">111</td><td align="left">81</td></tr><tr><td align="left" colspan="3"><italic># of years reading mammograms</italic></td></tr><tr><td align="left">Less than 1</td><td align="left">81</td><td align="left">59</td></tr><tr><td align="left">1 to 5</td><td align="left">53</td><td align="left">39</td></tr><tr><td align="left">6 to 12</td><td align="left">3</td><td align="left">2</td></tr><tr><td align="left" colspan="3"><italic># of mammographic cases reading per week</italic></td></tr><tr><td align="left">Less than 20</td><td align="left">108</td><td align="left">79</td></tr><tr><td align="left">20 to 200</td><td align="left">28</td><td align="left">20</td></tr><tr><td align="left">More than 200</td><td align="left">1</td><td align="left">1</td></tr><tr><td align="left" colspan="3"><italic># of hours per week spent reading mammograms</italic></td></tr><tr><td align="left">Less than 4</td><td align="left">131</td><td align="left">96</td></tr><tr><td align="left">4 to 30</td><td align="left">5</td><td align="left">4</td></tr><tr><td align="left">More than 30</td><td align="left">1</td><td align="left">1</td></tr><tr><td align="left" colspan="3"><italic># of readers completed a fellowship lasted for 3 to 6&#x000a0;months</italic></td></tr><tr><td align="left">Completed fellowship</td><td align="left">16</td><td align="left">12</td></tr><tr><td align="left">Did not complete fellowship</td><td align="left">119</td><td align="left">87</td></tr><tr><td align="left">Not specified</td><td align="left">2</td><td align="left">1</td></tr><tr><td align="left" colspan="3"><italic># of readers read for breast screening programme</italic></td></tr><tr><td align="left">Yes</td><td align="left">16</td><td align="left">12</td></tr><tr><td align="left">No</td><td align="left">121</td><td align="left">88</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec4"><title>Mammographic Normal Cases</title><p id="Par23">This retrospective study includes data from readers that completed seven BREAST test sets, each comprising 60 de-identified full-field digital mammographic (FFDM) cases, with 40 cases being cancer-free and 20 cases indicating cancer. For the purpose of this investigation, only normal cancer-free cases were included. Thus, a total of 280 normal FFDM cases (comprised of four images per case: two bilateral craniocaudal/CC and two mediolateral oblique/MLO views) acquired from screening asymptomatic women aged between 40 and 75 (mean and median&#x02009;=&#x02009;57, standard deviation&#x02009;=&#x02009;7, and range&#x02009;=&#x02009;33 based on the age details of 130 women/cases, while ages of 10 women were not available due to anonymisation process) were utilised. These cases were collected from various mammography machines, including Fujifilm (Fujifilm Corporation, Minato City, Tokyo, Japan), GE (GE Healthcare, Chicago, IL, USA), Hologic (Hologic, Inc., Marlborough, MA, USA), Philips (Philips Healthcare, Amsterdam, the Netherlands), Sectra (Sectra, Link&#x000f6;ping, Sweden), and Siemens (Munich, Germany). Each normal case&#x02019;s ground truth underwent confirmation of cancer-free status by at least two independent expert radiologists, each possessed over 20 years of experience, with validation through subsequent negative screen outcomes.</p></sec><sec id="Sec5"><title>Categorising Hardest- vs Easiest-to-Interpret Normal Cases </title><p id="Par24">To categorise normal cases as <italic>hardest-</italic> vs <italic>easiest-to-interpret</italic>, we initially calculated difficulty scores for each of the 280 normal cases using the Royal Australian and New Zealand College of Radiologists (RANZCR) scoring system [<xref ref-type="bibr" rid="CR28">28</xref>] provided by the 137 RTs. A RANZCR score of 1 represents a normal case, while a score of 2 indicates that RTs considered the case as benign. Scores of 3, 4, or 5 signify an equivocal or malignant finding observed by the readers with higher numbers indicating a greater confidence of disease presence. Difficulty scores were computed by dividing the number of RTs who misclassified a normal case as cancer (provided a rating of 3, 4, or 5) by the total number RTs who read the test set. Subsequently, the 280 normal cases were then classified as <italic>hardest-</italic> and <italic>easiest-to-interpret</italic> cases based on the 75th and 25th percentiles of the cases containing the highest and lowest difficulty scores, correspondingly. This resulted in 70 <italic>hardest-</italic> and 70 <italic>easiest-to-interpret</italic> normal cases, totalling of 140 normal cases/560 DICOM images combined. To ensure a clear distinction between the most and least difficult normal cases in order to enable optimal feature learning for our machine learning model, only images in the upper and lower quartiles were used for further analysis. Normal cases in these two categories also resulted in a total of 59 <italic>low-density</italic> (35 <italic>hardest-</italic> and 24 <italic>easiest-to-interpret</italic>) and 81 <italic>high-density</italic> normal cases (35 <italic>hardest-</italic> and 46 <italic>easiest-to-interpret</italic>).</p></sec><sec id="Sec6"><title>Global Radiomic Feature/Score Per Case</title><p id="Par25">To obtain a global radiomic feature/score for each of the 140 normal cases, a total of 34 quantitative GMRFs of 560 images belonging to 140 cases extracted from the previous study [<xref ref-type="bibr" rid="CR11">11</xref>] were used. Details about the GMRFs extraction method can be found in the previous study [<xref ref-type="bibr" rid="CR11">11</xref>]. Briefly, from the 560 DICOM images, we first generated 560 binary masks using a standardised gray level threshold value set at 100 (manual adjustments on the value were also performed where needed) to extract the required breast region from its background while eliminating unwanted artefacts and labels. After that, we converted the DICOM images and masks to a TIFF file format, flipped all the right CC and MLO images to the left to have a consistent left-side chest wall on all images, and cropped the TIFF images and masks based on the maximum size of breast region. These cropped TIFF images and masks were used as input for the radiomic analysis (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). We then outlined the region of interest on the images using the lattice-based/ROI (multiple regions of interests covering the entire breast image) [<xref ref-type="bibr" rid="CR30">30</xref>] and squared-based/SQ (largest square rectangular box inscribed within breast) [<xref ref-type="bibr" rid="CR31">31</xref>] approaches. The 34 handcrafted GMRFs/scores per image were afterward extracted based on the region of interest delineated using our in-house MATLAB platforms and then normalised to calibrate image intensity mean to zero and standard deviation to one using a common z-score normalisation method [<xref ref-type="bibr" rid="CR32">32</xref>]. Features using the ROI approach [<xref ref-type="bibr" rid="CR30">30</xref>] were analysed using MATLAB distinct block processing technique (block size 214&#x02009;&#x000d7;&#x02009;214 pixels) and summarised using the standard deviation method. The extracted GMRFs of 4 images (i.e. 2 CC and 2 MLO images) belonging to a case were then combined and averaged to obtain one global radiomic feature/score per case.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Radiomics workflow. <bold>1.</bold> Input mammographic images and masks were acquired. <bold>2.</bold> Region of interest (yellow colour region) was delineated using lattice- and squared-based approaches. <bold>3.</bold> A set of 34 global mammographic radiomic features (GMRFs)/scores per image were extracted from the yellow region of interest, then standardised to have image intensity mean equal to zero and standard deviation equal to one. The extracted GMRFs of four images belonging to each of the 140 cases were then averaged to obtain one GMRF per case. <bold>4.</bold> Finally, using the averaged GMRFs, a random forest machine learning model for differentiating radiology trainees&#x02019; <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases was constructed and assessed</p></caption><graphic xlink:href="10278_2024_1291_Fig1_HTML" id="MO1"/></fig></p><p id="Par26">The 34 GMRFs consisted of 30&#x000a0;Gray level co-occurrence matrix/GLCM-based Haralick texture features [<xref ref-type="bibr" rid="CR33">33</xref>], 2 neighbourhood gray tone difference matrix/NGTDM-based texture features [<xref ref-type="bibr" rid="CR34">34</xref>], and 2 first-order statistics/FOS-based features [<xref ref-type="bibr" rid="CR25">25</xref>] (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref> and Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). These features were chosen because of their usefulness in describing mammographic appearances in measuring the contrast values of spatial inter-relationships between neighbouring pixels (GLCM and NGTDM) and the distribution of single pixel intensity value within the image region of interest (FOS) [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR33">33</xref>].
<table-wrap id="Tab2"><label>Table 2</label><caption><p> Extracted global mammographic radiomic features (<italic>n</italic>&#x02009;=&#x02009;34)</p></caption><graphic position="anchor" xlink:href="10278_2024_1291_Tab2_HTML" id="MO2"/><table-wrap-foot><p>^Features (<italic>n</italic>&#x02009;=&#x02009;15) showing statistically significant difference (<italic>p</italic>-value&#x02009;&#x0003c;&#x02009;0.05) between <italic>hardest-</italic> and <italic>easiest-to-interpret</italic> normal cases of radiology trainees</p><p><sup>*</sup> and highlighted in grey&#x02009;=&#x02009;important features (<italic>n</italic>&#x02009;=&#x02009;2) from the machine learning classifier. The higher importance score means the more useful the features were for the classifier</p><p>Abbreviations: <italic>FOS</italic> first order statistics, <italic>GLCM</italic> gray-level co-occurrence matrix, <italic>NGTDM</italic> neighbourhood gray-tone difference matrix, <italic>n/a</italic> not applicable, <italic>ROI</italic> multiple regions of interests defined by the lattice-based approach covering the entire breast image, <italic>SQ</italic> largest square rectangular box inscribed within breast, <italic>Std</italic> standard deviation</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec7"><title>Model Building</title><p id="Par27">For the task of differentiating between normal cases that are <italic>hardest-</italic> and those of <italic>easiest-to-interpret</italic> for RTs, a random forest machine learning model was built using the averaged 34 GMRFs feeding through MATLAB ensemble of decision trees boosted with the adaptive logistic regression method (i.e. LogitBoost). The random forest with boosting approach was chosen due to its ability to produce an explainable model with automatic estimation of feature importance and its built-in feature selection approach which could minimise feature overfitting and potential selection bias problems [<xref ref-type="bibr" rid="CR35">35</xref>]. Important GMRFs were recognised based on the analysis of feature importance scores using MATLAB&#x02019;s predictor importance algorithm, which also helps in identifying and mitigating redundant and biased features. Feature importance scores indicate how significant each feature was in the dataset when building the predictive model with larger value means larger effect the features had on the model in predicting <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases of RTs (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>).
</p></sec><sec id="Sec8"><title>Statistical Analysis and Validation</title><p id="Par28">In order to examine the performance of the model on our data and to maximise the use of the available data for both training and validation, we trained and validated the model using the resampling leave-one-out-cross-validation (LOOCV) approach (an unbiased, dependable, and accurate validation method for assessing a machine learning model&#x02019; generalisation performance) [<xref ref-type="bibr" rid="CR36">36</xref>]. Each time when training the model, all cases were used, except one case which was left out and used once as a test set to validate the model&#x02019;s predictive performance. We repeated this process 140 times (as per the total number of the normal cases we had) until each case was left out and used once as a test set. The model&#x02019;s performance was then evaluated based on how accurately it predicted the left-out/unseen case in each repetition, providing an effectively estimation of how well the model generalises to the unseen cases. The overall performance of the model for discriminating <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases of RTs was assessed using the AUC.</p><p id="Par29">A Kruskal&#x02013;Wallis test was employed to investigate if the 34 GMRFs differed between <italic>hardest-</italic> and <italic>easiest-to-interpret</italic> normal cases of RTs, and if difficulty level differed among <italic>low-</italic> vs <italic>high-density</italic> normal cases of RTs. A <italic>p</italic>-value of less than 0.05 was considered statistically significant.</p><p id="Par30">Moreover, a scree test of exploratory factor analysis [<xref ref-type="bibr" rid="CR37">37</xref>] was used to determine the usefulness of the GMRFs based on the sum of their importance scores from the model.</p><p id="Par31">Radiomics and statistical analysis were performed using MATLAB R2022a (MathWorks, Natick, MA, USA).</p></sec></sec><sec id="Sec9"><title>Results</title><sec id="Sec10"><title>Global Mammographic Radiomic Features Predicting Difficult Normal Cases of Radiology Trainees</title><p id="Par32">The overall performance of the machine learning classification model for differentiating <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases of RTs using GMRFs is shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>, which indicates an AUC of 0.75 (95% confidence interval, 0.67&#x02013;0.83).<fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>Model performance. For discriminating <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases of radiology trainees, AUC&#x02009;=&#x02009;0.75 (95% confidence interval, 0.67&#x02013; 0.83) was achieved by the random forest machine learning model</p></caption><graphic xlink:href="10278_2024_1291_Fig2_HTML" id="MO3"/></fig></p></sec><sec id="Sec11"><title>Significant Global Mammographic Radiomic Features and Breast Density of Difficult Normal Cases</title><p id="Par33">Table <xref rid="Tab2" ref-type="table">2</xref> shows that 15 out of the total 34 GMRFs had a statistically significant difference between <italic>hardest-</italic> vs <italic>easiest-to-interpret</italic> normal cases of RTs with <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05.</p><p id="Par34">Table <xref rid="Tab2" ref-type="table">2</xref> and Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> show the significant GMRFs based on their importance scores derived from the predictive machine learning model. Out of the 34 features, when comparing each feature&#x02019;s total importance scores ranking from the highest to the lowest, two important features were recognised. These features were <italic>SQ_Cluster_prominence_9</italic> (feature# 31) of GLCM, and <italic>ROI_Std_Range_all</italic> (feature# 16) of FOS. <italic>Cluster prominence</italic> measures the skewness and asymmetry of the GLCM [<xref ref-type="bibr" rid="CR33">33</xref>] and was calculated using the squared-based approach [<xref ref-type="bibr" rid="CR31">31</xref>]. <italic>Range</italic> describes the difference between maximum and minimum of image gray level values [<xref ref-type="bibr" rid="CR25">25</xref>] and was calculated using the lattice-based method [<xref ref-type="bibr" rid="CR30">30</xref>].<fig id="Fig3"><label>Fig.&#x000a0;3</label><caption><p>Scree plot showing significant global mammographic radiomic features. From 34 features, two important features were identified, indicating in the scree plot with the steep slope occurred after the second highest features (as shown by the red arrow). Those important features, ranked from the highest to the lowest important scores, were: (1)&#x02009;<italic>SQ_Cluster_prominence_9</italic> (feature# 31) of GLCM, and (2) <italic>ROI_Std_Range_all</italic> (feature# 16) of FOS. FOS first order statistics, GLCM gray-level co-occurrence matrix, ROI multiple regions of interests defined by the lattice-based approach covering the entire breast image, SQ largest square rectangular box inscribed within breast</p></caption><graphic xlink:href="10278_2024_1291_Fig3_HTML" id="MO4"/></fig></p><p id="Par35">Figure&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> reveals that the difficulty of fatty or <italic>low-density</italic> normal cases does not significantly differ from that of dense or <italic>high-density</italic> cases (<italic>p</italic>-value&#x02009;=&#x02009;0.12), with <italic>low-density</italic> cases appearing to be more challenging for RTs, albeit non-significant.<fig id="Fig4"><label>Fig.&#x000a0;4</label><caption><p>Breast density comparison. Non statistically significant difference (<italic>p</italic>&#x02009;=&#x02009;0.12) in the difficulty level was found between <italic>low-density</italic> and <italic>high-density</italic> normal cases of radiology trainees</p></caption><graphic xlink:href="10278_2024_1291_Fig4_HTML" id="MO5"/></fig></p></sec></sec><sec id="Sec12"><title>Discussion</title><p id="Par36">In this proof-of-concept study, we explored (1) if using a set of global handcrafted radiomic or computer-extracted image features derived from mammograms, <italic>hardest-</italic> vs <italic>easiest-to-interpret</italic> normal cancer-free cases of RTs can be classified, and (2) whether any of these features are useful in this classification task.</p><p id="Par37">Previous works [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>] recognised the usefulness of local radiomic features in identifying missed mammographic masses and false positive location errors of RTs, obtaining AUCs of up to 0.61 and accuracies of up to 40%. Other later studies [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR16">16</xref>] indicated the value of GMRFs in predicting most <italic>difficult-to-interpret</italic> normal cases of general and experienced radiologists (over 20&#x000a0;years of experience reading mammograms), attaining AUCs of up to 0.73. Building on these recent research outputs [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], we explored the feasibility of using GMRFs in describing RTs&#x02019; <italic>hardest-</italic> vs <italic>easiest-to-interpret</italic> normal cases based on the hypothesis that the image characteristics of these two categories&#x02019; cases are diverse. In addition, the results from our machine learning classifier revealed similar findings in that GMRFs (describing the whole image and largest square rectangular inscribed within breast) had the ability to distinguish between <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases of RTs, achieving an AUC of 0.75 (95% CI, 0.67&#x02013;0.83) (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). This finding affirms the importance of GMRFs in predicting <italic>hardest-to-interpret</italic> normal cases for less-experience readers like RTs (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>).</p><p id="Par38">Mammographic breast density using BI-RADS category are often employed as a surrogate measure in assessing difficult normal cases for RTs, where cases with higher density are regularly considered to be more difficult to interpret [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR38">38</xref>]. However, studies have shown that breast density category details alone may not be completely reliable for predicting difficult/easy normal cases of radiologists including RTs [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR39">39</xref>]. In line with these findings, the results from our dataset confirmed that BI-RADS density categories were not strongly correlated with difficulty scores (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). Our GMRFs (e.g. <italic>SQ_Cluster_prominence_9</italic> and <italic>ROI_Std_Range_all</italic>) relating to <italic>hardest-to-interpret</italic> normal cases of RTs therefore may be used to provide supplementary clinical image information (in addition to BI-RADS breast density class) about most difficult features that RTs are likely to commit a false positive error. Also, since RTs find recognising normal image features challenging [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR14">14</xref>], our findings could therefore aid their screening mammographic interpretation expertise development in recognising hardest and easiest breast features of normal cases which could then facilitate automatic hardest and easiest normal cases test set curation for customised education/training programmes. Using the proposed model, we can create customised test sets tailored to the specific learning needs of trainees at different stages of their careers. For example, early-stage trainees could be presented with easier cases to build foundational skills, while more advanced trainees could be challenged with harder cases that reflect real-world complexities. This customised test set curation would allow for targeted education and training programmes that align with the trainees&#x02019; current skill levels, helping them to progress more effectively through their learning journey.</p><p id="Par39">Interestingly, when comparing two groups based on a single GMRF, 15 out of 34 features showed a statistically significant difference between <italic>hardest-</italic> and <italic>easiest-to-interpret</italic> normal cases of RTs (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05). However, when examining the 34 features together through our machine learning classifier, only two features (<italic>cluster prominence</italic>, i.e. <italic>SQ_Cluster_prominence_9</italic>, calculated using the squared-based approach [<xref ref-type="bibr" rid="CR31">31</xref>] and <italic>range</italic>, i.e. <italic>ROI_Std_Range_all</italic>, calculated using the lattice-based method [<xref ref-type="bibr" rid="CR30">30</xref>]) were found to be most useful in describing RTs&#x02019; <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref> and Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>). <italic>Range</italic>, in particular, has also been discovered to be a valuable feature in previous studies [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR20">20</xref>] highlighting the significance of <italic>range</italic> in various classification tasks among different groups of readers (e.g. categorising <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases of readers in general as well as RTs). While <italic>cluster prominence</italic> was not found to be an important feature in the previous work [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR20">20</xref>], in this dataset, we observed that more difficult cases, which resulted in false positive errors more frequently, exhibited higher <italic>cluster prominence</italic> which is a measure of the skewness and asymmetry of the GLCM. This suggests that <italic>cluster prominence</italic> may be an important marker of highly challenging cases for RTs. A higher value of <italic>cluster prominence</italic> implies more asymmetry about the mean in the GLCM, while a lower value indicates a peak near the mean value and less variation about the mean. Intuitively, <italic>cluster prominence</italic> refers to the extent to which clusters of pixels within an image stand out from their surroundings. In other words, it measures the distinctiveness of clusters within the image with a higher <italic>cluster prominence</italic> value indicating that clusters are more salient or prominent within the image. In the context of our study, normal cases with higher <italic>cluster prominence</italic> value pose greater difficulty for trainees. Trainees may struggle with these cases because the heightened prominence of clusters within the image makes it more challenging to distinguish between normal tissue and potential abnormalities, resulting in false positive annotations. Although the features may be abstract in nature and not quantifiable by humans, they could be quantitatively measured using our radiomics approach and used as educational tools to teach and/or alert RTs that the higher the value of <italic>cluster prominence</italic>, the harder the case could be for RTs, increasing the chance of them making a false positive error. Furthermore, creating an alert system based on these features and educating RTs about the correlations between higher value of <italic>cluster prominence</italic> and harder cases can improve their ability to recognise difficult normal cases and enhance decision-making in clinical practice. Nonetheless, more studies are needed to further examine the effectiveness and reliability of these features.</p><p id="Par40">This study also has a few limitations that should be recognised. It was a proof-of-concept study examining the efficacy of 34 handcrafted GMRFs [<xref ref-type="bibr" rid="CR11">11</xref>] in identifying the <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> confirmed cancer-free normal cases of 137 RTs (mostly with less than 1&#x000a0;year of experience reading mammograms) specifically. Only normal cases were included in the study which contained only those that had difficulty scores of greater than or equal to the 75th percentile (<italic>hardest-to-interpret</italic>) and less than or equal to the 25th percentile (<italic>easiest-to-interpret</italic>). LOOCV approach [<xref ref-type="bibr" rid="CR36">36</xref>] was used to train and validate the model in order to maximise the use of the available data. The GMRFs were extracted from the region of interest delineated using the lattice-based [<xref ref-type="bibr" rid="CR30">30</xref>] and squared-based [<xref ref-type="bibr" rid="CR31">31</xref>] approaches. Future research should explore other approaches of identifying region of interest (e.g. retroareolar region), validating the model (e.g. holdout method [<xref ref-type="bibr" rid="CR36">36</xref>]), employing other difficult normal cases with difficulty scores falling outside the included range (e.g. scores that are less than the 75th percentile and greater than 25th percentile), and radiomic analysis involving local and/or deep learning features [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR40">40</xref>].</p></sec><sec id="Sec13"><title>Conclusions</title><p id="Par41">In conclusion, in addition to previous research [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR20">20</xref>], our work highlights the importance of GMRFs for classifying <italic>hardest-</italic> from <italic>easiest-to-interpret</italic> normal cases of RTs with two important features (c<italic>luster prominence</italic> and <italic>range</italic>) being identified. Our findings could be useful for developing RTs&#x02019; interpretation expertise in identifying the most difficult image features of normal breast cases as well as enabling automatic and tailored test set curation of the most difficult cases for RTs&#x02019; education/training programmes.</p></sec></body><back><glossary><title>Abbreviations</title><def-list><def-item><term>AUC</term><def><p id="Par2">Area under receiver operating characteristic curves</p></def></def-item><def-item><term>BC</term><def><p id="Par3">Breast cancer</p></def></def-item><def-item><term>BI-RADS</term><def><p id="Par4">Breast imaging and reporting data system</p></def></def-item><def-item><term>BREAST</term><def><p id="Par5">Breastscreen REader Assessment STrategy</p></def></def-item><def-item><term>CC</term><def><p id="Par6">Craniocaudal</p></def></def-item><def-item><term>FOS</term><def><p id="Par7">First-order statistics</p></def></def-item><def-item><term>GLCM</term><def><p id="Par8">Gray level co-occurrence matrix</p></def></def-item><def-item><term>GMRFs</term><def><p id="Par9">Global mammographic radiomic features</p></def></def-item><def-item><term>MLO</term><def><p id="Par10">Mediolateral oblique</p></def></def-item><def-item><term>NGTDM</term><def><p id="Par11">Neighbourhood gray-tone difference matrix</p></def></def-item><def-item><term>RANZCR</term><def><p id="Par12">Royal Australian and New Zealand College of Radiologists</p></def></def-item><def-item><term>ROI</term><def><p id="Par13">Multiple regions of interests defined by the lattice-based approach covering the entire breast image</p></def></def-item><def-item><term>RTs</term><def><p id="Par14">Radiology trainees</p></def></def-item><def-item><term>SQ</term><def><p id="Par15">Largest square rectangular box inscribed within breast</p></def></def-item></def-list></glossary><fn-group><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>The authors would like to express appreciation to the BreastScreen Reader Assessment Strategy (BREAST) programme at the University of Sydney for access and use of the data. BREAST is funded/supported by the Commonwealth Government Department of Health and Aged Care and the National Breast Cancer Foundation (NBCF), with their images provided by BreastScreen Australia and the Cancer Institute New South Wales (CINSW). The authors also would like to acknowledge the funding support for this research provided by the National Health and Medical Research Council [grant ID: APP1162872] and NBCF [grant ID: IIRS-18-089]. Z.G. is supported by the CINSW Early Career Fellowship [grant ID: 2022/ECF1426]. The authors wish to thank Dr Robert Heard for his statistical advice and the reviewers for their rigorous assessment of this manuscript.</p></ack><notes notes-type="author-contribution"><title>Author Contribution</title><p>All authors contributed to the study concept and design. Material preparation and data collection and analysis were performed by Somphone Siviengphanom and Ziba Gandomkar. The first draft of the manuscript was written by Somphone Siviengphanom, and all authors commented on previous versions of the manuscript. All authors read and approved the final manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p> Open Access funding enabled and organized by CAUL and its Member Institutions. This work was supported by the National Health and Medical Research Council [grant ID: APP1162872] and National Breast Cancer Foundation [grant ID: IIRS-18&#x02013;089] and Cancer Institute New South Wales [grant ID: 2022/ECF1426]. The funders played no role in study design, data collection and analysis, and interpretation of data, or the writing of this article.</p></notes><notes notes-type="data-availability"><title>Data Availability</title><p>The data that support the findings of this study are available from BREAST, but&#x000a0;restrictions apply to their availability, as they were used under license for the current study and are not publicly&#x000a0;available. However, data may be available from the authors upon reasonable request and with permission from&#x000a0;BREAST.</p></notes><notes><title>Declarations</title><notes id="FPar1"><title>Ethics Approval</title><p id="Par42">Ethical approval was obtained for this retrospective study from the Human Research Ethics Committee of the University of Sydney [Protocol number 2019/013 and 2017/028].</p></notes><notes id="FPar2"><title>Consent to Participate</title><p id="Par43">Informed consent was obtained from all individual readers included in the study.</p></notes><notes id="FPar3"><title>Consent for Publication</title><p id="Par44">Informed consent was obtained from all individual readers included in the study.</p></notes><notes id="FPar4" notes-type="COI-statement"><title>Conflict of Interest</title><p id="Par45">P.C.B. and Z.G. as well as an academic at the University of Sydney are CEO and Co-founder (P.C.B.)/employee (Z.G.) of DetectED-X, a company which aims to educate radiologists. The paper will not impact on DetectED-X&#x02019;s activities. All other authors of this manuscript, other than being employee of Western Sydney University (S.J.L.), employee (P.D.T.)/student (S.S.) of the University of Sydney, employee of the University of Technology Sydney (S.S.), declare no relationships with any companies, whose products or services may be related to the subject matter of the article.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">Sung H, et al.: Global Cancer Statistics 2020: GLOBOCAN Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countries. CA: A Cancer Journal for Clinicians 71:209&#x02013;249, 2021</mixed-citation></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Paci</surname><given-names>E</given-names></name></person-group><article-title>Summary of the Evidence of Breast Cancer Service Screening Outcomes in Europe and First Estimate of the Benefit and Harm Balance Sheet</article-title><source>Journal of Medical Screening</source><year>2012</year><volume>19</volume><fpage>5</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1258/jms.2012.012077</pub-id><pub-id pub-id-type="pmid">22972806</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Paci E: Summary of the Evidence of Breast Cancer Service Screening Outcomes in Europe and First Estimate of the Benefit and Harm Balance Sheet. Journal of Medical Screening 19:5-13, 2012<pub-id pub-id-type="pmid">22972806</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Ekpo</surname><given-names>EU</given-names></name><name><surname>Alakhras</surname><given-names>M</given-names></name><name><surname>Brennan</surname><given-names>P</given-names></name></person-group><article-title>Errors in Mammography Cannot be Solved Through Technology Alone</article-title><source>Asian Pac J Cancer Prev</source><year>2018</year><volume>19</volume><fpage>291</fpage><lpage>301</lpage><pub-id pub-id-type="pmid">29479948</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Ekpo EU, Alakhras M, Brennan P: Errors in Mammography Cannot be Solved Through Technology Alone. Asian Pac J Cancer Prev 19:291-301, 2018<pub-id pub-id-type="pmid">29479948</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Lo</surname><given-names>JY</given-names></name><name><surname>Kuzmiak</surname><given-names>CM</given-names></name><name><surname>Ghate</surname><given-names>SV</given-names></name><name><surname>Yoon</surname><given-names>SC</given-names></name><name><surname>Mazurowski</surname><given-names>MA</given-names></name></person-group><article-title>Using computer-extracted image features for modeling of error-making patterns in detection of mammographic masses among radiology residents</article-title><source>Medical Physics</source><year>2014</year><volume>41</volume><fpage>091907</fpage><pub-id pub-id-type="doi">10.1118/1.4892173</pub-id><pub-id pub-id-type="pmid">25186394</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Zhang J, Lo JY, Kuzmiak CM, Ghate SV, Yoon SC, Mazurowski MA: Using computer-extracted image features for modeling of error-making patterns in detection of mammographic masses among radiology residents. Medical Physics 41:091907, 2014<pub-id pub-id-type="pmid">25186394</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Silber</surname><given-names>JI</given-names></name><name><surname>Mazurowski</surname><given-names>MA</given-names></name></person-group><article-title>Modeling false positive error making patterns in radiology trainees for improved mammography education</article-title><source>Journal of Biomedical Informatics</source><year>2015</year><volume>54</volume><fpage>50</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.jbi.2015.01.007</pub-id><pub-id pub-id-type="pmid">25640462</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Zhang J, Silber JI, Mazurowski MA: Modeling false positive error making patterns in radiology trainees for improved mammography education. Journal of Biomedical Informatics 54:50-57, 2015<pub-id pub-id-type="pmid">25640462</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Wong DJ, et al.: Do reader characteristics affect diagnostic efficacy in screening mammography? A systematic review. Clinical Breast Cancer, 2023</mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Gandomkar</surname><given-names>Z</given-names></name><name><surname>Lewis</surname><given-names>SJ</given-names></name><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Ekpo</surname><given-names>EU</given-names></name><name><surname>Brennan</surname><given-names>PC</given-names></name></person-group><article-title>A machine learning model based on readers&#x02019; characteristics to predict their performances in reading screening mammograms</article-title><source>Breast Cancer</source><year>2022</year><volume>29</volume><fpage>589</fpage><lpage>598</lpage><pub-id pub-id-type="doi">10.1007/s12282-022-01335-3</pub-id><pub-id pub-id-type="pmid">35122217</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Gandomkar Z, Lewis SJ, Li T, Ekpo EU, Brennan PC: A machine learning model based on readers&#x02019; characteristics to predict their performances in reading screening mammograms. Breast Cancer 29:589-598, 2022<pub-id pub-id-type="pmid">35122217</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Hofvind</surname><given-names>S</given-names></name><etal/></person-group><article-title>Audit feedback on reading performance of screening mammograms: An international comparison</article-title><source>Journal of Medical Screening</source><year>2016</year><volume>23</volume><fpage>150</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1177/0969141315610790</pub-id><pub-id pub-id-type="pmid">26892191</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Hofvind S, et al.: Audit feedback on reading performance of screening mammograms: An international comparison. Journal of Medical Screening 23:150-159, 2016<pub-id pub-id-type="pmid">26892191</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Suleiman</surname><given-names>ME</given-names></name><name><surname>Rickard</surname><given-names>M</given-names></name><name><surname>Brennan</surname><given-names>PC</given-names></name></person-group><article-title>Perfecting detection through education</article-title><source>Radiography</source><year>2020</year><volume>26</volume><fpage>S49</fpage><lpage>S53</lpage><pub-id pub-id-type="doi">10.1016/j.radi.2020.06.006</pub-id><pub-id pub-id-type="pmid">32698948</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Suleiman ME, Rickard M, Brennan PC: Perfecting detection through education. Radiography 26:S49-S53, 2020<pub-id pub-id-type="pmid">32698948</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>W</given-names></name><name><surname>Peters</surname><given-names>G</given-names></name></person-group><article-title>Mammographic screening for breast cancer: A review</article-title><source>Journal of Medical Radiation Sciences</source><year>2013</year><volume>60</volume><fpage>35</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1002/jmrs.6</pub-id><pub-id pub-id-type="pmid">26229605</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Lee W, Peters G: Mammographic screening for breast cancer: A review. Journal of Medical Radiation Sciences 60:35-39, 2013<pub-id pub-id-type="pmid">26229605</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Siviengphanom</surname><given-names>S</given-names></name><name><surname>Gandomkar</surname><given-names>Z</given-names></name><name><surname>Lewis</surname><given-names>SJ</given-names></name><name><surname>Brennan</surname><given-names>PC</given-names></name></person-group><article-title>Global radiomic features from mammography for predicting difficult-to-interpret normal cases</article-title><source>Journal of Digital Imaging</source><year>2023</year><volume>36</volume><fpage>1541</fpage><lpage>1552</lpage><pub-id pub-id-type="doi">10.1007/s10278-023-00836-7</pub-id><pub-id pub-id-type="pmid">37253894</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Siviengphanom S, Gandomkar Z, Lewis SJ, Brennan PC: Global radiomic features from mammography for predicting difficult-to-interpret normal cases. Journal of Digital Imaging 36:1541&#x02013;1552, 2023<pub-id pub-id-type="pmid">37253894</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Vlahiotis</surname><given-names>A</given-names></name><name><surname>Griffin</surname><given-names>B</given-names></name><name><surname>Stavros Md</surname><given-names>FAT</given-names></name><name><surname>Margolis</surname><given-names>J</given-names></name></person-group><article-title>Analysis of utilization patterns and associated costs of the breast imaging and diagnostic procedures after screening mammography</article-title><source>ClinicoEconomics and Outcomes Research</source><year>2018</year><volume>10</volume><fpage>157</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.2147/CEOR.S150260</pub-id><pub-id pub-id-type="pmid">29618934</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Vlahiotis A, Griffin B, Stavros Md FAT, Margolis J: Analysis of utilization patterns and associated costs of the breast imaging and diagnostic procedures after screening mammography. ClinicoEconomics and Outcomes Research Volume 10:157-167, 2018<pub-id pub-id-type="pmid">29618934</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Gandomkar</surname><given-names>Z</given-names></name><name><surname>Mello-Thoms</surname><given-names>C</given-names></name></person-group><article-title>Visual search in breast imaging</article-title><source>Br J Radiol</source><year>2019</year><volume>92</volume><fpage>20190057</fpage><pub-id pub-id-type="doi">10.1259/bjr.20190057</pub-id><pub-id pub-id-type="pmid">31287719</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Gandomkar Z, Mello-Thoms C: Visual search in breast imaging. Br J Radiol 92:20190057, 2019<pub-id pub-id-type="pmid">31287719</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Nodine</surname><given-names>CF</given-names></name><etal/></person-group><article-title>How experience and training influence mammography expertise</article-title><source>Acad Radiol</source><year>1999</year><volume>6</volume><fpage>575</fpage><lpage>585</lpage><pub-id pub-id-type="doi">10.1016/S1076-6332(99)80252-9</pub-id><pub-id pub-id-type="pmid">10516859</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Nodine CF, et al.: How experience and training influence mammography expertise. Acad Radiol 6:575-585, 1999<pub-id pub-id-type="pmid">10516859</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Buist</surname><given-names>DS</given-names></name><etal/></person-group><article-title>Influence of annual interpretive volume on screening mammography performance in the United States</article-title><source>Radiology</source><year>2011</year><volume>259</volume><fpage>72</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1148/radiol.10101698</pub-id><pub-id pub-id-type="pmid">21343539</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Buist DS, et al.: Influence of annual interpretive volume on screening mammography performance in the United States. Radiology 259:72-84, 2011<pub-id pub-id-type="pmid">21343539</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Siviengphanom S, Gandomkar Z, Lewis SJ, Brennan PC: Global mammographic radiomic signature can predict radiologists&#x02019; difficult-to-interpret normal cases. Proc. SPIE Medical Imaging 2023: Image Perception, Observer Performance, and Technology Assessment: City</mixed-citation></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Ang</surname><given-names>ZZ</given-names></name><name><surname>Rawashdeh</surname><given-names>MA</given-names></name><name><surname>Heard</surname><given-names>R</given-names></name><name><surname>Brennan</surname><given-names>PC</given-names></name><name><surname>Lee</surname><given-names>W</given-names></name><name><surname>Lewis</surname><given-names>SJ</given-names></name></person-group><article-title>Classification of normal screening mammograms is strongly influenced by perceived mammographic breast density</article-title><source>Journal of Medical Imaging and Radiation Oncology</source><year>2017</year><volume>61</volume><fpage>461</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1111/1754-9485.12576</pub-id><pub-id pub-id-type="pmid">28052571</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Ang ZZ, Rawashdeh MA, Heard R, Brennan PC, Lee W, Lewis SJ: Classification of normal screening mammograms is strongly influenced by perceived mammographic breast density. Journal of Medical Imaging and Radiation Oncology 61:461-469, 2017<pub-id pub-id-type="pmid">28052571</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Darker I, Chen Y, Gale A: Health professionals' agreement on density judgements and successful abnormality identification within the UK Breast Screening Programme. Proc. SPIE Medical Imaging: City</mixed-citation></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Gandomkar</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Reliability of radiologists&#x02019; first impression when interpreting a screening mammogram</article-title><source>PLOS ONE</source><year>2023</year><volume>18</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0284605</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Gandomkar Z, et al.: Reliability of radiologists&#x02019; first impression when interpreting a screening mammogram. PLOS ONE 18:1-19, 2023</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Siviengphanom</surname><given-names>S</given-names></name><name><surname>Lewis</surname><given-names>SJ</given-names></name><name><surname>Brennan</surname><given-names>PC</given-names></name><name><surname>Gandomkar</surname><given-names>Z</given-names></name></person-group><article-title>Computer-extracted global radiomic features can predict the radiologists&#x02019; first impression about the abnormality of a screening mammogram</article-title><source>British Journal of Radiology</source><year>2024</year><volume>97</volume><fpage>168</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1093/bjr/tqad025</pub-id><pub-id pub-id-type="pmid">38263826</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Siviengphanom S, Lewis SJ, Brennan PC, Gandomkar Z: Computer-extracted global radiomic features can predict the radiologists&#x02019; first impression about the abnormality of a screening mammogram. British Journal of Radiology 97:168&#x02013;179, 2024<pub-id pub-id-type="pmid">38263826</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Brennan</surname><given-names>PC</given-names></name><etal/></person-group><article-title>Radiologists can detect the 'gist' of breast cancer before any overt signs of cancer appear</article-title><source>Sci Rep</source><year>2018</year><volume>8</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41598-018-26100-5</pub-id><pub-id pub-id-type="pmid">29311619</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Brennan PC, et al.: Radiologists can detect the 'gist' of breast cancer before any overt signs of cancer appear. Sci Rep 8:1-12, 2018<pub-id pub-id-type="pmid">29311619</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Gandomkar</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Global processing provides malignancy evidence complementary to the information captured by humans or machines following detailed mammogram inspection</article-title><source>Sci Rep</source><year>2021</year><volume>11</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41598-021-99582-5</pub-id><pub-id pub-id-type="pmid">33414495</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Gandomkar Z, et al.: Global processing provides malignancy evidence complementary to the information captured by humans or machines following detailed mammogram inspection. Sci Rep 11:1-12, 2021<pub-id pub-id-type="pmid">33414495</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Siviengphanom S, Lewis SJ, Brennan PC, Gandomkar Z: Predicting the gist of breast cancer on a screening mammogram using global radiomic features. Proc. SPIE Medical Imaging 2024: Image Perception, Observer Performance, and Technology Assessment: City</mixed-citation></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>KK</given-names></name><name><surname>Georgian-Smith</surname><given-names>D</given-names></name><name><surname>Tambouret</surname><given-names>R</given-names></name><name><surname>Birdwell</surname><given-names>RL</given-names></name><name><surname>Wolfe</surname><given-names>JM</given-names></name></person-group><article-title>The gist of the abnormal: Above-chance medical decision making in the blink of an eye</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2013</year><volume>20</volume><fpage>1170</fpage><lpage>1175</lpage><pub-id pub-id-type="doi">10.3758/s13423-013-0459-3</pub-id><pub-id pub-id-type="pmid">23771399</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Evans KK, Georgian-Smith D, Tambouret R, Birdwell RL, Wolfe JM: The gist of the abnormal: Above-chance medical decision making in the blink of an eye. Psychonomic Bulletin &#x00026; Review 20:1170-1175, 2013<pub-id pub-id-type="pmid">23771399</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Gillies</surname><given-names>RJ</given-names></name><name><surname>Kinahan</surname><given-names>PE</given-names></name><name><surname>Hricak</surname><given-names>H</given-names></name></person-group><article-title>Radiomics: Images Are More than Pictures</article-title><source>They Are Data. Radiology</source><year>2016</year><volume>278</volume><fpage>563</fpage><lpage>577</lpage><pub-id pub-id-type="pmid">26579733</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Gillies RJ, Kinahan PE, Hricak H: Radiomics: Images Are More than Pictures, They Are Data. Radiology 278:563-577, 2016<pub-id pub-id-type="pmid">26579733</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Siviengphanom</surname><given-names>S</given-names></name><name><surname>Gandomkar</surname><given-names>Z</given-names></name><name><surname>Lewis</surname><given-names>SJ</given-names></name><name><surname>Brennan</surname><given-names>PC</given-names></name></person-group><article-title>Mammography-based Radiomics in Breast Cancer: A Scoping Review of Current Knowledge and Future Needs</article-title><source>Academic Radiology</source><year>2021</year><volume>29</volume><fpage>1228</fpage><lpage>1247</lpage><pub-id pub-id-type="doi">10.1016/j.acra.2021.09.025</pub-id><pub-id pub-id-type="pmid">34799256</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Siviengphanom S, Gandomkar Z, Lewis SJ, Brennan PC: Mammography-based Radiomics in Breast Cancer: A Scoping Review of Current Knowledge and Future Needs. Academic Radiology 29:1228-1247, 2021<pub-id pub-id-type="pmid">34799256</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Gandomkar Z, et al.: An end-to-end deep learning model can detect the gist of the abnormal in prior mammograms as perceived by experienced radiologists. Proc. SPIE Medical Imaging 2021: Image Perception, Observer Performance, and Technology Assessment: City</mixed-citation></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="book"><person-group person-group-type="author"><name><surname>Brennan</surname><given-names>P</given-names></name><name><surname>Lee</surname><given-names>W</given-names></name><name><surname>Tapia</surname><given-names>K</given-names></name></person-group><source>Breast Screen Reader Assessment Strategy (BREAST): A Research Infrastructure with a Translational Objective</source><year>2018</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name></element-citation><mixed-citation id="mc-CR28" publication-type="book">Brennan P, Lee W, Tapia K: Breast Screen Reader Assessment Strategy (BREAST): A Research Infrastructure with a Translational Objective, Cambridge: Cambridge University Press, 2018</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">McEntee M, Brennan P, Evanoff M, Phillps P, O Connor W, Manning D: Optimum ambient lighting conditions for the viewing of softcopy radiological images: SPIE, 2006</mixed-citation></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Parenchymal texture analysis in digital mammography: A fully automated pipeline for breast cancer risk assessment</article-title><source>Medical Physics</source><year>2015</year><volume>42</volume><fpage>4149</fpage><lpage>4160</lpage><pub-id pub-id-type="doi">10.1118/1.4921996</pub-id><pub-id pub-id-type="pmid">26133615</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Zheng Y, et al.: Parenchymal texture analysis in digital mammography: A fully automated pipeline for breast cancer risk assessment. Medical Physics 42:4149-4160, 2015<pub-id pub-id-type="pmid">26133615</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Gandomkar Z, Suleiman M, Demchig D, Brennan P, McEntee M: BI-RADS density categorization using deep neural networks. Proc. SPIE 10952, Medical Imaging 2019: Image Perception, Observer Performance, and Technology Assessment: City</mixed-citation></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Haga</surname><given-names>A</given-names></name><etal/></person-group><article-title>Standardization of imaging features for radiomics analysis</article-title><source>The Journal of Medical Investigation</source><year>2019</year><volume>66</volume><fpage>35</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.2152/jmi.66.35</pub-id><pub-id pub-id-type="pmid">31064950</pub-id>
</element-citation><mixed-citation id="mc-CR32" publication-type="journal">Haga A, et al.: Standardization of imaging features for radiomics analysis. The Journal of Medical Investigation 66:35-37, 2019<pub-id pub-id-type="pmid">31064950</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Haralick RM, Shanmugam K, Dinstein IH: Textural Features for Image Classification. IEEE Transactions on Systems, Man, and Cybernetics SMC-3:610&#x02013;621, 1973</mixed-citation></ref><ref id="CR34"><label>34.</label><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name><surname>Amadasun</surname><given-names>M</given-names></name><name><surname>King</surname><given-names>R</given-names></name></person-group><article-title>Textural features corresponding to textural properties</article-title><source>IEEE Transactions on Systems, Man, and Cybernetics</source><year>1989</year><volume>19</volume><fpage>1264</fpage><lpage>1274</lpage><pub-id pub-id-type="doi">10.1109/21.44046</pub-id></element-citation><mixed-citation id="mc-CR34" publication-type="journal">Amadasun M, King R: Textural features corresponding to textural properties. IEEE Transactions on Systems, Man, and Cybernetics 19:1264-1274, 1989</mixed-citation></citation-alternatives></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L</given-names></name></person-group><article-title>Random Forests</article-title><source>Machine Learning</source><year>2001</year><volume>45</volume><fpage>5</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></element-citation><mixed-citation id="mc-CR35" publication-type="journal">Breiman L: Random Forests. Machine Learning 45:5-32, 2001</mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Molinaro</surname><given-names>AM</given-names></name><name><surname>Simon</surname><given-names>R</given-names></name><name><surname>Pfeiffer</surname><given-names>RM</given-names></name></person-group><article-title>Prediction error estimation: a comparison of resampling methods</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>3301</fpage><lpage>3307</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bti499</pub-id><pub-id pub-id-type="pmid">15905277</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal">Molinaro AM, Simon R, Pfeiffer RM: Prediction error estimation: a comparison of resampling methods. Bioinformatics 21:3301-3307, 2005<pub-id pub-id-type="pmid">15905277</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Ledesma RD, Valero-Mora P, Macbeth G: The Scree Test and the Number of Factors: a Dynamic Graphics Approach. The Spanish Journal of Psychology 18, 2015</mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">A Tapia K, Rickard MT, McEntee MF, Garvey G, Lydiard L, C Brennan P: Impact of breast density on cancer detection: observations from digital mammography test sets. International Journal of Radiology &#x00026; Radiation Therapy 7:36&#x02013;41, 2020</mixed-citation></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name><surname>Grimm</surname><given-names>LJ</given-names></name><name><surname>Kuzmiak</surname><given-names>CM</given-names></name><name><surname>Ghate</surname><given-names>SV</given-names></name><name><surname>Yoon</surname><given-names>SC</given-names></name><name><surname>Mazurowski</surname><given-names>MA</given-names></name></person-group><article-title>Radiology Resident Mammography Training</article-title><source>Academic Radiology</source><year>2014</year><volume>21</volume><fpage>888</fpage><lpage>892</lpage><pub-id pub-id-type="doi">10.1016/j.acra.2014.01.025</pub-id><pub-id pub-id-type="pmid">24928157</pub-id>
</element-citation><mixed-citation id="mc-CR39" publication-type="journal">Grimm LJ, Kuzmiak CM, Ghate SV, Yoon SC, Mazurowski MA: Radiology Resident Mammography Training. Academic Radiology 21:888-892, 2014<pub-id pub-id-type="pmid">24928157</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Pertuz S, Torres GF, Tamimi R, Kamarainen J: Open Framework for Mammography-based Breast Cancer Risk Assessment. Proc. 2019 IEEE EMBS International Conference on Biomedical &#x00026; Health Informatics (BHI): City</mixed-citation></ref></ref-list></back></article>