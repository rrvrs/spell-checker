<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Imaging Inform Med</journal-id><journal-id journal-id-type="iso-abbrev">J Imaging Inform Med</journal-id><journal-title-group><journal-title>Journal of Imaging Informatics in Medicine</journal-title></journal-title-group><issn pub-type="ppub">2948-2925</issn><issn pub-type="epub">2948-2933</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39356368</article-id><article-id pub-id-type="pmc">PMC12092313</article-id>
<article-id pub-id-type="publisher-id">1275</article-id><article-id pub-id-type="doi">10.1007/s10278-024-01275-8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Automated Neural Architecture Search for Cardiac Amyloidosis Classification from [18F]-Florbetaben PET Images</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-6403-0585</contrib-id><name><surname>Bargagna</surname><given-names>Filippo</given-names></name><address><email>filippo.bargagna@phd.unipi.it</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><bio><sec id="FPar1"><title><bold>Filippo Bargagna</bold></title><p id="Par1">received a master&#x02019;s degree with honors in Biomedical Engineering (Bioinstrumentation and Bioinformatics) in October 2022 from the University of Pisa and is currently a PhD Student in Information Engineering at the Department of Information Engineering of the University of Pisa. His research endeavors center around the design and implementation of Deep Learning systems, with a specific focus on their application in the realm of medical imaging and unstructured data.</p></sec></bio></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Zigrino</surname><given-names>Donato</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><bio><sec id="FPar2"><title><bold>Donato Zigrino</bold></title><p id="Par2">received a master&#x02019;s degree in Biomedical Engineering (Bioinstrumentation and Bioinformatics) in July 2023 from the University of Pisa. His research activity mainly concerns the application of deep learning tools on biomedical images.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>De Santi</surname><given-names>Lisa Anita</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><bio><sec id="FPar3"><title><bold>Lisa Anita De Santi</bold></title><p id="Par3">is a Ph.D. student in the Information Engineering Department at Pisa University and she works at Fondazione Toscana Gabriele Monasterio in Pisa. Her research interests focus Deep Learning application and Explainable Artificial Intelligence in Nuclear Medicine Imaging. Her main goal is to take advantage of advanced Artificial Intelligence algorithms to develop new reliable diagnostic tools which may facilitate early detection and monitoring of degenerative disease.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Genovesi</surname><given-names>Dario</given-names></name><xref ref-type="aff" rid="Aff3">3</xref><bio><sec id="FPar4"><title><bold>Dario Genovesi</bold></title><p id="Par4">graduated in Medicine and Surgery from the University of Pisa in February 2004 and specialized in Nuclear Medicine from the University of Pisa in November 2007. Since May 2008 he has been Medical Director of Nuclear Medicine at the Fondazione G Monasterio in Pisa. He carries out research in the field of nuclear medicine, mainly cardiological and neurological.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Scipioni</surname><given-names>Michele</given-names></name><xref ref-type="aff" rid="Aff4">4</xref><bio><sec id="FPar5"><title><bold>Michele Scipioni</bold></title><p id="Par5">received the Master Degree with Honors in Biomedical Engineering at the School of Engineering, University of Pisa, in 2015, and the PhD degree with honors in Biomedical Engineering, at the Information Engineering Department at Pisa University of Pisa in 2018. Since 2019 he is a research fellow at Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Boston, MA, USA. His research activity is on medical images reconstruction and processing algorithms, mainly applied on Nuclear Medicine and MRI.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Favilli</surname><given-names>Brunella</given-names></name><xref ref-type="aff" rid="Aff3">3</xref><bio><sec id="FPar6"><title><bold>Brunella Favilli</bold></title><p id="Par6">is a radiology technician at the Nuclear Medicine Unit of the
&#x0201c;Fondazione CNR/Regione Toscana G. Monasterio&#x0201d; in Pisa. She obtained M.Sc. in Biology Science from the University of Pisa and the Master of Science in Radiology Technician from the University of Pisa. She is co-author of more than 25 peer reviewed publications.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Vergaro</surname><given-names>Giuseppe</given-names></name><xref ref-type="aff" rid="Aff5">5</xref><bio><sec id="FPar7"><title><bold>Giuseppe Vergaro</bold></title><p id="Par7">is affiliate researcher at the Scuola Superiore Sant&#x02019;Anna, Pisa. He had a joint PhD from the Universit&#x000e9; Sorbonne, Paris and Scuola Superiore Sant&#x02019;Anna, Pisa. His research activity is now ranging from the molecular effects of sacubitril/valsartan in left ventricular systolic dysfunction to the investigation of the prognostic significance of cardiac biomarkers from large randomized clinical trials. He is also involved in educational activities at the University of Pisa (Dpt. of Physics) and at the Scuola Superiore Sant&#x02019;Anna. He is author of more than 95 peer-reviewed articles published on national and international Journals, and he is serving as editor and reviewer for several Journals in the field of cardiovascular Medicine.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Emdin</surname><given-names>Michele</given-names></name><xref ref-type="aff" rid="Aff5">5</xref><xref ref-type="aff" rid="Aff6">6</xref><bio><sec id="FPar8"><title><bold>Michele Emdin</bold></title><p id="Par8">is Full Professor of Cardiology, Coordinator of the Health Sciences Interdisciplinary Center at the Sant&#x02019;Anna School of Advanced Studies, Contract Professor of Pathophysiology and Diagnostics at the Department of Physics, University of Pisa, Italy, Chief of Cardiology, Director of Cardiothoracic Department at Foundation G. Monasterio. He graduated from Pisa and Milan University with M.D. and Cardiovascular Pathophysiology Ph.D. degrees in 1987 and 1992, respectively. He received Cardiovascular Medicine and Nuclear Medicine Specialty degrees in 1987 and in 1997, and a Master Degree in Health Service Management in 2009 at the Sant&#x02019;Anna School. Emdin&#x02019;s research during the last decades, has examined the pathophysiology of ischemic heart disease, heart failure and the role of&#x000a0;neuro-hormonal derangement in the evolution of heart failure, as well as mechanisms of cardiovascular diseases, innovation in diagnostics, and therapeutics of cardiovascular diseases.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Giorgetti</surname><given-names>Assuero</given-names></name><xref ref-type="aff" rid="Aff3">3</xref><bio><sec id="FPar9"><title><bold>Assuero Giorgetti</bold></title><p id="Par9">graduated in Medicine and Surgery from the University of Pisa in 1992; he specialized in Nuclear Medicine at the University of Pisa in 1998. Since 2000 he has been employed as I level Medicine Doctor at the Azienda Ospedaliero Universitaria Pisana with research and clinical tasks to be done in the Nuclear Medicine and PET Unit of the Institute of Clinical Physiology/CNR first, and at the Fondazione CNR/Regione Toscana &#x0201c;G. Monasterio&#x0201d;, then (since 2013). From 2020 he is Head of the Nuclear Medicine Unit of the &#x0201c;Fondazione CNR/Regione Toscana G. Monasterio&#x0201d;. He is co-author of more than 150 abstracts and original papers on Italian and international journals.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Positano</surname><given-names>Vincenzo</given-names></name><xref ref-type="aff" rid="Aff2">2</xref><bio><sec id="FPar10"><title><bold>Vincenzo Positano</bold></title><p id="Par10">obtained his MSc degree in Electronic Engineering in 1992 at the University of Pisa. Since 2009 he has worked as a Senior Scientist at the Bioengineering Unit of the Fondazione G Monasterio in Pisa. His research activity is mainly focused on multimodal cardiovascular image analysis, also using machine learning tools. Since 2003 he has been an Adjunct Professor at the Faculty of Biomedical Engineering of Pisa University, holding the course of Medical Image Analysis. He is the author of more than 200 peer-reviewed journal papers spanning from basic to clinical-oriented image analysis problems mainly focused on the cardiovascular district.</p></sec></bio></contrib><contrib contrib-type="author"><name><surname>Santarelli</surname><given-names>Maria Filomena</given-names></name><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff7">7</xref><bio><sec id="FPar11"><title><bold>Maria Filomena Santarelli</bold></title><p id="Par11">is senior researcher at the CNR Institute of clinical Physiology of Pisa. She has a Master of Science Degree on Informatics and a PhD in Biomedical Engineering. She teaches regular courses on Biomedical Imaging at the Biomedical Engineering Master Degree at Pisa University. Her research activity is mainly on Biomedical image and signal processing, in particular on Nuclear Medicine images acquisition and processing. She has published more than 120 peer-reviewed papers, about 150 proceedings and more than 10 book-chapter and/or volumes on medical image processing and tissue characterization.</p></sec></bio></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03ad39j10</institution-id><institution-id institution-id-type="GRID">grid.5395.a</institution-id><institution-id institution-id-type="ISNI">0000 0004 1757 3729</institution-id><institution>Department of Information Engineering, </institution><institution>University of Pisa, </institution></institution-wrap>Via G. Caruso 16, 56122 Pisa, Italy </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/058a2pj71</institution-id><institution-id institution-id-type="GRID">grid.452599.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1781 8976</institution-id><institution>Bioengineering Unit, </institution><institution>Fondazione Toscana G Monasterio, </institution></institution-wrap>Via Giuseppe Moruzzi, 56124 Pisa, Italy </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/058a2pj71</institution-id><institution-id institution-id-type="GRID">grid.452599.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1781 8976</institution-id><institution>Nuclear Medicine Unit, </institution><institution>Fondazione Toscana G Monasterio, </institution></institution-wrap>Via Giuseppe Moruzzi, 56124 Pisa, Italy </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/002pd6e78</institution-id><institution-id institution-id-type="GRID">grid.32224.35</institution-id><institution-id institution-id-type="ISNI">0000 0004 0386 9924</institution-id><institution>Athinoula A. Martinos Center for Biomedical Imaging, </institution><institution>Massachusetts General Hospital and Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/058a2pj71</institution-id><institution-id institution-id-type="GRID">grid.452599.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1781 8976</institution-id><institution>Division of Cardiology and Cardiovascular Medicine, </institution><institution>Fondazione Toscana G Monasterio, </institution></institution-wrap>Via Giuseppe Moruzzi, 56124 Pisa, Italy </aff><aff id="Aff6"><label>6</label>Health Science Interdisciplinary Center, Scuola Universitaria Superiore &#x02018;S. Anna&#x0201d;, Piazza Martiri della Libert&#x000e0; 33, 56127 Pisa, Italy </aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01kdj2848</institution-id><institution-id institution-id-type="GRID">grid.418529.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1756 390X</institution-id><institution>CNR Institute of Clinical Physiology, </institution></institution-wrap>Via Giuseppe Moruzzi, 56124 Pisa, Italy </aff></contrib-group><pub-date pub-type="epub"><day>2</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>2</day><month>10</month><year>2024</year></pub-date><pub-date pub-type="collection"><month>6</month><year>2025</year></pub-date><volume>38</volume><issue>3</issue><fpage>1452</fpage><lpage>1466</lpage><history><date date-type="received"><day>18</day><month>6</month><year>2024</year></date><date date-type="rev-recd"><day>30</day><month>8</month><year>2024</year></date><date date-type="accepted"><day>8</day><month>9</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par12">Medical image classification using convolutional neural networks (CNNs) is promising but often requires extensive manual tuning for optimal model definition. Neural architecture search (NAS) automates this process, reducing human intervention significantly. This study applies NAS to [18F]-Florbetaben PET cardiac images for classifying cardiac amyloidosis (CA) sub-types (amyloid light chain (AL) and transthyretin amyloid (ATTR)) and controls. Following data preprocessing and augmentation, an evolutionary cell-based NAS approach with a fixed network macro-structure is employed, automatically deriving cells&#x02019; micro-structure. The algorithm is executed five times, evaluating 100 mutating architectures per run on an augmented dataset of 4048 images (originally 597), totaling 5000 architectures evaluated. The best network (NAS-Net) achieves 76.95% overall accuracy. <italic>K</italic>-fold analysis yields mean&#x02009;&#x000b1;&#x02009;SD percentages of sensitivity, specificity, and accuracy on the test dataset: AL subjects (98.7&#x02009;&#x000b1;&#x02009;2.9, 99.3&#x02009;&#x000b1;&#x02009;1.1, 99.7&#x02009;&#x000b1;&#x02009;0.7), ATTR-CA subjects (93.3&#x02009;&#x000b1;&#x02009;7.8, 78.0&#x02009;&#x000b1;&#x02009;2.9, 70.9&#x02009;&#x000b1;&#x02009;3.7), and controls (35.8&#x02009;&#x000b1;&#x02009;14.6, 77.1&#x02009;&#x000b1;&#x02009;2.0, 96.7&#x02009;&#x000b1;&#x02009;4.4). NAS-derived network performance rivals manually determined networks in the literature while using fewer parameters, validating its automatic approach&#x02019;s efficacy.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Neural architecture search</kwd><kwd>AutoML</kwd><kwd>Nuclear medicine</kwd><kwd>[18-F]-Florbetaben</kwd><kwd>Cardiac amyloidosis</kwd></kwd-group><funding-group><award-group><funding-source><institution>Universit&#x000e0; di Pisa</institution></funding-source></award-group><open-access><p>Open access funding provided by Universit&#x000e0; di Pisa within the CRUI-CARE Agreement.</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Society for Imaging Informatics in Medicine 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par13">Machine learning (ML) is a discipline that supports radiologists in the development of new biomarkers and better analysis of medical images towards accurate diagnosis. Among ML techniques, deep learning (DL) provides powerful methods for classification, segmentation, and recognition of medical images [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. DL is based on algorithms relying on Neural Network (NN) structures, made of several interconnected nodes, also known as neurons, that process information and automatically extract features from unstructured data [<xref ref-type="bibr" rid="CR3">3</xref>].</p><p id="Par14">NN, in general, are comprised of three main types of layers, each one composed of several nodes: the input layer, which receives data and passes it to the rest of the architecture; the hidden layers, which apply non-linear functions to the data; the output layer, that provides processing results under various formats depending on the task at hand (regression, classification).</p><p id="Par15">Convolutional neural networks (CNN) are a subtype of NN, having as hidden layers three specific ones: convolutional layer, pooling layer, and fully connected layer. When using CNNs for classification tasks, convolutional and pooling layers extract features and information and feed them to the fully connected layers. These final layers, in turn, give class scores for the images. Designing and finding an appropriate neural network, a CNN in particular, can be a challenging task; in fact, most of the advances in neural network models usually require considerable hand-tuning of the neural network architecture, which is time-consuming and error-prone. Often, modifications to existing architectures are made using transfer learning, but their effectiveness is very much linked to the experience and knowledge of the researcher [<xref ref-type="bibr" rid="CR4">4</xref>].</p><p id="Par16">In recent years, auto machine learning (AutoML) has been developed to fulfill two main goals: automate the learning process from data pre-processing to model evaluation and make deep learning accessible to non-experts. An example of AutoML is neural architecture search (NAS) [<xref ref-type="bibr" rid="CR5">5</xref>], which uses automated algorithms and techniques to find architectures that can achieve high performance while minimizing the need for manual trial-and-error. The process involves exploring a large search space of possible architectures and hyperparameters to find the most suitable configuration for the given problem.</p><p id="Par17">The first NAS methods relied on reinforcement learning [<xref ref-type="bibr" rid="CR6">6</xref>] and evolutionary learning [<xref ref-type="bibr" rid="CR7">7</xref>] approaches, which achieved the best classification accuracy in image classification. This novel methodology has been used to accomplish some medical tasks, such as classifying skin lesions [<xref ref-type="bibr" rid="CR8">8</xref>] or segmenting medical images for surgery planning and computer-aided diagnosis [<xref ref-type="bibr" rid="CR9">9</xref>].</p><p id="Par18">However, as far as we know, there are no studies regarding the application of this technique to the classification of nuclear medicine images, positron emission tomography (PET) in particular. This research aims to fill this gap by adopting and implementing the NAS-based evolutionary algorithm for cardiac amyloidosis (CA) classification from early acquired [18F]-Florbetaben PET images. Given a dataset that includes PET images from subjects with both light chain amyloidosis (AL) and transthyretin amyloidosis (ATTR) sub-types of CA as well as control subjects, the NAS methodology used in the present work is shown to automatically develop and evaluate the optimal network for the classification of the three data classes.</p><p id="Par19">A comparison is also made with a CNN network already present in the literature, named CAclassNET [<xref ref-type="bibr" rid="CR10">10</xref>], built with the classic methodology of manually finding an optimal network for classification through numerous hand-tuning phases of the parameters present in the network.</p></sec><sec id="Sec2"><title>Materials and Methods</title><sec id="Sec3"><title>Theory</title><sec id="Sec4"><title>Neural Architecture Search</title><p id="Par20">NAS focuses on optimizing the topology of an architecture, usually portrayed through a directed acyclic graph (DAG), where neural network operations label the nodes or edges. NAS methods are typically categorized according to three dimensions: 1. The <italic>Search Space</italic>
<bold>A</bold> refers to all possible architectures that can be used for a given task; 2. The <italic>Search Strategy</italic>, which explores the search space by selecting a single architecture <italic>&#x003b1;</italic> (&#x02208; A); and 3. The <italic>Performance Estimation Strategy</italic>, that evaluates the model&#x02019;s predictive performance on unseen data and can be done, for example, using the classic training and validation approach on the data. Figure <xref rid="Fig1" ref-type="fig">1</xref> gives a synthetic description of the NAS workflow followed in this work.
<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>The Neural Architecture Search workflow</p></caption><graphic xlink:href="10278_2024_1275_Fig1_HTML" id="MO2"/></fig></p></sec><sec id="Sec5"><title>Search Space</title><p id="Par21">A search space is the set of all architectures that the NAS algorithm is allowed to select. Common NAS search spaces range in size from a few thousand to over a billion architectures. Let us consider a NN as a function that, by applying operations to input variables <italic>x</italic>, produces output variables <italic>y</italic>. We can formalize it as a DAG with a set of nodes {<italic>z</italic><sup>(1)</sup><italic>,z</italic><sup>(2)</sup><italic>,&#x02026;,z</italic><sup>(<italic>k</italic>)</sup><italic>,&#x02026;</italic>}&#x02009;=&#x02009;<italic>Z</italic>. Let <italic>O</italic> be a set of operations, each node <italic>z</italic><sup>(<italic>k</italic>)</sup>, except for the first one that is considered the input node, is a tensor evaluated as follows:<disp-formula id="Equa"><alternatives><tex-math id="d33e479">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}^{\left(k\right)}={o}^{\left(k\right)}\left({I}^{\left(k\right)}\right)$$\end{document}</tex-math><mml:math id="d33e484" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>k</mml:mi></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>k</mml:mi></mml:mfenced></mml:msup><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>k</mml:mi></mml:mfenced></mml:msup></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="10278_2024_1275_Article_Equa.gif" position="anchor"/></alternatives></disp-formula>with <italic>I</italic><sup>(<italic>k</italic>)</sup> inputs form the sets of parent nodes and <italic>o</italic><sup>(<italic>k</italic>)</sup> (&#x02208;&#x02009;<italic>O</italic>) operation applied to nodes. The main operations, as per [<xref ref-type="bibr" rid="CR11">11</xref>], are convolutions, pooling, activation functions, concatenation, addition, etc. Once all the possible operations are defined, the search space can be considered either as a whole or not, giving, respectively: 1. Global search space or 2. cell-based search space. A chain and a hierarchical structure are also possible but not of interest for this work. In a global search space approach, NAS algorithms find all the components required for the entire neural network; consequently, the search space is large because the graph represents the entire network down to the single operation. Instead, in a cell-based search space approach (the one used in this work), the network is subdivided into several cells [<xref ref-type="bibr" rid="CR12">12</xref>] with different hyperparameters (e.g., the number of filters in the first cell can be different from the number of filters in the second one). This second approach was proposed because many handcrafted architectures consist of repetitions of fixed structures called cells or blocks, which can be represented by a DAG. In this case, the network macro-architecture is manually defined [<xref ref-type="bibr" rid="CR5">5</xref>], while the NAS approach is reserved for the micro-architecture inside each cell. Usually, two kinds of cells are stacked together repetitively: the <italic>normal cell</italic> that preserves the dimensions of the input; the <italic>reduction cell</italic> that reduces the spatial dimensions of the input.</p></sec><sec id="Sec6"><title>Search Strategy</title><p id="Par22">A search strategy is an optimization technique used to find a high-performing architecture in the search space. Once the search space has been defined, it is important to explore it using suitable approaches. There are generally two main categories of search strategies: the black box optimization&#x02013;based techniques (including multi-fidelity techniques) [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR14">14</xref>], and the one-shot techniques [<xref ref-type="bibr" rid="CR15">15</xref>]. However, there are some NAS methods for which both or neither category applies. Once the search space has been defined, it is important to explore it using suitable approaches. The NAS problem can be defined as follows [<xref ref-type="bibr" rid="CR11">11</xref>]: Let <italic>D</italic> be the space of all datasets, <italic>M</italic> the space of all deep learning models, and <italic>A</italic> the architecture search space, then a general deep learning algorithm &#x0039b; is defined as follows:<disp-formula id="Equb"><alternatives><tex-math id="d33e567">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\wedge :D\;x\;A\to M$$\end{document}</tex-math><mml:math id="d33e572" display="block"><mml:mrow><mml:mo>&#x02227;</mml:mo><mml:mo>:</mml:mo><mml:mi>D</mml:mi><mml:mspace width="0.277778em"/><mml:mi>x</mml:mi><mml:mspace width="0.277778em"/><mml:mi>A</mml:mi><mml:mo stretchy="false">&#x02192;</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math><graphic xlink:href="10278_2024_1275_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par23">In this setting, an architecture <italic>&#x003b1;</italic>&#x02009;<inline-formula id="IEq1"><alternatives><tex-math id="d33e590">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\in$$\end{document}</tex-math><mml:math id="d33e595"><mml:mo>&#x02208;</mml:mo></mml:math><inline-graphic xlink:href="10278_2024_1275_Article_IEq1.gif"/></alternatives></inline-formula>&#x02009;<italic>A</italic> defines the network&#x02019;s topology, parameters, hyperparameters, and regularization. Let <italic>d</italic>&#x02009;<inline-formula id="IEq2"><alternatives><tex-math id="d33e605">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\in$$\end{document}</tex-math><mml:math id="d33e610"><mml:mo>&#x02208;</mml:mo></mml:math><inline-graphic xlink:href="10278_2024_1275_Article_IEq1.gif"/></alternatives></inline-formula>&#x02009;<italic>D</italic> be a dataset, which is split into a training and a validation set (<italic>d</italic><sub>train</sub>, <italic>d</italic><sub>validation</sub>), the algorithm estimates the model <italic>m</italic><sub><italic>&#x003b1;,&#x003b8;</italic></sub>&#x02009;<inline-formula id="IEq3"><alternatives><tex-math id="d33e633">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\in$$\end{document}</tex-math><mml:math id="d33e638"><mml:mo>&#x02208;</mml:mo></mml:math><inline-graphic xlink:href="10278_2024_1275_Article_IEq1.gif"/></alternatives></inline-formula>&#x02009;<italic>M</italic><sub><italic>&#x003b1;</italic></sub> by minimizing a loss function <italic>L</italic> with a regularization term <italic>R</italic>:<disp-formula id="Equc"><alternatives><tex-math id="d33e654">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\wedge \left(\alpha , d\right)=\begin{array}{c}\text{arg}\;min\\ {m}_{\alpha , \theta }\in {M}_{\alpha }\end{array}\mathcal{L}\left({m}_{\alpha , \theta }, {d}_{train}\right)+R(\theta )$$\end{document}</tex-math><mml:math id="d33e659" display="block"><mml:mrow><mml:mo>&#x02227;</mml:mo><mml:mfenced close=")" open="("><mml:mi>&#x003b1;</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtext>arg</mml:mtext><mml:mspace width="0.277778em"/><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>&#x003b1;</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">train</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="10278_2024_1275_Article_Equc.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par24">NAS has the task of finding <italic>&#x003b1;</italic><sup>&#x02217;</sup> which maximizes an objective function <inline-formula id="IEq4"><alternatives><tex-math id="d33e721">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(\alpha )$$\end{document}</tex-math><mml:math id="d33e726"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="10278_2024_1275_Article_IEq4.gif"/></alternatives></inline-formula> of the validation partition <italic>d</italic><sub>validation</sub>. For example, considering the classification task, <inline-formula id="IEq5"><alternatives><tex-math id="d33e740">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(\alpha )$$\end{document}</tex-math><mml:math id="d33e745"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="10278_2024_1275_Article_IEq4.gif"/></alternatives></inline-formula> is usually the validation accuracy:<disp-formula id="Equd"><alternatives><tex-math id="d33e756">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\alpha }^{*}= \begin{array}{c}\text{arg}\;max\\ \alpha \in A\end{array} f(\alpha )$$\end{document}</tex-math><mml:math id="d33e761" display="block"><mml:mrow><mml:mmultiscripts><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mrow/><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:mmultiscripts><mml:mo>=</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtext>arg</mml:mtext><mml:mspace width="0.277778em"/><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="10278_2024_1275_Article_Equd.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par25">Here, the function <italic>f</italic> is considered only dependent on <inline-formula id="IEq6"><alternatives><tex-math id="d33e801">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="d33e806"><mml:mi>&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="10278_2024_1275_Article_IEq6.gif"/></alternatives></inline-formula> as all the other settings are considered fixed during the NAS procedure. Several approaches exist in literature to explore the search space, such as random search, reinforcement learning [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], gradient-based optimization differentiable ARchiTecture search (DARTS) [<xref ref-type="bibr" rid="CR17">17</xref>], and evolutionary algorithms [<xref ref-type="bibr" rid="CR7">7</xref>]. Evolutionary algorithms use the essential components of a genetic optimizer to find the best neural network [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. The approach described in [<xref ref-type="bibr" rid="CR19">19</xref>] and used in the present work requires the definition of a set of primary operations and mutation rules; the overall macro-architecture is also predetermined. Each architecture consists of a sequence of normal cells (in a stack of <italic>N</italic> cells) and reduction cells. For each stack of normal cells, the number of convolutional filters is equal to <italic>F</italic>; this number is then doubled after each reduction cell. The goal of this algorithm is to find the best reduction and normal cells (micro-architecture). Then, the search strategy works as follows: after an initial selection of <italic>P</italic> architectures, each consisting of a repetition of normal and reduction cells, the validation accuracy is evaluated by training each model from scratch. After, the evolution algorithm is applied. With <italic>C</italic> as the number of generations (number of steps of the evolutionary algorithm), a sample of <italic>S</italic> models is randomly selected with replacement. The model with the highest accuracy among the <italic>S</italic> selected samples is then picked as the parent and mutated. The following three mutation rules are chosen according to [<xref ref-type="bibr" rid="CR19">19</xref>]:<list list-type="order"><list-item><p id="Par26"><italic>Operation mutation</italic>: once a cell and a pair of hidden states are selected, one of the two operations is changed (probability: 0.475).</p></list-item><list-item><p id="Par27"><italic>Hidden state mutation</italic>: once a cell and a pair of hidden states are selected, one of the two hidden states is changed (probability: 0.475).</p></list-item><list-item><p id="Par28"><italic>Identity mutation</italic> (in which nothing changes) is also possible but with a lower probability (0.05).</p></list-item></list></p><p id="Par29">At each step, a mutation is randomly selected and then applied to a specific cell (normal or reduction) (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). The offspring is then trained, and its validation accuracy is evaluated. The oldest model is then removed from the population to keep the size <italic>P</italic> constant.
<fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>Visual representation of hidden state and operation mutations inside a cell. Hidden state mutation (top): hidden state 2 connection to operations is changed; Operation mutation (bottom): the convolutional dilatation operation (OP DIL) is changed into a convolutional separable operation (OP SEP), the average pooling (OP AVG) is left unchanged</p></caption><graphic xlink:href="10278_2024_1275_Fig2_HTML" id="MO1"/></fig></p><p id="Par30">To speed up the search, the different architectures are trained for a smaller number of epochs. Then, only a subset, consisting of the best models, is selected, eventually augmented (by increasing <italic>N</italic> and/or <italic>F</italic>), and trained for a higher number of epochs.</p></sec><sec id="Sec7"><title>Performance Estimation Strategy</title><p id="Par31">A performance estimation strategy is any method used to quickly predict the performance of neural architectures to avoid fully training the architecture. For example, while we can run a discrete search strategy by fully training and evaluating architectures chosen throughout the search, using a performance estimation strategy such as learning curve extrapolation can greatly increase the speed of the search. During the search process, it is necessary to evaluate the performance of the candidate architecture. The easiest approach that can be used is training a neural network from scratch and evaluating its performance on the validation set. Since this approach is computationally heavy and requires a lot of GPU time, different approaches are proposed in the literature to speed up the performance estimation [<xref ref-type="bibr" rid="CR5">5</xref>]. One of the most used methods that we used in the present work is the <italic>lower fidelity estimates</italic>, consisting of estimating the performance of the network from the learning curve trained for fewer epochs and from the relevant hyperparameters [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>].</p></sec></sec><sec id="Sec8"><title>Image Data</title><sec id="Sec9"><title>Cardiac Amyloidosis Diagnosis</title><p id="Par32">CA is a cardiomyopathy associated with the deposition of protein fibrils in the extracellular space of the heart [<xref ref-type="bibr" rid="CR22">22</xref>]. Several types of amyloidosis can usually be distinguished. The most relevant in cardiac amyloidosis are immunoglobulin light-chain amyloidosis (AL) and transthyretin-related amyloidosis (ATTR). The main problem of this disease is that the early clinical symptoms can be confused with other conditions such as hypertensive heart disease or heart hypertrophy secondary to aortic valve stenosis. Moreover, these two subtypes of amyloidosis require different therapies: AL patients are usually treated with chemotherapy or stem cell transplantation, while ATTR patients are subjected to small RNA-silencing molecules or stabilizers [<xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR24">24</xref>]. Therefore, it is very important not only to diagnose the presence of amyloidosis as soon as possible but also to be able to characterize which subtype it is. Nowadays, the diagnosis of ATTR in the absence of a monoclonal disease can be obtained by scintigraphy with bone-seeking agent labelled with 99mTc. Instead, when a monoclonal component in serum and/or urine is present or for the diagnosis of AL, a histologic approach, often by endocardiac biopsy is required [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]. The major drawback of cardiac biopsy is the risk associated with the invasiveness of the technique. Therefore, researchers are trying to use non-invasive methods such as medical imaging to obtain the information needed for early diagnosis [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>]. In PET imaging, characterization of the CA can be performed by the evaluation of specific quantitative indexes such as standardized uptake value (SUV) SUV<sub>max</sub>, SUV<sub>mean</sub> and molecular volume obtained with [18F]-Florbetaben by acquiring early and late static 3D images of the thorax after the injection of the radiopharmaceutical [<xref ref-type="bibr" rid="CR28">28</xref>&#x02013;<xref ref-type="bibr" rid="CR30">30</xref>]. Alternatively, a dynamic approach can also be taken to evaluate indexes that allow CA diagnosis [<xref ref-type="bibr" rid="CR31">31</xref>]. Being able to make an accurate differential diagnosis from a single static PET images acquired in an early phase, i.e., after a few minutes from the injection of the tracer, should have the double advantage of reducing the waiting time for the examination to be performed (for the patient) and obtaining a better organization for the nuclear medicine laboratory. Accordingly, in the present work, a set of cardiac amyloidosis images, consisting of 3D static PET acquired 15 min after the injection of the [18F]-Florbetaben, was used to test the goodness of the proposed approach.</p></sec><sec id="Sec10"><title>Subjects and Cardiac PET Data Acquisition</title><p id="Par33">A total of 47 subjects are included in this retrospective study, including 28 patients with systemic amyloidosis and heart involvement (13 patients with AL and 15 patients with ATTR cardiac amyloidosis, respectively) and 19 control patients with the clinical suspicion of CA, that received an alternative diagnosis, such as left-ventricle hypertrophy secondary to aortic-valve stenosis, primary hypertrophic cardiomyopathy, or hypertensive cardiac hypertrophy. Patients with ischemic heart disease, chronic liver disease, or severe renal failure were not included in the study. Diagnosis of CA was based on clinical examination, biomarkers positivity, electrocardiogram, echocardiography, bone-scintigraphy, cardiac magnetic resonance (CMR), and histological evidence of amyloid deposition according to the most recent cardiological evidence and guidelines [<xref ref-type="bibr" rid="CR32">32</xref>, <xref ref-type="bibr" rid="CR33">33</xref>]. Further details on patients&#x02019; characteristics are described in [<xref ref-type="bibr" rid="CR10">10</xref>]. The study was approved by the institutional ethics committee and the AIFA (Agenzia Italiana del Farmaco) committee; all subjects signed an informed consent form. The study complied with the Declaration of Helsinki. Each subject underwent PET/CT examination. A Discovery RX VCT 64-slice tomography (GE Healthcare, Milwaukee, WI, USA) was used for image acquisition. Firstly, a low-dose-computed tomography (CT) (tube current 30&#x000a0;mA, tube voltage 120&#x000a0;kV, effective dose of 1&#x000a0;mSv), covering the heart, was performed for attenuation correction. Then, 40&#x000a0;min of PET data were acquired, starting at the time of injection of an intravenous bolus of [18F]-Florbetaben (300 Mbq/1&#x000a0;ml) followed by a saline flush of 10&#x000a0;ml (1&#x000a0;ml/s). The raw PET list mode data file was histogrammed between 15 and 20&#x000a0;min of post-injection, to create a single static sinogram. Then, 3D static PET images were reconstructed using the ordered subset expectation maximization (OSEM) iterative algorithm with three iterations and 21 subsets. Each 3D volume consisted of 47 axial slices with a 128&#x02009;&#x000d7;&#x02009;128 pixels matrix.</p></sec></sec><sec id="Sec11"><title>Image Pre-processing</title><p id="Par34">From the reconstructed axial slices of each volume, only those covering the heart were taken into consideration in the study; accordingly, for each patient, the number of images considered varied from a minimum of eight to a maximum of 19 slices. In addition, image cropping was performed. The final dimensions of the images are of 77&#x02009;&#x000d7;&#x02009;104 pixels. A total of 592 2D images (193 from controls, 240 from AL-subtype patients, and 159 from ATTR-subtype) have been considered in the study. In Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, examples of reconstructed and cropped images from AL, ATTR, and CTRL subjects are shown. To achieve better performance during training and avoid overfitting, data augmentation has been implemented. Following, an affine transformation was used [<xref ref-type="bibr" rid="CR10">10</xref>], being recognized in literature as the most suitable methodology for the augmentation of data sets in medical imaging [<xref ref-type="bibr" rid="CR34">34</xref>]. Specifically, each image was randomly translated in both row and column directions of a maximum of 10 pixels and randomly rotated of maximum&#x02009;&#x000b1;&#x02009;10&#x000b0;. The affine transformation was applied ten times for each input image. The data augmentation is performed as a one-time preprocessing step and only on the training set. To avoid data leakage when evaluating the results, data splitting was performed at the patient&#x02019;s level, avoiding the presence of slices from the same subjects both in the training/validation and the test set. After data augmentation, the overall dimensions of the sets are the following:<list list-type="bullet"><list-item><p id="Par35">The training set consists of 384 images augmented to 3840 (10&#x02009;&#x000d7;&#x02009;data augmentation; 1550 AL, 1010 ATTR, 1280 CTRL).</p></list-item><list-item><p id="Par36">The validation set consists of 96 images (40 AL; 30 ATTR; 26 CTRL).</p></list-item><list-item><p id="Par37">The test set consists of 112 images (45 AL; 33 ATTR; 34 CTRL).</p></list-item></list><fig id="Fig3"><label>Fig.&#x000a0;3</label><caption><p>Example of images from the different classes: values are in SUV</p></caption><graphic xlink:href="10278_2024_1275_Fig3_HTML" id="MO3"/></fig></p></sec><sec id="Sec12"><title>Hardware and Software Specs</title><p id="Par38">The overall algorithm is run on a PC, with Ubuntu Operative System 22.04.3 LTS, equipped with a Core i7 4790k 4-core CPU, 32GB of Ram and an Nvidia Titan Xp GPU with 12 GB of VRAM. The algorithm is implemented in Python 3.9.13 using the Anaconda environment 22.9.0 with the respective libraries. Pytorch 1.13.1 with CUDA 11.7 and CuDNN 8.5 was used for the core DL development.</p></sec><sec id="Sec13"><title>Implementation of the Algorithm and Methods Detail</title><p id="Par39">The approach used to classify the datasets is based on the method described in &#x0201c;<xref rid="Sec3" ref-type="sec">Theory</xref>&#x0201d;.</p><sec id="Sec14"><title>Choice of the Primitive Operations</title><p id="Par40">The primitive operations that can be used to build a normal or a reduction cell have been selected based on [<xref ref-type="bibr" rid="CR9">9</xref>] and [<xref ref-type="bibr" rid="CR19">19</xref>]. To avoid redundancy, convolutions, max pooling, and mean pooling were restricted to 3&#x02009;&#x000d7;&#x02009;3; indeed, [<xref ref-type="bibr" rid="CR9">9</xref>] shows that larger kernel sizes like 5&#x02009;&#x000d7;&#x02009;5 and 7&#x02009;&#x000d7;&#x02009;7 can be substituted by stacking appropriate 3&#x02009;&#x000d7;&#x02009;3 convolutions. In this way, each operation possesses distinct properties that cannot be substituted by others. The chosen operations are defined through a dictionary. Following [<xref ref-type="bibr" rid="CR12">12</xref>], 1&#x02009;&#x000d7;&#x02009;1 convolutions are inserted to ensure equal dimensions of the two hidden input states. Each convolution consists of a sequence of Conv-ReLU-batch normalization. Batch normalization is a popular technique used in neural networks to improve performance and stability. This is achieved by normalizing the output of a layer to have a mean of zero and a standard deviation of one [<xref ref-type="bibr" rid="CR35">35</xref>]. This allows the network to learn more efficiently and prevents overfitting.</p></sec><sec id="Sec15"><title>Implementation of the Evolutionary Algorithm</title><p id="Par41">To determine the best model for the provided datasets, some parameters were set.<list list-type="bullet"><list-item><p id="Par42">The number of filters of the first cell (<italic>F</italic>) (this number is doubled before each reduction cell) was initially set equal to 4.</p></list-item><list-item><p id="Par43">The number of operations for each cell. For example, <italic>n</italic> operations correspond to <italic>n-1</italic> hidden states: 2 as inputs, one as output, and the remaining <italic>n-4</italic> are generated by applying the selected operations to the previously selected hidden states. The number of operations was set to 6.</p></list-item><list-item><p id="Par44">The number of classes for the classification task: equal to 3 corresponding to CTRL class (i.e., control subjects), AL and ATTR classes.</p></list-item><list-item><p id="Par45">The number of input channels is equal to one since the PET images are grayscale.</p></list-item><list-item><p id="Par46">The number of layers of the architecture is 4, as shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>.</p></list-item><list-item><p id="Par47">The number of starting architectures <bold>P</bold> is 100, with 900 evolutionary steps <bold>C</bold> (in each step 1 sample was mutated (<bold>S</bold>)).</p></list-item></list><fig id="Fig4"><label>Fig.&#x000a0;4</label><caption><p>Structure of the architecture we are looking for</p></caption><graphic xlink:href="10278_2024_1275_Fig4_HTML" id="MO4"/></fig></p><p id="Par48">An example for the first convolutional operation in the normal cell could be:</p><p id="Par49"><bold>x</bold>&#x02009;=&#x02009;Conv2D(<bold>input_tensor,</bold>
<italic>F</italic>&#x02009;=&#x02009;4, kernel_size&#x02009;=&#x02009;(3, 3), strides&#x02009;=&#x02009;(1, 1), padding&#x02009;=&#x02009;&#x02018;same&#x02019;)</p><p id="Par50"><bold>x</bold>&#x02009;=&#x02009;ReLU(<bold>x</bold>)</p><p id="Par51"><bold>x</bold>&#x02009;=&#x02009;BatchNormalization(<bold>x</bold>)</p><p id="Par52">The NAS algorithm was run five times (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>). For each run, a first training step using 25 epochs was performed on a population of 100 evolving individuals, maximizing the overall classification accuracy. In the second step, the best five architectures underwent a further 175 epochs training. Hence, 5&#x02009;&#x000d7;&#x02009;(P&#x02009;+&#x02009;C)&#x02009;=&#x02009;5000 individuals were generated in the first step and 25 (5&#x02009;&#x000d7;&#x02009;5) were more deeply analyzed in the second step. In the final step, the best individual (i.e., the one with the higher overall accuracy) was identified. Once the best model is selected, a stochastic <italic>k</italic>-fold validation of the best model is performed using five random splits of the training/validation dataset. All the training was done using the Adam optimizer, with a learning rate of 1e-3, cross-entropy loss, and a batch size of 32. Detailed values of the hyperparameters used for the architecture search algorithm are shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>.<fig id="Fig5"><label>Fig.&#x000a0;5</label><caption><p>Overall performance estimation strategy and model selection</p></caption><graphic xlink:href="10278_2024_1275_Fig5_HTML" id="MO5"/></fig><table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>Hyperparameters for the architecture search algorithm</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Hyperparameter</th><th align="left">Value</th></tr></thead><tbody><tr><td align="left">Starting number of filters <bold>F</bold></td><td align="left">4</td></tr><tr><td align="left">Per cell operations</td><td align="left">6</td></tr><tr><td align="left">Number of classes</td><td align="left">3</td></tr><tr><td align="left">Number of channels</td><td align="left">1</td></tr><tr><td align="left">Number of layers</td><td align="left">4</td></tr><tr><td align="left">Number of starting architectures <bold>P</bold></td><td align="left">100</td></tr><tr><td align="left">Number of evolutionary steps <bold>C</bold></td><td align="left">900</td></tr><tr><td align="left">Number of mutated samples per step <bold>S</bold></td><td align="left">1</td></tr><tr><td align="left">Number of training epochs</td><td align="left">25</td></tr><tr><td align="left">Number of further training epochs</td><td align="left">175</td></tr><tr><td align="left">Batch size</td><td align="left">32</td></tr><tr><td align="left">Loss function</td><td align="left">Cross-entropy loss</td></tr><tr><td align="left">Learning rate</td><td align="left">1e-3</td></tr><tr><td align="left">Optimizer</td><td align="left">Adam (default parameters)</td></tr></tbody></table></table-wrap></p><p id="Par53">Pseudocode for the implemented algorithm is provided below. From top to bottom: initialization, initial model population creation, evolution process, final training of the best architectures and output.<graphic position="anchor" xlink:href="10278_2024_1275_Figa_HTML" id="MO6"/></p></sec></sec><sec id="Sec16"><title>CAclassNET as Handcrafted Neural Network for Comparison</title><p id="Par54">To evaluate the goodness of the net obtained by the NAS methodology, a comparison was made with the CNN, named CAclassNET, previously proposed by the authors in [<xref ref-type="bibr" rid="CR10">10</xref>]. In the present work, the CAclassNET was newly implemented by using Python and Pytorch facilities (in [<xref ref-type="bibr" rid="CR10">10</xref>], it was implemented in Matlab), for a better comparison between the two networks, and trained with the optimized hyperparameters described in [<xref ref-type="bibr" rid="CR10">10</xref>]. The training was then repeated five times to statistically evaluate the performance of the classifier on the provided dataset.</p></sec></sec><sec id="Sec17"><title>Results</title><p id="Par55">The initial and final validation accuracy results for each individual architecture among the best five are reported in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref> for each run.
<table-wrap id="Tab2"><label>Table&#x000a0;2</label><caption><p>Best five individuals for each of the five runs</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2">Individual #</th><th align="left">Initial validation accuracy<break/>(25 epochs)</th><th align="left">Final validation accuracy<break/>(175 further epochs)</th></tr></thead><tbody><tr><td align="left" rowspan="5">1st RUN</td><td align="left">5</td><td align="left">75.00%</td><td align="left">72.92%</td></tr><tr><td align="left">250</td><td align="left">65.63%</td><td align="left"><italic>84.38%</italic></td></tr><tr><td align="left">421</td><td align="left">63.54%</td><td align="left">87.50%</td></tr><tr><td align="left">688</td><td align="left"><italic>63.54%</italic></td><td align="left">67.71%</td></tr><tr><td align="left">990</td><td align="left">78.13%</td><td align="left">75.00%</td></tr><tr><td align="left" rowspan="5">2nd RUN</td><td align="left"><bold>363</bold></td><td align="left">76.04%</td><td align="left"><bold><italic>90.63%</italic></bold></td></tr><tr><td align="left">376</td><td align="left">68.75%</td><td align="left">79.16%</td></tr><tr><td align="left">849</td><td align="left">80.21%</td><td align="left">84.38%</td></tr><tr><td align="left">878</td><td align="left">85.42%</td><td align="left">82.29%</td></tr><tr><td align="left">887</td><td align="left">81.25%</td><td align="left">77.08%</td></tr><tr><td align="left" rowspan="5">3rd RUN</td><td align="left">372</td><td align="left">85.42%</td><td align="left">82.29%</td></tr><tr><td align="left">487</td><td align="left">66.66%</td><td align="left"><italic>89.58%</italic></td></tr><tr><td align="left">562</td><td align="left">76.04%</td><td align="left">85.41%</td></tr><tr><td align="left">666</td><td align="left">65.63%</td><td align="left">80.21%</td></tr><tr><td align="left">995</td><td align="left">82.29%</td><td align="left">83.33%</td></tr><tr><td align="left" rowspan="5">4th RUN</td><td align="left">49</td><td align="left">69.79%</td><td align="left">69.54%</td></tr><tr><td align="left">129</td><td align="left">71.88%</td><td align="left">77.08%</td></tr><tr><td align="left">268</td><td align="left">72.91%</td><td align="left">78.13%</td></tr><tr><td align="left">342</td><td align="left">65.63%</td><td align="left">80.21%</td></tr><tr><td align="left">929</td><td align="left">73.96%</td><td align="left"><italic>85.42%</italic></td></tr><tr><td align="left" rowspan="5">5th RUN</td><td align="left">8</td><td align="left">59.38%</td><td align="left"><italic>80.21%</italic></td></tr><tr><td align="left">472</td><td align="left">73.96%</td><td align="left">67.71%</td></tr><tr><td align="left">602</td><td align="left">70.83%</td><td align="left">76.04%</td></tr><tr><td align="left">669</td><td align="left">77.08%</td><td align="left">79.17%</td></tr><tr><td align="left">799</td><td align="left">77.08%</td><td align="left">65.63%</td></tr></tbody></table></table-wrap></p><p id="Par56">Accuracy values were normally distributed (<italic>p</italic>&#x02009;=&#x02009;0.485, Shapiro-Wilkinson test). One-way analysis of variance (ANOVA) detected no significant accuracy difference (<italic>p</italic>&#x02009;=&#x02009;0.829) in the five final validation runs (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). Tukey test has been used to detect anomalous observations in accuracy values, and no outliers have been detected. Of the five runs, the second run yielded the best validation accuracy, achieved by individual 363, with a final accuracy of 90.63%. The relevant confusion matrix for the validation set is shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>. According to such results, further deep analysis was performed on this net (NAS-Net in the following).<fig id="Fig6"><label>Fig.&#x000a0;6</label><caption><p>Confusion matrix on the validation set for the best model</p></caption><graphic xlink:href="10278_2024_1275_Fig6_HTML" id="MO7"/></fig></p><p id="Par57">The structure of the normal and reduction cells is shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>; the first two hidden states, <italic>c</italic><sub><italic>k</italic>&#x02212;2</sub> and <italic>c</italic><sub><italic>k</italic>&#x02212;1</sub>, represent the two inputs of each cell, while <italic>c</italic><sub><italic>k</italic></sub> represents the output state.<fig id="Fig7"><label>Fig.&#x000a0;7</label><caption><p>Graphs describing the architecture of the normal (top) and reduction (bottom) cell</p></caption><graphic xlink:href="10278_2024_1275_Fig7_HTML" id="MO8"/></fig></p><p id="Par58">As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>, two kinds of convolution are used: dilated convolutions (DIL_CONV) and dilated separable convolutions (SEP_CONV). Each convolution operation consists of a sequence: 1. convolution; 2. ReLU; 3. batch normalization (BN). For separable convolutions, these operations are repeated twice [<xref ref-type="bibr" rid="CR12">12</xref>]. The NAS-Net was trained five times, splitting the training and validation entries differently in a stochastic manner to statistically evaluate the performance of the classifier. For each run, the parameters were reset.</p><p id="Par59">Figure <xref rid="Fig8" ref-type="fig">8</xref> shows the validation and training loss of the classifier over epochs; continuous lines are the mean values of the five runs, and shadowed regions cover 95% of the confidence interval. For each run, the performance of the NAS-Net on the test set (unseen data) was also evaluated.<fig id="Fig8"><label>Fig.&#x000a0;8</label><caption><p>Average training (blue) and validation (red) accuracy (<bold>a</bold>) and loss (<bold>b</bold>) with 95% confidence intervals (shaded areas). On the <italic>x</italic>-axis the epochs</p></caption><graphic xlink:href="10278_2024_1275_Fig8_HTML" id="MO9"/></fig></p><p id="Par60">Figure&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref> shows two examples of confusion matrices obtained during the different runs (the best and the worst runs, respectively). Table <xref rid="Tab3" ref-type="table">3</xref> summarizes the overall classifier performances, evaluated in terms of sensitivity, specificity, and accuracy. From repeated measurements ANOVA analysis, it results that sensitivity and specificity values in all three comparisons (i.e., AL vs. ATTR, AL vs. CTRL, and ATTR vs. CTRL) as well as accuracy values in AL vs. ATTR and AL vs. CTRL, are significantly different (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001); no significant difference was detected between ATTR vs. CTRL accuracy values (<italic>p</italic>&#x02009;=&#x02009;0.173). The overall mean accuracy of the best classifier for the test set was 76<italic>.</italic>95% (&#x000b1;&#x02009;2<italic>.</italic>13%). The time needed for a single run of the evolutionary algorithm and to evaluate the 5 best architectures was, on average, about 12&#x000a0;h and 30&#x000a0;min. Every subsequent retraining of the best model required about 20&#x000a0;min.<fig id="Fig9"><label>Fig.&#x000a0;9</label><caption><p>Best (left) and worst (right) confusion matrices obtained during two of the five runs</p></caption><graphic xlink:href="10278_2024_1275_Fig9_HTML" id="MO10"/></fig><table-wrap id="Tab3"><label>Table&#x000a0;3</label><caption><p>Performance of the NAS-Net model (%)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Class</th><th align="left">Sensitivity</th><th align="left">Accuracy</th><th align="left">Specificity</th></tr></thead><tbody><tr><td align="left">AL</td><td align="left">98.7&#x02009;&#x000b1;&#x02009;2.9</td><td align="left">99.3&#x02009;&#x000b1;&#x02009;1.1</td><td align="left">99.7&#x02009;&#x000b1;&#x02009;0<italic>.</italic>7</td></tr><tr><td align="left">ATTR</td><td align="left">93.3&#x02009;&#x000b1;&#x02009;7.8</td><td align="left">78.0&#x02009;&#x000b1;&#x02009;2.9</td><td align="left">70.9&#x02009;&#x000b1;&#x02009;3.7</td></tr><tr><td align="left">CTRL</td><td align="left">35.8&#x02009;&#x000b1;&#x02009;14.6</td><td align="left">77.1&#x02009;&#x000b1;&#x02009;2.0</td><td align="left">96.7&#x02009;&#x000b1;&#x02009;4.4</td></tr></tbody></table></table-wrap></p><sec id="Sec18"><title>Comparison with the Handcrafted Neural Network</title><p id="Par61">The average accuracy of the CAclassNET was 99.38% for the training set and 87.35% for the validation set. Table <xref rid="Tab4" ref-type="table">4</xref> shows the performance of the handcrafted classifier as measured by sensitivity, accuracy, and specificity. Similarly to the results of Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>, also for Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref>, the ANOVA analysis was performed: sensitivity and specificity values in all three comparisons, as well as for accuracy values in AL vs. ATTR and AL vs. CTRL, are significantly different (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001); no significant difference was detected between ATTR vs. CTRL accuracy values (<italic>p</italic>&#x02009;=&#x02009;0.8). The overall accuracy on the test set was 79<italic>.</italic>21%&#x02009;&#x000b1;&#x02009;3<italic>.</italic>4%. The performances in terms of sensitivity, accuracy, and specificity are better than those of a doctor with more than 10&#x000a0;years of experience in cardiac nuclear medicine in fact, they resulted to be as follows [<xref ref-type="bibr" rid="CR10">10</xref>]: sensitivity, specificity, and accuracy equal to 0.533, 0.744, and 0.673 respectively for AL patients, 0.314, 0.802, and 0.665 for ATTR patients, 0.562, 0.667, and 0.627 for CTRL.
<table-wrap id="Tab4"><label>Table&#x000a0;4</label><caption><p>Performance of the CAclassNET classifier (%)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Class</th><th align="left">Sensitivity</th><th align="left">Accuracy</th><th align="left">Specificity</th></tr></thead><tbody><tr><td align="left">AL</td><td align="left">99.0&#x02009;&#x000b1;&#x02009;1.6</td><td align="left">99.6&#x02009;&#x000b1;&#x02009;0<italic>.</italic>6</td><td align="left">100.0&#x02009;&#x000b1;&#x02009;0<italic>.</italic>0</td></tr><tr><td align="left">ATTR</td><td align="left">76.2&#x02009;&#x000b1;&#x02009;14.0</td><td align="left">79.6&#x02009;&#x000b1;&#x02009;3.5</td><td align="left">80.1&#x02009;&#x000b1;&#x02009;5.6</td></tr><tr><td align="left">CTRL</td><td align="left">55.8&#x02009;&#x000b1;&#x02009;11.0</td><td align="left">79.2&#x02009;&#x000b1;&#x02009;3.3</td><td align="left">89.4&#x02009;&#x000b1;&#x02009;6.2</td></tr></tbody></table></table-wrap></p><p id="Par62">Table <xref rid="Tab5" ref-type="table">5</xref> summarizes the differences between the two models in four aspects: number of parameters, time to define an architecture, training time, and classification time of a new image. Regarding accuracy at the subject level, both the architecture developed using the NAS method and CAclassNET are able to consistently and correctly identify 8 (3 CTRLs, 3 ALs, 2 ATTRs) out of the 11 (5 CTRLs, 3 ALs, 3 ATTRs) subjects in the test dataset. Note that ALs are always correctly classified.
<table-wrap id="Tab5"><label>Table&#x000a0;5</label><caption><p>Comparison between the best architecture discovered by the NAS algorithm (NAS-Net) and CAclassNET</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Features</th><th align="left">NAS-Net</th><th align="left">CAclassNet</th></tr></thead><tbody><tr><td align="left">Number of parameters</td><td align="left">2.763&#x02009;&#x000d7;&#x02009;10<sup>3</sup></td><td align="left">93.827&#x02009;&#x000d7;&#x02009;10<sup>3</sup></td></tr><tr><td align="left">Implementation time</td><td align="left">&#x02009;~&#x02009;8&#x000a0;h per 1000 architectures evaluated</td><td align="left">days/weeks</td></tr><tr><td align="left"><p>Training time</p><p>(200 epochs) [s]</p></td><td align="left">224.67 (&#x02243; 3<italic>&#x02032;45&#x02033;</italic>)</td><td align="left">187<italic>.</italic>06(&#x02243; 3&#x02032;7&#x02033;)</td></tr><tr><td align="left">Classification time of a new image [ms]</td><td align="left">6<italic>.</italic>4</td><td align="left">3<italic>.</italic>4</td></tr></tbody></table></table-wrap></p></sec></sec><sec id="Sec19"><title>Discussion</title><sec id="Sec20"><title>Contribution of This Work</title><p id="Par63">The main objective of this study was to demonstrate the effectiveness of the neural architecture search algorithms for medical image classification, early acquired [18F]-Florbetaben PET images in particular. The use of NAS methods for defining the best model for image analysis has the great advantage of greatly reducing the operator&#x02019;s contribution in defining the structure and parameters to be used, making these operations almost completely automatic. Therefore, the effort required to design the deep learning models is reduced, and researchers can focus on other aspects, such as data pre-processing and model tuning, improving the performance of the models found. Unlike ordinary images, in which large databases are available online, the analysis of medical images using deep learning methods is often challenging due to privacy concerns and the rarity of certain pathologies. This is especially true for PET images, where datasets are increasingly limited. In literature, some attempts have been made, and some methods based on the NAS approach have been proposed on medical images, mainly for image segmentation [<xref ref-type="bibr" rid="CR9">9</xref>], but, as far as we know, there are no studies on the classification of cardiac amyloidosis from early acquired [18F]-Florbetaben PET images; in fact, we can state that only the authors have implemented a CNN that performs this task [<xref ref-type="bibr" rid="CR10">10</xref>], but not using NAS technology.</p></sec><sec id="Sec21"><title>Methodology</title><p id="Par64">The cell-based search space method was selected in this work. This search space consists of architectures composed of repeating blocks of two main types: normal and reduction cells. Each cell consists of a DAG that describes how the different states are combined to form a new state using primary operations. Search space is then explored using an aged evolutionary algorithm: the oldest individual in history dies at each generation. The results obtained after running the proposed NAS approach five times, after 25 epochs had an accuracy from a minimum of 59.38% (see Table <xref rid="Tab2" ref-type="table">2</xref>, fifth run) to a maximum of 85.42% (see Table <xref rid="Tab2" ref-type="table">2</xref>, second and third run), with a mean value of 73.04%. Therefore, already after 25 epochs, the NAS approach has given quite promising results. But the results obviously improved after a further 175 epochs, bringing the accuracy to a minimum value of 65.63% (see Table <xref rid="Tab2" ref-type="table">2</xref>, fifth run) and a maximum of 90.63% (Table <xref rid="Tab2" ref-type="table">2</xref>, second run) with a mean of 79.24%. The model giving the highest accuracy has been considered as the network for cardiac amyloidosis classification. The proposed two-step approach was designed to obtain a reasonable processing time for individual selection. The structure of the best network model obtained by the proposed NAS approach (NAS-Net) is shown in Figs. <xref rid="Fig4" ref-type="fig">4</xref> and <xref rid="Fig7" ref-type="fig">7</xref>; the behavior of the architecture as a graph is evident both for the structure as a whole and for the individual cells. The identity operations in the reduction cell (Fig. <xref rid="Fig7" ref-type="fig">7</xref>) are introduced to maintain the network&#x02019;s depth constant.</p></sec><sec id="Sec22"><title>Results</title><p id="Par65">The confusion matrix obtained for the network with higher validation accuracy (see Fig. <xref rid="Fig6" ref-type="fig">6</xref>) demonstrates that the determination of the cardiac amyloidosis AL class is optimal, with some uncertainty between the ATTR class and controls. Training and validation accuracy trends of the selected model, shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>, have a typical shape in network analysis: both curves increase over epochs as the model learns to make more appropriate predictions on both sets. A gap exists between training and validation curves being training higher than validation; this is expected and mainly due to the low number of data available as it happens to all imaging techniques that require, for example, the use of ionizing tracers and/or invasive maneuvers for which images are acquired only if strictly necessary. However, it is worth to note that at 200 epochs the accuracy for validation data is anyway quite high, having the mean value equal to 98.3% (see Fig. <xref rid="Fig8" ref-type="fig">8</xref>). Also, for training and validation losses both curves decrease over epochs. This is an indication that the model is learning to make more accurate predictions for the training and validation set. Both confusion matrices (Fig. <xref rid="Fig9" ref-type="fig">9</xref>) and sensitivity, accuracy, and specificity values (Table <xref rid="Tab3" ref-type="table">3</xref>) show that the network well determines AL cardiac amyloidosis patients. In contrast, ATTR amyloidosis patients and controls are sometimes incorrectly diagnosed, with NAS-Net privileging sensitivity for ATTRs (93.3%) and specificity for CTRLs (96.7%). This is well documented in literature where it is asserted that the cardiac PET imaging using [18F]-Florbetaben well characterizes the presence of type AL amyloidosis, while it is not able to determine the ATTR and to distinguish it from other pathologies or from the non-presence of cardiac pathology [<xref ref-type="bibr" rid="CR30">30</xref>]. This is even true when considering early acquired images, i.e., at 15 min after injection [<xref ref-type="bibr" rid="CR10">10</xref>], as it is in our study. On the other hand, by reducing the classification task to AL vs. non-AL subjects, the performance of the discovered classifier is optimal, well identifying subjects affected by CA of type AL. To demonstrate the validity of the proposed approach, that is, it automatically generates an optimal network that is comparable with the best one obtainable manually, a comparison has been made with a state-of-art handcrafted CNN, carefully tuned on the same data set. In fact, from Tables <xref rid="Tab3" ref-type="table">3</xref> and <xref rid="Tab4" ref-type="table">4</xref>, we can see that the two networks showed a similar performance pattern, with very good sensitivity, accuracy, and specificity values for the AL class and lower values for ATTR and CTRL classes. All values were &#x0003e;70% except for the CTRL sensitivity value for both networks. Moreover, in Table <xref rid="Tab5" ref-type="table">5</xref>, the performances of the two nets are compared, showing a 40 times higher value of the number of parameters for the CAclassNet, while the training processing time and the classification time of a new image are slightly higher for NAS-based net. Overall, we can say that the NAS-based algorithm found a model whose performance is comparable to that available in the literature. Indeed, it correctly discriminates between AL and non-AL images but shows intermediate performance in classifying ATTR and CTRL.</p></sec><sec id="Sec23"><title>Advantages, Disadvantages, and Limitations</title><p id="Par66">The implementation of this approach made it possible to clearly highlight both the advantages and disadvantages of this technique. A great advantage is that the best architecture can be automatically identified that is better suited to the specific problem at hand. The disadvantage is the computational cost since multiple neural networks must be trained and evaluated to find the best one. In this work, to reduce this weakness, we reduced the number of training epochs to speed up the process of exploring search space. Then, the best architectures were trained for more epochs to find the best-discovered model. However, it is worth noting that such optimal parameters search phase, which requires high processing times, in conventional methods has still to be performed, and it is done with the continuous contribution of the operator and, therefore, not automatically. While the definition and training of CAclassNET required repeated architecture evaluations and, only subsequently, hyperparameter tuning, the evolutionary algorithm set for the NAS network automatically selects the best architecture once the hyperparameters are specified (Table <xref rid="Tab1" ref-type="table">1</xref>). In the present work, these hyperparameters were set according to empirical knowledge in NAS literature, reducing the time required for hyperparameter search. One hidden cost that could also be considered is the human-production cost associated with the implementation of the code used for this work, which, however, can be reused as an asset for future model development (code once, run forever).</p><p id="Par67">The network generated here with the NAS method is aimed at classifying amyloidosis from PET data; in the present work, we have not evaluated whether this net can be adapted to other image classification tasks. Anyway, we suppose that, either by re-running the evolutionary algorithm on new data/with different hyperparameters or with appropriate network modifications typical of transfer learning, the methods shown in this work could be used for the development of any convolutional model for the classification of biomedical images (or even other tasks, with appropriate modifications).</p><p id="Par68">One limitation in this work is the low amount of data: data relevant to 47 subjects are considered, for a total of 592 2D PET images. This is not a lot of data for deep learning analysis, as it is often the case for biomedical images. But one of the purposes of this work was precisely to evaluate whether the NAS methodology was efficient even when the data available is rather limited.</p></sec></sec><sec id="Sec24"><title>Conclusions</title><p id="Par69">In the present work, the NAS approach was applied to classify medical images. In particular, the main objective has been to evaluate the possibility of automatically finding an optimal network for the classification of cardiac amyloidosis from [18F]-Florbetaben PET images acquired 15 min after injection. The results obtained are very promising, being very similar to those available in the literature for CNNs designed manually, while for the proposed approach this task was carried out completely automatically.</p></sec></body><back><fn-group><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>Filippo Bargagna and Donato Zigrino contributed equally to this work.</p></fn></fn-group><ack><title>Acknowledgements</title><p>The authors would like to thank the student Marta Beltrami who provided the results of the subject-based classification, a study carried out as part of her master&#x02019;s thesis.</p></ack><notes notes-type="author-contribution"><title>Author Contribution</title><p>All authors contributed to the study conception and design. All authors read and approved the final manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open access funding provided by Universit&#x000e0; di Pisa within the CRUI-CARE Agreement.</p></notes><notes notes-type="data-availability"><title>Data Availability</title><p>Data used in this article are not available due to it being property of the healthcare institution.</p></notes><notes notes-type="data-availability"><title>Code Availability</title><p>Developed code is available upon request to the corresponding author.</p></notes><notes><title>Declarations</title><notes id="FPar12"><title>Ethics Approval</title><p id="Par70">Relating to the data used in this article, both the AIFA (Agenzia Italiana del Farmaco) committee and the institutional ethics committee gave their approval to the study. The research complied with the Helsinki Declaration.</p></notes><notes id="FPar13" notes-type="COI-statement"><title>Competing Interests</title><p id="Par71">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">D. Shen, G. Wu, H. Il Suk, Deep Learning in Medical Image Analysis, Annu. Rev. Biomed. Eng. 19 (2017) 221&#x02013;248. 10.1146/annurev-bioeng-071516-044442.</mixed-citation></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Suzuki</surname><given-names>K</given-names></name></person-group><article-title>Overview of deep learning in medical imaging, Radiol</article-title><source>Phys. Technol.</source><year>2017</year><volume>10</volume><fpage>257</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1007/s12194-017-0406-5</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">K. Suzuki, Overview of deep learning in medical imaging, Radiol. Phys. Technol. 10 (2017) 257&#x02013;273. 10.1007/s12194-017-0406-5.</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">P. Ren, Y. Xiao, X. Chang, P.Y. Huang, Z. Li, X. Chen, X. Wang, A comprehensive survey of neural architecture search: Challenges and solutions, ACM Comput. Surv. 54 (2021). 10.1145/3447582.</mixed-citation></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Alzubaidi</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Duan</surname><given-names>Y</given-names></name><name><surname>Gu</surname><given-names>Y</given-names></name></person-group><article-title>A comparison review of transfer learning and self-supervised learning: Definitions, applications, advantages and limitations</article-title><source>Expert Systems with Applications</source><year>2024</year><volume>242</volume><fpage>122807</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2023.122807</pub-id></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Z. Zhao, L. Alzubaidi, J. Zhang, Y. Duan, Y. Gu, A comparison review of transfer learning and self-supervised learning: Definitions, applications, advantages and limitations, Expert Systems with Applications, (2024) 242: 122807, 10.1016/j.eswa.2023.122807.</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">T. Elsken, J.H. Metzen, F. Hutter, Neural Architecture Search: A Survey, (2018). <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1808.05377">http://arxiv.org/abs/1808.05377</ext-link>.</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">B. Baker, O. Gupta, N. Naik, R. Raskar, Designing Neural Network Architectures using Reinforcement Learning, (2016). <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1611.02167">http://arxiv.org/abs/1611.02167</ext-link>.&#x000a0;<italic>in Proc. Int. Conf. Learn. Represent. (ICLR), Mar. 2017, pp. 1&#x02013;18. doi: 1611.02167</italic>.</mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">E. Real, S. Moore, A. Selle, S. Saxena, Y.L. Suematsu, J. Tan, Q. Le, A. Kurakin, Large-Scale Evolution of Image Classifiers, (2017). <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1703.01041">http://arxiv.org/abs/1703.01041</ext-link>.</mixed-citation></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Kwasigroch</surname><given-names>A</given-names></name><name><surname>Grochowski</surname><given-names>M</given-names></name><name><surname>Mikolajczyk</surname><given-names>A</given-names></name></person-group><article-title>Neural architecture search for skin lesion classification</article-title><source>IEEE Access.</source><year>2020</year><volume>8</volume><fpage>9061</fpage><lpage>9071</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2964424</pub-id></element-citation><mixed-citation id="mc-CR8" publication-type="journal">A. Kwasigroch, M. Grochowski, A. Mikolajczyk, Neural architecture search for skin lesion classification, IEEE Access. 8 (2020) 9061&#x02013;9071. 10.1109/ACCESS.2020.2964424.</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Weng</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Qiu</surname><given-names>X</given-names></name></person-group><article-title>NAS-Unet: Neural architecture search for medical image segmentation</article-title><source>IEEE Access.</source><year>2019</year><volume>7</volume><fpage>44247</fpage><lpage>44257</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2908991</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Y. Weng, T. Zhou, Y. Li, X. Qiu, NAS-Unet: Neural architecture search for medical image segmentation, IEEE Access. 7 (2019) 44247&#x02013;44257. 10.1109/ACCESS.2019.2908991.</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Santarelli</surname><given-names>MF</given-names></name><name><surname>Genovesi</surname><given-names>D</given-names></name><name><surname>Positano</surname><given-names>V</given-names></name><name><surname>Scipioni</surname><given-names>M</given-names></name><name><surname>Vergaro</surname><given-names>G</given-names></name><name><surname>Favilli</surname><given-names>B</given-names></name><name><surname>Giorgetti</surname><given-names>A</given-names></name><name><surname>Emdin</surname><given-names>M</given-names></name><name><surname>Landini</surname><given-names>L</given-names></name><name><surname>Marzullo</surname><given-names>P</given-names></name></person-group><article-title>Deep-learning-based cardiac amyloidosis classification from early acquired pet images</article-title><source>Int. J. Cardiovasc. Imaging.</source><year>2021</year><volume>37</volume><fpage>2327</fpage><lpage>2335</lpage><pub-id pub-id-type="doi">10.1007/s10554-021-02190-7</pub-id><pub-id pub-id-type="pmid">33591476</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">M.F. Santarelli, D. Genovesi, V. Positano, M. Scipioni, G. Vergaro, B. Favilli, A. Giorgetti, M. Emdin, L. Landini, P. Marzullo, Deep-learning-based cardiac amyloidosis classification from early acquired pet images, Int. J. Cardiovasc. Imaging. 37 (2021) 2327&#x02013;2335. 10.1007/s10554-021-02190-7.<pub-id pub-id-type="pmid">33591476</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">M. Wistuba, A. Rawat, T. Pedapati, A Survey on Neural Architecture Search, (2019). <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1905.01392">http://arxiv.org/abs/1905.01392</ext-link>.</mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">B. Zoph, V. Vasudevan, J. Shlens, Q. V. Le, Learning Transferable Architectures for Scalable Image Recognition, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. (2018) 8697&#x02013;8710. 10.1109/CVPR.2018.00907.</mixed-citation></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Alarie</surname><given-names>S</given-names></name><name><surname>Audet</surname><given-names>C</given-names></name><name><surname>Gheribi</surname><given-names>AE</given-names></name><name><surname>Kokkolaras</surname><given-names>M</given-names></name><name><surname>Le Digabel</surname><given-names>S</given-names></name></person-group><article-title>Two decades of blackbox optimization applications</article-title><source>EURO Journal on Computational Optimization</source><year>2021</year><volume>9</volume><fpage>100011</fpage><pub-id pub-id-type="doi">10.1016/j.ejco.2021.100011</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">S. Alarie, C. Audet, A. E. Gheribi, M. Kokkolaras, S. Le Digabel, Two decades of blackbox optimization applications, EURO Journal on Computational Optimization, (2021), 9:100011, 10.1016/j.ejco.2021.100011</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandez-Godino</surname><given-names>MG</given-names></name></person-group><article-title>Review of multi-fidelity models</article-title><source>Advances in Computational Science and Engineering</source><year>2023</year><volume>4</volume><issue>1</issue><fpage>351</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.3934/acse.2023015</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal">M.G. Fernandez-Godino, Review of multi-fidelity models, Advances in Computational Science and Engineering (2023), (1)4;351-400. 10.3934/acse.2023015.</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Bender</surname><given-names>G</given-names></name><name><surname>Kindermans</surname><given-names>P-J</given-names></name><name><surname>Zoph</surname><given-names>B</given-names></name><name><surname>Vasudevan</surname><given-names>V</given-names></name><name><surname>Le</surname><given-names>Q</given-names></name></person-group><article-title>Understanding and simplifying one-shot architecture search</article-title><source>Proceedings of Machine Learning Research</source><year>2018</year><volume>80</volume><fpage>550</fpage><lpage>559</lpage></element-citation><mixed-citation id="mc-CR15" publication-type="journal">G. Bender, P.-J. Kindermans, B. Zoph, V. Vasudevan, and Q. Le, Understanding and simplifying one-shot architecture search, (2018) Proceedings of Machine Learning Research, 80:550&#x02013;559.</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">B. Zoph, Q. V. Le, Neural architecture search with reinforcement learning, 5th Int. Conf. Learn. Represent. ICLR 2017 - Conf. Track Proc. (2017) 1&#x02013;16.</mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">H. Liu, K. Simonyan, Y. Yang, DARTS: Differentiable architecture search, 7th Int. Conf. Learn. Represent. ICLR 2019. (2019) 1&#x02013;13.</mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">H. Liu, K. Simonyan, O. Vinyals, C. Fernando, K. Kavukcuoglu, Hierarchical representations for efficient architecture search, 6th Int. Conf. Learn. Represent. ICLR 2018 - Conf. Track Proc. (2018) 1&#x02013;13.</mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">E. Real, A. Aggarwal, Y. Huang, Q. V. Le, Regularized evolution for image classifier architecture search, 33rd AAAI Conf. Artif. Intell. AAAI 2019, 31st Innov. Appl. Artif. Intell. Conf. IAAI 2019 9th AAAI Symp. Educ. Adv. Artif. Intell. EAAI 2019. (2019) 4780&#x02013;4789. 10.1609/aaai.v33i01.33014780.</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">T. Domhan, T. Springenberg, F. Hutter, Speeding Up Automatic Hyperparameter Optimization of.pdf, Twenty-Fourth Int. Jt. Conf. Artif. Intell. (. (2015) 3460&#x02013;3468.</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">A. Klein, S. Falkner, J.T. Springenberg, F. Hutter, Learning curve prediction with Bayesian neural networks, 5th Int. Conf. Learn. Represent. ICLR 2017 - Conf. Track Proc. (2017).</mixed-citation></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Falk</surname><given-names>RH</given-names></name><name><surname>Dubrey</surname><given-names>SW</given-names></name></person-group><article-title>Amyloid Heart Disease</article-title><source>Prog. Cardiovasc. Dis.</source><year>2010</year><volume>52</volume><fpage>347</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1016/j.pcad.2009.11.007</pub-id><pub-id pub-id-type="pmid">20109604</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">R.H. Falk, S.W. Dubrey, Amyloid Heart Disease, Prog. Cardiovasc. Dis. 52 (2010) 347&#x02013;361. 10.1016/j.pcad.2009.11.007.<pub-id pub-id-type="pmid">20109604</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Skinner</surname><given-names>M</given-names></name><name><surname>Sanchorawala</surname><given-names>V</given-names></name><name><surname>Seldin</surname><given-names>DC</given-names></name><name><surname>Dember</surname><given-names>LM</given-names></name><name><surname>Falk</surname><given-names>RH</given-names></name><name><surname>Berk</surname><given-names>JL</given-names></name><name><surname>Anderson</surname><given-names>JJ</given-names></name><name><surname>O'Hara</surname><given-names>C</given-names></name><name><surname>Finn</surname><given-names>KT</given-names></name><name><surname>Libbey</surname><given-names>CA</given-names></name><name><surname>Wiesman</surname><given-names>J</given-names></name><name><surname>Quillen</surname><given-names>K</given-names></name><name><surname>Swan</surname><given-names>N</given-names></name><name><surname>Wright</surname><given-names>DG</given-names></name></person-group><article-title>High-Dose Melphalan and Autologous Stem-Cell Transplantation in Patients with AL Amyloidosis: An 8-Year Study</article-title><source>Ann. Intern. Med.</source><year>2004</year><volume>140</volume><fpage>85</fpage><pub-id pub-id-type="doi">10.7326/0003-4819-140-2-200401200-00008</pub-id><pub-id pub-id-type="pmid">14734330</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">M. Skinner, V. Sanchorawala, D.C. Seldin, L.M. Dember, R.H. Falk, J.L. Berk, J.J. Anderson, C. O'Hara, K.T. Finn, C.A. Libbey, J. Wiesman, K. Quillen, N. Swan, D.G. Wright, High-Dose Melphalan and Autologous Stem-Cell Transplantation in Patients with AL Amyloidosis: An 8-Year Study, Ann. Intern. Med. 140 (2004) 85. 10.7326/0003-4819-140-2-200401200-00008.<pub-id pub-id-type="pmid">14734330</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Ruberg</surname><given-names>FL</given-names></name><name><surname>Berk</surname><given-names>JL</given-names></name></person-group><article-title>Transthyretin (TTR) cardiac amyloidosis</article-title><source>Circulation.</source><year>2012</year><volume>126</volume><fpage>1286</fpage><lpage>1300</lpage><pub-id pub-id-type="doi">10.1161/CIRCULATIONAHA.111.078915</pub-id><pub-id pub-id-type="pmid">22949539</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">F.L. Ruberg, J.L. Berk, Transthyretin (TTR) cardiac amyloidosis, Circulation. 126 (2012) 1286&#x02013;1300. 10.1161/CIRCULATIONAHA.111.078915.<pub-id pub-id-type="pmid">22949539</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">P. Mollee, P. Renaut, D. Gottlieb, H. Goodman, How to diagnose amyloidosis, Intern. Med. J. 44 (2014) 7&#x02013;17.10.1111/imj.12288.</mixed-citation></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Santarelli</surname><given-names>MF</given-names></name><name><surname>Scipioni</surname><given-names>M</given-names></name><name><surname>Genovesi</surname><given-names>D</given-names></name><name><surname>Giorgetti</surname><given-names>A</given-names></name><name><surname>Marzullo</surname><given-names>P</given-names></name><name><surname>Landini</surname><given-names>L</given-names></name></person-group><article-title>Imaging Techniques as an Aid in the Early Detection of Cardiac Amyloidosis</article-title><source>Curr. Pharm. Des.</source><year>2020</year><volume>27</volume><fpage>1878</fpage><lpage>1889</lpage><pub-id pub-id-type="doi">10.2174/1381612826666200813133557</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">M.F. Santarelli, M. Scipioni, D. Genovesi, A. Giorgetti, P. Marzullo, L. Landini, Imaging Techniques as an Aid in the Early Detection of Cardiac Amyloidosis, Curr. Pharm. Des. 27 (2020) 1878&#x02013;1889. 10.2174/1381612826666200813133557.</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>SP</given-names></name><name><surname>Park</surname><given-names>JB</given-names></name><name><surname>Kim</surname><given-names>HK</given-names></name><name><surname>Kim</surname><given-names>YJ</given-names></name><name><surname>Grogan</surname><given-names>M</given-names></name><name><surname>Sohn</surname><given-names>DW</given-names></name></person-group><article-title>Contemporary imaging diagnosis of cardiac amyloidosis</article-title><source>J. Cardiovasc. Imaging.</source><year>2019</year><volume>27</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.4250/jcvi.2019.27.e9</pub-id><pub-id pub-id-type="pmid">30701710</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">S.P. Lee, J.B. Park, H.K. Kim, Y.J. Kim, M. Grogan, D.W. Sohn, Contemporary imaging diagnosis of cardiac amyloidosis, J. Cardiovasc. Imaging. 27 (2019) 1&#x02013;10. 10.4250/jcvi.2019.27.e9.<pub-id pub-id-type="pmid">30701710</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Kircher</surname><given-names>M</given-names></name><name><surname>Ihne</surname><given-names>S</given-names></name><name><surname>Brumberg</surname><given-names>J</given-names></name><name><surname>Morbach</surname><given-names>C</given-names></name><name><surname>Knop</surname><given-names>S</given-names></name><name><surname>Kort&#x000fc;m</surname><given-names>KM</given-names></name><name><surname>St&#x000f6;rk</surname><given-names>S</given-names></name><name><surname>Buck</surname><given-names>AK</given-names></name><name><surname>Reiter</surname><given-names>T</given-names></name><name><surname>Bauer</surname><given-names>WR</given-names></name><name><surname>Lapa</surname><given-names>C</given-names></name></person-group><article-title>Detection of cardiac amyloidosis with 18F-Florbetaben-PET/CT in comparison to echocardiography, cardiac MRI and DPD-scintigraphy</article-title><source>Eur. J. Nucl. Med. Mol. Imaging.</source><year>2019</year><volume>46</volume><fpage>1407</fpage><lpage>1416</lpage><pub-id pub-id-type="doi">10.1007/s00259-019-04290-y</pub-id><pub-id pub-id-type="pmid">30798427</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">M. Kircher, S. Ihne, J. Brumberg, C. Morbach, S. Knop, K.M. Kort&#x000fc;m, S. St&#x000f6;rk, A.K. Buck, T. Reiter, W.R. Bauer, C. Lapa, Detection of cardiac amyloidosis with 18F-Florbetaben-PET/CT in comparison to echocardiography, cardiac MRI and DPD-scintigraphy, Eur. J. Nucl. Med. Mol. Imaging. 46 (2019) 1407&#x02013;1416. 10.1007/s00259-019-04290-y.<pub-id pub-id-type="pmid">30798427</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Y Y.J. Kim, S. Ha, Y. il Kim, Cardiac amyloidosis imaging with amyloid positron emission tomography: A systematic review and meta-analysis, J. Nucl. Cardiol. 27 (2020) 123&#x02013;132. 10.1007/s12350-018-1365-x.</mixed-citation></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Genovesi</surname><given-names>D</given-names></name><name><surname>Vergaro</surname><given-names>G</given-names></name><name><surname>Giorgetti</surname><given-names>A</given-names></name><name><surname>Marzullo</surname><given-names>P</given-names></name><name><surname>Scipioni</surname><given-names>M</given-names></name><name><surname>Santarelli</surname><given-names>MF</given-names></name><name><surname>Pucci</surname><given-names>A</given-names></name><name><surname>Buda</surname><given-names>G</given-names></name><name><surname>Volpi</surname><given-names>E</given-names></name><name><surname>Emdin</surname><given-names>M</given-names></name></person-group><article-title>[18F]-Florbetaben PET/CT for Differential Diagnosis Among Cardiac Immunoglobulin Light Chain, Transthyretin Amyloidosis, and Mimicking Conditions</article-title><source>JACC Cardiovasc. Imaging.</source><year>2021</year><volume>14</volume><fpage>246</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1016/j.jcmg.2020.05.031</pub-id><pub-id pub-id-type="pmid">32771577</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">D. Genovesi, G. Vergaro, A. Giorgetti, P. Marzullo, M. Scipioni, M.F. Santarelli, A. Pucci, G. Buda, E. Volpi, M. Emdin, [18F]-Florbetaben PET/CT for Differential Diagnosis Among Cardiac Immunoglobulin Light Chain, Transthyretin Amyloidosis, and Mimicking Conditions, JACC Cardiovasc. Imaging. 14 (2021) 246&#x02013;255. 10.1016/j.jcmg.2020.05.031.<pub-id pub-id-type="pmid">32771577</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Santarelli</surname><given-names>MF</given-names></name><name><surname>Genovesi</surname><given-names>D</given-names></name><name><surname>Scipioni</surname><given-names>M</given-names></name><name><surname>Positano</surname><given-names>V</given-names></name><name><surname>Favilli</surname><given-names>B</given-names></name><name><surname>Giorgetti</surname><given-names>A</given-names></name><name><surname>Vergaro</surname><given-names>G</given-names></name><name><surname>Landini</surname><given-names>L</given-names></name><name><surname>Emdin</surname><given-names>M</given-names></name><name><surname>Marzullo</surname><given-names>P</given-names></name></person-group><article-title>Cardiac amyloidosis characterization by kinetic model fitting on [18F]florbetaben PET images</article-title><source>J. Nucl. Cardiol.</source><year>2022</year><volume>29</volume><fpage>1919</fpage><lpage>1932</lpage><pub-id pub-id-type="doi">10.1007/s12350-021-02608-8</pub-id><pub-id pub-id-type="pmid">33864226</pub-id>
</element-citation><mixed-citation id="mc-CR31" publication-type="journal">M.F. Santarelli, D. Genovesi, M. Scipioni, V. Positano, B. Favilli, A. Giorgetti, G. Vergaro, L. Landini, M. Emdin, P. Marzullo, Cardiac amyloidosis characterization by kinetic model fitting on [18F]florbetaben PET images, J. Nucl. Cardiol. 29 (2022) 1919&#x02013;1932. 10.1007/s12350-021-02608-8.<pub-id pub-id-type="pmid">33864226</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Gillmore</surname><given-names>JD</given-names></name><name><surname>Wechalekar</surname><given-names>A</given-names></name><name><surname>Bird</surname><given-names>J</given-names></name><name><surname>Cavenagh</surname><given-names>J</given-names></name><name><surname>Hawkins</surname><given-names>S</given-names></name><name><surname>Kazmi</surname><given-names>M</given-names></name><name><surname>Lachmann</surname><given-names>HJ</given-names></name><name><surname>Hawkins</surname><given-names>PN</given-names></name><name><surname>Pratt</surname><given-names>G</given-names></name></person-group><article-title>Guidelines on the diagnosis and investigation of AL amyloidosis</article-title><source>Br. J. Haematol.</source><year>2015</year><volume>168</volume><fpage>207</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1111/bjh.13156</pub-id><pub-id pub-id-type="pmid">25312307</pub-id>
</element-citation><mixed-citation id="mc-CR32" publication-type="journal">J.D. Gillmore, A. Wechalekar, J. Bird, J. Cavenagh, S. Hawkins, M. Kazmi, H.J. Lachmann, P.N. Hawkins, G. Pratt, Guidelines on the diagnosis and investigation of AL amyloidosis, Br. J. Haematol. 168 (2015) 207&#x02013;218. 10.1111/bjh.13156.<pub-id pub-id-type="pmid">25312307</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Gillmore</surname><given-names>JD</given-names></name><name><surname>Maurer</surname><given-names>MS</given-names></name><name><surname>Falk</surname><given-names>RH</given-names></name><name><surname>Merlini</surname><given-names>G</given-names></name><name><surname>Damy</surname><given-names>T</given-names></name><name><surname>Dispenzieri</surname><given-names>A</given-names></name><name><surname>Wechalekar</surname><given-names>AD</given-names></name><name><surname>Berk</surname><given-names>JL</given-names></name><name><surname>Quarta</surname><given-names>CC</given-names></name><name><surname>Grogan</surname><given-names>M</given-names></name><name><surname>Lachmann</surname><given-names>HJ</given-names></name><name><surname>Bokhari</surname><given-names>S</given-names></name><name><surname>Castano</surname><given-names>A</given-names></name><name><surname>Dorbala</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>GB</given-names></name><name><surname>Glaudemans</surname><given-names>AWJM</given-names></name><name><surname>Rezk</surname><given-names>T</given-names></name><name><surname>Fontana</surname><given-names>M</given-names></name><name><surname>Palladini</surname><given-names>G</given-names></name><name><surname>Milani</surname><given-names>P</given-names></name><name><surname>Guidalotti</surname><given-names>PL</given-names></name><name><surname>Flatman</surname><given-names>K</given-names></name><name><surname>Lane</surname><given-names>T</given-names></name><name><surname>Vonberg</surname><given-names>FW</given-names></name><name><surname>Whelan</surname><given-names>CJ</given-names></name><name><surname>Moon</surname><given-names>JC</given-names></name><name><surname>Ruberg</surname><given-names>FL</given-names></name><name><surname>Miller</surname><given-names>EJ</given-names></name><name><surname>Hutt</surname><given-names>DF</given-names></name><name><surname>Hazenberg</surname><given-names>BP</given-names></name><name><surname>Rapezzi</surname><given-names>C</given-names></name><name><surname>Hawkins</surname><given-names>PN</given-names></name></person-group><article-title>Nonbiopsy diagnosis of cardiac transthyretin amyloidosis</article-title><source>Circulation.</source><year>2016</year><volume>133</volume><fpage>2404</fpage><lpage>2412</lpage><pub-id pub-id-type="doi">10.1161/CIRCULATIONAHA.116.021612</pub-id><pub-id pub-id-type="pmid">27143678</pub-id>
</element-citation><mixed-citation id="mc-CR33" publication-type="journal">J.D. Gillmore, M.S. Maurer, R.H. Falk, G. Merlini, T. Damy, A. Dispenzieri, A.D. Wechalekar, J.L. Berk, C.C. Quarta, M. Grogan, H.J. Lachmann, S. Bokhari, A. Castano, S. Dorbala, G.B. Johnson, A.W.J.M. Glaudemans, T. Rezk, M. Fontana, G. Palladini, P. Milani, P.L. Guidalotti, K. Flatman, T. Lane, F.W. Vonberg, C.J. Whelan, J.C. Moon, F.L. Ruberg, E.J. Miller, D.F. Hutt, B.P. Hazenberg, C. Rapezzi, P.N. Hawkins, Nonbiopsy diagnosis of cardiac transthyretin amyloidosis, Circulation. 133 (2016) 2404&#x02013;2412. 10.1161/CIRCULATIONAHA.116.021612.<pub-id pub-id-type="pmid">27143678</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">E. Goceri, Medical image data augmentation: techniques, comparisons and interpretations. Artificial Intelligence Review (2023) 56:12561&#x02013;12605. 10.1007/s10462-023-10453-z</mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">S. Ioffe, C. Szegedy, Batch normalization: Accelerating deep network training by reducing internal covariate shift, 32nd Int. Conf. Mach. Learn. ICML 2015. 1 (2015) 448&#x02013;456.</mixed-citation></ref></ref-list></back></article>