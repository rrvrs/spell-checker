<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Polymers (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Polymers (Basel)</journal-id><journal-id journal-id-type="publisher-id">polymers</journal-id><journal-title-group><journal-title>Polymers</journal-title></journal-title-group><issn pub-type="epub">2073-4360</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006213</article-id><article-id pub-id-type="pmc">PMC11860118</article-id><article-id pub-id-type="doi">10.3390/polym17040550</article-id><article-id pub-id-type="publisher-id">polymers-17-00550</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Predicting Stress&#x02013;Strain Curve with Confidence: Balance Between Data Minimization and Uncertainty Quantification by a Dual Bayesian Model</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Tianyi</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af1-polymers-17-00550" ref-type="aff">1</xref><xref rid="af2-polymers-17-00550" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Zhengyuan</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><xref rid="af1-polymers-17-00550" ref-type="aff">1</xref><xref rid="af2-polymers-17-00550" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Zhen</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af3-polymers-17-00550" ref-type="aff">3</xref></contrib><contrib contrib-type="author"><name><surname>Wei</surname><given-names>Zhenhua</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af4-polymers-17-00550" ref-type="aff">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8540-7293</contrib-id><name><surname>Zhong</surname><given-names>Gan-Ji</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af2-polymers-17-00550" ref-type="aff">2</xref><xref rid="af5-polymers-17-00550" ref-type="aff">5</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Zhong-Ming</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af2-polymers-17-00550" ref-type="aff">2</xref><xref rid="af5-polymers-17-00550" ref-type="aff">5</xref><xref rid="c1-polymers-17-00550" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-4899-9998</contrib-id><name><surname>Liu</surname><given-names>Han</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af1-polymers-17-00550" ref-type="aff">1</xref><xref rid="af2-polymers-17-00550" ref-type="aff">2</xref><xref rid="af5-polymers-17-00550" ref-type="aff">5</xref><xref rid="c1-polymers-17-00550" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Kr&#x000f6;ger</surname><given-names>Martin</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-polymers-17-00550"><label>1</label>SOlids inFormaTics AI-Laboratory (SOFT-AI-Lab), Sichuan University, Chengdu 610065, China</aff><aff id="af2-polymers-17-00550"><label>2</label>College of Polymer Science and Engineering, Sichuan University, Chengdu 610065, China</aff><aff id="af3-polymers-17-00550"><label>3</label>College of Mathematics and Physics, Chengdu University of Technology, Chengdu 610059, China</aff><aff id="af4-polymers-17-00550"><label>4</label>Department of Ocean Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China</aff><aff id="af5-polymers-17-00550"><label>5</label>State Key Laboratory for Polymer Materials Engineering, Sichuan University, Chengdu 610065, China</aff><author-notes><corresp id="c1-polymers-17-00550"><label>*</label>Correspondence: <email>zmli@scu.edu.cn</email> (Z.-M.L.); <email>happylife@ucla.edu</email> (H.L.)</corresp></author-notes><pub-date pub-type="epub"><day>19</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>17</volume><issue>4</issue><elocation-id>550</elocation-id><history><date date-type="received"><day>14</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>14</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>18</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Driven by polymer processing&#x02013;property data, machine learning (ML) presents an efficient paradigm in predicting the stress&#x02013;strain curve. However, it is generally challenged by (i) the deficiency of training data, (ii) the one-to-many issue of processing&#x02013;property relationship (i.e., aleatoric uncertainty), and (iii) the unawareness of model uncertainty (i.e., epistemic uncertainty). Here, leveraging a Bayesian neural network (BNN) and a recently proposed dual-architected model for curve prediction, we introduce a dual Bayesian model that enables accurate prediction of the stress&#x02013;strain curve while distinguishing between aleatoric and epistemic uncertainty at each processing condition. The model is trained using a Taguchi array dataset that minimizes the data size while maximizing the representativeness of 27 samples in a 4D processing parameter space, significantly reducing data requirements. By incorporating hidden layers and output-distribution layers, the model quantifies both aleatoric and epistemic uncertainty, aligning with experimental data fluctuations, and provides a 95% confidence interval for stress&#x02013;strain predictions at each processing condition. Overall, this study establishes an uncertainty-aware framework for curve property prediction with reliable, modest uncertainty at a small data size, thus balancing data minimization and uncertainty quantification.</p></abstract><kwd-group><kwd>polymeric materials</kwd><kwd>mechanical behavior</kwd><kwd>machine learning</kwd><kwd>prediction uncertainty</kwd><kwd>polymer processing</kwd></kwd-group><funding-group><award-group><funding-source>National Natural Science Foundation of China</funding-source><award-id>52303042</award-id><award-id>52033005</award-id><award-id>52173040</award-id><award-id>52173225</award-id></award-group><award-group><funding-source>Fundamental Research Funds for the Central Universities</funding-source><award-id>YJ202271</award-id></award-group><award-group><funding-source>State Key Laboratory of Polymer Materials Engineering</funding-source><award-id>sklpme2024-2-08</award-id></award-group><award-group><funding-source>Shenzhen Science Foundation</funding-source><award-id>JCYJ20220530115407016</award-id></award-group><award-group><funding-source>National Key R&#x00026;D Program of China</funding-source><award-id>2023YFB3712500</award-id></award-group><funding-statement>H.L. acknowledges funding from the National Natural Science Foundation of China under the grant No. 52303042, the Fundamental Research Funds for the Central Universities under the grant No. YJ202271, and the State Key Laboratory of Polymer Materials Engineering under the grant No. sklpme2024-2-08. Z.W. acknowledges the support from the Shenzhen Science Foundation (grant No. JCYJ20220530115407016) and the Guangdong Provincial Science Foundation (grant No. 2024A1515011026). G.J.Z. and Z.M.L. acknowledge the support from the National Key R&#x00026;D Program of China (2023YFB3712500) and the National Natural Science Foundation of China (grants Nos. 52033005, 52173040, and 52173225). Parts of the computational work were performed on TianHe-1(A) at the National Supercomputer Center in Tianjin.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-polymers-17-00550"><title>1. Introduction</title><p>Due to their structural complexity, polymeric materials typically exhibit intricate stress&#x02013;strain curves. Additionally, the &#x0201c;black box&#x0201d; simulation process (as shown in <xref rid="polymers-17-00550-f001" ref-type="fig">Figure 1</xref>) during the manufacturing stage poses a challenge for accurate prediction through physics-driven simulations [<xref rid="B1-polymers-17-00550" ref-type="bibr">1</xref>]. As an alternative, machine learning (ML) provides an efficient approach to &#x0201c;bypass physics laws&#x0201d; and extract the polymer processing&#x02013;property relationship purely from training data [<xref rid="B2-polymers-17-00550" ref-type="bibr">2</xref>], enabling accurate prediction of stress&#x02013;strain curves at different processing conditions [<xref rid="B1-polymers-17-00550" ref-type="bibr">1</xref>,<xref rid="B3-polymers-17-00550" ref-type="bibr">3</xref>,<xref rid="B4-polymers-17-00550" ref-type="bibr">4</xref>,<xref rid="B5-polymers-17-00550" ref-type="bibr">5</xref>,<xref rid="B6-polymers-17-00550" ref-type="bibr">6</xref>,<xref rid="B7-polymers-17-00550" ref-type="bibr">7</xref>]. However, ascribed to (i) its data-driven nature and (ii) the curve-output complexity, the ML approach is generally limited by the deficiency of training data size [<xref rid="B8-polymers-17-00550" ref-type="bibr">8</xref>], failing to extract a reliable correlation pattern between polymer processing conditions and their resultant specimens&#x02019; stress&#x02013;strain curves, with no confidence interval attached to each prediction [<xref rid="B9-polymers-17-00550" ref-type="bibr">9</xref>,<xref rid="B10-polymers-17-00550" ref-type="bibr">10</xref>,<xref rid="B11-polymers-17-00550" ref-type="bibr">11</xref>]. Moreover, considering the intrinsic and inevitable fluctuations at each processing condition, the specimens prepared at the same condition generally show some variations in stress&#x02013;strain curves, that is, the &#x0201c;one-to-many&#x0201d; issue [<xref rid="B1-polymers-17-00550" ref-type="bibr">1</xref>,<xref rid="B12-polymers-17-00550" ref-type="bibr">12</xref>], or referred to as aleatoric uncertainty (see <xref rid="polymers-17-00550-f001" ref-type="fig">Figure 1</xref>), which apparently falls out of the ML applicability of the &#x0201c;one-to-one&#x0201d; training scheme that requires unique mapping between inputs and outputs [<xref rid="B13-polymers-17-00550" ref-type="bibr">13</xref>]. As such, it presents a grand challenge for ML approaches to address the &#x0201c;one-to-many&#x0201d; issue and predict stress&#x02013;strain curves with confidence at a small data size.</p><p>By incorporating physics principles as prior knowledge, recent ML models have been demonstrated to hold the promise to greatly reduce the needs for large training data size [<xref rid="B14-polymers-17-00550" ref-type="bibr">14</xref>,<xref rid="B15-polymers-17-00550" ref-type="bibr">15</xref>,<xref rid="B16-polymers-17-00550" ref-type="bibr">16</xref>]. Impressively, by integrating a curve type classifier and a curve feature regressor, a dual neural network (DNN) model is recently proposed to enable stress&#x02013;strain curve prediction at an extremely small data size [<xref rid="B1-polymers-17-00550" ref-type="bibr">1</xref>]. In contrast, using a single model to predict the entire stress&#x02013;strain curve vector would significantly increase model complexity and require much larger amounts of training data. Despite their reduced data-size requirement, the ML models are mathematically incapable of addressing the &#x0201c;one-to-many&#x0201d; issue and outputting different stress&#x02013;strain curves simultaneously at one processing condition&#x02014;that is, &#x0201c;aleatoric uncertainty&#x0201d; [<xref rid="B17-polymers-17-00550" ref-type="bibr">17</xref>], and little is known about the confidence interval of model prediction without quantifying the uncertainty of model parameters&#x02014;that is, &#x0201c;epistemic uncertainty&#x0201d; [<xref rid="B9-polymers-17-00550" ref-type="bibr">9</xref>,<xref rid="B17-polymers-17-00550" ref-type="bibr">17</xref>]. In that regard, various statistical methods have been developed to establish uncertainty-aware ML models, with both aleatoric and epistemic uncertainty included [<xref rid="B18-polymers-17-00550" ref-type="bibr">18</xref>]. Specifically, Bayesian neural networks (BNNs) have been a representative methodology for uncertainty quantification and, by providing sufficient training data [<xref rid="B19-polymers-17-00550" ref-type="bibr">19</xref>,<xref rid="B20-polymers-17-00550" ref-type="bibr">20</xref>], have been applied to successfully predict simple-patterned stress&#x02013;strain curves with a 95% confidence interval provided for reliability guidance [<xref rid="B21-polymers-17-00550" ref-type="bibr">21</xref>,<xref rid="B22-polymers-17-00550" ref-type="bibr">22</xref>]. However, heavily relying on a large data size, the BNN models would generate unrealistically wide uncertainty estimations at a small data size, thus failing to evaluate the prediction reliability. Obviously, it is challenging to balance data minimization and uncertainty quantification, and as a result, there remains a lack of ML models to predict the stress&#x02013;strain curve with reliable modest uncertainty at a small data size.</p><p>Here, combining (i) the BNN model for uncertainty quantification and (ii) the DNN model for curve prediction at a small data size [<xref rid="B1-polymers-17-00550" ref-type="bibr">1</xref>], we introduce a dual Bayesian model to predict the stress&#x02013;strain curve with reliable modest uncertainty at a small data size by taking the example of injection-molded polypropylene specimens prepared at different molding conditions. Inherited from the DNN model, the present architecture features the state-of-the-art simplicity of 183 neurons in total in the hidden layers for stress&#x02013;strain curve prediction, significantly reducing the need for extensive training data. The construction of training data adopts a Taguchi array dataset of 27 samplings in a 4D processing parameter space, that is, a small dataset evenly distributed across the space to capture all main features of property evolution as a function of processing parameters (see <xref rid="sec3dot1-polymers-17-00550" ref-type="sec">Section 3.1</xref>). Based on the DNN architecture setting and Taguchi sampling strategy, the model further adds a probability density distribution layer as the output in order to mathematically address the &#x0201c;one-to-many&#x0201d; issue and quantify the aleatoric uncertainty accordingly (see <xref rid="sec3dot2-polymers-17-00550" ref-type="sec">Section 3.2</xref>). By assuming normal-distribution-type uncertainty, the present model yields normal distributions in good agreement with the training data distributions of curve features at different molding conditions, with an average miscalibration area &#x02248; 0.11 under its uncertainty calibration curve (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>). Finally, in order to evaluate its prediction reliability, the model&#x02019;s epistemic uncertainty is quantified by adopting BNN hidden neurons to establish a <italic toggle="yes">prior</italic> normal distribution for each model parameter, that is, neuron weights and biases. After training these parameter distributions, the model estimates the epistemic uncertainty of its output distribution by statistically analyzing the outputs at different model parameters (see <xref rid="sec3dot4-polymers-17-00550" ref-type="sec">Section 3.4</xref>). Notably, the incorporation of epistemic uncertainty leads to an increased but yet satisfactory modest 95% confidence interval of stress&#x02013;strain curve prediction, with an average miscalibration area &#x02248; 0.18 for each curve feature, demonstrating the model&#x02019;s applicability for reliability guidance (see <xref rid="sec3dot5-polymers-17-00550" ref-type="sec">Section 3.5</xref>). Overall, this study pioneers an uncertainty-aware dual Bayesian framework for stress&#x02013;strain curve prediction (or curve property in general) with reliable modest uncertainty at a small data size, thus balancing data minimization and uncertainty quantification.</p></sec><sec id="sec2-polymers-17-00550"><title>2. Materials and Experimental Methods</title><sec id="sec2dot1-polymers-17-00550"><title>2.1. Materials</title><p>The isotactic-polypropylene (iPP) granules used in this study are of the commercial type &#x0201c;T30S&#x0201d; iPP, manufactured with Ziegler-Natta catalysts and procured from Yanchang Petroleum Refining and Petrochemical Company in Xi&#x02019;an, China. These granules have a melting temperature of 161.2 &#x000b0;C, as determined by differential scanning calorimetry (Q2000, TA Instruments-Waters LLC, New Castle, DE, USA), and a melt flow rate of 3.2 g/10 min (2.16 kg and 230 &#x000b0;C).</p></sec><sec id="sec2dot2-polymers-17-00550"><title>2.2. Injection Molding Experiments</title><p>Employing a commercial hydraulic injection machine obtained from Haitian Plastics Machinery Ltd. Company in Ningbo, China, the iPP granules are injection-molded into dumbbell-shaped specimens with dimensions of 30 mm (length), 5 mm (width), and 1 mm (thickness) during the injection molding process, where four key tunable parameters determine the final mechanical performance of material. These parameters encompass (i) injection pressure (<inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), (ii) injection rate (<inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) for mold filling, (iii) packing pressure (<inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) to sustain cavity filling post 95% mold occupation, and (iv) mold temperature (<inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) during the filling and cooling stages as indicated in <xref rid="polymers-17-00550-f001" ref-type="fig">Figure 1</xref>; the detailed data have been screened using the Taguchi method and are thoroughly illustrated in <xref rid="sec3dot1-polymers-17-00550" ref-type="sec">Section 3.1</xref>, along with <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>a. While maintaining other pertinent factors constant, such as a 5 s packing time, a 30 s cooling time, and a processing temperature gradient along the injection screw (sequentially set as 160 &#x000b0;C, 180 &#x000b0;C, 200 &#x000b0;C, 210 &#x000b0;C, and 200 &#x000b0;C from hopper to nozzle), the specimens are prepared under diverse molding conditions within the operable range.</p></sec><sec id="sec2dot3-polymers-17-00550"><title>2.3. Stress&#x02013;Strain Curve Measurements</title><p>Tensile tests are performed to acquire stress&#x02013;strain profiles until fracture for all injection-molded iPP samples (oriented longitudinally, parallel to the injection flow). These tests are executed using the &#x0201c;Instron Model 5576 Series&#x0201d; Universal Testing System (Norwood, MA, USA) in adherence to the American Society of Testing and Materials (ASTM) D-638 testing standards, with testing conditions set at a room temperature of 23 &#x000b0;C and a tensile speed of 50 mm/min.</p></sec></sec><sec id="sec3-polymers-17-00550"><title>3. Result</title><sec id="sec3dot1-polymers-17-00550"><title>3.1. Description of the Stress&#x02013;Strain Curve Dataset</title><list list-type="simple"><list-item><label>(1)</label><p>Mini-Dataset Construction by Taguchi Sampling Representation</p></list-item></list><p>To build a small-sized but high-quality dataset, we utilize herein the Taguchi orthogonal method, a robust experimental design technique that minimizes the number of experiments needed to create a mini-dataset of 27 molding conditions (see <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>a) [<xref rid="B1-polymers-17-00550" ref-type="bibr">1</xref>,<xref rid="B23-polymers-17-00550" ref-type="bibr">23</xref>]. Each condition with four adjustable processing parameters, namely, <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, varies two parameters from surrounding conditions using three levels of alteration in the 4D processing parameter space, with orthogonal arrays systematically ensuring even distribution of experiments across the entire parameter space and providing an informative representation of the stress&#x02013;strain curve evolution as a function of processing parameters. For each of the 27 molding conditions, 3 to 7 iPP injection-molded specimens are used to characterize the aleatoric uncertainty of stress&#x02013;strain curves at each condition or to ensure their statistical replicability, resulting in a total of 152 curves in the dataset. This Taguchi sampling strategy is capable of covering the entire 4D design space with an extremely small yet highly informative dataset. As a <italic toggle="yes">posteriori</italic> validation, the resultant model predictivity would manifest the Taguchi-guided dataset&#x02019;s high quality (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>).</p><list list-type="simple"><list-item><label>(2)</label><p>&#x0201c;One-to-Many&#x0201d; Curve Variation at Each Molding Condition</p></list-item></list><p>We now take a close inspection into the stress&#x02013;strain curve patterns at each molding condition. <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>b,c show two example sets of iPP specimens&#x02019; stress&#x02013;strain curves at two molding conditions, respectively, wherein the curve patterns follow the typical mechanical behaviors of semicrystalline polymers and exhibit complex multiple regimes [<xref rid="B24-polymers-17-00550" ref-type="bibr">24</xref>,<xref rid="B25-polymers-17-00550" ref-type="bibr">25</xref>,<xref rid="B26-polymers-17-00550" ref-type="bibr">26</xref>,<xref rid="B27-polymers-17-00550" ref-type="bibr">27</xref>,<xref rid="B28-polymers-17-00550" ref-type="bibr">28</xref>,<xref rid="B29-polymers-17-00550" ref-type="bibr">29</xref>], including strain softening regime, steady flow regime, and strain hardening regime (see <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>d), governed by iPP&#x02019;s complex microstructural evolution. Notably, at each molding condition, the stress&#x02013;strain curves exhibit high aleatoric uncertainty and show an extent of fluctuation&#x02014;especially for the elongation at break&#x02014;that is, the &#x0201c;one-to-many&#x0201d; issue, which is ascribed to the intrinsic and inevitable fluctuations of processing parameters and the specimens&#x02019; microstructural discrepancy thereof. To address the &#x0201c;one-to-many&#x0201d; issue, the curve variation at each molding condition would be simplified into a dual distribution representation for DNN model construction (see <xref rid="sec3dot2-polymers-17-00550" ref-type="sec">Section 3.2</xref> and <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>).</p></sec><sec id="sec3dot2-polymers-17-00550"><title>3.2. Simplifying the &#x0201c;One-to-Many&#x0201d; Variational Curve Representation by a Dual Distribution</title><list list-type="simple"><list-item><label>(1)</label><p>Categorical-Distributed Nature of Curve Type</p></list-item></list><p>Since ML model training strictly follows the principle of &#x0201c;one-to-one&#x0201d; unique mapping between inputs and outputs [<xref rid="B13-polymers-17-00550" ref-type="bibr">13</xref>], we address herein the issue of &#x0201c;one-to-many&#x0201d; curve variation at each molding condition by simplifying each set of stress&#x02013;strain curves at one condition as a dual distribution&#x02014;that is, a coupled distribution of curve types and features, ready to reconstruct the expected stress&#x02013;strain curve and its aleatoric uncertainty (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>). Accordingly, the ML model would output a dual distribution that describes the curve variation at each molding condition, rather than simultaneously outputting the many different curves themselves that would be out of the model&#x02019;s capability.</p><p>Regarding the dual distribution, we first investigate the categorical distribution of curve type at each molding condition. Based on the variation in iPP&#x02019;s mechanical response, the curve type can be categorized into three groups, as illustrated in <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>d, as follows: (i) Type I, which is characterized by strain softening; (ii) Type II, which exhibits steady flow; and (iii) Type III, which displays strain hardening after steady flow. Notably, the stress&#x02013;strain curves at one molding condition generally have the same curve type or exhibit a dominant curve type with a few exceptions, as shown in <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>b,c. Further, <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>e shows an example of curve type distribution at one molding condition, which covers all three curve types with one curve type dominating, highlighting the categorical distributed nature of curve type at each molding condition. Accordingly, this probabilistic distribution would be forecasted by constructing an ML classifier configured with a categorical distribution output layer (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>).</p><list list-type="simple"><list-item><label>(2)</label><p>Approxi-Normal-Distributed Nature of Curve Feature Point</p></list-item></list><p>Next, we investigate the distribution of curve features associated with five feature points that dictate the evolution trend of stress&#x02013;strain curves, as illustrated in <xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>d, including (i) the linear limit point (<inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), which marks the end of the linear change of the curve; (ii) the maximum yielding point (<inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), where the curve meets the first peak and the slope turns from positive to negative; (iii) the strain softening inflection point (<inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), where the curve curvature starts to change from negative to positive; (iv) the steady flow limit point (<inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">w</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), which has the same stress value but more elongation; and finally, (v) the fracture point (<inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) when the curve ends. Note that, instead of predicting the entire curve points, predicting solely the five feature points&#x02014;together with the dominant curve type information&#x02014;is ready to reconstruct the corresponding stress&#x02013;strain curve (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>), thus significantly reducing the ML model complexity and the data size requirement.</p><p><xref rid="polymers-17-00550-f002" ref-type="fig">Figure 2</xref>f shows a violin plot of the distribution of curve features at one molding condition, wherein the white point indicates the median, the shape&#x02019;s width reflects data frequency, and each feature has been standardized for illustration purposes. To a moderate extent, all curve features share more or less similar distribution characteristics, with an approxi-symmetric or slightly skewed peak centered around zero, highlighting the approxi-normal distributed nature of curve features. For simplicity, these curve feature distributions would be forecasted by constructing an ML regressor configured with a normal distribution output layer (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>), that is, approximating each curve feature&#x02019;s aleatoric uncertainty by a normal distribution.</p></sec><sec id="sec3dot3-polymers-17-00550"><title>3.3. Predicting the &#x0201c;One-to-Many&#x0201d; Variational Curve by a Dual-Distribution Neural Network</title><list list-type="simple"><list-item><label>(1)</label><p>Dual-Distribution Neural Network Architecture</p></list-item></list><p>To predict the dual-distribution representation of curve variation at each molding condition, we construct herein a dual-distribution neural network (DNN) model. <xref rid="polymers-17-00550-f003" ref-type="fig">Figure 3</xref>a shows the DNN model architecture built by a parallel integration of a curve-type classifier and a curve feature regressor, which takes molding condition as input and is responsible for outputting a distribution of curve type and feature, respectively. Note that, regarding the output-distribution format, the curve-type classifier adopts a categorical distribution output layer and outputs a categorical distribution, as represented by three probability values associated with three curve types (see <xref rid="polymers-17-00550-f003" ref-type="fig">Figure 3</xref>a), while the curve feature predictor adopts a normal distribution output layer and outputs a normal distribution for each curve feature, as represented by its mean value <italic toggle="yes">&#x003bc;</italic> and standard deviation <italic toggle="yes">&#x003b4;</italic> (see <xref rid="polymers-17-00550-f003" ref-type="fig">Figure 3</xref>b).</p><p>Given the dual-distribution output at each molding condition, its expected stress&#x02013;strain curve is ready to reconstruct, with an aleatoric uncertainty provided, as illustrated in <xref rid="polymers-17-00550-f003" ref-type="fig">Figure 3</xref>c. Note that, since the curve feature predictor would yield nonnull outputs for all curve features and cannot distinguish the curve type, a dominant curve type must be provided by the curve type classifier for stress&#x02013;strain curve reconstruction. More technical details about the reconstruction rules are provided in the following section (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>-(3)). Overall, the DNN architecture, combining the curve type classifier and curve feature regressor, forms a knowledge-informed neural network (KINN). This approach leverages the state-of-the-art simplicity of reduced hidden neurons for stress&#x02013;strain curve prediction [<xref rid="B1-polymers-17-00550" ref-type="bibr">1</xref>], with a total of 83 hidden neurons for the curve type classifier and 100 hidden neurons for the curve feature regressor, significantly reducing the data size requirement while maintaining model accuracy (see <xref rid="sec3dot3-polymers-17-00550" ref-type="sec">Section 3.3</xref>-(2)).</p><list list-type="simple"><list-item><label>(2)</label><p>Prediction Accuracy of the Dual-Distribution Neural Network</p></list-item></list><p>Now, we investigate the DNN model&#x02019;s training performance and prediction accuracy. Regarding the DNN training process, the classifier and regressor are trained independently, and their loss functions are defined as the negative log-likelihood of true data under the predicted distribution. All training hyperparameters have been fine-tuned to optimize the model&#x02019;s performance. The stochastic gradient descent (SGD) optimizer is adopted to optimize the neuron weights and biases in 2000 epochs, with an initial learning rate of 0.01 and a batch size of 6 curves per molding condition. We observed that the training loss rapidly decreases and plateaus at 0.4 for the classifier and 5.0 for the regressor. Additionally, the root mean square error (RMSE) and categorical accuracy (CA) reach 0.9 and 1, respectively, by the end of training (as shown in <xref rid="app1-polymers-17-00550" ref-type="app">Figure S1</xref>). Note that, before training, all data are subjected to preprocessing to ensure the training performance, with the curve features and molding conditions subjected to standardization, and the curve types represented by one-hot representation. For null curve features in curve type I and II, the fracture point value is assigned to the null value as the regressor output. More details about the data preprocessing and the training process are provided in the <xref rid="app1-polymers-17-00550" ref-type="app">Supplementary Materials</xref>.</p><p><xref rid="polymers-17-00550-f004" ref-type="fig">Figure 4</xref> shows the prediction accuracy of the curve type classifier, wherein 25 molding conditions are selected as the training set and the remaining 2 conditions serve as the test set, and the confusion matrix of both the training and test sets exhibits a 100% classification accuracy. To validate the classifier&#x02019;s performance, <xref rid="polymers-17-00550-f004" ref-type="fig">Figure 4</xref>b provides the stress&#x02013;strain curves at one test molding condition, and the predicted versus true curve type distribution is provided in <xref rid="polymers-17-00550-f004" ref-type="fig">Figure 4</xref>c. Impressively, the model prediction assigns a 70% probability to curve type III and a 30% probability to curve type II, offering an excellent agreement with the experimental results of 83% type III and 17% type II. Considering the complexity of curve variations at each condition, the close match between predicted versus true distribution demonstrates the classifier&#x02019;s capability in predicting the dominant curve type at each molding condition.</p><p><xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref> shows the prediction accuracy of the curve feature regressor, wherein one molding condition is selected as the test set and the remaining 26 conditions are the training set. As the regressor outputs a normal distribution to quantify each curve feature&#x02019;s aleatoric uncertainty, we adopt herein two types of <italic toggle="yes">y</italic> = <italic toggle="yes">x</italic> calibration curves to evaluate the prediction accuracy of the normal distribution&#x02019;s mean <italic toggle="yes">&#x003bc;</italic> (see <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>a) and standard deviation <italic toggle="yes">&#x003b4;</italic> (see <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>b), respectively. <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>a shows the predicted versus true mean values for each curve feature, with the horizontal and vertical error bars representing the standard deviation of true versus predicted data, respectively. It is notable that all training data points are located around the <italic toggle="yes">y</italic> = <italic toggle="yes">x</italic> line, with the mean squared error (MSE) less than 0.15, which is considered satisfactory herein. More importantly, when extrapolating to the test condition, the regressor exhibits a reasonably good extrapolability to the test set&#x02014;despite the training data size being extremely small and the test set being an extrapolation condition uncovered by the training condition regime.</p><p>Further, we evaluate the prediction accuracy of the normal distribution&#x02019;s standard deviation <italic toggle="yes">&#x003b4;</italic>, that is, the aleatoric uncertainty quantification at each molding condition. <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>b shows the average calibration plot of observed versus predicted data proportion in the <italic toggle="yes">&#x003b1;</italic>-prediction interval for each curve feature, wherein <italic toggle="yes">&#x003b1;</italic> ranges from 0% to 100% to indicate the data proportion falling within the <italic toggle="yes">&#x003b1;</italic>-prediction interval. Ideally, the predicted normal distribution is expected to satisfy the requirement that the observed proportion should be equal to <italic toggle="yes">&#x003b1;</italic> in the <italic toggle="yes">&#x003b1;</italic>-prediction interval, that is, forming a <italic toggle="yes">y</italic> = <italic toggle="yes">x</italic> line in the average calibration plot. Otherwise, the inconsistency between predicted versus true data distribution can be evaluated by the miscalibration area between the calibration curve and the <italic toggle="yes">y</italic> = <italic toggle="yes">x</italic> line, which identifies the distribution range deviating from the real data distribution, suggesting either insufficient or excessive uncertainty estimation. We find that, for each curve feature, the predicted normal distribution exhibits a satisfactory accuracy in describing the experimental data distribution, with an average miscalibration area of 0.11. And in most cases, these miscalibrations show a calibration curve above the <italic toggle="yes">y</italic> = <italic toggle="yes">x</italic> reference line (see <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>b), suggesting a slightly excessive uncertainty estimation, which is potentially beneficial for extrema estimation and reliability guidance thereof. Overall, these results demonstrate that the DNN model can accurately predict the dual-distribution representation of curve variation at each molding condition.</p><list list-type="simple"><list-item><label>(3)</label><p>Reconstructing Variational Curve from its Dual Distribution Representation</p></list-item></list><p>Based on the dual distribution prediction, we can reconstruct the expected stress&#x02013;strain curve and its aleatoric uncertainty at each molding condition. <xref rid="polymers-17-00550-f006" ref-type="fig">Figure 6</xref>a&#x02013;c illustrate the stress&#x02013;strain curve reconstruction rules. First, given the dominant curve type, the expected mean curve is reconstructed by monotonic spline interpolation between the mean values of relevant curve features. Then in the same spirit, the aleatoric uncertainty of this reconstructed curve is provided by connecting the rectangle vertices associated with these curve feature points, wherein each rectangle represents the extrema boundary that encompasses the corresponding curve feature variation. Herein, the rectangle bounds are constructed using the 95% confidence intervals of curve feature distributions, that is, using <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi><mml:mo>&#x000b1;</mml:mo><mml:mn>1.96</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> as the lower and upper bounds to maximally cover the variation range of curve feature points. Finally, considering the monotonic increase trend at the strain hardening regime, the connection between rectangle vertices generally follows the positive-slope linking rule (see <xref rid="polymers-17-00550-f006" ref-type="fig">Figure 6</xref>b), while in some scenarios with substantial fluctuation of the fracture point, the positive-slope linking rule may fail, and to rectify the systematic error, a zero-slope linking rule is applied instead, as shown in <xref rid="polymers-17-00550-f006" ref-type="fig">Figure 6</xref>c. Overall, the set of reconstruction rules offers a simple yet reliable approach to generate the expected stress&#x02013;strain curve and its aleatoric uncertainty in an efficient manner.</p><list list-type="simple"><list-item><label>(4)</label><p>Predicting Curve Variation at Different Molding Conditions</p></list-item></list><p>Based on the reconstruction rules, we finally evaluate the stress&#x02013;strain curve prediction of the DNN model at different molding conditions. <xref rid="polymers-17-00550-f006" ref-type="fig">Figure 6</xref>d&#x02013;f showcase the prediction of the reconstructed stress&#x02013;strain curve at different molding conditions and its aleatoric uncertainty, wherein the experimental curve data are added as a reference, and their predicted curve type distributions are provided in <xref rid="polymers-17-00550-f006" ref-type="fig">Figure 6</xref>g&#x02013;i. Indeed, the reconstructed mean stress&#x02013;strain curves offer an excellent agreement with their experimental curve references, and the established 95% confidence interval can apparently encompass all corresponding raw data curves within the predicted bounds. Further, to evaluate the model&#x02019;s extrapolability to different molding conditions, we iteratively select from the dataset one molding condition as a test set, while the remaining 26 conditions serve as a training set, and it has been proved that the DNN model remains a reasonably good extrapolability to each test condition (see <xref rid="app1-polymers-17-00550" ref-type="app">Supplementary Materials, Table S1</xref>). Despite some discrepancies between the predicted and experimental data, it can be concluded that the DNN model is capable of predicting stress&#x02013;strain curve variation with a modest and reliable 95% confidence interval&#x02014;that is, enabling aleatoric uncertainty quantification, ready for extrema estimation and reliability guidance after further incorporating the epistemic uncertainty (see <xref rid="sec3dot4-polymers-17-00550" ref-type="sec">Section 3.4</xref>).</p></sec><sec id="sec3dot4-polymers-17-00550"><title>3.4. Beyond Curve Variation: Uncertainty Quantification by Bayesian Neural Network</title><list list-type="simple"><list-item><label>(1)</label><p>Epistemic Uncertainty Induced by Model Deviation</p></list-item></list><p>Relying on the distribution output layer, we have demonstrated that the DNN model can generate a probability density distribution to describe the experimental data distribution and quantify its aleatoric uncertainty. However, given the same experimental data, it is very likely that there exists a set of DNN models with different model parameters that can offer comparable model performance, as illustrated in <xref rid="polymers-17-00550-f007" ref-type="fig">Figure 7</xref>. In principle, these models can accurately describe the stress&#x02013;strain curve variation at molding conditions within the experimental dataset but exhibit an evident model deviation between each other in the entire condition range (see <xref rid="polymers-17-00550-f007" ref-type="fig">Figure 7</xref>), which is ascribed to the uncertainty of model parameters&#x02014;that is, &#x0201c;epistemic uncertainty&#x0201d; [<xref rid="B17-polymers-17-00550" ref-type="bibr">17</xref>]. Here, relying on the Bayesian inference theorem (see <xref rid="sec3dot4-polymers-17-00550" ref-type="sec">Section 3.4</xref>-(2)), the Bayesian neural network (BNN) approach would be applied to quantify the epistemic uncertainty of the DNN model [<xref rid="B21-polymers-17-00550" ref-type="bibr">21</xref>,<xref rid="B30-polymers-17-00550" ref-type="bibr">30</xref>,<xref rid="B31-polymers-17-00550" ref-type="bibr">31</xref>]. We expect that, by incorporating the epistemic uncertainty, the model prediction would account for not only the data deviation but also the model deviation (see <xref rid="polymers-17-00550-f007" ref-type="fig">Figure 7</xref>), so as to enhance the prediction accuracy and reliability.</p><list list-type="simple"><list-item><label>(2)</label><p>Bayesian Inference Theorem</p></list-item></list><p>In the provided dataset <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> represents input samples and <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> represents output samples, the ML model is trained to produce results through the adjustment of model parameters <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the number of model parameters (i.e., neuron weights and biases) is determined by the number of neurons in the DNN model herein. By minimizing the loss function <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> between the model <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the target value <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, traditional ML models typically seek a specific set of parameters <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> to establish a one-to-one mapping relationship between input samples <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and output samples <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>In contrast, Bayesian methods, represented by Equation (1), provide a unique capability to capture both the aleatoric and epistemic uncertainty by stochastic probability models [<xref rid="B21-polymers-17-00550" ref-type="bibr">21</xref>,<xref rid="B22-polymers-17-00550" ref-type="bibr">22</xref>]:<disp-formula id="FD1-polymers-17-00550"><label>(1)</label><mml:math id="mm23" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
wherein <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>&#x000b7;</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is the probability density function (PDF), herein modeled as a normal distribution with a mean of <inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and a variance of <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> to quantify aleatoric uncertainty, serving as the prior. It is assumed that the data in the dataset <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are independent of each other, allowing the likelihood <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> to be expressed as Equation (2):<disp-formula id="FD2-polymers-17-00550"><label>(2)</label><mml:math id="mm29" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
and according to Bayes&#x02019; theorem [<xref rid="B30-polymers-17-00550" ref-type="bibr">30</xref>,<xref rid="B31-polymers-17-00550" ref-type="bibr">31</xref>], the posterior PDF <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> can be computed by Equation (3), which is intrinsically connected to the representation of epistemic uncertainty:<disp-formula id="FD3-polymers-17-00550"><label>(3)</label><mml:math id="mm31" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
wherein a prior PDF <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is set as the independent Gaussian for each weight and bias in BNN neurons, collectively describing the possible distribution of <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>. Then, given the new input <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, the predicted output distribution <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is defined by Equation (4) as follows:<disp-formula id="FD4-polymers-17-00550"><label>(4)</label><mml:math id="mm37" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
which represents the total uncertainty consisting of both the aleatoric and epistemic uncertainty. Employing variational inference (VI) to approximate the true posterior <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> via the BNN model [<xref rid="B31-polymers-17-00550" ref-type="bibr">31</xref>], a factorized Gaussian distribution <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is utilized, where the BNN model parameters <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> comprises the mean and standard deviation in each independent Gaussian to describe the distribution of each neuron weight or bias, as expressed by Equation (5):<disp-formula id="FD5-polymers-17-00550"><label>(5)</label><mml:math id="mm41" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>By substituting <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> in Equation (4) with <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, the total uncertainty <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is derived as Equation (6):<disp-formula id="FD6-polymers-17-00550"><label>(6)</label><mml:math id="mm45" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As a result, the mean <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and the upper-bound variance <inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> are computed by Equations (7) and (8), respectively [<xref rid="B21-polymers-17-00550" ref-type="bibr">21</xref>,<xref rid="B31-polymers-17-00550" ref-type="bibr">31</xref>]:<disp-formula id="FD7-polymers-17-00550"><label>(7)</label><mml:math id="mm48" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="sans-serif">&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="sans-serif">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="sans-serif">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="sans-serif">&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="sans-serif">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="sans-serif">&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD8-polymers-17-00550"><label>(8)</label><mml:math id="mm49" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mo>&#x023df;</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>U</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mo>&#x023df;</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>U</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder></mml:mrow></mml:mrow></mml:math></disp-formula>
wherein the expected mean <inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> (referred to as <inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> below) is calculated via sampling neuron weights and biases from their Gaussian distributions in the well-trained BNN model (see <xref rid="polymers-17-00550-f008" ref-type="fig">Figure 8</xref>). Accordingly, the aleatoric uncertainty <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> (referred to as <inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> below) and the epistemic uncertainty <inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> (referred to as <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm57" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively, below) can be obtained to evaluate the deviation of data and model separately (see <xref rid="sec3dot4-polymers-17-00550" ref-type="sec">Section 3.4</xref>-(3)).</p><list list-type="simple"><list-item><label>(3)</label><p>Total Uncertainty Quantification by a Dual-Distribution Bayesian Network</p></list-item></list><p>According to the above BNN approach, we construct herein a dual-distribution Bayesian network (DBN) to simultaneously address both the aleatoric and epistemic uncertainty. Compared to the DNN model, the DBN model simply replaces all hidden neurons with the BNN neuron type. Unlike setting a single value for weights and biases in traditional neurons, the BNN neurons use some distribution parameters to describe the distribution of weights and biases (i.e., mean and standard deviation in Gaussian distribution herein), and these distribution parameters are optimized via the same training scheme as the DNN model. After training, we randomly sample from the distributions of weights and biases to output multiple dual-distribution results so that the DBN model is equivalent to multiple DNN models under different settings of weights and biases. By statistically analyzing the multiple outputs based on Equation (8), the DBN model enables quantification of both the aleatoric and epistemic uncertainty.</p><p><xref rid="polymers-17-00550-f008" ref-type="fig">Figure 8</xref> illustrates the quantification of epistemic uncertainty using the DBN model, wherein the weights and biases in BNN neurons are sampled from their independent Gaussian distributions so that the BNN-based curve type classifier and curve feature regressor are equivalent to multiple classifiers and regressors based on artificial neural networks (ANNs) under different settings of weights and biases. By statistical averaging, the BNN-based classifier outputs the mean probability for each curve type (denoted as <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>), along with a standard deviation (<inline-formula><mml:math id="mm62" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) that encapsulates the potential deviation in curve type classification, that is, the epistemic uncertainty of the classifier model (see <xref rid="polymers-17-00550-f008" ref-type="fig">Figure 8</xref>a). Similarly, the BNN-based regressor yields multiple mean <italic toggle="yes">&#x003bc;</italic> and standard deviation <italic toggle="yes">&#x003b4;</italic> for each curve feature distribution and then statistically averages the multiple values to obtain the expected mean <inline-formula><mml:math id="mm63" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> and aleatoric uncertainty <inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> for each curve feature, along with the standard deviation of <italic toggle="yes">&#x003bc;</italic> and <italic toggle="yes">&#x003b4;</italic> (denoted as <inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) computed as the epistemic uncertainty of the regressor model (see <xref rid="polymers-17-00550-f008" ref-type="fig">Figure 8</xref>b). Overall, by introducing a BNN hidden neuron into the DNN architecture, the DBN model can not only inherit all the DNN model&#x02019;s attributes for stress&#x02013;strain curve prediction but also quantify the epistemic uncertainty of the DNN model toward enhanced model reliability.</p></sec><sec id="sec3dot5-polymers-17-00550"><title>3.5. Curve Uncertainty Prediction by the Dual-Distribution Bayesian Model</title><list list-type="simple"><list-item><label>(1)</label><p>Prediction Accuracy of the Dual-Distribution Uncertainty</p></list-item></list><p>We now evaluate the DBN model&#x02019;s prediction accuracy by taking into consideration the epistemic uncertainty of its dual distribution output. Note that the DBN and DNN model shares the same training scheme, and the training details are provided in <xref rid="app1-polymers-17-00550" ref-type="app">Supplementary Materials</xref>. Unlike the DNN model that predicts only one dual-distribution output at a molding condition, the DBN model can generate multiple dual-distribution outputs at the same molding condition, for example, 100 outputs herein, via sampling different combinations of weights and biases from their independent distributions in BNN neurons. The final output of the DBN model is the &#x0201c;dual-distribution uncertainty&#x0201d;&#x02014;that is, the mean and variance of the multiple dual-distribution outputs (see <xref rid="polymers-17-00550-f008" ref-type="fig">Figure 8</xref>), which represent, respectively, the aleatoric and epistemic uncertainty in predicting a stress&#x02013;strain curve at the molding condition.</p><p><xref rid="polymers-17-00550-f009" ref-type="fig">Figure 9</xref> shows the prediction accuracy of the BNN-based curve type classifier in the DBN model, wherein the dominant curve type at each molding condition is determined by averaging over 100 predictions of curve type distribution, and the confusion matrix of both the training and test sets exhibits a 100% classification accuracy. Similar to the classifier performance in the DNN model (see <xref rid="polymers-17-00550-f004" ref-type="fig">Figure 4</xref>), the BNN-based classifier offers a curve type distribution in excellent agreement with its experimental data reference (see <xref rid="polymers-17-00550-f009" ref-type="fig">Figure 9</xref>b,c). Moreover, the predicted distribution contains not only the mean probability for each curve type but also the standard deviation that quantifies the classifier&#x02019;s epistemic uncertainty, thus fundamentally enhancing the model prediction reliability.</p><p><xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref> shows the prediction accuracy of the BNN-based curve feature regressor in the DBN model, wherein two types of <italic toggle="yes">y</italic> = <italic toggle="yes">x</italic> calibration curves are provided to evaluate the accuracy of, respectively, the predicted mean <italic toggle="yes">&#x003bc;</italic> (see <xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref>a) and variance <italic toggle="yes">&#x003b4;</italic> (see <xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref>b) of the experimental curve feature distribution. Note that the mean and variance are determined by averaging over 100 predictions of curve feature distribution, as computed by Equations (7) and (8), respectively, and herein, the upper-bound variance is utilized to benefit extrema estimation by combining all sources of uncertainty, that is, a variance of <inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (see Equation (8)). <xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref>a shows the predicted versus true mean values for each curve feature, with the horizontal and vertical error bars representing the variance of true versus predicted data, respectively, and the average calibration plot of observed versus predicted data proportion in the <italic toggle="yes">&#x003b1;</italic>-prediction interval is provided in <xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref>b.</p><p>Similar to the regressor performance in the DNN model (see <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>), the BNN-based regressor offers a satisfactory match between predicted versus true mean values, with the training set MSE less than 0.15, comparable to that of the DNN model (i.e., an MSE of 0.15, see <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>a). And when extrapolating to the test set, the regressor exhibits evidently better extrapolability than the DNN model (see <xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref>a), suggesting that the statistical average operation of BNN-based outputs is likely to eliminate the bias effect of model deviation and, therefore, enhance the model&#x02019;s extrapolability. We then evaluate the predicted upper-bound variance based on the miscalibration area in the average calibration plot for each curve feature (see <xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref>b). As expected, by considering the upper-bound variance, the predicted normal distribution exhibits an expanded width yet remains satisfactory in describing the experimental data distribution, with an average miscalibration area of 0.18, higher than that of the DNN model (i.e., an area of 0.11, see <xref rid="polymers-17-00550-f005" ref-type="fig">Figure 5</xref>b), and to a more evident extent, these miscalibrations show a calibration curve above the <italic toggle="yes">y</italic> = <italic toggle="yes">x</italic> reference line (see <xref rid="polymers-17-00550-f010" ref-type="fig">Figure 10</xref>b), suggesting an excessive yet modest uncertainty estimation, which is considered to be beneficial herein for extrema estimation.</p><list list-type="simple"><list-item><label>(2)</label><p>Reconstructing Curve Uncertainty from its Dual Distribution Uncertainty</p></list-item></list><p>Based on the dual-distribution output of DBN model, we can reconstruct the expected stress&#x02013;strain curve and both its aleatoric and epistemic uncertainty, following the same reconstruction rules applied to the DNN model (see <xref rid="polymers-17-00550-f006" ref-type="fig">Figure 6</xref>). <xref rid="polymers-17-00550-f011" ref-type="fig">Figure 11</xref> shows the reconstruction of the stress&#x02013;strain curve and its uncertainty based on the DBN model. Compared to DNN-based reconstruction, DBN-based reconstruction provides a statistically model-averaged estimation of the expected mean <inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> and variance <inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> of curve variation at each molding condition (see Equations (7) and (8)), fundamentally eliminating the biased-model effect on aleatoric uncertainty quantification. More distinctively, the reconstruction approach introduces two new sources of uncertainty, that is, the epistemic uncertainty of <inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm71" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#x02014;herein denoted as <inline-formula><mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (see Equation (8))&#x02014;which are reconstructed as three new uncertainty regions associated to the stress&#x02013;strain curve&#x02019;s mean value, lower bound, and upper bound, respectively (see <xref rid="polymers-17-00550-f011" ref-type="fig">Figure 11</xref>a). For simplicity, each epistemic uncertainty region is approximated by a normal distribution at a 95% confidence interval, given the computed mean (<inline-formula><mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm75" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>) and variance (<inline-formula><mml:math id="mm76" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm77" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>). Based on these reconstruction rules, the visualization of the stress&#x02013;strain curve prediction distinctively differentiates between the aleatoric and epistemic uncertainty.</p><p><xref rid="polymers-17-00550-f011" ref-type="fig">Figure 11</xref>b&#x02013;d showcase the reconstructed stress&#x02013;strain curve and its aleatoric and epistemic uncertainty at different molding conditions, wherein the experimental curve data are added as a reference, and their predicted curve type distributions are provided in <xref rid="polymers-17-00550-f011" ref-type="fig">Figure 11</xref>e&#x02013;g. Unlike the DNN model solely characterizing the aleatoric uncertainty (see <xref rid="polymers-17-00550-f006" ref-type="fig">Figure 6</xref>), the DBN model provides a reconstructed stress&#x02013;strain curve with a taxonomy of different sources of curve uncertainty at each molding condition. Notably, by incorporating epistemic uncertainty, these curve reconstructions remain closely similar to DNN-based reconstructions, revealing that the epistemic uncertainty is controlled within a modest extent at a small data size. When extrapolating to different test molding conditions, it is notable that the DBN model can generally offer modest epistemic uncertainty at a magnitude negligible or comparable to the aleatoric uncertainty (see <xref rid="app1-polymers-17-00550" ref-type="app">Supplementary Materials</xref>), demonstrating the reliability of DBN model in predicting stress&#x02013;strain curve at a modest uncertainty using small-size dataset, with both the epistemic and aleatoric uncertainty differentiated and visualized.</p><list list-type="simple"><list-item><label>(3)</label><p>Curve Uncertainty Quantification at Different Molding Conditions</p></list-item></list><p>Based on the visualized uncertainty sources, we finally establish the maximum uncertainty quantification of the stress&#x02013;strain curve prediction. According to the upper-bound variance estimation in curve uncertainty (see Equation (8)), the maximum uncertainty can be attained by summing up all uncertainty sources, that is, a normal distribution with a mean <inline-formula><mml:math id="mm78" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> and variance <inline-formula><mml:math id="mm79" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> at 95% confidence interval, as illustrated in <xref rid="polymers-17-00550-f012" ref-type="fig">Figure 12</xref>a. <xref rid="polymers-17-00550-f012" ref-type="fig">Figure 12</xref>b&#x02013;d show some examples of the maximum uncertainty quantification at different molding conditions (see the middle panel), with the uncertainty source visualization and the predicted curve type distribution provided in the left and right panels, respectively. Indeed, we find that the maximum uncertainty boundary can properly encompass its experimental stress&#x02013;strain curves at each molding condition, especially for those key feature points captured by the curve feature regressor. Note that, despite their satisfactory alignment, the predictions and experimental data exhibit some discernible discrepancies, which deserve future investigations and might be rooted in (i) the predefined normal distribution of curve features and (ii) the monotonic spline interpolation in curve reconstruction rules. Importantly, by summing up all uncertainty sources, we find that the maximum uncertainty remains a modest range slightly larger than its raw data distribution, which echoes the constrained epistemic uncertainty of the DBN model, and these findings remain true when extrapolating to different test molding conditions (see <xref rid="app1-polymers-17-00550" ref-type="app">Supplementary Materials</xref>). Based on the modest maximum-uncertainty, it concludes that the DBN model is adept at extrema estimation and reliability guidance, that is, &#x0201c;predict stress&#x02013;strain curve with confidence&#x0201d;.</p></sec></sec><sec sec-type="conclusions" id="sec4-polymers-17-00550"><title>4. Conclusions</title><p>Overall, this study pioneers a machine learning framework&#x02014;the dual Bayesian network (DBN) model&#x02014;to predict complex stress&#x02013;strain curves with reliable and modest uncertainty, even with a small dataset. The model excels in differentiating between aleatoric and epistemic uncertainty and visualizing all sources of uncertainty. Notably, by accounting for all uncertainties, the maximum uncertainty of each prediction is controlled within a modest range, effectively encompassing the experimental data, despite the challenging task of extrapolating across the entire design space with limited data points. This balance between data minimization and uncertainty quantification is achieved through the following two key strategies of the DBN model: (i) the state-of-the-art simplicity of the dual classifier&#x02013;regressor architecture and (ii) the small yet high-quality dataset generated via the Taguchi sampling method. We believe the DBN model&#x02019;s capabilities are potentially transferable to a variety of curve-type properties, making it versatile for extrema estimation and reliability analysis in material property predictions.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><app-group><app id="app1-polymers-17-00550"><title>Supplementary Materials</title><p>The following supporting information can be downloaded at: <uri xlink:href="https://www.mdpi.com/article/10.3390/polym17040550/s1">https://www.mdpi.com/article/10.3390/polym17040550/s1</uri>, Figure S1: Training performance of DBN model. (a) Training loss of curve feature regressor as a function of training epochs. The loss function is defined as negative log-likelihood loss. (b) Training loss of curve type classifier. (c) Root mean square error (RMSE) of curve feature regressor as a function of training epochs for the training set. (d) Categorical accuracy (CA) of curve type classifier as a function of training epochs for the training set. (e) Evolution of regressor RMSE as a function of training epochs for the validation set. (f) Evolution of classifier CA as a function of training epochs for the validation set; Table S1: List of DBN model predictions at each of the 27 molding conditions. For each test condition in the first column, the model is trained with the other 26 conditions. The second column presents the result of curve type classifier with error bar indicating its uncertainty and the third column is the curve reconstruction output with one plot indicating all uncertainty sources (upper panel) and one offering the maximum uncertainty by summing up all uncertainties (lower panel); Table S2: List of 27 molding conditions used for prediction. References [<xref rid="B32-polymers-17-00550" ref-type="bibr">32</xref>,<xref rid="B33-polymers-17-00550" ref-type="bibr">33</xref>,<xref rid="B34-polymers-17-00550" ref-type="bibr">34</xref>,<xref rid="B35-polymers-17-00550" ref-type="bibr">35</xref>] are cited in the Supplementary Materials.</p><supplementary-material id="polymers-17-00550-s001" position="float" content-type="local-data"><media xlink:href="polymers-17-00550-s001.zip"/></supplementary-material></app></app-group><notes><title>Author Contributions</title><p>Conceptualization: H.L.; methodology: T.L. and H.L.; investigation: T.L., Z.C. and H.L.; visualization: T.L. and H.L.; supervision: Z.Z., Z.W., G.-J.Z., Z.-M.L. and H.L.; writing (original draft): T.L. and H.L.; writing (review and editing): Z.Z., Z.W., G.-J.Z., Z.-M.L. and H.L. All authors have read and agreed to the published version of the manuscript.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The original contributions presented in this study are included in the article and <xref rid="app1-polymers-17-00550" ref-type="app">Supplementary Material</xref>. Further inquiries can be directed to the corresponding author.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare that they have no competing interests.</p></notes><ref-list><title>References</title><ref id="B1-polymers-17-00550"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Wu</surname><given-names>F.-Y.</given-names></name>
<name><surname>Zhong</surname><given-names>G.-J.</given-names></name>
<name><surname>Li</surname><given-names>Z.-M.</given-names></name>
</person-group><article-title>Predicting the complex stress-strain curves of polymeric solids by classification-embedded dual neural network</article-title><source>Mater. Des.</source><year>2023</year><volume>227</volume><elocation-id>111773</elocation-id><pub-id pub-id-type="doi">10.1016/j.matdes.2023.111773</pub-id></element-citation></ref><ref id="B2-polymers-17-00550"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Huang</surname><given-names>Z.</given-names></name>
<name><surname>Schoenholz</surname><given-names>S.S.</given-names></name>
<name><surname>Cubuk</surname><given-names>E.D.</given-names></name>
<name><surname>Smedskjaer</surname><given-names>M.M.</given-names></name>
<name><surname>Sun</surname><given-names>Y.</given-names></name>
<name><surname>Wang</surname><given-names>W.</given-names></name>
<name><surname>Bauchy</surname><given-names>M.</given-names></name>
</person-group><article-title>Learning molecular dynamics: Predicting the dynamics of glasses by a machine learning simulator</article-title><source>Mater. Horiz.</source><year>2023</year><volume>10</volume><fpage>3416</fpage><lpage>3428</lpage><pub-id pub-id-type="doi">10.1039/D3MH00028A</pub-id><pub-id pub-id-type="pmid">37382413</pub-id>
</element-citation></ref><ref id="B3-polymers-17-00550"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Niu</surname><given-names>S.</given-names></name>
<name><surname>Zhang</surname><given-names>E.</given-names></name>
<name><surname>Bazilevs</surname><given-names>Y.</given-names></name>
<name><surname>Srivastava</surname><given-names>V.</given-names></name>
</person-group><article-title>Modeling finite-strain plasticity using physics-informed neural network and assessment of the network performance</article-title><source>J. Mech. Phys. Solids</source><year>2023</year><volume>172</volume><elocation-id>105177</elocation-id><pub-id pub-id-type="doi">10.1016/j.jmps.2022.105177</pub-id></element-citation></ref><ref id="B4-polymers-17-00550"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Feng</surname><given-names>H.</given-names></name>
<name><surname>Prabhakar</surname><given-names>P.</given-names></name>
</person-group><article-title>Parameterization-based neural network: Predicting non-linear stress&#x02013;strain response of composites</article-title><source>Eng. Comput.</source><year>2024</year><volume>40</volume><fpage>1621</fpage><lpage>1635</lpage><pub-id pub-id-type="doi">10.1007/s00366-023-01849-0</pub-id></element-citation></ref><ref id="B5-polymers-17-00550"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Aoyagi</surname><given-names>T.</given-names></name>
</person-group><article-title>Optimization of the elastic properties of block copolymers using coarse-grained simulation and an artificial neural network</article-title><source>Comput. Mater. Sci.</source><year>2022</year><volume>207</volume><elocation-id>111286</elocation-id><pub-id pub-id-type="doi">10.1016/j.commatsci.2022.111286</pub-id></element-citation></ref><ref id="B6-polymers-17-00550"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chai</surname><given-names>Z.</given-names></name>
<name><surname>Zong</surname><given-names>Z.</given-names></name>
<name><surname>Yong</surname><given-names>H.</given-names></name>
<name><surname>Ke</surname><given-names>X.</given-names></name>
<name><surname>Zhu</surname><given-names>J.</given-names></name>
<name><surname>Ding</surname><given-names>H.</given-names></name>
<name><surname>Guo</surname><given-names>C.F.</given-names></name>
<name><surname>Wu</surname><given-names>Z.</given-names></name>
</person-group><article-title>Tailoring Stress-strain Curves of Flexible Snapping Mechanical Metamaterial for On-demand Mechanical Responses via Data-driven Inverse Design</article-title><source>Adv. Mater.</source><year>2024</year><volume>36</volume><elocation-id>2404369</elocation-id><pub-id pub-id-type="doi">10.1002/adma.202404369</pub-id><pub-id pub-id-type="pmid">38938165</pub-id>
</element-citation></ref><ref id="B7-polymers-17-00550"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ha</surname><given-names>C.S.</given-names></name>
<name><surname>Yao</surname><given-names>D.</given-names></name>
<name><surname>Xu</surname><given-names>Z.</given-names></name>
<name><surname>Liu</surname><given-names>C.</given-names></name>
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Elkins</surname><given-names>D.</given-names></name>
<name><surname>Kile</surname><given-names>M.</given-names></name>
<name><surname>Deshpande</surname><given-names>V.</given-names></name>
<name><surname>Kong</surname><given-names>Z.</given-names></name>
<name><surname>Bauchy</surname><given-names>M.</given-names></name>
<etal/>
</person-group><article-title>Rapid inverse design of metamaterials based on prescribed mechanical behavior through machine learning</article-title><source>Nat. Commun.</source><year>2023</year><volume>14</volume><elocation-id>5765</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-40854-1</pub-id><pub-id pub-id-type="pmid">37718343</pub-id>
</element-citation></ref><ref id="B8-polymers-17-00550"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Fu</surname><given-names>Z.</given-names></name>
<name><surname>Yang</surname><given-names>K.</given-names></name>
<name><surname>Xu</surname><given-names>X.</given-names></name>
<name><surname>Bauchy</surname><given-names>M.</given-names></name>
</person-group><article-title>Machine learning for glass science and engineering: A review</article-title><source>J. Non-Cryst. Solids</source><year>2021</year><volume>557</volume><elocation-id>119419</elocation-id><pub-id pub-id-type="doi">10.1016/j.jnoncrysol.2019.04.039</pub-id></element-citation></ref><ref id="B9-polymers-17-00550"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Angelopoulos</surname><given-names>A.N.</given-names></name>
<name><surname>Bates</surname><given-names>S.</given-names></name>
<name><surname>Fannjiang</surname><given-names>C.</given-names></name>
<name><surname>Jordan</surname><given-names>M.I.</given-names></name>
<name><surname>Zrnic</surname><given-names>T.</given-names></name>
</person-group><article-title>Prediction-powered inference</article-title><source>Science</source><year>2023</year><volume>382</volume><fpage>669</fpage><lpage>674</lpage><pub-id pub-id-type="doi">10.1126/science.adi6000</pub-id><pub-id pub-id-type="pmid">37943906</pub-id>
</element-citation></ref><ref id="B10-polymers-17-00550"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Butler</surname><given-names>K.T.</given-names></name>
<name><surname>Davies</surname><given-names>D.W.</given-names></name>
<name><surname>Cartwright</surname><given-names>H.</given-names></name>
<name><surname>Isayev</surname><given-names>O.</given-names></name>
<name><surname>Walsh</surname><given-names>A.</given-names></name>
</person-group><article-title>Machine learning for molecular and materials science</article-title><source>Nature</source><year>2018</year><volume>559</volume><fpage>547</fpage><lpage>555</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0337-2</pub-id><pub-id pub-id-type="pmid">30046072</pub-id>
</element-citation></ref><ref id="B11-polymers-17-00550"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Qian</surname><given-names>X.</given-names></name>
<name><surname>Yoon</surname><given-names>B.-J.</given-names></name>
<name><surname>Arr&#x000f3;yave</surname><given-names>R.</given-names></name>
<name><surname>Qian</surname><given-names>X.</given-names></name>
<name><surname>Dougherty</surname><given-names>E.R.</given-names></name>
</person-group><article-title>Knowledge-driven learning, optimization, and experimental design under uncertainty for materials discovery</article-title><source>Patterns</source><year>2023</year><volume>4</volume><elocation-id>100863</elocation-id><pub-id pub-id-type="doi">10.1016/j.patter.2023.100863</pub-id><pub-id pub-id-type="pmid">38035192</pub-id>
</element-citation></ref><ref id="B12-polymers-17-00550"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Brunner</surname><given-names>A.J.</given-names></name>
</person-group><article-title>Fracture mechanics testing of fiber-reinforced polymer composites: The effects of the &#x0201c;human factor&#x0201d; on repeatability and reproducibility of test data</article-title><source>Eng. Fract. Mech.</source><year>2022</year><volume>264</volume><elocation-id>108340</elocation-id><pub-id pub-id-type="doi">10.1016/j.engfracmech.2022.108340</pub-id></element-citation></ref><ref id="B13-polymers-17-00550"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Liu</surname><given-names>Y.</given-names></name>
<name><surname>Li</surname><given-names>K.</given-names></name>
<name><surname>Zhao</surname><given-names>Z.</given-names></name>
<name><surname>Schoenholz</surname><given-names>S.S.</given-names></name>
<name><surname>Cubuk</surname><given-names>E.D.</given-names></name>
<name><surname>Gupta</surname><given-names>P.</given-names></name>
<name><surname>Bauchy</surname><given-names>M.</given-names></name>
</person-group><article-title>End-to-end differentiability and tensor processing unit computing to accelerate materials&#x02019; inverse design</article-title><source>npj Comput. Mater.</source><year>2023</year><volume>9</volume><elocation-id>121</elocation-id><pub-id pub-id-type="doi">10.1038/s41524-023-01080-x</pub-id></element-citation></ref><ref id="B14-polymers-17-00550"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Zhang</surname><given-names>T.</given-names></name>
<name><surname>Anoop Krishnan</surname><given-names>N.M.</given-names></name>
<name><surname>Smedskjaer</surname><given-names>M.M.</given-names></name>
<name><surname>Ryan</surname><given-names>J.V.</given-names></name>
<name><surname>Gin</surname><given-names>S.</given-names></name>
<name><surname>Bauchy</surname><given-names>M.</given-names></name>
</person-group><article-title>Predicting the dissolution kinetics of silicate glasses by topology-informed machine learning</article-title><source>npj Mater. Degrad.</source><year>2019</year><volume>3</volume><fpage>32</fpage><pub-id pub-id-type="doi">10.1038/s41529-019-0094-1</pub-id></element-citation></ref><ref id="B15-polymers-17-00550"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wakjira</surname><given-names>T.G.</given-names></name>
<name><surname>Alam</surname><given-names>M.S.</given-names></name>
</person-group><article-title>Peak and ultimate stress-strain model of confined ultra-high-performance concrete (UHPC) using hybrid machine learning model with conditional tabular generative adversarial network</article-title><source>Appl. Soft Comput.</source><year>2024</year><volume>154</volume><elocation-id>111353</elocation-id><pub-id pub-id-type="doi">10.1016/j.asoc.2024.111353</pub-id></element-citation></ref><ref id="B16-polymers-17-00550"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Tsai</surname><given-names>M.-L.</given-names></name>
<name><surname>Huang</surname><given-names>C.-W.</given-names></name>
<name><surname>Chang</surname><given-names>S.-W.</given-names></name>
</person-group><article-title>Theory-inspired machine learning for stress&#x02013;strain curve prediction of short fiber-reinforced composites with unseen design space</article-title><source>Extrem. Mech. Lett.</source><year>2023</year><volume>65</volume><elocation-id>102097</elocation-id><pub-id pub-id-type="doi">10.1016/j.eml.2023.102097</pub-id></element-citation></ref><ref id="B17-polymers-17-00550"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>H&#x000fc;llermeier</surname><given-names>E.</given-names></name>
<name><surname>Waegeman</surname><given-names>W.</given-names></name>
</person-group><article-title>Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods</article-title><source>Mach. Learn.</source><year>2021</year><volume>110</volume><fpage>457</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1007/s10994-021-05946-3</pub-id></element-citation></ref><ref id="B18-polymers-17-00550"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>H.</given-names></name>
<name><surname>Fu</surname><given-names>Z.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Sabri</surname><given-names>N.F.A.</given-names></name>
<name><surname>Bauchy</surname><given-names>M.</given-names></name>
</person-group><article-title>Balance between accuracy and simplicity in empirical forcefields for glass modeling: Insights from machine learning</article-title><source>J. Non-Cryst. Solids</source><year>2019</year><volume>515</volume><fpage>133</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.jnoncrysol.2019.04.020</pub-id></element-citation></ref><ref id="B19-polymers-17-00550"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Correa</surname><given-names>M.</given-names></name>
<name><surname>Bielza</surname><given-names>C.</given-names></name>
<name><surname>Pamies-Teixeira</surname><given-names>J.</given-names></name>
</person-group><article-title>Comparison of Bayesian networks and artificial neural networks for quality detection in a machining process</article-title><source>Expert Syst. Appl.</source><year>2009</year><volume>36</volume><fpage>7270</fpage><lpage>7279</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2008.09.024</pub-id></element-citation></ref><ref id="B20-polymers-17-00550"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jospin</surname><given-names>L.V.</given-names></name>
<name><surname>Laga</surname><given-names>H.</given-names></name>
<name><surname>Boussaid</surname><given-names>F.</given-names></name>
<name><surname>Buntine</surname><given-names>W.</given-names></name>
<name><surname>Bennamoun</surname><given-names>M.</given-names></name>
</person-group><article-title>Hands-On Bayesian Neural Networks&#x02014;A Tutorial for Deep Learning Users</article-title><source>IEEE Comput. Intell. Mag.</source><year>2022</year><volume>17</volume><fpage>29</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1109/MCI.2022.3155327</pub-id></element-citation></ref><ref id="B21-polymers-17-00550"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Olivier</surname><given-names>A.</given-names></name>
<name><surname>Shields</surname><given-names>M.D.</given-names></name>
<name><surname>Graham-Brady</surname><given-names>L.</given-names></name>
</person-group><article-title>Bayesian neural networks for uncertainty quantification in data-driven materials modeling</article-title><source>Comput. Methods Appl. Mech. Eng.</source><year>2021</year><volume>386</volume><elocation-id>114079</elocation-id><pub-id pub-id-type="doi">10.1016/j.cma.2021.114079</pub-id></element-citation></ref><ref id="B22-polymers-17-00550"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fern&#x000e1;ndez</surname><given-names>J.</given-names></name>
<name><surname>Chiach&#x000ed;o</surname><given-names>M.</given-names></name>
<name><surname>Chiach&#x000ed;o</surname><given-names>J.</given-names></name>
<name><surname>Mu&#x000f1;oz</surname><given-names>R.</given-names></name>
<name><surname>Herrera</surname><given-names>F.</given-names></name>
</person-group><article-title>Uncertainty quantification in Neural Networks by Approximate Bayesian Computation: Application to fatigue in composite materials</article-title><source>Eng. Appl. Artif. Intell.</source><year>2022</year><volume>107</volume><elocation-id>104511</elocation-id><pub-id pub-id-type="doi">10.1016/j.engappai.2021.104511</pub-id></element-citation></ref><ref id="B23-polymers-17-00550"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Taguchi</surname><given-names>G.</given-names></name>
</person-group><article-title>Quality engineering (Taguchi methods) for the development of electronic circuit technology</article-title><source>IEEE Trans. Reliab.</source><year>1995</year><volume>44</volume><fpage>225</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1109/24.387375</pub-id></element-citation></ref><ref id="B24-polymers-17-00550"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Smith</surname><given-names>T.</given-names></name>
<name><surname>Gupta</surname><given-names>C.</given-names></name>
<name><surname>Siavoshani</surname><given-names>A.Y.</given-names></name>
<name><surname>Wang</surname><given-names>S.-Q.</given-names></name>
</person-group><article-title>Building a phenomenological chain-level understanding of mechanics of semicrystalline polymers: 1. Experimental</article-title><source>Polymer</source><year>2023</year><volume>274</volume><elocation-id>125878</elocation-id><pub-id pub-id-type="doi">10.1016/j.polymer.2023.125878</pub-id></element-citation></ref><ref id="B25-polymers-17-00550"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>S.-Q.</given-names></name>
<name><surname>Smith</surname><given-names>T.</given-names></name>
<name><surname>Gupta</surname><given-names>C.</given-names></name>
<name><surname>Siavoshani</surname><given-names>A.Y.</given-names></name>
</person-group><article-title>Building a phenomenological chain-level understanding of mechanics of semicrystalline polymers: 2. Conceptual</article-title><source>Polymer</source><year>2023</year><volume>274</volume><elocation-id>125877</elocation-id><pub-id pub-id-type="doi">10.1016/j.polymer.2023.125877</pub-id></element-citation></ref><ref id="B26-polymers-17-00550"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Ben Jar</surname><given-names>P.-Y.</given-names></name>
<name><surname>Xue</surname><given-names>S.</given-names></name>
<name><surname>Li</surname><given-names>L.</given-names></name>
</person-group><article-title>Quantification of strain-induced damage in semi-crystalline polymers: A review</article-title><source>J. Mater. Sci.</source><year>2019</year><volume>54</volume><fpage>62</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1007/s10853-018-2859-2</pub-id></element-citation></ref><ref id="B27-polymers-17-00550"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dusunceli</surname><given-names>N.</given-names></name>
<name><surname>Colak</surname><given-names>O.U.</given-names></name>
</person-group><article-title>Modelling effects of degree of crystallinity on mechanical behavior of semicrystalline polymers</article-title><source>Int. J. Plast.</source><year>2008</year><volume>24</volume><fpage>1224</fpage><lpage>1242</lpage><pub-id pub-id-type="doi">10.1016/j.ijplas.2007.09.003</pub-id></element-citation></ref><ref id="B28-polymers-17-00550"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Poli&#x00144;ska</surname><given-names>M.</given-names></name>
<name><surname>Rozanski</surname><given-names>A.</given-names></name>
<name><surname>Galeski</surname><given-names>A.</given-names></name>
<name><surname>Bojda</surname><given-names>J.</given-names></name>
</person-group><article-title>The Modulus of the Amorphous Phase of Semicrystalline Polymers</article-title><source>Macromolecules</source><year>2021</year><volume>54</volume><fpage>9113</fpage><lpage>9123</lpage><pub-id pub-id-type="doi">10.1021/acs.macromol.1c01576</pub-id></element-citation></ref><ref id="B29-polymers-17-00550"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ranganathan</surname><given-names>R.</given-names></name>
<name><surname>Kumar</surname><given-names>V.</given-names></name>
<name><surname>Brayton</surname><given-names>A.L.</given-names></name>
<name><surname>Kr&#x000f6;ger</surname><given-names>M.</given-names></name>
<name><surname>Rutledge</surname><given-names>G.C.</given-names></name>
</person-group><article-title>Atomistic Modeling of Plastic Deformation in Semicrystalline Polyethylene: Role of Interphase Topology, Entanglements, and Chain Dynamics</article-title><source>Macromolecules</source><year>2020</year><volume>53</volume><fpage>4605</fpage><lpage>4617</lpage><pub-id pub-id-type="doi">10.1021/acs.macromol.9b02308</pub-id></element-citation></ref><ref id="B30-polymers-17-00550"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Abdar</surname><given-names>M.</given-names></name>
<name><surname>Pourpanah</surname><given-names>F.</given-names></name>
<name><surname>Hussain</surname><given-names>S.</given-names></name>
<name><surname>Rezazadegan</surname><given-names>D.</given-names></name>
<name><surname>Liu</surname><given-names>L.</given-names></name>
<name><surname>Ghavamzadeh</surname><given-names>M.</given-names></name>
<name><surname>Fieguth</surname><given-names>P.</given-names></name>
<name><surname>Cao</surname><given-names>X.</given-names></name>
<name><surname>Khosravi</surname><given-names>A.</given-names></name>
<name><surname>Acharya</surname><given-names>U.R.</given-names></name>
<etal/>
</person-group><article-title>A review of uncertainty quantification in deep learning: Techniques, applications and challenges</article-title><source>Inf. Fusion</source><year>2021</year><volume>76</volume><fpage>243</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.1016/j.inffus.2021.05.008</pub-id></element-citation></ref><ref id="B31-polymers-17-00550"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Psaros</surname><given-names>A.F.</given-names></name>
<name><surname>Meng</surname><given-names>X.</given-names></name>
<name><surname>Zou</surname><given-names>Z.</given-names></name>
<name><surname>Guo</surname><given-names>L.</given-names></name>
<name><surname>Karniadakis</surname><given-names>G.E.</given-names></name>
</person-group><article-title>Uncertainty quantification in scientific machine learning: Methods, metrics, and comparisons</article-title><source>J. Comput. Phys.</source><year>2023</year><volume>477</volume><elocation-id>111902</elocation-id><pub-id pub-id-type="doi">10.1016/j.jcp.2022.111902</pub-id></element-citation></ref><ref id="B32-polymers-17-00550"><label>32.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kamalov</surname><given-names>F.</given-names></name>
<name><surname>Moussa</surname><given-names>S.</given-names></name>
<name><surname>Reyes</surname><given-names>J.A.</given-names></name>
</person-group><article-title>Data Transformation in Machine Learning: Empirical Analysis</article-title><source>Proceedings of the 2023 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)</source><conf-loc>Sakheer, Bahrain</conf-loc><conf-date>20&#x02013;21 November 2023</conf-date><fpage>115</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1109/3ICT60104.2023.10391512</pub-id></element-citation></ref><ref id="B33-polymers-17-00550"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Djordjevi&#x00107;</surname><given-names>L.</given-names></name>
<name><surname>Jordovi&#x00107;-Pavlovi&#x00107;</surname><given-names>M.I.</given-names></name>
<name><surname>&#x00106;ojba&#x00161;i&#x00107;</surname><given-names>&#x0017d;.M.</given-names></name>
<name><surname>Galovi&#x00107;</surname><given-names>S.P.</given-names></name>
<name><surname>Popovi&#x00107;</surname><given-names>M.N.</given-names></name>
<name><surname>Ne&#x00161;i&#x00107;</surname><given-names>M.V.</given-names></name>
<name><surname>Markushev</surname><given-names>D.D.</given-names></name>
</person-group><article-title>Influence of data scaling and normalization on overall neural network performances in photoacoustics</article-title><source>Opt. Quant. Electron.</source><year>2022</year><volume>54</volume><fpage>501</fpage><pub-id pub-id-type="doi">10.1007/s11082-022-03799-1</pub-id></element-citation></ref><ref id="B34-polymers-17-00550"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mehta</surname><given-names>P.</given-names></name>
<name><surname>Bukov</surname><given-names>M.</given-names></name>
<name><surname>Wang</surname><given-names>C.-H.</given-names></name>
<name><surname>Day</surname><given-names>A.G.R.</given-names></name>
<name><surname>Richardson</surname><given-names>C.</given-names></name>
<name><surname>Fisher</surname><given-names>C.K.</given-names></name>
<name><surname>Schwab</surname><given-names>D.J.</given-names></name>
</person-group><article-title>A high-bias, low-variance introduction to Machine Learning for physicists</article-title><source>Phys. Rep.</source><year>2019</year><volume>810</volume><fpage>1</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.physrep.2019.03.001</pub-id><pub-id pub-id-type="pmid">31404441</pub-id>
</element-citation></ref><ref id="B35-polymers-17-00550"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hirschfeld</surname><given-names>L.</given-names></name>
<name><surname>Swanson</surname><given-names>K.</given-names></name>
<name><surname>Yang</surname><given-names>K.</given-names></name>
<name><surname>Barzilay</surname><given-names>R.</given-names></name>
<name><surname>Coley</surname><given-names>C.W.</given-names></name>
</person-group><article-title>Uncertainty Quantification Using Neural Networks for Molecular Property Prediction</article-title><source>J. Chem. Inf. Model.</source><year>2020</year><volume>60</volume><fpage>3770</fpage><lpage>3780</lpage><pub-id pub-id-type="doi">10.1021/acs.jcim.0c00502</pub-id><pub-id pub-id-type="pmid">32702986</pub-id>
</element-citation></ref></ref-list></back><floats-group><fig position="float" id="polymers-17-00550-f001"><label>Figure 1</label><caption><p>Schematic of the stress&#x02013;strain curves illustrating the aleatoric uncertainty associated with polymer specimens prepared under identical injection molding conditions. The three-colored curves represent three separate specimens, highlighting the inherent variability in mechanical behavior, even when processed with the same parameters (i.e., mold temperature <italic toggle="yes">T</italic><sub>mold</sub>, packing pressure <italic toggle="yes">P</italic><sub>pack</sub>, injection pressure <italic toggle="yes">P</italic><sub>inject</sub>, and injection rate <italic toggle="yes">R</italic><sub>inject</sub>) due to the complex, black box nature of the polymer manufacturing process.</p></caption><graphic xlink:href="polymers-17-00550-g001" position="float"/></fig><fig position="float" id="polymers-17-00550-f002"><label>Figure 2</label><caption><p>Dataset visualization of the stress&#x02013;strain curves at different molding conditions. (<bold>a</bold>) Selected 27 molding conditions with the Taguchi method. Each condition has four tunable parameters, including mold temperature Tmold, packing pressure Ppack, injection pressure Pinject, and injection rate Rinject. (<bold>b</bold>) Stress&#x02013;strain curves of specimens prepared at Tmold = 80 &#x000b0;C, Ppack = 20 MPa, Pinject = 70 MPa, and Rinject = 24.858 cm<sup>3</sup>/s. (<bold>c</bold>) Stress&#x02013;strain curves of specimens prepared at Tmold = 20 &#x000b0;C, Ppack = 20 MPa, Pinject = 30 MPa, Rinject = 24.858 cm<sup>3</sup>/s; (<bold>d</bold>) Schematic illustrating three different stress&#x02013;strain curve types, including strain softening type, steady flow type, and strain hardening type. The points indicate key curve features, including linear limit point, maximum yielding point, strain softening inflection point, steady flow limit point, and fracture point. (<bold>e</bold>) Example of curve type distribution at one molding condition. (<bold>f</bold>) Violin plot of the distribution of standardized curve features at one molding condition.</p></caption><graphic xlink:href="polymers-17-00550-g002" position="float"/></fig><fig position="float" id="polymers-17-00550-f003"><label>Figure 3</label><caption><p>Schematic of the dual-distribution neural network (DNN). (<bold>a</bold>) DNN architecture built to predict the dual-distribution representation of curve variation, including (i) the categorical distribution of curve type and (ii) the approxi-normal distribution of each curve feature, provided by a curve type classifier and a curve feature predictor, respectively. (<bold>b</bold>) Schematic of the curve feature predictor, which outputs each feature&#x02019;s aleatoric uncertainty as a normal distribution represented by its mean <italic toggle="yes">&#x003bc;</italic> and standard deviation <italic toggle="yes">&#x003b4;</italic>. (<bold>c</bold>) Schematic of the reconstructed stress&#x02013;strain curve and its aleatoric uncertainty based on the predicted curve type and feature distribution.</p></caption><graphic xlink:href="polymers-17-00550-g003" position="float"/></fig><fig position="float" id="polymers-17-00550-f004"><label>Figure 4</label><caption><p>Prediction accuracy of the curve type classifier. (<bold>a</bold>) Confusion matrix of the training set. The dataset contains 27 molding conditions, wherein 25 conditions are selected as the training set, while the remaining 2 conditions serve as the test set. (<bold>b</bold>) Stress&#x02013;strain curves in one test condition. (<bold>c</bold>) Predicted versus true categorical distribution of curve type in the test condition.</p></caption><graphic xlink:href="polymers-17-00550-g004" position="float"/></fig><fig position="float" id="polymers-17-00550-f005"><label>Figure 5</label><caption><p>Prediction accuracy of the curve feature predictor. (<bold>a</bold>) Predicted versus true mean values for each curve feature, wherein the horizontal and vertical error bars represent the standard deviation of true versus predicted data, respectively. (<bold>b</bold>) Average calibration plot of observed versus predicted proportion in &#x003b1;-prediction interval for each curve feature, wherein &#x003b1; ranges from 0% to 100% to indicate the data proportion falling within the &#x003b1;-prediction interval.</p></caption><graphic xlink:href="polymers-17-00550-g005" position="float"/></fig><fig position="float" id="polymers-17-00550-f006"><label>Figure 6</label><caption><p>Stress&#x02013;strain curve prediction using the DNN model. (<bold>a</bold>&#x02013;<bold>c</bold>) Schematic illustrating the rules to reconstruct the expected stress&#x02013;strain curve and its aleatoric uncertainty based on the dual distribution of curve types and features (see text for the details). (<bold>d</bold>&#x02013;<bold>f</bold>) Examples of stress&#x02013;strain curve prediction at different molding conditions, including (<bold>d</bold>) Tmold = 80 &#x000b0;C, Ppack = 80 MPa, Pinject = 30 MPa, and Rinject = 58.002 cm<sup>3</sup>/s; (<bold>e</bold>) Tmold = 50 &#x000b0;C, Ppack = 50 MPa, Pinject = 50 MPa, and Rinject = 58.002 cm<sup>3</sup>/s; and (<bold>f</bold>) Tmold = 20 &#x000b0;C, Ppack = 80 MPa, Pinject = 30 MPa, and Rinject = 41.43 cm<sup>3</sup>/s, wherein the shadow region represents the curve&#x02019;s aleatoric uncertainty. Experimental data are also added as a reference. (<bold>g</bold>&#x02013;<bold>i</bold>) Predicted curve type distributions at these molding conditions.</p></caption><graphic xlink:href="polymers-17-00550-g006" position="float"/></fig><fig position="float" id="polymers-17-00550-f007"><label>Figure 7</label><caption><p>Schematic illustration of epistemic uncertainty induced by model deviation. The total uncertainty consists of aleatoric uncertainty (data deviation) and epistemic uncertainty (model deviation).</p></caption><graphic xlink:href="polymers-17-00550-g007" position="float"/></fig><fig position="float" id="polymers-17-00550-f008"><label>Figure 8</label><caption><p>Uncertainty quantification by dual-distribution Bayesian network (DBN). (<bold>a</bold>) Schematic illustrating the working principle of a curve-type classifier using a Bayesian neural network (BNN), wherein the weights and biases in BNN neurons are sampled from their independent Gaussian distributions so that the BNN-based classifier is equivalent to multiple classifiers based on artificial neural networks (ANNs) under different settings of weights and biases. By statistical averaging, the mean <italic toggle="yes">&#x003bc;</italic> and standard deviation <italic toggle="yes">&#x003b4;</italic> of curve type probability are obtained. (<bold>b</bold>) BNN-based curve feature regressor, wherein the multiple mean <italic toggle="yes">&#x003bc;</italic> and standard deviation <italic toggle="yes">&#x003b4;</italic> of curve feature distribution are statistically averaged to obtain the expected mean <inline-formula><mml:math id="mm80" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> and aleatoric uncertainty <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, and meanwhile, the standard deviation of <italic toggle="yes">&#x003bc;</italic> and <italic toggle="yes">&#x003b4;</italic> are computed as the epistemic uncertainty <inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></caption><graphic xlink:href="polymers-17-00550-g008" position="float"/></fig><fig position="float" id="polymers-17-00550-f009"><label>Figure 9</label><caption><p>Prediction accuracy of the BNN-based curve type classifier. (<bold>a</bold>) Confusion matrix of the training set. The BNN-based classifier uses the same training scheme as the DNN model (see <xref rid="polymers-17-00550-f004" ref-type="fig">Figure 4</xref>). (<bold>b</bold>) Stress&#x02013;strain curves in one test condition. (<bold>c</bold>) Predicted versus true categorical distribution of curve type in the test condition. The classifier predicts a mean probability with an error bar provided for each curve feature.</p></caption><graphic xlink:href="polymers-17-00550-g009" position="float"/></fig><fig position="float" id="polymers-17-00550-f010"><label>Figure 10</label><caption><p>Prediction accuracy of the BNN-based curve feature predictor. (<bold>a</bold>) Predicted versus true mean values for each curve feature, wherein the horizontal and vertical error bars represent the variance of true versus predicted data, respectively. The predicted variance is the upper-bound variance computed by Equation (8). (<bold>b</bold>) Average calibration plot of observed versus predicted proportion in <italic toggle="yes">&#x003b1;</italic>-prediction interval for each curve feature, wherein <italic toggle="yes">&#x003b1;</italic> ranges from 0% to 100% to indicate the data proportion falling within the <italic toggle="yes">&#x003b1;</italic>-prediction interval.</p></caption><graphic xlink:href="polymers-17-00550-g010" position="float"/></fig><fig position="float" id="polymers-17-00550-f011"><label>Figure 11</label><caption><p>Reconstruction of the stress&#x02013;strain curve and its uncertainty using the DBN model. (<bold>a</bold>) Schematic illustrating the rules to reconstruct the expected stress&#x02013;strain curve and its aleatoric and epistemic uncertainty based on the mean and variance of multiple dual-distribution outputs (see text for the details). (<bold>b</bold>&#x02013;<bold>d</bold>) Examples of the reconstructed stress&#x02013;strain curve and its aleatoric and epistemic uncertainty at different molding conditions, including (<bold>d</bold>) Tmold = 80 &#x000b0;C, Ppack = 80 MPa, Pinject = 30 MPa, and Rinject = 58.002 cm<sup>3</sup>/s; (<bold>e</bold>) Tmold = 50 &#x000b0;C, Ppack = 50 MPa, Pinject = 50 MPa, and Rinject = 58.002 cm<sup>3</sup>/s; and (<bold>f</bold>) Tmold = 20 &#x000b0;C, Ppack = 80 MPa, Pinject = 30 MPa, and Rinject = 41.43 cm<sup>3</sup>/s, wherein the shadow regions represent the epistemic uncertainty. Experimental data are also added as a reference. (<bold>e</bold>&#x02013;<bold>g</bold>) Predicted curve type distributions at these molding conditions.</p></caption><graphic xlink:href="polymers-17-00550-g011" position="float"/></fig><fig position="float" id="polymers-17-00550-f012"><label>Figure 12</label><caption><p>Maximum uncertainty quantification of stress&#x02013;strain curve prediction using the DBN model. (<bold>a</bold>) Schematic illustrating the maximum uncertainty bounds (middle panel) attained by summing up all uncertainty sources (left panel), that is, a variance of <inline-formula><mml:math id="mm81" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mo stretchy="false">&#x000af;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (see Equation (8)) for a normal distribution at a 95% confidence interval. The predicted curve type distribution is provided in the right panel. (<bold>b</bold>&#x02013;<bold>d</bold>) Examples of maximum uncertainty quantification at different molding conditions, including (<bold>b</bold>) <italic toggle="yes">T</italic><sub>mold</sub> = 80 &#x000b0;C, <italic toggle="yes">P</italic><sub>pack</sub> = 20 MPa, <italic toggle="yes">P</italic><sub>inject</sub> = 50 MPa, and <italic toggle="yes">R</italic><sub>inject</sub> = 58.002 cm<sup>3</sup>/s and (<bold>c</bold>) <italic toggle="yes">T</italic><sub>mold</sub> = 50 &#x000b0;C, <italic toggle="yes">P</italic><sub>pack</sub> = 20 MPa, <italic toggle="yes">P</italic><sub>inject</sub> = 70 MPa, and <italic toggle="yes">R</italic><sub>inject</sub> = 41.43 cm<sup>3</sup>/s and (<bold>d</bold>) <italic toggle="yes">T</italic><sub>mold</sub> = 20 &#x000b0;C, <italic toggle="yes">P</italic><sub>pack</sub> = 50 MPa, <italic toggle="yes">P</italic><sub>inject</sub> = 70 MPa, and <italic toggle="yes">R</italic><sub>inject</sub> = 41.43 cm<sup>3</sup>/s.</p></caption><graphic xlink:href="polymers-17-00550-g012" position="float"/></fig></floats-group></article>