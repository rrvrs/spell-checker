<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title-group><journal-title>bioRxiv</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39868321</article-id><article-id pub-id-type="pmc">PMC11761634</article-id>
<article-id pub-id-type="doi">10.1101/2025.01.09.632260</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">2</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Assessing Generative Model Coverage of Protein Structures with SHAPES</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3365-1542</contrib-id><name><surname>Lu</surname><given-names>Tianyu</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="data collection" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-collection/">data collection</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="manuscript writing" vocab-term-identifier="https://credit.niso.org/contributor-roles/manuscript-writing/">manuscript writing</role><xref rid="A1" ref-type="aff">1</xref><xref rid="A3" ref-type="aff">3</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Melissa</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="data collection" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-collection/">data collection</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="manuscript writing" vocab-term-identifier="https://credit.niso.org/contributor-roles/manuscript-writing/">manuscript writing</role><xref rid="A1" ref-type="aff">1</xref><xref rid="A3" ref-type="aff">3</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Yilin</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">methodology</role><xref rid="A1" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Kim</surname><given-names>Jinho</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><xref rid="A2" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-7948-2895</contrib-id><name><surname>Huang</surname><given-names>Po-Ssu</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="manuscript writing" vocab-term-identifier="https://credit.niso.org/contributor-roles/manuscript-writing/">manuscript writing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="supervised research" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervised-research/">supervised research</role><xref rid="A1" ref-type="aff">1</xref><xref rid="CR1" ref-type="corresp">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Department of Bioengineering, Stanford University, Stanford, CA, USA</aff><aff id="A2"><label>2</label>Department of Physics, Stanford University, Stanford, CA, USA</aff><aff id="A3"><label>3</label>Equal contribution</aff><author-notes><corresp id="CR1"><label>*</label>Correspondence: <email>possu@stanford.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>17</day><month>1</month><year>2025</year></pub-date><elocation-id>2025.01.09.632260</elocation-id><permissions><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</ext-link>, which allows reusers to distribute, remix, adapt, and build upon the material in any medium or format, so long as attribution is given to the creator. The license allows for commercial use.</license-p></license></permissions><self-uri content-type="pdf">nihpp-2025.01.09.632260.pdf</self-uri><abstract id="ABS1"><title>SUMMARY</title><p id="P1">Recent advances in generative modeling enable efficient sampling of protein structures, but their tendency to optimize for designability imposes a bias toward idealized structures at the expense of loops and other complex structural motifs critical for function. We introduce SHAPES (Structural and Hierarchical Assessment of Proteins with Embedding Similarity) to evaluate five state-of-the-art generative models of protein structures. Using structural embeddings across multiple structural hierarchies, ranging from local geometries to global protein architectures, we reveal substantial undersampling of the observed protein structure space by these models. We use Fr&#x000e9;chet Protein Distance (FPD) to quantify distributional coverage. Different models are distinct in their coverage behavior across different sampling noise scales and temperatures; the frequency of TERtiary Motifs (TERMs) further supports the observations. More robust sequence design and structure prediction methods are likely crucial in guiding the development of models with improved coverage of the designable protein space.</p></abstract></article-meta></front><body><sec id="S1"><title>INTRODUCTION</title><p id="P2">Navigating the design space of protein structures has traditionally relied on domain expertise guided by energy functions<sup><xref rid="R1" ref-type="bibr">1</xref></sup>. With the introduction of generative models, structure-based design and hypothesis generation has become more robust. Instead of relying on energy functions, the protein structure space parameterized under a generative model facilitates sample generation and selection according to designability metrics<sup><xref rid="R2" ref-type="bibr">2</xref></sup>. While generative models are capable of efficiently sampling from protein structure space, evaluation of their capacity to generate all observed structural features in proteins remains understudied and unquantified.</p><p id="P3">Generative models aim to capture a complex data distribution by applying a learned transformation which turns noise into realistic samples (<xref rid="F1" ref-type="fig">Figure 1A</xref>)<sup><xref rid="R3" ref-type="bibr">3</xref></sup>. An application of generative modeling is the ability to sample novel, diverse and realistic protein structures. The quality of a sampled backbone is typically evaluated with designability, measured <italic toggle="yes">in silico</italic> by computing the Root Mean Square Deviation (RMSD) of the predicted structures from the sequences designed for it with the original backbone. In our analysis, we designed eight sequences with ProteinMPNN<sup><xref rid="R4" ref-type="bibr">4</xref></sup> and predicted their structures with ESMFold<sup><xref rid="R5" ref-type="bibr">5</xref></sup>. A protein backbone is said to be designable if at least one predicted structure has RMSD &#x0003c; 2.0 &#x000c5;ngstroms to the designed backbone. Many experimental successes have been reported, making designability a robust metric to filter designs<sup><xref rid="R6" ref-type="bibr">6</xref>&#x02013;<xref rid="R8" ref-type="bibr">8</xref></sup>. However, sampled structures are often idealized, containing higher proportions of alpha helices and beta sheets than native structures deposited in the Protein Data Bank (PDB) (<xref rid="F1" ref-type="fig">Figure 1B</xref>)<sup><xref rid="R9" ref-type="bibr">9</xref></sup>. This biased sampling of secondary structures motivates the following questions: 1. What regions of protein structure space are not being covered by generative models optimized for designability? 2. How can we quantify and interpret the distributional coverage of protein structure space? 3. What limitations does biased sampling place on the ability to design functional structural elements?</p><p id="P4">To answer these questions, we present the SHAPES framework to analyze the behavior of generative models of protein structures. We quantify distributional similarity with Fr&#x000e9;chet Protein Distance (FPD), analogous to the Fr&#x000e9;chet ProtT5 Distance introduced by Alamdari <italic toggle="yes">et al.</italic><sup><xref rid="R10" ref-type="bibr">10</xref></sup> but using embeddings of protein structures instead of embeddings of protein sequences. The SHAPES evaluation framework consists of sampling a set of structures from a generative model, computing embeddings and the FPD of the embeddings with a reference dataset to quantify distribution similarity. We examine five different models: Chroma<sup><xref rid="R11" ref-type="bibr">11</xref></sup>, Genie2<sup><xref rid="R12" ref-type="bibr">12</xref></sup>, Protpardelle<sup><xref rid="R13" ref-type="bibr">13</xref></sup>, RFdiffusion<sup><xref rid="R6" ref-type="bibr">6</xref></sup>, and Multiflow<sup><xref rid="R14" ref-type="bibr">14</xref></sup>. They are all based on diffusion or flow-matching models, but each is trained with different structural representations and have different sampling schemes. RFdiffusion relies on a pretrained structure prediction model (RoseTTAFold) while other models are trained from scratch. Each residue is represented by a frame (rotation and translation), where both are denoised during sampling. Multiflow also uses residue frames but introduces a discrete flow-matching objective for sequence prediction trained jointly with the structure flow-matching objective. Chroma introduces correlated noise that models the polymer chain structure and the scaling of the radius of gyration of proteins. Genie2 uses Frenet-Serret frames during denoising formed by triplets of adjacent alpha-carbon atoms. Protpardelle treats each residue as atomic coordinates instead of frames and is not equivariant to rotations, unlike the network architectures in other models. These differences result in different parameterizations of the distribution of protein structures.</p><p id="P5">We show that many models do not cover the full diversity of structural elements at all structural hierarchies, from nearest neighbor geometries, to local amino acid environment shells, to global protein architectures. While coverage improves with higher temperatures and noise scales during sampling, such samples also reveal unique pathologies of generated structures which make them less designable than low-temperature samples. Finally, we use TERtiary Motifs (TERMs)<sup><xref rid="R15" ref-type="bibr">15</xref></sup> to validate the FPD trends and show that complex functional motifs involving loops are more likely to be found in samples drawn from models with greater coverage of the PDB.</p></sec><sec id="S2"><title>RESULTS</title><sec id="S3"><title>Optimizing Designability Leads to Complexity Reduction</title><p id="P6">Designability aims to answer the question of whether or not there exists a sequence which can fold into a given backbone. By definition, this criterion is satisfied for all accurately modeled structures deposited in the PDB. However, we find that 43.7% of structures in CATH<sup><xref rid="R16" ref-type="bibr">16</xref></sup> are not designable, even when using the <italic toggle="yes">native</italic> sequence, in agreement with recent works which show similar results<sup><xref rid="R14" ref-type="bibr">14</xref>,<xref rid="R17" ref-type="bibr">17</xref></sup>. Using designability as a metric to guide the development of generative models and for ranking designs inevitably steers sampling towards the <italic toggle="yes">designable</italic> subset of protein structures and does not measure the ability to model the full set of observed protein structures.</p><p id="P7">For generative models optimized to maximize designability, what structural features do they introduce? To understand this, we partially add noise to 21,663 structures generated with Protpardelle at high temperature, which are on average less designable than low temperature samples, then denoise the structures with RFdiffusion which produces more designable structures on average. Indeed, designability improves across all lengths (<xref rid="F2" ref-type="fig">Figure 2B</xref>), but is coupled with a reduction in loop content and an increase in alpha and beta secondary structures (<xref rid="F2" ref-type="fig">Figure 2A</xref>). Notably, the RFdiffusion-induced vector field which transports secondary structure density from the Protpardelle to the Partial Diffusion distributions consistently shows movement towards higher secondary structure content, except near the diagonal boundary where beta content is replaced with alpha content. We show an example in which the front-facing loop is remodeled into two helices with a minimal turn (<xref rid="F2" ref-type="fig">Figure 2C</xref>). We posit that the gain in designability is partly attributed to complexity reduction, in particular the erasure of loops which are difficult to design and predict. This behavior is valuable in design tasks which require engineering structural rigidity but could be a limitation in design tasks which require structural flexibility, such as engineering for allostery<sup><xref rid="R18" ref-type="bibr">18</xref></sup>.</p></sec><sec id="S4"><title>SHAPES Reveal Undersampled Regions of Protein Structure Space</title><p id="P8">The increase in secondary structure content does not fully elucidate the differences between designable and undesignable regions of protein structure space, as both designable and undesignable CATH structures have similar secondary structure distributions (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 1</xref>). To capture more fine-grained features of protein geometry, we use learned representations of protein structures at all structural hierarchies. Local amino acid nearest neighbor geometries are represented by Foldseek tokens, local amino acid environments including second shell contacts and beyond are represented by ProteinMPNN and ESM3 embeddings, and the geometry of protein architectures are represented by ProtDomainSegmentor embeddings (<xref rid="F3" ref-type="fig">Figure 3A</xref>). Foldseek tokens are learned through an autoencoding objective of nearest neighbor geometric features<sup><xref rid="R19" ref-type="bibr">19</xref></sup>. They represent a discrete structural alphabet used for accurate and rapid retrieval in large structural datasets. ProteinMPNN encoder embeddings are used by its decoder to predict amino acid identity, thus the embedding is rich in information on the structural context which surrounds all residue types<sup><xref rid="R4" ref-type="bibr">4</xref></sup>. ESM3 encoder embeddings are used by its decoder to predict masked coordinates rather than masked residue type, but again it necessitates the representation of diverse structural context<sup><xref rid="R20" ref-type="bibr">20</xref></sup>. ProtDomainSegmentor embeddings are used to predict the CATH architecture for each residue<sup><xref rid="R21" ref-type="bibr">21</xref></sup>. Indeed, principal components of such embeddings exhibit more separation between designable and undesignable structures (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 1</xref>).</p><p id="P9">To better understand the distributional coverage behavior of generative models of protein structure, in particular the subspaces which samples tend to over-sample and under-sample, we drew 64,989 structures each from Chroma<sup><xref rid="R11" ref-type="bibr">11</xref></sup>, Genie2<sup><xref rid="R12" ref-type="bibr">12</xref></sup>, Protpardelle<sup><xref rid="R13" ref-type="bibr">13</xref></sup>, RFdiffusion<sup><xref rid="R6" ref-type="bibr">6</xref></sup>, and 21,663 from Multiflow<sup><xref rid="R14" ref-type="bibr">14</xref></sup>, matching the length distribution in Ingraham <italic toggle="yes">et al.</italic>&#x02019;s CATH dataset<sup><xref rid="R16" ref-type="bibr">16</xref>,<xref rid="R22" ref-type="bibr">22</xref></sup>. We compared samples to ground truth structures from the CATH dataset as it represents a broad, expert-curated distribution of all known protein domains. We computed structure embeddings and visualized the first two principal components. The reference dataset is further filtered by resolution &#x0003c; 3.0 &#x000c5;, R<sub>free</sub> &#x0003c; 0.25 and no NMR structures.</p><p id="P10">Using ESM3 mean-pooled encoder embeddings, the first two principal components show a distinct streak in sampled structures not present in native CATH structures, indicating novel structural elements, along with a region present in CATH but not present in sampled structures (<xref rid="F3" ref-type="fig">Figure 3B</xref>). The equivalent plots for ProteinMPNN and ProtDomainSegmentor embeddings are given in <xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 2</xref>. We rendered the structures in <xref rid="F3" ref-type="fig">Figure 3C</xref> and show that the streak is formed by idealized alpha helical structures and the undersampled region, mostly alpha-beta mixtures, is enriched in enzyme domains.</p><p id="P11">We show rasterized plots for all five models stratified by designable and undesignable along with the underlying CATH distribution for ESM3 and ProtDomainSegmentor embeddings in <xref rid="SD1" ref-type="supplementary-material">Supplementary Figures S14</xref> to <xref rid="SD1" ref-type="supplementary-material">S71</xref>. We omit ProteinMPNN raster plots for sampled structures as the sampled distribution is too narrow for structure visualization to be insightful. The designable structures are typically more concentrated and less diverse than the undesignable structures. In addition to undersampling of undesignable CATH structure space, there exist large regions of <italic toggle="yes">designable</italic> CATH structure space more enriched in beta sheets and loops such as immunoglobulins that are undersampled by all models. This pattern is consistent across models and structure embeddings. Pathologies in undesignable samples are also revealed: flexible tails with a rigid core, lever-arm effects where a flexible linker can cause large RMSD in the rigid bodies it links, poor packing, unpaired or poorly paired beta strands, an isolated beta sheet, little to no secondary structure, and chain breaks. However, not all undesignable structures exhibit visually notable pathologies and it is plausible that such undesignable samples can become designable with improved sequence design models.</p></sec><sec id="S5"><title>Fr&#x000e9;chet Protein Distance (FPD) reveal undersampling of fold distributions</title><p id="P12">To quantitatively compare the distributional coverage of different models, we compute the Fr&#x000e9;chet distance, where lower values indicate greater distribution similarity (<xref rid="S10" ref-type="sec">Methods</xref>, <xref rid="F4" ref-type="fig">Figure 4</xref>, <xref rid="SD1" ref-type="supplementary-material">Supplementary Figures 3</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">4</xref>). As observed in Genie2,<sup><xref rid="R12" ref-type="bibr">12</xref></sup>, increasing the noise injected during sampling broadens the secondary structure distribution coverage. To quantify the effect of sampling temperature, we also sample at medium and high temperature settings from each diffusion-based model 21,336 structures each, except Multiflow as an analogous parameter is not exposed to the user, (<xref rid="F4" ref-type="fig">Figure 4</xref>, <xref rid="SD1" ref-type="supplementary-material">Supplementary Figures 3</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">4</xref>) and compute the FPD of each setting. The exact values of the high temperature parameter differs between models and were chosen based on the highest temperature which still can generate plausible samples by visual inspection. For Chroma, inverse temperature 3 coincides with the point beyond which the evidence lower bound starts to drop sharply (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 2</xref> in Chroma<sup><xref rid="R11" ref-type="bibr">11</xref></sup>). We also report the FPD computed using designable samples (FPD-D) and undesignable samples (FPD-ND). As sampling temperature increases, the sampled structures generally become more diverse as expected. Relating the effect of sampling temperature back to designability, we observe a consistent trend of fewer designable samples at higher sampling temperatures (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 5</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">6</xref>). However, this designability-diversity trade-off is distinct from a designability-coverage trade-off: the trend in the FPD gap, defined as the difference between FPD-D and FPD-ND, is distinct between models. In Chroma, while the overall increase in diversity gives better distributional coverage, the distribution coverage of designable samples at higher temperature becomes worse. In RFdiffusion, while diversity visibly increases, we observe a mode shift which leads to worse coverage. In Genie2 and Protpardelle, coverage improves for both designable and undesignable samples. Based on the distinction between diversity vs. distribution coverage, we recommend reporting both FPD-D and FPD-ND to quantify how much of the increase in diversity is due to venturing into non-natural structure space or due to better coverage of the training data distribution, along with reporting designability-coverage trade-offs (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 7</xref>).</p><p id="P13">While CATH provides an expert-curated distribution of diverse protein domains, solely using CATH as ground truth may be misleading as different models have different training data distributions. We compute the same FPD metrics using another reference distribution, the PDB as clustered in AlphaFold3 (AF3-PDB) (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figures 8</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">10</xref>)<sup><xref rid="R25" ref-type="bibr">25</xref></sup>. We observe the same trends in FPD and the FPD gap across different embedding types and sampling temperatures, indicating that the biased coverage is not due to differences in CATH data leakage into the training set between models or artifacts in CATH domain parsing but rather a general behavior.</p></sec><sec id="S6"><title>FPD Trends Agree with Frequency Differences in Residue Nearest Neighbor Geometry</title><p id="P14">While ProteinMPNN and ESM3 capture local residue environments, strictly local geometric features may be over-smoothed given the large number of neighbors ProteinMPNN (48) and ESM3 (16) uses as context. A structure representation which uses geometric features derived from only a single nearest neighbor is Foldseek. As they are discrete, they cannot be mean-pooled. Instead, we compute similarity to a reference distribution of structures by counting the frequencies of Foldseek tokens per length range, representing the nearest-neighbor geometries commonly observed in each bin. Foldseek tokens are grouped per-token (unigram) and per pair of adjacent tokens (bigram). The KL divergence between unigram and bigram Foldseek token frequencies of CATH or AF3-PDB structures with sampled structures agree with trends in FPD using continuous embeddings, where higher sampling temperatures and noise scales give lower KL divergences. Stratifying by length ranges, we also reveal a length-dependent bias in coverage of native local structural elements (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 11</xref>). Chroma, Protpardelle, and especially Multiflow (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 12</xref>) have greater mismatch for longer protein lengths while Genie2 coverage is more even throughout. In particular, there is a large distribution mismatch for protein lengths below 100 amino acids in RFdiffusion samples. The coverage is not uniform across length ranges, as RFdiffusion matches the native CATH distribution more closely for proteins longer than 150 amino acids. Interestingly for RFdiffusion, increased noise scale improves coverage for proteins shorter than 150 amino acids but worsens coverage for longer proteins, in agreement with the higher FPD at higher noise scales. For all other models, the effect of sampling temperature is consistent, with higher temperature giving better coverage. The agreement with FPD trends using ProteinMPNN and ESM3 embeddings confirms that the conclusions drawn for continuous embeddings are not due to embedding artifacts but are general across embedding types. The same trends are also observed with both CATH and AF3-PDB as the reference distribution.</p></sec><sec id="S7"><title>Functional Tertiary Structural Alphabets are Underrepresented</title><p id="P15">The incomplete coverage protein structure space indicates that there exist tertiary structural elements present in native structures but are absent in the samples. To evaluate this, we queried sampled structure sets with recurring metal-binding TERtiary Motifs (TERMs)<sup><xref rid="R15" ref-type="bibr">15</xref></sup> (<xref rid="F5" ref-type="fig">Figure 5</xref>). We elect to use TERMs because they form a tertiary structural alphabet derived from a set cover of the PDB such that each TERM is a structural building block and has realizations in native structures. The rank order of TERMs is based on the amount of structural novelty each TERM introduces which we can use to gain intuition on a generative model&#x02019;s ability to sample frequent vs. rare TERMs. The motifs range from short loops to double and triple loop contacts and fragments of secondary structure elements. Notably, TERMs are more interpretable than the embeddings used to compute FPD. We used MASTER<sup><xref rid="R26" ref-type="bibr">26</xref></sup> to rapidly search structure sets, with a dynamic RMSD threshold as defined in Mackenzie <italic toggle="yes">et al.</italic><sup><xref rid="R15" ref-type="bibr">15</xref></sup> for a match to count.</p><p id="P16">Some TERMs, such as Calcium 034754, Calcium 008622, and Calcium 130482, are prevalent across different model samples. In contrast, some TERMs, such as Magnesium 001807, Copper 005382, Copper 294816, and Sodium 002955, are entirely absent from almost all model samples except Protpardelle. In general, Protpardelle is able to cover all TERMs, in agreement with achieving the lowest FPD of the models benchmarked. For most TERMs, the number of matches in the 21,336 CATH structures is greater than the number of matches found in the 21,336 sampled structures per model setting, indicating widespread undersampling, except for Copper 034863 which is much more oversampled by Chroma and RFdiffusion.</p></sec></sec><sec id="S8"><title>DISCUSSION</title><p id="P17">To address the three questions motivating this study, using SHAPES we show that structures containing loops and loops mixed with alpha-beta structures, in which enzymes are prevalent, are not covered by most generative models. The degree to which each model covers protein structure space is quantified using FPD for comparison between different models. Specifically, RFdiffusion is optimized for highly designable samples with high secondary structure content, Genie2 generalizes to novel protein architectures while retaining consistent local geometric features with high noise scales, and Protpardelle can sample diverse loops. Distribution spread can be improved across all models by increasing sampling temperature and noise scale at the expense of designability and sometimes the coverage of the native distribution. This biased sampling imposes a limitation on the ability to sample functional structural elements.</p><p id="P18">The ability to draw unbiased samples from the protein fold space is crucial to solving motif scaffolding problems. Conditional generation is the process of drawing samples from P(scaffold | motif) = P(scaffold, motif) / P(motif) which may be computationally intractable when the likelihood of generating the motif in any scaffold is near zero. We posit that the unpredictable performance of models in motif-scaffolding benchmarks, which vary from motif to motif<sup><xref rid="R6" ref-type="bibr">6</xref>,<xref rid="R20" ref-type="bibr">20</xref></sup>, can in part be attributed to the frequency each motif is found in unconditional samples. When unconditional samples do not cover scaffolds which host motifs, especially those which exist in the PDB, conditional sampling could force the sampling trajectory out-of-distribution and generate unrealistic samples. While generating idealized <italic toggle="yes">de novo</italic> proteins is highly impactful, as demonstrated by the design of picomolar binders and highly active enzymes<sup><xref rid="R7" ref-type="bibr">7</xref>,<xref rid="R8" ref-type="bibr">8</xref>,<xref rid="R27" ref-type="bibr">27</xref></sup>, designing subtle but functional mechanisms inherent to natural protein structures can be challenging when sampling from nonnatural or biased distributions of structures. For example, designing an enzyme that is amenable to optimization by directed evolution may be more facile with scaffolds sampled from a native structure distribution than with highly idealized scaffolds, since naturally abundant structures are products of evolution.</p><p id="P19">SHAPES offers unique advantages over using pairwise TM score or the number of clusters as diversity metrics. Mean pairwise TM score below 0.6 can be obtained trivially by mode collapse on two dissimilar folds. The number of clusters can be arbitrarily increased by generating a single alpha helix with increasing lengths. In both cases, SHAPES features are able to detect inadequate distribution coverage. Importantly, SHAPES highlights undersampled regions in which their precise identification is critical if the goal is to train a generative model which covers the full conformational diversity, thus also capturing the full functional diversity, that exists in a target data distribution. Nonetheless, current metrics of designability, diversity, and novelty are still useful as they all offer different perspectives on the performance of generative models of protein structures. The usefulness of a generative model for a protein designer depends on the objective, whether representation learning is used to predict function<sup><xref rid="R28" ref-type="bibr">28</xref>,<xref rid="R29" ref-type="bibr">29</xref></sup>, generating diversity within a single fold<sup><xref rid="R30" ref-type="bibr">30</xref></sup>, or extrapolating beyond natural protein structures and thereby removing the structural vestiges of evolution that hamper recombinant expression and yield. FPD is dependent on the choice of reference structures, so use cases in which the goal is to inherently sample from a custom set of structures, such as nanobody design, can be easily handled.</p><p id="P20">Designability currently guides samples towards a non-natural structure distribution. As natural structures incorporate flexible elements such as loops to achieve function, we anticipate that increased robustness in sequence design and structure prediction models will expand the space of designable protein functions such that designability can guide samples towards any desired region of protein structures while not sacrificing its predictive power on the likelihood of experimental success. As the known protein structure universe continues to expand<sup><xref rid="R31" ref-type="bibr">31</xref></sup> and protein design goals become more multi-objective and ambitious, we hope that SHAPES can guide the development of the next generation of generative models of protein structures.</p><sec id="S9"><title>LIMITATIONS</title><p id="P21">For consistency, we elect to use the standard sequence design method in the field, ProteinMPNN<sup><xref rid="R4" ref-type="bibr">4</xref></sup>. Use of other sequence design methods may give different designability results, in particular using the built-in sequence design models in Chroma and Multiflow. Also for consistency, we elect to use ESMFold for structure prediction instead of AlphaFold2 despite its limitations<sup><xref rid="R32" ref-type="bibr">32</xref></sup>. We reasoned that given the very low designability of AlphaFold2 in single sequence mode (1.34% on CATH with native sequences)<sup><xref rid="R17" ref-type="bibr">17</xref></sup> and the absence of multiple sequence alignments to run AlphaFold2 in MSA-mode for ProteinMPNN-designed sequences, a fast and relatively robust single-sequence model such as ESMFold is most appropriate. Different structure-prediction models would also give different designability results. Results for the coverage behavior of conditional sampling may be different than the unconditional setting analyzed here due to different forms of guidance used during sampling and cases in which an unconditional model is fine-tuned to obtain a conditional model. We leave analysis of conditional samples to future work.</p><p id="P22">While SHAPES does not rely on the sequence design capability of ProteinMPNN, it nonetheless relies on representations learned from models trained for unrelated tasks. An alternative is to use embeddings directly extracted from a diffusion model<sup><xref rid="R3" ref-type="bibr">3</xref>,<xref rid="R33" ref-type="bibr">33</xref></sup>. Other embeddings can be used, as long as they can capture features which can discern samples apart, such as using LigandMPNN<sup><xref rid="R34" ref-type="bibr">34</xref></sup> embeddings to evaluate generative models of all-atom protein structures.</p></sec></sec><sec id="S10"><title>METHODS</title><sec id="S11"><title>SHAPES</title><p id="P23">Using SHAPES consists of the following steps:</p><list list-type="order" id="L1"><list-item><p id="P24">Choose a target training data distribution. Here we choose CATH<sup><xref rid="R16" ref-type="bibr">16</xref></sup> and AF3-PDB<sup><xref rid="R9" ref-type="bibr">9</xref></sup>.</p></list-item><list-item><p id="P25">Sample structures at varying lengths from a generative model. Here we match the length distribution of the reference dataset.</p></list-item><list-item><p id="P26">Compute structure embeddings: Foldseek, ProteinMPNN, ESM3, and ProtDomainSegmentor</p></list-item><list-item><p id="P27">Compute Fr&#x000e9;chet Protein Distance (FPD) for each continuous embedding and KL-divergence for Foldseek tokens.</p></list-item><list-item><p id="P28">Visualization of distribution coverage.</p></list-item></list></sec><sec id="S12"><title>Fr&#x000e9;chet Protein Distance (FPD)</title><p id="P29">Given <inline-formula><mml:math id="M1" display="inline"><mml:mi>N</mml:mi></mml:math></inline-formula> data points from a ground truth distribution <inline-formula><mml:math id="M2" display="inline"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M3" display="inline"><mml:mi>M</mml:mi></mml:math></inline-formula> samples from a model <inline-formula><mml:math id="M4" display="inline"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mtext>x</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we compute embeddings <inline-formula><mml:math id="M5" display="inline"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M6" display="inline"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. The distributional similarity of sampled structures to reference structures can be quantified by computing the Fr&#x000e9;chet Protein Distance (FPD) given by <xref rid="FD1" ref-type="disp-formula">Equation 1</xref>.
<disp-formula id="FD1"><label>(1)</label>
<mml:math id="M7" display="block"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>&#x02016;</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">&#x003bc;</mml:mi><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">&#x003bc;</mml:mi><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x02016;</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mtext>Tr</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M8" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">&#x003bc;</mml:mi><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M9" display="inline"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">&#x003bc;</mml:mi><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the mean vectors of the reference structures and the sampled structures respectively, and <inline-formula><mml:math id="M10" display="inline"><mml:mrow><mml:msub><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M11" display="inline"><mml:mrow><mml:msub><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mtext>sample</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the covariance matrices of the reference structures and the sampled structures respectively. In practice, fewer samples, on the order of 2000 can be used to estimate the FPD computed with a large number of samples, on the order of 20000 (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 13</xref>).</p></sec><sec id="S13"><title>TERMs</title><p id="P30">The metal-binding motifs are from <xref rid="SD1" ref-type="supplementary-material">Figure S9</xref> of Mackenzie <italic toggle="yes">et al.</italic><sup><xref rid="R15" ref-type="bibr">15</xref></sup>. The formula used to compute the RMSD threshold for each motif is given by <xref rid="FD1" ref-type="disp-formula">Equation 1</xref> of Mackenzie <italic toggle="yes">et al.</italic>:
<disp-formula id="FD2">
<mml:math id="M12" display="block"><mml:mrow><mml:mi>c</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:msqrt><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M13" display="inline"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of residues, <inline-formula><mml:math id="M14" display="inline"><mml:mi>k</mml:mi></mml:math></inline-formula> indexes the segment, such that the <inline-formula><mml:math id="M15" display="inline"><mml:mi>n</mml:mi><mml:mo>&#x02019;</mml:mo><mml:mtext>th</mml:mtext></mml:math></inline-formula> segment has length <inline-formula><mml:math id="M16" display="inline"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M17" display="inline"><mml:mi>L</mml:mi></mml:math></inline-formula> is a correlation length set to 20 as recommended. Here, <inline-formula><mml:math id="M18" display="inline"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:mrow></mml:math></inline-formula> which is double the recommended value as the recommended value of 1.0 gave zero matches for most models for most motifs. <inline-formula><mml:math id="M19" display="inline"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mrow></mml:math></inline-formula> for Calcium 130482 and <inline-formula><mml:math id="M20" display="inline"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:math></inline-formula> for Copper 034863 as more than 5000 matches were found with <inline-formula><mml:math id="M21" display="inline"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:mrow></mml:math></inline-formula>.</p></sec></sec><sec sec-type="supplementary-material" id="SM1"><title>Supplementary Material</title><supplementary-material id="SD1" position="float" content-type="local-data"><label>Supplement 1</label><media xlink:href="media-1.pdf" id="d67e1010" position="anchor"/></supplementary-material></sec></body><back><ack id="S14"><title>ACKNOWLEDGMENTS</title><p id="P31">The authors thank Richard Shuai for comments on the manuscript. T.L is supported by the Stanford Graduate Fellowship. M.L. is supported by Stanford Bioengineering department&#x02019;s Summer Research Experiences for Undergraduates (REU) program. P.-S.H. is supported by NIH (R01GM147893).</p></ack><sec sec-type="data-availability" id="S15"><title>Data and code availability</title><p id="P32">&#x02022; All original code has been deposited at the GitHub repository <ext-link xlink:href="https://github.com/ProteinDesignLab/protein_shapes" ext-link-type="uri">https://github.com/ProteinDesignLab/protein_shapes</ext-link> and data generated has been deposited at Zenodo under the DOI <ext-link xlink:href="10.5281/zenodo.14166398" ext-link-type="doi">10.5281/zenodo.14166398</ext-link>.</p></sec><ref-list><title>References</title><ref id="R1"><label>1.</label><mixed-citation publication-type="journal"><name><surname>Alford</surname><given-names>R. F.</given-names></name>, <name><surname>Leaver-Fay</surname><given-names>A.</given-names></name>, <name><surname>Jeliazkov</surname><given-names>J. R.</given-names></name>, <name><surname>O&#x02019;Meara</surname><given-names>M. J.</given-names></name>, <name><surname>DiMaio</surname><given-names>F. P.</given-names></name>, <name><surname>Park</surname><given-names>H.</given-names></name>, <name><surname>Shapovalov</surname><given-names>M. V.</given-names></name>, <name><surname>Renfrew</surname><given-names>P. D.</given-names></name>, <name><surname>Mulligan</surname><given-names>V. K.</given-names></name>, <name><surname>Kappel</surname><given-names>K</given-names></name>. <etal/> (<year>2017</year>). <article-title>The rosetta all-atom energy function for macromolecular modeling and design</article-title>. <source>Journal of chemical theory and computation</source>
<volume>13</volume>, <fpage>3031</fpage>&#x02013;<lpage>3048</lpage>.<pub-id pub-id-type="pmid">28430426</pub-id>
</mixed-citation></ref><ref id="R2"><label>2.</label><mixed-citation publication-type="journal"><name><surname>Chu</surname><given-names>A. E.</given-names></name>, <name><surname>Lu</surname><given-names>T.</given-names></name>, and <name><surname>Huang</surname><given-names>P.-S.</given-names></name> (<year>2024</year>). <article-title>Sparks of function by de novo protein design</article-title>. <source>Nature biotechnology</source>
<volume>42</volume>, <fpage>203</fpage>&#x02013;<lpage>215</lpage>.</mixed-citation></ref><ref id="R3"><label>3.</label><mixed-citation publication-type="journal"><name><surname>Song</surname><given-names>Y.</given-names></name>, <name><surname>Sohl-Dickstein</surname><given-names>J.</given-names></name>, <name><surname>Kingma</surname><given-names>D. P.</given-names></name>, <name><surname>Kumar</surname><given-names>A.</given-names></name>, <name><surname>Ermon</surname><given-names>S.</given-names></name>, and <name><surname>Poole</surname><given-names>B</given-names></name>. (<year>2020</year>). <article-title>Score-based generative modeling through stochastic differential equations</article-title>. <source>arXiv preprint arXiv:2011.13456</source>.</mixed-citation></ref><ref id="R4"><label>4.</label><mixed-citation publication-type="journal"><name><surname>Dauparas</surname><given-names>J.</given-names></name>, <name><surname>Anishchenko</surname><given-names>I.</given-names></name>, <name><surname>Bennett</surname><given-names>N.</given-names></name>, <name><surname>Bai</surname><given-names>H.</given-names></name>, <name><surname>Ragotte</surname><given-names>R. J.</given-names></name>, <name><surname>Milles</surname><given-names>L. F.</given-names></name>, <name><surname>Wicky</surname><given-names>B. I.</given-names></name>, <name><surname>Courbet</surname><given-names>A.</given-names></name>, <name><surname>de Haas</surname><given-names>R. J.</given-names></name>, <name><surname>Bethel</surname><given-names>N</given-names></name>. <etal/> (<year>2022</year>). <article-title>Robust deep learning&#x02013;based protein sequence design using proteinmpnn</article-title>. <source>Science</source>
<volume>378</volume>, <fpage>49</fpage>&#x02013;<lpage>56</lpage>.<pub-id pub-id-type="pmid">36108050</pub-id>
</mixed-citation></ref><ref id="R5"><label>5.</label><mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>Z.</given-names></name>, <name><surname>Akin</surname><given-names>H.</given-names></name>, <name><surname>Rao</surname><given-names>R.</given-names></name>, <name><surname>Hie</surname><given-names>B.</given-names></name>, <name><surname>Zhu</surname><given-names>Z.</given-names></name>, <name><surname>Lu</surname><given-names>W.</given-names></name>, <name><surname>dos Santos Costa</surname><given-names>A.</given-names></name>, <name><surname>Fazel-Zarandi</surname><given-names>M.</given-names></name>, <name><surname>Sercu</surname><given-names>T.</given-names></name>, <name><surname>Candido</surname><given-names>S</given-names></name>. <etal/> (<year>2022</year>). <article-title>Language models of protein sequences at the scale of evolution enable accurate structure prediction</article-title>. <source>BioRxiv</source>
<volume>2022</volume>, <fpage>500902</fpage>.</mixed-citation></ref><ref id="R6"><label>6.</label><mixed-citation publication-type="journal"><name><surname>Watson</surname><given-names>J. L.</given-names></name>, <name><surname>Juergens</surname><given-names>D.</given-names></name>, <name><surname>Bennett</surname><given-names>N. R.</given-names></name>, <name><surname>Trippe</surname><given-names>B. L.</given-names></name>, <name><surname>Yim</surname><given-names>J.</given-names></name>, <name><surname>Eisenach</surname><given-names>H. E.</given-names></name>, <name><surname>Ahern</surname><given-names>W.</given-names></name>, <name><surname>Borst</surname><given-names>A. J.</given-names></name>, <name><surname>Ragotte</surname><given-names>R. J.</given-names></name>, <name><surname>Milles</surname><given-names>L. F.</given-names></name>
<etal/> (<year>2023</year>). <article-title>De novo design of protein structure and function with rfdiffusion</article-title>. <source>Nature</source>
<volume>620</volume>, <fpage>1089</fpage>&#x02013;<lpage>1100</lpage>.<pub-id pub-id-type="pmid">37433327</pub-id>
</mixed-citation></ref><ref id="R7"><label>7.</label><mixed-citation publication-type="journal"><name><surname>Torres</surname><given-names>S. V.</given-names></name>, <name><surname>Leung</surname><given-names>P. J.</given-names></name>, <name><surname>Lutz</surname><given-names>I. D.</given-names></name>, <name><surname>Venkatesh</surname><given-names>P.</given-names></name>, <name><surname>Watson</surname><given-names>J. L.</given-names></name>, <name><surname>Hink</surname><given-names>F.</given-names></name>, <name><surname>Huynh</surname><given-names>H.-H.</given-names></name>, <name><surname>Yeh</surname><given-names>A. H.-W.</given-names></name>, <name><surname>Juergens</surname><given-names>D.</given-names></name>, <name><surname>Bennett</surname><given-names>N. R.</given-names></name>
<etal/> (<year>2022</year>). <article-title>De novo design of high-affinity protein binders to bioactive helical peptides</article-title>. <source>Biorxiv</source> ( <fpage>2022</fpage>&#x02013;<lpage>12</lpage>).</mixed-citation></ref><ref id="R8"><label>8.</label><mixed-citation publication-type="journal"><name><surname>Braun</surname><given-names>M.</given-names></name>, <name><surname>Tripp</surname><given-names>A.</given-names></name>, <name><surname>Chakatok</surname><given-names>M.</given-names></name>, <name><surname>Kaltenbrunner</surname><given-names>S.</given-names></name>, <name><surname>Totaro</surname><given-names>M. G.</given-names></name>, <name><surname>Stoll</surname><given-names>D.</given-names></name>, <name><surname>Bijelic</surname><given-names>A.</given-names></name>, <name><surname>Elaily</surname><given-names>W.</given-names></name>, <name><surname>Hoch</surname><given-names>S. Y. Y.</given-names></name>, <name><surname>Aleotti</surname><given-names>M</given-names></name>. <etal/> (<year>2024</year>). <article-title>Computational design of highly active de novo enzymes</article-title>. <source>bioRxiv</source> ( <fpage>2024</fpage>&#x02013;<lpage>08</lpage>).</mixed-citation></ref><ref id="R9"><label>9.</label><mixed-citation publication-type="journal"><name><surname>Berman</surname><given-names>H. M.</given-names></name>, <name><surname>Battistuz</surname><given-names>T.</given-names></name>, <name><surname>Bhat</surname><given-names>T. N.</given-names></name>, <name><surname>Bluhm</surname><given-names>W. F.</given-names></name>, <name><surname>Bourne</surname><given-names>P. E.</given-names></name>, <name><surname>Burkhardt</surname><given-names>K.</given-names></name>, <name><surname>Feng</surname><given-names>Z.</given-names></name>, <name><surname>Gilliland</surname><given-names>G. L.</given-names></name>, <name><surname>Iype</surname><given-names>L.</given-names></name>, <name><surname>Jain</surname><given-names>S</given-names></name>. <etal/> (<year>2002</year>). <article-title>The protein data bank</article-title>. <source>Acta Crystallographica Section D: Biological Crystallography</source>
<volume>58</volume>, <fpage>899</fpage>&#x02013;<lpage>907</lpage>.<pub-id pub-id-type="pmid">12037327</pub-id>
</mixed-citation></ref><ref id="R10"><label>10.</label><mixed-citation publication-type="journal"><name><surname>Alamdari</surname><given-names>S.</given-names></name>, <name><surname>Thakkar</surname><given-names>N.</given-names></name>, <name><surname>van den Berg</surname><given-names>R.</given-names></name>, <name><surname>Lu</surname><given-names>A. X.</given-names></name>, <name><surname>Fusi</surname><given-names>N.</given-names></name>, <name><surname>Amini</surname><given-names>A. P.</given-names></name>, and <name><surname>Yang</surname><given-names>K. K.</given-names></name> (<year>2023</year>). <article-title>Protein generation with evolutionary diffusion: sequence is all you need</article-title>. <source>bioRxiv</source> ( <fpage>2023</fpage>&#x02013;<lpage>09</lpage>).</mixed-citation></ref><ref id="R11"><label>11.</label><mixed-citation publication-type="journal"><name><surname>Ingraham</surname><given-names>J. B.</given-names></name>, <name><surname>Baranov</surname><given-names>M.</given-names></name>, <name><surname>Costello</surname><given-names>Z.</given-names></name>, <name><surname>Barber</surname><given-names>K. W.</given-names></name>, <name><surname>Wang</surname><given-names>W.</given-names></name>, <name><surname>Ismail</surname><given-names>A.</given-names></name>, <name><surname>Frappier</surname><given-names>V.</given-names></name>, <name><surname>Lord</surname><given-names>D. M.</given-names></name>, <name><surname>Ng-Thow-Hing</surname><given-names>C.</given-names></name>, <name><surname>Van Vlack</surname><given-names>E. R.</given-names></name>
<etal/> (<year>2023</year>). <article-title>Illuminating protein space with a programmable generative model</article-title>. <source>Nature</source>
<volume>623</volume>, <fpage>1070</fpage>&#x02013;<lpage>1078</lpage>.<pub-id pub-id-type="pmid">37968394</pub-id>
</mixed-citation></ref><ref id="R12"><label>12.</label><mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>Y.</given-names></name>, <name><surname>Lee</surname><given-names>M.</given-names></name>, <name><surname>Zhang</surname><given-names>Z.</given-names></name>, and <name><surname>AlQuraishi</surname><given-names>M</given-names></name>. (<year>2024</year>). <article-title>Out of many, one: Designing and scaffolding proteins at the scale of the structural universe with genie 2</article-title>. <source>arXiv preprint arXiv:2405.15489</source>.</mixed-citation></ref><ref id="R13"><label>13.</label><mixed-citation publication-type="journal"><name><surname>Chu</surname><given-names>A. E.</given-names></name>, <name><surname>Kim</surname><given-names>J.</given-names></name>, <name><surname>Cheng</surname><given-names>L.</given-names></name>, <name><surname>El Nesr</surname><given-names>G.</given-names></name>, <name><surname>Xu</surname><given-names>M.</given-names></name>, <name><surname>Shuai</surname><given-names>R. W.</given-names></name>, and <name><surname>Huang</surname><given-names>P.-S.</given-names></name> (<year>2024</year>). <article-title>An all-atom protein generative model</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>121</volume>, <fpage>e2311500121</fpage>.</mixed-citation></ref><ref id="R14"><label>14.</label><mixed-citation publication-type="journal"><name><surname>Campbell</surname><given-names>A.</given-names></name>, <name><surname>Yim</surname><given-names>J.</given-names></name>, <name><surname>Barzilay</surname><given-names>R.</given-names></name>, <name><surname>Rainforth</surname><given-names>T.</given-names></name>, and <name><surname>Jaakkola</surname><given-names>T</given-names></name>. (<year>2024</year>). <article-title>Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design</article-title>. <source>arXiv preprint arXiv:2402.04997</source>.</mixed-citation></ref><ref id="R15"><label>15.</label><mixed-citation publication-type="journal"><name><surname>Mackenzie</surname><given-names>C. O.</given-names></name>, <name><surname>Zhou</surname><given-names>J.</given-names></name>, and <name><surname>Grigoryan</surname><given-names>G</given-names></name>. (<year>2016</year>). <article-title>Tertiary alphabet for the observable protein structural universe</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>113</volume>, <fpage>E7438</fpage>&#x02013;<lpage>E7447</lpage>.</mixed-citation></ref><ref id="R16"><label>16.</label><mixed-citation publication-type="journal"><name><surname>Orengo</surname><given-names>C. A.</given-names></name>, <name><surname>Michie</surname><given-names>A. D.</given-names></name>, <name><surname>Jones</surname><given-names>S.</given-names></name>, <name><surname>Jones</surname><given-names>D. T.</given-names></name>, <name><surname>Swindells</surname><given-names>M. B.</given-names></name>, and <name><surname>Thornton</surname><given-names>J. M.</given-names></name> (<year>1997</year>). <article-title>Cath&#x02013;a hierarchic classification of protein domain structures</article-title>. <source>Structure</source>
<volume>5</volume>, <fpage>1093</fpage>&#x02013;<lpage>1109</lpage>.<pub-id pub-id-type="pmid">9309224</pub-id>
</mixed-citation></ref><ref id="R17"><label>17.</label><mixed-citation publication-type="journal"><name><surname>Akpinaroglu</surname><given-names>D.</given-names></name>, <name><surname>Seki</surname><given-names>K.</given-names></name>, <name><surname>Guo</surname><given-names>A.</given-names></name>, <name><surname>Zhu</surname><given-names>E.</given-names></name>, <name><surname>Kelly</surname><given-names>M. J.</given-names></name>, and <name><surname>Kortemme</surname><given-names>T</given-names></name>. (<year>2023</year>). <article-title>Structure-conditioned masked language models for protein sequence design generalize beyond the native sequence space</article-title>. <source>bioRxiv</source> ( <fpage>2023</fpage>&#x02013;<lpage>12</lpage>).</mixed-citation></ref><ref id="R18"><label>18.</label><mixed-citation publication-type="journal"><name><surname>Kortemme</surname><given-names>T</given-names></name>. (<year>2024</year>). <article-title>De novo protein design&#x02014;from new structures to programmable functions</article-title>. <source>Cell</source>
<volume>187</volume>, <fpage>526</fpage>&#x02013;<lpage>544</lpage>.<pub-id pub-id-type="pmid">38306980</pub-id>
</mixed-citation></ref><ref id="R19"><label>19.</label><mixed-citation publication-type="journal"><name><surname>van Kempen</surname><given-names>M.</given-names></name>, <name><surname>Kim</surname><given-names>S. S.</given-names></name>, <name><surname>Tumescheit</surname><given-names>C.</given-names></name>, <name><surname>Mirdita</surname><given-names>M.</given-names></name>, <name><surname>Gilchrist</surname><given-names>C. L.</given-names></name>, <name><surname>S&#x000f6;ding</surname><given-names>J.</given-names></name>, and <name><surname>Steinegger</surname><given-names>M</given-names></name>. (<year>2022</year>). <article-title>Foldseek: fast and accurate protein structure search</article-title>. <source>Biorxiv</source> ( <fpage>2022</fpage>&#x02013;<lpage>02</lpage>).</mixed-citation></ref><ref id="R20"><label>20.</label><mixed-citation publication-type="journal"><name><surname>Hayes</surname><given-names>T.</given-names></name>, <name><surname>Rao</surname><given-names>R.</given-names></name>, <name><surname>Akin</surname><given-names>H.</given-names></name>, <name><surname>Sofroniew</surname><given-names>N. J.</given-names></name>, <name><surname>Oktay</surname><given-names>D.</given-names></name>, <name><surname>Lin</surname><given-names>Z.</given-names></name>, <name><surname>Verkuil</surname><given-names>R.</given-names></name>, <name><surname>Tran</surname><given-names>V. Q.</given-names></name>, <name><surname>Deaton</surname><given-names>J.</given-names></name>, <name><surname>Wiggert</surname><given-names>M</given-names></name>. <etal/> (<year>2024</year>). <article-title>Simulating 500 million years of evolution with a language model</article-title>. <source>bioRxiv</source> ( <fpage>2024</fpage>&#x02013;<lpage>07</lpage>).</mixed-citation></ref><ref id="R21"><label>21.</label><mixed-citation publication-type="journal"><name><surname>Eguchi</surname><given-names>R. R.</given-names></name>, and <name><surname>Huang</surname><given-names>P.-S.</given-names></name> (<year>2020</year>). <article-title>Multi-scale structural analysis of proteins by deep semantic segmentation</article-title>. <source>Bioinformatics</source>
<volume>36</volume>, <fpage>1740</fpage>&#x02013;<lpage>1749</lpage>.<pub-id pub-id-type="pmid">31424530</pub-id>
</mixed-citation></ref><ref id="R22"><label>22.</label><mixed-citation publication-type="journal"><name><surname>Ingraham</surname><given-names>J.</given-names></name>, <name><surname>Garg</surname><given-names>V.</given-names></name>, <name><surname>Barzilay</surname><given-names>R.</given-names></name>, and <name><surname>Jaakkola</surname><given-names>T</given-names></name>. (<year>2019</year>). <article-title>Generative models for graph-based protein design</article-title>. <source>Advances in neural information processing systems</source>
<volume>32</volume>.</mixed-citation></ref><ref id="R23"><label>23.</label><mixed-citation publication-type="journal"><name><surname>Touw</surname><given-names>W. G.</given-names></name>, <name><surname>Baakman</surname><given-names>C.</given-names></name>, <name><surname>Black</surname><given-names>J.</given-names></name>, <name><surname>Te Beek</surname><given-names>T. A.</given-names></name>, <name><surname>Krieger</surname><given-names>E.</given-names></name>, <name><surname>Joosten</surname><given-names>R. P.</given-names></name>, and <name><surname>Vriend</surname><given-names>G</given-names></name>. (<year>2015</year>). <article-title>A series of pdb-related databanks for everyday needs</article-title>. <source>Nucleic acids research</source>
<volume>43</volume>, <fpage>D364</fpage>&#x02013;<lpage>D368</lpage>.<pub-id pub-id-type="pmid">25352545</pub-id>
</mixed-citation></ref><ref id="R24"><label>24.</label><mixed-citation publication-type="journal"><name><surname>Kabsch</surname><given-names>W.</given-names></name>, and <name><surname>Sander</surname><given-names>C</given-names></name>. (<year>1983</year>). <article-title>Dictionary of protein secondary structure: pattern recognition of hydrogen-bonded and geometrical features. Biopolymers</article-title>: <source>Original Research on Biomolecules</source>
<volume>22</volume>, <fpage>2577</fpage>&#x02013;<lpage>2637</lpage>.</mixed-citation></ref><ref id="R25"><label>25.</label><mixed-citation publication-type="journal"><name><surname>Abramson</surname><given-names>J.</given-names></name>, <name><surname>Adler</surname><given-names>J.</given-names></name>, <name><surname>Dunger</surname><given-names>J.</given-names></name>, <name><surname>Evans</surname><given-names>R.</given-names></name>, <name><surname>Green</surname><given-names>T.</given-names></name>, <name><surname>Pritzel</surname><given-names>A.</given-names></name>, <name><surname>Ronneberger</surname><given-names>O.</given-names></name>, <name><surname>Willmore</surname><given-names>L.</given-names></name>, <name><surname>Ballard</surname><given-names>A. J.</given-names></name>, <name><surname>Bambrick</surname><given-names>J</given-names></name>. <etal/> (<year>2024</year>). <article-title>Accurate structure prediction of biomolecular interactions with alphafold 3</article-title>. <source>Nature</source> ( <fpage>1</fpage>&#x02013;<lpage>3</lpage>).</mixed-citation></ref><ref id="R26"><label>26.</label><mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>J.</given-names></name>, and <name><surname>Grigoryan</surname><given-names>G</given-names></name>. (<year>2015</year>). <article-title>Rapid search for tertiary fragments reveals protein sequence&#x02013;structure relationships</article-title>. <source>Protein Science</source>
<volume>24</volume>, <fpage>508</fpage>&#x02013;<lpage>524</lpage>.<pub-id pub-id-type="pmid">25420575</pub-id>
</mixed-citation></ref><ref id="R27"><label>27.</label><mixed-citation publication-type="journal"><name><surname>Gloegl</surname><given-names>M.</given-names></name>, <name><surname>Krishnakumar</surname><given-names>A.</given-names></name>, <name><surname>Ragotte</surname><given-names>R.</given-names></name>, <name><surname>Goreshnik</surname><given-names>I.</given-names></name>, <name><surname>Coventry</surname><given-names>B.</given-names></name>, <name><surname>Bera</surname><given-names>A. K.</given-names></name>, <name><surname>Kang</surname><given-names>A.</given-names></name>, <name><surname>Joyce</surname><given-names>E.</given-names></name>, <name><surname>Ahn</surname><given-names>G.</given-names></name>, <name><surname>Huang</surname><given-names>B</given-names></name>. <etal/> (<year>2024</year>). <article-title>Target-conditioned diffusion generates potent tnfr superfamily antagonists and agonists</article-title>. <source>bioRxiv</source> ( <fpage>2024</fpage>&#x02013;<lpage>09</lpage>).</mixed-citation></ref><ref id="R28"><label>28.</label><mixed-citation publication-type="journal"><name><surname>Jamasb</surname><given-names>A. R.</given-names></name>, <name><surname>Morehead</surname><given-names>A.</given-names></name>, <name><surname>Joshi</surname><given-names>C. K.</given-names></name>, <name><surname>Zhang</surname><given-names>Z.</given-names></name>, <name><surname>Didi</surname><given-names>K.</given-names></name>, <name><surname>Mathis</surname><given-names>S. V.</given-names></name>, <name><surname>Harris</surname><given-names>C.</given-names></name>, <name><surname>Tang</surname><given-names>J.</given-names></name>, <name><surname>Cheng</surname><given-names>J.</given-names></name>, <name><surname>Lio</surname><given-names>P</given-names></name>. <etal/> (<year>2024</year>). <article-title>Evaluating representation learning on the protein` structure universe</article-title>. <source>arXiv preprint arXiv:2406.13864</source>.</mixed-citation></ref><ref id="R29"><label>29.</label><mixed-citation publication-type="journal"><name><surname>Rao</surname><given-names>R.</given-names></name>, <name><surname>Bhattacharya</surname><given-names>N.</given-names></name>, <name><surname>Thomas</surname><given-names>N.</given-names></name>, <name><surname>Duan</surname><given-names>Y.</given-names></name>, <name><surname>Chen</surname><given-names>P.</given-names></name>, <name><surname>Canny</surname><given-names>J.</given-names></name>, <name><surname>Abbeel</surname><given-names>P.</given-names></name>, and <name><surname>Song</surname><given-names>Y</given-names></name>. (<year>2019</year>). <article-title>Evaluating protein transfer learning with tape</article-title>. <source>Advances in neural information processing systems</source>
<volume>32</volume>.</mixed-citation></ref><ref id="R30"><label>30.</label><mixed-citation publication-type="journal"><name><surname>Eguchi</surname><given-names>R. R.</given-names></name>, <name><surname>Choe</surname><given-names>C. A.</given-names></name>, and <name><surname>Huang</surname><given-names>P.-S.</given-names></name> (<year>2022</year>). <article-title>Ig-vae: Generative modeling of protein structure by direct 3d coordinate generation</article-title>. <source>PLoS computational biology</source>
<volume>18</volume>, <fpage>e1010271</fpage>.<pub-id pub-id-type="pmid">35759518</pub-id>
</mixed-citation></ref><ref id="R31"><label>31.</label><mixed-citation publication-type="journal"><name><surname>Barrio-Hernandez</surname><given-names>I.</given-names></name>, <name><surname>Yeo</surname><given-names>J.</given-names></name>, <name><surname>J&#x000e4;nes</surname><given-names>J.</given-names></name>, <name><surname>Mirdita</surname><given-names>M.</given-names></name>, <name><surname>Gilchrist</surname><given-names>C. L.</given-names></name>, <name><surname>Wein</surname><given-names>T.</given-names></name>, <name><surname>Varadi</surname><given-names>M.</given-names></name>, <name><surname>Velankar</surname><given-names>S.</given-names></name>, <name><surname>Beltrao</surname><given-names>P.</given-names></name>, and <name><surname>Steinegger</surname><given-names>M</given-names></name>. (<year>2023</year>). <article-title>Clustering predicted structures at the scale of the known protein universe</article-title>. <source>Nature</source>
<volume>622</volume>, <fpage>637</fpage>&#x02013;<lpage>645</lpage>.<pub-id pub-id-type="pmid">37704730</pub-id>
</mixed-citation></ref><ref id="R32"><label>32.</label><mixed-citation publication-type="journal"><name><surname>Hermosilla</surname><given-names>A. M.</given-names></name>, <name><surname>Berner</surname><given-names>C.</given-names></name>, <name><surname>Ovchinnikov</surname><given-names>S.</given-names></name>, and <name><surname>Vorobieva</surname><given-names>A. A.</given-names></name> (<year>2024</year>). <article-title>Validation of de novo designed water-soluble and transmembrane <italic toggle="yes">&#x003b2;</italic>-barrels by in silico folding and melting</article-title>. <source>Protein Science</source>
<volume>33</volume>, <fpage>e5033</fpage>.<pub-id pub-id-type="pmid">38864690</pub-id>
</mixed-citation></ref><ref id="R33"><label>33.</label><mixed-citation publication-type="journal"><name><surname>Luo</surname><given-names>G.</given-names></name>, <name><surname>Dunlap</surname><given-names>L.</given-names></name>, <name><surname>Park</surname><given-names>D. H.</given-names></name>, <name><surname>Holynski</surname><given-names>A.</given-names></name>, and <name><surname>Darrell</surname><given-names>T</given-names></name>. (<year>2024</year>). <article-title>Diffusion hyperfeatures: Searching through time and space for semantic correspondence</article-title>. <source>Advances in Neural Information Processing Systems</source>
<volume>36</volume>.</mixed-citation></ref><ref id="R34"><label>34.</label><mixed-citation publication-type="journal"><name><surname>Dauparas</surname><given-names>J.</given-names></name>, <name><surname>Lee</surname><given-names>G. R.</given-names></name>, <name><surname>Pecoraro</surname><given-names>R.</given-names></name>, <name><surname>An</surname><given-names>L.</given-names></name>, <name><surname>Anishchenko</surname><given-names>I.</given-names></name>, <name><surname>Glasscock</surname><given-names>C.</given-names></name>, and <name><surname>Baker</surname><given-names>D</given-names></name>. (<year>2023</year>). <article-title>Atomic context-conditioned protein sequence design using ligandmpnn</article-title>. <source>Biorxiv ( 2023&#x02013;12)</source>.</mixed-citation></ref></ref-list></back><floats-group><fig position="float" id="F1"><label>Figure 1.</label><caption><title>Generative models capture a biased set of protein structure space.</title><p id="P33">(A) Generative models of protein structures convert noise to samples which are optimized to match the data distribution, e.g. CATH. Models are optimized for the ability to draw samples with high designability, which implicitly imposes a filter that over-emphasizes the designable subspace of protein structures and under-emphasizes the undesignable subspace. (B) Secondary structure elements more prominently show alpha helices and beta sheets in sampled structures compared to native structures in CATH.</p></caption><graphic xlink:href="nihpp-2025.01.09.632260v2-f0001" position="float"/></fig><fig position="float" id="F2"><label>Figure 2.</label><caption><title>Partial diffusion with RFdiffusion reduces structural complexity.</title><p id="P34">(A) 20 steps of partial diffusion using RFdiffusion applied to 21,663 samples of Protpardelle leads to reduced loop content and more alpha and beta content. Partial diffusion by RFdiffusion induces a vector field in secondary structure content. We approximate the true vector field using the start and end secondary structure content before and after partial diffusion. (B) The max TM score is taken over each group of eight ProteinMPNN designed sequences for each structure. The median is taken over all structures for every length. (C) Example of a high temperature sample from Protpardelle (left) and the structural edits made by 20 steps of RFdiffusion partial diffusion at the default sampling temperature.</p></caption><graphic xlink:href="nihpp-2025.01.09.632260v2-f0002" position="float"/></fig><fig position="float" id="F3"><label>Figure 3.</label><caption><title>Protein structure embeddings reveal undersampled and <italic toggle="yes">de novo</italic> structure space.</title><p id="P35">(A) Protein structure embeddings used in SHAPES. After mean-pooling across the sequence dimension, the dimensionality is 128 for ProteinMPNN and ESM3, 4096 for ProtDomainSegmentor. Foldseek tokens are discrete and cannot be mean-pooled, thus we count the frequency of each token in each length range (<xref rid="SD1" ref-type="supplementary-material">Supplementary Figure 11</xref>). (B) First two principal components of mean-pooled ESM3 embeddings colored by helix content determined by DSSP<sup><xref rid="R23" ref-type="bibr">23</xref>,<xref rid="R24" ref-type="bibr">24</xref></sup>. The indicated dashed guide lines denote visual boundaries of native structure space not sampled (Undersampled) and novel regions of protein structure space only observed in samples but not in native structures (<italic toggle="yes">De novo</italic>). (C) Rasterized visualization of panel B with 16 equally spaced grid squares in each principal component axis. A representative structure from each grid was chosen at random. Empty grid squares indicate the absence of any structure in the enclosed region. <italic toggle="yes">De novo</italic> alpha helices are shaded along the lower-right diagonal and the structures from CATH which do not have corresponding structures in the samples are shaded along the left and top rims. The structures are displayed in CATH raster plot are given in the <xref rid="SD1" ref-type="supplementary-material">Supplementary Information</xref>.</p></caption><graphic xlink:href="nihpp-2025.01.09.632260v2-f0003" position="float"/></fig><fig position="float" id="F4"><label>Figure 4.</label><caption><title>Generative models do not capture the full expressivity of PDB structures.</title><p id="P36">PCA projections of ESM3 mean-pooled encoder embeddings with sampled structure projections overlayed on CATH structure projections. The streak observed in the sampled structures is not present in the native CATH distribution (<xref rid="F3" ref-type="fig">Figure 3B</xref>). The top row corresponds to default sampling temperatures for each model. FPD: Fr&#x000e9;chet Protein Distance for all samples to CATH reference set. FPD-D: FPD for designable samples with RMSD &#x0003c; 2.0 &#x000c5;. FPD-ND: FPD for undesignable samples with RMSD &#x0003e; 2.0 &#x000c5;. Plots for ProtDomainSegmentor and ProteinMPNN embeddings are given in <xref rid="SD1" ref-type="supplementary-material">Supplementary Figures 3</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">4</xref>. Plots for all continuous embeddings with AF3-PDB as the reference distribution instead of CATH are given in <xref rid="SD1" ref-type="supplementary-material">Supplementary Figures 8</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">10</xref>.</p></caption><graphic xlink:href="nihpp-2025.01.09.632260v2-f0004" position="float"/></fig><fig position="float" id="F5"><label>Figure 5.</label><caption><title>Functional tertiary structural alphabets are absent in samples.</title><p id="P37">A: CATH, B: Chroma Default, C: Chroma Inverse Temperature 3, D: Chroma Inverse Temperature 4, E: Genie2 Default, F: Genie2 Scale 0.8, G: Genie2 Scale 1.0, H: MultiFlow, I: RFdiffusion Default, J: RFdiffusion Noise Scale 2, K: RFdiffusion Noise Scale 3, L: Protpardelle Stepscale 0.8, M: Protpardelle Stepscale 1.0, N: Protpardelle Stepscale 1.2. Counts of metal-binding TERMs in CATH and sampled structure sets when queried by MASTER. The RMSD threshold for each TERM depends on its complexity measured by the number of residues and the number of fragments, where more complex TERMs have less strict RMSD thresholds for a match to be counted (<xref rid="S10" ref-type="sec">Methods</xref>).</p></caption><graphic xlink:href="nihpp-2025.01.09.632260v2-f0005" position="float"/></fig></floats-group></article>