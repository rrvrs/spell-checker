<!--

File produced by pipelineRunner package (for JATS 2 SCJATS with pipeline SCJATS)
At: 2025-05-21T23:52:23.861Z

Version        : 1.16.1
Last update    : 2024-08-27
Modified by    : dunnm

-->
<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40306261</article-id><article-id pub-id-type="pmc">PMC12094817</article-id>
<article-id pub-id-type="doi">10.1093/bioinformatics/btaf248</article-id><article-id pub-id-type="publisher-id">btaf248</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject><subj-group subj-group-type="category-toc-heading"><subject>Data and Text Mining</subject></subj-group></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI01060</subject></subj-group></article-categories><title-group><article-title>Co-design protein sequence and structure in discrete space via generative flow</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3222-2268</contrib-id><name><surname>Yang</surname><given-names>Sen</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="lead">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="lead">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="lead">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources" degree-contribution="lead">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="lead">Writing - original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &#x00026; editing</role><aff>
<institution>Bioinformatics Center of AMMS</institution>, Beijing, 100039, <country country="CN">China</country></aff><xref rid="btaf248-cor1" ref-type="corresp"/><!--yangsen@bmi.ac.cn--></contrib><contrib contrib-type="author"><name><surname>Ju</surname><given-names>Lingli</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="equal">Funding acquisition</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role><aff>
<institution>The 921st Hospital of Chinese PLA</institution>, Changsha, 410073, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><name><surname>Cheng</surname><given-names>Peng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &#x00026; editing</role><aff>
<institution>Bioinformatics Center of AMMS</institution>, Beijing, 100039, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhou</surname><given-names>JiangLin</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role><aff>
<institution>Bioinformatics Center of AMMS</institution>, Beijing, 100039, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><name><surname>Cai</surname><given-names>Yamin</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="supporting">Funding acquisition</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="supporting">Validation</role><aff>
<institution>The 921st Hospital of Chinese PLA</institution>, Changsha, 410073, <country country="CN">China</country></aff></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Feng</surname><given-names>Dawei</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="lead">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="lead">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &#x00026; editing</role><aff>
<institution>Computer College, National University of Defense Technology</institution>, Changsha, 410073, <country country="CN">China</country></aff><xref rid="btaf248-cor1" ref-type="corresp"/><!--davyfeng.c@gmail.com--></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Elofsson</surname><given-names>Arne</given-names></name><role>Associate Editor</role></contrib></contrib-group><author-notes><corresp id="btaf248-cor1">Corresponding authors. Sen Yang, Bioinformatics Center of AMMS, No. 27, Taiping Road, Haidian District, Beijing, 100039, China. E-mail: <email>yangsen@bmi.ac.cn</email>; Dawei Feng, Computer College, National University of Defense Technology Changsha, China. E-mail: <email>davyfeng.c@gmail.com</email>.</corresp></author-notes><pub-date pub-type="collection"><month>5</month><year>2025</year></pub-date><pub-date pub-type="epub" iso-8601-date="2025-04-30"><day>30</day><month>4</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>30</day><month>4</month><year>2025</year></pub-date><volume>41</volume><issue>5</issue><elocation-id>btaf248</elocation-id><history><date date-type="received"><day>13</day><month>1</month><year>2025</year></date><date date-type="rev-recd"><day>17</day><month>4</month><year>2025</year></date><date date-type="editorial-decision"><day>21</day><month>4</month><year>2025</year></date><date date-type="accepted"><day>29</day><month>4</month><year>2025</year></date><date date-type="corrected-typeset"><day>21</day><month>5</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025. Published by Oxford University Press.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="btaf248.pdf"/><abstract><title>Abstract</title><sec id="s1"><title>Motivation</title><p>Generative models have demonstrated considerable promise in <italic toggle="yes">de novo</italic> protein design. Traditional approaches typically focus on either sequence or structure in isolation, limiting the capacity to explore the intricate sequence&#x02013;structure landscape and achieve optimal designs. However, joint protein sequence and structure co-design remains a largely underexplored challenge.</p></sec><sec id="s2"><title>Results</title><p>We present CoFlow, a discrete model for protein co-design from scratch or given constraints. CoFlow employs a joint discrete flow and integrates a multi-modal protein masked language model to facilitate co-design in the discrete space. Comprehensive experiments demonstrate that CoFlow outperforms previous design methods across multiple evaluation metrics. Notably, CoFlow achieves a consistency approximately eight times higher than that of ESM3 in unconditional generation. Moreover, CoFlow exhibits competitive performance in conditional generation tasks, including motif-scaffolding, protein folding, and inverse folding.</p></sec><sec id="s3"><title>Availability and implementation</title><p>The source code of CoFlow, including data preprocessing and model, is available at <ext-link xlink:href="https://github.com/LtECoD/CoFlow" ext-link-type="uri">https://github.com/LtECoD/CoFlow</ext-link> and <ext-link xlink:href="https://zenodo.org/records/14842367" ext-link-type="uri">https://zenodo.org/records/14842367</ext-link>. (DOI: 10.5281/zenodo.14842367).</p></sec></abstract><funding-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>National Natural Science Foundation of China</institution><institution-id institution-id-type="DOI">10.13039/501100001809</institution-id></institution-wrap>
</funding-source><award-id>62306334</award-id><award-id>81830101</award-id><award-id>WDZC20245250107</award-id></award-group></funding-group><counts><page-count count="8"/></counts></article-meta></front><body><sec><title>1 Introduction</title><p>Over more than 3 billion years of natural evolution, numerous proteins have evolved to perform crucial biological functions in life processes. However, natural proteins are constrained by evolutionary limitations, having adapted to specific ecological and physiological contexts, which often renders them suboptimal for applications such as drug development and enzyme engineering. To overcome these limitations, <italic toggle="yes">de novo</italic> protein design (<xref rid="btaf248-B9" ref-type="bibr">Huang <italic toggle="yes">et al.</italic> 2016</xref>) seeks to create proteins that do not exist in nature but can be tailored for novel applications, including enzymes (<xref rid="btaf248-B18" ref-type="bibr">Ming <italic toggle="yes">et al.</italic> 2023</xref>), antibodies (<xref rid="btaf248-B11" ref-type="bibr">Joubbi <italic toggle="yes">et al.</italic> 2024</xref>), and even molecular switches (<xref rid="btaf248-B13" ref-type="bibr">Langan <italic toggle="yes">et al.</italic> 2019</xref>).</p><p>Traditional protein design methods emphasize directed evolution (<xref rid="btaf248-B19" ref-type="bibr">Polizzi and DeGrado 2020</xref>) and rational design, typically relying on energy functions and geometric constraints (<xref rid="btaf248-B14" ref-type="bibr">Leman <italic toggle="yes">et al.</italic> 2020</xref>). However, these approaches face limitations in designing structurally and functionally diverse proteins. In recent years, generative artificial intelligence models, such as the language model (<xref rid="btaf248-B2" ref-type="bibr">Brown <italic toggle="yes">et al.</italic> 2020</xref>) and diffusion model (<xref rid="btaf248-B8" ref-type="bibr">Ho <italic toggle="yes">et al.</italic> 2020</xref>), have been introduced for protein design, leading to significant advancements in both protein sequence design (<xref rid="btaf248-B5" ref-type="bibr">Dauparas <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btaf248-B6" ref-type="bibr">Ferruz <italic toggle="yes">et al.</italic> 2022</xref>, <xref rid="btaf248-B17" ref-type="bibr">Madani <italic toggle="yes">et al.</italic> 2023</xref>) and structure design (<xref rid="btaf248-B24" ref-type="bibr">Watson <italic toggle="yes">et al.</italic> 2023</xref>, <xref rid="btaf248-B25" ref-type="bibr">Yim <italic toggle="yes">et al.</italic> 2023</xref>, <xref rid="btaf248-B23" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024</xref>) (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1</xref>). As a result, a two-stage paradigm, where the backbone structure and sequence are generated sequentially, has been typically employed to design various proteins. Nevertheless, the information flow in such an approach is unidirectional, being insufficient to capture the intricate sequence&#x02013;structure landscape that governs protein functionality. Therefore, designing proteins with optimal performance across diverse applications remains challenging. Meanwhile, efforts have been made to co-design protein sequence and structure either sequentially (<xref rid="btaf248-B1" ref-type="bibr">Anand and Achim 2022</xref>, <xref rid="btaf248-B10" ref-type="bibr">Ingraham <italic toggle="yes">et al.</italic> 2023</xref>, <xref rid="btaf248-B20" ref-type="bibr">Ren <italic toggle="yes">et al.</italic> 2024</xref>) or jointly (<xref rid="btaf248-B3" ref-type="bibr">Campbell <italic toggle="yes">et al.</italic> 2024</xref>), yet sequence and structure often remain loosely coupled due to their separate modeling. Recently, ESM3 (<xref rid="btaf248-B7" ref-type="bibr">Hayes <italic toggle="yes">et al.</italic> 2025</xref>), a generative masked language model, was introduced to learn representation and generation across multiple modalities. Specifically, ESM3 employs a VQ-VAE (<xref rid="btaf248-B22" ref-type="bibr">Van Den Oord <italic toggle="yes">et al.</italic> 2017</xref>) to encode protein structure into discrete tokens and decode structure from tokens (<xref rid="btaf248-F1" ref-type="fig">Fig.&#x000a0;1b</xref>), thus enabling the unified learning of both sequence and structure distributions within a single model. Although ESM3 presents a novel approach to protein co-design, its performance in unconditional generation remains suboptimal (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). Most structures generated by the released ESM3 exhibit lower pTMs compared to natural proteins.</p><fig position="float" id="btaf248-F1"><label>Figure 1.</label><caption><p>Overview of CoFlow. (a) CoFlow leverages a generative flow to iteratively unmask discrete sequence and structure tokens, allowing for various inputs and supporting both unconditional co-generation and conditional generation tasks, including structure prediction, sequence design, and motif-scaffolding. (b) Discrete protein structure tokens are obtained through the structure VQ-VAE model in ESM3. (c) The joint flow trajectory of sequence and structure is modeled concurrently. (d) The network architecture of CoFlow, which incorporates an additional time feature encoder into ESM3.</p></caption><graphic xlink:href="btaf248f1" position="float"/></fig><p>To overcome the above issue, we propose a novel protein co-design model, CoFlow, which leverages a joint generative flow to co-design protein sequences and backbone in discrete space (<xref rid="btaf248-F1" ref-type="fig">Fig.&#x000a0;1a</xref>). CoFlow operates within a probabilistic generative framework to model discrete distribution and sample protein instances. It utilizes continuous-time Markov chains (<xref rid="btaf248-B3" ref-type="bibr">Campbell <italic toggle="yes">et al.</italic> 2024</xref>), providing greater flexibility than diffusion models and enabling more diverse and controllable sampling. The generative flow implements linear interpolation (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>) from noise to discrete tokens. To tokenize protein structures and recover three-dimensional coordinates, CoFlow incorporates the structure VQ-VAE from ESM3 (<xref rid="btaf248-B7" ref-type="bibr">Hayes <italic toggle="yes">et al.</italic> 2025</xref>). As a joint generative model, CoFlow integrates two generative flows for sequence and structure, respectively (<xref rid="btaf248-F1" ref-type="fig">Fig.&#x000a0;1c</xref>). It employs a bidirectional transformer enhanced with layer-wise Fourier time features to model sequence and structure within a unified latent space. The final outputs are two predicted categorical distributions (<xref rid="btaf248-F1" ref-type="fig">Fig.&#x000a0;1d</xref>). Sampling from CoFlow starts from fully or partially masked tokens, enabling both unconditional generation and various conditional generation tasks.</p><p>We conduct comprehensive experiments to evaluate CoFlow against other protein design baselines across various generation tasks. The experimental results show that CoFlow surpasses existing baselines in design consistency for unconditional generation. Notably, CoFlow achieves a consistency that is eight times higher than that of ESM3. In addition, CoFlow demonstrates superior performance in conditional generation tasks, including motif-scaffolding, structure prediction, and sequence design.</p></sec><sec><title>2 Materials and methods</title><sec><title>2.1 Preliminary</title><p>A protein can be modeled as a linear chain of residues, each associated with an amino acid and three-dimensional atomic coordinates. To convert continuous coordinates into discrete tokens, we utilize the structure VQ-VAE in ESM3 (<xref rid="btaf248-B7" ref-type="bibr">Hayes <italic toggle="yes">et al.</italic> 2025</xref>), which exhibits exceptional capability in encoding and decoding protein structures (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S6</xref>). Consequently, we represent a protein as <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the sequence tokens (i.e. amino acids), and <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> represents backbone structure tokens. Here, the superscript indicates the residue index, and <italic toggle="yes">N</italic> is the total number of residues in the protein.</p><p>Protein co-design in discrete space involves generating a protein <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula>, specifically the sequence tokens <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">s</mml:mi></mml:math></inline-formula> and the structure tokens <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">r</mml:mi></mml:math></inline-formula>. Similar to the diffusion model, the generative flow samples <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula> iteratively, from <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the initial input and <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the generated sample. Depending on the content of <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula>, the co-design paradigm encompasses a range of tasks (<xref rid="btaf248-F1" ref-type="fig">Fig.&#x000a0;1a</xref>). If <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is fully masked, the model performs unconditional co-design. If <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is given but <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is masked, the model predicts the folding of the protein. Conversely, if <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is given and <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is masked, the model performs inverse folding. Finally, if a subset of residues is given with their sequence and structure tokens, the model then scaffolds the motif. We denote the sequence mask token as <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and the structure mask as <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Additionally, we use the notation <italic toggle="yes">M</italic> to represent a generic mask when sequence and structure specifications are not distinguished.</p></sec><sec><title>2.2 The joint flow</title><p>The joint discrete generative flow, denoted as <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, represents a probability distribution that transitions smoothly from noise to data, where <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the white noise distribution <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>noise</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the data distribution <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>data</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Constructing <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> directly is non-trivial; thus, we define it through a simplified conditional flow over data points that can be explicitly modeled (<xref rid="btaf248-B3" ref-type="bibr">Campbell <italic toggle="yes">et al.</italic> 2024</xref>). Accordingly, <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is expressed as:</p><disp-formula id="E1">
<label>(1)</label>
<mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">data</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>
</disp-formula><p>As the protein <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula> comprises sequence <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">s</mml:mi></mml:math></inline-formula> and structure <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi mathvariant="bold-italic">r</mml:mi></mml:math></inline-formula>, we decompose <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> as:</p><disp-formula id="E2">
<label>(2)</label>
<mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>
</disp-formula><p>This decomposition assumes independence between sequence and structure during interpolation. Additionally, we assume residues are also independent. Consequently, for simplicity, residue-level notations such as <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are used instead of <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in the following (<inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>):</p><disp-formula id="E3">
<label>(3)</label>
<mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>
</disp-formula><p>Using linear interpolation, <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is given by:</p><disp-formula id="E4">
<label>(4)</label>
<mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>
</disp-formula><p>where <italic toggle="yes">f</italic> represents the one-hot encoding function. <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be formulated like <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Detailed derivations are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>.</p><p>The generative flow aims to sample a trajectory from <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> using a generative model parameterized by <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mi>&#x003b8;</mml:mi></mml:math></inline-formula>. Specifically, the <italic toggle="yes">t</italic>-step posterior distribution <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> can be deduced as (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S3</xref>):</p><disp-formula id="E5">
<label>(5)</label>
<mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo>&#x02009;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula><p>where <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> represents the predicted categorical distribution over the token vocabulary, ensuring that the probability of the mask token <italic toggle="yes">M</italic> is zero. <xref rid="E5" ref-type="disp-formula">Equation (5)</xref> implies that if <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the mask token <italic toggle="yes">M</italic>, <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is sampled from the predicted distribution with a probability of <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>; otherwise, <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> remains masked as <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. To enable transitions between the mask token and other states, we follow <xref rid="btaf248-B3" ref-type="bibr">Campbell <italic toggle="yes">et al.</italic> (2024)</xref> by introducing balanced noise to <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Consequently, <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> becomes:</p><disp-formula id="E6">
<label>(6)</label>
<mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext><mml:mo>&#x02009;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula><p>This adjustment introduces a bonus probability of <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>&#x003b7;</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula> for unmasking and allows <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> to transition to <italic toggle="yes">M</italic> with a probability of <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#x003b7;</mml:mi><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. Note that <xref rid="E6" ref-type="disp-formula">Equation (6)</xref> allows non-masked tokens to revert to masked only before the last sampling step. However, at the last step, this probability becomes zero, ensuring that non-masked tokens do not revert to masked at the final step.</p></sec><sec><title>2.3 Model</title><p>
<xref rid="btaf248-F1" ref-type="fig">Figure&#x000a0;1d</xref> illustrates the overall architecture of the CoFlow model. It takes sequence and structure tokens, along with the time step <italic toggle="yes">t</italic>, as input. The neural network architecture is a transformer with the initial protein representation formed by summing embeddings of sequence and structure. The model&#x02019;s trunk consists of 48 blocks, each containing a transformer variant module proposed in ESM3 (<xref rid="btaf248-B7" ref-type="bibr">Hayes <italic toggle="yes">et al.</italic> 2025</xref>), augmented by layer-wise Fourier time features. The output of CoFlow includes two distributions for each residue: sequence distribution <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> and structure distribution <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. During training, a time step <italic toggle="yes">t</italic> is randomly sampled, and the interpolated protein <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is computed according to <xref rid="E2" ref-type="disp-formula">Equation (2)</xref>. This interpolated input is used to predict <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, with the training objective defined as minimizing the cross-entropy loss. We train CoFlow using proteins ranging in length from 40 to 512 from the MGnify30 (<xref rid="btaf248-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>) dataset. As a result, CoFlow is well-suited for generating proteins with lengths up to 512. Training details can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S4</xref>.</p></sec></sec><sec><title>3 Results and discussion</title><sec><title>3.1 Unconditional generation</title><p>We first evaluate CoFlow against several strong baselines on the unconditional generation task, which involves sampling amino acid sequence and three-dimensional atom coordinates without any conditional restrictions. Following the methodology in Multiflow (<xref rid="btaf248-B3" ref-type="bibr">Campbell <italic toggle="yes">et al.</italic> 2024</xref>), we assess the generated proteins in terms of consistency, diversity, and novelty. Consistency is measured using scRMSD that quantifies the divergence between the generated backbone structure and the predicted backbone by AlphaFold2 (<xref rid="btaf248-B12" ref-type="bibr">Jumper <italic toggle="yes">et al.</italic> 2021</xref>) from the generated sequence. Diversity is defined as one minus the average pairwise TMScore (<xref rid="btaf248-B27" ref-type="bibr">Zhang and Skolnick 2004</xref>) among generated consistent proteins (scRMSD&#x02009;&#x0003c;&#x02009;2&#x02009;&#x000c5;). A high average pairwise TMScore indicates significant similarity among the generated proteins, leading to low diversity, whereas a lower TMScore suggests higher diversity. Similarly, for each generated protein, novelty is quantified as one minus the highest TMScore between it and proteins in the PDB database. A lower TMScore reflects greater novelty in the generated proteins.</p><p>In <xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2a&#x02013;c</xref>, we conduct a comparative evaluation with four ESM3 (our experiments are based on ESM3-open) variants with different sampling strategies (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S5</xref>). For each model, 500 proteins of random lengths are sampled. All four models exhibit high average backbone scRMSD values (<xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2a</xref>), indicating poor consistency between the generated sequences and their corresponding structures. Additionally, the pTM distribution of the ESM3 models demonstrates a large variance (<xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2b</xref>), suggesting that many of the generated structures are disordered (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). It indicates a significant limitation of ESM3 in unconditional structure generation. In contrast, CoFlow achieves markedly better performance compared to the four ESM3 models, with higher consistency and pTM scores. The average scRMSD for CoFlow is 3.1&#x02009;&#x000c5;, whereas the lowest average scRMSD among the ESM3 models is 24.3&#x02009;&#x000c5; (achieved by ESM3: <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>&#x02192;</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>&#x02192;</mml:mo><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow></mml:math></inline-formula>), making CoFlow&#x02019;s consistency approximately eight times that of ESM3. For pTM, CoFlow demonstrates a significantly higher mean value and lower variance than ESM3, indicating its capability to generate more plausible protein structures. Regarding diversity, CoFlow exhibits a slight superiority over ESM3 (<xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2c</xref>). Examples of proteins designed unconditionally by CoFlow are presented in <xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2e</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>.</p><fig position="float" id="btaf248-F2"><label>Figure 2.</label><caption><p>Comparison of unconditional generation. (a&#x02013;c) CoFlow is compared with ESM3 across various sampling strategies using metrics including scRMSD, pTM, and diversity. (d) The prediction accuracy for structure and sequence tokens is also evaluated in a comparative analysis between CoFlow and ESM3. (e) Illustration of two structures generated by CoFlow alongside their corresponding predictions. (f&#x02013;h) Additionally, CoFlow is benchmarked against several strong baselines in terms of scRMSD, novelty, and secondary structure distribution.</p></caption><graphic xlink:href="btaf248f2" position="float"/></fig><p>We further compare the unmasking accuracy of CoFlow and ESM3 (<xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2d</xref>). Using a hold-out dataset of 10K proteins, we linearly interpolate sequence and structure tokens over time and task both models with predicting the masked tokens. Overall, the prediction accuracy for structure tokens is lower than that for sequence tokens, which is expected given that the structure vocabulary is larger than the sequence vocabulary, making structure prediction more challenging. Notably, CoFlow demonstrates significantly higher prediction accuracy than ESM3, particularly for structure tokens. This enhanced accuracy in structure prediction reinforces the superior consistency of CoFlow compared to ESM3.</p><p>CoFlow is also compared with previous strong baselines, including backbone structure generation models such as FrameDiff (<xref rid="btaf248-B25" ref-type="bibr">Yim <italic toggle="yes">et al.</italic> 2023</xref>), RFDiffusion (<xref rid="btaf248-B24" ref-type="bibr">Watson <italic toggle="yes">et al.</italic> 2023</xref>), and Proteus (<xref rid="btaf248-B23" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024</xref>), as well as protein co-design models like Chroma (<xref rid="btaf248-B10" ref-type="bibr">Ingraham <italic toggle="yes">et al.</italic> 2023</xref>), MultiFlow (<xref rid="btaf248-B3" ref-type="bibr">Campbell <italic toggle="yes">et al.</italic> 2024</xref>), Protpardelle (<xref rid="btaf248-B4" ref-type="bibr">Chu <italic toggle="yes">et al.</italic> 2024</xref>), and ProteinGenerator (<xref rid="btaf248-B16" ref-type="bibr">Lisanza <italic toggle="yes">et al.</italic> 2024</xref>). For each model, we generate 100 proteins with lengths of 100, 200, 300, 400, and 500 residues. For structure design baselines, we additionally use ProteinMPNN (<xref rid="btaf248-B5" ref-type="bibr">Dauparas <italic toggle="yes">et al.</italic> 2022</xref>) to design sequences for the generated backbones. As shown in <xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2f</xref>, CoFlow exhibits comparable consistency with previous models for proteins shorter than 300 residues. However, it outperforms other baselines in generating proteins of 400 and 500 residues, highlighting its advantage in handling long proteins. In terms of novelty, CoFlow achieves performance comparable to Chroma, Proteus, MultiFlow, Protpardelle, and Proteingenerator (<xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2g</xref>). Furthermore, we examine the secondary structure distributions of all models in comparison to those of natural proteins from the PDB database. As illustrated in <xref rid="btaf248-F2" ref-type="fig">Fig.&#x000a0;2h</xref>, the secondary structure distribution of CoFlow closely approximates that of RFDiffusion, but inferior to another co-design method Protpardelle.</p></sec><sec><title>3.2 Conditional generation</title><p>Next, we conduct experiments to evaluate the performance of CoFlow on conditional generation tasks, including motif-scaffolding, folding, and inverse folding. Motif-scaffolding (<xref rid="btaf248-B21" ref-type="bibr">Trippe <italic toggle="yes">et al.</italic> 2023</xref>) involves generating a compatible scaffold while preserving a given motif structure. Folding (<xref rid="btaf248-B12" ref-type="bibr">Jumper <italic toggle="yes">et al.</italic> 2021</xref>) aims to predict the 3D structure of a specified amino acid sequence, whereas inverse folding (<xref rid="btaf248-B5" ref-type="bibr">Dauparas <italic toggle="yes">et al.</italic> 2022</xref>) seeks to reconstruct the amino acid sequence from a given 3D structure.</p><p>For the motif-scaffolding task, we use the dataset curated by <xref rid="btaf248-B26" ref-type="bibr">Yim <italic toggle="yes">et al.</italic> (2024)</xref>, which includes 24 specific scaffolding problems. For each problem, we randomly sample lengths that satisfy the given constraints, keeping the sequence and structure tokens of the specified motif unchanged while masking all other tokens. These inputs are then provided to the generative model to sample 100 candidates. A generated sample is considered successful if it meets two criteria: (1) the TMScore between the generated structure and the predicted structure exceeds 0.8, and (2) the predicted motif structure matches the native structure with a backbone RMSD of less than 1&#x02009;&#x000c5;. Like the setting in unconditional generation, we compare CoFlow against four models: the first generates sequences using ESM3 and predicts structures with ESMFold (<xref rid="btaf248-B15" ref-type="bibr">Lin <italic toggle="yes">et al.</italic> 2023</xref>); the second generates structures with ESM3 and predicts sequences using ProteinMPNN (<xref rid="btaf248-B5" ref-type="bibr">Dauparas <italic toggle="yes">et al.</italic> 2022</xref>); the last two employ ESM3 to generate sequences and structures in different orders. <xref rid="btaf248-F3" ref-type="fig">Figure&#x000a0;3a</xref> shows that CoFlow effectively generates reasonable scaffolds for the given functional motifs, successfully solving 20 out of 24 problems and outperforming all ESM3-based models. Additionally, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref> illustrates successful scaffolds for each motif generated by CoFlow.</p><fig position="float" id="btaf248-F3"><label>Figure 3.</label><caption><p>Comparison with ESM3 on conditional generation. (a) Solved problems in the motif-scaffolding task. (b) Backbone RMSD for structure prediction. (c) Recovery rate in the inverse folding task.</p></caption><graphic xlink:href="btaf248f3" position="float"/></fig><p>For the folding and inverse folding tasks, we utilize the test dataset curated by <xref rid="btaf248-B3" ref-type="bibr">Campbell <italic toggle="yes">et al.</italic> (2024)</xref>, which consists of 438 monomers excluded from the fine-tuning dataset. We evaluate the performance of ESM3 and CoFlow by comparing the backbone RMSD between predicted and ground truth structures. As shown in <xref rid="btaf248-F3" ref-type="fig">Fig.&#x000a0;3b</xref>, CoFlow achieves superior performance over ESM3 in a zero-shot setting. For the inverse folding task, we evaluate the average native sequence recovery (NSR) of CoFlow and ESM3. <xref rid="btaf248-F3" ref-type="fig">Figure&#x000a0;3c</xref> demonstrates that CoFlow achieves an average NSR of 0.56, compared to 0.5 for ESM3, indicating that CoFlow is more effective in generating accurate sequences that fold into the specified structures.</p></sec><sec><title>3.3 Ablation study</title><p>We evaluate the impact of sampling steps on protein generation. Specifically, we randomly sample 200 proteins using sampling steps of 50, 100, 200, 400, and 1200 and compare the generation entropy sum of sequence and structure, as well as the pTM score of the generated structure. <xref rid="btaf248-F4" ref-type="fig">Figure&#x000a0;4a</xref> shows that the entropy gradually decreases as the number of sampling steps increases. Similarly, <xref rid="btaf248-F4" ref-type="fig">Fig.&#x000a0;4b</xref> illustrates that the average pTM score improves with more sampling steps. These results indicate that increasing the number of sampling steps enables the model to generate proteins with greater confidence. However, the improvement is not linear; the gain diminishes as the number of steps increases. For instance, increasing the sampling steps from 50 to 400 almost doubles the average pTM score, whereas further increasing the steps to 1200 yields only a marginal improvement. Based on this analysis, we set the sampling steps to 400 to achieve a balance between sampling efficiency and generation quality. We also evaluate the entropy of ESM3 across different sampling steps (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>). Its entropy remains nearly constant when the sampling steps exceed 200, converging from a maximum of 2.9 to 2.5. In contrast, CoFlow exhibits a continuous decrease in entropy as the sampling steps increase, dropping from 3.4 to 2.3 (<xref rid="btaf248-F4" ref-type="fig">Fig.&#x000a0;4a</xref>). This indicates that the gain provided by increasing sampling steps is relatively smaller for ESM3 compared to CoFlow.</p><fig position="float" id="btaf248-F4"><label>Figure 4.</label><caption><p>Ablation study. Generation entropy (a) and pTM distribution of generated structures (b) with different sampling steps. Generation entropy (c) and pTM distribution of generated structures (d) with different sampling strategies. (e) pTM distribution of structures generated by ESM3, ESM3 equipped with generative flow, and CoFlow.</p></caption><graphic xlink:href="btaf248f4" position="float"/></fig><p>We validate the four sampling strategies (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S5</xref>) to explore the effect of generation order for sequence and structure tokens. These strategies produce similar pTM scores for the generated structures (<xref rid="btaf248-F4" ref-type="fig">Fig.&#x000a0;4d</xref>). However, the asynchronous strategy achieves the lowest generation entropy (<xref rid="btaf248-F4" ref-type="fig">Fig.&#x000a0;4c</xref>). The result is consistent with the intuitive understanding that alternating the generation of sequence and structure tokens allows the model to more effectively capture the complex correlations between them, thereby enhancing generation quality. Consequently, we adopt the asynchronous sampling strategy in unconditional generation.</p><p>Since CoFlow shares a similar training objective with ESM3, i.e. predicting masked tokens, we evaluate the effectiveness of directly integrating ESM3 with the flow model. <xref rid="btaf248-F4" ref-type="fig">Figure&#x000a0;4</xref> presents the pTM distribution of structures generated by the three models using kernel density estimation. The results indicate that while ESM3 combined with discrete flow performs comparably to its naive counterpart, CoFlow exhibits significant superiority over both. We attribute this performance improvement to two key factors. First, ESM3 is trained with a masking ratio of approximately 25%&#x02013;30%, whereas CoFlow is trained with a variable masking ratio ranging from 0% to 100%. Consequently, ESM3 struggles when generating from scratch, as it lacks initial token guidance, leading to its underperformance in this comparison. Second, ESM3 does not incorporate a time feature, meaning it lacks an explicit mechanism to track the progression of iterative generation. In contrast, CoFlow integrates time features, allowing it to dynamically adjust its generation process at different stages, thereby facilitating high-quality iterative generation.</p></sec></sec><sec><title>4 Conclusion</title><p>In this article, we propose CoFlow, a discrete flow-based model designed to jointly generate protein sequence and structure. Our experiments demonstrate that CoFlow outperforms ESM3 and other strong baselines across various generation tasks. Despite these promising results, several limitations warrant further investigation. One limitation is that CoFlow does not currently incorporate or generate side-chain structures, which are known to be critical for improving the accuracy and realism of molecular modeling. While this aspect lies beyond the current scope and objectives of our work, we recognize its importance and consider it a key direction for future research to further enhance the precision and biological applicability of CoFlow. Large language models consistently adhere to scaling laws, wherein performance improves with increased model size, given sufficient data and computational resources. Although our model is currently constrained in parameter scale, it has already achieved notable results, suggesting that further scaling of model size or training data could unlock additional potential and significantly enhance performance. Additionally, our work has primarily focused on monomer design and has not yet addressed the design of protein complexes, underscoring a critical direction for future research. Lastly, our evaluation of CoFlow has been limited to <italic toggle="yes">in silico</italic> experiments. Wet-lab validation remains essential for a comprehensive assessment of the model&#x02019;s practical utility and constitutes a key focus for future studies.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data"><label>btaf248_Supplementary_Data</label><media xlink:href="btaf248_supplementary_data.pdf"/></supplementary-material></sec></body><back><sec><title>Author contributions</title><p>Sen Yang (Conceptualization [lead], Data curation [lead], Methodology [lead], Resources [lead], Writing&#x02014;original draft [lead], Writing&#x02014;review &#x00026; editing [equal]), Lingli Ju (Funding acquisition [equal], Validation [equal]), Peng Cheng (Formal analysis [equal], Writing&#x02014;review &#x00026; editing [equal]), Jianglin Zhou (Formal analysis [equal], Validation [equal]), and Yamin Cai (Funding acquisition [Supporting], Validation [Supporting]), Dawei Feng(Investigation [lead], Supervision [lead], Writing&#x02014;review &#x00026; editing [equal])</p></sec><sec><title>Supplementary data</title><p>
<xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p><p>Conflict of interest: None declared.</p></sec><sec><title>Funding</title><p>This work is supported by funds from the National Natural Science Foundation of China under Grant No. 62306334 and No. 81830101, the Open Fund of PDL No. WDZC20245250107.</p></sec><sec><title>Code availability</title><p>Source codes in this study are available at <ext-link xlink:href="https://github.com/LtECoD/CoFlow" ext-link-type="uri">https://github.com/LtECoD/CoFlow</ext-link> and <ext-link xlink:href="https://zenodo.org/records/14842367" ext-link-type="uri">https://zenodo.org/records/14842367</ext-link>.</p></sec><ref-list id="ref1"><title>References</title><ref id="btaf248-B1"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Anand</surname>
<given-names>N</given-names>
</string-name>, <string-name><surname>Achim</surname><given-names>T.</given-names></string-name></person-group> Protein structure and sequence generation with equivariant denoising diffusion probabilistic models. In: <italic toggle="yes">NeurIPS, Machine Learning in Structural Biology Workshop,</italic> New Orleans, Louisiana, USA: Neural Information Processing Systems Foundation, <year>2022.</year></mixed-citation></ref><ref id="btaf248-B2"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Brown</surname>
<given-names>T</given-names>
</string-name>, <string-name><surname>Mann</surname><given-names>B</given-names></string-name>, <string-name><surname>Ryder</surname><given-names>N</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> Language models are few-shot learners. In: <italic toggle="yes">NeurIPS</italic>, Vol. 33. online, Neural Information Processing Systems Foundation, <year>2020</year>, <fpage>1877</fpage>&#x02013;<lpage>901</lpage>.</mixed-citation></ref><ref id="btaf248-B3"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Campbell</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Yim</surname><given-names>J</given-names></string-name>, <string-name><surname>Barzilay</surname><given-names>R</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> Generative flows on discrete state-spaces: enabling multimodal flows with applications to protein co-design. In: <italic toggle="yes">Proceedings of the 41st ICML</italic>. Vienna, Austria: International Conference on Machine Learning, <year>2024</year>.</mixed-citation></ref><ref id="btaf248-B4"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Chu</surname>
<given-names>AE</given-names>
</string-name>, <string-name><surname>Kim</surname><given-names>J</given-names></string-name>, <string-name><surname>Cheng</surname><given-names>L</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>An all-atom protein generative model</article-title>. <source>Proc Natl Acad Sci USA</source> &#x000a0;<year>2024</year>;<volume>121</volume>:<fpage>e2311500121</fpage>.<pub-id pub-id-type="pmid">38916999</pub-id>
</mixed-citation></ref><ref id="btaf248-B5"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Dauparas</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Anishchenko</surname><given-names>I</given-names></string-name>, <string-name><surname>Bennett</surname><given-names>N</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Robust deep learning-based protein sequence design using ProteinMPNN</article-title>. <source>Science</source> &#x000a0;<year>2022</year>;<volume>378</volume>:<fpage>49</fpage>&#x02013;<lpage>56</lpage>.<pub-id pub-id-type="pmid">36108050</pub-id>
</mixed-citation></ref><ref id="btaf248-B6"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ferruz</surname>
<given-names>N</given-names>
</string-name>, <string-name><surname>Schmidt</surname><given-names>S</given-names></string-name>, <string-name><surname>H&#x000f6;cker</surname><given-names>B.</given-names></string-name></person-group> &#x000a0;<article-title>ProtGPT2 is a deep unsupervised language model for protein design</article-title>. <source>Nat Commun</source> &#x000a0;<year>2022</year>;<volume>13</volume>:<fpage>4348</fpage>.<pub-id pub-id-type="pmid">35896542</pub-id>
</mixed-citation></ref><ref id="btaf248-B7"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hayes</surname>
<given-names>T</given-names>
</string-name>, <string-name><surname>Rao</surname><given-names>R</given-names></string-name>, <string-name><surname>Akin</surname><given-names>H</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Simulating 500 million years of evolution with a language model</article-title>. <source>Science</source> &#x000a0;<year>2025</year>;<volume>387</volume>:<fpage>850</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">39818825</pub-id>
</mixed-citation></ref><ref id="btaf248-B8"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ho</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Jain</surname><given-names>A</given-names></string-name>, <string-name><surname>Abbeel</surname><given-names>P.</given-names></string-name></person-group> &#x000a0;<article-title>Denoising diffusion probabilistic models</article-title>. <source>NeurIPS</source> &#x000a0;<year>2020</year>;<volume>33</volume>:<fpage>6840</fpage>&#x02013;<lpage>51</lpage>.</mixed-citation></ref><ref id="btaf248-B9"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Huang</surname>
<given-names>PS</given-names>
</string-name>, <string-name><surname>Boyken</surname><given-names>SE</given-names></string-name>, <string-name><surname>Baker</surname><given-names>D.</given-names></string-name></person-group> &#x000a0;<article-title>The coming of age of de novo protein design</article-title>. <source>Nature</source> &#x000a0;<year>2016</year>;<volume>537</volume>:<fpage>320</fpage>&#x02013;<lpage>7</lpage>.<pub-id pub-id-type="pmid">27629638</pub-id>
</mixed-citation></ref><ref id="btaf248-B10"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ingraham</surname>
<given-names>JB</given-names>
</string-name>, <string-name><surname>Baranov</surname><given-names>M</given-names></string-name>, <string-name><surname>Costello</surname><given-names>Z</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Illuminating protein space with a programmable generative model</article-title>. <source>Nature</source> &#x000a0;<year>2023</year>;<volume>623</volume>:<fpage>1070</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">37968394</pub-id>
</mixed-citation></ref><ref id="btaf248-B11"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Joubbi</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Micheli</surname><given-names>A</given-names></string-name>, <string-name><surname>Milazzo</surname><given-names>P</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Antibody design using deep learning: from sequence and structure design to affinity maturation</article-title>. <source>Brief Bioinform</source> &#x000a0;<year>2024</year>;<volume>25</volume>:<fpage>bbae307</fpage>.<pub-id pub-id-type="pmid">38960409</pub-id>
</mixed-citation></ref><ref id="btaf248-B12"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Jumper</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Evans</surname><given-names>R</given-names></string-name>, <string-name><surname>Pritzel</surname><given-names>A</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Highly accurate protein structure prediction with alphafold</article-title>. <source>Nature</source> &#x000a0;<year>2021</year>;<volume>596</volume>:<fpage>583</fpage>&#x02013;<lpage>9</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id>
</mixed-citation></ref><ref id="btaf248-B13"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Langan</surname>
<given-names>RA</given-names>
</string-name>, <string-name><surname>Boyken</surname><given-names>SE</given-names></string-name>, <string-name><surname>Ng</surname><given-names>AH</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>De novo design of bioactive protein switches</article-title>. <source>Nature</source> &#x000a0;<year>2019</year>;<volume>572</volume>:<fpage>205</fpage>&#x02013;<lpage>10</lpage>.<pub-id pub-id-type="pmid">31341284</pub-id>
</mixed-citation></ref><ref id="btaf248-B14"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Leman</surname>
<given-names>JK</given-names>
</string-name>, <string-name><surname>Weitzner</surname><given-names>BD</given-names></string-name>, <string-name><surname>Lewis</surname><given-names>SM</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Macromolecular modeling and design in Rosetta: recent methods and frameworks</article-title>. <source>Nat Methods</source> &#x000a0;<year>2020</year>;<volume>17</volume>:<fpage>665</fpage>&#x02013;<lpage>80</lpage>.<pub-id pub-id-type="pmid">32483333</pub-id>
</mixed-citation></ref><ref id="btaf248-B15"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lin</surname>
<given-names>Z</given-names>
</string-name>, <string-name><surname>Akin</surname><given-names>H</given-names></string-name>, <string-name><surname>Rao</surname><given-names>R</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Evolutionary-scale prediction of atomic-level protein structure with a language model</article-title>. <source>Science</source> &#x000a0;<year>2023</year>;<volume>379</volume>:<fpage>1123</fpage>&#x02013;<lpage>30</lpage>.<pub-id pub-id-type="pmid">36927031</pub-id>
</mixed-citation></ref><ref id="btaf248-B16"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lisanza</surname>
<given-names>SL</given-names>
</string-name>, <string-name><surname>Gershon</surname><given-names>JM</given-names></string-name>, <string-name><surname>Tipps</surname><given-names>SWK</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Multistate and functional protein design using RoseTTAFold sequence space diffusion</article-title>. <source>Nat Biotechnol</source> &#x000a0;<year>2024</year>:<fpage>1</fpage>&#x02013;<lpage>11</lpage>.<pub-id pub-id-type="pmid">38191665</pub-id>
</mixed-citation></ref><ref id="btaf248-B17"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Madani</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Krause</surname><given-names>B</given-names></string-name>, <string-name><surname>Greene</surname><given-names>ER</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Large language models generate functional protein sequences across diverse families</article-title>. <source>Nat Biotechnol</source> &#x000a0;<year>2023</year>;<volume>41</volume>:<fpage>1099</fpage>&#x02013;<lpage>106</lpage>.<pub-id pub-id-type="pmid">36702895</pub-id>
</mixed-citation></ref><ref id="btaf248-B18"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ming</surname>
<given-names>Y</given-names>
</string-name>, <string-name><surname>Wang</surname><given-names>W</given-names></string-name>, <string-name><surname>Yin</surname><given-names>R</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>A review of enzyme design in catalytic stability by artificial intelligence</article-title>. <source>Brief Bioinform</source> &#x000a0;<year>2023</year>;<volume>24</volume>:<fpage>bbad065</fpage>.<pub-id pub-id-type="pmid">36971385</pub-id>
</mixed-citation></ref><ref id="btaf248-B19"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Polizzi</surname>
<given-names>NF</given-names>
</string-name>, <string-name><surname>DeGrado</surname><given-names>WF.</given-names></string-name></person-group> &#x000a0;<article-title>A defined structural unit enables de novo design of small-molecule&#x02013;binding proteins</article-title>. <source>Science</source> &#x000a0;<year>2020</year>;<volume>369</volume>:<fpage>1227</fpage>&#x02013;<lpage>33</lpage>.<pub-id pub-id-type="pmid">32883865</pub-id>
</mixed-citation></ref><ref id="btaf248-B20"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Ren</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Zhu</surname><given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>H.</given-names></string-name></person-group> CarbonNovo: Joint design of protein structure and sequence using a unified energy-based model. In: <italic toggle="yes">Proceedings of the 41st ICML.</italic> Vienna, Austria: International Conference on Machine Learning, 2024.</mixed-citation></ref><ref id="btaf248-B21"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Trippe</surname>
<given-names>BL</given-names>
</string-name>, <string-name><surname>Yim</surname><given-names>J</given-names></string-name>, <string-name><surname>Tischer</surname><given-names>D</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem. In: <italic toggle="yes">ICLR</italic>. Kigali, Rwanda: International Conference on Learning Representations, <year>2023</year>.</mixed-citation></ref><ref id="btaf248-B22"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Van Den Oord</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Vinyals</surname><given-names>O</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>Neural discrete representation learning</article-title>. <source>NeurIPS</source>. Long Beach, California, USA: Neural Information Processing Systems Foundation, <year>2017.</year></mixed-citation></ref><ref id="btaf248-B23"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname>
<given-names>C</given-names>
</string-name>, <string-name><surname>Qu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Peng</surname><given-names>Z</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> Proteus: exploring protein structure generation for enhanced designability and efficiency. In: <italic toggle="yes">Proceedings of the 41st ICML.</italic> Vienna, Austria: International Conference on Machine Learning, 2024.</mixed-citation></ref><ref id="btaf248-B24"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Watson</surname>
<given-names>JL</given-names>
</string-name>, <string-name><surname>Juergens</surname><given-names>D</given-names></string-name>, <string-name><surname>Bennett</surname><given-names>NR</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> &#x000a0;<article-title>De novo design of protein structure and function with RFdiffusion</article-title>. <source>Nature</source> &#x000a0;<year>2023</year>;<volume>620</volume>:<fpage>1089</fpage>&#x02013;<lpage>100</lpage>.<pub-id pub-id-type="pmid">37433327</pub-id>
</mixed-citation></ref><ref id="btaf248-B25"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Yim</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Trippe</surname><given-names>BL</given-names></string-name>, <string-name><surname>De Bortoli</surname><given-names>V</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> SE(3) diffusion model with application to protein backbone generation. In: <italic toggle="yes">Proceedings of the 40th ICML.</italic> Honolulu, Hawaii, USA: International Conference on Machine Learning, <year>2023</year>.</mixed-citation></ref><ref id="btaf248-B26"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Yim</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Campbell</surname><given-names>A</given-names></string-name>, <string-name><surname>Mathieu</surname><given-names>E</given-names></string-name></person-group> &#x000a0;<etal>et al</etal> Improved motif-scaffolding with SE(3) flow matching. In: <italic toggle="yes">ICLR 2024 Workshop on Generative and Experimental Perspectives for Biomolecular Design</italic>. Vienna, Austria: International Conference on Learning Representations, <year>2024</year>.</mixed-citation></ref><ref id="btaf248-B27"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname>
<given-names>Y</given-names>
</string-name>, <string-name><surname>Skolnick</surname><given-names>J.</given-names></string-name></person-group> &#x000a0;<article-title>Scoring function for automated assessment of protein structure template quality</article-title>. <source>Proteins</source> &#x000a0;<year>2004</year>;<volume>57</volume>:<fpage>702</fpage>&#x02013;<lpage>10</lpage>.<pub-id pub-id-type="pmid">15476259</pub-id>
</mixed-citation></ref></ref-list></back></article>