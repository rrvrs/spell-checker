<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="data-paper" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Data</journal-id><journal-id journal-id-type="iso-abbrev">Sci Data</journal-id><journal-title-group><journal-title>Scientific Data</journal-title></journal-title-group><issn pub-type="epub">2052-4463</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39730327</article-id><article-id pub-id-type="pmc">PMC11680833</article-id><article-id pub-id-type="publisher-id">4336</article-id><article-id pub-id-type="doi">10.1038/s41597-024-04336-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Data Descriptor</subject></subj-group></article-categories><title-group><article-title>An image and video dataset of nesting green sea turtles with annotated data</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9901-4469</contrib-id><name><surname>Hipiny</surname><given-names>Irwandi</given-names></name><address><email>mhihipni@unimas.my</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Ujir</surname><given-names>Hamimah</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Hassan</surname><given-names>Ruhana</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Abang Aimran</surname><given-names>Abang Arabi</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05b307002</institution-id><institution-id institution-id-type="GRID">grid.412253.3</institution-id><institution-id institution-id-type="ISNI">0000 0000 9534 9846</institution-id><institution>Universiti Malaysia Sarawak, </institution><institution>Faculty of Computer Science and Information Technology, </institution></institution-wrap>Sarawak, 94300 Malaysia </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05b307002</institution-id><institution-id institution-id-type="GRID">grid.412253.3</institution-id><institution-id institution-id-type="ISNI">0000 0000 9534 9846</institution-id><institution>Universiti Malaysia Sarawak, </institution><institution>Faculty of Resource Science Technology, </institution></institution-wrap>Sarawak, 94300 Malaysia </aff><aff id="Aff3"><label>3</label>Sarawak Forestry Corporation, Sarawak, 93250 Malaysia </aff></contrib-group><pub-date pub-type="epub"><day>27</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>27</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>11</volume><elocation-id>1441</elocation-id><history><date date-type="received"><day>28</day><month>8</month><year>2024</year></date><date date-type="accepted"><day>18</day><month>12</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Photo- and video-based reidentification of green sea turtles using their natural markers is far less invasive than artificial tagging. An RGB camera mounted on a man-portable rig, was used to collect video data on Greater Talang Island (1 &#x000b0;54&#x02019;45&#x02033;N 109 &#x000b0;46&#x02019;33&#x02033;E) from September to October 2022, and September 2023. This islet is located 30 minutes offshore from the Sematan district in Southwest Sarawak, Malaysia. In total, 42 videos of 42 unique individuals were captured, from which 14,471 video frames were extracted and annotated with a bounding box each. Through manual inspection, the annotation data were diligently checked and edited if necessary. Additionally, 130 selected frames were further annotated each with a region-of-interest mask containing only the carapace. These data have the potential to aid researchers in training computer vision models for various tasks such as counting, segmentation and individual reidentification.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Zoology</kwd><kwd>Research data</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">501100003093</institution-id><institution>Ministry of Higher Education, Malaysia (MOHE)</institution></institution-wrap></funding-source><award-id>FRGS/1/2021/ICT02/UNIMAS/02/1</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background &#x00026; Summary</title><p id="Par2">The iconic green sea turtles (<italic>Chelonia mydas</italic>) are an important part of Sarawak&#x02019;s coastal ecosystem. They are recognized as endangered under the International Union for Conservation of Nature (IUCN) Red List of Threatened Species<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, and are totally protected in Sarawak, under the Wild Life Protection Ordinance 1998<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. To aid in their conservation effort, several active nesting sites in Sarawak were declared as a Totally Protected Area (TPA)<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> to limit interactions with humans and support population growth via the establishment of natural hatcheries. To estimate the population size and understand migratory behavior, nesting individuals captured within the TPAs are tagged by affixing a metal tag with a unique ID to each front flipper, enabling future reidentification. Records of turtle landings and nests at Greater Talang and the surrounding areas have been maintained since 1946<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>.</p><p id="Par3">Unfortunately, the artificial tagging practice places significant stress on the sea turtles<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. Moreover, there is a high risk of tag loss<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. While reidentifying individuals based on photos of their natural markers (i.e., facial scales, flipper scales, scutes pattern, and pigmentation pattern), holds promise, its efficacy is hampered by the time required to process the data. Hence, automating the tasks using computer models has emerged as an ideal solution. These natural markers are either found on the facial areas, flippers, or carapace. The carapace, being the largest body part of a green sea turtle, is easier to photograph in a less invasive manner. Examples of natural markers found on the carapace include the scutes pattern<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> and the pigmentation pattern (on the posterior part)<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>.</p><p id="Par4">This motivated the collection of video data at Greater Talang, one of the four islets that form Talang-Satang National Park. The islets are surrounded by shallow coral reefs that provide shelter and resting grounds for grazing sea turtles. In 2017, Greater Talang recorded the highest number of landings, with 1,881, followed by Lesser Talang with 838 landings, and Greater Satang with 215 landings<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>. Landings at Greater Talang peak during the dry season<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, i.e., from May until September each year, and subside during the rough monsoon weather from November until April of the following year. During the monsoon season, the rough sea disperses the sand at the small beach area at the southern tip of Greater Talang, refer to Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>, rendering it unsuitable for egg laying<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>.<fig id="Fig1"><label>Fig. 1</label><caption><p>A satellite image of Greater Talang Island, Sarawak, Malaysia, sourced from Google Earth<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. The sandy beach area is situated at the southern tip of the island, where most of the nesting activities are concentrated.</p></caption><graphic xlink:href="41597_2024_4336_Fig1_HTML" id="d33e254"/></fig></p><p id="Par5">Videos were collected from September to October 2022 and September 2023 using an RGB camera mounted on a man-portable rig. The rig, including the camera, weighs approximately 8.5 kg and can be carried on a person or temporarily planted on a porous surface. An ideal setup would consist of many stationary cameras arranged in a grid to ensure maximum coverage of the beach area. However, due to cost limitations and permit&#x02019;s constraints, the decision was made to employ a man-portable rig instead.</p><p id="Par6">There is a common consensus that green sea turtles randomly select their nest excavation site<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. Another theory suggests beach topography as the determining factor<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. Therefore, permanently planting the camera rig at an identified hotspot is possible. Nevertheless, a mobile setup increases the number of possible recordings since the data collection team can quickly relocate to another individual once the current recording is completed.</p><p id="Par7">A video frame with a bounding box annotation indicates the presence of a green sea turtle, and vice versa. Samples with varying quality levels are shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. An ROI mask separates the foreground, specifically, the carapace, from the background. Annotation data for each frame are stored inside a paired JSON file. The visualized ROI mask samples are shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>. The research team had published two prior works using the annotated dataset<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. The first article<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> reported the performance of a pre-trained YOLOv7 model<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> on a bounding box detection task. The second article<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> evaluated the instance segmentation performance of Mask R-CNN<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> by comparing it to manually annotated ROI masks on contrast-equalized images.<fig id="Fig2"><label>Fig. 2</label><caption><p>Bounding box image samples with varying quality levels: (<bold>a</bold>) good, (<bold>b</bold>) slight blurring, (<bold>c</bold>) strong blurring, (<bold>d</bold>) excessive blurring, (<bold>e</bold>) partially-visible (occlusion), (<bold>f</bold>) JPEG compression, and (<bold>g</bold>) illumination change. Image blurring and out-of-plane transformations were due to the camera&#x02019;s motion invoked by the rig operator&#x02019;s movement and/or strong winds. Illumination varies due to the amount of moonlight received. The dimensions of the bounding box are nonuniform and depend on the size of the enclosed sea turtle. A short video showcasing the bounding box annotations across continuous frames is available on the author&#x02019;s YouTube page (<ext-link ext-link-type="uri" xlink:href="https://youtu.be/aLRbj9gdFEg">https://youtu.be/aLRbj9gdFEg</ext-link>).</p></caption><graphic xlink:href="41597_2024_4336_Fig2_HTML" id="d33e329"/></fig><fig id="Fig3"><label>Fig. 3</label><caption><p>(<bold>a</bold>) - (<bold>e</bold>) Visualized ROI mask samples. In most cases, the edges of the carapace are easily identifiable, except for the top and bottom parts where extra attention is required to visually separate the hard shell from the soft body parts, i.e., the head, body, and flippers. A side-view image<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, (<bold>f</bold>), of a green sea turtle is provided as a visual reference.</p></caption><graphic xlink:href="41597_2024_4336_Fig3_HTML" id="d33e350"/></fig></p><p id="Par8">Public wildlife video and/or photo datasets are abundant, but only a small number exist for sea turtles. SeaTurtleID2022<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> is a large-scale, long-span dataset containing timestamped photos of free-swimming loggerheads, captured during snorkeling surveys from distances ranging from 7 meters to a few centimeters. The dataset contains 8,729 photos of 438 individuals collected over a 13-year period. Annotation data include identity, encounter timestamps, and segmentation masks for body parts (i.e., head, carapace, and flippers). The photos were captured at large time intervals, thus enabling the use of time-aware splits during training and validation. Another large public dataset, TurtleSpot Taiwan<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>, contains 3,515 crowdsourced sea turtle sighting photos of 762 individuals, captured underwater or on land. The included species are Greens, Hawksbills, and Olive Ridleys. The annotation data included sighting location, date, time, depth, observation method, and photographs of the whole body as well as the left and right faces. Smaller public datasets, such as ZindiTurtleRecall<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> and PANDANCHELOMY<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, are also available, but these datasets typically have minimal annotation data. The two datasets contain photos of sea turtles captured on land in a controlled environment. Side-by-side comparisons of the datasets are shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Comparison with existing datasets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">SeaTurtleID 2022<sup><xref ref-type="bibr" rid="CR19">19</xref></sup></th><th align="left">TurtleSpot Taiwan<sup><xref ref-type="bibr" rid="CR20">20</xref></sup></th><th align="left">ZindiTurtle Recall<sup><xref ref-type="bibr" rid="CR21">21</xref></sup></th><th align="left">PANDAN CHELOMY<sup><xref ref-type="bibr" rid="CR7">7</xref></sup></th><th align="left">GTST-2023<sup><xref ref-type="bibr" rid="CR14">14</xref></sup></th></tr></thead><tbody><tr><td>Species</td><td>Loggerhead.</td><td>Green, Hawksbill and Olive Ridley.</td><td>Green and Hawksbill.</td><td>Green (Juvenile).</td><td>Green.</td></tr><tr><td>Modality</td><td>Photos.</td><td>Photos.</td><td>Photos.</td><td>Photos.</td><td>Photos and videos.</td></tr><tr><td>Environment</td><td>Underwater.</td><td>Both.</td><td>On land.</td><td>On land.</td><td>On land.</td></tr><tr><td>Dataset size</td><td>8,729 photos of 438 individuals.</td><td>3,515 photos of 762 individuals.</td><td>300 photos of 100 individuals (training set).</td><td>70 photos of 16 individuals.</td><td>42 videos of 42 individuals. 14,471 photos.</td></tr><tr><td>Target body part(s)</td><td>Whole body.</td><td>Whole body, left and right face.</td><td>Top, left, and right face.</td><td>Carapace.</td><td>Carapace.</td></tr><tr><td>Annotation data</td><td>Identity, encounter timestamp, and segmentation masks.</td><td>Crowd-sourced: Sighting location, date, time, depth and observation method. Inferred: Identity, sex, life stage, behaviour, taxa and physical abnormality (if any).</td><td>Identity and face pose.</td><td>Identity.</td><td>Identity, bounding box coordinates and labels, and segmentation masks.</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec2"><title>Methods</title><p id="Par9">The production of the dataset<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> involved a multistage process, shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>. This section describes each stage in detail.<fig id="Fig4"><label>Fig. 4</label><caption><p>The multistage dataset production process.</p></caption><graphic xlink:href="41597_2024_4336_Fig4_HTML" id="d33e514"/></fig></p><p id="Par10">The experimental protocol described in this section was reviewed and approved by a research review committee under the jurisdiction of Sarawak Forestry Corporation. The permits (permit numbers: SFC.810-4/6/1 (2021) - 73 and SFC.810-4/6/1 (2023) - 075) were issued only after receiving a successful approval.</p><p id="Par11">Stage one involves video collection, which is performed during two separate periods: September to October 2022 and September 2023. A man-portable rig, as shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>, weighing approximately 8.5 kg was used to capture the videos. The rig has a CCTV camera, powered by an external battery with a capacity of 50,000 milliamp-hours, ensuring extended operational time. The rig was built using extendable poles, adjustable to a height of 1.5 to 2.1 meters, and can be hoisted up to 3 meters above the ground.<fig id="Fig5"><label>Fig. 5</label><caption><p>The man-portable camera rig.</p></caption><graphic xlink:href="41597_2024_4336_Fig5_HTML" id="d33e528"/></fig></p><p id="Par12">The recordings were made at night, in near darkness, with only moonlight as the primary source of illumination. The camera does emit infrared light, but it is minimal. In a typical scenario, park wardens alert the data collection team to the presence of a nesting green sea turtle on the beach. The team begins to approach and record only after the individual has finished covering the new nest with sand. In some cases, recording starts only after the park wardens have completed the tagging and measurement activities, when the green sea turtle is already making its way back to the sea. During recording, the team positions the downwards-facing camera at an appropriate height and as perpendicular as possible to the carapace. The camera position is maintained for a period of time to obtain sharp and in-focus images of the carapace.</p><p id="Par13">Stage two is video encoding. A total of 42 videos, each featuring a unique green sea turtle, were successfully collected over the two data collection periods. The videos were encoded using the H264 MPEG-4 codec, at an original resolution of 2,560 x 1,920 and a frame rate of 20 FPS. The total size for all videos is 1.66 GB.</p><p id="Par14">During stage three, video frames were extracted every fifth frame. This is a good interval for capturing sea turtles&#x02019; laboured movement on land, resulting in 14,471 video frames. The videos were not trimmed, thereby including background noise inside the data.</p><p id="Par15">Stage four involves the iterative and exhaustive process of adding annotation data to each video frame to provide context. The annotation data can later be used to train or validate machine learning models. There are two annotation types: bounding boxes and ROI masks. Bounding box annotations were manually added to 1,339 video frames extracted from all 42 videos. An augmented version of the set was used to train a Roboflow Object Detection (Fast) model<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> (mAP 93.0%, precision 97.6%, and recall 87.0%) to produce bounding box annotations for the remaining frames. The model&#x02019;s confidence threshold and overlap threshold were both set at 50.0% during inference. These threshold values were relaxed to ensure that a large number of bounding box images would be collected, with false positives removed later during manual inspection. The complete list of preprocessing steps and augmentations is shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>. Next, the bounding box annotations were inspected and edited if necessary. The first annotator performed an initial pass to detect and flag anomalies. A two-person team then performed a quality check pass, making edits if necessary. Manual checks are essential since missed or erroneous detection is still possible with the trained object detector model. A similar setup was used to produce the ROI masks. The frame selection criteria were as follows: the target (i.e., the carapace) must be in focus, experience minimal blurring, and be substantially large. The annotator used Labelme software<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, a graphical image annotation tool, to carefully mark the carapace&#x02019;s outline for 130 selected video frames. A two-person team then visually checked the created masks and edited any discrepancies.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Preprocessing steps and augmentations for the training data.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td>Preprocessing steps</td><td>Auto-orient</td></tr><tr><td/><td>Rescaled to 640&#x000a0;&#x000d7;&#x000a0;480</td></tr><tr><td/><td>Tile: 2 rows x 2 columns</td></tr><tr><td>Augmentations</td><td>Flip: Horizontal and Vertical</td></tr><tr><td/><td>Rotation between &#x000a0;&#x02212;&#x000a0;15.&#x000a0;0&#x02009;&#x000b0; and &#x000a0;+&#x000a0;15.&#x000a0;0&#x02009;&#x000b0;</td></tr><tr><td/><td>Blur: up to 2.5px</td></tr><tr><td/><td>Noise: up to 0.1% of pixels</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec3"><title>Data Records</title><p id="Par16">The complete dataset is archived on Kaggle under the title &#x02018;GTST-2023&#x02019;<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. The dataset contains 42 videos and two image sets: Set A, which includes 14,471 video frames with bounding box annotations, and Set B, which includes 130 frames with ROI mask annotations. All images had a resolution of 2,560 x 1,920 pixels and were stored in RGB format. For Set A, each image is paired with a JSON file containing the following key-value pairs: <list list-type="bullet"><list-item><p id="Par17">predictions: This key corresponds to the properties of the predicted bounding box. <list list-type="bullet"><list-item><p id="Par18">x: The horizontal center point of the detected object.</p></list-item><list-item><p id="Par19">y: The vertical center point of the detected object.</p></list-item><list-item><p id="Par20">width: The width of the bounding box.</p></list-item><list-item><p id="Par21">height: The height of the bounding box.</p></list-item><list-item><p id="Par22">confidence: The prediction&#x02019;s confidence score.</p></list-item><list-item><p id="Par23">class: The deep learning object detector predicts a single class, i.e., &#x02018;sea-turtle&#x02019;.</p></list-item><list-item><p id="Par24">detection_id: Identifier for Roboflow&#x02019;s hosted inference call.</p></list-item><list-item><p id="Par25">image_path: Path to the image.</p></list-item><list-item><p id="Par26">prediction_type: Prediction type used by Roboflow.</p></list-item></list></p></list-item><list-item><p id="Par27">image: This key corresponds to the image. <list list-type="bullet"><list-item><p id="Par28">width: Width of the image.</p></list-item><list-item><p id="Par29">height: Height of the image.</p></list-item></list></p></list-item></list></p><p id="Par30">For Set B, each image is paired with a JSON file containing the following key-value pairs: <list list-type="bullet"><list-item><p id="Par31">version: This key corresponds to the dataset&#x02019;s version.</p></list-item><list-item><p id="Par32">flags: This key corresponds to flags, if any.</p></list-item><list-item><p id="Par33">shapes: This key corresponds to shape object(s). Only one shape object (i.e., carapace) per image. <list list-type="bullet"><list-item><p id="Par34">label: The identifier for the shape object.</p></list-item><list-item><p id="Par35">points: An array of piecewise points that mark the shape object&#x02019;s outline.</p></list-item><list-item><p id="Par36">group_id: The group identifier.</p></list-item><list-item><p id="Par37">shape_type: Shape&#x02019;s type is set as &#x02018;polygon&#x02019;.</p></list-item><list-item><p id="Par38">flags: Flags, if any.</p></list-item></list></p></list-item><list-item><p id="Par39">imagePath: This key corresponds to the path of the image.</p></list-item><list-item><p id="Par40">imageData: This key corresponds to the image&#x02019;s data in binary form.</p></list-item><list-item><p id="Par41">imageHeight: This key corresponds to the height of the image.</p></list-item><list-item><p id="Par42">imageWidth: This key corresponds to the width of the image.</p></list-item></list></p><p id="Par43">The entire dataset<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> is approximately 3.66 GB in size.</p></sec><sec id="Sec4"><title>Technical Validation</title><p id="Par44">Data annotations were evaluated based on established criteria to ensure consistency, especially in ambiguous cases. For the autogenerated bounding box annotations, annotators consistently applied the definition for Class &#x02018;sea turtle,&#x02019; i.e., the bounding box was retained (or added) if the enclosed object could be visually identified as a sea turtle, determined by consensus. Bounding box annotations for blurred and poorly illuminated images were retained to ensure that the source data were broad and substantial enough to be representative of real-world conditions. Bounding box images containing an individual with partially occluded body part(s) were also retained. As described in the Methods section, the bounding box annotations underwent a two-pass check. During the initial pass, the annotator performed a check to detect and flag anomalies. In the second pass, a two-person team conducted a quality check, making edits where necessary. Ambiguous cases were resolved through majority voting, involving the two-person team and the annotator. The same process was applied when producing the ROI mask annotations.</p><p id="Par45">Video frames in the dataset<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> exhibit common image deformations such as blurring, in-plane and out-of-plane transformations, illumination changes, and scale changes. Additionally, the videos were purposely not trimmed to only contain good frames of the carapace. This ensures the substantial presence of background noise, which is very useful for training and validating robust computer models.</p></sec><sec id="Sec5"><title>Usage Notes</title><p id="Par46">The bounding boxes and ROI masks can be visualized using any suitable image viewer that supports the JSON annotation format, such as the LabelMe software<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>These authors contributed equally: Hamimah Ujir, Ruhana Hassan, Abang Arabi Abang Aimran.</p></fn></fn-group><ack><title>Acknowledgements</title><p>The authors gratefully acknowledge the financial support from the Ministry of Higher Education Malaysia via the Fundamental Research Grant Scheme, FRGS/1/2021/ICT02/UNIMAS/02/1. Special thanks to Khalif A. Zakry and Syahiran Soria, the data collectors, for their diligence in completing the data collection and annotation tasks. We also express our appreciation to Sarawak Forestry Corporation for issuing the necessary permits and to park wardens and rangers for their generous assistance and helpful guidance during the data collection phase. Additionally, we acknowledge Universiti Malaysia Sarawak for the essential support provided throughout this research project.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>I.H. prepared the initial manuscript drafts and edited contributions from all co-authors to produce the final submission. I.H. and H.U. performed the quality check on the annotated data. R.H. and A.A.A.I. provided technical expertise on Greater Talang and green sea turtles. All authors have read and agreed to the final version of this manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open Access funding provided by Universiti Malaysia Sarawak.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>No additional code is supplied together this manuscript.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par47">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">IUCN. (2024). The IUCN Red List of Threatened Species. Version 2024-2.<ext-link ext-link-type="uri" xlink:href="https://www.iucnredlist.org/">https://www.iucnredlist.org/</ext-link>. Accessed: 2024-11-27.</mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">Wildlife Protection Ordinance. Laws of Sarawak (1998).</mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Sarawak Government Gazette. Sarawak Government (1999).</mixed-citation></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Leh</surname><given-names>C</given-names></name></person-group><article-title>Marine turtles in Sarawak</article-title><source>Marine Turtle Newsletter</source><year>1985</year><volume>35</volume><fpage>1</fpage><lpage>3</lpage></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Leh, C. Marine turtles in Sarawak. <italic>Marine Turtle Newsletter</italic><bold>35</bold>, 1&#x02013;3 (1985).</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Buteler</surname><given-names>C</given-names></name><name><surname>Bardier</surname><given-names>C</given-names></name><name><surname>Cabrera</surname><given-names>MR</given-names></name><name><surname>Gonzalez</surname><given-names>Y</given-names></name><name><surname>V&#x000e9;lez-Rubio</surname><given-names>GM</given-names></name></person-group><article-title>To tag or not to tag: Comparative performance of tagging and photo-identification in a long-term mark-recapture of juvenile green turtles (Chelonia mydas)</article-title><source>Amphibia-Reptilia</source><year>2022</year><volume>44</volume><fpage>45 &#x02013; 58</fpage><pub-id pub-id-type="doi">10.1163/15685381-bja10119</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Buteler, C., Bardier, C., Cabrera, M. R., Gonzalez, Y. &#x00026; V&#x000e9;lez-Rubio, G. M. To tag or not to tag: Comparative performance of tagging and photo-identification in a long-term mark-recapture of juvenile green turtles (Chelonia mydas). <italic>Amphibia-Reptilia</italic><bold>44</bold>, 45 &#x02013; 58, 10.1163/15685381-bja10119 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Balazs</surname><given-names>GH</given-names></name></person-group><article-title>Factors affecting the retention of metal tags on sea turtles</article-title><source>Marine Turtle Newsletter</source><year>1982</year><volume>20</volume><fpage>11</fpage><lpage>14</lpage></element-citation><mixed-citation id="mc-CR6" publication-type="journal">Balazs, G. H. Factors affecting the retention of metal tags on sea turtles. <italic>Marine Turtle Newsletter</italic><bold>20</bold>, 11&#x02013;14 (1982).</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Hipiny</surname><given-names>I</given-names></name><name><surname>Ujir</surname><given-names>H</given-names></name><name><surname>Mujahid</surname><given-names>A</given-names></name><name><surname>Yahya</surname><given-names>NK</given-names></name></person-group><article-title>Towards automated biometric identification of sea turtles (Chelonia mydas)</article-title><source>Journal of ICT Research and Applications</source><year>2018</year><volume>12</volume><fpage>256</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.5614/itbj.ict.res.appl.2018.12.3.4</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Hipiny, I., Ujir, H., Mujahid, A. &#x00026; Yahya, N. K. Towards automated biometric identification of sea turtles (Chelonia mydas). <italic>Journal of ICT Research and Applications</italic><bold>12</bold>, 256&#x02013;266, 10.5614/itbj.ict.res.appl.2018.12.3.4 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Tabuki</surname><given-names>K</given-names></name><name><surname>Nishizawa</surname><given-names>H</given-names></name><name><surname>Abe</surname><given-names>O</given-names></name><name><surname>Okuyama</surname><given-names>J</given-names></name><name><surname>Tanizaki</surname><given-names>S</given-names></name></person-group><article-title>Utility of carapace images for long-term photographic identification of nesting green turtles</article-title><source>Journal of Experimental Marine Biology and Ecology</source><year>2021</year><volume>545</volume><fpage>151632</fpage><pub-id pub-id-type="doi">10.1016/j.jembe.2021.151632</pub-id></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Tabuki, K., Nishizawa, H., Abe, O., Okuyama, J. &#x00026; Tanizaki, S. Utility of carapace images for long-term photographic identification of nesting green turtles. <italic>Journal of Experimental Marine Biology and Ecology</italic><bold>545</bold>, 151632, 10.1016/j.jembe.2021.151632 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Mohammad Razi</surname><given-names>MA</given-names></name><etal/></person-group><article-title>Climate change, tsunami and biodiversity endangered at the South China sea, past, current and prediction models for the future: A comprehensive study</article-title><source>Marine Pollution Bulletin</source><year>2022</year><volume>175</volume><fpage>113255</fpage><pub-id pub-id-type="doi">10.1016/j.marpolbul.2021.113255</pub-id><pub-id pub-id-type="pmid">35074593</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Mohammad Razi, M. A. <italic>et al</italic>. Climate change, tsunami and biodiversity endangered at the South China sea, past, current and prediction models for the future: A comprehensive study. <italic>Marine Pollution Bulletin</italic><bold>175</bold>, 113255, 10.1016/j.marpolbul.2021.113255 (2022).<pub-id pub-id-type="pmid">35074593</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Banks</surname><given-names>E</given-names></name></person-group><article-title>The breeding of the edible turtle (Chelone mydas)</article-title><source>Sarawak Museum Journal</source><year>1937</year><volume>4</volume><fpage>523</fpage><lpage>532</lpage></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Banks, E. The breeding of the edible turtle (Chelone mydas). <italic>Sarawak Museum Journal</italic><bold>4</bold>, 523&#x02013;532 (1937).</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>T</given-names></name></person-group><article-title>The edible turtle (Chelonia mydas) in Borneo. 1. Breeding season</article-title><source>Sarawak Museum Journal</source><year>1951</year><volume>5</volume><fpage>593</fpage><lpage>596</lpage></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Harrison, T. The edible turtle (Chelonia mydas) in Borneo. 1. Breeding season. <italic>Sarawak Museum Journal</italic><bold>5</bold>, 593&#x02013;596 (1951).</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Eckert, K. L. Environmental unpredictability and leatherback sea turtle (Dermochelys coriacea) nest loss. <italic>Herpetologica</italic> 315&#x02013;323 (1987).</mixed-citation></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Hays</surname><given-names>G</given-names></name><etal/></person-group><article-title>Nest site selection by sea turtles</article-title><source>Journal of the Marine Biological Association of the United Kingdom</source><year>1995</year><volume>75</volume><fpage>667</fpage><lpage>674</lpage><pub-id pub-id-type="doi">10.1017/S0025315400039084</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Hays, G. <italic>et al</italic>. Nest site selection by sea turtles. <italic>Journal of the Marine Biological Association of the United Kingdom</italic><bold>75</bold>, 667&#x02013;674 (1995).</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Hipiny, I. GTST-2023. 10.34740/kaggle/ds/5348665. Accessed: 2024-12-14. (2024).</mixed-citation></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Zakry</surname><given-names>KA</given-names></name><name><surname>Soria</surname><given-names>MS</given-names></name><name><surname>Hipiny</surname><given-names>I</given-names></name><name><surname>Ujir</surname><given-names>H</given-names></name><name><surname>Hassan</surname><given-names>R</given-names></name><name><surname>Hardi</surname><given-names>R</given-names></name></person-group><article-title>Chelonia mydas detection and image extraction from field recordings</article-title><source>IAES International Journal of Artificial Intelligence (IJ-AI)</source><year>2024</year><volume>13</volume><fpage>2354</fpage><lpage>2363</lpage><pub-id pub-id-type="doi">10.11591/ijai.v13.i2.pp2354-2363</pub-id></element-citation><mixed-citation id="mc-CR15" publication-type="journal">Zakry, K. A., Soria, M. S., Hipiny, I., Ujir, H., Hassan, R. &#x00026; Hardi, R. Chelonia mydas detection and image extraction from field recordings. <italic>IAES International Journal of Artificial Intelligence (IJ-AI)</italic><bold>13</bold>, 2354&#x02013;2363, 10.11591/ijai.v13.i2.pp2354-2363 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Wang, C.-Y., Bochkovskiy, A. &#x00026; Liao, H.-Y. M. Yolov7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors. In <italic>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, 7464&#x02013;7475 (2023).</mixed-citation></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Soria</surname><given-names>MS</given-names></name><name><surname>Zakry</surname><given-names>KA</given-names></name><name><surname>Hipiny</surname><given-names>I</given-names></name><name><surname>Ujir</surname><given-names>H</given-names></name><name><surname>Hassan</surname><given-names>R</given-names></name><name><surname>Jerry</surname><given-names>AL</given-names></name></person-group><article-title>An instance segmentation method for nesting green sea turtle&#x02019;s carapace using mask r-cnn</article-title><source>International Journal of Computing and Digital Systems</source><year>2024</year><volume>16</volume><fpage>201</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.12785/ijcds/160116</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Soria, M. S., Zakry, K. A., Hipiny, I., Ujir, H., Hassan, R. &#x00026; Jerry, A. L. An instance segmentation method for nesting green sea turtle&#x02019;s carapace using mask r-cnn. <italic>International Journal of Computing and Digital Systems</italic><bold>16</bold>, 201&#x02013;211 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">He, K., Gkioxari, G., Dollar, P. &#x00026; Girshick, R. Mask R-CNN. In <italic>Proceedings of the IEEE International Conference on Computer Vision (ICCV)</italic> (2017).</mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Adam, L., &#x0010c;erm&#x000e1;k, V., Papafitsoros, K. &#x00026; Picek, L. SeaTurtleID2022: A long-span dataset for reliable sea turtle re-identification. In <italic>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</italic>, 7146&#x02013;7156 (2024).</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Hoh, D. &#x00026; Fong, C. Sea turtle sightings in Taiwan. v1.9. Turtlespot Taiwan. Dataset/Occurrence.<ext-link ext-link-type="uri" xlink:href="https://ipt.taibif.tw/resource?r=turtlespot&#x00026;v=1.9">https://ipt.taibif.tw/resource?r=turtlespot&#x00026;v=1.9</ext-link>, 10.15468/43z4mj (2022). Accessed via GBIF.org on 2024-06-20.</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Turtle recall: Conservation challenge. <ext-link ext-link-type="uri" xlink:href="https://zindi.africa/competitions/turtle-recall-conservation-challenge">https://zindi.africa/competitions/turtle-recall-conservation-challenge</ext-link>. Accessed: 2024-06-20.</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Dwyer, B., Nelson, J., Solawetz, J. <italic>et al</italic>. Roboflow (version 1.0) [software]. <ext-link ext-link-type="uri" xlink:href="https://roboflow.com">https://roboflow.com</ext-link>. Accessed: 2024-7-4. (2024).</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Wada, K. Labelme: Image Polygonal Annotation with Python, 10.5281/zenodo.5711226.</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Google Earth, Greater Talang island, Sarawak, 1&#x000b0;54&#x02032;45&#x02033;n 109 &#x000b0;46&#x02032;33&#x02033;e. <ext-link ext-link-type="uri" xlink:href="https://earth.google.com/web/">https://earth.google.com/web/</ext-link>. Accessed June 12, 2024.</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Paradiz, M. Wikimedia commons - green sea turtle (3767496025).jpg (2009).</mixed-citation></ref></ref-list></back></article>