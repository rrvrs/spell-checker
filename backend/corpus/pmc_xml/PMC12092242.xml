<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Mol Psychiatry</journal-id><journal-id journal-id-type="iso-abbrev">Mol Psychiatry</journal-id><journal-title-group><journal-title>Molecular Psychiatry</journal-title></journal-title-group><issn pub-type="ppub">1359-4184</issn><issn pub-type="epub">1476-5578</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39741179</article-id><article-id pub-id-type="pmc">PMC12092242</article-id>
<article-id pub-id-type="publisher-id">2877</article-id><article-id pub-id-type="doi">10.1038/s41380-024-02877-y</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Unraveling the associations between voice pitch and major depressive disorder: a multisite genetic study</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2483-1696</contrib-id><name><surname>Di</surname><given-names>Yazheng</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Rahmani</surname><given-names>Elior</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Mefford</surname><given-names>Joel</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Jinhan</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Ravi</surname><given-names>Vijay</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0849-7894</contrib-id><name><surname>Gorla</surname><given-names>Aditya</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Alwan</surname><given-names>Abeer</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8689-6570</contrib-id><name><surname>Kendler</surname><given-names>Kenneth S.</given-names></name><xref ref-type="aff" rid="Aff7">7</xref><xref ref-type="aff" rid="Aff8">8</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Zhu</surname><given-names>Tingshao</given-names></name><address><email>tszhu@psych.ac.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9427-4429</contrib-id><name><surname>Flint</surname><given-names>Jonathan</given-names></name><address><email>JFlint@mednet.ucla.edu</email></address><xref ref-type="aff" rid="Aff9">9</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03j7v5j15</institution-id><institution-id institution-id-type="GRID">grid.454868.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1797 8574</institution-id><institution>CAS Key Laboratory of Behavioral Science, </institution><institution>Institute of Psychology, </institution></institution-wrap>100101 Beijing, China </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05qbk4x57</institution-id><institution-id institution-id-type="GRID">grid.410726.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1797 8419</institution-id><institution>Department of Psychology, </institution><institution>University of Chinese Academy of Sciences, </institution></institution-wrap>100049 Beijing, China </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/046rm7j60</institution-id><institution-id institution-id-type="GRID">grid.19006.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2167 8097</institution-id><institution>Department of Computational Medicine, </institution><institution>University of California Los Angeles, </institution></institution-wrap>Los Angeles, CA USA </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/046rm7j60</institution-id><institution-id institution-id-type="GRID">grid.19006.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2167 8097</institution-id><institution>Department of Neurology, </institution><institution>University of California Los Angeles, </institution></institution-wrap>Los Angeles, CA USA </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/046rm7j60</institution-id><institution-id institution-id-type="GRID">grid.19006.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2167 8097</institution-id><institution>Department of Electrical and Computer Engineering, </institution><institution>University of California Los Angeles, </institution></institution-wrap>Los Angeles, CA USA </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/046rm7j60</institution-id><institution-id institution-id-type="GRID">grid.19006.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2167 8097</institution-id><institution>Bioinformatics Interdepartmental Program, </institution><institution>University of California Los Angeles, </institution></institution-wrap>Los Angeles, CA USA </aff><aff id="Aff7"><label>7</label>Virginia Institute for Psychiatric and Behavioral Genetics, Richmond, VA USA </aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02nkdxk79</institution-id><institution-id institution-id-type="GRID">grid.224260.0</institution-id><institution-id institution-id-type="ISNI">0000 0004 0458 8737</institution-id><institution>Department of Psychiatry, </institution><institution>Virginia Commonwealth University School of Medicine, </institution></institution-wrap>Richmond, VA USA </aff><aff id="Aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/046rm7j60</institution-id><institution-id institution-id-type="GRID">grid.19006.3e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2167 8097</institution-id><institution>Department of Psychiatry and Biobehavioral Sciences, Brain Research Institute, </institution><institution>University of California Los Angeles, </institution></institution-wrap>Los Angeles, CA USA </aff></contrib-group><pub-date pub-type="epub"><day>31</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>31</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2025</year></pub-date><volume>30</volume><issue>6</issue><fpage>2686</fpage><lpage>2695</lpage><history><date date-type="received"><day>3</day><month>6</month><year>2024</year></date><date date-type="rev-recd"><day>3</day><month>12</month><year>2024</year></date><date date-type="accepted"><day>13</day><month>12</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Major depressive disorder (MDD) often goes undiagnosed due to the absence of clear biomarkers. We sought to identify voice biomarkers for MDD and separate biomarkers indicative of MDD predisposition from biomarkers reflecting current depressive symptoms. Using a two-stage meta-analytic design to remove confounds, we tested the association between features representing vocal pitch and MDD in a multisite case-control cohort study of Chinese women with recurrent depression. Sixteen features were replicated in an independent cohort, with absolute association coefficients (beta values) from the combined analysis ranging from 0.24 to 1.07, indicating moderate to large effects. The statistical significance of these associations remained robust, with P values ranging from 7.2 &#x000d7; 10<sup>&#x02013;6</sup> to 6.8 &#x000d7; 10<sup>&#x02013;58</sup>. Eleven features were significantly associated with current depressive symptoms. Using genotype data, we found that this association was driven in part by a genetic correlation with MDD. Significant voice features, reflecting a slower pitch change and a lower pitch, achieved an AUC-ROC of 0.90 (sensitivity of 0.85 and specificity of 0.81) in MDD classification. Our results return vocal features to a more central position in clinical and research work on MDD.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Genetics</kwd><kwd>Psychology</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/100000025</institution-id><institution>U.S. Department of Health &#x00026; Human Services | NIH | National Institute of Mental Health (NIMH)</institution></institution-wrap></funding-source><award-id>MH-122596</award-id><award-id>MH-122596</award-id><award-id>MH-122596</award-id><award-id>MH-122596</award-id><award-id>MH-122596</award-id><award-id>MH-122596</award-id><award-id>MH-122596</award-id><award-id>MH-122596</award-id><award-id>MH-122596</award-id><principal-award-recipient><name><surname>Di</surname><given-names>Yazheng</given-names></name><name><surname>Rahmani</surname><given-names>Elior</given-names></name><name><surname>Mefford</surname><given-names>Joel</given-names></name><name><surname>Wang</surname><given-names>Jinhan</given-names></name><name><surname>Ravi</surname><given-names>Vijay</given-names></name><name><surname>Gorla</surname><given-names>Aditya</given-names></name><name><surname>Alwan</surname><given-names>Abeer</given-names></name><name><surname>Zhu</surname><given-names>Tingshao</given-names></name><name><surname>Flint</surname><given-names>Jonathan</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par2">Changes in human pitch and tone of speech have been noted as an important sign of depression for over a century [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Although not contained in symptomatic criteria for major depressive disorder (MDD) in DSM-III [<xref ref-type="bibr" rid="CR3">3</xref>], DSM-IIIR [<xref ref-type="bibr" rid="CR4">4</xref>], DSM-IV [<xref ref-type="bibr" rid="CR5">5</xref>], or DSM-5 [<xref ref-type="bibr" rid="CR6">6</xref>], they are found in 26 out of 28 detailed clinical descriptions of melancholia published from 1880-1900 [<xref ref-type="bibr" rid="CR1">1</xref>] and in 19 out of 21 of such descriptions of depression published in the 20th century [<xref ref-type="bibr" rid="CR2">2</xref>]. Given the current challenges in diagnosing MDD [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>], where a large proportion of cases (ranging from 50 to 90%) remain untreated [<xref ref-type="bibr" rid="CR9">9</xref>&#x02013;<xref ref-type="bibr" rid="CR11">11</xref>], the transformation of voice phenomena into diagnostic biomarkers could aid in both clinical and research arenas.</p><p id="Par3">Clinical observations describe the speech patterns of depressed patients as slow, weak, low-pitched, and monotonous [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>]. These phenomena are typically quantified by increased pause time, lower volume, lower pitch, and reduced pitch variability [<xref ref-type="bibr" rid="CR14">14</xref>&#x02013;<xref ref-type="bibr" rid="CR16">16</xref>]. Many studies have sought to develop features from pitch as a biomarker for depression [<xref ref-type="bibr" rid="CR17">17</xref>&#x02013;<xref ref-type="bibr" rid="CR26">26</xref>], but none have, to date, achieved sufficient accuracy and precision for clinical utility. The large number of both vocal features and confounds [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>] imposes a multi-testing burden that requires large sample sizes which few studies have obtained [<xref ref-type="bibr" rid="CR16">16</xref>]. Also, a critical distinction between current mood and susceptibility to MDD on effects on voice has never been addressed [<xref ref-type="bibr" rid="CR27">27</xref>&#x02013;<xref ref-type="bibr" rid="CR29">29</xref>]. Furthermore, MDD is likely heterogeneous [<xref ref-type="bibr" rid="CR30">30</xref>, <xref ref-type="bibr" rid="CR31">31</xref>]: studies not accounting for this may be underpowered [<xref ref-type="bibr" rid="CR16">16</xref>].</p><p id="Par4">Our study of the relationship between voice features and MDD was designed to be well-powered, using thousands of subjects, to be more robust to heterogeneity by analyzing cases with recurrent depression of one sex only, and able to separate susceptibility to MDD from the effect of current mood on voice features by using genetic data. We used a large case-control study of MDD where we could replicate findings in an independent sample, both from China. Since, of the four groups of speech features (source, spectral, prosodic, and formant features [<xref ref-type="bibr" rid="CR16">16</xref>]), the association between depression and a key component of prosody, pitch, has repeatedly been observed [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], our analysis was restricted to examining pitch-related features. Our results return vocal features to a more central position in clinical and research work on MDD.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Subjects</title><p id="Par5">We used recordings conducted as part of the CONVERGE [<xref ref-type="bibr" rid="CR32">32</xref>] (China, Oxford, and VCU Experimental Research on Genetic Epidemiology) study (3968 cases and 4354 controls). CONVERGE recruited only women with recurrent MDD from hospital settings and compared them with matched controls with no history of MDD, thus reducing heterogeneity in both genetic and vocal signals [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>]. A summary of demographic data from cases and controls is provided in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S1</xref>; the relation of these to depression is reported in earlier publications [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR35">35</xref>&#x02013;<xref ref-type="bibr" rid="CR40">40</xref>]. All recordings, obtained during diagnostic interviews, were listened to, and segments that contained only the patient&#x02019;s voice at an adequate quality for the analyses (see the Method section in Supplementary for details) were identified. In this study, a &#x0201c;segment&#x0201d; refers to the longest continuous portion of an audio recording that contains only the patient&#x02019;s voice, uninterrupted by other speakers. Segments are not split at pauses within the patient&#x02019;s speech but are instead defined by changes in the speaker, ensuring that each segment represents uninterrupted speech from the patient alone. It can be as short as a single word or as long as a complex sentence or multiple sentences. This resulted in 364,929 voice segments with a duration greater than two seconds from 7654 subjects. The selection of subjects for each component of the study is shown in Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>, which provides an overview of the design of the project (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1a</xref>), and a PRISMA diagram to indicate how many cases and controls were discarded at different stages and pathways of analyses (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1b</xref>).</p></sec><sec id="Sec4"><title>Feature identification</title><p id="Par6">The perceptual attribute of pitch corresponds to the physical measurement of fundamental frequency, or F0 [<xref ref-type="bibr" rid="CR15">15</xref>]. Our interest in prosodic features of speech, particularly pitch (hereafter referred to as the F0) and change in pitch (&#x00394;F0), led us to choose the INTERSPEECH 2016 Computational Paralinguistics Evaluation (COMPARE16) feature set [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>]. The primary application for the feature set has been depression detection [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR43">43</xref>&#x02013;<xref ref-type="bibr" rid="CR47">47</xref>] and it captures typical temporal information and long-term information either statically, through the use of utterance level statistics/functionals, or dynamically, through frame-based delta (&#x00394;F0) coefficients, reflecting differences between the adjacent vectors&#x02019; feature coefficients [<xref ref-type="bibr" rid="CR48">48</xref>, <xref ref-type="bibr" rid="CR49">49</xref>]. Its feature extraction process is well documented [<xref ref-type="bibr" rid="CR50">50</xref>], with standardized and well-referenced methodologies that facilitate reproducibility and validation by other researchers in many languages (including Chinese) [<xref ref-type="bibr" rid="CR51">51</xref>&#x02013;<xref ref-type="bibr" rid="CR54">54</xref>].</p><p id="Par7">The COMPARE16 feature set contains 83 F0/&#x00394;F0-based features, many of which are highly correlated (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S2</xref>). Implementing a feature selection process to remove redundancy (described in Supplementary Methods), we extracted 30 voice features (Table&#x000a0;<xref rid="MOESM2" ref-type="media">S2</xref>, their distributions are in Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S3</xref> and Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S4</xref>), providing a comprehensive characterization of the speaker&#x02019;s prosodic patterns, pitch, and intonation [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>] We calculated statistics and functions based on the time series of F0, and its differential values, namely pitch change speed (&#x00394;F0). These statistics and functions include mean values, quartiles, range, and regression coefficients, which capture pitch trends and dynamics in speech.</p></sec><sec id="Sec5"><title>A two-stage meta-analysis identifies 20 features associated with MDD</title><p id="Par8">Our association analysis had to account for a number of potential confounds. Not everyone in the study spoke the same language: 60% of the subjects spoke in standard Mandarin, whereas the rest spoke either local languages or Mandarin with local accents. This might not matter if language differences were randomized with respect to case status, but uneven case/control ratios between hospitals could confound the analysis. Similarly, the quality of the recordings varied, potentially confounding the association testing. While we made every attempt to ensure that the location of interviews was comparable (in outpatient departments) and that the interviews were carried out in the same way by clinically experienced interviewers that we had trained (Supplementary Methods), these and other, unknown confounders might impact the voice features.</p><p id="Par9">We dealt with these issues as follows. First, during the process of identifying the patients&#x02019; voice segments, we annotated background noise and language. The noise was categorized into five levels, and a binary indicator tagged whether the subjects&#x02019; speech was in standard Mandarin or not. We included these features as covariates in our analyses.</p><p id="Par10">Second, to account for differences between hospitals, we implemented a two-stage meta-analysis, in which associations were first calculated at the hospital level, including demographic features as covariates (Table&#x000a0;<xref rid="MOESM2" ref-type="media">S1</xref>), noise levels, and speech indicators, and subsequently pooling results using a random-effects model. We selected 27 hospitals with at least 100 individuals, yielding a total subject count of N&#x02009;=&#x02009;5681 (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). By analyzing cases and controls within each hospital first and then combining the results in a meta-analysis, we alleviated the risk of site-specific confounders. We identified 20 features significantly associated with MDD at a 5% FDR threshold (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>; a description of the vocal features is given in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S2</xref>). All features were standardized (to give a standard deviation of 1) before analysis so that beta coefficients can be compared and interpreted. Eighteen features were significant under a family-wise error rate control using Bonferroni (P value&#x02009;&#x0003c;&#x02009;0.0017), with 14 features showing absolute &#x003b2; coefficients greater than 0.3. The most significantly associated feature is a &#x00394;F0 measure (interquartile range; &#x003b2; = &#x02013;1.07, SE = 0.07, P<sub>FDR</sub>=1.1 &#x000d7; 10<sup>&#x02013;49</sup>).<table-wrap id="Tab1"><label>Table 1</label><caption><p>Associations between voice pitch features and major depressive disorder.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Features</th><th rowspan="2">Statistical functionals</th><th colspan="3">CONVERGE</th><th colspan="4">Replication</th><th colspan="3">Combined</th></tr><tr><th>Beta</th><th>P</th><th>P_FDR</th><th>Beta</th><th>P</th><th>P_FDR</th><th>Power</th><th>Beta</th><th>P</th><th>P_FDR</th></tr></thead><tbody><tr><td>&#x00394;F0_iqr1-3</td><td>Interquartile range (3rd&#x02013;1st)</td><td>&#x02013;1.07</td><td>3.5E&#x02013;51</td><td>1.1E&#x02013;49</td><td>&#x02013;1.09</td><td>1.46E&#x02013;07</td><td>0</td><td>1</td><td>&#x02013;1.07</td><td>3.4E&#x02013;59</td><td>6.7E&#x02013;58</td></tr><tr><td>&#x00394;F0_percentile99.0</td><td>Maximum (99th percentile)</td><td>&#x02013;0.97</td><td>1.2E&#x02013;43</td><td>1.8E&#x02013;42</td><td>&#x02013;0.97</td><td>5.35E&#x02013;06</td><td>0</td><td>1</td><td>&#x02013;0.97</td><td>1.8E&#x02013;49</td><td>1.8E&#x02013;48</td></tr><tr><td>F0_upleveltime90</td><td>Time with F0&#x0003e;90th percentile</td><td>&#x02013;0.80</td><td>1.5E&#x02013;41</td><td>1.5E&#x02013;40</td><td>&#x02013;0.78</td><td>5.37E&#x02013;05</td><td>0.0001</td><td>1</td><td>&#x02013;0.80</td><td>1.9E&#x02013;45</td><td>1.3E&#x02013;44</td></tr><tr><td>&#x00394;F0_kurtosis</td><td>Kurtosis</td><td>0.87</td><td>1.5E&#x02013;39</td><td>1.1E&#x02013;38</td><td>0.83</td><td>2.69E&#x02013;04</td><td>0.0005</td><td>1</td><td>0.86</td><td>6.4E&#x02013;42</td><td>3.2E&#x02013;41</td></tr><tr><td>&#x00394;F0_rqmean</td><td>Root quadratic mean</td><td>&#x02013;0.69</td><td>6.3E&#x02013;31</td><td>3.8E&#x02013;30</td><td>&#x02013;0.76</td><td>2.99E&#x02013;04</td><td>0.0005</td><td>0.99</td><td>&#x02013;0.70</td><td>6.3E&#x02013;34</td><td>2.1E&#x02013;33</td></tr><tr><td>&#x00394;F0_quartile3</td><td>3rd quartile</td><td>&#x02013;0.78</td><td>5.4E&#x02013;30</td><td>2.7E&#x02013;29</td><td>&#x02013;0.88</td><td>1.16E&#x02013;05</td><td>0</td><td>0.98</td><td>&#x02013;0.80</td><td>4.1E&#x02013;35</td><td>1.6E&#x02013;34</td></tr><tr><td>&#x00394;F0_minPos</td><td>Position of the minimum</td><td>&#x02013;0.60</td><td>3.3E&#x02013;25</td><td>1.4E&#x02013;24</td><td>&#x02013;0.57</td><td>7.05E&#x02013;07</td><td>0</td><td>0.96</td><td>&#x02013;0.59</td><td>7.2E&#x02013;31</td><td>2.0E&#x02013;30</td></tr><tr><td>&#x00394;F0_amean</td><td>Mean</td><td>0.43</td><td>5.8E&#x02013;20</td><td>2.0E&#x02013;19</td><td>0.56</td><td>5.85E&#x02013;08</td><td>0</td><td>0.88</td><td>0.45</td><td>3.0E&#x02013;26</td><td>7.4E&#x02013;26</td></tr><tr><td>&#x00394;F0_linregc1</td><td>Slope of linear regression</td><td>&#x02013;0.39</td><td>6.0E&#x02013;20</td><td>2.0E&#x02013;19</td><td>&#x02013;0.55</td><td>3.12E&#x02013;03</td><td>0.0042</td><td>0.88</td><td>&#x02013;0.41</td><td>8.7E&#x02013;21</td><td>1.5E&#x02013;20</td></tr><tr><td>F0_range</td><td>Range</td><td>0.57</td><td>1.0E&#x02013;19</td><td>3.1E&#x02013;19</td><td>0.48</td><td>2.35E&#x02013;03</td><td>0.0034</td><td>0.88</td><td>0.55</td><td>3.7E&#x02013;22</td><td>8.2E&#x02013;22</td></tr><tr><td>&#x00394;F0_maxPos</td><td>Position of the maximum</td><td>&#x02013;0.55</td><td>1.8E&#x02013;19</td><td>4.9E&#x02013;19</td><td>&#x02013;0.61</td><td>1.36E&#x02013;03</td><td>0.0023</td><td>0.87</td><td>&#x02013;0.56</td><td>5.4E&#x02013;22</td><td>1.1E&#x02013;21</td></tr><tr><td>&#x00394;F0_qregc1</td><td>1st quadratic regression coefficient</td><td>0.38</td><td>1.0E&#x02013;17</td><td>2.6E&#x02013;17</td><td>0.47</td><td>1.04E&#x02013;04</td><td>0.0002</td><td>0.83</td><td>0.40</td><td>9.2E&#x02013;22</td><td>1.7E&#x02013;21</td></tr><tr><td>&#x00394;F0_flatness</td><td>Flatness</td><td>&#x02013;0.43</td><td>5.5E&#x02013;14</td><td>1.3E&#x02013;13</td><td>&#x02013;0.39</td><td>2.85E&#x02013;05</td><td>0.0001</td><td>0.68</td><td>&#x02013;0.42</td><td>6.6E&#x02013;18</td><td>1.0E&#x02013;17</td></tr><tr><td>F0_lpc2</td><td>2nd linear prediction coding coefficient</td><td>0.33</td><td>1.3E&#x02013;09</td><td>2.7E&#x02013;09</td><td>0.41</td><td>2.22E&#x02013;05</td><td>0.0001</td><td>0.44</td><td>0.34</td><td>6.0E&#x02013;13</td><td>8.6E&#x02013;13</td></tr><tr><td>F0_lpc4</td><td>4th linear prediction coding coefficient</td><td>&#x02013;0.28</td><td>4.9E&#x02013;09</td><td>9.8E&#x02013;09</td><td>&#x02013;0.25</td><td>1.07E&#x02013;01</td><td>0.1259</td><td>0.4</td><td>&#x02013;0.27</td><td>2.7E&#x02013;09</td><td>3.6E&#x02013;09</td></tr><tr><td>F0_kurtosis</td><td>Kurtosis</td><td>0.23</td><td>1.1E&#x02013;05</td><td>2.0E&#x02013;05</td><td>0.30</td><td>1.81E&#x02013;03</td><td>0.0028</td><td>0.19</td><td>0.24</td><td>3.6E&#x02013;08</td><td>4.5E&#x02013;08</td></tr><tr><td>F0_lpc0</td><td>0th linear prediction coding coefficient</td><td>&#x02013;0.29</td><td>9.0E&#x02013;05</td><td>1.6E&#x02013;04</td><td>&#x02013;0.39</td><td>1.97E&#x02013;02</td><td>0.0246</td><td>0.14</td><td>&#x02013;0.30</td><td>6.1E&#x02013;06</td><td>7.2E&#x02013;06</td></tr><tr><td>&#x00394;F0_risetime</td><td>Time with which &#x00394;F0 is rising</td><td>&#x02013;0.15</td><td>4.1E&#x02013;04</td><td>6.9E&#x02013;04</td><td>&#x02013;0.25</td><td>1.39E&#x02013;01</td><td>0.1539</td><td>0.1</td><td>&#x02013;0.16</td><td>8.9E&#x02013;05</td><td>9.9E&#x02013;05</td></tr><tr><td>F0_ff0_maxSegLen</td><td>Maximum length of voiced segments with F0&#x02009;&#x0003e;&#x02009;0</td><td>0.19</td><td>6.3E&#x02013;03</td><td>1.0E&#x02013;02</td><td>0.12</td><td>2.69E&#x02013;01</td><td>0.2837</td><td>0.05</td><td>0.19</td><td>3.2E&#x02013;03</td><td>3.4E&#x02013;03</td></tr><tr><td>F0_rqmean</td><td>Root quadratic mean</td><td>0.14</td><td>9.0E&#x02013;03</td><td>1.3E&#x02013;02</td><td>0.00</td><td>9.97E&#x02013;01</td><td>0.9974</td><td>0.05</td><td>0.12</td><td>1.7E&#x02013;02</td><td>1.7E&#x02013;02</td></tr></tbody></table><table-wrap-foot><p>The table shows the names of the prosodic phenotypes, explained in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S2</xref>. Beta values (Beta) P values (P) and FDR corrected (FDR) are from the logistic regression analysis. Beta coefficients are derived from analyses of normalized voice features (with standard deviation of 1).Results from the CONVERGE study and an independently collected replication are shown. The column headed &#x02018;Power&#x02019; shows the power of the replication study to detect the effect found in the discovery sample. The last three columns (&#x02018;Combined&#x02019;) are results from a meta-analysis of CONVERGE and the Replication sample.</p></table-wrap-foot></table-wrap></p><p id="Par11">To test the sensitivity of our results to differences between cases and controls, we compared analyses with and without the inclusion of 20 genetic principal components (PCs). The results of this analysis are presented in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S3</xref>, and a comparison of the betas with and without adjusting for genetic PCs is presented in Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S5</xref>. The correlation between betas in the two analyses was r&#x02009;=&#x02009;0.99, P&#x02009;=&#x02009;8.7 &#x000d7; 10<sup>&#x02013;28</sup>. These results demonstrate a high degree of consistency in the estimated association effects, irrespective of the adjustment for genetic PCs. There is no overall decrease in significance with the inclusion of the genetic covariates, implying that cases and controls are overall adequately matched by location, which implicitly also means matching by accent.</p></sec><sec id="Sec6"><title>Replication in an independent sample</title><p id="Par12">We evaluated the 20 associated features in an independent sample. The replication sample was collected six years after the discovery CONVERGE data, using the same selection criteria and interview protocol (described in Supplementary Methods). The replication sample collected data from three new hospitals, and one that was part of the CONVERGE sample. It used none of the same interviewers and the participants did not overlap with the discovery sample. A description of the sample is given in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S4</xref>. While the replication sample is smaller than the discovery sample (1084, Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>), power to detect twelve of the features was greater than 80% (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Again, we listened to all recordings, annotated them for quality and accent, extracted prosodic features, analyzed the association within each hospital, and combined results by meta-analysis. As Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> shows, 14 features exceeded a Bonferroni corrected threshold of 0.0025 (0.05/20) and 16 exceeded an FDR 5% threshold. We argue that this strong replication finding in an independent sample, excludes systematic bias in the way recordings were made, the way interviews were conducted, and differences in accent among subjects and differences between hospitals.</p><p id="Par13">Finally, we jointly analyzed the discovery and replication samples by meta-analysis and show the results in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. Eighteen features exceeded the Bonferroni corrected threshold and all exceeded the 5% FDR threshold. The three most significantly associated features were &#x00394;F0 interquartile range <inline-formula id="IEq1"><alternatives><tex-math id="d33e1168">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({{{\rm{\beta }}}}=-1.07,{{{\rm{SE}}}}=0.07,{{{{\rm{P}}}}}_{{{{\rm{FDR}}}}}=6.8\times {10}^{-58})$$\end{document}</tex-math><mml:math id="d33e1173"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1.07</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">SE</mml:mi><mml:mo>=</mml:mo><mml:mn>0.07</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">FDR</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>6.8</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>58</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41380_2024_2877_Article_IEq1.gif"/></alternatives></inline-formula>, which measures the range between the 25th and 75th percentile of pitch change speed (&#x00394;F0), &#x00394;F0 maximum <inline-formula id="IEq2"><alternatives><tex-math id="d33e1208">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({{{\rm{\beta }}}}=-0.97,{{{\rm{SE}}}}=0.07,{{{{\rm{P}}}}}_{{{{\rm{FDR}}}}}=1.8\times {10}^{-48})$$\end{document}</tex-math><mml:math id="d33e1213"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.97</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">SE</mml:mi><mml:mo>=</mml:mo><mml:mn>0.07</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">FDR</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.8</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>48</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41380_2024_2877_Article_IEq2.gif"/></alternatives></inline-formula>, which measures the highest value of pitch change speed, and time with F0&#x0003e;90th percentile <inline-formula id="IEq3"><alternatives><tex-math id="d33e1248">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({{{\rm{\beta }}}}=-0.80,{{{\rm{SE}}}}=0.06,{{{{\rm{P}}}}}_{{{{\rm{FDR}}}}}=1.3\times {10}^{-44})$$\end{document}</tex-math><mml:math id="d33e1253"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.80</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">SE</mml:mi><mml:mo>=</mml:mo><mml:mn>0.06</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">FDR</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.3</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>44</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41380_2024_2877_Article_IEq3.gif"/></alternatives></inline-formula>, which measures the amount of time the pitch stays above the 90th percentile of its range. We found that there was no significant heterogeneity in the association effects between Mandarin speakers and non-Mandarin speakers (Supplementary Results).</p></sec><sec id="Sec7"><title>Differences between case and control interviews do not account for the associations</title><p id="Par14">We considered next one additional potential confound: the possible impact of the questions asked at interview. The interview for cases is typically more than twice as long as for controls, as we ask about past occurrences of depression and associated stressful life events. Could the emotion associated with this questioning alter speech in such a way as bias our findings? We conducted a sensitivity analysis on responses to neutral questions to check if the effects remained consistent across contexts.</p><p id="Par15">We selected two questions from the demographic section of the interview based on their high response rates (Table&#x000a0;<xref rid="MOESM2" ref-type="media">S5</xref>) and neutral nature. These questions (D2.A: &#x0201c;What is your date of birth?&#x0201d; and D10: &#x0201c;How much do you weigh while wearing indoor clothing?&#x0201d;) were chosen because they are unlikely to trigger emotional differences between MDD cases and controls. We identified 533 subjects with voice responses to question D2.A and 617 to question D10. The average segment durations were 3.37&#x02009;s (SD&#x02009;=&#x02009;3.05), and 8.47&#x02009;s (SD&#x02009;=&#x02009;2.69), respectively. For each question, we used the corresponding segments to extract the 16 pitch features that were associated with MDD in our main analysis. Using the two-stage meta-analysis method again, we re-estimated their associations. Due to the small sample sizes, power to detect effects was low so we used a one-sided binomial sign test to test consistency in the direction of association effects between the two analyses.</p><p id="Par16">The estimated association effects in context-constrained analysis are reported in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S6</xref>. We found that for question D10, three out of 16 pitch features maintained significant associations with MDD at FDR&#x02009;&#x0003c;&#x02009;0.05. Remarkably, 15 out of 16 features showed the same direction of association effects, a fraction significantly higher than chance (Binomial P&#x02009;=&#x02009;0.00026). For D2.A, despite the average duration being only 3.37&#x02009;s, three features achieved nominal significance for associations (uncorrected P&#x02009;&#x0003c;&#x02009;0.05), and 12 out of 16 pitch features showed consistent directions of association effects (Binomial P&#x02009;=&#x02009;0.038). In total, 12 out of 16 voice features showed consistent directions of association effects across all four analyses. We conclude that the findings from the main analyses are not biased by the context of the interview.</p><p id="Par17">As a summary for these analyses, Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S6</xref> shows the effect sizes (beta coefficients) and the 95% confidence intervals for the association between 16 voice F0/&#x00394;F0 features and MDD in the discovery (CONVERGE), replication and single segment analyses.</p></sec><sec id="Sec8"><title>Genetic correlations between pitch features and MDD</title><p id="Par18">Cases for the CONVERGE study were identified as those who have a history of recurrent MDD, and though all were ascertained through hospitals, many were in remission. This raises the important question as to what the association with voice features represents: does it reflect their current low mood, compared to controls, or does it reflect their history of MDD? We addressed this question in the following way.</p><p id="Par19">To see if any voice features correlated with current mood, we used a standard assessment of current mood for subjects, the depressive symptom checklist (SCL) [<xref ref-type="bibr" rid="CR55">55</xref>]. These data were only available for the replication sample. The distributions of SCL scores for cases and controls are presented in Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S7</xref>. Of the 16 pitch features, 11 showed a significant association with current depressive symptoms, after FDR correction (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>).<table-wrap id="Tab2"><label>Table 2</label><caption><p>Voice pitch features associated with SCL scores.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Feature</th><th>Beta</th><th>SE</th><th>P</th><th>P_FDR</th></tr></thead><tbody><tr><td>&#x00394;F0_maxPos</td><td>&#x02013;0.222</td><td>0.04</td><td>3.4E&#x02013;08</td><td>5.5E&#x02013;07</td></tr><tr><td>&#x00394;F0_percentile99.0 *</td><td>&#x02013;0.296</td><td>0.074</td><td>6.7E&#x02013;05</td><td>5.3E&#x02013;04</td></tr><tr><td>&#x00394;F0_rqmean</td><td>&#x02013;0.238</td><td>0.067</td><td>3.6E&#x02013;04</td><td>0.001</td></tr><tr><td>&#x00394;F0_quartile3</td><td>&#x02013;0.286</td><td>0.081</td><td>3.9E&#x02013;04</td><td>0.001</td></tr><tr><td>F0_upleveltime90</td><td>&#x02013;0.246</td><td>0.066</td><td>1.9E&#x02013;04</td><td>0.001</td></tr><tr><td>&#x00394;F0_iqr1-3 *</td><td>&#x02013;0.309</td><td>0.097</td><td>0.001</td><td>0.004</td></tr><tr><td>&#x00394;F0_kurtosis *</td><td>0.225</td><td>0.081</td><td>0.005</td><td>0.01</td></tr><tr><td>F0_lpc2</td><td>0.118</td><td>0.042</td><td>0.005</td><td>0.01</td></tr><tr><td>&#x00394;F0_amean</td><td>0.133</td><td>0.053</td><td>0.01</td><td>0.02</td></tr><tr><td>F0_kurtosis *</td><td>0.097</td><td>0.041</td><td>0.02</td><td>0.03</td></tr><tr><td>F0_range</td><td>0.128</td><td>0.057</td><td>0.02</td><td>0.03</td></tr><tr><td>&#x00394;F0_flatness</td><td>&#x02013;0.116</td><td>0.056</td><td>0.04</td><td>0.05</td></tr><tr><td>&#x00394;F0_qregc1</td><td>0.104</td><td>0.062</td><td>0.09</td><td>0.12</td></tr><tr><td>&#x00394;F0_linregc1</td><td>&#x02013;0.103</td><td>0.067</td><td>0.12</td><td>0.14</td></tr><tr><td>&#x00394;F0_minPos</td><td>&#x02013;0.13</td><td>0.086</td><td>0.13</td><td>0.14</td></tr><tr><td>F0_lpc0</td><td>&#x02013;0.047</td><td>0.104</td><td>0.65</td><td>0.65</td></tr></tbody></table><table-wrap-foot><p>The associations between pitch features and SCL scores were estimated in the replication sample using a two-stage meta-analysis. Asterisks indicate heritable features, from Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>.</p></table-wrap-foot></table-wrap></p><p id="Par20">These results confirm that most of the features we found to be associated with MDD are correlated with current mood (the relatively smaller sample for this analysis cannot exclude the possibility that all features are thus associated). To examine whether the association reflected a genetic effect common to both variability in vocal features and susceptibility to MDD we estimated the SNP-based heritability for each of the 16 pitch features (this analysis was carried out with CONVERGE data, the only group for which there are genetic data [<xref ref-type="bibr" rid="CR32">32</xref>]). Results are presented in Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>. Four features were heritable at FDR&#x02009;&#x0003c;&#x02009;0.05. We repeated the heritability analyses adjusting for more genetic PCs to determine whether population structure might contribute to the correlation and found that the heritability remained significant even after adjusting for as many as 60 genetic PCs (Table&#x000a0;<xref rid="MOESM2" ref-type="media">S7</xref>). While we cannot rule out the possibility that all vocal features are to some extent heritable (our sample size is too small to confidently detect heritabilities of less than 10%), Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref> shows that SNP-based heritability varies significantly: the estimated confidence interval of the heritability for two, &#x00394;F0_maxPos and &#x00394;F0_qregc1, lie outside those for &#x00394;F0_iqr1-3. The low heritability of these features indicates the genetic effects are unlikely to be the only contributing factor to the association with MDD. We did not find any genome-wide significant SNPs for these heritable features (Supplementary Results), presumably owing to the limited sample size.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Heritable voice pitch features and their genetic correlation with MDD.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Feature</th><th colspan="4">SNP heritability</th><th colspan="4">Genetic Correlation with MDD</th></tr><tr><th>h2</th><th>95% CI</th><th>P</th><th>P_FDR</th><th>rg</th><th>95% CI</th><th>P</th><th>P_FDR</th></tr></thead><tbody><tr><td><bold>&#x00394;F0_iqr1-3</bold></td><td><bold>0.171</bold></td><td><bold>(0.071, 0.272)</bold></td><td><bold>0.0004</bold></td><td><bold>0.006</bold></td><td><bold>&#x02013;0.45</bold></td><td><bold>(&#x02013;0.77, &#x02013;0.13)</bold></td><td><bold>0.03</bold></td><td><bold>0.04</bold></td></tr><tr><td><bold>F0_kurtosis</bold></td><td><bold>0.134</bold></td><td><bold>(0.035, 0.234)</bold></td><td><bold>0.004</bold></td><td><bold>0.03</bold></td><td>&#x02013;0.3</td><td>(&#x02013;1.14, 0.54)</td><td>0.2</td><td>0.2</td></tr><tr><td><bold>&#x00394;F0_kurtosis</bold></td><td><bold>0.125</bold></td><td><bold>(0.025, 0.225)</bold></td><td><bold>0.007</bold></td><td><bold>0.03</bold></td><td><bold>0.55</bold></td><td><bold>(0.23, 0.88)</bold></td><td><bold>0.01</bold></td><td><bold>0.02</bold></td></tr><tr><td><bold>&#x00394;F0_percentile99.0</bold></td><td><bold>0.121</bold></td><td><bold>(0.022, 0.221)</bold></td><td><bold>0.008</bold></td><td><bold>0.03</bold></td><td><bold>&#x02013;0.7</bold></td><td><bold>(&#x02013;1.28, &#x02013;0.11)</bold></td><td><bold>4.2E&#x02013;05</bold></td><td><bold>0.0002</bold></td></tr><tr><td>&#x00394;F0_flatness</td><td>0.105</td><td>(0.007, 0.203)</td><td>0.02</td><td>0.05</td><td/><td/><td/><td/></tr><tr><td>F0_lpc2</td><td>0.093</td><td>(&#x02013;0.005, 0.191)</td><td>0.03</td><td>0.08</td><td/><td/><td/><td/></tr><tr><td>&#x00394;F0_rqmean</td><td>0.058</td><td>(&#x02013;0.040, 0.157)</td><td>0.12</td><td>0.25</td><td/><td/><td/><td/></tr><tr><td>F0_upleveltime90</td><td>0.044</td><td>(&#x02013;0.053, 0.141)</td><td>0.18</td><td>0.32</td><td/><td/><td/><td/></tr><tr><td>&#x00394;F0_minPos</td><td>0.03</td><td>(&#x02013;0.067, 0.128)</td><td>0.27</td><td>0.40</td><td/><td/><td/><td/></tr><tr><td>&#x00394;F0_amean</td><td>0.024</td><td>(&#x02013;0.073, 0.120)</td><td>0.31</td><td>0.40</td><td/><td/><td/><td/></tr><tr><td>&#x00394;F0_quartile3</td><td>0.019</td><td>(&#x02013;0.078, 0.116)</td><td>0.35</td><td>0.40</td><td/><td/><td/><td/></tr><tr><td>F0_lpc0</td><td>0.019</td><td>(&#x02013;0.079, 0.116)</td><td>0.35</td><td>0.40</td><td/><td/><td/><td/></tr><tr><td>F0_range</td><td>0.001</td><td>(&#x02013;0.096, 0.098)</td><td>0.49</td><td>0.49</td><td/><td/><td/><td/></tr><tr><td>&#x00394;F0_linregc2</td><td>&#x02013;0.004</td><td>(&#x02013;0.101, 0.093)</td><td>0.47</td><td>0.49</td><td/><td/><td/><td/></tr><tr><td>&#x00394;F0_qregc1</td><td>&#x02013;0.028</td><td>(&#x02013;0.124, 0.068)</td><td>0.28</td><td>0.40</td><td/><td/><td/><td/></tr><tr><td>&#x00394;F0_maxPos</td><td>&#x02013;0.065</td><td>(&#x02013;0.160, 0.030)</td><td>0.09</td><td>0.21</td><td/><td/><td/><td/></tr></tbody></table></table-wrap></p><p id="Par21">We estimated the genetic correlation with MDD for the four features with evidence of heritability and found that three &#x00394;F0 features had significant genetic correlations (Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>). They were: (1) the interquartile range (IQR1-3), quantifying the variation of speed in pitch change; (2) the kurtosis, signaling the extremity of speed in pitch change; and (3) the maximum, representing the speed of the fastest pitch change. There was no detectable genetic correlation with MDD for one heritable feature, &#x00394;F0_kurtosis. Again, while we cannot exclude the possibility of some degree of genetic correlation for this and other features, our results indicate that genetic effects alone cannot explain the association with MDD for all features. The vocal features index a composite of heritable and non-heritable contributions to mood change.</p></sec><sec id="Sec9"><title>Associations between pitch features and MDD symptoms, risk factors, and comorbidities</title><p id="Par22">The deep set of phenotypes available in CONVERGE, which includes MDD symptoms, environmental risk factors, comorbid disease, and suicidality, permit us to explore other associations for the vocal features associated with MDD. For these exploratory analyses we included all 30 voice features and tested association with 33 traits (detailed in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S8</xref>). The results of within-case two-stage meta-analysis are shown in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S8</xref>. We categorized the traits into six classes (MDD symptoms, MDD clinical features, suicidal features, co-morbid psychiatric disease, neuroticism and stressful life events) as we were interested in determining the effects on these categories.</p><p id="Par23">110 associations are significant at an uncorrected 5% significance threshold (where 50 are expected by chance). Surprisingly, features assessing stressful life events showed the greatest enrichment of low P values. After applying a Bonferroni correction for the 990 tests (P&#x02009;&#x0003c;&#x02009;0.05/990&#x02009;=&#x02009;5.1 &#x000d7; 10<sup>&#x02013;5</sup>) six associations were significant, four for stressful life events, one for the personality trait neuroticism, and one for premenstrual syndrome score. Two features replicated (corrected threshold P&#x02009;&#x0003c;&#x02009;0.05/6&#x02009;=&#x02009;0.008). Both associations were between the total number of stressful life events and &#x00394;F0 features, including the IQR1-3 of &#x00394;F0 (16 hospitals in CONVERGE, total N&#x02009;=&#x02009;2,064, &#x003b2; = - 0.21, SE = 0.03, uncorrected P=1.9 &#x000d7; 10<sup>&#x02013;11</sup>; four hospitals in the replication, total N&#x02009;=&#x02009;295, &#x003b2; = &#x02013;0.20, SE = 0.07, uncorrected P = 0.0078) and maximum of &#x00394;F0 (16 hospitals in CONVERGE, total N&#x02009;=&#x02009;2064, &#x003b2; = &#x02013;0.19, SE = 0.03, uncorrected P = 6.5 &#x000d7; 10<sup>&#x02013;10</sup>; four hospitals in the replication, total N&#x02009;=&#x02009;295, &#x003b2; = &#x02013;0.20, SE = 0.08, uncorrected P = 0.0074).</p></sec><sec id="Sec10"><title>Classification performance</title><p id="Par24">If the voice features are to have any clinical utility, they must not just be associated with MDD, but they must predict it accurately. We took advantage of access to our two independently collected samples (discovery and replication), using the discovery group for training data (n&#x02009;=&#x02009;7654) and the replication sample (n&#x02009;=&#x02009;1189) to test the classification performance.</p><p id="Par25">We compared the classification performance of a full model against a null model. The null model was a logistic regression (LR) model trained on the covariates. We then trained a full model using the covariates together with the identified voice features in discovery, based on the same LR method. Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref> illustrates these comparisons. Integrating voice data significantly enhanced the predictive accuracy of our models. Adding voice features to the LR model increased the AUC-ROC from 0.70 to 0.83 and the accuracy from 0.63 to 0.76.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Classification performance using the identified voice pitch features.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Model</th><th>Method</th><th>Feature</th><th>AUC-ROC</th><th>AUC-PR</th><th>Sensitivity</th><th>Specificity</th><th>F1 Score</th><th>Accuracy</th></tr></thead><tbody><tr><td>NULL</td><td>LR</td><td>Demographic Covariates</td><td>0.70</td><td>0.62</td><td>0.75</td><td>0.53</td><td>0.63</td><td>0.62</td></tr><tr><td rowspan="4">FULL</td><td>LR</td><td>Demographic Covariates + Voice</td><td>0.83</td><td>0.77</td><td>0.81</td><td>0.70</td><td>0.73</td><td>0.75</td></tr><tr><td>SVM</td><td>Demographic Covariates + Voice</td><td>0.86</td><td>0.80</td><td>0.88</td><td>0.67</td><td>0.75</td><td>0.76</td></tr><tr><td>MLP</td><td>Demographic Covariates + Voice</td><td>0.85</td><td>0.80</td><td>0.86</td><td>0.69</td><td>0.75</td><td>0.76</td></tr><tr><td>XGBoost</td><td>Demographic Covariates + Voice</td><td>0.90</td><td>0.88</td><td>0.85</td><td>0.81</td><td>0.80</td><td>0.82</td></tr></tbody></table><table-wrap-foot><p><italic>LR</italic> Logistic Regression, <italic>XGBoost</italic> Extreme Gradient Boosting, <italic>SVM</italic> Support Vector Machine, <italic>MLP</italic> Multi-layer Perceptron.</p></table-wrap-foot></table-wrap></p><p id="Par26">We then tested whether the classification results were robust to different machine learning methods. We evaluated this on three established methods suitable for our dataset, support vector machine (SVM), extreme gradient boosting (XGBoost), and multi-layer perceptron (MLP). Results improved prediction, with XGBoost delivering an AUC of 0.90 (sensitivity of 0.85, and specificity of 0.81). Figure&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> plots the ROC curves for a null model (using covariates only to classify depression) and the four models using voice features. The precision-recall curve of these models are in Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S8</xref>.<fig id="Fig1"><label>Fig. 1</label><caption><title>Receiver operating characteristic (ROC) curve.</title><p>The figure shows the ROC for four models for predicting depression from voice features, and a null model, a logistic regression model trained on demographic covariates only (LR-Covar). The full models are logistic regression (LR), support vector machine (SVM), multi-layer perceptron (MLP), and extreme gradient boosting (XGBoost), trained on voice and covariates (Covar+Voice). AUC: area under the curve.</p></caption><graphic xlink:href="41380_2024_2877_Fig1_HTML" id="d33e2091"/></fig></p></sec></sec><sec id="Sec11" sec-type="discussion"><title>Discussion</title><p id="Par27">We set out to find voice pitch features associated with MDD. By using a large and homogeneous case-control cohort, a two-stage meta-analysis and an independent replication, we provide robust evidence that certain pitch features distinguished MDD cases from matched controls. The associated features were a slower change in pitch and a particularly uneven distribution of these variations. Features measuring the variability and extremity of pitch change speed were heritable and had genetic correlations with MDD, which we interpret to mean that at least some of the association between variation in pitch and susceptibility to depression is genetic in origin. Classification of those with and without depression, based on vocal features, was achieved with an AUC of 0.90, highlighting the potential use of these features as biomarkers for MDD detection and secondary prevention.</p><p id="Par28">Establishing a robust, replicable association between voice features and MDD is difficult because of the numerous confounds that could potentially introduce systematic differences between cases and controls and thus corrupt our findings. We addressed this concern by using a large, and as far as possible homogeneous sample of depression. Our study used only women with recurrent MDD in a population where many comorbid disorders, such as smoking, alcohol, and drug abuse, are rare or practically non-existent [<xref ref-type="bibr" rid="CR32">32</xref>]. By adopting a two-stage meta-analysis to take into account variation between hospitals, and using an independent replication sample, our results are unlikely to be explained by differences between hospitals, location, accent, quality of the recording or the interview questions.</p><p id="Par29">Our findings support and extend previous studies which have indicated potential links between pitch patterns and MDD, but were limited by smaller sample sizes or more heterogeneous cohorts [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>]. First, our large sample size provided adequate power to test several pitch features from a standardized features set, providing more fine-grained quantitative evidence for the descriptions of the monotonous speech pattern in MDD than in previous studies. Previous studies have found that depressed people speak more slowly with lower pitch and decreased variability [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR25">25</xref>]. Here, our study showed MDD was negatively associated with features measuring how fast pitch changes (the maximum, the 3rd quartile, and the root quadratic mean of &#x00394;F0, Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>), indicating that the reduced rate of change in pitch is a characteristic of voice in MDD patients. We also found that MDD patients spend less time in their upper vocal range (Time with F0&#x0003e;90<sup>th</sup> percentile, Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>), affirming the &#x0201c;low-pitched&#x0201d; pattern.</p><p id="Par30">Second, our results indicate that MDD&#x02019;s pitch dynamics involve more than reduced variability, showing a broader pitch range and more extreme values (range and kurtosis of F0, Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Our analysis also revealed an uneven distribution of the speed with which an MDD patient&#x02019;s pitch changes, as shown by the negative association between MDD and the flatness of &#x00394;F0 and the positive association with the kurtosis of &#x00394;F0 (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Overall, these various features enrich our understanding of pitch dynamics, demonstrating a pattern of slower change in pitch, yet with more frequent occurrences of extreme values and pitch change speed.</p><p id="Par31">Third, our research examined the relationship between voice features and the effects of current low mood, and the effects of susceptibility to MDD. Some vocal features might be more reflective of a person&#x02019;s underlying propensity towards developing MDD, while others could be more indicative of a current depressive state. We found that some vocal features were indeed heritable, but still correlated with changes in current mood: individuals with an increased genetic risk of MDD may have a smaller value of speed for the fastest pitch change, thus being unable to speak as fast as those without depression. They may show a narrower IQR of pitch change speeds and more frequently occurring extreme changes of pitch (higher kurtosis). Shared genetic effects exist between at least some &#x00394;F0 features and MDD, but while our low power to detect heritability and genetic correlations raises the possibility that the other features may also be associated in this way, our findings are consistent with vocal features&#x02019; association with both current low mood and susceptibility to MDD.</p><p id="Par32">We also found that two heritable voice features were associated with the number of stressful life events. The reason for these associations is unclear, but suggests the possibility that stressful life events reveal a latent predisposition to depression [<xref ref-type="bibr" rid="CR56">56</xref>, <xref ref-type="bibr" rid="CR57">57</xref>], evidenced through a change in vocal features.</p><p id="Par33">It is interesting to consider physiological interpretations of our findings. Possibly, changes in pitch could reflect tiredness, or the psychomotor retardation that characterizes an episode of MDD. We do not have physiological assessments of our subjects that characterize these features (all of our data are from interviews, and therefore reflect the subjects&#x02019; perceptions) but it is worth pointing out that at some level physiological and psychological contributions will be confounded. For example retardation of thought (psychological) can result in a slowness of expression (motor effect), so that in many cases the distinction may not be relevant.</p><p id="Par34">Could the features we identified provide clinically useful predictions? A key aim of our research was to find vocal biomarkers that could take on this role. Applying XGBoost to the independent test dataset we obtained an AUC-ROC of 0.90, and a level of accuracy indicating that the features could be useful in identifying cases of MDD. We applied three models for classification (SVM, XGBoost, and MLP) because relying on a single model would not provide sufficient evidence for the robustness and generalizability of the voice features across different machine learning approaches. SVM excels at handling high-dimensional data and constructing optimal decision boundaries, but it assumes that the data is linearly separable in the kernel-transformed feature space [<xref ref-type="bibr" rid="CR58">58</xref>]. If the relationship between the features and depression states is highly non-linear, SVM may struggle to find an optimal solution. In contrast, XGBoost [<xref ref-type="bibr" rid="CR59">59</xref>], an ensemble of decision trees, can capture complex feature interactions and handle non-linear relationships. However, it may not be as effective as deep learning models like MLP in capturing hierarchical representations of the data. MLP, with its deep learning architecture, can learn intricate patterns and hierarchical representations, but it is prone to overfitting, particularly when the dataset is small or the network is overly complex [<xref ref-type="bibr" rid="CR60">60</xref>]. By applying the voice features and geographical covariates to all three models, we provide a robust justification for the usefulness and generalizability of the voice features in depression classification.</p><p id="Par35">Our results should be assessed with respect to several limitations. First, we only recruited Han Chinese women with recurrent MDD. Our results may not extrapolate to men, those with single episode MDD, or to non-Chinese speakers. Second, our analysis focused solely on pitch features, and future studies should explore other feature types. Neural network-based approaches, which can learn directly from raw audio signals, also hold promise for detecting depression but face challenges in portability and interpretability, particularly when addressing complex confounding factors [<xref ref-type="bibr" rid="CR61">61</xref>] (Supplementary Results). Third, although our context-constrained analysis demonstrates that the signals we found are persistent across speech content, we cannot separate pitch differences due to word choice from pitch differences due to emotional content without additional experiments directly controlling the linguistic context.</p><p id="Par36">While we don&#x02019;t know how far results will generalize outside the female Chinese cohort, the findings reveal that vocal features can be used to identify MDD cases with high accuracy and we expect that with improvements, such as the inclusion of additional voice features, even higher predictive accuracy may be obtainable. Our hope is that these findings will further encourage efforts to assess changes in the voice, long understood by experienced clinicians to be a valuable sign, returning it to a more central position in clinical and research work on MDD.</p></sec><sec id="Sec12"><title>Methods</title><sec id="Sec13"><title>Participants</title><p id="Par37">We used data from the CONVERGE [<xref ref-type="bibr" rid="CR32">32</xref>] study, in which women with recurrent MDD were recruited from 58 provincial mental health centers and psychiatric departments of general medical hospitals in 45 cities and 23 provinces of China. Participants were aged between 30 and 60, with two or more episodes of MDD that met the DSM-IV criteria [<xref ref-type="bibr" rid="CR5">5</xref>], with the first episode occurring between ages 14&#x02013;50. Cases were excluded if they had pre-existing bipolar disorder, nonaffective psychosis, smoking/nicotine dependence (alcohol and substance abuse were virtually absent in this study, so it was not assessed), or mental retardation. Control subjects, screened to exclude a history of MDD, were recruited from patients undergoing minor surgical procedures at general hospitals and individuals attending local community centers. The replication study [<xref ref-type="bibr" rid="CR43">43</xref>] used the same inclusion/exclusion criteria as CONVERGE, and recruited samples from 20 different hospitals in China, with a final sample size of 1189 (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). This study was approved by Institutional Review Boards at UCLA, Bio-x Center, Shanghai Jiao Tong University (M16033), and local hospitals. All participants provided written informed consent.</p></sec><sec id="Sec14"><title>Data collection</title><p id="Par38">All subjects went through a semi-structured interview using a computerized assessment system as outlined previously [<xref ref-type="bibr" rid="CR43">43</xref>] and described in Supplementary Methods. Recordings for cases were obtained in outpatient clinics. Controls were recorded in outpatient clinics and in community health centers. Recordings were not standardized and varied in quality and content. All participants provided DNA samples for genetic analysis. Details of DNA sequencing and genotype imputation have been previously reported [<xref ref-type="bibr" rid="CR32">32</xref>] and described briefly in Supplementary Methods.</p></sec><sec id="Sec15"><title>Covariates</title><p id="Par39">The covariates were five demographic variables and two recording quality variables. The demographic variables were age, education level, occupation, marital status, and social class. The recording quality referred to noise level and accent. The noise level and accent label were determined subjectively by the listeners during the process of identifying the patients&#x02019; voice segments. The noise was categorized into four levels: (1) No noise; (2) Slight noise but the subject&#x02019;s speech was clear; (3) Noise present but the content of the subject&#x02019;s speech could be clearly heard; (4) High noise levels and unclear speech. Note that noise level 4 means that the speech, although difficult to understand, can still be comprehended with extra effort. And samples were excluded during quality controls stage if the speech is not able to comprehended at all. The accent was a binary label that indicated whether the subjects&#x02019; speech was in standard Mandarin or not.</p></sec><sec id="Sec16"><title>Voice data preprocessing</title><p id="Par40">In total, 8322 subjects the subjects recruited in CONVERGE had interview recordings (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). To obtain the subjects&#x02019; utterances, a group of undergraduates listened to the recordings to identify any voice segments from the subjects with a duration &#x0003e;2&#x02009;s. Audio samples were excluded where the noise was so prominent that the content of the subject&#x02019;s speech could not be understood, which yielded 7654 subjects with available segments. All segments from the same subject were concatenated in the order in which they occur in the interview and down sampled to 8&#x02009;kHz. Two postgraduate psychological students listened to all the segments to ensure that no speech voice other than the subjects was included in the segments and that no words were cut off mid-way.</p><p id="Par41">The preprocessing procedure in the replication study was the same as in CONVERGE. Of the initially recruited 1301 participants (551 cases), 1189 subjects (including 490 cases) had available voice segments (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). All segments from the same subject were concatenated into one, to extract voice features for replicating the association between voice and MDD and identifying the voice features associated with SCL (see distribution of the audio segment length in Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S9</xref>). The speech segments in the replication study were further annotated to indicate the specific question that prompted each spoken response (Table&#x000a0;<xref rid="MOESM2" ref-type="media">S5</xref>). This additional level of data analysis was introduced to better understand the relationship between the interview content and the participants&#x02019; speech patterns. We additionally extracted the same voice features on the non-concatenated segments corresponding to a single question for a sensitivity analysis, which we referred to as, the context-constrained analysis (described below).</p></sec><sec id="Sec17"><title>Voice features</title><p id="Par42">We used the INTERSPEECH 2016 Computational Paralinguistics Evaluation [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>]. Calculations were implemented in the openSMILE python package v2.4.2 [<xref ref-type="bibr" rid="CR62">62</xref>] and described in Supplementary Methods. Given that many of the features were highly correlated (for example, the arithmetic and root-quadratic mean of F0, as shown in Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S2</xref>), we removed redundant features (described in Supplementary Methods), resulting in a set of 15 F0-based features and 15 &#x00394;F0-based features. We provide in Supplementary Table&#x000a0;<xref rid="MOESM2" ref-type="media">S2</xref> technical definitions of the 30 features used, along with non-technical explanations of what each feature measures.</p></sec><sec id="Sec18"><title>Two-stage meta-analysis</title><p id="Par43">We used a two-stage meta-analytic framework to take into account differences between hospitals. In the first stage, for each hospital a linear regression model was fitted for each F0-related feature as the dependent variable using MDD and covariates as the predictor variables. We applied rank-based inverse normal transformation to the voice features. At stage 2, beta coefficients for MDD and standard errors from stage 1 were pooled using random-effects meta-analysis [<xref ref-type="bibr" rid="CR63">63</xref>], assuming that the true effect sizes in different sites are not exactly the same but are drawn from a distribution of effect sizes. P values were FDR-adjusted [<xref ref-type="bibr" rid="CR64">64</xref>]. In the second stage, we repeated the analyses in four hospitals with sample sizes &#x02265;100 (N&#x02009;=&#x02009;1084, Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). We performed the same procedure as in the two-stage meta-analysis above. We combined results from both discovery and replication cohorts using random-effects meta-analysis [<xref ref-type="bibr" rid="CR63">63</xref>].</p></sec><sec id="Sec19"><title>Heritability and genetic correlations</title><p id="Par44">Heritability and genetic correlations were estimated on the 7654 subjects in CONVERGE (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). The SNP-based heritability used a generalized REML (restricted maximum likelihood) method implemented in LDAK [<xref ref-type="bibr" rid="CR65">65</xref>]. We applied rank-based inverse normal transformation to the voice features and incorporated the above covariates and 20 genetic PCs. P values were FDR-adjusted. For heritable voice features, we estimated their genetic correlation with MDD, adjusting for these same covariates and 20 genetic PCs. The genetic correlation was calculated through a bivariate GREML analysis implemented in GCTA [<xref ref-type="bibr" rid="CR66">66</xref>, <xref ref-type="bibr" rid="CR67">67</xref>]. P values were FDR-adjusted based on the number of heritable voice features.</p></sec><sec id="Sec20"><title>Associations between pitch features and current mood</title><p id="Par45">To identify biomarkers for current mood, subjects in the replication cohort were given a 16-item, self-administered questionnaire assessing the severity of depression-related symptoms on a five-point distress scale over the past 30 days (subscales for depression symptom checklist, SCL) [<xref ref-type="bibr" rid="CR55">55</xref>]. We used the same two-stage meta-analysis method to estimate the association between the 16 voice features and SCL scores. All four hospitals from the replication cohort with sample sizes &#x02265;100 were selected (N&#x02009;=&#x02009;1084, Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). At stage 1, for each hospital, a linear regression model was fitted for each pitch feature as the dependent variable using SCL scores and the covariates as the predictor variables. At stage 2, beta coefficients for SCL and standard errors from stage 1 were pooled using random-effects meta-analyses [<xref ref-type="bibr" rid="CR63">63</xref>]. SCL scores were standardized using rank-based inverse normal transformation. P values were FDR-adjusted.</p></sec><sec id="Sec21"><title>Classification model</title><p id="Par46">We employed a logistic regression model using seven covariates (age, education level, occupation, marital status, social class, noise level, and accent) to establish a null model. Full models that incorporated both these covariates and voice features were then developed. We included all 20 voice features identified as associated with MDD during the discovery stage, including those not replicated. We used samples available in the discovery group for training data (n&#x02009;=&#x02009;7654). For the test data set we used the replication sample (n&#x02009;=&#x02009;1189). There was no re-estimation of weights in the test sample.</p><p id="Par47">We compared the results of the full model with the null model based on logistic regression. Then we tested the classification performances using SVM, XGBoost, and MLP as the classifiers. The performance of models was evaluated across several metrics: accuracy, sensitivity, specificity, AUC-ROC, AUC-PR, and F1-score. To identify the best hyperparameters for each model, a grid search with 5-folds cross-validation was employed on the training dataset. The above process was implemented in python with package scikit-learn [<xref ref-type="bibr" rid="CR68">68</xref>] v1.2.2 and xgboost [<xref ref-type="bibr" rid="CR59">59</xref>] v2.0.3.</p></sec><sec id="Sec22"><title>Associations between pitch features and MDD symptoms, risk factors, and comorbidities</title><p id="Par48">We examined the relationship between the 30 voice F0/&#x00394;F0 features with 33 variables related to MDD, including eight risk factor variables, 11 comorbidity variables, seven symptoms, three variables about suicidality, age of onset, number of MDD episodes, neuroticism, and premenstrual syndrome score (summarized in Table&#x000a0;<xref rid="MOESM2" ref-type="media">S8</xref>). We again employed the two-stage meta-analysis procedure. At stage 1, for each hospital, a multivariate linear regression model was fitted for each pitch feature as the dependent variable using one of the above variables and covariates as the independent variables. At stage 2, we used the Q statistics to measure the heterogeneity of the pooled beta coefficients and standard errors. If the heterogeneity test is significant (P&#x02009;&#x0003c;&#x02009;0.05), we then used the random-effects model for meta-analyses, otherwise we used fixed-effects [<xref ref-type="bibr" rid="CR64">64</xref>]. We applied a Bonferroni correction to obtain a 5% significance threshold. Due to the high endorsement rates for certain variables within some hospitals, the hospitals included in the meta-analysis varied depending on the variable being analyzed (for example, if all cases from one hospital did not have suicidal attempts, this hospital would be excluded for the analysis of suicidal attempts at stage 1). We reported the number of hospitals and sample size for each association along with the meta-results.</p></sec><sec id="Sec23"><title>Context-constrained analysis</title><p id="Par49">We counted the total number of available voice segments for each question in the replication cohort and selected the two most frequently answered questions from the demographic section of the interview: D2.A (&#x0201c;What is your date of birth?&#x0201d;) and D10 (&#x0201c;How much do you weigh while wearing indoor clothing?&#x0201d;). For each question, we used the corresponding segments to extract the 16 voice features that were associated with MDD in our previous analysis. Finally, we re-assessed the associations between these voice features and MDD through the two-stage meta-analysis method. The limited voice duration and small sample size reduced power to detect a significant signal. We applied the one-sided binomial sign test to determine whether the number of voice features demonstrating consistent directions of association effects between the concatenated segments and the context-constrained segments was greater than expected by chance (that is, a one-sided test of whether this fraction is greater than 0.5).</p></sec></sec><sec id="Sec24" sec-type="supplementary-material"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41380_2024_2877_MOESM1_ESM.docx"><caption><p>Supplemental material</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41380_2024_2877_MOESM2_ESM.xlsx"><caption><p>Supplemental Tables</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41380-024-02877-y.</p></sec><notes notes-type="author-contribution"><title>Author contributions</title><p>Conceived and designed the study: JF, TZ, AA, ER; Analysed the data: YD, JM, JW, VR, AG. Wrote the paper: YD, KSK, JF. All authors contributed to the interpretation of data, provided feedback on drafts, and approved the final draft.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>This work was supported by R01-MH122596 from the National Institute of Mental Health, 200176/A/15/Z from the Wellcome Trust, and a philanthropic donation from Shirley and Walter Wang. The funding agencies and donors were not involved in the conduct, analysis, or reporting of this work.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>Site-level summary statistics necessary for generating the final meta-analysis results, as well as labels and model predictions required to reproduce the ROC and precision-recall curves are available from the corresponding author upon reasonable request.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>Scripts to run the two-stage meta-analysis and classification modeling are available from the corresponding author upon reasonable request.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par50">The authors declare no competing interests.</p></notes><notes id="FPar2"><title>Ethics approval and consent to participate</title><p id="Par51">This study was approved by Institutional Review Boards at UCLA, Bio-x Center, Shanghai Jiao Tong University (M16033), and local hospitals. All participants provided written informed consent. All methods were performed in accordance with relevant guidelines and regulations.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Kendler</surname><given-names>KS</given-names></name></person-group><article-title>The genealogy of major depression: symptoms and signs of melancholia from 1880 to 1900</article-title><source>Mol Psychiatry</source><year>2017</year><volume>22</volume><fpage>1539</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1038/mp.2017.148</pub-id><pub-id pub-id-type="pmid">28785109</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Kendler KS. The genealogy of major depression: symptoms and signs of melancholia from 1880 to 1900. Mol Psychiatry. 2017;22:1539&#x02013;53.<pub-id pub-id-type="pmid">28785109</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Kendler</surname><given-names>KS</given-names></name></person-group><article-title>The phenomenology of major depression and the representativeness and nature of DSM criteria</article-title><source>AJP</source><year>2016</year><volume>173</volume><fpage>771</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1176/appi.ajp.2016.15121509</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Kendler KS. The phenomenology of major depression and the representativeness and nature of DSM criteria. AJP. 2016;173:771&#x02013;80.</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders, Third Edition. Washington, D.C: American Psychiatric Association; 1980.</mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders, Revised Third Edition. Washington, D.C: American Psychiatric Association; 1987.</mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">American Psychiatric Association. Diagnostic and statistical manual of mental disorders, Fourth Edition. Washington, D.C: American Psychiatric Association; 1994.</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">American Psychiatric Association. Diagnostic and statistical manual of mental disorders (DSM-5&#x000ae;). Washington, D.C: American Psychiatric Association; 2013.</mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Lux</surname><given-names>V</given-names></name><name><surname>Kendler</surname><given-names>KS</given-names></name></person-group><article-title>Deconstructing major depression: a validation study of the DSM-IV symptomatic criteria</article-title><source>Psychol Med</source><year>2010</year><volume>40</volume><fpage>1679</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1017/S0033291709992157</pub-id><pub-id pub-id-type="pmid">20059797</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Lux V, Kendler KS. Deconstructing major depression: a validation study of the DSM-IV symptomatic criteria. Psychol Med. 2010;40:1679&#x02013;90.<pub-id pub-id-type="pmid">20059797</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Hyman</surname><given-names>SE</given-names></name></person-group><article-title>Can neuroscience be integrated into the DSM-V?</article-title><source>Nat Rev Neurosci</source><year>2007</year><volume>8</volume><fpage>725</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1038/nrn2218</pub-id><pub-id pub-id-type="pmid">17704814</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Hyman SE. Can neuroscience be integrated into the DSM-V? Nat Rev Neurosci. 2007;8:725&#x02013;32.<pub-id pub-id-type="pmid">17704814</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Kessler</surname><given-names>RC</given-names></name><name><surname>Berglund</surname><given-names>P</given-names></name><name><surname>Demler</surname><given-names>O</given-names></name><name><surname>Jin</surname><given-names>R</given-names></name><name><surname>Koretz</surname><given-names>D</given-names></name><name><surname>Merikangas</surname><given-names>KR</given-names></name><etal/></person-group><article-title>The epidemiology of major depressive disorder results from the national comorbidity survey replication (NCS-R)</article-title><source>JAMA</source><year>2003</year><volume>289</volume><fpage>3095</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1001/jama.289.23.3095</pub-id><pub-id pub-id-type="pmid">12813115</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Kessler RC, Berglund P, Demler O, Jin R, Koretz D, Merikangas KR, et al. The epidemiology of major depressive disorder results from the national comorbidity survey replication (NCS-R). JAMA. 2003;289:3095&#x02013;105.<pub-id pub-id-type="pmid">12813115</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Ma</surname><given-names>C</given-names></name><name><surname>Xu</surname><given-names>G</given-names></name><etal/></person-group><article-title>Prevalence of depressive disorders and treatment in China: a cross-sectional epidemiological study</article-title><source>Lancet Psychiatry</source><year>2021</year><volume>8</volume><fpage>981</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1016/S2215-0366(21)00251-0</pub-id><pub-id pub-id-type="pmid">34559991</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Lu J, Xu X, Huang Y, Li T, Ma C, Xu G, et al. Prevalence of depressive disorders and treatment in China: a cross-sectional epidemiological study. Lancet Psychiatry. 2021;8:981&#x02013;90.<pub-id pub-id-type="pmid">34559991</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Thornicroft</surname><given-names>G</given-names></name><name><surname>Chatterji</surname><given-names>S</given-names></name><name><surname>Evans-Lacko</surname><given-names>S</given-names></name><name><surname>Gruber</surname><given-names>M</given-names></name><name><surname>Sampson</surname><given-names>N</given-names></name><name><surname>Aguilar-Gaxiola</surname><given-names>S</given-names></name><etal/></person-group><article-title>Undertreatment of people with major depressive disorder in 21 countries</article-title><source>Br J Psychiatry</source><year>2017</year><volume>210</volume><fpage>119</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1192/bjp.bp.116.188078</pub-id><pub-id pub-id-type="pmid">27908899</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Thornicroft G, Chatterji S, Evans-Lacko S, Gruber M, Sampson N, Aguilar-Gaxiola S, et al. Undertreatment of people with major depressive disorder in 21 countries. Br J Psychiatry. 2017;210:119&#x02013;24.<pub-id pub-id-type="pmid">27908899</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Guislain J Orales sur Les Phr&#x000e9;nopathies, ou Trait&#x000ea; Th&#x000ea;orique Et Pratique Des Maladies Mentales: Cours Donn&#x000e9; A La Clinique Des &#x000ca;tablissements D&#x02019;Ali&#x000e9;n&#x000e9;s A Gand. Vol. 1. Paris, &#x00026; Bonn,: Gand; 1852.</mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Kraepelin E Manic-depressive insanity and paranoia. Edinburgh: E. &#x00026; S. Livingstone; 1921.</mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Sobin C Psychomotor Symptoms of Depression. A m J Psychiatry. 1997;15.</mixed-citation></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Cummins</surname><given-names>N</given-names></name><name><surname>Scherer</surname><given-names>S</given-names></name><name><surname>Krajewski</surname><given-names>J</given-names></name><name><surname>Schnieder</surname><given-names>S</given-names></name><name><surname>Epps</surname><given-names>J</given-names></name><name><surname>Quatieri</surname><given-names>TF</given-names></name></person-group><article-title>A review of depression and suicide risk assessment using speech analysis</article-title><source>Speech Commun</source><year>2015</year><volume>71</volume><fpage>10</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1016/j.specom.2015.03.004</pub-id></element-citation><mixed-citation id="mc-CR15" publication-type="journal">Cummins N, Scherer S, Krajewski J, Schnieder S, Epps J, Quatieri TF. A review of depression and suicide risk assessment using speech analysis. Speech Commun. 2015;71:10&#x02013;49.</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Low</surname><given-names>DM</given-names></name><name><surname>Bentley</surname><given-names>KH</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name></person-group><article-title>Automated assessment of psychiatric disorders using speech: A systematic review</article-title><source>Laryngoscope Investig Otolaryngol</source><year>2020</year><volume>5</volume><fpage>96</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1002/lio2.354</pub-id><pub-id pub-id-type="pmid">32128436</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Low DM, Bentley KH, Ghosh SS. Automated assessment of psychiatric disorders using speech: A systematic review. Laryngoscope Investig Otolaryngol. 2020;5:96&#x02013;116.<pub-id pub-id-type="pmid">32128436</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Nilsonne</surname><given-names>&#x000c5;</given-names></name></person-group><article-title>Acoustic analysis of speech variables during depression and after improvement</article-title><source>Acta Psychiatr Scand</source><year>1987</year><volume>76</volume><fpage>235</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1111/j.1600-0447.1987.tb02891.x</pub-id><pub-id pub-id-type="pmid">3673650</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Nilsonne &#x000c5;. Acoustic analysis of speech variables during depression and after improvement. Acta Psychiatr Scand. 1987;76:235&#x02013;45.<pub-id pub-id-type="pmid">3673650</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Nilsonne</surname><given-names>&#x000c5;</given-names></name></person-group><article-title>Speech characteristics as indicators of depressive illness</article-title><source>Acta Psychiatr Scand</source><year>1988</year><volume>77</volume><fpage>253</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1111/j.1600-0447.1988.tb05118.x</pub-id><pub-id pub-id-type="pmid">3394527</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Nilsonne &#x000c5;. Speech characteristics as indicators of depressive illness. Acta Psychiatr Scand. 1988;77:253&#x02013;63.<pub-id pub-id-type="pmid">3394527</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Mundt</surname><given-names>JC</given-names></name><name><surname>Snyder</surname><given-names>PJ</given-names></name><name><surname>Cannizzaro</surname><given-names>MS</given-names></name><name><surname>Chappie</surname><given-names>K</given-names></name><name><surname>Geralts</surname><given-names>DS</given-names></name></person-group><article-title>Voice acoustic measures of depression severity and treatment response collected via interactive voice response (IVR) technology</article-title><source>J Neurolinguist</source><year>2007</year><volume>20</volume><fpage>50</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.jneuroling.2006.04.001</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Mundt JC, Snyder PJ, Cannizzaro MS, Chappie K, Geralts DS. Voice acoustic measures of depression severity and treatment response collected via interactive voice response (IVR) technology. J Neurolinguist. 2007;20:50&#x02013;64.</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Mundt</surname><given-names>JC</given-names></name><name><surname>Vogel</surname><given-names>AP</given-names></name><name><surname>Feltner</surname><given-names>DE</given-names></name><name><surname>Lenderking</surname><given-names>WR</given-names></name></person-group><article-title>Vocal acoustic biomarkers of depression severity and treatment response</article-title><source>Biol Psychiatry</source><year>2012</year><volume>72</volume><fpage>580</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2012.03.015</pub-id><pub-id pub-id-type="pmid">22541039</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Mundt JC, Vogel AP, Feltner DE, Lenderking WR. Vocal acoustic biomarkers of depression severity and treatment response. Biol Psychiatry. 2012;72:580&#x02013;7.<pub-id pub-id-type="pmid">22541039</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Kuny</surname><given-names>S</given-names></name><name><surname>Stassen</surname><given-names>HH</given-names></name></person-group><article-title>Speaking behavior and voice sound characteristics in depressive patients during recovery</article-title><source>J Psychiatr Res</source><year>1993</year><volume>27</volume><fpage>289</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1016/0022-3956(93)90040-9</pub-id><pub-id pub-id-type="pmid">8295161</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Kuny S, Stassen HH. Speaking behavior and voice sound characteristics in depressive patients during recovery. J Psychiatr Res. 1993;27:289&#x02013;307.<pub-id pub-id-type="pmid">8295161</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Cannizzaro</surname><given-names>M</given-names></name><name><surname>Harel</surname><given-names>B</given-names></name><name><surname>Reilly</surname><given-names>N</given-names></name><name><surname>Chappell</surname><given-names>P</given-names></name><name><surname>Snyder</surname><given-names>PJ</given-names></name></person-group><article-title>Voice acoustical measurement of the severity of major depression</article-title><source>Brain Cogn</source><year>2004</year><volume>56</volume><fpage>30</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2004.05.003</pub-id><pub-id pub-id-type="pmid">15380873</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Cannizzaro M, Harel B, Reilly N, Chappell P, Snyder PJ. Voice acoustical measurement of the severity of major depression. Brain Cogn. 2004;56:30&#x02013;5.<pub-id pub-id-type="pmid">15380873</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Alpert</surname><given-names>M</given-names></name><name><surname>Pouget</surname><given-names>ER</given-names></name><name><surname>Silva</surname><given-names>RR</given-names></name></person-group><article-title>Reflections of depression in acoustic measures of the patient&#x02019;s speech</article-title><source>J Affect Disord</source><year>2001</year><volume>66</volume><fpage>59</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/S0165-0327(00)00335-9</pub-id><pub-id pub-id-type="pmid">11532533</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Alpert M, Pouget ER, Silva RR. Reflections of depression in acoustic measures of the patient&#x02019;s speech. J Affect Disord. 2001;66:59&#x02013;69.<pub-id pub-id-type="pmid">11532533</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Pan W, Flint J, Shenhav L, Liu T, Liu M, Hu B, et al. Re-examining the robustness of voice features in predicting depression: Compared with baseline of confounders. Li Z, editor. PLoS ONE. 2019;14:e0218172.</mixed-citation></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>T</given-names></name><name><surname>Pan</surname><given-names>W</given-names></name><name><surname>Hu</surname><given-names>B</given-names></name><name><surname>Zhu</surname><given-names>T</given-names></name></person-group><article-title>Acoustic differences between healthy and depressed people: a cross-situation study</article-title><source>BMC Psychiatry</source><year>2019</year><volume>19</volume><fpage>300</fpage><pub-id pub-id-type="doi">10.1186/s12888-019-2300-7</pub-id><pub-id pub-id-type="pmid">31615470</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Wang J, Zhang L, Liu T, Pan W, Hu B, Zhu T. Acoustic differences between healthy and depressed people: a cross-situation study. BMC Psychiatry. 2019;19:300.<pub-id pub-id-type="pmid">31615470</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Schultebraucks</surname><given-names>K</given-names></name><name><surname>Yadav</surname><given-names>V</given-names></name><name><surname>Shalev</surname><given-names>AY</given-names></name><name><surname>Bonanno</surname><given-names>GA</given-names></name><name><surname>Galatzer-Levy</surname><given-names>IR</given-names></name></person-group><article-title>Deep learning-based classification of posttraumatic stress disorder and depression following trauma utilizing visual and auditory markers of arousal and mood</article-title><source>Psychol Med</source><year>2022</year><volume>52</volume><fpage>957</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1017/S0033291720002718</pub-id><pub-id pub-id-type="pmid">32744201</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Schultebraucks K, Yadav V, Shalev AY, Bonanno GA, Galatzer-Levy IR. Deep learning-based classification of posttraumatic stress disorder and depression following trauma utilizing visual and auditory markers of arousal and mood. Psychol Med. 2022;52:957&#x02013;67.<pub-id pub-id-type="pmid">32744201</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Di</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Zhu</surname><given-names>T</given-names></name></person-group><article-title>Combining polygenic risk score and voice features to detect major depressive disorders</article-title><source>Front Genet</source><year>2021</year><volume>12</volume><fpage>2451</fpage><pub-id pub-id-type="doi">10.3389/fgene.2021.761141</pub-id></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Di Y, Wang J, Liu X, Zhu T. Combining polygenic risk score and voice features to detect major depressive disorders. Front Genet. 2021;12:2451.</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Flint J The genetic basis of major depressive disorder. Mol Psychiatry [Internet]. 2023 Jan 26 [cited 2023 Jan 31]; Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41380-023-01957-9">https://www.nature.com/articles/s41380-023-01957-9</ext-link></mixed-citation></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Hasler</surname><given-names>G</given-names></name><name><surname>Drevets</surname><given-names>WC</given-names></name><name><surname>Manji</surname><given-names>HK</given-names></name><name><surname>Charney</surname><given-names>DS</given-names></name></person-group><article-title>Discovering endophenotypes for major depression</article-title><source>Neuropsychopharmacol</source><year>2004</year><volume>29</volume><fpage>1765</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1038/sj.npp.1300506</pub-id></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Hasler G, Drevets WC, Manji HK, Charney DS. Discovering endophenotypes for major depression. Neuropsychopharmacol. 2004;29:1765&#x02013;81.</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Kendler</surname><given-names>KS</given-names></name><name><surname>Aggen</surname><given-names>SH</given-names></name><name><surname>Neale</surname><given-names>MC</given-names></name></person-group><article-title>Evidence for multiple genetic factors underlying DSM-IV criteria for major depression</article-title><source>JAMA Psychiatry</source><year>2013</year><volume>70</volume><fpage>599</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1001/jamapsychiatry.2013.751</pub-id><pub-id pub-id-type="pmid">23740048</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Kendler KS, Aggen SH, Neale MC. Evidence for multiple genetic factors underlying DSM-IV criteria for major depression. JAMA Psychiatry. 2013;70:599&#x02013;607.<pub-id pub-id-type="pmid">23740048</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>RE</given-names></name><name><surname>Cai</surname><given-names>N</given-names></name><name><surname>Dahl</surname><given-names>AW</given-names></name><name><surname>Bigdeli</surname><given-names>TB</given-names></name><name><surname>Edwards</surname><given-names>AC</given-names></name><name><surname>Webb</surname><given-names>BT</given-names></name><etal/></person-group><article-title>Molecular genetic analysis subdivided by adversity exposure suggests etiologic heterogeneity in major depression</article-title><source>AJP</source><year>2018</year><volume>175</volume><fpage>545</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1176/appi.ajp.2017.17060621</pub-id></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Peterson RE, Cai N, Dahl AW, Bigdeli TB, Edwards AC, Webb BT, et al. Molecular genetic analysis subdivided by adversity exposure suggests etiologic heterogeneity in major depression. AJP. 2018;175:545&#x02013;54.</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><collab>CONVERGE consortium.</collab></person-group><article-title>Sparse whole-genome sequencing identifies two loci for major depressive disorder</article-title><source>Nature</source><year>2015</year><volume>523</volume><fpage>588</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1038/nature14659</pub-id><pub-id pub-id-type="pmid">26176920</pub-id>
</element-citation><mixed-citation id="mc-CR32" publication-type="journal">CONVERGE consortium. Sparse whole-genome sequencing identifies two loci for major depressive disorder. Nature. 2015;523:588&#x02013;91.<pub-id pub-id-type="pmid">26176920</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Andrianopoulos</surname><given-names>MV</given-names></name><name><surname>Darrow</surname><given-names>KN</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name></person-group><article-title>Multimodal standardization of voice among four multicultural populations: fundamental frequency and spectral characteristics</article-title><source>J Voice</source><year>2001</year><volume>15</volume><fpage>194</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/S0892-1997(01)00021-2</pub-id><pub-id pub-id-type="pmid">11411474</pub-id>
</element-citation><mixed-citation id="mc-CR33" publication-type="journal">Andrianopoulos MV, Darrow KN, Chen J. Multimodal standardization of voice among four multicultural populations: fundamental frequency and spectral characteristics. J Voice. 2001;15:194&#x02013;219.<pub-id pub-id-type="pmid">11411474</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name><surname>Kendler</surname><given-names>KS</given-names></name><name><surname>Gardner</surname><given-names>C</given-names></name><name><surname>Neale</surname><given-names>M</given-names></name><name><surname>Prescott</surname><given-names>C</given-names></name></person-group><article-title>Genetic risk factors for major depression in men and women: similar or different heritabilities and same or partly distinct genes?</article-title><source>Psychol Med</source><year>2001</year><volume>31</volume><fpage>605</fpage><pub-id pub-id-type="doi">10.1017/S0033291701003907</pub-id><pub-id pub-id-type="pmid">11352363</pub-id>
</element-citation><mixed-citation id="mc-CR34" publication-type="journal">Kendler KS, Gardner C, Neale M, Prescott C. Genetic risk factors for major depression in men and women: similar or different heritabilities and same or partly distinct genes? Psychol Med. 2001;31:605.<pub-id pub-id-type="pmid">11352363</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Tao</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Xie</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Qiu</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>W</given-names></name><etal/></person-group><article-title>Examining the relationship between lifetime stressful life events and the onset of major depression in Chinese women</article-title><source>J Affect Disord</source><year>2011</year><volume>135</volume><fpage>95</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.jad.2011.06.054</pub-id><pub-id pub-id-type="pmid">21821294</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Tao M, Li Y, Xie D, Wang Z, Qiu J, Wu W, et al. Examining the relationship between lifetime stressful life events and the onset of major depression in Chinese women. J Affect Disord. 2011;135:95&#x02013;9.<pub-id pub-id-type="pmid">21821294</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Cai</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name><name><surname>Ni</surname><given-names>S</given-names></name><etal/></person-group><article-title>Perceived parenting and risk for major depression in Chinese women</article-title><source>Psychol Med</source><year>2012</year><volume>42</volume><fpage>921</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1017/S0033291711001942</pub-id><pub-id pub-id-type="pmid">21943491</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal">Gao J, Li Y, Cai Y, Chen J, Shen Y, Ni S, et al. Perceived parenting and risk for major depression in Chinese women. Psychol Med. 2012;42:921&#x02013;30.<pub-id pub-id-type="pmid">21943491</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name><surname>Gan</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Xie</surname><given-names>D</given-names></name><name><surname>Shao</surname><given-names>C</given-names></name><name><surname>Yang</surname><given-names>F</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name><etal/></person-group><article-title>The impact of educational status on the clinical features of major depressive disorder among Chinese women</article-title><source>J Affect Disord</source><year>2012</year><volume>136</volume><fpage>988</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1016/j.jad.2011.06.046</pub-id><pub-id pub-id-type="pmid">21824664</pub-id>
</element-citation><mixed-citation id="mc-CR37" publication-type="journal">Gan Z, Li Y, Xie D, Shao C, Yang F, Shen Y, et al. The impact of educational status on the clinical features of major depressive disorder among Chinese women. J Affect Disord. 2012;136:988&#x02013;92.<pub-id pub-id-type="pmid">21824664</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>F</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Xie</surname><given-names>D</given-names></name><name><surname>Shao</surname><given-names>C</given-names></name><name><surname>Ren</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>W</given-names></name><etal/></person-group><article-title>Age at onset of major depressive disorder in Han Chinese women: Relationship with clinical features and family history</article-title><source>J Affect Disord</source><year>2011</year><volume>135</volume><fpage>89</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.jad.2011.06.056</pub-id><pub-id pub-id-type="pmid">21782247</pub-id>
</element-citation><mixed-citation id="mc-CR38" publication-type="journal">Yang F, Li Y, Xie D, Shao C, Ren J, Wu W, et al. Age at onset of major depressive disorder in Han Chinese women: Relationship with clinical features and family history. J Affect Disord. 2011;135:89&#x02013;94.<pub-id pub-id-type="pmid">21782247</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Flint</surname><given-names>J</given-names></name><etal/></person-group><article-title>Associations of educational attainment, occupation, social class and major depressive disorder among Han Chinese women</article-title><source>PLOS ONE</source><year>2014</year><volume>9</volume><fpage>e86674</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0086674</pub-id><pub-id pub-id-type="pmid">24497966</pub-id>
</element-citation><mixed-citation id="mc-CR39" publication-type="journal">Shi J, Zhang Y, Liu F, Li Y, Wang J, Flint J, et al. Associations of educational attainment, occupation, social class and major depressive disorder among Han Chinese women. PLOS ONE. 2014;9:e86674.<pub-id pub-id-type="pmid">24497966</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Shi</surname><given-names>S</given-names></name><name><surname>Yang</surname><given-names>F</given-names></name><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Tao</surname><given-names>M</given-names></name><etal/></person-group><article-title>Patterns of co-morbidity with anxiety disorders in Chinese women with recurrent major depression</article-title><source>Psychol Med</source><year>2012</year><volume>42</volume><fpage>1239</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1017/S003329171100273X</pub-id><pub-id pub-id-type="pmid">22126712</pub-id>
</element-citation><mixed-citation id="mc-CR40" publication-type="journal">Li Y, Shi S, Yang F, Gao J, Li Y, Tao M, et al. Patterns of co-morbidity with anxiety disorders in Chinese women with recurrent major depression. Psychol Med. 2012;42:1239&#x02013;48.<pub-id pub-id-type="pmid">22126712</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Schuller B, Steidl S, Batliner A, Hirschberg J, Burgoon JK, Baird A, et al. The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception, Sincerity &#x00026; Native Language. In: Interspeech 2016 [Internet]. ISCA; 2016 [cited 2023 Apr 19]. p. 2001&#x02013;5. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.isca-speech.org/archive/interspeech_2016/schuller16_interspeech.html">https://www.isca-speech.org/archive/interspeech_2016/schuller16_interspeech.html</ext-link></mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Weninger F, Eyben F, Schuller BW, Mortillaro M, Scherer KR On the Acoustics of Emotion in Audio: What Speech, Music, and Sound have in Common. Front Psychol [Internet]. 2013 [cited 2021 Dec 20];4. Available from: <ext-link ext-link-type="uri" xlink:href="http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00292/abstract">http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00292/abstract</ext-link></mixed-citation></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name><surname>Di</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Zhu</surname><given-names>T</given-names></name></person-group><article-title>Using i-vectors from voice features to identify major depressive disorder</article-title><source>J Affect Disord</source><year>2021</year><volume>288</volume><fpage>161</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/j.jad.2021.04.004</pub-id><pub-id pub-id-type="pmid">33895418</pub-id>
</element-citation><mixed-citation id="mc-CR43" publication-type="journal">Di Y, Wang J, Li W, Zhu T. Using i-vectors from voice features to identify major depressive disorder. J Affect Disord. 2021;288:161&#x02013;6.<pub-id pub-id-type="pmid">33895418</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Afshan A, Guo J, Park SJ, Ravi V, Flint J, Alwan A Effectiveness of Voice Quality Features in Detecting Depression. Interspeech 2018 [Internet]. 2018 Sep [cited 2023 Apr 19]; Available from: <ext-link ext-link-type="uri" xlink:href="https://par.nsf.gov/biblio/10098305-effectiveness-voice-quality-features-detecting-depression">https://par.nsf.gov/biblio/10098305-effectiveness-voice-quality-features-detecting-depression</ext-link></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Alghowinem S, Goecke R, Epps J, Wagner M, Cohn J Cross-Cultural Depression Recognition from Vocal Biomarkers. In: Interspeech 2016 [Internet]. ISCA; 2016 [cited 2023 May 23]. p. 1943&#x02013;7. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.isca-speech.org/archive/interspeech_2016/alghowinem16_interspeech.html">https://www.isca-speech.org/archive/interspeech_2016/alghowinem16_interspeech.html</ext-link></mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Quatieri TF, Malyska N Vocal-source biomarkers for depression: a link to psychomotor activity. In: Interspeech 2012 [Internet]. ISCA; 2012 [cited 2022 Jul 7]. p. 1059&#x02013;62. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.isca-speech.org/archive/interspeech_2012/quatieri12_interspeech.html">https://www.isca-speech.org/archive/interspeech_2012/quatieri12_interspeech.html</ext-link></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Syed ZS, Schroeter J, Sidorov K, Marshall D Computational Paralinguistics: Automatic Assessment of Emotions, Mood and Behavioural State from Acoustics of Speech. In: Interspeech 2018 [Internet]. ISCA; 2018 [cited 2023 Nov 27]. p. 511&#x02013;5. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.isca-speech.org/archive/interspeech_2018/syed18_interspeech.html">https://www.isca-speech.org/archive/interspeech_2018/syed18_interspeech.html</ext-link></mixed-citation></ref><ref id="CR48"><label>48.</label><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name><surname>Schuller</surname><given-names>B</given-names></name><name><surname>Batliner</surname><given-names>A</given-names></name><name><surname>Steidl</surname><given-names>S</given-names></name><name><surname>Seppi</surname><given-names>D</given-names></name></person-group><article-title>Recognising realistic emotions and affect in speech: State of the art and lessons learnt from the first challenge</article-title><source>Speech Commun</source><year>2011</year><volume>53</volume><fpage>1062</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1016/j.specom.2011.01.011</pub-id></element-citation><mixed-citation id="mc-CR48" publication-type="journal">Schuller B, Batliner A, Steidl S, Seppi D. Recognising realistic emotions and affect in speech: State of the art and lessons learnt from the first challenge. Speech Commun. 2011;53:1062&#x02013;87.</mixed-citation></citation-alternatives></ref><ref id="CR49"><label>49.</label><citation-alternatives><element-citation id="ec-CR49" publication-type="journal"><person-group person-group-type="author"><name><surname>Schuller</surname><given-names>B</given-names></name><name><surname>Steidl</surname><given-names>S</given-names></name><name><surname>Batliner</surname><given-names>A</given-names></name><name><surname>Burkhardt</surname><given-names>F</given-names></name><name><surname>Devillers</surname><given-names>L</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>C</given-names></name><etal/></person-group><article-title>Paralinguistics in speech and language&#x02014;State-of-the-art and the challenge</article-title><source>Comput Speech Lang</source><year>2013</year><volume>27</volume><fpage>4</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.csl.2012.02.005</pub-id></element-citation><mixed-citation id="mc-CR49" publication-type="journal">Schuller B, Steidl S, Batliner A, Burkhardt F, Devillers L, M&#x000fc;ller C, et al. Paralinguistics in speech and language&#x02014;State-of-the-art and the challenge. Comput Speech Lang. 2013;27:4&#x02013;39.</mixed-citation></citation-alternatives></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Eyben F Real-time speech and music classification by large audio feature space extraction. Springer; 2015.</mixed-citation></ref><ref id="CR51"><label>51.</label><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>K</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name></person-group><article-title>A systematic review on automated clinical depression diagnosis</article-title><source>npj Ment Health Res</source><year>2023</year><volume>20</volume><fpage>1</fpage><lpage>17</lpage></element-citation><mixed-citation id="mc-CR51" publication-type="journal">Mao K, Wu Y, Chen J. A systematic review on automated clinical depression diagnosis. npj Ment Health Res. 2023;20:1&#x02013;17.</mixed-citation></citation-alternatives></ref><ref id="CR52"><label>52.</label><citation-alternatives><element-citation id="ec-CR52" publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>S</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Chakraborty</surname><given-names>D</given-names></name><name><surname>Chua</surname><given-names>YHV</given-names></name><name><surname>Tolomeo</surname><given-names>S</given-names></name><name><surname>Winkler</surname><given-names>S</given-names></name><etal/></person-group><article-title>Identifying psychiatric manifestations in schizophrenia and depression from audio-visual behavioural indicators through a machine-learning approach</article-title><source>Schizophr</source><year>2022</year><volume>8</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41537-022-00287-z</pub-id></element-citation><mixed-citation id="mc-CR52" publication-type="journal">Xu S, Yang Z, Chakraborty D, Chua YHV, Tolomeo S, Winkler S, et al. Identifying psychiatric manifestations in schizophrenia and depression from audio-visual behavioural indicators through a machine-learning approach. Schizophr. 2022;8:1&#x02013;13.</mixed-citation></citation-alternatives></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="other">Ringeval F, Schuller B, Valstar M, Cummins Ni, Cowie R, Tavabi L, et al. AVEC 2019 Workshop and Challenge: State-of-Mind, Detecting Depression with AI, and Cross-Cultural Affect Recognition. arXiv:190711510 [cs, stat] [Internet]. 2019 Jul 10 [cited 2021 Jan 21]; Available from: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1907.11510">http://arxiv.org/abs/1907.11510</ext-link></mixed-citation></ref><ref id="CR54"><label>54.</label><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>L</given-names></name><name><surname>Rocca</surname><given-names>R</given-names></name><name><surname>Simonsen</surname><given-names>A</given-names></name><name><surname>Olsen</surname><given-names>L</given-names></name><name><surname>Parola</surname><given-names>A</given-names></name><name><surname>Bliksted</surname><given-names>V</given-names></name><etal/></person-group><article-title>Speech- and text-based classification of neuropsychiatric conditions in a multidiagnostic setting</article-title><source>Nat Ment Health</source><year>2023</year><volume>1</volume><fpage>971</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1038/s44220-023-00152-7</pub-id></element-citation><mixed-citation id="mc-CR54" publication-type="journal">Hansen L, Rocca R, Simonsen A, Olsen L, Parola A, Bliksted V, et al. Speech- and text-based classification of neuropsychiatric conditions in a multidiagnostic setting. Nat Ment Health. 2023;1:971&#x02013;81.</mixed-citation></citation-alternatives></ref><ref id="CR55"><label>55.</label><citation-alternatives><element-citation id="ec-CR55" publication-type="journal"><person-group person-group-type="author"><name><surname>Derogatis</surname><given-names>LR</given-names></name></person-group><article-title>SCL-90: an outpatient psychiatric rating scale-preliminary report</article-title><source>Psychopharmacol Bull</source><year>1973</year><volume>9</volume><fpage>13</fpage><lpage>28</lpage><pub-id pub-id-type="pmid">4682398</pub-id>
</element-citation><mixed-citation id="mc-CR55" publication-type="journal">Derogatis LR. SCL-90: an outpatient psychiatric rating scale-preliminary report. Psychopharmacol Bull. 1973;9:13&#x02013;28.<pub-id pub-id-type="pmid">4682398</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR56"><label>56.</label><citation-alternatives><element-citation id="ec-CR56" publication-type="journal"><person-group person-group-type="author"><name><surname>Kendler</surname><given-names>KS</given-names></name><name><surname>Karkowski-Shuman</surname><given-names>L</given-names></name></person-group><article-title>Stressful life events and genetic liability to major depression: genetic control of exposure to the environment?</article-title><source>Psychol Med</source><year>1997</year><volume>27</volume><fpage>539</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1017/S0033291797004716</pub-id><pub-id pub-id-type="pmid">9153675</pub-id>
</element-citation><mixed-citation id="mc-CR56" publication-type="journal">Kendler KS, Karkowski-Shuman L. Stressful life events and genetic liability to major depression: genetic control of exposure to the environment? Psychol Med. 1997;27:539&#x02013;47.<pub-id pub-id-type="pmid">9153675</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR57"><label>57.</label><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name><surname>Kendler</surname><given-names>KS</given-names></name><name><surname>Kessler</surname><given-names>RC</given-names></name><name><surname>Walters</surname><given-names>EE</given-names></name><name><surname>MacLean</surname><given-names>C</given-names></name><name><surname>Neale</surname><given-names>MC</given-names></name><name><surname>Heath</surname><given-names>AC</given-names></name><etal/></person-group><article-title>Stressful life events, genetic liability, and onset of an episode of major depression in women</article-title><source>FOC</source><year>2010</year><volume>8</volume><fpage>459</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1176/foc.8.3.foc459</pub-id></element-citation><mixed-citation id="mc-CR57" publication-type="journal">Kendler KS, Kessler RC, Walters EE, MacLean C, Neale MC, Heath AC, et al. Stressful life events, genetic liability, and onset of an episode of major depression in women. FOC. 2010;8:459&#x02013;70.</mixed-citation></citation-alternatives></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="other">Suthaharan S Support Vector Machine. In: Suthaharan S, editor. Machine Learning Models and Algorithms for Big Data Classification: Thinking with Examples for Effective Learning [Internet]. Boston, MA: Springer US; 2016. p. 207&#x02013;35. Available from: 10.1007/978-1-4899-7641-3_9</mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other">Chen T, Guestrin C XGBoost: A Scalable Tree Boosting System. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining [Internet]. San Francisco California USA: ACM; 2016 [cited 2024 May 15]. p. 785&#x02013;94. Available from: <ext-link ext-link-type="uri" xlink:href="https://dl.acm.org/doi/10.1145/2939672.2939785">https://dl.acm.org/doi/10.1145/2939672.2939785</ext-link></mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="other">Glorot X, Bengio Y Understanding the difficulty of training deep feedforward neural networks. In: Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics [Internet]. JMLR Workshop and Conference Proceedings; 2010 [cited 2024 May 16]. p. 249&#x02013;56. Available from: <ext-link ext-link-type="uri" xlink:href="https://proceedings.mlr.press/v9/glorot10a.html">https://proceedings.mlr.press/v9/glorot10a.html</ext-link></mixed-citation></ref><ref id="CR61"><label>61.</label><citation-alternatives><element-citation id="ec-CR61" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Ravi</surname><given-names>V</given-names></name><name><surname>Flint</surname><given-names>J</given-names></name><name><surname>Alwan</surname><given-names>A</given-names></name></person-group><article-title>Speechformer-CTC: sequential modeling of depression detection with speech temporal classification</article-title><source>Speech Commun</source><year>2024</year><volume>163</volume><fpage>103106</fpage><pub-id pub-id-type="doi">10.1016/j.specom.2024.103106</pub-id><pub-id pub-id-type="pmid">39364289</pub-id>
</element-citation><mixed-citation id="mc-CR61" publication-type="journal">Wang J, Ravi V, Flint J, Alwan A. Speechformer-CTC: sequential modeling of depression detection with speech temporal classification. Speech Commun. 2024;163:103106. Sep 1<pub-id pub-id-type="pmid">39364289</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="other">Eyben F, W&#x000f6;llmer M, Schuller B Opensmile: the munich versatile and fast open-source audio feature extractor. In: Proceedings of the 18th ACM international conference on Multimedia [Internet]. Firenze Italy: ACM; 2010 [cited 2023 May 24]. p. 1459&#x02013;62. Available from: <ext-link ext-link-type="uri" xlink:href="https://dl.acm.org/doi/10.1145/1873951.1874246">https://dl.acm.org/doi/10.1145/1873951.1874246</ext-link></mixed-citation></ref><ref id="CR63"><label>63.</label><citation-alternatives><element-citation id="ec-CR63" publication-type="journal"><person-group person-group-type="author"><name><surname>Viechtbauer</surname><given-names>W</given-names></name></person-group><article-title>Conducting Meta-Analyses in R with the metafor Package</article-title><source>J Stat Softw</source><year>2010</year><volume>36</volume><fpage>1</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.18637/jss.v036.i03</pub-id></element-citation><mixed-citation id="mc-CR63" publication-type="journal">Viechtbauer W. Conducting Meta-Analyses in R with the metafor Package. J Stat Softw. 2010;36:1&#x02013;48.</mixed-citation></citation-alternatives></ref><ref id="CR64"><label>64.</label><citation-alternatives><element-citation id="ec-CR64" publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>J R Stat Soc Ser B (Methodol)</source><year>1995</year><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation><mixed-citation id="mc-CR64" publication-type="journal">Benjamini Y, Hochberg Y. Controlling the false discovery rate: a practical and powerful approach to multiple testing. J R Stat Soc Ser B (Methodol). 1995;57:289&#x02013;300.</mixed-citation></citation-alternatives></ref><ref id="CR65"><label>65.</label><citation-alternatives><element-citation id="ec-CR65" publication-type="journal"><person-group person-group-type="author"><name><surname>Speed</surname><given-names>D</given-names></name><name><surname>Cai</surname><given-names>N</given-names></name><name><surname>Johnson</surname><given-names>MR</given-names></name><name><surname>Nejentsev</surname><given-names>S</given-names></name><name><surname>Balding</surname><given-names>DJ</given-names></name></person-group><article-title>Reevaluation of SNP heritability in complex human traits</article-title><source>Nat Genet</source><year>2017</year><volume>49</volume><fpage>986</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/ng.3865</pub-id><pub-id pub-id-type="pmid">28530675</pub-id>
</element-citation><mixed-citation id="mc-CR65" publication-type="journal">Speed D, Cai N, Johnson MR, Nejentsev S, Balding DJ. Reevaluation of SNP heritability in complex human traits. Nat Genet. 2017;49:986&#x02013;92.<pub-id pub-id-type="pmid">28530675</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR66"><label>66.</label><citation-alternatives><element-citation id="ec-CR66" publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Goddard</surname><given-names>ME</given-names></name><name><surname>Visscher</surname><given-names>PM</given-names></name><name><surname>Wray</surname><given-names>NR</given-names></name></person-group><article-title>Estimation of pleiotropy between complex diseases using single-nucleotide polymorphism-derived genomic relationships and restricted maximum likelihood</article-title><source>Bioinformatics</source><year>2012</year><volume>28</volume><fpage>2540</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bts474</pub-id><pub-id pub-id-type="pmid">22843982</pub-id>
</element-citation><mixed-citation id="mc-CR66" publication-type="journal">Lee SH, Yang J, Goddard ME, Visscher PM, Wray NR. Estimation of pleiotropy between complex diseases using single-nucleotide polymorphism-derived genomic relationships and restricted maximum likelihood. Bioinformatics. 2012;28:2540&#x02013;2.<pub-id pub-id-type="pmid">22843982</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR67"><label>67.</label><citation-alternatives><element-citation id="ec-CR67" publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Goddard</surname><given-names>ME</given-names></name><name><surname>Visscher</surname><given-names>PM</given-names></name></person-group><article-title>GCTA: a tool for genome-wide complex trait analysis</article-title><source>Am J Hum Genet</source><year>2011</year><volume>88</volume><fpage>76</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/j.ajhg.2010.11.011</pub-id><pub-id pub-id-type="pmid">21167468</pub-id>
</element-citation><mixed-citation id="mc-CR67" publication-type="journal">Yang J, Lee SH, Goddard ME, Visscher PM. GCTA: a tool for genome-wide complex trait analysis. Am J Hum Genet. 2011;88:76&#x02013;82.<pub-id pub-id-type="pmid">21167468</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR68"><label>68.</label><citation-alternatives><element-citation id="ec-CR68" publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><etal/></person-group><article-title>Scikit-learn: machine learning in python</article-title><source>J Mach Learn Res</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>30</lpage></element-citation><mixed-citation id="mc-CR68" publication-type="journal">Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. Scikit-learn: machine learning in python. J Mach Learn Res. 2011;12:2825&#x02013;30.</mixed-citation></citation-alternatives></ref></ref-list></back></article>