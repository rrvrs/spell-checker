<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39730438</article-id><article-id pub-id-type="pmc">PMC11680688</article-id><article-id pub-id-type="publisher-id">79603</article-id><article-id pub-id-type="doi">10.1038/s41598-024-79603-9</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Customer churn prediction model based on hybrid neural networks</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Xinyu</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Xia</surname><given-names>Guoen</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Zhang</surname><given-names>Xianquan</given-names></name><address><email>zxq6622@163.com</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Ma</surname><given-names>Wenbin</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Yu</surname><given-names>Chunqiang</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02frt9q65</institution-id><institution-id institution-id-type="GRID">grid.459584.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 2196 0260</institution-id><institution>College of Computer Science and Engineering, </institution><institution>Guangxi Normal University, </institution></institution-wrap>Guilin, 541000 China </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02c9qn167</institution-id><institution-id institution-id-type="GRID">grid.256609.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2254 5798</institution-id><institution>College of Business Administration, </institution><institution>Guangxi University, </institution></institution-wrap>Nanning, 530000 China </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02ayg6516</institution-id><institution-id institution-id-type="GRID">grid.453699.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 1759 3711</institution-id><institution>College of Business Administration, </institution><institution>Guangxi University of Finance and Economics, </institution></institution-wrap>Nanning, 530000 China </aff></contrib-group><pub-date pub-type="epub"><day>28</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>28</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>14</volume><elocation-id>30707</elocation-id><history><date date-type="received"><day>4</day><month>6</month><year>2024</year></date><date date-type="accepted"><day>11</day><month>11</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">In today&#x02019;s competitive market environment, accurately identifying potential churn customers and taking effective retention measures are crucial for improving customer retention and ensuring the sustainable development of an organization. However, traditional machine learning algorithms and single deep learning models have limitations in extracting complex nonlinear and time-series features, resulting in unsatisfactory prediction results. To address this problem, this study proposes a hybrid neural network-based customer churn prediction model, CCP-Net. In the data preprocessing stage, the ADASYN sampling algorithm balances the sample sizes of churned and non-churned customers to eliminate the negative impact of sample imbalance on the model performance. In the feature extraction stage, CCP-Net uses Multi-Head Self-Attention to learn the global dependencies of the input sequences, combines with BiLSTM to capture the long-term dependencies in the sequential data, and uses CNN to extract the local features, and ultimately generates the prediction results. Experimental results of cross-validation on Telecom, Bank, Insurance, and News datasets show that CCP-Net outperforms the comparison algorithms in all performance metrics. For example, CCP-Net achieves a Precision of 92.19% on the Telecom dataset, 91.96% on the Bank dataset, 95.87% on the Insurance dataset, and 95.12% on the News dataset, which compares to other hybrid neural network models, the performance improvement of CCP-Net ranges from 1% to 3%. These results indicate that the design of the CCP-Net model effectively improves the accuracy and robustness of churn prediction, enabling it to be widely applied to different industries, especially in the financial, telecommunication, and media fields, to provide more comprehensive and effective churn management strategies for enterprises.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Hybrid neural network</kwd><kwd>Churn prediction</kwd><kwd>Deep learning</kwd></kwd-group><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Computer science</kwd><kwd>Information technology</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>62062013</award-id><award-id>62162006</award-id><principal-award-recipient><name><surname>Zhang</surname><given-names>Xianquan</given-names></name><name><surname>Yu</surname><given-names>Chunqiang</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">In today&#x02019;s increasingly competitive business environment, the impact of customer churn on organizations is becoming increasingly significant. Churn refers to the behavior of customers who stop purchasing or using a company&#x02019;s products or services, including canceling subscriptions, terminating services, or switching to competitors. This phenomenon directly cuts down an organization&#x02019;s revenue and may damage its reputation, thus threatening its long-term development.</p><p id="Par3">With the advent of the big data era, the application of Customer Relationship Management (CRM) systems in customer data analysis is becoming increasingly critical. CRM systems can integrate customer contact information, interaction records, and purchase history, helping organizations comprehensively understand customers&#x02019; needs and gain real-time access to customer trends<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Studies have shown that increased customer churn significantly reduces business profits, and the cost of acquiring new customers is usually five times higher than maintaining existing ones<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. Therefore, in the fierce market competition, enterprises need to carry out customer churn prediction, identify potential lost customers, and take targeted retention strategies to improve customer loyalty and ensure the sustainable development of enterprises<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>.</p></sec><sec id="Sec2"><title>Related work</title><sec id="Sec3"><title>Literature review</title><sec id="Sec4"><title>Machine learning algorithm</title><p id="Par4">In the field of customer churn prediction, traditional methods mainly rely on machine learning algorithms, including Support Vector Machine(SVM)<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>, K-means clustering algorithm (K-means), Logistic Regression (LR)<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup>, Naive Bayes (NB)<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>, K-nearest Neighbor (KNN), Decision Tree (DT)<sup><xref ref-type="bibr" rid="CR7">7</xref>&#x02013;<xref ref-type="bibr" rid="CR9">9</xref></sup>, Random Forest (RF)<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>, LGBM, Adaboost<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, and XGBoost<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>.</p><p id="Par5">Xiahou et al.<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> proposed using K-means combined with SVM for customer churn prediction. The study showed that customer clustering by K-means significantly improves prediction accuracy. NV et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> explored the application of algorithms such as LR and NB in banking datasets and found that NB outperforms LR. Kiguchi et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> investigated the predictive effectiveness of LR, DT, and RF in the education market and the results showed that LR has the best performance. Ahmad et al.<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> tested algorithms such as DT, RF, and XGBoost in the Spark environment and found that XGBoost performs best. Lalwani et al.<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> performed feature selection by gravitational search algorithms and found that AdaBoost and XGBoost are the leading performances among multiple models. Sikri et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> proposed a Ratio-based sample balancing technique for unbalanced customer churn data and combined it with multiple independent machine learning algorithms for prediction. Dhanawade et al.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> significantly improved the model&#x02019;s performance for minority-class customer identification by combining multiple machine learning algorithms with SMOTE. The model can identify customers in a few categories and its prediction accuracy. He et al.<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> proposed an integrated learning approach called Ensemble-Fusion, which combines 17 algorithms and outperforms a single model.</p><p id="Par6">Although traditional machine learning algorithms perform well in processing structured data and simple feature engineering tasks, they are limited in extracting complex nonlinear features and processing large-scale datasets as the size and complexity of the data increase, leading to a decrease in prediction accuracy.</p></sec><sec id="Sec5"><title>Single deep learning algorithm</title><p id="Par7">In contrast to machine learning algorithms, deep learning algorithms show significant advantages in dealing with high-dimensional data and complex feature relationships, so more and more researchers are beginning to apply deep learning to customer churn prediction. Common deep learning algorithms include Backpropagation (BP)<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, Artificial Neural Networks (ANN)<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>, Multi-Layer Perceptron (MLP)<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>, Convolutional Neural Network (CNN)<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, Recurrent Neural Network (RNN)<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>, Long Short-Term Memory (LSTM)<sup><xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>, Bi-directional Long Short-Term Memory (BiLSTM)<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, TabNet<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>,and Transformer<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>.</p><p id="Par8">Khine et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> proposed a model combining K-means and MLP for bank customer churn prediction, which performs user clustering through K-means and subsequently uses MLP for prediction, and the results show that the model has high prediction accuracy and short training time. Venkatesh et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> developed an MLP model based on Artificial Fish Swarm Algorithm for customer churn prediction in IoT environment with an accuracy of 93.52%. In addition, Saha et al.<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> tested integrated learning algorithms (AdaBoost, RF, XGBoost, LGBM) with ANNs and CNNs and found that ANNs and CNNs exhibited the highest accuracy in the two datasets, respectively. Zhang et al.<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> explored the application of BiLSTM for customer churn prediction, and the experiments showed that BiLSTM outperforms traditional machine learning methods in terms of accuracy. Latheef et al.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> proposed the use of SMOTE to deal with category imbalance before using LSTM for churn prediction, and the experimental results showed that SMOTE substantially improved the prediction performance. Aditsania et al.<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> used Adaptive Synthetic Sampling (ADASYN) to process the data and combined it with the BP algorithm for customer churn prediction and achieved good results.</p><p id="Par9">Despite its excellent performance, a single deep-learning model still has limitations. For example, RNN and LSTM are good at capturing long-term dependencies. Still, they may be inadequate in extracting local features, while CNN, although outstanding in extracting local features, has limited effectiveness in dealing with long-term dependencies. Therefore, it is difficult for a single model to handle long-term dependencies and local feature extraction.</p></sec><sec id="Sec6"><title>Hybrid neural network model</title><p id="Par10">Hybrid neural network models have emerged to overcome the limitations of traditional machine learning and single deep learning algorithms. Such models significantly improve the accuracy and efficiency of churn prediction by combining different types of neural networks. Hybrid neural networks show great potential in this field.</p><p id="Par11">Zhou et al.<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> proposed a hybrid neural network model (LSTM-CNN) that combines LSTM and CNN, which can capture both long-term dependencies and local features, thus significantly improving the accuracy of prediction. Hu et al.<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> proposed a PRNN model that combines an RNN with an LSTM and incorporates a product operation to enhance the interaction capability between features. Khattak et al.<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> further innovated based on LSTM-CNN by using BiLSTM instead of LSTM, which improves the understanding of sequence information and enhances the performance of customer churn prediction. Wu<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> proposed a hybrid neural network model called HNNSAE that combines the entity embedding layer, feature extraction layer, and MLP; it significantly enhances the richness of feature representation and the ability to capture the correlation information between data using Multi-Head Self-Attention, which significantly improves the prediction performance. Wang et al.<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> introduced the Attention mechanism into the LSTM model to form an LSTM-Attention model, which enables the model to focus more on key information and improves the understanding of sequential data. Experimental results show that LSTM-Attention outperforms a single LSTM model in a customer churn prediction task. Wang et al.<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> proposed a FCLCNN-LSTM model, which, by combining the fully-connected layers, CNN, and LSTM, captures features from different layers and performs well in the customer churn prediction task.</p><p id="Par12">These studies show that hybrid neural network models have a promising application in customer churn prediction. They can overcome the limitations of a single deep learning model, understand data features more comprehensively, and improve prediction accuracy and efficiency.</p></sec></sec><sec id="Sec7"><title>Research motivations</title><p id="Par13">Although existing models have made some progress in improving the performance of customer churn prediction, they still face several key challenges, mainly including the following three points:<list list-type="bullet"><list-item><p id="Par14">Class imbalance problem: In actual customer churn datasets, the ratio of churned customers to non-churned customers is usually severely imbalanced. This imbalance can cause the model to overfit the majority class (non-churned customers) and under-identify the minority class (churned customers) during training, thus affecting the overall prediction performance.</p></list-item><list-item><p id="Par15">Limitations of feature extraction: existing hybrid neural network models are relatively homogeneous in their customer feature extraction methods, making it difficult to adequately capture the diversity and complexity of customer features and limiting the model&#x02019;s prediction accuracy.</p></list-item><list-item><p id="Par16">Insufficient generalization capability: most of the hybrid neural network studies have been validated only on datasets from a single industry, and the lack of evaluation of generalization performance on datasets from different domains limits the wide application of the model and its practical value.</p></list-item></list></p></sec><sec id="Sec8"><title>Research contributions</title><p id="Par17">To address the above challenges, this study proposes a hybrid neural network-based customer churn prediction model, Customer Churn Prediction Networks (CCP-Net), with the following key contributions:<list list-type="bullet"><list-item><p id="Par18">Solving the category imbalance problem: In the data preprocessing stage, this study adopts the ADASYN sampling algorithm to effectively address the category imbalance problem in the dataset. Compared with the traditional oversampling method, the synthetic samples generated by ADASYN are closer to the original data distribution. This avoids the model training bias caused by the inconsistent sample distribution, thus improving the negative impact of category imbalance on the prediction performance.</p></list-item><list-item><p id="Par19">Enhance feature extraction capability: By combining Multi-Head Self-Attention, BiLSTM, and CNN, CCP-Net gives full play to the advantages of each model, makes up for the deficiencies in the structural design of the existing hybrid neural networks, and significantly improves the comprehensiveness and accuracy of feature extraction. This multi-network synergistic design is of great significance to improve the accuracy of customer churn prediction.</p></list-item><list-item><p id="Par20">Enhanced generalization capability: through experiments on datasets from multiple industries (Telecom, Bank, Insurance, News), it is found that the CCP-Net model is not only suitable for churn prediction of Telecom, but also for churn prediction of Bank, Insurance, and News, and shows good prediction performance. This indicates that CCP-Net has a strong generalization ability and has the potential to be widely applied in different industries.</p></list-item></list></p></sec></sec><sec id="Sec9"><title>Proposed methodology</title><p id="Par21">Customer churn prediction involves complex multimodal data, which requires models that can handle multiple feature types simultaneously. Traditional single deep learning models (CNN or LSTM) each focus on different data features, making it difficult to comprehensively handle this type of complex data. Specifically, CNN excels in capturing spatial features and is particularly suitable for processing image data, but has limited effectiveness in processing time-series data; LSTM excels in capturing long-term dependencies in time-series and can effectively process time-series data, but is relatively deficient in extracting local features. In addition, in the face of complex scenarios such as feature interaction and category imbalance, it is often difficult for a single model to achieve ideal prediction performance.</p><p id="Par22">To solve the above problems, we propose the CCP-Net model. CCP-Net consists of three main modules: Multi-Head Self-Attention, BiLSTM, and CNN. The following is a detailed description of the CCP-Net model.</p><sec id="Sec10"><title>Multi-head self-attention</title><p id="Par23">Since the release of the Transformer model, Multi-Head Self-Attention has received a lot of attention. Multi-Head Self-Attention allows the attention heads to learn in parallel on different subspaces, enabling each attention head to focus on different aspects of the information in the sequence and, through the computation of different weight matrices, to generate finer-grained feature representations that better capture the various dependencies in the sequence. In the task of customer churn prediction, Multi-Head Self-Attention can help the model capture the key features and patterns in customer transaction data more effectively and improve the model&#x02019;s understanding and prediction of customer churn behavior. The structure of the improved Multi-Head Self-Attention mechanism model is shown in Figure <xref rid="Fig1" ref-type="fig">1</xref>:<fig id="Fig1"><label>Fig. 1</label><caption><p>Structure of the improved Multi-Head Self-Attention model.</p></caption><graphic xlink:href="41598_2024_79603_Fig1_HTML" id="MO1"/></fig></p><p id="Par24">The computational steps of Multi-Head Self-Attention are as follows:</p><p id="Par25">(1) Projection</p><p id="Par26">The input sequence <italic>X</italic> is linearly mapped to obtain the representation of multiple subspaces respectively.</p><p id="Par27">(2) Attention matrix computation</p><p id="Par28">Attention computation is performed for each projected subspace separately. The attention module of each subspace requires matrix operations, and the output of the attention matrix can be computed using Equation&#x000a0;<xref rid="Equ1" ref-type="disp-formula">1</xref>, where <italic>Q</italic> denotes the query vector,&#x000a0;<italic>K</italic> denotes the key vector,<italic>v</italic> denotes the value vector, and <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{k}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq1.gif"/></alternatives></inline-formula> denotes the dimension of <italic>K</italic>. The output of each attention head can be derived using Equation&#x000a0;<xref rid="Equ2" ref-type="disp-formula">2</xref>, where <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$head_{i}$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq2.gif"/></alternatives></inline-formula> denotes the output of the <italic>i</italic>th attention head, and <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_i^QW_i^KW_i^V$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>Q</mml:mi></mml:msubsup><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>K</mml:mi></mml:msubsup><mml:msubsup><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq3.gif"/></alternatives></inline-formula> denotes the weight of the <italic>i</italic>th attention head of the <italic>Q</italic>,<italic>K</italic>,<italic>V</italic> vector, respectively.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Attention(Q,K,V)= &#x00026; Soft\textrm{max}(\frac{QK^T}{\sqrt{d_k}})\cdot V \end{aligned}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mtext>max</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:msup><mml:mi>K</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} head_{i}= &#x00026; Attention(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V}) \end{aligned}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>(3) Combination</p><p id="Par29">As shown in Equation&#x000a0;<xref rid="Equ3" ref-type="disp-formula">3</xref>, the outputs of each attention head are combined by a linear mapping, and <italic>Concat</italic> denotes the combination operation.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} MultiHead(Q,K,V)=Concat(head_1,...,head_h) \end{aligned}$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>(4) Output</p><p id="Par30">The final output of Multi-Head Self-Attention is obtained by linear mapping the combined outputs as shown in Equation&#x000a0;<xref rid="Equ4" ref-type="disp-formula">4</xref>, <inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W^o$$\end{document}</tex-math><mml:math id="M14"><mml:msup><mml:mi>W</mml:mi><mml:mi>o</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq4.gif"/></alternatives></inline-formula> denotes the weights of the linear mapping.<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Output=MultiHead(Q,K,V)\cdot W^{0} \end{aligned}$$\end{document}</tex-math><mml:math id="M16" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>To alleviate the gradient vanishing and promote the information transfer, we introduce the residual connection and Layer Normalization (LN) on Multi-Head Self-Attention, which improves the expressive ability of the model and accelerates the convergence speed, to train the model more effectively. The residual connection and Layer Normalisation are shown in Equation&#x000a0;<xref rid="Equ5" ref-type="disp-formula">5</xref> and Equation&#x000a0;<xref rid="Equ6" ref-type="disp-formula">6</xref> respectively:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Y= &#x00026; X+Output \end{aligned}$$\end{document}</tex-math><mml:math id="M18" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} LayerNorm(Y)= &#x00026; \frac{Y-\mu }{\sigma }\gamma +\beta \end{aligned}$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>N</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mfrac><mml:mi>&#x003b3;</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq5"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu$$\end{document}</tex-math><mml:math id="M22"><mml:mi>&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq5.gif"/></alternatives></inline-formula> and <inline-formula id="IEq6"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M24"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq6.gif"/></alternatives></inline-formula> are the mean and standard deviation of input <italic>Y</italic>, respectively, while <inline-formula id="IEq7"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M26"><mml:mi>&#x003b3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq7.gif"/></alternatives></inline-formula> and <inline-formula id="IEq8"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta$$\end{document}</tex-math><mml:math id="M28"><mml:mi>&#x003b2;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq8.gif"/></alternatives></inline-formula> are learnable parameters.</p></sec><sec id="Sec11"><title>BiLSTM</title><p id="Par31">BiLSTM processes the input data by forward LSTM and reverse LSTM, in which LSTM has an input gate, forgetting gate, cell gate, and output gate, which can effectively learn and memorize the historical and future temporal information in the data. For example, if a customer has recently made frequent transactions with a company, the probability of churn is significantly reduced; on the contrary, the risk of churn increases. The LSTM model structure is shown in Figure <xref rid="Fig2" ref-type="fig">2</xref>:<fig id="Fig2"><label>Fig. 2</label><caption><p>Structure of LSTM model.</p></caption><graphic xlink:href="41598_2024_79603_Fig2_HTML" id="MO2"/></fig></p><p id="Par32">(1) Forgetting Gate</p><p id="Par33">The function of the forgetting gate is to decide what information to discard from the cell gate. The input of the forgetting gate consists of the output of the hidden state in the previous time step <inline-formula id="IEq9"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t-1}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq9.gif"/></alternatives></inline-formula> and the input of the current time step <inline-formula id="IEq10"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{t}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq10.gif"/></alternatives></inline-formula>, which are multiplied with the corresponding weights <inline-formula id="IEq11"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{fh}$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">fh</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq11.gif"/></alternatives></inline-formula> and <inline-formula id="IEq12"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{fx}$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">fx</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq12.gif"/></alternatives></inline-formula>, respectively, and then added with the bias of the forgetting gate <inline-formula id="IEq13"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b_{f}$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq13.gif"/></alternatives></inline-formula>, which is mapped to the interval [0,1] by the Sigmoid function <inline-formula id="IEq14"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M40"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq14.gif"/></alternatives></inline-formula> to decide the information to be discarded as shown in Equation&#x000a0;<xref rid="Equ7" ref-type="disp-formula">7</xref> to get the output of the forgetting gate <inline-formula id="IEq15"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{t}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq15.gif"/></alternatives></inline-formula>.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} f_t=\sigma (W_{fh}h_{t-1}+W_{fx}X_t+b_f) \end{aligned}$$\end{document}</tex-math><mml:math id="M44" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">fh</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">fx</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>(2) Input gate</p><p id="Par34">The function of the input gate is to determine the information to be stored in the cell gate. The output of the previous time step <inline-formula id="IEq16"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t-1}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq16.gif"/></alternatives></inline-formula> and the input of the current time step <inline-formula id="IEq17"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{t}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq17.gif"/></alternatives></inline-formula> will be multiplied by the corresponding weights <inline-formula id="IEq18"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{ix}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ix</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq18.gif"/></alternatives></inline-formula> and <inline-formula id="IEq19"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{ih}$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ih</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq19.gif"/></alternatives></inline-formula>, respectively, and then added to the input gate bias <inline-formula id="IEq20"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b_{i}$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq20.gif"/></alternatives></inline-formula>. These values are mapped to the [0,1] interval by the Sigmoid function <inline-formula id="IEq21"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M56"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq21.gif"/></alternatives></inline-formula> indicating the degree of updating the cell gate as shown in Equation&#x000a0;<xref rid="Equ8" ref-type="disp-formula">8</xref> to obtain the output of the input gate <inline-formula id="IEq22"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i_{t}$$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq22.gif"/></alternatives></inline-formula>.<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} i_t=\sigma (W_{ix}h_{t-1}+W_{ih}X_{t}+b_{i}) \end{aligned}$$\end{document}</tex-math><mml:math id="M60" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ix</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ih</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>(3) Cell gate</p><p id="Par35">The cell gate consists of two key steps: computing the new candidate value vector and updating the cell gate.</p><p id="Par36">To compute the new candidate value vector, it is necessary to multiply the hidden state of the previous time step <inline-formula id="IEq23"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t-1}$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq23.gif"/></alternatives></inline-formula> and the input of the current time step <inline-formula id="IEq24"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{t}$$\end{document}</tex-math><mml:math id="M64"><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq24.gif"/></alternatives></inline-formula> with the corresponding weights <inline-formula id="IEq25"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{ch}$$\end{document}</tex-math><mml:math id="M66"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ch</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq25.gif"/></alternatives></inline-formula> and <inline-formula id="IEq26"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{cx}$$\end{document}</tex-math><mml:math id="M68"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">cx</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq26.gif"/></alternatives></inline-formula>, respectively, and then add the bias of the cell gate candidate values <inline-formula id="IEq27"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b_{c}$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mi>b</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq27.gif"/></alternatives></inline-formula>, which are mapped by the hyperbolic tangent function <italic>tanh</italic> into the interval [-1, 1] as shown in Equation&#x000a0;<xref rid="Equ9" ref-type="disp-formula">9</xref>, to generate a new candidate value vector <inline-formula id="IEq28"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{C}_{t}$$\end{document}</tex-math><mml:math id="M72"><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq28.gif"/></alternatives></inline-formula>. This new candidate value vector represents the candidate values to be updated to the cell gate.<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \tilde{C}_{t}=\textrm{tanh}(W_{Ch}h_{t-1}+W_{cx}X_{t}+b_{c}) \end{aligned}$$\end{document}</tex-math><mml:math id="M74" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>tanh</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">Ch</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">cx</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>For the step of updating the cell gate, the cell gate <inline-formula id="IEq29"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t-1}$$\end{document}</tex-math><mml:math id="M76"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq29.gif"/></alternatives></inline-formula> from the previous time step is multiplied element-by-element with the forget gate <inline-formula id="IEq30"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{t}$$\end{document}</tex-math><mml:math id="M78"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq30.gif"/></alternatives></inline-formula> via <inline-formula id="IEq31"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bigodot$$\end{document}</tex-math><mml:math id="M80"><mml:mo>&#x02a00;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq31.gif"/></alternatives></inline-formula>, discarding the information that needs to be discarded. Then the new candidate value <inline-formula id="IEq32"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{C}_{t}$$\end{document}</tex-math><mml:math id="M82"><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq32.gif"/></alternatives></inline-formula> is multiplied element by element with the input gate <inline-formula id="IEq33"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i_{t}$$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq33.gif"/></alternatives></inline-formula> via <inline-formula id="IEq34"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bigodot$$\end{document}</tex-math><mml:math id="M86"><mml:mo>&#x02a00;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq34.gif"/></alternatives></inline-formula> to add the information that needs to be input. As shown in Equation&#x000a0;<xref rid="Equ10" ref-type="disp-formula">10</xref>, the two are added together to get the updated cell gate <inline-formula id="IEq35"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t}$$\end{document}</tex-math><mml:math id="M88"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq35.gif"/></alternatives></inline-formula>.<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} C_t=f_t\odot C_{t-1}+i_t\odot \tilde{C}_t \end{aligned}$$\end{document}</tex-math><mml:math id="M90" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02299;</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02299;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>(4) Output gate</p><p id="Par37">The output gate controls the extent to which the hidden state of the current time step is output to the external output. As shown in Equation&#x000a0;<xref rid="Equ11" ref-type="disp-formula">11</xref>, the output gate <inline-formula id="IEq36"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_{t}$$\end{document}</tex-math><mml:math id="M92"><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq36.gif"/></alternatives></inline-formula> is computed from the output of the previous time step <inline-formula id="IEq37"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t-1}$$\end{document}</tex-math><mml:math id="M94"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq37.gif"/></alternatives></inline-formula> and the input of the current time step <inline-formula id="IEq38"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{t}$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq38.gif"/></alternatives></inline-formula>, which are multiplied with the corresponding weights <inline-formula id="IEq39"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{oh}$$\end{document}</tex-math><mml:math id="M98"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">oh</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq39.gif"/></alternatives></inline-formula> and <inline-formula id="IEq40"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{ox}$$\end{document}</tex-math><mml:math id="M100"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ox</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq40.gif"/></alternatives></inline-formula>, respectively, and then added to the bias of the output gate <inline-formula id="IEq41"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b_{o}$$\end{document}</tex-math><mml:math id="M102"><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq41.gif"/></alternatives></inline-formula>. These values are mapped to the interval [0,1] by the Sigmoid function <inline-formula id="IEq42"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M104"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq42.gif"/></alternatives></inline-formula> indicating which parts of the hidden state <inline-formula id="IEq43"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t}$$\end{document}</tex-math><mml:math id="M106"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq43.gif"/></alternatives></inline-formula> of the current time step will be output to the outside of the network.<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} O_{t}=\sigma (W_{oh}h_{t-1}+W_{ox}X_{t}+b_{o}) \end{aligned}$$\end{document}</tex-math><mml:math id="M108" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">oh</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ox</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>As shown in Equation&#x000a0;<xref rid="Equ12" ref-type="disp-formula">12</xref>, the hidden state <inline-formula id="IEq44"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t}$$\end{document}</tex-math><mml:math id="M110"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq44.gif"/></alternatives></inline-formula> update is accomplished by the element-by-element product <inline-formula id="IEq45"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bigodot$$\end{document}</tex-math><mml:math id="M112"><mml:mo>&#x02a00;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq45.gif"/></alternatives></inline-formula> and the hyperbolic tangent function <italic>tanh</italic>. The output gate <inline-formula id="IEq46"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O_{t}$$\end{document}</tex-math><mml:math id="M114"><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq46.gif"/></alternatives></inline-formula> controls the extent to which <italic>tanh</italic> acts on the cell gate <inline-formula id="IEq47"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t}$$\end{document}</tex-math><mml:math id="M116"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq47.gif"/></alternatives></inline-formula> to obtain the hidden state <inline-formula id="IEq48"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t}$$\end{document}</tex-math><mml:math id="M118"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq48.gif"/></alternatives></inline-formula> for the current time step.<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} h_t=O_t\odot \tanh (C_t) \end{aligned}$$\end{document}</tex-math><mml:math id="M120" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02299;</mml:mo><mml:mo>tanh</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>The BiLSTM model structure is shown in Figure <xref rid="Fig3" ref-type="fig">3</xref>.<fig id="Fig3"><label>Fig. 3</label><caption><p>Structure of BiLSTM model.</p></caption><graphic xlink:href="41598_2024_79603_Fig3_HTML" id="MO3"/></fig></p><p id="Par38">The output of BiLSTM <inline-formula id="IEq49"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Output_{BiLSTM}$$\end{document}</tex-math><mml:math id="M122"><mml:mrow><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">BiLSTM</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq49.gif"/></alternatives></inline-formula> is a concatenation of the hidden state <inline-formula id="IEq50"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{forward}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi mathvariant="italic">forward</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq50.gif"/></alternatives></inline-formula> of the forward propagation LSTM and the hidden state <inline-formula id="IEq51"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{backward}$$\end{document}</tex-math><mml:math id="M126"><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi mathvariant="italic">backward</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq51.gif"/></alternatives></inline-formula> of the backward propagation LSTM as shown in Equation&#x000a0;<xref rid="Equ13" ref-type="disp-formula">13</xref>:<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Output_{BiLSTM}=[h_{forward},h_{backward}] \end{aligned}$$\end{document}</tex-math><mml:math id="M128" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>O</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="italic">BiLSTM</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi mathvariant="italic">forward</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi mathvariant="italic">backward</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula></p></sec><sec id="Sec12"><title>CNN</title><p id="Par39">CNN is a feed-forward neural network, which consists of a convolutional layer, activation layer, pooling layer, and fully connected layer, and can extract the local features of the data through different sizes of filters, effectively learning the spatial structure of the input data and convert it into high-dimensional feature representations, and help the CCP-Net model to learn more complex and advanced features from the transaction data through multiple convolution, activation, and pooling operations. The CNN model structure is shown in Figure <xref rid="Fig4" ref-type="fig">4</xref>.<fig id="Fig4"><label>Fig. 4</label><caption><p>Structure of CNN model.</p></caption><graphic xlink:href="41598_2024_79603_Fig4_HTML" id="MO4"/></fig></p><p id="Par40">(1) Convolutional layer</p><p id="Par41">The data is fed into the convolutional layer and a convolution operation will be performed to capture the local features and generate the feature map, the convolution operation can be expressed by Equation&#x000a0;<xref rid="Equ14" ref-type="disp-formula">14</xref>. Where <italic>X</italic> is the input data,&#x000a0;<italic>W</italic> is the convolution kernel, the step size is <italic>s</italic>,&#x000a0;<inline-formula id="IEq52"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Conv_{i}$$\end{document}</tex-math><mml:math id="M130"><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq52.gif"/></alternatives></inline-formula> is the <italic>i</italic>th neuron in the output of the convolution layer,&#x000a0;<inline-formula id="IEq53"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{i\cdot s+j}$$\end{document}</tex-math><mml:math id="M132"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq53.gif"/></alternatives></inline-formula> is the <inline-formula id="IEq54"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i\cdot s+j$$\end{document}</tex-math><mml:math id="M134"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq54.gif"/></alternatives></inline-formula>th element of the input data,&#x000a0;<inline-formula id="IEq55"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{j}$$\end{document}</tex-math><mml:math id="M136"><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq55.gif"/></alternatives></inline-formula> is the <italic>j</italic>th weight of the convolution kernel and <italic>b</italic> is the bias.<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Conv_{i}=\sum _{j=1}^{k}X_{i\cdot s+j}\cdot W_{j}+b \end{aligned}$$\end{document}</tex-math><mml:math id="M138" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>(2) Activation layer</p><p id="Par42">After the convolutional layer, an activation function will be used to introduce nonlinear features to enhance the expressive ability of the neural network, this model uses the <italic>Relu</italic> activation function, which can overcome the problem of gradient vanishing and make the model have a faster training speed, the <italic>Relu</italic> activation function is shown in Equation&#x000a0;<xref rid="Equ15" ref-type="disp-formula">15</xref>.&#x000a0;<inline-formula id="IEq56"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$A_{i}$$\end{document}</tex-math><mml:math id="M140"><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq56.gif"/></alternatives></inline-formula> denotes the <italic>i</italic>th neuron in the output of the activation layer;<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} A_{i}=max(0,Con\nu _{i}) \end{aligned}$$\end{document}</tex-math><mml:math id="M142" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>&#x003bd;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula>(3) Pooling layer</p><p id="Par43">The data is fed into a pooling layer that reduces the size of the feature map and the number of parameters while retaining key information; this model uses maximum pooling as shown in Equation&#x000a0;<xref rid="Equ16" ref-type="disp-formula">16</xref>.&#x000a0;<italic>P</italic> is the size of the pooling window, and <inline-formula id="IEq57"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P_{i}$$\end{document}</tex-math><mml:math id="M144"><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq57.gif"/></alternatives></inline-formula> denotes the <italic>i</italic>th neuron output from the pooling layer;<disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} P_{i}=max(A_{i\cdot p:(i+1)\cdot p}) \end{aligned}$$\end{document}</tex-math><mml:math id="M146" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>p</mml:mi><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula>(4) Fully connected layer</p><p id="Par44">The fully connected layer spreads the previously extracted features to get the prediction result <italic>fc</italic>. As shown in Equation&#x000a0;<xref rid="Equ17" ref-type="disp-formula">17</xref>.&#x000a0;<inline-formula id="IEq58"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{fc}$$\end{document}</tex-math><mml:math id="M148"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">fc</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq58.gif"/></alternatives></inline-formula> is the weight of the fully connected layer and <inline-formula id="IEq59"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b_{fc}$$\end{document}</tex-math><mml:math id="M150"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">fc</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq59.gif"/></alternatives></inline-formula> is the bias of the fully connected layer.<disp-formula id="Equ17"><label>17</label><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} fc=P\cdot W_{fc}+b_{fc} \end{aligned}$$\end{document}</tex-math><mml:math id="M152" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">fc</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">fc</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ17.gif" position="anchor"/></alternatives></disp-formula></p></sec><sec id="Sec13"><title>CCP-Net model</title><p id="Par45">Existing hybrid neural network models have some shortcomings in their structural design. For example, the PRNN model mainly relies on RNN and LSTM, but RNN and LSTM are prone to gradient vanishing or gradient explosion problems when dealing with long-term dependencies, which limits their performance in customer churn prediction tasks. The HNNSAE model relies only on multi-head self-attention for feature extraction, and the single LSTM-Attention and GRU-Attention models are excellent at time series feature extraction, but are deficient in local feature extraction, resulting in limited prediction accuracy. In contrast, the LSTM-CNN, BiLSTM-CNN, and FCLCNN-LSTM models are capable of extracting both local and global features, but are still deficient in dealing with complex global dependencies, while Multi-Head Self-Attention is more advantageous in capturing complex global dependencies, which enhances the model&#x02019;s feature extraction capability.<fig id="Fig5"><label>Fig. 5</label><caption><p>Structure of CCP-Net model.</p></caption><graphic xlink:href="41598_2024_79603_Fig5_HTML" id="MO5"/></fig></p><p id="Par46">To address these limitations, this study proposes a customer churn prediction network model called CCP-Net, CCP-Net combines three types of neural networks: Multi-Head Self-Attention, BiLSTM, and CNN. The structure of CCP-Net is shown in Figure <xref rid="Fig5" ref-type="fig">5</xref>.<list list-type="bullet"><list-item><p id="Par47">Multi-Head Self-Attention Module:</p><p id="Par151">CCP-Net first uses the Multi-Head Self-Attention module to process customer transaction sequences. This module focuses on different parts of the information in the sequence by decomposing the input sequence into multiple attention heads that learn in parallel in different subspaces. Compared with the single-attention mechanism, Multi-Head Attention can capture the complex relationships between features and effectively extract key information and potential patterns in the transaction data by weighted summation of the outputs of individual attention heads.</p><p id="Par152">Multi-Head Self-Attention can capture global dependencies and process information in parallel, avoiding the information decay triggered by the step-by-step processing of traditional sequential models (e.g., LSTM and GRU). In addition, the multi-head mechanism enables the model to focus on the contextual information of different parts of the input sequence to fully capture the complex dependencies between features, especially in the task of customer churn prediction, which helps to capture global contextual information in long time series, such as customers&#x02019; historical behaviors, consumption habits, and long-term dependencies. In this way, the model can capture complex dependencies quickly, avoiding the problem of gradient vanishing or gradient explosion, resulting in a more comprehensive understanding of customer behavior patterns.</p></list-item><list-item><p id="Par48">BiLSTM module:</p><p id="Par153">The output of the Multi-Head Self-Attention is then passed to the BiLSTM module, which, by processing the input sequences in both directions, can take into account both the information flows from the past and the future, leading to a more comprehensive understanding of the context of the sequence data. Compared to BiGRU, BiLSTM introduces three important gating mechanisms - input gates, forgetting gates, and output gates - which effectively manage the storing and forgetting of information to ensure that important contextual information is retained over long sequences. This gives BiLSTM a significant advantage in dealing with complex long-term dependencies, especially in customer churn prediction, where customer churn behavior is usually influenced by multiple factors that may be distributed at different locations in the time series.</p><p id="Par154">Through the two-way propagation mechanism, BiLSTM is not only able to capture past behavioral information but also predict future changes, which comprehensively improves the model&#x02019;s prediction capability. In contrast, although BiGRU is also capable of bi-directional processing, it has a relatively simplified structure and relies only on update gates and reset gates to control the flow of information, which reduces the amount of computation, but BiGRU is more limited than BiLSTM in the modeling of long-term dependencies. As a result, BiLSTM is more suitable for capturing long-term behavioral patterns in customer churn prediction and can more accurately model important features in long-term time series.</p></list-item><list-item><p id="Par49">CNN module:</p><p id="Par155">The output of the BiLSTM module is then passed to the CNN module, which extracts local features through convolutional operations to capture short-term patterns in the transactional data. The CNN&#x02019;s translation invariance enables it to identify local features efficiently. It combines with the ReLU activation function to introduce nonlinearities and reduce the feature dimensions through a maximal pooling operation to transform the local features into a higher-dimensional representation. Through multi-layer convolution operation, CNN performs layer-by-layer feature extraction on the input data and can discover important local patterns. In the task of churn prediction, local features such as short-term behavioral patterns and immediate changes in customer interactions are also critical, and CNNs help the model better understand short-term customer behavioral changes by capturing these local features, which enhances the model&#x02019;s prediction capability.</p></list-item></list></p><p id="Par156">In summary, by combining the advantages of Multi-Head Self-Attention, BiLSTM, and CNN, CCP-Net overcomes the deficiencies of existing models in capturing global and local dependencies and comprehensively improves the performance of customer churn prediction. Multi-Head Self-Attention provides a global perspective, helping the model to capture complex customer behavior patterns; BiLSTM strengthens long-term dependency learning in time series and effectively handles multi-dimensional information of customer churn; CNN excels in local feature extraction, enabling the model to achieve efficient learning at different feature levels. Through this comprehensive design, CCP-Net not only significantly improves the prediction accuracy, but also enhances its applicability in practical applications.</p></sec></sec><sec id="Sec14"><title>Experiment</title><p id="Par50">The experiment is divided into the following four steps:(1) Data acquisition, (2) Data preprocessing, (3) Building the CCP-Net model and training, and (4) Experimental analysis. The flow of the experiment is shown in Figure <xref rid="Fig6" ref-type="fig">6</xref>.<fig id="Fig6"><label>Fig. 6</label><caption><p>Flow chart of the experiment.</p></caption><graphic xlink:href="41598_2024_79603_Fig6_HTML" id="MO6"/></fig></p><sec id="Sec15"><title>Data acquisition</title><p id="Par51">Four customer churn datasets from the Kaggle data science competition platform are used in this study, including Telecom<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, Bank<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>, Insurance<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, and News<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. These datasets are widely used in the field of customer churn prediction, facilitating the comparison of the model proposed in this paper with other models. Table <xref rid="Tab1" ref-type="table">1</xref> summarises the details of each dataset and shows that all these datasets suffer from significant category imbalance.<list list-type="bullet"><list-item><p id="Par52">The Telecom dataset contains customers&#x02019; transaction frequency, service usage, and churn history.</p></list-item><list-item><p id="Par53">The Bank dataset records customers&#x02019; transaction behavior, account balances, and other financial activities.</p></list-item><list-item><p id="Par54">The Insurance dataset provides historical information about customers and product usage.</p></list-item><list-item><p id="Par55">The News dataset includes information about users&#x02019; reading habits, language, address, and more.</p></list-item></list></p></sec><sec id="Sec16"><title>Data preprocessing</title><p id="Par56">Data preprocessing is a critical step to ensure model performance. Our preprocessing steps for the four datasets are as follows:<table-wrap id="Tab1"><label>Table 1</label><caption><p>Dataset information.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">sample size</th><th align="left">number of features</th><th align="left">number of churned customers</th><th align="left">number of non-churned customers</th><th align="left">churn rate</th></tr></thead><tbody><tr><td align="left">Telecom</td><td align="left">7043</td><td align="left">21</td><td align="left">1869</td><td align="left">5163</td><td align="left">26.58%</td></tr><tr><td align="left">Bank</td><td align="left">10000</td><td align="left">14</td><td align="left">2037</td><td align="left">7963</td><td align="left">20.37%</td></tr><tr><td align="left">Insurance</td><td align="left">33908</td><td align="left">17</td><td align="left">3967</td><td align="left">29941</td><td align="left">11.70%</td></tr><tr><td align="left">News</td><td align="left">15855</td><td align="left">19</td><td align="left">3037</td><td align="left">12818</td><td align="left">19.15%</td></tr></tbody></table></table-wrap></p><sec id="Sec17"><title>Data cleansing</title><p id="Par57">In our initial data exploration, we found a small number of missing and duplicate values in the dataset. Since these problematic data accounted for a relatively small percentage of the data, it was straightforward to remove rows that contained missing or duplicate values. For example, the &#x02019;Language&#x02019;, &#x02019;weekly fee&#x02019;, and &#x02019;Nielsen Prizm&#x02019; columns in the News dataset had some missing values, and deleting the corresponding rows was sufficient. In addition, entries with similar but different expressions are unified, e.g., in the Telecom dataset, &#x02019;No internet service&#x02019; and &#x02019;No phone service&#x02019; are unified as &#x02019;No&#x02019;.</p></sec><sec id="Sec18"><title>Data encoding</title><p id="Par58">The dataset contains both numeric and categorical data.<list list-type="bullet"><list-item><p id="Par59">For numerical data, we used standardization to adjust their mean to 0 and variance to 1 to ensure the consistency of different features on the numerical scale.</p></list-item><list-item><p id="Par60">For category-based data, since the format of category-based data is string-based, it cannot be directly used for further calculations, so we need to convert the string data to numeric representation through label encoding and convert the string format of category-based data to numeric representation so that the model can recognize the relationship between different categories. For example, in the Bank dataset, the category values of &#x02019;Geography&#x02019; and &#x02019;Gender&#x02019; are encoded as 0, 1, 2, etc.</p></list-item></list></p></sec><sec id="Sec19"><title>Feature selection</title><p id="Par61">To reduce feature dimensionality and remove noise, we use correlation heatmaps to identify features with low correlation with the target variable. Heatmap is a visualization tool that demonstrates the correlation between features through shades of colors, and its core principle is based on the calculation of the correlation coefficient, which is used to measure the strength and direction of the linear relationship between two variables and takes the value in the range of [-1, 1]. Specifically, 1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation.</p><p id="Par62">By analyzing the correlation coefficients on the correlation heatmap, we can exclude feature columns with low correlation with the target variable, thus avoiding overfitting the model to unimportant features. This strategy not only reduces the training time but also enhances the generalization ability of the model. The main reason for choosing to remove features with correlation coefficients below a specific threshold is to reduce noise and improve the validity and interpretability of the model. Features with low correlation may not have a significant impact on the prediction of the target variable, and retaining them may introduce interference and lead to a decrease in model performance. By removing unimportant features, the model can focus more on features that are more relevant to the target variable, thus improving generalization on new data and reducing the risk of overfitting, as well as shortening training time.</p><p id="Par63">Figures <xref rid="Fig7" ref-type="fig">7</xref>, <xref rid="Fig8" ref-type="fig">8</xref>, <xref rid="Fig9" ref-type="fig">9</xref>, <xref rid="Fig10" ref-type="fig">10</xref> show the correlation heatmaps for the datasets Telecom, Bank, Insurance, and News, respectively.<fig id="Fig7"><label>Fig. 7</label><caption><p>Heatmap of Telecom dataset correlation.</p></caption><graphic xlink:href="41598_2024_79603_Fig7_HTML" id="MO7"/></fig><fig id="Fig8"><label>Fig. 8</label><caption><p>Heatmap of Bank dataset correlation.</p></caption><graphic xlink:href="41598_2024_79603_Fig8_HTML" id="MO8"/></fig><fig id="Fig9"><label>Fig. 9</label><caption><p>Heatmap of Insurance dataset correlation.</p></caption><graphic xlink:href="41598_2024_79603_Fig9_HTML" id="MO9"/></fig><fig id="Fig10"><label>Fig. 10</label><caption><p>Heatmap of News dataset correlation.</p></caption><graphic xlink:href="41598_2024_79603_Fig10_HTML" id="MO10"/></fig></p><p id="Par64">
<list list-type="bullet"><list-item><p id="Par65">Telecom dataset</p><p id="Par66">In the Telecom dataset, we removed feature columns with correlation coefficients less than 0.1, including &#x02018;customerID&#x02019;, &#x02018;Gender&#x02019;, &#x02018;PhoneService&#x02019;, &#x02018;MultipleLines&#x02019;, &#x02018;InternetService&#x02019;, &#x02018;StreamingTV&#x02019;, and &#x02018; StreamingMovies&#x02019;. These features are not considered important for the following reasons:</p><p id="Par666">&#x02018;customerID&#x02019;: this feature is a unique identifier for each customer and does not provide meaningful correlation information when predicting churn. It is only an identifier and does not reflect the customer&#x02019;s behavior or other characteristics that can be used for churn prediction.</p><p id="Par667">&#x02018;Gender&#x02019; and &#x02018;PhoneService&#x02019;: while gender and having a phone service not may have an impact on customer behavior in some scenarios, in this dataset these features are weakly correlated with churn, showing a low correlation that may lead to overfitting of the model or learning to noise.</p><p id="Par668">&#x02018;MultipleLines&#x02019;, &#x02018;InternetService&#x02019;, &#x02018;StreamingTV&#x02019;, and &#x02018;StreamingMovies&#x02019;: these features are more indirectly related to whether or not a customer is churning, and the correlation is low, especially when there is no further data to support it (e.g., the customer&#x02019;s specific usage). For example, whether or not a customer uses a particular service does not always reflect whether or not they will churn, and therefore these features were not considered sufficiently important in this experiment.</p></list-item><list-item><p id="Par67">Bank dataset</p><p id="Par68">For the Bank dataset, we removed feature columns with correlation coefficients less than 0.03: &#x02018;CustomerId&#x02019;, &#x02018;Surname&#x02019;, &#x02018;Tenure&#x02019;, &#x02018;HasCrCard&#x02019;, and &#x02018;EstimatedSalary&#x02019;. The reason for deleting these features is as follows:</p><p id="Par688">&#x02018;CustomerId&#x02019; and &#x02018;Surname&#x02019;: these two features are unique identifiers or surnames of customers and are unsuitable for predicting churn as they do not contain any key information about customer behavior or correlation to churn. As identifying information only, they have no real value for model training.</p><p id="Par689">&#x02018;Tenure&#x02019; and &#x02018;EstimatedSalary&#x02019;: the low correlation of these features suggests that they contribute less to churn prediction.&#x02019; Tenure&#x02019; may be correlated with customer churn, but the correlation with churn is weak in this dataset. &#x02018;EstimatedSalary&#x02019; also has limited predictive power and may not be as meaningful as other financial or behavioral characteristics of customers.</p></list-item><list-item><p id="Par69">Insurance dataset</p><p id="Par70">In the Insurance dataset, we removed feature columns with correlation coefficients less than 0.05: &#x0201c;feature_0&#x0201d;, &#x0201c;feature_2&#x0201d;, &#x0201c;feature_7&#x0201d;, &#x0201c;feature_10&#x0201d;, and &#x0201c;feature_14&#x0201d;. The reasons for the deletion of these features are as follows:</p><p id="Par701">&#x0201c;feature_0&#x0201d;, &#x0201c;feature_2&#x0201d;, &#x0201c;feature_7&#x0201d;, &#x0201c;feature_10&#x0201d;, and &#x0201c;feature_14&#x0201d;: these features had a weak correlation with the target variable (churn) in the preliminary analysis. They do not provide enough information to help distinguish whether customers are churning or not, and may simply be noise or irrelevant information in the data. Retaining these features introduces unnecessary complexity and leads to a reduction in model performance, so they were chosen to be removed.</p></list-item><list-item><p id="Par71">News dataset</p><p id="Par72">For the News dataset, we removed feature columns with correlation coefficients less than 0.05: &#x02018;Ethnicity&#x02019;, &#x02018;dummy for Children&#x02019;, &#x02018;Address&#x02019;, &#x02018;City&#x02019;, &#x02018;County&#x02019;, &#x02018;Zip Code&#x02019;, &#x02018;weekly fee&#x02019;, &#x02018;Nielsen Prizm&#x02019; and &#x02018; Source Channel&#x02019;. The reasons for removing these features are as follows:</p><p id="Par722">&#x02018;Ethnicity&#x02019; and &#x02018;dummy for Children&#x02019;: these two features are of low relevance and may introduce bias or sensitivity issues, particularly in social science data. They fail to provide a meaningful contribution to the prediction of attrition rates.</p><p id="Par724">&#x02018;Address&#x02019;, &#x02018;City&#x02019;, &#x02018;County&#x02019;, and &#x02018;Zip Code&#x02019;: this geolocation information is usually not directly related to customer behavior, especially when there are no other details about the customer&#x02019;s location. Whilst they may be valid in some specific scenarios, in the current dataset they are less relevant and tend to introduce noise.</p><p id="Par726">&#x02018;weekly fee&#x02019;, &#x02018;Nielsen Prizm&#x02019;, and &#x02018;Source Channel&#x02019;: these features are weakly correlated and may not be directly related to the target variable (churn). In particular, &#x02018;weekly fee&#x02019; and &#x02018;Nielsen Prizm&#x02019; are not very useful in predicting churn and may simply reflect non-critical user behavior information.</p></list-item></list>
</p><p id="Par727">Through this series of feature selection processes, we not only improve the training efficiency of the model but also enhance its generalization ability. Removing irrelevant or low-relevance features makes the model more focused on features that are more relevant to the target variable, which ultimately improves the accuracy of the prediction and reduces the risk of overfitting.</p></sec><sec id="Sec20"><title>Data balancing</title><p id="Par73">In the four datasets (Telecom, Bank, Insurance, and News) used in the experiment, the churn rates are 26. 58%, 20. 37%, 11. 70% and 19. 15%, respectively, all of which suffer from a significant category imbalance. To address this issue, this experiment uses the ADASYN technique to balance the dataset.</p><p id="Par74">ADASYN is an improved oversampling technique, the core idea of which is to generate new synthetic samples by interpolating the feature space of a small number of class samples. Compared with the traditional SMOTE algorithm, ADASYN introduces a dynamic consideration mechanism of sample importance, which adjusts the number of synthetic samples generated according to the importance of each minority class sample in the classification. This dynamic adjustment mechanism makes the model pay more attention to those samples that have a critical impact on the classification task during the training process, effectively reducing the risk of overfitting to the majority class.</p><p id="Par75">ADASYN pays special attention to the difficulty and criticality of minority samples when generating synthetic samples. Unlike traditional oversampling methods, ADASYN determines the importance of the minority samples based on their neighborhood density, which in turn determines the number of synthetic samples to be generated. Specifically, ADASYN calculates the neighbourhood density <inline-formula id="IEq60"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D(x_i)$$\end{document}</tex-math><mml:math id="M154"><mml:mrow><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq60.gif"/></alternatives></inline-formula> for each minority class sample <inline-formula id="IEq61"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math><mml:math id="M156"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq61.gif"/></alternatives></inline-formula>,as shown in Equation&#x000a0;<xref rid="Equ18" ref-type="disp-formula">18</xref>:<disp-formula id="Equ18"><label>18</label><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} D(x_i)=\frac{|N_k(x_i)|}{|N_k(x)|} \end{aligned}$$\end{document}</tex-math><mml:math id="M158" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ18.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq62"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$|N_k(x_i)|$$\end{document}</tex-math><mml:math id="M160"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq62.gif"/></alternatives></inline-formula> denotes the number of minority class samples adjacent to sample <inline-formula id="IEq63"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math><mml:math id="M162"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq63.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq64"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$|N_k(x)|$$\end{document}</tex-math><mml:math id="M164"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq64.gif"/></alternatives></inline-formula> is the total number of neighbors of all minority class samples. Based on this density, ADASYN can generate the number of synthetic samples <inline-formula id="IEq65"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_{new}(x_i)$$\end{document}</tex-math><mml:math id="M166"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">new</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq65.gif"/></alternatives></inline-formula> for each minority class sample, as shown in Equation&#x000a0;<xref rid="Equ19" ref-type="disp-formula">19</xref>.<disp-formula id="Equ19"><label>19</label><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} N_{\text {new}}(x_i) = D(x_i) \cdot N_{\text {total}} \end{aligned}$$\end{document}</tex-math><mml:math id="M168" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mtext>new</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mtext>total</mml:mtext></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ19.gif" position="anchor"/></alternatives></disp-formula>This adjustment mechanism allows more synthetic samples to be generated for hard-to-classify samples near the decision boundary, thus helping the model to pay more attention to these &#x02018;boundary&#x02019; samples and improve its ability to recognize a small number of classes.</p><p id="Par76">In addition, by generating more synthetic samples for these critical boundary samples, ADASYN enhances the model&#x02019;s performance in these hard-to-distinguish regions and improves its overall generalization. In this way, ADASYN not only balances the class distribution but also significantly improves the recognition of minority classes.</p><p id="Par77">After determining the number of generated samples, ADASYN selects the closest <italic>k</italic> neighbor samples <inline-formula id="IEq66"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{x_{i_1}, x_{i_2}, \ldots , x_{i_k}\}$$\end{document}</tex-math><mml:math id="M170"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq66.gif"/></alternatives></inline-formula> that are closest to each of the minority class samples <inline-formula id="IEq67"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math><mml:math id="M172"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq67.gif"/></alternatives></inline-formula>. Then, synthetic samples <inline-formula id="IEq68"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{new}$$\end{document}</tex-math><mml:math id="M174"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi mathvariant="italic">new</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq68.gif"/></alternatives></inline-formula> are generated by Equation&#x000a0;<xref rid="Equ20" ref-type="disp-formula">20</xref>:<disp-formula id="Equ20"><label>20</label><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x_{\text {new}} = x_i + \lambda (x_j - x_i) \end{aligned}$$\end{document}</tex-math><mml:math id="M176" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mtext>new</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ20.gif" position="anchor"/></alternatives></disp-formula>Where <inline-formula id="IEq69"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math><mml:math id="M178"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq69.gif"/></alternatives></inline-formula> is one of the selected neighbors and <inline-formula id="IEq70"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><mml:math id="M180"><mml:mi>&#x003bb;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq70.gif"/></alternatives></inline-formula> is a random number between 0 and 1 indicating that the newly generated sample is located somewhere between <inline-formula id="IEq71"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math><mml:math id="M182"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq71.gif"/></alternatives></inline-formula> and its neighbor <inline-formula id="IEq72"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_j$$\end{document}</tex-math><mml:math id="M184"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq72.gif"/></alternatives></inline-formula>.</p><p id="Par78">Figure <xref rid="Fig11" ref-type="fig">11</xref> show the changes in the distribution of categories before and after the application of ADASYN, further validating the effectiveness of ADASYN in balancing the dataset.<fig id="Fig11"><label>Fig. 11</label><caption><p>Changes in category distribution before and after treatment with ADASYN.</p></caption><graphic xlink:href="41598_2024_79603_Fig11_HTML" id="MO11"/></fig></p></sec></sec><sec id="Sec21"><title>Building the CCP-Net model and training</title><p id="Par79">In this experiment, we choose to use Jupyter Notebook as the development environment and conduct the experiment on the Windows 10 operating system. Data preprocessing, model evaluation, and the implementation of machine learning algorithms are all based on the Scikit-learn library, while the construction and training of the CCP-Net model are based on the PyTorch framework. To ensure the training efficiency and reliability of the results, this experiment is configured with two Intel Xeon E5-2620 v4 processors, 64 GB of RAM, and four NVIDIA Tesla M40 GPUs to accelerate the model training and processing of large-scale datasets.</p><p id="Par80">In the output phase of the CCP-Net model, a <italic>Sigmoid</italic> activation function is used to limit the prediction results between 0 and 1, as shown in Equation&#x000a0;<xref rid="Equ21" ref-type="disp-formula">21</xref>:<disp-formula id="Equ21"><label>21</label><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} y=Sigmoid(W^T\cdot x+b) \end{aligned}$$\end{document}</tex-math><mml:math id="M186" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ21.gif" position="anchor"/></alternatives></disp-formula>Where if the output value is less than 0.5, it means that the customer will not churn; if the output value is greater than or equal to 0.5, it means that the customer has a high probability of churn. This probability prediction provides a clear indication of the binary classification problem and facilitates subsequent decision-making.</p><p id="Par81">For the task of predicting customer churn in binary classification, we choose Binary Cross Entropy Loss (BCELoss) as the loss function to quantify the difference between the model predictions and the true labels. This loss function is defined as shown in Equation&#x000a0;<xref rid="Equ22" ref-type="disp-formula">22</xref>:<disp-formula id="Equ22"><label>22</label><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L=-[y\cdot \log {(\hat{y})}+(1-y)\cdot \log {(1-\hat{y})}] \end{aligned}$$\end{document}</tex-math><mml:math id="M188" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>y</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mo>log</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:mo>log</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ22.gif" position="anchor"/></alternatives></disp-formula>Where <inline-formula id="IEq73"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y}$$\end{document}</tex-math><mml:math id="M190"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq73.gif"/></alternatives></inline-formula> denotes the predicted output of the model,<italic>y</italic> denotes the true labels, and <italic>L</italic> is 0 when <italic>y</italic> is equal to 1, indicating no loss.</p><p id="Par82">To improve the generalization ability of the model, a 10-fold cross-validation method was used in this study. Specifically, the dataset is divided into ten equal parts, and each time, one part is kept as the validation set, and the remaining nine parts are used as the training set. This process is repeated ten times and the average of the ten experimental results is calculated to ensure the stability and reliability of the results.</p><p id="Par83">During the training process, we use Adam optimizer, an optimization algorithm that combines momentum and adaptive learning rate to accelerate model training and improve convergence speed. The initial learning rate is set to 0.001 and is dynamically adjusted during training to maintain model stability. In addition, we introduce the Early Stopping technique to prevent model overfitting. When the validation set loss does not improve significantly within some epochs, the training is stopped early to save computational resources and improve model stability. The pseudo-code of the CCP-Net model is shown in Algorithm&#x000a0;1.</p><p id="Par84">
<fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>Training Process for CCP-Net Model.</p></caption><graphic position="anchor" xlink:href="41598_2024_79603_Figa_HTML" id="MO12"/></fig>
</p></sec></sec><sec id="Sec22"><title>Experimental analysis</title><sec id="Sec23"><title>Evaluation metrics</title><p id="Par85">In the customer churn prediction task, the evaluation of the model performance can be achieved using a confusion matrix, which consists of four key components: True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN). Among them:<list list-type="bullet"><list-item><p id="Par86">TP represents the number of samples correctly predicted as churn customers.</p></list-item><list-item><p id="Par87">TN represents the number of samples correctly predicted as non-churning customers.</p></list-item><list-item><p id="Par88">FP represents the number of samples incorrectly predicted as churn customers.</p></list-item><list-item><p id="Par89">FN represents the number of samples incorrectly predicted as non-churning customers.</p></list-item></list></p><p id="Par899">Table <xref rid="Tab2" ref-type="table">2</xref> demonstrates the structure of the confusion matrix:<table-wrap id="Tab2"><label>Table 2</label><caption><p>Confusion matrix.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Real</th><th align="left" colspan="2">Prediction</th></tr><tr><th align="left">Churn</th><th align="left">Non-Churn</th></tr></thead><tbody><tr><td align="left">Churn</td><td align="left">TP</td><td align="left">FN</td></tr><tr><td align="left">Non-Churn</td><td align="left">FP</td><td align="left">TN</td></tr></tbody></table></table-wrap></p><p id="Par90">To comprehensively evaluate the performance of different classification algorithms in customer churn prediction, the following four main evaluation metrics are selected in this study: Accuracy, Precision, Recall, and F1. These metrics can reflect the model&#x02019;s performance in the churn prediction task from multiple perspectives.<list list-type="bullet"><list-item><p id="Par91">Accuracy refers to the proportion of samples correctly predicted by the model to the total samples, as shown in Equation&#x000a0;<xref rid="Equ23" ref-type="disp-formula">23</xref>. For the churn prediction task, Accuracy is used to measure the overall prediction accuracy of the model.</p></list-item></list></p><p id="Par256">
<disp-formula id="Equ23"><label>23</label><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Accuracy=\frac{TN+TN}{TP+TN+FP+FN} \end{aligned}$$\end{document}</tex-math><mml:math id="M192" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ23.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par240">
<list list-type="bullet"><list-item><p id="Par92">Precision is the proportion of actual churn customers in the sample predicted as churn by the model, as shown in Equation&#x000a0;<xref rid="Equ24" ref-type="disp-formula">24</xref>. In churn prediction, a higher Precision means that the model has a lower false alarm rate in churn prediction.</p></list-item></list>
</p><p>
<disp-formula id="Equ24"><label>24</label><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Precision=\frac{TP}{TP+FP} \end{aligned}$$\end{document}</tex-math><mml:math id="M194" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ24.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par241">
<list list-type="bullet"><list-item><p id="Par93">Recall is the proportion of actual churn customers successfully predicted as churn customers by the model, as shown in Equation&#x000a0;<xref rid="Equ25" ref-type="disp-formula">25</xref>. In churn prediction, a higher Recall indicates that the model performs well in capturing real churn customers and has a lower underreporting rate.</p></list-item></list>
</p><p id="Par280">
<disp-formula id="Equ25"><label>25</label><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Recall=\frac{TP}{TP+FN} \end{aligned}$$\end{document}</tex-math><mml:math id="M196" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ25.gif" position="anchor"/></alternatives></disp-formula>
</p><p id="Par253">
<list list-type="bullet"><list-item><p id="Par94">F1 is the reconciled average of Precision and Recall, as shown in Equation&#x000a0;<xref rid="Equ26" ref-type="disp-formula">26</xref>. F1 integrates the model&#x02019;s prediction accuracy and ability to capture real churn customers, and can effectively assess the overall performance of the model.</p></list-item></list>
</p><p id="Par254">
<disp-formula id="Equ26"><label>26</label><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F1=2\times \frac{Precision\times Recall}{Precision+Recall} \end{aligned}$$\end{document}</tex-math><mml:math id="M198" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_79603_Article_Equ26.gif" position="anchor"/></alternatives></disp-formula>
</p></sec><sec id="Sec24"><title>Analysis of experimental parameters</title><p id="Par95">In this experiment, a systematic grid search was conducted to analyze the key parameters of the CCP-Net model, focusing on two key parameters in Multi-Head Self-Attention: Attentional dimensions and Attentional head counts. In the evaluation process, we chose the F1 value as the main metric to evaluate the performance of the model in the customer churn prediction task under different parameter configurations. The parameter ranges for the grid search are set as follows: Attentional dimensions are 32, 64, and 128, and Attentional head counts are 4, 8, 16, 32, and 64. Figure <xref rid="Fig12" ref-type="fig">12</xref> show the variation in the performance of the CCP-Net model in the four industry datasets (Telecom, Bank, Insurance, News) for different attentional dimensions and attentional head counts.<fig id="Fig12"><label>Fig. 12</label><caption><p>F1 values for different attentional dimensions and attentional head counts.</p></caption><graphic xlink:href="41598_2024_79603_Fig12_HTML" id="MO13"/></fig></p><sec id="Sec25"><title>Performance variation analysis</title><p id="Par96">The experimental results show that different datasets exhibit significant performance differences under attentional dimensions and attentional head counts configurations. For example, in the Telecom dataset, the model performance reaches the highest with an F1 value of 91.18% when the attentional dimensions are 64 and attentional head counts are 4, while in the Bank dataset, the attentional dimensions are 64 and attentional head counts are 8, the F1 value reaches 90.19%. For the Insurance dataset, the configuration with attentional dimensions of 128 and attentional head counts of 32 performs the best with an F1 value of 95.43%, while in the News dataset, the configuration with attentional dimensions of 128 and the configuration with attentional head counts of 16 achieved the best results with an F1 value of 94.22%.</p><p id="Par97">These results show that datasets with larger sample sizes (Insurance and News) typically require larger attentional dimensions (128) and more attentional head counts (16 or 32) to capture more features and complex patterns in the data. This suggests that when the data volume increases, the model requires a higher representation capability to extract information efficiently. In contrast, for datasets with relatively small sample sizes (Telecom and Bank), smaller attentional dimensions (64) and fewer attentional head counts (4 or 8) are sufficient to satisfy the model performance requirements and help avoid overfitting.</p><p id="Par98">In summary, we can see that in Multi-Head Self-Attention, the selection of attentional dimensions and attentional head counts should be adjusted according to the characteristics of the dataset, especially when the dataset has a large sample size, the use of larger attentional dimensions and more attentional head counts can significantly improve the model performance. While datasets with smaller sample sizes, smaller attentional dimensions, and attentional head counts can achieve excellent performance.</p></sec><sec id="Sec26"><title>Optimal parameter configuration</title><p id="Par99">Based on the results of the grid search, we determined the optimal configuration of each parameter of the CCP-Net model, as shown in Table <xref rid="Tab3" ref-type="table">3</xref>. With this optimal parameter configuration, the CCP-Net model demonstrates the best performance in the customer churn prediction task, which fully demonstrates the importance of optimal parameter selection to enhance the model&#x02019;s prediction capability. With this configuration, the model can effectively capture the complex patterns and features in the data, thus achieving excellent classification results on datasets from different industries.<table-wrap id="Tab3"><label>Table 3</label><caption><p>CCP-Net model parameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Model parameter</th><th align="left" colspan="4">Dataset</th></tr><tr><th align="left">Telecom</th><th align="left">Bank</th><th align="left">Insurance</th><th align="left">News</th></tr></thead><tbody><tr><td align="left">Multi-Head Self-Attention dimension</td><td align="left">64</td><td align="left">64</td><td align="left">128</td><td align="left">128</td></tr><tr><td align="left">Multi-Head Self-Attention head counts</td><td align="left">4</td><td align="left">8</td><td align="left">32</td><td align="left">16</td></tr><tr><td align="left">LSTM hidden layer size</td><td align="left" colspan="4">100</td></tr><tr><td align="left">LSTM layers</td><td align="left" colspan="4">1</td></tr><tr><td align="left">CNN input dimension size</td><td align="left" colspan="2">[100,64]</td><td align="left">[256,128]</td><td align="left">[128,64]</td></tr><tr><td align="left">Convolution kernel size</td><td align="left" colspan="4">[10,5]</td></tr><tr><td align="left">padding</td><td align="left" colspan="4">[5,3]</td></tr><tr><td align="left">pooled kernel size</td><td align="left" colspan="4">2</td></tr></tbody></table></table-wrap></p></sec></sec><sec id="Sec27"><title>Comparative experimental analysis</title><p id="Par100">To validate the performance of the CCP-Net model, a variety of state-of-the-art machine learning and deep learning algorithms commonly used for customer churn prediction were selected for systematic comparison in this study, including SVM, Decision Tree, KNN, XGBoost, Random Forest, MLP, TabNet, CNN, GRU, LSTM, BiGRU, BiLSTM, Transformer, GRU-CNN, LSTM-CNN, BiGRU-CNN, BiLSTM-CNN, LSTM-Attention, and FCLCNN-LSTM. Table <xref rid="Tab4" ref-type="table">4</xref> summarises the comparative experimental results of each model, and the results show that CCP-Net performs excellently on datasets from four different industries and has obvious advantages in feature extraction and processing complex data. By combining Multi-Head Self-Attention, BiLSTM, and CNN, CCP-Net can capture global and local features efficiently, which makes it more advantageous in processing complex data. In contrast, while single models (e.g., LSTM, GRU) excel in time series data processing, they cannot adequately model global dependencies. At the same time, traditional machine learning methods are highly dependent on feature engineering and are less adaptable.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Comparison of experimental results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Model name</th><th align="left" colspan="4">Telecom</th><th align="left" colspan="4">Bank</th></tr><tr><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th></tr></thead><tbody><tr><td align="left">SVM</td><td align="left">84.95</td><td align="left">87.43</td><td align="left">81.98</td><td align="left">84.59</td><td align="left">84.69</td><td align="left">84.27</td><td align="left">85.31</td><td align="left">84.78</td></tr><tr><td align="left">Decision tree</td><td align="left">81.53</td><td align="left">81.69</td><td align="left">81.68</td><td align="left">81.68</td><td align="left">80.88</td><td align="left">80.12</td><td align="left">82.19</td><td align="left">81.13</td></tr><tr><td align="left">KNN</td><td align="left">82.77</td><td align="left">83.50</td><td align="left">82.07</td><td align="left">82.76</td><td align="left">83.95</td><td align="left">82.67</td><td align="left">85.91</td><td align="left">84.25</td></tr><tr><td align="left">XGBoost</td><td align="left">85.38</td><td align="left">86.70</td><td align="left">83.87</td><td align="left">85.25</td><td align="left">87.15</td><td align="left">86.48</td><td align="left">88.07</td><td align="left">87.27</td></tr><tr><td align="left">Random forest</td><td align="left">85.54</td><td align="left">87.34</td><td align="left">83.45</td><td align="left">85.34</td><td align="left">87.01</td><td align="left">87.02</td><td align="left">87.02</td><td align="left">87.01</td></tr><tr><td align="left">MLP</td><td align="left">82.78</td><td align="left">83.43</td><td align="left">82.38</td><td align="left">82.80</td><td align="left">83.73</td><td align="left">83.65</td><td align="left">83.85</td><td align="left">83.74</td></tr><tr><td align="left">TabNet</td><td align="left">85.16</td><td align="left">86.57</td><td align="left">83.56</td><td align="left">85.02</td><td align="left">84.95</td><td align="left">85.22</td><td align="left">84.61</td><td align="left">84.89</td></tr><tr><td align="left">CNN</td><td align="left">88.32</td><td align="left">91.88</td><td align="left">84.27</td><td align="left">87.87</td><td align="left">85.80</td><td align="left">89.48</td><td align="left">81.18</td><td align="left">85.11</td></tr><tr><td align="left">GRU</td><td align="left">88.35</td><td align="left">91.13</td><td align="left">84.75</td><td align="left">87.69</td><td align="left">85.92</td><td align="left">89.45</td><td align="left">81.85</td><td align="left">85.58</td></tr><tr><td align="left">LSTM</td><td align="left">88.43</td><td align="left">91.17</td><td align="left">85.31</td><td align="left">88.06</td><td align="left">86.31</td><td align="left">89.62</td><td align="left">82.17</td><td align="left">85.71</td></tr><tr><td align="left">BiGRU</td><td align="left">88.78</td><td align="left">91.53</td><td align="left">85.12</td><td align="left">88.13</td><td align="left">87.02</td><td align="left">89.77</td><td align="left">82.34</td><td align="left">85.91</td></tr><tr><td align="left">BiLSTM</td><td align="left">88.72</td><td align="left">91.61</td><td align="left">85.36</td><td align="left">88.31</td><td align="left">87.23</td><td align="left">89.94</td><td align="left">83.85</td><td align="left">86.74</td></tr><tr><td align="left">Transformer</td><td align="left">89.48</td><td align="left">91.81</td><td align="left">86.08</td><td align="left">88.85</td><td align="left">88.05</td><td align="left">90.15</td><td align="left">86.32</td><td align="left">88.19</td></tr><tr><td align="left">GRU-CNN</td><td align="left">89.29</td><td align="left">91.22</td><td align="left">86.18</td><td align="left">88.52</td><td align="left">87.18</td><td align="left">89.68</td><td align="left">83.96</td><td align="left">86.38</td></tr><tr><td align="left">LSTM-CNN</td><td align="left">89.51</td><td align="left">91.23</td><td align="left">86.28</td><td align="left">88.79</td><td align="left">87.48</td><td align="left">89.91</td><td align="left">84.34</td><td align="left">87.02</td></tr><tr><td align="left">BiGRU-CNN</td><td align="left">90.57</td><td align="left">91.96</td><td align="left">89.25</td><td align="left">90.53</td><td align="left">88.39</td><td align="left">90.35</td><td align="left">85.72</td><td align="left">88.05</td></tr><tr><td align="left">BiLSTM-CNN</td><td align="left">90.91</td><td align="left">92.09</td><td align="left">89.66</td><td align="left">90.84</td><td align="left">88.65</td><td align="left">90.82</td><td align="left">86.01</td><td align="left">88.31</td></tr><tr><td align="left">LSTM-Attention</td><td align="left">89.85</td><td align="left">91.54</td><td align="left">86.63</td><td align="left">89.07</td><td align="left">87.65</td><td align="left">90.26</td><td align="left">83.63</td><td align="left">86.91</td></tr><tr><td align="left">FCLCNN-LSTM</td><td align="left">90.58</td><td align="left">91.88</td><td align="left">89.73</td><td align="left">90.78</td><td align="left">88.84</td><td align="left">90.75</td><td align="left">88.07</td><td align="left">89.17</td></tr><tr><td align="left">Attention-BiGRU-CNN</td><td align="left">90.95</td><td align="left">92.11</td><td align="left">89.77</td><td align="left">90.86</td><td align="left">89.51</td><td align="left">90.63</td><td align="left">88.12</td><td align="left">89.48</td></tr><tr><td align="left">CCP-Net</td><td align="left">91.17</td><td align="left">92.19</td><td align="left">90.24</td><td align="left">91.18</td><td align="left">89.68</td><td align="left">91.96</td><td align="left">88.41</td><td align="left">90.19</td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Model name</th><th align="left" colspan="4">Insurance</th><th align="left" colspan="4">News</th></tr><tr><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th></tr></thead><tbody><tr><td align="left">SVM</td><td align="left">82.74</td><td align="left">81.91</td><td align="left">84.09</td><td align="left">82.97</td><td align="left">84.05</td><td align="left">85.43</td><td align="left">83.97</td><td align="left">84.38</td></tr><tr><td align="left">Decision tree</td><td align="left">78.11</td><td align="left">78.57</td><td align="left">77.31</td><td align="left">77.92</td><td align="left">80.39</td><td align="left">80.52</td><td align="left">84.69</td><td align="left">82.54</td></tr><tr><td align="left">KNN</td><td align="left">78.18</td><td align="left">79.97</td><td align="left">75.27</td><td align="left">77.52</td><td align="left">81.39</td><td align="left">79.61</td><td align="left">82.49</td><td align="left">81.22</td></tr><tr><td align="left">XGBoost</td><td align="left">85.84</td><td align="left">84.39</td><td align="left">87.96</td><td align="left">86.12</td><td align="left">86.84</td><td align="left">87.12</td><td align="left">87.49</td><td align="left">87.30</td></tr><tr><td align="left">Random forest</td><td align="left">85.31</td><td align="left">83.35</td><td align="left">88.30</td><td align="left">85.73</td><td align="left">88.85</td><td align="left">88.02</td><td align="left">90.79</td><td align="left">89.38</td></tr><tr><td align="left">MLP</td><td align="left">78.42</td><td align="left">78.37</td><td align="left">78.56</td><td align="left">78.44</td><td align="left">81.69</td><td align="left">80.11</td><td align="left">83.49</td><td align="left">81.70</td></tr><tr><td align="left">TabNet</td><td align="left">82.85</td><td align="left">81.40</td><td align="left">85.27</td><td align="left">83.25</td><td align="left">82.01</td><td align="left">81.19</td><td align="left">84.86</td><td align="left">82.98</td></tr><tr><td align="left">CNN</td><td align="left">85.89</td><td align="left">88.84</td><td align="left">82.16</td><td align="left">85.35</td><td align="left">88.21</td><td align="left">86.78</td><td align="left">88.68</td><td align="left">87.74</td></tr><tr><td align="left">GRU</td><td align="left">86.38</td><td align="left">87.36</td><td align="left">83.49</td><td align="left">85.32</td><td align="left">88.04</td><td align="left">89.58</td><td align="left">86.31</td><td align="left">87.72</td></tr><tr><td align="left">LSTM</td><td align="left">86.42</td><td align="left">87.56</td><td align="left">84.93</td><td align="left">86.20</td><td align="left">88.12</td><td align="left">89.89</td><td align="left">86.52</td><td align="left">88.11</td></tr><tr><td align="left">BiGRU</td><td align="left">89.18</td><td align="left">90.68</td><td align="left">88.69</td><td align="left">89.93</td><td align="left">90.48</td><td align="left">91.35</td><td align="left">88.41</td><td align="left">90.02</td></tr><tr><td align="left">BiLSTM</td><td align="left">89.95</td><td align="left">90.83</td><td align="left">88.75</td><td align="left">89.76</td><td align="left">90.65</td><td align="left">91.62</td><td align="left">88.38</td><td align="left">90.59</td></tr><tr><td align="left">Transformer</td><td align="left">90.68</td><td align="left">91.35</td><td align="left">90.31</td><td align="left">90.83</td><td align="left">90.79</td><td align="left">92.38</td><td align="left">89.01</td><td align="left">90.67</td></tr><tr><td align="left">GRU-CNN</td><td align="left">93.24</td><td align="left">93.95</td><td align="left">92.05</td><td align="left">92.74</td><td align="left">90.28</td><td align="left">91.68</td><td align="left">89.85</td><td align="left">90.77</td></tr><tr><td align="left">LSTM-CNN</td><td align="left">93.65</td><td align="left">94.25</td><td align="left">92.89</td><td align="left">93.56</td><td align="left">90.82</td><td align="left">92.86</td><td align="left">89.91</td><td align="left">91.36</td></tr><tr><td align="left">BiGRU-CNN</td><td align="left">93.63</td><td align="left">94.05</td><td align="left">92.68</td><td align="left">93.25</td><td align="left">91.65</td><td align="left">92.96</td><td align="left">90.24</td><td align="left">91.62</td></tr><tr><td align="left">BiLSTM-CNN</td><td align="left">93.96</td><td align="left">94.60</td><td align="left">93.00</td><td align="left">93.77</td><td align="left">91.83</td><td align="left">93.37</td><td align="left">90.61</td><td align="left">91.90</td></tr><tr><td align="left">LSTM-Attention</td><td align="left">93.75</td><td align="left">93.23</td><td align="left">92.71</td><td align="left">92.97</td><td align="left">91.42</td><td align="left">92.96</td><td align="left">90.70</td><td align="left">91.81</td></tr><tr><td align="left">FCLCNN-LSTM</td><td align="left">94.14</td><td align="left">94.35</td><td align="left">93.58</td><td align="left">93.96</td><td align="left">92.86</td><td align="left">94.28</td><td align="left">91.57</td><td align="left">92.89</td></tr><tr><td align="left">Attention-BiGRU-CNN</td><td align="left">94.95</td><td align="left">94.89</td><td align="left">94.78</td><td align="left">94.86</td><td align="left">93.12</td><td align="left">94.26</td><td align="left">92.52</td><td align="left">93.48</td></tr><tr><td align="left">CCP-Net</td><td align="left">95.86</td><td align="left">95.87</td><td align="left">95.03</td><td align="left">95.43</td><td align="left">94.08</td><td align="left">95.12</td><td align="left">93.24</td><td align="left">94.22</td></tr></tbody></table></table-wrap></p><sec id="Sec28"><title>CCP-Net vs Machine learning algorithm</title><p id="Par101">The selected machine learning models (e.g., SVM, Decision Tree, KNN, etc.) rely on complex feature engineering and hyper-parameter tuning, and thus the performance fluctuates widely on different datasets. For example, the choice of regularisation parameters and kernel function for SVM, the tree depth for the Decision Tree, and the number of neighbors K for KNN are all key factors affecting model performance. If these hyperparameters are not reasonably tuned, the model performance may be significantly degraded. For example, on the Insurance dataset, the accuracy of the Decision Tree is only 78.11%. At the same time, its Precision, Recall, and F1 values are 78.57%, 77.31%, and 77.92%, respectively, which are much lower than the CCP-Net model&#x02019;s values of 95.86%, 95.87%, 95.03%, and 95.43%. As a hybrid neural network, CCP-Net can automatically learn the data representation, significantly reduce the reliance on manual feature engineering, and effectively extract complex features through its internal structure. Compared to algorithms such as KNN which are sensitive to noise and outliers, CCP-Net&#x02019;s deep structure can better adapt to different data distributions, thus showing greater robustness in dealing with outliers. This design allows CCP-Net to consistently maintain high performance on multiple datasets, whereas traditional machine learning methods often perform poorly in the face of feature fluctuations.</p><p id="Par102">While integrated learning methods (such as XGBoost and Random Forest) offer improved performance compared to a single model, their complexity and computational cost subsequently increase, and the interpretability of the model is often inferior to that of a single model. CCP-Net, through its deep learning structure, provides an approach that balances performance and interpretability. In experiments on four datasets, CCP-Net generally outperforms these machine learning models on all metrics, with increases ranging from 1% to 6%. For example, in the Telecom dataset, CCP-Net&#x02019;s Precision is 92.19%, while KNN&#x02019;s Precision is only 83.50%; in the Bank dataset, CCP-Net&#x02019;s F1 value is 90.19%, much higher than Random Forest&#x02019;s 87.01%. These results demonstrate the effectiveness of CCP-Net in dealing with complex features.</p></sec><sec id="Sec29"><title>CCP-Net vs Single deep learning algorithm</title><p id="Par103">For single deep learning algorithms such as MLP, TabNet, CNN, GRU, LSTM, BiGRU, BiLSTM, and Transformer, these models may not extract information comprehensively when processing data. For example, MLP has a simple structure containing only input, hidden, and output layers, and lacks a specialized feature extraction structure, leading to its poor performance on various metrics; its Accuracy of 78.42% and F1 of 78.44% on the Insurance dataset are the worst performers among the listed deep learning algorithms. Although TabNet performs well with structured datasets, it does not capture long-term dependencies in time series data as effectively as models specifically designed for time series prediction (e.g., GRU, LSTM), and therefore performs poorly with data containing time series.CNNs typically use fixed-size convolutional kernels, which limits their performance when dealing with data that has variable length or complex ability when dealing with sequence data with variable length or complex temporal dependencies. Although GRU, LSTM, BiGRU, and BiLSTM have memory capabilities when processing sequence data, they may not be able to effectively capture important information in the sequences when processing long sequence data due to the gradient vanishing or explosion problem. In contrast, CCP-Net combines Multi-Head Self-Attention, BiLSTM, and CNN, which fully utilizes the advantages of global and local feature extraction to overcome the gradient problem in long sequence processing, and therefore exhibits stronger prediction ability on diverse features. In addition, the Transformer model&#x02019;s self-attention mechanism excels in capturing global dependencies but lacks the flexibility to deal with local features, whereas the design of CCP-Net takes both into account, resulting in superior performance in the face of complex time series data.</p><p id="Par104">In the comparison experiments, the CCP-Net model excels in all performance metrics. For example, on the Telecom dataset, the Precision of CCP-Net is 92.19%, while the Precision of LSTM and BiLSTM is 91.17% and 91.61%, respectively. On the News dataset, the F1 value of CCP-Net is 94.22%, while the F1 values of Transformer and CNN are 90.67% and 87.74%, respectively. These results show that CCP-Net can perform effective feature extraction on diverse features through its unique architectural design, demonstrating strong generalization ability.</p></sec><sec id="Sec30"><title>Alternative model analysis</title><p id="Par106">Table <xref rid="Tab5" ref-type="table">5</xref> shows the performance comparison of GRU, LSTM, BiGRU, and BiLSTM on the Telecom dataset. Although GRU and LSTM are similar in accuracy, LSTM has a slight advantage in Precision and Recall, with an F1-Score of 88.06%, which is 0.37% higher than GRU. This difference indicates that LSTM is better at capturing complex dependencies in long time series; especially when dealing with long-time dependencies, it can effectively avoid the problem of gradient disappearance, thus enhancing the overall performance of the model.</p><p id="Par105">
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Alternative model analysis (GRU vs. LSTM).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Model name</th><th align="left" colspan="5">Telecom</th></tr><tr><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th><th align="left">Time(s)</th></tr></thead><tbody><tr><td align="left">GRU</td><td align="left">88.35</td><td align="left">91.13</td><td align="left">84.75</td><td align="left">87.69</td><td align="left">16.89</td></tr><tr><td align="left">LSTM</td><td align="left">88.43</td><td align="left">91.17</td><td align="left">85.31</td><td align="left">88.06</td><td align="left">17.25</td></tr><tr><td align="left">BiGRU</td><td align="left">88.78</td><td align="left">91.53</td><td align="left">85.12</td><td align="left">88.13</td><td align="left">17.54</td></tr><tr><td align="left">BiLSTM</td><td align="left">88.72</td><td align="left">91.61</td><td align="left">85.36</td><td align="left">88.31</td><td align="left">17.85</td></tr><tr><td align="left">BiGRU-CNN</td><td align="left">90.57</td><td align="left">91.96</td><td align="left">89.25</td><td align="left">90.53</td><td align="left">18.28</td></tr><tr><td align="left">BiLSTM-CNN</td><td align="left">90.91</td><td align="left">92.09</td><td align="left">89.66</td><td align="left">90.84</td><td align="left">18.87</td></tr><tr><td align="left">Attention-BiGRU-CNN</td><td align="left">90.95</td><td align="left">92.11</td><td align="left">89.77</td><td align="left">90.86</td><td align="left">30.35</td></tr><tr><td align="left">CCP-Net</td><td align="left">91.17</td><td align="left">92.19</td><td align="left">90.24</td><td align="left">91.18</td><td align="left">32.94</td></tr></tbody></table></table-wrap>
</p><p id="Par107">In the comparison between BiGRU and BiLSTM, the F1-Score of BiLSTM (88.31%) is slightly higher than that of BiGRU (88.13%). This difference is mainly attributed to the gating mechanism of LSTM, which gives BiLSTM an advantage in modeling long-term dependencies. Although BiGRU is better in terms of computational efficiency, BiLSTM is more suitable for processing complex time series data, especially in capturing long-term dependencies.</p><p id="Par108">After combining with CNN, the F1-Score of BiLSTM-CNN improves to 90.84%, which is higher than the 90.53% of BiGRU-CNN. This result shows that the CNN layer can effectively enhance the local feature extraction and pattern capture of BiLSTM, and further improve the overall performance of the model, especially in the high-dimensional feature space.</p><p id="Par109">By integrating Multi-Head Self-Attention, BiLSTM, and CNN, CCP-Net achieves an F1-Score of 91.18% on the Telecom dataset, outperforming Attention-BiGRU-CNN (90.86%). The Multi-Head Self-Attention module captures global dependencies, BiLSTM handles local dependencies, and the CNN layer further refines features. The combination of the three gives CCP-Net a significant advantage in handling complex features and modeling long and short-term dependencies.</p><p id="Par110">Although the training time of CCP-Net (32.94 seconds) is slightly longer compared to Attention-BiGRU-CNN (30.35 seconds), the increase in this time mainly stems from the BiLSTM module, which significantly improves the expressive power and predictive accuracy of the model. Thus, despite being slightly less computationally efficient, the performance improvement of CCP-Net justifies these additional overheads and shows its unique advantages in complex feature modeling and global dependency capture.</p></sec><sec id="Sec31"><title>Comparative experimental conclusions</title><p id="Par111">Although LSTM-CNN, BiLSTM-CNN, LSTM-Attention, and FCLCNN-LSTM have improved performance compared to a single neural network, CCP-Net combines Multi-Head Self-Attention, BiLSTM, and CNNs to show stronger learning capabilities and obtain better performance results. This combination not only enhances the feature extraction ability of the model but also improves the generalization ability of the model to better cope with data with different characteristics. In Precision, a performance metric, the CCP-Net model generally outperforms other models, with an increase of between 1% and 3%. For example, on the Telecom dataset, the F1 value of CCP-Net is 91.18%, while the F1 values of LSTM-CNN and BiLSTM-CNN are 88.79% and 90.84%, respectively; on the News dataset, the F1 value of CCP-Net is 94.22%, while the F1 values of LSTM-Attention and FCLCNN-LSTM have F1 values of 91.81% and 92.89%, respectively. These results show the obvious advantage of CCP-Net in model prediction performance, especially when dealing with complex features, its multi-level feature fusion capability makes it outperform traditional hybrid models.</p></sec><sec id="Sec32"><title>Error bars and T-tests</title><p id="Par112">
<list list-type="bullet"><list-item><p id="Par113">Error bars</p><p id="Par213">To analyze the stability and robustness of different hybrid neural network models in more depth, we compare the F1 value performance of BiLSTM-CNN, LSTM-Attention, FCLCNN-LSTM, and CCP-Net on the four datasets of Telecom, Bank, Insurance, and News, and use the error bar to which is visualized (shown in Figure <xref rid="Fig13" ref-type="fig">13</xref>). From the results, it can be seen that CCP-Net exhibits the smallest performance fluctuation on all the test datasets, indicating that it has more stability. In particular, in the Bank dataset, the confidence interval of CCP-Net is <inline-formula id="IEq74"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$90.17 \pm 0.31$$\end{document}</tex-math><mml:math id="M200"><mml:mrow><mml:mn>90.17</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>0.31</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq74.gif"/></alternatives></inline-formula>, which is significantly smaller than that of other models, further demonstrating its superior stability and robustness. In contrast, BiLSTM-CNN has an F1 value of <inline-formula id="IEq75"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$88.10\pm 0.36$$\end{document}</tex-math><mml:math id="M202"><mml:mrow><mml:mn>88.10</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>0.36</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq75.gif"/></alternatives></inline-formula>, LSTM-Attention <inline-formula id="IEq76"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$86.75\pm 0.35$$\end{document}</tex-math><mml:math id="M204"><mml:mrow><mml:mn>86.75</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>0.35</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq76.gif"/></alternatives></inline-formula>, and FCLCNN-LSTM <inline-formula id="IEq77"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$89.08\pm 0.33$$\end{document}</tex-math><mml:math id="M206"><mml:mrow><mml:mn>89.08</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>0.33</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq77.gif"/></alternatives></inline-formula>, and the performance of these models fluctuates more on the Bank dataset, with a higher width of confidence intervals, suggesting that their performances are relatively unstable, and they may be more stable in different customer churn prediction tasks with greater uncertainty. It can be seen that CCP-Net not only performs well in performance but also demonstrates stronger adaptability to complex tasks through smaller volatility and narrower confidence intervals, which is of great significance for customer churn prediction in practical applications.</p></list-item><list-item><p id="Par114">T-tests</p><p id="Par214">In machine learning and statistical analyses, it is critical to assess the significance of differences in performance between models. The T-test is a commonly used statistical method for comparing the difference between two sample means and determining whether that difference is statistically significant. The T-test enables us to understand whether a model&#x02019;s performance on a particular task is by chance or reflects an inherent difference in its performance. To further validate the performance improvement of CCP-Net over other hybrid neural network models, we conducted an independent samples T-test to assess the significance of the differences in the F1 values of the models across the datasets. The results of the analysis are shown in Table <xref rid="Tab6" ref-type="table">6</xref>: It can be seen through Table <xref rid="Tab6" ref-type="table">6</xref> that CCP-Net exhibits a trend of significantly outperforming other hybrid neural network models on all datasets. This indicates that the design and implementation of CCP-Net can effectively enhance the F1 value and thus improve the prediction performance. On the Telecom, Bank, Insurance, and News datasets, the P-values of CCP-Net with other hybrid neural network models (e.g., BiLSTM-CNN, LSTM-Attention, and FCLCNN-LSTM) are all less than 0.05, which demonstrates its significant advantage over other models. These results not only demonstrate the superiority of CCP-Net but also provide a reliable statistical basis for its wide use in practical applications. With the help of a T-test, we confirm the consistency and performance improvement of CCP-Net on multiple datasets, which further proves its effectiveness and reliability in complex tasks such as customer churn prediction.</p></list-item></list>
</p></sec><sec id="Sec33"><title>Comparative experimental conclusions</title><p id="Par115">CCP-Net significantly outperforms other models in various performance metrics and demonstrates higher stability and consistency in prediction performance on different industry datasets, reflecting its excellent generalization ability. This generalization capability enables CCP-Net to flexibly adapt to diverse data characteristics and make full use of the synergy between Multi-Head Self-Attention, BiLSTM, and CNN, thus maintaining high prediction accuracy when dealing with complex customer behavior patterns.<fig id="Fig13"><label>Fig. 13</label><caption><p>F1 Scores with Confidence Intervals across Different Models and Datasets.</p></caption><graphic xlink:href="41598_2024_79603_Fig13_HTML" id="MO14"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption><p>T-test results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Models Comparison</th><th align="left">T-statistic</th><th align="left">P-value</th><th align="left">CCP-Net is superior to this model?</th></tr></thead><tbody><tr><td align="left" rowspan="3">Telecom</td><td align="left">CCP-Net vs BiLSTM-CNN</td><td align="left">13.18</td><td align="left">4.26e-19</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs LSTM-Attention</td><td align="left">17.73</td><td align="left">4.29e-25</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs FCLCNN-LSTM</td><td align="left">6.98</td><td align="left">3.20e-09</td><td align="left">yes</td></tr><tr><td align="left" rowspan="3">Bank</td><td align="left">CCP-Net vs BiLSTM-CNN</td><td align="left">37.80</td><td align="left">1.47e-42</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs LSTM-Attention</td><td align="left">90.53</td><td align="left">3.76e-64</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs FCLCNN-LSTM</td><td align="left">22.43</td><td align="left">2.86e-30</td><td align="left">yes</td></tr><tr><td align="left" rowspan="3">Insurance</td><td align="left">CCP-Net vs BiLSTM-CNN</td><td align="left">30.06</td><td align="left">4.58e-37</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs LSTM-Attention</td><td align="left">34.44</td><td align="left">2.59e-40</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs FCLCNN-LSTM</td><td align="left">35.49</td><td align="left">4.93e-41</td><td align="left">yes</td></tr><tr><td align="left" rowspan="3">Nesw</td><td align="left">CCP-Net vs BiLSTM-CNN</td><td align="left">27.89</td><td align="left">2.70e-35</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs LSTM-Attention</td><td align="left">28.85</td><td align="left">4.29e-36</td><td align="left">yes</td></tr><tr><td align="left">CCP-Net vs FCLCNN-LSTM</td><td align="left">28.67</td><td align="left">6.09e-36</td><td align="left">yes</td></tr></tbody></table></table-wrap></p><p id="Par116">The design of CCP-Net takes into account the characteristics of different industries to ensure its broad applicability in multiple domains. For example, in the telecom industry (e.g., Telecom), the global dependency learning capability of the Multi-Head Self-Attention module significantly enhances the capture of complex customer behavioral patterns. CCP-Net achieves an Accuracy of 91.17% on the Telecom dataset, significantly higher than the BiLSTM-CNN&#x02019;s 90.91% and LSTM-CNN&#x02019;s 89.51%. This enables CCP-Net to handle large amounts of time-series data and identify potential churn risks promptly. In the financial industry (e.g., Bank and Insurance), the capability of the BiLSTM module in modeling long-term dependencies significantly improves the understanding of the changing dynamics of customer churn. In the Bank dataset, CCP-Net achieves an Accuracy of 89.68%, which is significantly improved compared to BiLSTM&#x02019;s 87.23%; in the Insurance dataset, CCP-Net&#x02019;s F1 value of 95.43% outperforms the other algorithms, especially XGBoost&#x02019;s 86.12% and Random Forest of 85.73%, further validating its effectiveness in capturing customer transaction history and behavioral patterns. In addition, CCP-Net&#x02019;s feature extraction capability lays the foundation for its application in the media industry (e.g. News), helping companies to deeply analyze users&#x02019; reading habits and preferences. In the News dataset, CCP-Net&#x02019;s Precision reaches 95.12%, much higher than CNN&#x02019;s 86.78% and BiLSTM&#x02019;s 91.62%, which enables enterprises to formulate customer retention strategies more effectively.</p><p id="Par117">In the error bar analysis, CCP-Net shows the smallest performance fluctuation on all test datasets, indicating that it has stronger stability. In particular, in the Bank dataset, the confidence interval of CCP-Net is <inline-formula id="IEq78"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$90.17 \pm 0.31$$\end{document}</tex-math><mml:math id="M208"><mml:mrow><mml:mn>90.17</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>0.31</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq78.gif"/></alternatives></inline-formula>, which is significantly lower than that of other models, which further demonstrates its superior stability and robustness. In contrast, other models such as BiLSTM-CNN and LSTM-Attention have wider confidence intervals on this dataset, suggesting that their performance is relatively unstable, which may lead to greater uncertainty in practical applications.</p><p id="Par118">To further validate the performance improvement of CCP-Net over other hybrid neural network models, we conducted an independent sample t-test. The results show that in the Telecom, Bank, Insurance, and News datasets, the P-values between CCP-Net and BiLSTM-CNN, LSTM-Attention, and FCLCNN-LSTM are all less than 0.05, indicating significant advantages. For example, in the Bank dataset, CCP-Net vs BiLSTM-CNN has a T-statistic of 37.80 and a P-value of 1.47e-42, showing a significant performance difference. These results provide a solid statistical basis for the effectiveness of CCP-Net in customer churn prediction.</p><p id="Par119">In summary, by comparing with other models, CCP-Net performs well on datasets from different domains, fully proving its effectiveness and reliability in dealing with complex customer churn prediction problems. Overall, CCP-Net not only performs well in the task of customer churn prediction but also it&#x02019;s flexible structure and powerful feature learning capability provide it with a wide range of application potentials in different industries, thus providing effective customer relationship management solutions for enterprises.</p></sec></sec><sec id="Sec34"><title>Ablation experiment analysis</title><p id="Par120">This section provides an in-depth analysis of the importance of each module in the task of customer churn prediction and its impact on model performance through ablation experiments on each module of the CCP-Net model. The results of the ablation experiments are shown in Table <xref rid="Tab7" ref-type="table">7</xref>.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Results of ablation experiments.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="3">Module</th><th align="left" colspan="4">Telecom</th><th align="left" colspan="4">Bank</th></tr><tr><th align="left">Attention</th><th align="left">BiLSTM</th><th align="left">CNN</th><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th></tr></thead><tbody><tr><td align="left"><inline-formula id="IEq79"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M210"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq79.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq80"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M212"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq80.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq81"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M214"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq81.gif"/></alternatives></inline-formula></td><td align="left">87.21</td><td align="left">91.05</td><td align="left">82.78</td><td align="left">86.66</td><td align="left">84.88</td><td align="left">89.12</td><td align="left">79.59</td><td align="left">84.02</td></tr><tr><td align="left"><inline-formula id="IEq82"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M216"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq82.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq83"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M218"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq83.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq84"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M220"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq84.gif"/></alternatives></inline-formula></td><td align="left">88.72</td><td align="left">91.61</td><td align="left">85.36</td><td align="left">88.31</td><td align="left">87.23</td><td align="left">89.94</td><td align="left">83.85</td><td align="left">86.74</td></tr><tr><td align="left"><inline-formula id="IEq85"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M222"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq85.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq86"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M224"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq86.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq87"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M226"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq87.gif"/></alternatives></inline-formula></td><td align="left">88.32</td><td align="left">91.88</td><td align="left">84.27</td><td align="left">87.87</td><td align="left">85.80</td><td align="left">89.48</td><td align="left">81.18</td><td align="left">85.11</td></tr><tr><td align="left"><inline-formula id="IEq88"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M228"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq88.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq89"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M230"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq89.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq90"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M232"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq90.gif"/></alternatives></inline-formula></td><td align="left">90.73</td><td align="left">92.04</td><td align="left">89.31</td><td align="left">90.65</td><td align="left">87.78</td><td align="left">89.69</td><td align="left">85.55</td><td align="left">87.55</td></tr><tr><td align="left"><inline-formula id="IEq91"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M234"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq91.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq92"><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M236"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq92.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq93"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M238"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq93.gif"/></alternatives></inline-formula></td><td align="left">89.32</td><td align="left">92.12</td><td align="left">86.20</td><td align="left">88.93</td><td align="left">86.55</td><td align="left">89.43</td><td align="left">82.93</td><td align="left">86.03</td></tr><tr><td align="left"><inline-formula id="IEq94"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M240"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq94.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq95"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M242"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq95.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq96"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M244"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq96.gif"/></alternatives></inline-formula></td><td align="left">90.91</td><td align="left">92.09</td><td align="left">89.66</td><td align="left">90.84</td><td align="left">88.65</td><td align="left">90.82</td><td align="left">86.01</td><td align="left">88.31</td></tr><tr><td align="left"><inline-formula id="IEq97"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M246"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq97.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq98"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M248"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq98.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq99"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M250"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq99.gif"/></alternatives></inline-formula></td><td align="left"><bold>91.17</bold></td><td align="left"><bold>92.19</bold></td><td align="left"><bold>90.24</bold></td><td align="left"><bold>91.18</bold></td><td align="left"><bold>89.68</bold></td><td align="left"><bold>91.96</bold></td><td align="left"><bold>88.41</bold></td><td align="left"><bold>90.19</bold></td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="3">Module</th><th align="left" colspan="4">Insurance</th><th align="left" colspan="4">News</th></tr><tr><th align="left">Attention</th><th align="left">BiLSTM</th><th align="left">CNN</th><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th><th align="left">Accuracy (%)</th><th align="left">Precision (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th></tr></thead><tbody><tr><td align="left"><inline-formula id="IEq100"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M252"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq100.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq101"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M254"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq101.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq102"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M256"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq102.gif"/></alternatives></inline-formula></td><td align="left">87.67</td><td align="left">88.48</td><td align="left">86.60</td><td align="left">87.51</td><td align="left">86.89</td><td align="left">84.01</td><td align="left">86.59</td><td align="left">85.54</td></tr><tr><td align="left"><inline-formula id="IEq103"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M258"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq103.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq104"><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M260"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq104.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq105"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M262"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq105.gif"/></alternatives></inline-formula></td><td align="left">89.95</td><td align="left">90.83</td><td align="left">88.75</td><td align="left">89.76</td><td align="left">90.65</td><td align="left">91.62</td><td align="left">88.38</td><td align="left">89.90</td></tr><tr><td align="left"><inline-formula id="IEq106"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M264"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq106.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq107"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M266"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq107.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq108"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M268"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq108.gif"/></alternatives></inline-formula></td><td align="left">85.89</td><td align="left">88.84</td><td align="left">82.16</td><td align="left">85.35</td><td align="left">88.21</td><td align="left">86.78</td><td align="left">88.68</td><td align="left">87.74</td></tr><tr><td align="left"><inline-formula id="IEq109"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M270"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq109.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq110"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M272"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq110.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq111"><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M274"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq111.gif"/></alternatives></inline-formula></td><td align="left">94.44</td><td align="left">94.64</td><td align="left">94.02</td><td align="left">94.28</td><td align="left">93.62</td><td align="left">93.94</td><td align="left">91.68</td><td align="left">93.08</td></tr><tr><td align="left"><inline-formula id="IEq112"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M276"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq112.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq113"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M278"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq113.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq114"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M280"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq114.gif"/></alternatives></inline-formula></td><td align="left">93.56</td><td align="left">93.74</td><td align="left">93.40</td><td align="left">93.56</td><td align="left">91.31</td><td align="left">91.58</td><td align="left">91.65</td><td align="left">91.60</td></tr><tr><td align="left"><inline-formula id="IEq115"><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M282"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq115.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq116"><alternatives><tex-math id="M283">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M284"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq116.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq117"><alternatives><tex-math id="M285">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M286"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq117.gif"/></alternatives></inline-formula></td><td align="left">93.96</td><td align="left">94.60</td><td align="left">93.00</td><td align="left">93.77</td><td align="left">91.83</td><td align="left">93.37</td><td align="left">90.61</td><td align="left">91.90</td></tr><tr><td align="left"><inline-formula id="IEq118"><alternatives><tex-math id="M287">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M288"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq118.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq119"><alternatives><tex-math id="M289">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M290"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq119.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq120"><alternatives><tex-math id="M291">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M292"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq120.gif"/></alternatives></inline-formula></td><td align="left"><bold>95.86</bold></td><td align="left"><bold>95.87</bold></td><td align="left"><bold>95.03</bold></td><td align="left"><bold>95.43</bold></td><td align="left"><bold>94.08</bold></td><td align="left"><bold>95.12</bold></td><td align="left"><bold>93.24</bold></td><td align="left"><bold>94.22</bold></td></tr></tbody></table></table-wrap></p><sec id="Sec35"><title>Contribution of multi-head self-attention module to model performance</title><p id="Par121">The Multi-Head Self-Attention module plays a crucial role in capturing global dependencies. When this module is removed (the BiLSTM and CNN modules are retained), the overall performance of the model decreases significantly, especially in the extraction of global features. This is specifically shown in:<list list-type="bullet"><list-item><p id="Par122">In the Telecom dataset, after the removal of multi-head self-attention, accuracy decreased from 91. 17% to 90. 91%, precision decreased from 92. 19% to 92. 09%, recall decreased from 90. 24% to 89. 66%, F1 value decreased from 91. 18% to 90. 84%.</p></list-item><list-item><p id="Par123">In the Insurance dataset, removing Multi-Head Self-Attenti reduced Accuracy from 95.86% to 93.96%, Precision from 95.87% to 94.60%, Recall from 95.03% to 93.00%, and F1 value from 95.43% to 93.77%.</p></list-item></list></p><p id="Par221">These changes suggest that Multi-Head Self-Attention is essential for learning global dependencies, although BiLSTM and CNN can effectively capture time series dependencies and local features. Especially in the Insurance dataset, the module significantly improves the prediction accuracy and enhances the model&#x02019;s ability to capture complex patterns.</p></sec><sec id="Sec36"><title>Contribution of the BiLSTM module to model performance</title><p id="Par124">The BiLSTM module performs well in time series feature extraction. When the BiLSTM module is removed (the Multi-Head Self-Attention and CNN modules are retained), the model performance decreases significantly, especially in the reduction of Recall and F1 values. The specific performance is shown as follows:<list list-type="bullet"><list-item><p id="Par125">In the Telecom dataset, after removing BiLSTM, Recall decreases from 90.24% to 86.20% and the F1 value decreases from 91.18% to 88.93%.</p></list-item><list-item><p id="Par126">In the Bank dataset, after removing BiLSTM, Recall decreased from 88.41% to 82.93% and the F1 value decreased from 90.19% to 86.03%.</p></list-item></list></p><p id="Par300">These results show that BiLSTM plays a key role in capturing long-term dependencies of customer behavior, and is particularly good at capturing temporal trends, effectively improving the classification ability of the model.</p></sec><sec id="Sec37"><title>Contribution of CNN module to model performance</title><p id="Par127">The importance of CNN modules in local feature extraction cannot be ignored. The model performance is also significantly affected when removing the CNN module (retaining the Multi-Head Self-Attention and BiLSTM modules). Specifically, it is shown as follows:<list list-type="bullet"><list-item><p id="Par128">In the Insurance dataset, after removing CNN, Accuracy decreases from 95.86% to 94.44%, Precision decreases from 95.87% to 94.64%, while Recall and F1 values show a corresponding decrease.</p></list-item><list-item><p id="Par129">In the News dataset, after removing the CNN, the Recall of the model decreased from 93.24% to 91.68% and the F1 value decreased from 94.22% to 93.08%.</p></list-item></list></p><p id="Par301">These results show that the CNN module performs particularly well in dealing with localized and nonlinear features, and can significantly improve the overall performance of the model, especially when faced with complex and diverse datasets.</p></sec><sec id="Sec38"><title>Conclusion of ablation experiments</title><p id="Par130">The results of the ablation experiments of the CCP-Net model on different industry datasets show that the complementary functionality of its modules improves the generalization ability of the model. For example, the performance degradation caused by the removal of Multi-Head Self-Attention is particularly noticeable in the Telecom and Insurance datasets, suggesting that this module is indispensable in dealing with industries with complex customer behavior patterns. Meanwhile, BiLSTM is more effective in handling time-series data, which is particularly suitable for the financial sector where long-term dependencies need to be captured. This flexible structural design enables CCP-Net to be widely applied to customer churn prediction tasks in different fields, providing a good basis for its promotion in various industries.</p></sec></sec><sec id="Sec39"><title>Impact of ADASYN on the performance of the CCP-Net model</title><p id="Par131">To assess the potential impact of ADASYN on the performance of the CCP-Net model, this experiment analyses the performance changes of the CCP-Net model before and after applying ADASYN. The experimental results are shown in Figure <xref rid="Fig14" ref-type="fig">14</xref>.<fig id="Fig14"><label>Fig. 14</label><caption><p>Changes in model performance before and after processing with ADASYN.</p></caption><graphic xlink:href="41598_2024_79603_Fig14_HTML" id="MO15"/></fig></p><p id="Par132">After processing with ADASYN, all performance metrics of the CCP-Net model are significantly improved. For example, in the Telecom dataset, the accuracy of the CCP-Net model is 87.64% using data not processed by ADASYN, and the accuracy of the CCP-Net model improves from 87.64% to 91.17% using data processed by ADASYN; meanwhile, the precision improves from 78. 52% to 92. 19%, the recall improves from 72. 74% to 90. 24%, and F1 improves from 75.49% to 91.18%. Similar trends were observed in other datasets; for example, in the Insurance dataset, accuracy improved from 89. 46% to 95. 86%, precision from 84. 49% to 95. 87%, recall from 82. 79% to 95. 03% and F1 from 83.72% to 95.43%.</p><p id="Par133">This result shows that applying ADASYN as an effective category balancing processing method to the CCP-Net model significantly enhances its overall performance in the customer churn prediction task. This not only demonstrates the effectiveness of ADASYN in dealing with the category imbalance problem but also demonstrates its potential to enhance the model generalization ability and improve the various metrics of the classification task.</p></sec><sec id="Sec40"><title>Algorithm complexity analysis</title><p id="Par134">In the task of customer churn prediction, the computational complexity of a model directly affects its training and prediction efficiency, which in turn affects its feasibility and applicability in practical applications. Model complexity not only affects the execution speed but also determines the resource requirements, such as memory and computational power. To better understand the advantages and limitations of CCP-Net, this paper compares it with several other hybrid neural network models (LSTM-CNN, BiLSTM-CNN, LSTM-Attention, FCLCNN-LSTM), analyses its temporal and spatial complexity, and explores the trade-offs between complexity and performance. The specific meanings of the symbols are shown in Table <xref rid="Tab8" ref-type="table">8</xref>:<table-wrap id="Tab8"><label>Table 8</label><caption><p>Description of the meaning of symbols.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Symbol</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left"><italic>n</italic></td><td align="left">Length of the input sequence</td></tr><tr><td align="left"><italic>d</italic></td><td align="left">Dimension of input features</td></tr><tr><td align="left"><italic>h</italic></td><td align="left">Dimension of the hidden state</td></tr><tr><td align="left"><italic>l</italic></td><td align="left">Number of layers in the LSTM layer</td></tr><tr><td align="left"><italic>k</italic></td><td align="left">Size of the convolution kernel</td></tr><tr><td align="left"><italic>c</italic></td><td align="left">Number of convolution kernels</td></tr></tbody></table></table-wrap></p><sec id="Sec41"><title>Time complexity</title><p id="Par135">CCP-Net consists of three modules: Multi-Head Self-Attention, BiLSTM, and CNN. The time complexity for each attention head in Multi-Head Self-Attention to compute the linear transformation of the input features and perform the weighted summation is <inline-formula id="IEq121"><alternatives><tex-math id="M293">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot d^2 \cdot h)$$\end{document}</tex-math><mml:math id="M294"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq121.gif"/></alternatives></inline-formula>, where <italic>h</italic> is the number of attention heads. The computational complexity of BiLSTM in capturing long-term dependencies in the time series is <inline-formula id="IEq122"><alternatives><tex-math id="M295">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot h^2 \cdot l)$$\end{document}</tex-math><mml:math id="M296"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq122.gif"/></alternatives></inline-formula>, where <italic>l</italic> is the length of the sequence. The computational complexity of CNN in performing convolutional operations on the input sequence is: <inline-formula id="IEq123"><alternatives><tex-math id="M297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(k \cdot n \cdot c)$$\end{document}</tex-math><mml:math id="M298"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq123.gif"/></alternatives></inline-formula>, where <italic>k</italic> is the filter size, and <italic>c</italic> is the number of channels. Thus, the overall time complexity of CCP-Net is <inline-formula id="IEq124"><alternatives><tex-math id="M299">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot d^2 \cdot h + n \cdot h^2 \cdot l + k \cdot n \cdot c)$$\end{document}</tex-math><mml:math id="M300"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq124.gif"/></alternatives></inline-formula>.</p><p id="Par136">In contrast, the time complexity of LSTM-CNN, BiLSTM-CNN, and FCLCNN-LSTM is: <inline-formula id="IEq125"><alternatives><tex-math id="M301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot h^2 + k \cdot n \cdot c)$$\end{document}</tex-math><mml:math id="M302"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq125.gif"/></alternatives></inline-formula>, and the time complexity of LSTM-Attention is: <inline-formula id="IEq126"><alternatives><tex-math id="M303">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot h^2 + n \cdot d^2)$$\end{document}</tex-math><mml:math id="M304"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq126.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec42"><title>Spatial complexity</title><p id="Par137">For CCP-Net, Multi-Head Self-Attention has a space complexity of <inline-formula id="IEq127"><alternatives><tex-math id="M305">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot d)$$\end{document}</tex-math><mml:math id="M306"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq127.gif"/></alternatives></inline-formula>, which is used to store the attention weights and intermediate variables. BiLSTM has a space complexity of <inline-formula id="IEq128"><alternatives><tex-math id="M307">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot h \cdot l)$$\end{document}</tex-math><mml:math id="M308"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>h</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq128.gif"/></alternatives></inline-formula>, which is used to store the intermediate variables of the hidden state and the gating unit. CNN has a space complexity of <inline-formula id="IEq129"><alternatives><tex-math id="M309">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot c)$$\end{document}</tex-math><mml:math id="M310"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq129.gif"/></alternatives></inline-formula>, which is used to store the intermediate results of the convolution operation. Therefore, the overall space complexity of CCP-Net is <inline-formula id="IEq130"><alternatives><tex-math id="M311">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot d + n \cdot h \cdot l + n \cdot c)$$\end{document}</tex-math><mml:math id="M312"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>h</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq130.gif"/></alternatives></inline-formula>.</p><p id="Par138">In contrast, the space complexity of LSTM-CNN, BiLSTM-CNN, and FCLCNN-LSTM is <inline-formula id="IEq131"><alternatives><tex-math id="M313">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot h + n \cdot c)$$\end{document}</tex-math><mml:math id="M314"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq131.gif"/></alternatives></inline-formula>, and the space complexity of LSTM-Attention is <inline-formula id="IEq132"><alternatives><tex-math id="M315">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$O(n \cdot h + n \cdot d)$$\end{document}</tex-math><mml:math id="M316"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_79603_Article_IEq132.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec43"><title>Time overhead and GPU memory usage</title><p id="Par139">Table <xref rid="Tab9" ref-type="table">9</xref> shows the computation time and GPU memory usage of different models when running 100 epochs on the Telecom dataset. From the data in the table, it can be seen that there is a significant difference in the time overhead and GPU memory usage of each model during training, which is closely related to the complexity and structural characteristics of the models.<table-wrap id="Tab9"><label>Table 9</label><caption><p>Model time overhead and GPU memory usage.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model name</th><th align="left">Time(seconds)</th><th align="left">GPU memory usage(MB)</th></tr></thead><tbody><tr><td align="left">LSTM-CNN</td><td align="left">18.72</td><td align="left">137.31</td></tr><tr><td align="left">BiLSTM-CNN</td><td align="left">18.85</td><td align="left">148.49</td></tr><tr><td align="left">LSTM-Attention</td><td align="left">27.10</td><td align="left">152.66</td></tr><tr><td align="left">FCLCNN-LSTM</td><td align="left">19.85</td><td align="left">142.25</td></tr><tr><td align="left">CCP-Net</td><td align="left">32.94</td><td align="left">168.06</td></tr></tbody></table></table-wrap></p><p id="Par140">
<list list-type="bullet"><list-item><p id="Par141">Time overhead</p><p id="Par142">The training time of LSTM-CNN and BiLSTM-CNN is 18.72 seconds and 18.85 seconds respectively, which is not much different from each other, reflecting the lower computational requirements of these models, which are suitable for tasks with high response time requirements.</p><p id="Par302">The training time of LSTM-Attention is significantly longer at 27.10 seconds, which is closely related to the introduction of the Attention mechanism, which requires more computational resources to capture the global dependency information, which increases the computation time of the model.</p><p id="Par303">The training time of FCLCNN-LSTM is 19.85 seconds, which is slightly higher than that of LSTM-CNN and BiLSTM-CNN, but still within a reasonable range, indicating that the model is also more efficient.</p><p id="Par304">The training time of CCP-Net is 32.94 seconds, which is the longest among all models. Due to its combination of the Multi-Head Self-Attention, BiLSTM, and CNN modules, the computational requirements are significantly higher. In particular, the introduction of the Attention module and the BiLSTM layer allows the model to handle more complex sequence dependencies and feature interactions, which improves the model&#x02019;s predictive ability, but at the expense of computational efficiency.</p></list-item><list-item><p id="Par143">GPU memory usage</p><p id="Par144">LSTM-CNN and BiLSTM-CNN show relatively low memory requirements with 137.31 MB and 148.49 MB of GPU memory usage, respectively. This is due to their relatively simple structure, which does not introduce complex global dependency modeling modules (e.g., Multi-Head Self-Attention), and thus is more efficient in terms of memory usage.</p><p id="Par309">The GPU memory usage of LSTM-Attention is 152.66 MB, which is slightly higher than that of LSTM-CNN and BiLSTM-CNN, which is mainly because the Multi-Head Self-Attention mechanism requires more memory to store the attention weights and intermediate computation results during the training process.</p><p id="Par311">The memory usage of FCLCNN-LSTM is 142.25 MB, which is slightly higher than that of LSTM-CNN and BiLSTM-CNN, but still lighter compared to LSTM-Attention.</p><p id="Par312">CCP-Net has the highest GPU memory usage of 168.06 MB, which is closely related to its complex architecture (containing Multi-Head Self-Attention, BiLSTM, and CNN). The Multi-Head Self-Attention module in particular has a significant increase in overhead in terms of memory requirements, resulting in a relatively high memory usage for CCP-Net. Net&#x02019;s relatively high memory usage.</p></list-item></list>
</p></sec><sec id="Sec44"><title>Performance versus complexity trade-offs</title><p id="Par145">In summary, CCP-Net is higher than other hybrid neural network models in both time and space complexity, especially when dealing with complex behavioral patterns, and its ability to capture multi-dimensional features significantly improves prediction accuracy. However, the higher computational resource requirements and training time may cause some limitations in scenarios with high real-time requirements or limited resources. In contrast, models such as LSTM-CNN, BiLSTM-CNN, LSTM-Attention and FCLCNN-LSTM can complete training and prediction in a shorter time due to lower time and space complexity, which is suitable for tasks that require fast response or operate in resource-constrained environments; however, these models are not as good as CCP-LSTM in capturing the global dependency information and handling complex feature interactions are not as good as CCP-Net.</p><p id="Par146">In practice, the selection of an appropriate model should take into account the specific application requirements. If the task emphasizes high performance and complex data processing capability, CCP-Net is a better choice; if it focuses more on real-time performance and resource efficiency, lightweight models (LSTM-CNN or FCLCNN-LSTM) are more suitable. Meanwhile, BiLSTM-CNN and LSTM-Attention can also be used as a compromise between performance and efficiency for scenarios with high requirements for the extraction of temporal features.</p></sec></sec></sec><sec id="Sec45"><title>Conclusions and future work</title><p id="Par147">In this paper, we propose a customer churn prediction model, CCP-Net, which integrates Multi-Head Self-Attention, BiLSTM, and CNN. We aim to solve the customer churn problem effectively. To verify the validity of the model, we conducted systematic data preprocessing on datasets from four different industries and implemented ten-fold cross-validation to ensure the reliability of the evaluation results.</p><p id="Par148">After analyzing the experimental parameters, we determine the optimal configuration of each parameter in the CCP-Net model. Through comparative experiments, we can see that CCP-Net outperforms a variety of common deep learning algorithms and hybrid neural networks, demonstrating significant superiority and strong generalization ability. In addition, ablation experiments further validate the architectural soundness of CCP-Net, showing that the combination of Multi-Head Self-Attention, BiLSTM, and CNN endows the model with excellent prediction performance. We also explore the application of ADASYN technology in improving the predictive performance of the model, and the results show that all the performance metrics of CCP-Net are significantly improved after training with ADASYN-treated data, which fully demonstrates the effectiveness of ADASYN in customer churn prediction.</p><p id="Par149">Although CCP-Net performs well in prediction accuracy, its high time and space complexity limits its feasibility in real-time applications. Therefore, we plan to improve the model in future research, working to reduce time and space complexity while maintaining prediction accuracy. Future work will explore more advanced data processing techniques, model optimization methods, and innovative algorithms. We expect that the results of these studies will help organizations to deeply understand and manage their customer relationships, and thus achieve sustainable business development.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author contributions</title><p>All authors contributed greatly to this paper, Xinyu Liu designed the experiments and wrote the main manuscript, Guoen Xia, Xianquan Zhang, Wenbin Ma, and Chunqiang Yu suggested revisions to the paper and touched up the language. All authors reviewed the manuscript.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>Underlying data supporting the results can be provided by sending a request to the corresponding author.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>The code used for this research is publicly available at https://github.com/segujn/CCP-Net.git.</p></notes><notes><title>Declarations</title><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par877">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Xiahou</surname><given-names>X</given-names></name><name><surname>Harada</surname><given-names>Y</given-names></name></person-group><article-title>B2c e-commerce customer churn prediction based on k-means and svm</article-title><source>J. Theor. Appl. Electron. Commer. Res.</source><year>2022</year><volume>17</volume><fpage>458</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.3390/jtaer17020024</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Xiahou, X. &#x00026; Harada, Y. B2c e-commerce customer churn prediction based on k-means and svm. <italic>J. Theor. Appl. Electron. Commer. Res.</italic><bold>17</bold>, 458&#x02013;475 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>En Xia</surname><given-names>G</given-names></name><name><surname>Dong Jin</surname><given-names>W</given-names></name></person-group><article-title>Model of customer churn prediction on support vector machine</article-title><source>Systems Engineering - Theory &#x00026; Practice</source><year>2008</year><volume>28</volume><fpage>71</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/S1874-8651(09)60003-X</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">En Xia, G. &#x00026; Dong Jin, W. Model of customer churn prediction on support vector machine. <italic>Systems Engineering - Theory &#x00026; Practice</italic><bold>28</bold>, 71&#x02013;77 (2008).</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Karimi, N., Dash, A., Rautaray, S.&#x000a0;S. &#x00026; Pandey, M. Customer profiling and retention using recommendation system and factor identification to predict customer churn in telecom industry. Machine Learning: Theoretical Foundations and Practical Applications 155&#x02013;172 (2021).</mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Mishra, A. &#x00026; Reddy, U.&#x000a0;S. A comparative study of customer churn prediction in telecom industry using ensemble based classifiers. 2017 International Conference on Inventive Computing and Informatics (ICICI) 721&#x02013;725 (2017).</mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Kim, S., Shin, K.-s. &#x00026; Park, K. An application of support vector machines for customer churn analysis: Credit card case. In International Conference on Natural Computation, 636&#x02013;647 (Springer, 2005).</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">NV, M.&#x000a0;K., KK, B.&#x000a0;K. &#x00026; Mudhol, A.&#x000a0;C. Machine learning based prediction of customer churning in banking sector. In 2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS), 474&#x02013;481 (IEEE, 2022).</mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Kiguchi</surname><given-names>M</given-names></name><name><surname>Saeed</surname><given-names>W</given-names></name><name><surname>Medi</surname><given-names>I</given-names></name></person-group><article-title>Churn prediction in digital game-based learning using data mining techniques: Logistic regression, decision tree, and random forest</article-title><source>Appl. Soft Comput.</source><year>2022</year><volume>118</volume><fpage>108491</fpage><pub-id pub-id-type="doi">10.1016/j.asoc.2022.108491</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Kiguchi, M., Saeed, W. &#x00026; Medi, I. Churn prediction in digital game-based learning using data mining techniques: Logistic regression, decision tree, and random forest. <italic>Appl. Soft Comput.</italic><bold>118</bold>, 108491 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Al-Najjar</surname><given-names>D</given-names></name><name><surname>Al-Rousan</surname><given-names>N</given-names></name><name><surname>Al-Najjar</surname><given-names>HM</given-names></name></person-group><article-title>Machine learning to develop credit card customer churn prediction</article-title><source>J. Theor. Appl. Electron. Commer. Res.</source><year>2022</year><volume>17</volume><fpage>1529</fpage><lpage>1542</lpage><pub-id pub-id-type="doi">10.3390/jtaer17040077</pub-id></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Al-Najjar, D., Al-Rousan, N. &#x00026; Al-Najjar, H. M. Machine learning to develop credit card customer churn prediction. <italic>J. Theor. Appl. Electron. Commer. Res.</italic><bold>17</bold>, 1529&#x02013;1542 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Ahmad, A.&#x000a0;K., Jafar, A. &#x00026; Aljoumaa, K. Customer churn prediction in telecom using machine learning in big data platform. Journal of Big Data <bold>6</bold> (2019).</mixed-citation></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Lalwani</surname><given-names>P</given-names></name><name><surname>Mishra</surname><given-names>MK</given-names></name><name><surname>Chadha</surname><given-names>JS</given-names></name><name><surname>Sethi</surname><given-names>P</given-names></name></person-group><article-title>Customer churn prediction system: a machine learning approach</article-title><source>Computing</source><year>2021</year><volume>104</volume><fpage>271</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1007/s00607-021-00908-y</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Lalwani, P., Mishra, M. K., Chadha, J. S. &#x00026; Sethi, P. Customer churn prediction system: a machine learning approach. <italic>Computing</italic><bold>104</bold>, 271&#x02013;294 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Dhanawade, A., Mahapatra, B. &#x00026; Bhatt, A. A smote-based churn prediction system using machine learning techniques. 2023 1st DMIHER International Conference on Artificial Intelligence in Education and Industry 4.0 (IDICAIEI) <bold>1</bold>, 1&#x02013;7 (2023).</mixed-citation></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Sikri</surname><given-names>A</given-names></name><name><surname>Jameel</surname><given-names>R</given-names></name><name><surname>Idrees</surname><given-names>SM</given-names></name><name><surname>Kaur</surname><given-names>H</given-names></name></person-group><article-title>Enhancing customer retention in telecom industry with machine learning driven churn prediction</article-title><source>Scientific Reports</source><year>2024</year><volume>14</volume><fpage>13097</fpage><pub-id pub-id-type="doi">10.1038/s41598-024-63750-0</pub-id><pub-id pub-id-type="pmid">38849493</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Sikri, A., Jameel, R., Idrees, S. M. &#x00026; Kaur, H. Enhancing customer retention in telecom industry with machine learning driven churn prediction. <italic>Scientific Reports</italic><bold>14</bold>, 13097 (2024).<pub-id pub-id-type="pmid">38849493</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>C</given-names></name><name><surname>Ding</surname><given-names>CH</given-names></name></person-group><article-title>A novel classification algorithm for customer churn prediction based on hybrid ensemble-fusion model</article-title><source>Scientific Reports</source><year>2024</year><volume>14</volume><fpage>20179</fpage><pub-id pub-id-type="doi">10.1038/s41598-024-71168-x</pub-id><pub-id pub-id-type="pmid">39215049</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">He, C. &#x00026; Ding, C. H. A novel classification algorithm for customer churn prediction based on hybrid ensemble-fusion model. <italic>Scientific Reports</italic><bold>14</bold>, 20179 (2024).<pub-id pub-id-type="pmid">39215049</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Aditsania, A., Adiwijaya &#x00026; Saonard, A.&#x000a0;L. Handling imbalanced data in churn prediction using adasyn and backpropagation algorithm. 2017 3rd International Conference on Science in Information Technology (ICSITech) 533&#x02013;536 (2017).</mixed-citation></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Saha</surname><given-names>L</given-names></name><name><surname>Tripathy</surname><given-names>HK</given-names></name><name><surname>Gaber</surname><given-names>T</given-names></name><name><surname>El-Gohary</surname><given-names>H</given-names></name><name><surname>El-kenawy</surname><given-names>E-SM</given-names></name></person-group><article-title>Deep churn prediction method for telecommunication industry</article-title><source>Sustainability</source><year>2023</year><volume>15</volume><fpage>4543</fpage><pub-id pub-id-type="doi">10.3390/su15054543</pub-id></element-citation><mixed-citation id="mc-CR15" publication-type="journal">Saha, L., Tripathy, H. K., Gaber, T., El-Gohary, H. &#x00026; El-kenawy, E.-S.M. Deep churn prediction method for telecommunication industry. <italic>Sustainability</italic><bold>15</bold>, 4543 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Tsai</surname><given-names>C-F</given-names></name><name><surname>Lu</surname><given-names>Y-H</given-names></name></person-group><article-title>Customer churn prediction by hybrid neural networks</article-title><source>Expert Syst. Appl.</source><year>2009</year><volume>36</volume><fpage>12547</fpage><lpage>12553</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2009.05.032</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Tsai, C.-F. &#x00026; Lu, Y.-H. Customer churn prediction by hybrid neural networks. <italic>Expert Syst. Appl.</italic><bold>36</bold>, 12547&#x02013;12553 (2009).</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Tang, Q., Xia, G., Zhang, X. &#x00026; Long, F. A customer churn prediction model based on xgboost and mlp. In 2020 International Conference on Computer Engineering and Application (ICCEA), 608&#x02013;612 (IEEE, 2020).</mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Wu, H. A high-performance customer churn prediction system based on self-attention. ArXiv <bold>abs/2206.01523</bold> (2022).</mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Zhou, J., Yan, J., Yang, L., Wang, M. &#x00026; Xia, P. Customer churn prediction model based on lstm and cnn in music streaming. DEStech Transactions on Engineering and Technology Research (2019).</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Hu, J. et al. prnn: A recurrent neural network based approach for customer churn prediction in telecommunication sector. 2018 IEEE International Conference on Big Data (Big Data) 4081&#x02013;4085 (2018).</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Zhang, L. &#x00026; Wei, Q. Personalized and contextualized data analysis for e-commerce customer retention improvement with bi-lstm churn prediction. IEEE Transactions on Consumer Electronics (2024).</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Arik, S.&#x000a0;&#x000d6;. &#x00026; Pfister, T. Tabnet: Attentive interpretable tabular learning. ArXiv <bold>abs/1908.07442</bold> (2019).</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Vaswani, A. Attention is all you need. Advances in Neural Information Processing Systems (2017).</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Khine, S.&#x000a0;T. &#x00026; Myo, W.&#x000a0;W. Mining customer churns for banking industry using k-means and multi-layer perceptron. In 2023 IEEE Conference on Computer Applications (ICCA), 220&#x02013;225 (IEEE, 2023).</mixed-citation></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Venkatesh</surname><given-names>S</given-names></name><name><surname>Jeyakarthic</surname><given-names>M</given-names></name></person-group><article-title>Artificial fish swarm algorithm-based multilayer perceptron model for customer churn prediction in iot with cloud environment</article-title><source>International Journal of Business Information Systems</source><year>2023</year><volume>44</volume><fpage>442</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1504/IJBIS.2023.134958</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Venkatesh, S. &#x00026; Jeyakarthic, M. Artificial fish swarm algorithm-based multilayer perceptron model for customer churn prediction in iot with cloud environment. <italic>International Journal of Business Information Systems</italic><bold>44</bold>, 442&#x02013;465 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Latheef, J. &#x00026; Vineetha, S.&#x000a0;G. Lstm model to predict customer churn in banking sector with smote data preprocessing. 2021 2nd International Conference on Advances in Computing, Communication, Embedded and Secure Systems (ACCESS) 86&#x02013;90 (2021).</mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Khattak, A.&#x000a0;M. et al. Customer churn prediction using composite deep learning technique. <italic>Scientific Reports</italic><bold>13</bold> (2023).</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Wang, Y., Zheng, S., Liu, G. &#x00026; Li, J.-J. Research on bank customer churn model based on attention network. 2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA) 346&#x02013;350 (2023).</mixed-citation></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Rao</surname><given-names>C</given-names></name><name><surname>Hu</surname><given-names>F</given-names></name><name><surname>Xiao</surname><given-names>X</given-names></name><name><surname>Goh</surname><given-names>M</given-names></name></person-group><article-title>Risk assessment of customer churn in telco using fclcnn-lstm model</article-title><source>Expert Systems with Applications</source><year>2024</year><volume>248</volume><fpage>123352</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2024.123352</pub-id></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Wang, C., Rao, C., Hu, F., Xiao, X. &#x00026; Goh, M. Risk assessment of customer churn in telco using fclcnn-lstm model. <italic>Expert Systems with Applications</italic><bold>248</bold>, 123352 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Zhuang, S. Telecom customer churn prediction datasets. kaggle: <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/datasets/shilongzhuang/telecom-customer-churn-by-maven-analytics">https://www.kaggle.com/datasets/shilongzhuang/telecom-customer-churn-by-maven-analytics</ext-link> (2019).</mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Dhakad, S. Bank customer churn prediction datasets. kaggle: <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction">https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction</ext-link> (2022).</mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Kumar, V. Insurance churn prediction: Weekend hackathon. kaggle: <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/datasets/k123vinod/insurance-churn-prediction-weekend-hackathon">https://www.kaggle.com/datasets/k123vinod/insurance-churn-prediction-weekend-hackathon</ext-link> (2020).</mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Andieminogue. Newspaper churn. kaggle: <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/datasets/andieminogue/newspaper-churn">https://www.kaggle.com/datasets/andieminogue/newspaper-churn</ext-link> (2018).</mixed-citation></ref></ref-list></back></article>