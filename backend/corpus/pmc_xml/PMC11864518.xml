<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS One</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40009579</article-id><article-id pub-id-type="pmc">PMC11864518</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0316555</article-id><article-id pub-id-type="publisher-id">PONE-D-24-23591</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychological Attitudes</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychological Attitudes</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and Places</subject><subj-group><subject>Population Groupings</subject><subj-group><subject>Age Groups</subject><subj-group><subject>Children</subject><subj-group><subject>Infants</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and Places</subject><subj-group><subject>Population Groupings</subject><subj-group><subject>Families</subject><subj-group><subject>Children</subject><subj-group><subject>Infants</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Thermodynamics</subject><subj-group><subject>Entropy</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory Physiology</subject><subj-group><subject>Visual System</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Systems</subject><subj-group><subject>Visual System</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory Physiology</subject><subj-group><subject>Visual System</subject><subj-group><subject>Eye Movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Systems</subject><subj-group><subject>Visual System</subject><subj-group><subject>Eye Movements</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>The edge orientation entropy of natural scenes is associated with infant visual preferences and adult aesthetic judgements</article-title><alt-title alt-title-type="running-head">Infant perception of natural scene edge statistics</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0005-9645-3331</contrib-id><name><surname>McAdams</surname><given-names>Philip</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Svobodova</surname><given-names>Sara</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Newman</surname><given-names>Taysa-Ja</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Terry</surname><given-names>Kezia</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Mather</surname><given-names>George</given-names></name><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Skelton</surname><given-names>Alice E.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Franklin</surname><given-names>Anna</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>The Sussex Colour Group and Baby Lab, The School of Psychology, University of Sussex, Brighton, United Kingdom</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>The School of Psychology, University of Sussex, Brighton, United Kingdom</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Nature and Development Lab, The School of Psychology, University of Sussex, Brighton, United Kingdom</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Norouzian-Maleki</surname><given-names>Saeid</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>Shahid Beheshti University, IRAN, ISLAMIC REPUBLIC OF</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>anna.franklin@sussex.ac.uk</email> (AF); <email>p.mcadams@sussex.ac.uk</email> (PM)</corresp></author-notes><pub-date pub-type="epub"><day>26</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>20</volume><issue>2</issue><elocation-id>e0316555</elocation-id><history><date date-type="received"><day>18</day><month>6</month><year>2024</year></date><date date-type="accepted"><day>12</day><month>12</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; 2025 McAdams et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>McAdams et al</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0316555.pdf">
</self-uri><abstract><p>Statistical regularities of oriented edges in natural scenes, &#x02018;edge co-occurrence statistics&#x02019;, are associated with adults&#x02019; aesthetic responses, with greater preference for some images when the degree of randomness in the orientation of edges (Edge Orientation Entropy, EOE) across an image is relatively high. Here, we investigate whether this spatial image statistic is also associated with infants&#x02019; visual preferences. We measure infant looking time for images of building fa&#x000e7;ades previously used to identify the relationship between EOE and adult aesthetic judgements. Twenty-six 4&#x02013;9-month-old infants and 29 adults looked freely at pairs of the images. Infants and adults both looked longest at images where all edge orientations are about equally likely to occur (high 1st-order EOE), and at images with low correlation of edge orientations across the image (high 2nd-order EOE). Infant looking time and adult pleasantness judgements were also strongly related: infants looked longer at the building fa&#x000e7;ades that adults liked. Our results suggest that even as young as 4-months, infants&#x02019; spatial vision is sensitive to edge co-occurrence statistics that are typical of natural scenes and faces, where edges are more evenly distributed across orientations. We discuss the implications for understanding the sensory component of adult aesthetic judgements, as well as the role of natural scene statistics in infant perception.</p></abstract><funding-group><award-group id="award001"><funding-source>
<institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100019180</institution-id><institution>HORIZON EUROPE European Research Council</institution></institution-wrap>
</funding-source><award-id>772193</award-id><principal-award-recipient>
<name><surname>Franklin</surname><given-names>Anna</given-names></name>
</principal-award-recipient></award-group><funding-statement>This study is part of a project that has received funding from the European Research Council (ERC) under the Horizon 2020 research and innovation programme (Project COLORMIND: Grant agreement No. 772193, to A.F.). P.M&#x02019;s doctoral studentship also received part funding from Etta Loves Ltd. URL of each funder website: <ext-link xlink:href="https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-2020_en" ext-link-type="uri">https://research-and-innovation.ec.europa.eu/funding/funding-opportunities/funding-programmes-and-open-calls/horizon-2020_en</ext-link>
<ext-link xlink:href="https://www.ettaloves.com/pages/baby-lab-collab" ext-link-type="uri">https://www.ettaloves.com/pages/baby-lab-collab</ext-link>.</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="0"/><page-count count="15"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>Data availability statement The datasets generated and analysed during the current study are available in the Open Science Framework repository, <ext-link xlink:href="https://osf.io/k4b68/" ext-link-type="uri">https://osf.io/k4b68/</ext-link>. We provide the values for our analysis of the image statistics of the fa&#x000e7;ade stimuli and the infant and adult average looking times. The building fa&#x000e7;ade stimuli and adult pleasantness ratings are available from Christoph Redies (<ext-link xlink:href="https://osf.io/cxyj4/" ext-link-type="uri">https://osf.io/cxyj4/</ext-link>).</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>Data availability statement The datasets generated and analysed during the current study are available in the Open Science Framework repository, <ext-link xlink:href="https://osf.io/k4b68/" ext-link-type="uri">https://osf.io/k4b68/</ext-link>. We provide the values for our analysis of the image statistics of the fa&#x000e7;ade stimuli and the infant and adult average looking times. The building fa&#x000e7;ade stimuli and adult pleasantness ratings are available from Christoph Redies (<ext-link xlink:href="https://osf.io/cxyj4/" ext-link-type="uri">https://osf.io/cxyj4/</ext-link>).</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Decades of research has documented that even young infants look longer at some stimuli than others: for example, infants look longer at upright than inverted faces [<xref rid="pone.0316555.ref001" ref-type="bibr">1</xref>], vertical symmetry than horizontal [<xref rid="pone.0316555.ref002" ref-type="bibr">2</xref>], and red than green [<xref rid="pone.0316555.ref003" ref-type="bibr">3</xref>]. These &#x02018;visual preferences&#x02019; have provided much insight into infants&#x02019; visual and perceptual systems, and the role of experience in perceptual development. The relationship between infants&#x02019; visual preferences and adults&#x02019; aesthetic judgements has also been investigated, and several studies have revealed that infants look longer at certain stimuli the more adults like them [<xref rid="pone.0316555.ref004" ref-type="bibr">4</xref>&#x02013;<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>]. For example, infants look longer at faces that adults rate as attractive than unattractive [<xref rid="pone.0316555.ref004" ref-type="bibr">4</xref>], and look longer at preferred than disliked colours [<xref rid="pone.0316555.ref005" ref-type="bibr">5</xref>], biological motion [<xref rid="pone.0316555.ref006" ref-type="bibr">6</xref>], and art [<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>]. These associations between infant looking and adult liking do not necessarily indicate that infants have an &#x02018;aesthetic&#x02019; response or &#x02018;like&#x02019; certain stimuli, as infant looking can be driven by other factors such as interest, salience, or stimulation [<xref rid="pone.0316555.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0316555.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0316555.ref009" ref-type="bibr">9</xref>]. Rather, infants&#x02019; visual preferences are better understood as reflecting a sensory bias of the visual system, and the association with adult aesthetic judgements potentially provides further evidence that sensory biases contribute to aesthetic judgements later in life. One popular framework for understanding aesthetic judgements is as an interaction of sensory, emotive, and cognitive components [<xref rid="pone.0316555.ref010" ref-type="bibr">10</xref>]. Investigating infants&#x02019; visual preferences for aesthetic stimuli may help elucidate the sensory component, because the role of cognitive and emotional factors such as experience, conceptualisation, memory, knowledge, context, and culture is weaker in infancy relative to adulthood [<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>]. Establishing infants&#x02019; response to aesthetic stimuli is the first step in understanding how a mature aesthetic judgement develops. Beyond this, aesthetic stimuli provide a rich resource for further characterising infant perception.</p><p>Here, we further investigate the relationship between infants&#x02019; visual preferences and adult aesthetic judgements. We investigate whether infants look longer at building fa&#x000e7;ades that adults find more pleasant, and whether spatial image statistics are similarly associated with infants&#x02019; and adults&#x02019; response. Buildings are a stimulus that most people encounter in their day to day lives, and often generate aesthetic responses [<xref rid="pone.0316555.ref011" ref-type="bibr">11</xref>]. Decades of research in Architectural Design and the emerging field of Neuroarchitecture [<xref rid="pone.0316555.ref012" ref-type="bibr">12</xref>], has revealed numerous features of buildings that affect people&#x02019;s emotional, physical, and cognitive responses [<xref rid="pone.0316555.ref013" ref-type="bibr">13</xref>,<xref rid="pone.0316555.ref014" ref-type="bibr">14</xref>]. One line of research has focused on the low-level visual features and image statistics that could contribute to aesthetic judgements of architecture. For example, the fractal dimension [<xref rid="pone.0316555.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0316555.ref016" ref-type="bibr">16</xref>] and Fourier spectral properties [<xref rid="pone.0316555.ref017" ref-type="bibr">17</xref>] of architecture have been found to affect peoples&#x02019; preference and well-being in spaces. In addition, one recent study has found that edge co-occurrence statistics are associated with adult aesthetic judgements for building fa&#x000e7;ades [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>].</p><p>Edge co-occurrence statistics measure the statistical regularities of edge orientations across images, where edges are defined as a steep change in luminance, e.g., at object boundaries [<xref rid="pone.0316555.ref019" ref-type="bibr">19</xref>]. Edge co-occurrence statistics play a role in perceptual processes such as contour grouping, and object occlusion, categorization and detection in complex scenes [<xref rid="pone.0316555.ref020" ref-type="bibr">20</xref>&#x02013;<xref rid="pone.0316555.ref023" ref-type="bibr">23</xref>]. Grebenkina et al. [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>] (see also [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>]) measured edge co-occurrence statistics by calculating 1st-order and 2nd-order edge orientation entropy (EOE). First-order EOE measures the degree of randomness in the orientations of individual edges: an image where particular edge orientations are more frequent than others has low 1st-order EOE, whereas an image where no particular edge orientations are more frequent than others has high 1st-order EOE. Second-order EOE measures the degree of randomness in the relative orientations of pairs of edges: an image in which the orientations of edges are predictive of one another has lower 2nd-order EOE, and an image where the orientations of edges are independent has high 2nd-order EOE. Grebenkina et al. [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>] found that the degree of randomness of oriented edges as measured by EOE predicted how pleasant and interesting adults rated the building fa&#x000e7;ades: fa&#x000e7;ades were more pleasant and interesting the greater the EOE. Low EOE fa&#x000e7;ades have a range of orientated edges where certain orientations are more dominant than others (e.g., horizontal and vertical), representing a more simplistic fa&#x000e7;ade, for example, as in Modern style office buildings. High EOE fa&#x000e7;ades have a range of oriented edges where all possible orientations are more equally represented, and therefore will have more decoration and embellishments, for example, as in Renaissance architecture. EOE shares variance with curvature (high 1st-order and 2nd-order EOE images have more curves), which also relates to adult aesthetic judgement [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>,<xref rid="pone.0316555.ref025" ref-type="bibr">25</xref>], although EOE is more strongly related than curvature to aesthetic judgements of building fa&#x000e7;ades [<xref rid="pone.0316555.ref025" ref-type="bibr">25</xref>].</p><p>Here we use the same stimuli as Grebenkina et al. [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>], and the infant preferential looking technique [<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0316555.ref026" ref-type="bibr">26</xref>], to establish whether infants have a &#x02018;visual preference&#x02019; for building fa&#x000e7;ades with high EOE that corresponds to adults&#x02019; pleasantness judgements. The well-established infant preferential looking technique records infant looking times to pairs of stimuli, and as explained earlier, longer looking to one stimulus over the other is defined as a &#x02018;visual preference&#x02019; indicating some form of sensory bias that does not necessarily imply that infants like the stimulus. Our question here is not whether infants like the same building fa&#x000e7;ades as adults, but rather whether infants have a sensory bias for the building fa&#x000e7;ades that adults find most pleasant, and whether EOE as a spatial image statistic can explain the variance in infants&#x02019; sensory bias.</p><p>Our study is motivated by two aims. First, the study aims to gain insight into the extent to which early sensory biases in infancy are associated with a mature aesthetic response in adulthood. Second, the study aims to gain further insight into the characteristics of infant perception. Whilst infant vision has been well characterised with simple stimuli that isolate chromatic and spatial properties [<xref rid="pone.0316555.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0316555.ref027" ref-type="bibr">27</xref>], infants&#x02019; perception of complex stimuli such as art or natural scenes is less well characterised. Studies that investigate infants&#x02019; response to natural scenes are starting to provide insight into the role of top-down and bottom-up processing in infant perception [<xref rid="pone.0316555.ref028" ref-type="bibr">28</xref>], as well as further characterise infant eye-movements [<xref rid="pone.0316555.ref029" ref-type="bibr">29</xref>]. Other research has started to consider the extent to which infants are sensitive to the statistical regularities of natural scenes [<xref rid="pone.0316555.ref030" ref-type="bibr">30</xref>&#x02013;<xref rid="pone.0316555.ref032" ref-type="bibr">32</xref>]. For example, one study suggests that infants are sensitive to natural scene texture statistics [<xref rid="pone.0316555.ref030" ref-type="bibr">30</xref>]; and infant color vision appears to be aligned with the distribution of chromaticities in natural scenes [<xref rid="pone.0316555.ref032" ref-type="bibr">32</xref>]. An investigation of infants&#x02019; response to van Gogh landscapes also found that infants&#x02019; visual preference for the landscapes could be partly accounted for by a combination of image statistics such as saturation and luminance contrast, as well as edge statistics such as edge density [<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>]. The current study aims to build on this research and investigate the role of EOE in infant perception.</p><p>In order to investigate whether infants look longer at buildings that adults find more pleasant, and to identify whether there is a contribution of EOE, the current study records infant and adult looking responses to pairs of building fa&#x000e7;ade images from Grebenkina et al.&#x02019;s [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>] stimulus set. We also compute EOE for the images of building fa&#x000e7;ades, which are controlled in the amount of luminance contrast. We eye-track infants and adults looking at pairs of the stimuli, and then correlate infant and adult looking time. We also correlate infant looking time with adult pleasantness ratings from Grebenkina et al. [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>], and correlate 1st-order- and 2nd-order EOE with adult and infant measures. A series of multiple regressions investigates whether infant and adult responses are better accounted for by other spatial image statistics. The findings will establish whether the similarity between infant visual preferences and adult aesthetic judgements extends to architecture, and will also assess the role of EOE in infant perception.</p></sec><sec id="sec002"><title>Method</title><sec id="sec003"><title>Participants</title><p>Twenty-nine infants aged between 18 and 39 weeks old (<italic toggle="yes">M</italic> =&#x02009; 28 weeks, <italic toggle="yes">SD</italic> =&#x02009; 6 weeks, 17 male) took part. Three infants&#x02019; data were excluded from analysis because either: (i) the number of trials completed was less than the inclusion rate (&#x0003c;20), due to fussiness; (ii) an accurate calibration was not completed; or (iii) the infant&#x02019;s average looking time was classed as an outlier, calculated as 1.5 times less than or greater than the interquartile range. All infants were full term and weighed over 2500g at birth. Their parents reported no known neurological or visual conditions, or family history of color vision deficiency. Infants were opportunity sampled via social media and given a Baby Lab t-shirt for taking part in the study. There were 29 adult participants aged 18&#x02013;56 years (<italic toggle="yes">M</italic> =&#x02009; 23 years, <italic toggle="yes">SD</italic> =&#x02009; 8.4 years, 6 male), with normal or corrected-to-normal vision, recruited via opportunity sampling from the University of Sussex student and staff body. Adult participants were compensated for their time at payment equivalent to the UK national minimum wage. Written informed consent was obtained from infants&#x02019; caregivers and adult participants; the study conforms to the tenets of the Declaration of Helsinki (other than pre-registration), and ethical approval was granted by the University of Sussex Sciences &#x00026; Technology Cross-Schools Research Ethics Committee (ER/AES31/27) and from the European Research Council Executive Agency.</p></sec><sec id="sec004"><title>Stimuli</title><p>Stimuli were 26 greyscale digital photographs of building fa&#x000e7;ades, ranging from simple to highly ornamental, without faces, forms, figures, or writing, which might bias infant and adult looking (see <xref rid="pone.0316555.g001" ref-type="fig">Fig 1A</xref>). Stimuli were sampled from a stimulus set used in previous studies [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>,<xref rid="pone.0316555.ref033" ref-type="bibr">33</xref>], and were photographed by Christoph Redies, mostly in Vienna and Berlin. Each image was cropped to select only two stories of a building. Images were prepared as described in Grebenkina et al. [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>], and as described in brief below (see Image analysis). Stimuli were converted from color to greyscale using the ITU-R-601&#x02013;2 luma transform [<xref rid="pone.0316555.ref034" ref-type="bibr">34</xref>], which weights the color channels according to their perceived luminosity, and the luminance histograms were equalised so that each image shared the same luminance distribution. Images were re-sized to 800 pixels x 800 pixels using bilinear scaling. Stimuli subtended a visual angle of 22.77&#x000b0; when shown as pairs with their inner edges 3.72&#x000b0; to the left and right of the centre point of the screen (see <xref rid="pone.0316555.g001" ref-type="fig">Fig 1B</xref>). Stimuli were displayed on a HP LP2480zx LCD Monitor (HP, Reading, UK) with a screen resolution of 1920 x 1200 pixels. Stimuli were shown on a neutral grey background (x =&#x02009; 0.29, y =&#x02009; 0.25, Y =&#x02009; 21.33 cd/m<sup>2</sup>). Eye-movements were recorded via an EyeLink1000 Plus system (SR Research, Ontario, Canada).</p><fig position="float" id="pone.0316555.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0316555.g001</object-id><label>Fig 1</label><caption><title>Stimuli and trial example.</title><p>(A) Stimuli were sampled from a set of 26 cropped and square digital versions of building fa&#x000e7;ades ranging from low to high 1st-order and 2nd-order edge orientation entropy. Fa&#x000e7;ades are shown increasing in 1st-order edge orientation entropy from top-left to bottom-right, and with their corresponding edge orientation entropy values below each fa&#x000e7;ade - 1st-order (top number) and 2nd-order (bottom number). (B) Stimuli were shown to participants paired on a grey background. Building fa&#x000e7;ade images by Christoph Redies (<ext-link xlink:href="https://osf.io/cxyj4/" ext-link-type="uri">https://osf.io/cxyj4/</ext-link>), licensed under CC BY 4.0 (<ext-link xlink:href="https://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">https://creativecommons.org/licenses/by/4.0/</ext-link>).</p></caption><graphic xlink:href="pone.0316555.g001" position="float"/></fig></sec><sec id="sec005"><title>Image analysis</title><p>Edge co-occurrence statistics were computed using the Python code for EOE as described by Redies et al. [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>] (<ext-link xlink:href="https://osf.io/bd8ma/" ext-link-type="uri">https://osf.io/bd8ma/</ext-link>). Briefly, images were filtered using a set of 24 oriented odd-phase Gabor filters representing one full rotation, akin to receptive fields in the human visual system [<xref rid="pone.0316555.ref035" ref-type="bibr">35</xref>,<xref rid="pone.0316555.ref036" ref-type="bibr">36</xref>], so the filters would respond maximally to edges in an image. Pixels with the highest 10,000 edge responses in the image were included in the EOE computation. The orientation of the maximum filter response at each pixel defined the edge orientation at that pixel. Orientation values were distributed into 24 bins, and 1st-order EOE was calculated from the resulting orientation histogram using Shannon entropy. Low 1st-order EOE indicates that particular orientations dominate in an image, and high values indicate that orientations are represented more equally. Second-order EOE was calculated by a pairwise comparison of all oriented edges. Orientation differences and pixel separations were binned, and 2nd-order EOE was calculated from the orientation-difference histogram at each distance bin using Shannon entropy. A summary entropy value was calculated from the average EOE for edge pairs separated by 20&#x02013;240 pixels (see [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>], for further details). Low 2nd-order EOE indicates that edge orientations at a given position can predict the orientations at other positions, whereas high values indicate that all orientation differences are equally likely to occur and edge orientations at one location are less predictive of other edge orientations at other locations (e.g., few parallel edges).</p><p>Additional image statistics (spectral slope, entropy, fractal dimension, horizontal symmetry, vertical symmetry, edge density, Pyramid Histogram of Oriented Gradients (PHOG) self-similarity, PHOG complexity, and lacunarity; see <xref rid="pone.0316555.s001" ref-type="supplementary-material">S1 Table</xref>, for definitions) were calculated on the greyscale image matrices. Image analyses were conducted using bespoke in-house algorithms [<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0316555.ref037" ref-type="bibr">37</xref>,<xref rid="pone.0316555.ref038" ref-type="bibr">38</xref>], built-in MATLAB functions [<xref rid="pone.0316555.ref039" ref-type="bibr">39</xref>], and openly available algorithms [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>,<xref rid="pone.0316555.ref040" ref-type="bibr">40</xref>,<xref rid="pone.0316555.ref041" ref-type="bibr">41</xref>]. Our code for image and data analysis, and the links to any open access code made available by others will be available from the corresponding author on reasonable request.</p></sec><sec id="sec006"><title>Design and procedure</title><p>Each participant saw a random selection of 50 pairs of images. These were sampled from a total of 650 pairs which were created by each of the 26 stimuli being paired with every other stimulus twice with each stimulus in the pair appearing once on the left and once on the right. Infants and adults attended the experiment in-person, in a dimly-lit laboratory room, and were seated 50&#x02009;cm from the display, at eye-level. Infants were seated in a car seat mounted on a chair. Infants watched a cartoon on the display during camera set up, and then completed a 4-point spatial calibration. Following this, each infant viewed 50 trials of randomly selected pairs of images (e.g., see <xref rid="pone.0316555.g001" ref-type="fig">Fig 1B</xref>), displayed for 5s each, with each infant viewing a different random selection of image pairs. Between each trial, an attention-getting stimulus was displayed, composed of a black and white, rotating, geometric pattern which looms and shrinks, lasting until the infant fixated it, to ensure the infants&#x02019; attention was centrally located at the start of a trial. For adult participants, the design was identical to that of the infants except that adults were asked to look freely at the images and to look centrally at the inter-trial attention getter to proceed to the next trial.</p><p>The eye-movement data was analysed using the DataViewer software (SR Research Ltd) to extract the time spent looking at the left or right area of interest which bounded each image. Looking time was measured as the total dwell time of all fixations in the area of interest, excluding the time spent making saccades. Fixations are determined as the periods between saccade offsets and onsets, detected using a velocity threshold of 40&#x02009;degrees per second and an acceleration threshold of 8000&#x02009;degrees per second squared. The looking time was then averaged across all presentations of each stimulus. The average number of fixations to each stimulus was also computed, although a preliminary analysis identified that average looking time and number of fixations across stimuli were highly correlated for infants (<italic toggle="yes">r</italic> =&#x02009; 0.96, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001) and for adults (<italic toggle="yes">r</italic> =&#x02009;.87, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001), therefore only looking time was selected for further analysis.</p></sec><sec id="sec007"><title>Adult aesthetic ratings from Grebenkina et al. (2018)</title><p>Adults&#x02019; aesthetic judgements of the building fa&#x000e7;ades from [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>] were analyzed in the current study. Grebenkina et al.&#x02019;s data was from 27 participants (<italic toggle="yes">M</italic> =&#x02009; 26.4, 14 male) who were asked to rate each building fa&#x000e7;ade separately on three rating terms: interesting, pleasantness, and harmonious. We select the pleasantness measure for the current study because it is representative of the fundamental hedonic value of aesthetic evaluations [<xref rid="pone.0316555.ref042" ref-type="bibr">42</xref>], and found it correlated highly with the interest dimension in Grebenkina et al.</p></sec></sec><sec sec-type="results" id="sec008"><title>Results</title><sec id="sec009"><title>Relationship of infant and adult looking times</title><p>For both infants and adults, the average looking time at each building fa&#x000e7;ade was calculated (dwell time, excluding saccades &#x02013; see Method), averaging across all presentations of that fa&#x000e7;ade on left and right sides. This average looking time measure was then averaged across infants or adults for each fa&#x000e7;ade. Infant and adult looking time across the fa&#x000e7;ades were strongly related: infants looked longer at the building fa&#x000e7;ades which adults looked longer at, <italic toggle="yes">r</italic><sub><italic toggle="yes">s</italic></sub> =&#x02009; 0.734, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 492 (see <xref rid="pone.0316555.g002" ref-type="fig">Fig 2A</xref>).</p><fig position="float" id="pone.0316555.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0316555.g002</object-id><label>Fig 2</label><caption><title>Scatterplots of the relationships with infant looking time.</title><p>The relationships with infant looking time (averaged across participants) and other variables, across the 26 building fa&#x000e7;ades. Thumbnail images have been centred on the red data points to give insight into the visual characteristics underlying the relationships. (A) The relationship between infant and adult looking time (averaged across participants). (B) The relationship between infant looking time and adult pleasantness ratings (averaged across participants). (C) The relationship between infant looking time and 1st-order edge orientation entropy. (D) The relationship between infant looking time and 2nd-order edge orientation entropy.</p></caption><graphic xlink:href="pone.0316555.g002" position="float"/></fig></sec><sec id="sec010"><title>Relationship of infant looking time and adult pleasantness ratings</title><p>Adults&#x02019; pleasantness ratings from Grebenkina et al. [<xref rid="pone.0316555.ref018" ref-type="bibr">18</xref>] were converted to a scale ranging from 0 to 1. Infant looking time and adult pleasantness scores across the fa&#x000e7;ades had a strong relationship, where infants looked longer at fa&#x000e7;ades which adults rated as more pleasant, <italic toggle="yes">r</italic> =&#x02009; 0.783, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 9438 (see <xref rid="pone.0316555.g002" ref-type="fig">Fig 2B</xref>).</p></sec><sec id="sec011"><title>Relationship of EOE with looking time and pleasantness ratings</title><p>Infant looking time and 1st-order and 2nd-order EOE were strongly related: infants looked longer at fa&#x000e7;ades with higher EOE, 1st-order: <italic toggle="yes">r</italic><sub><italic toggle="yes">s</italic></sub> =&#x02009; 0.854, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 12991; and 2nd-order: <italic toggle="yes">r</italic><sub><italic toggle="yes">s</italic></sub> =&#x02009; 0.802, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 1966 (see <xref rid="pone.0316555.g002" ref-type="fig">Fig 2C</xref> and <xref rid="pone.0316555.g002" ref-type="fig">2D</xref>). Adult looking time and 1st-order and 2nd-order EOE revealed a strong relationship where adults looked longer at fa&#x000e7;ades with higher EOE, 1st-order: <italic toggle="yes">r</italic> =&#x02009; 0.610, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 44; and 2nd-order: <italic toggle="yes">r</italic> =&#x02009; 0.558, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 16. Adult pleasantness and 1st-order and 2nd-order EOE also revealed a strong relationship, 1st-order: <italic toggle="yes">r</italic> =&#x02009; 0.651, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 114; and 2nd-order: <italic toggle="yes">r</italic> =&#x02009; 0.617, <italic toggle="yes">n</italic> =&#x02009; 26, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, BF<sub>10</sub> =&#x02009; 51.</p></sec><sec id="sec012"><title>Comparison of EOE correlations with infant and adult measures</title><p>To establish whether infant looking times correlated more strongly with EOE than adult looking times, we computed confidence intervals for the correlation coefficients and their differences using bootstrap methods (as described in [<xref rid="pone.0316555.ref043" ref-type="bibr">43</xref>]). Participants were sampled independently with replacement from each group (infants and adults, preserving the dependency among dyads of observations) to create bootstrap samples. We then computed the two correlation coefficients based on the bootstrap samples, calculated and recorded the difference between the correlations, and repeated this 10,000 times. We then used the distribution of bootstrap differences to derive a confidence interval. The difference between the strength of the correlations with EOE for infants&#x02019; and adults&#x02019; looking time is significant for 1st-order EOE (difference: 0.29 [CI =&#x02009; 0.046, 0.562], <italic toggle="yes">p</italic> =&#x02009;.009), and 2nd-order EOE (difference: 0.28 [CI 0.006, 0.578], <italic toggle="yes">p</italic> =&#x02009;.044). First-order EOE also correlated significantly more strongly with infant looking time than adult pleasantness rating (difference: 0.17 [CI 0.028, 0.373], <italic toggle="yes">p</italic> =&#x02009;.016); however, there was no effect for 2nd-order EOE(difference: 0.14 [CI &#x02212;0.032, 0.342], <italic toggle="yes">p</italic> =&#x02009;.108).</p></sec><sec id="sec013"><title>Commonality analysis</title><p>Commonality analysis (CA) was conducted to examine the shared variance among adult pleasantness ratings, EOE, and infant looking time. CA decomposes the total variance explained by predictors into unique and shared components by conducting a full regression model and comparing it with partial models for each predictor [<xref rid="pone.0316555.ref044" ref-type="bibr">44</xref>]. The unique contribution of each predictor is calculated by subtracting the unique variance explained by the other predictor from the total variance explained by the full model, while the common contribution, or shared variance, is calculated by subtracting the unique contributions of each predictor from the total variance explained by the full model. First and 2nd-order EOE were analysed separately.</p><p>An overall multiple regression model indicated that 73.4% of the variance in infant looking time can be explained by the combined influence of 1st-order EOE and adult pleasantness ratings (<italic toggle="yes">F</italic>(2,23)&#x02009;=&#x02009;35.49, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, <italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup><sub>adj</sub> =&#x02009;.734, BF =&#x02009; 1351656). Adult pleasantness ratings uniquely explained 12.2% of the variance, 1st-order EOE uniquely explained 14.2% of the variance, and the shared variance among all three variables was 49.2%.</p><p>Similarly, 69.2% of the variance in infant looking time was explained by the combined influence of 2nd-order EOE and adult pleasantness ratings (<italic toggle="yes">F</italic>(2,23) =&#x02009; 29.079, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, <italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup><sub>adj</sub> =&#x02009;.692, BF =&#x02009; 29029). Adult pleasantness ratings uniquely explained 17.5% of the variance, 2nd-order EOE uniquely explained 10.3% of the variance, and the shared variance among all three variables was 43.9%.</p></sec><sec id="sec014"><title>Contribution of other image statistics to infant looking time</title><p>To investigate whether the relationship between infant looking and EOE could be explained by other image statistics that correlate with EOE, we also conducted multiple regression analyses with a range of additional image statistics as predictors: spectral slope, entropy, fractal dimension, horizontal symmetry, vertical symmetry, edge density, PHOG self-similarity, PHOG complexity, and lacunarity (see <xref rid="pone.0316555.s001" ref-type="supplementary-material">S1 Table</xref> for definitions). We conducted the regressions on 1st-order and 2nd-order EOE separately as these two variables are highly correlated (<italic toggle="yes">r</italic> =&#x02009;.972, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001). Variables were first screened for normality, linearity, and homoscedasticity, then converted into z-scores; then for variable selection, we used a backward elimination model, where simultaneously entered predictors are removed sequentially if the <italic toggle="yes">p</italic>-value of the regression coefficient is &#x0003e;&#x02009; 0.1 [<xref rid="pone.0316555.ref045" ref-type="bibr">45</xref>]. To assess the individual importance of predictors, we also calculated variance inflation factors (VIFs) to measure how much of the variance of an estimated regression coefficient is increased because of collinearity [<xref rid="pone.0316555.ref046" ref-type="bibr">46</xref>]. We removed predictors with high VIFs, which shared variance with the strongest predictor, until all VIFs were &#x0003c;&#x02009; 1.25 (i.e., &#x0003c;&#x02009; 20% variance explained by other predictors, and indicative of no multicollinearity issues [<xref rid="pone.0316555.ref046" ref-type="bibr">46</xref>,<xref rid="pone.0316555.ref047" ref-type="bibr">47</xref>] (see [<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>] for additional description).</p><p>A backward multiple linear regression with 1st-order EOE and the additional image statistics significantly predicted infant looking time, <italic toggle="yes">F</italic>(2, 23) =&#x02009; 31.451, <italic toggle="yes">p</italic> &#x0003c;&#x02009; 0.001, adj. <italic toggle="yes">R</italic><sup>2</sup> =&#x02009;.71, BF<sub>10</sub> =&#x02009; 52588. Two variables added to the model: 1st-order EOE (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.666, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001), and edge density (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.340, <italic toggle="yes">p</italic> =&#x02009;.008), with 1st-order EOE being the most significant predictor. We repeated this analysis for 2nd-order EOE and the additional statistics finding that the model significantly predicted infant looking time, <italic toggle="yes">F</italic>(3, 22) =&#x02009; 18.630, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001, adj. <italic toggle="yes">R</italic><sup>2</sup> =&#x02009;.68, BF<sub>10</sub> =&#x02009; 6585. Three variables added to the model: 2nd-order EOE (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.572, <italic toggle="yes">p</italic> &#x0003c;&#x02009;.001), edge density (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.333, <italic toggle="yes">p</italic> =&#x02009;.014), and horizontal symmetry (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.224, <italic toggle="yes">p</italic> =&#x02009;.074), with 2nd-order EOE being the most significant predictor.</p><p>Equivalent backward linear regression analyses on adult pleasantness ratings were conducted with 1st-order and 2nd-order EOE. The model with 1st-order EOE significantly predicted adult pleasantness scores, <italic toggle="yes">F</italic>(2, 23) =&#x02009; 16.133, <italic toggle="yes">p</italic> &#x0003c;&#x02009; 0.001, adj. <italic toggle="yes">R</italic><sup>2</sup> =&#x02009;.55, BF<sub>10</sub> =&#x02009; 562. Two predictors added significantly to the model: 1<sup>st</sup>-order EOE as the strongest predictor (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.487, <italic toggle="yes">p</italic> =&#x02009;.003) and edge density (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.432, <italic toggle="yes">p</italic> =&#x02009;.007). The 2nd-order EOE model also significantly predicted adult pleasantness score, <italic toggle="yes">F</italic>(2, 23) =&#x02009; 14.99, <italic toggle="yes">p</italic> &#x0003c;&#x02009; 0.001, adj. <italic toggle="yes">R</italic><sup>2</sup> =&#x02009;.53, BF<sub>10</sub> =&#x02009; 369, with two equivalently strong predictors: 2nd-order EOE (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.458, <italic toggle="yes">p</italic> =&#x02009;.005) and edge density (<italic toggle="yes">&#x003b2;</italic> =&#x02009; 0.459, <italic toggle="yes">p</italic> =&#x02009;.005).</p></sec></sec><sec sec-type="conclusions" id="sec015"><title>Discussion</title><p>The current study aimed to investigate whether infants and adults look longer at building fa&#x000e7;ades that adults find more pleasant, and to identify whether there was a contribution of edge co-occurrence statistics to infants&#x02019; and adults&#x02019; responses. We found that infants and adults looked longer at the building fa&#x000e7;ades which adults rated as more pleasant. We also found that EOE explained a large amount of the variance in how long infants and adults looked at, and how pleasant adults found, certain fa&#x000e7;ades. Commonality Analysis identified that there was a large percentage of shared variance among infant looking time, adult pleasantness ratings, and EOE (almost half of the variance was shared between the three variables). Multiple regression analyses that included several other spatial image statistics that draw on image features, such as the spatial frequency, contrast, and symmetry of the images, established that EOE predicted the most variance in infant and adult responses compared to these other image properties investigated.</p><p>The finding that infants look longer at the building fa&#x000e7;ades the more pleasant adults find them extends prior research which has also found associations of infant looking and adult aesthetic judgements for other types of stimuli [<xref rid="pone.0316555.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0316555.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0316555.ref007" ref-type="bibr">7</xref>]. One interpretation of these associations is that the visual system has sensory biases that partially govern both infant looking and adult aesthetic judgement. In support of the argument that infants and adults are similar in their response to EOE, we find a large amount of shared variance between infant looking, adult pleasantness ratings, and EOE. This could potentially provide support for the theory that early sensory biases provide the basis for aesthetic responses to form later in development. In the current study, both infant and adult looking and adult pleasantness judgments are biased to high EOE. This bias for high EOE stimuli could also be related to complexity since EOE relates to the amount of variety in the stimulus, which is a type of complexity, and stimuli generally appear more complex the higher the EOE. Although the nature of the relationship between complexity and aesthetics appears to vary according to the type of complexity investigated (e.g., number or variety of elements, organization, or symmetry [<xref rid="pone.0316555.ref048" ref-type="bibr">48</xref>]), the relationship between EOE and adult pleasantness ratings is consistent with prior research which finds that beauty increases with the variety of elements (see [<xref rid="pone.0316555.ref048" ref-type="bibr">48</xref>]). The findings of the current study potentially provide support for a Neuroaesthetic theory which proposes that images which mirror the statistical structure of natural scenes (such as images with high EOE [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>]) are more preferred aesthetically because the human visual system is adapted to process these statistics efficiently through phylogeny and/or ontogeny [<xref rid="pone.0316555.ref049" ref-type="bibr">49</xref>&#x02013;<xref rid="pone.0316555.ref052" ref-type="bibr">52</xref>]. The neural representation of edge co-occurrence statistics in natural scenes is thought to be a sparse one which reduces redundancy, allowing better edge detection, maximising neural resources and minimising metabolic costs ([<xref rid="pone.0316555.ref035" ref-type="bibr">35</xref>,<xref rid="pone.0316555.ref052" ref-type="bibr">52</xref>&#x02013;<xref rid="pone.0316555.ref056" ref-type="bibr">56</xref>], cf. [<xref rid="pone.0316555.ref057" ref-type="bibr">57</xref>]). This efficient coding has been theorised to contribute to adult aesthetic preference, and it has been proposed that stimuli which reflect the statistical regularities of natural scenes are more efficiently processed, which in turn, increases their aesthetic value [<xref rid="pone.0316555.ref058" ref-type="bibr">58</xref>,<xref rid="pone.0316555.ref059" ref-type="bibr">59</xref>]. For example, people tend to prefer some stimuli with a spectral slope and fractal dimension characteristic of natural scenes [<xref rid="pone.0316555.ref060" ref-type="bibr">60</xref>,<xref rid="pone.0316555.ref061" ref-type="bibr">61</xref>]. One possibility is that preference for high EOE is due to certain real-world stimuli such as landscapes, clouds, and trees typically having high 1st-order and 2nd-order EOE, and faces having high 1st-order and moderately high 2nd-order EOE [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>]. Adaptation to particular natural scenes with high EOE, such as those containing faces, could reduce sensitivity to high EOE, making images with high EOE more comfortable to view and therefore more liked [<xref rid="pone.0316555.ref049" ref-type="bibr">49</xref>]. Further research is needed to test this &#x02018;adaptation&#x02019; hypothesis. Viewed through this framework, the relationships between EOE and adults&#x02019; pleasantness judgements do not suggest that aesthetic value is in the stimulus, but rather it arises from how efficiently that stimulus is processed by our visual systems as a result of adaptation to natural scenes.</p><p>The current study also extends the limited research on infant perception of natural scene statistics. First and 2nd-order EOE explained more of the variance in infants&#x02019; looking than adults&#x02019; looking. This might be expected given infants&#x02019; greater reliance on bottom-up processing of scenes [<xref rid="pone.0316555.ref062" ref-type="bibr">62</xref>]. It seems plausible that infants would pay relatively more attention to low-level visual properties of scenes than adults due to less experience, conceptualisation, and memory of certain spaces. The fa&#x000e7;ades are likely to be perceived more abstractly by infants, resulting in a more sensory response, whereas adults are likely to have a greater influence of cognitive factors such as memories and associations triggered by the fa&#x000e7;ades. That infants have a bias to certain edge co-occurrence statistics reveals the capabilities of the infant visual system. The Goldilocks model of infant attention proposes that infants allocate attention to stimuli with a level of complexity that is &#x0201c;just right&#x0201d; for their ability [<xref rid="pone.0316555.ref063" ref-type="bibr">63</xref>]. Although infants have relatively immature visual systems in many ways, our finding that infants look longest at the images with the highest EOE, identifies that infants&#x02019; visual systems can manage this level of complexity. This could be considered when designing for infants so that design (e.g., book illustration) is optimized and &#x0201c;just right&#x0201d; for infants&#x02019; visual abilities [<xref rid="pone.0316555.ref064" ref-type="bibr">64</xref>].</p><p>The neural basis of EOE is thought to be in orientation-selective cells in the visual cortex and their long-range horizontal and feedback connections [<xref rid="pone.0316555.ref065" ref-type="bibr">65</xref>&#x02013;<xref rid="pone.0316555.ref067" ref-type="bibr">67</xref>], and such neural circuits are thought to be present by at least 4-months [<xref rid="pone.0316555.ref068" ref-type="bibr">68</xref>&#x02013;<xref rid="pone.0316555.ref070" ref-type="bibr">70</xref>]. Therefore, our finding that infant visual preferences are associated with EOE is consistent with this neural basis. A sensory bias for stimuli with high EOE in infancy could be functional as it would draw infants&#x02019; attention to elements of natural scenes with relatively high 1st or 2nd-order EOE that are evolutionarily important, such as faces [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>]. EOE is also useful for adult categorization of scenes [<xref rid="pone.0316555.ref023" ref-type="bibr">23</xref>] and contributes to other perceptual processes in adults, such as object occlusion [<xref rid="pone.0316555.ref022" ref-type="bibr">22</xref>]. Therefore, now that the current study has established that infants&#x02019; response is associated with EOE, further research can investigate whether a sensitivity to EOE is functional for infants&#x02019; perception and categorization of objects and scenes [<xref rid="pone.0316555.ref023" ref-type="bibr">23</xref>,<xref rid="pone.0316555.ref071" ref-type="bibr">71</xref>,<xref rid="pone.0316555.ref072" ref-type="bibr">72</xref>].</p><p>Another question for further research is the extent to which infants&#x02019; sensory bias for high EOE building fa&#x000e7;ades is associated with their &#x02018;visual diet&#x02019;. We consider it unlikely that the infants&#x02019; sensory bias for high EOE building fa&#x000e7;ades is due to how novel or familiar certain architectural styles are to them. For example, the infant participants lived in a city with a mix of architectural styles; it is unclear the extent to which young infants attend to building fa&#x000e7;ades in their daily life; and we have no evidence that the infant participants associated the stimuli with buildings rather than viewing them as abstract patterns. Another possibility is that the sensory bias for high EOE building fa&#x000e7;ades is due to greater novelty or familiarity of high EOE stimuli in general, or greater attention to certain stimuli with high EOE (such as faces) [<xref rid="pone.0316555.ref024" ref-type="bibr">24</xref>]. The infant participants will have been exposed to a range of natural and carpentered scenes which vary in their EOE, before taking part in the experiment, and although we do know that faces are dominant in infants&#x02019; &#x02018;visual diet&#x02019; [<xref rid="pone.0316555.ref073" ref-type="bibr">73</xref>], it is currently unknown whether high EOE would be more familiar or novel than low EOE stimuli to the infants. However, further research which quantifies the EOE of infants&#x02019; &#x02018;visual diet&#x02019; with head-mounted cameras [<xref rid="pone.0316555.ref074" ref-type="bibr">74</xref>], which does this for infants living in different environments, and which then measures those infants&#x02019; sensory biases for images with a range of EOE, would enable direct investigation of the extent to which infants&#x02019; sensory biases are associated with environmental experience. The current investigation, in identifying infants&#x02019; sensory bias for high EOE building fa&#x000e7;ades, paves the way for further research to address these theoretically interesting questions.</p></sec><sec sec-type="conclusions" id="sec016"><title>Conclusion</title><p>In conclusion, we reveal a striking similarity between infants&#x02019; visual preferences and adults&#x02019; aesthetic judgements: infants look longer at building fa&#x000e7;ades that adults judge to be pleasant. We also identify that edge co-occurrence statistics are associated with how long infants and adults look at building fa&#x000e7;ades, not only how pleasant adults find them. The findings contribute to our understanding of the role of sensory processes in aesthetic judgements. The findings also suggest that, even as young as 4-months of age, infants&#x02019; perception is responsive to the edge co-occurrence statistics that are typical of natural scenes and human faces.</p></sec><sec id="sec017" sec-type="supplementary-material"><title>Supporting information</title><supplementary-material id="pone.0316555.s001" position="float" content-type="local-data"><label>S1 Table</label><caption><title>Additional image statistics definitions and code used.</title><p>(DOCX)</p></caption><media xlink:href="pone.0316555.s001.docx"/></supplementary-material></sec></body><back><ack><p>We thank Christoph Redies and colleagues (Redies et al. 2017) for producing the stimuli and developing the EOE code. The image statistics and image analysis strategy were developed as part of the broader COLOURMIND project for a number of studies, with contributions from Jenny Bosten, Anna Franklin, Alice Skelton, John Maule, and Philip McAdams. We also thank Jenny Bosten and Christoph Redies for very helpful discussion and feedback on an earlier version of the manuscript.</p></ack><ref-list><title>References</title><ref id="pone.0316555.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Kato</surname><given-names>M</given-names></name>, <name><surname>Konishi</surname><given-names>Y</given-names></name>. <article-title>Where and how infants look: the development of scan paths and fixations in face perception</article-title>. <source>Infant Behav Dev</source>. <year>2013</year>;<volume>36</volume>(<issue>1</issue>):<fpage>32</fpage>&#x02013;<lpage>41</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.infbeh.2012.10.005</pub-id>
<pub-id pub-id-type="pmid">23261787</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Bornstein</surname><given-names>MH</given-names></name>, <name><surname>Ferdinandsen</surname><given-names>K</given-names></name>, <name><surname>Gross</surname><given-names>CG</given-names></name>. <article-title>Perception of symmetry in infancy</article-title>. <source>Dev Psychol</source>. <year>1981</year>;<volume>17</volume>(<issue>1</issue>):<fpage>82</fpage>&#x02013;<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037/0012-1649.17.1.82</pub-id></mixed-citation></ref><ref id="pone.0316555.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Bornstein</surname><given-names>MH</given-names></name>. <article-title>Qualities of color vision in infancy</article-title>. <source>J Exp Child Psychol</source>. <year>1975</year>;<volume>19</volume>(<issue>3</issue>):<fpage>401</fpage>&#x02013;<lpage>19</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/0022-0965(75)90070-3</pub-id>
<pub-id pub-id-type="pmid">1176886</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Slater</surname><given-names>A</given-names></name>, <name><surname>Von der Schulenburg</surname><given-names>C</given-names></name>, <name><surname>Brown</surname><given-names>E</given-names></name>, <name><surname>Badenoch</surname><given-names>M</given-names></name>, <name><surname>Butterworth</surname><given-names>G</given-names></name>, <name><surname>Parsons</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Newborn infants prefer attractive faces</article-title>. <source>Infant Behav Dev</source>. <year>1998</year>;<volume>21</volume>(<issue>2</issue>):<fpage>345</fpage>&#x02013;<lpage>54</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s0163-6383(98)90011-x</pub-id></mixed-citation></ref><ref id="pone.0316555.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Skelton</surname><given-names>AE</given-names></name>, <name><surname>Franklin</surname><given-names>A</given-names></name>. <article-title>Infants look longer at colours that adults like when colours are highly saturated</article-title>. <source>Psychon Bull Rev</source>. <year>2020</year>;<volume>27</volume>(<issue>1</issue>):<fpage>78</fpage>&#x02013;<lpage>85</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3758/s13423-019-01688-5</pub-id>
<pub-id pub-id-type="pmid">31848908</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Simion</surname><given-names>F</given-names></name>, <name><surname>Regolin</surname><given-names>L</given-names></name>, <name><surname>Bulf</surname><given-names>H</given-names></name>. <article-title>A predisposition for biological motion in the newborn baby</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2008</year>;<volume>105</volume>(<issue>2</issue>):<fpage>809</fpage>&#x02013;<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.0707021105</pub-id>
<pub-id pub-id-type="pmid">18174333</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>McAdams</surname><given-names>P</given-names></name>, <name><surname>Chambers</surname><given-names>M</given-names></name>, <name><surname>Bosten</surname><given-names>JM</given-names></name>, <name><surname>Skelton</surname><given-names>AE</given-names></name>, <name><surname>Franklin</surname><given-names>A</given-names></name>. <article-title>Chromatic and spatial image statistics predict infants&#x02019; visual preferences and adults&#x02019; aesthetic preferences for art</article-title>. <source>J Vis</source>. <year>2023</year>;<volume>23</volume>(<issue>8</issue>):<fpage>2</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1167/jov.23.8.2</pub-id>
<pub-id pub-id-type="pmid">37526623</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Aslin</surname><given-names>RN</given-names></name>. <article-title>What&#x02019;s in a look?</article-title>. <source>Dev Sci</source>. <year>2007</year>;<volume>10</volume>(<issue>1</issue>):<fpage>48</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/j.1467-7687.2007.00563.x</pub-id>
<pub-id pub-id-type="pmid">17181699</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Bornstein</surname><given-names>MH</given-names></name>, <name><surname>Mash</surname><given-names>C</given-names></name>, <name><surname>Arterberry</surname><given-names>ME</given-names></name>, <name><surname>Gandjbakhche</surname><given-names>A</given-names></name>, <name><surname>Nguyen</surname><given-names>T</given-names></name>, <name><surname>Esposito</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Visual stimulus structure, visual system neural activity, and visual behavior in young human infants</article-title>. <source>PLoS One</source>. <year>2024</year>;<volume>19</volume>(<issue>6</issue>):<fpage>e0302852</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0302852</pub-id>
<pub-id pub-id-type="pmid">38889176</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Chatterjee</surname><given-names>A</given-names></name>, <name><surname>Vartanian</surname><given-names>O</given-names></name>. <article-title>Neuroaesthetics</article-title>. <source>Trends Cogn Sci</source>. <year>2014</year>;<volume>18</volume>(<issue>7</issue>):<fpage>370</fpage>&#x02013;<lpage>5</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.tics.2014.03.003</pub-id>
<pub-id pub-id-type="pmid">24768244</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Chatterjee</surname><given-names>A</given-names></name>, <name><surname>Coburn</surname><given-names>A</given-names></name>, <name><surname>Weinberger</surname><given-names>A</given-names></name>. <article-title>The neuroaesthetics of architectural spaces</article-title>. <source>Cogn Process</source>. <year>2021</year>;<volume>22</volume>(<issue>Suppl 1</issue>):<fpage>115</fpage>&#x02013;<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10339-021-01043-4</pub-id>
<pub-id pub-id-type="pmid">34448969</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Coburn</surname><given-names>A</given-names></name>, <name><surname>Vartanian</surname><given-names>O</given-names></name>, <name><surname>Chatterjee</surname><given-names>A</given-names></name>. <article-title>Buildings, beauty, and the brain: a neuroscience of architectural experience</article-title>. <source>J Cogn Neurosci</source>. <year>2017</year>;<volume>29</volume>(<issue>9</issue>):<fpage>1521</fpage>&#x02013;<lpage>31</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/jocn_a_01146</pub-id>
<pub-id pub-id-type="pmid">28493809</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Vartanian</surname><given-names>O</given-names></name>, <name><surname>Navarrete</surname><given-names>G</given-names></name>, <name><surname>Chatterjee</surname><given-names>A</given-names></name>, <name><surname>Fich</surname><given-names>LB</given-names></name>, <name><surname>Leder</surname><given-names>H</given-names></name>, <name><surname>Modro&#x000f1;o</surname><given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Impact of contour on aesthetic judgments and approach-avoidance decisions in architecture</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2013</year>;<volume>110</volume> (<issue>Suppl 2</issue>):<fpage>10446</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.1301227110</pub-id>
<pub-id pub-id-type="pmid">23754408</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Coburn</surname><given-names>A</given-names></name>, <name><surname>Kardan</surname><given-names>O</given-names></name>, <name><surname>Kotabe</surname><given-names>H</given-names></name>, <name><surname>Steinberg</surname><given-names>J</given-names></name>, <name><surname>Hout</surname><given-names>MC</given-names></name>, <name><surname>Robbins</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Psychological responses to natural patterns in architecture</article-title>. <source>J Environl Psychol</source>. <year>2019</year>;<volume>62</volume><fpage>133</fpage>&#x02013;<lpage>45</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jenvp.2019.02.007</pub-id></mixed-citation></ref><ref id="pone.0316555.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>JH</given-names></name>, <name><surname>Ostwald</surname><given-names>MJ</given-names></name>. <article-title>The &#x02018;visual attractiveness&#x02019; of architectural facades: measuring visual complexity and attractive strength in architecture</article-title>. <source>Archit Sci Rev</source>. <year>2022</year>;<volume>66</volume>(<issue>1</issue>):<fpage>42</fpage>&#x02013;<lpage>52</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/00038628.2022.2137458</pub-id></mixed-citation></ref><ref id="pone.0316555.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Taylor</surname><given-names>RP</given-names></name>. <article-title>Reduction of physiological stress using fractal art and architecture</article-title>. <source>Leonardo</source>. <year>2006</year>;<volume>39</volume>(<issue>3</issue>):<fpage>245</fpage>&#x02013;<lpage>51</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/leon.2006.39.3.245</pub-id></mixed-citation></ref><ref id="pone.0316555.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Penacchio</surname><given-names>O</given-names></name>, <name><surname>Wilkins</surname><given-names>AJ</given-names></name>. <article-title>Visual discomfort and the spatial distribution of Fourier energy</article-title>. <source>Vision Res</source>. <year>2015</year>;<volume>108</volume><fpage>1</fpage>&#x02013;<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.visres.2014.12.013</pub-id>
<pub-id pub-id-type="pmid">25576380</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Grebenkina</surname><given-names>M</given-names></name>, <name><surname>Brachmann</surname><given-names>A</given-names></name>, <name><surname>Bertamini</surname><given-names>M</given-names></name>, <name><surname>Kaduhm</surname><given-names>A</given-names></name>, <name><surname>Redies</surname><given-names>C</given-names></name>. <article-title>Edge-Orientation Entropy Predicts Preference for Diverse Types of Man-Made Images</article-title>. <source>Front Neurosci</source>. <year>2018</year>;<volume>12</volume>:<fpage>678</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fnins.2018.00678</pub-id>
<pub-id pub-id-type="pmid">30323736</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Marr</surname><given-names>D</given-names></name>, <name><surname>Hildreth</surname><given-names>E</given-names></name>. <article-title>Theory of edge detection</article-title>. <source>Proc R Soc Lond B Biol Sci</source>. <year>1980</year>;<volume>207</volume>(<issue>1167</issue>):<fpage>187</fpage>&#x02013;<lpage>217</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1098/rspb.1980.0020</pub-id>
<pub-id pub-id-type="pmid">6102765</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Geisler</surname><given-names>WS</given-names></name>, <name><surname>Perry</surname><given-names>JS</given-names></name>, <name><surname>Super</surname><given-names>BJ</given-names></name>, <name><surname>Gallogly</surname><given-names>DP</given-names></name>. <article-title>Edge co-occurrence in natural images predicts contour grouping performance</article-title>. <source>Vision Res</source>. <year>2001</year>;<volume>41</volume>(<issue>6</issue>):<fpage>711</fpage>&#x02013;<lpage>24</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s0042-6989(00)00277-7</pub-id>
<pub-id pub-id-type="pmid">11248261</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Sigman</surname><given-names>M</given-names></name>, <name><surname>Cecchi</surname><given-names>GA</given-names></name>, <name><surname>Gilbert</surname><given-names>CD</given-names></name>, <name><surname>Magnasco</surname><given-names>MO</given-names></name>. <article-title>On a common circle: natural scenes and Gestalt rules</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2001</year>;<volume>98</volume>(<issue>4</issue>):<fpage>1935</fpage>&#x02013;<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.98.4.1935</pub-id>
<pub-id pub-id-type="pmid">11172054</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Geisler</surname><given-names>WS</given-names></name>, <name><surname>Perry</surname><given-names>JS</given-names></name>. <article-title>Contour statistics in natural images: grouping across occlusions</article-title>. <source>Vis Neurosci</source>. <year>2009</year>;<volume>26</volume>(<issue>1</issue>):<fpage>109</fpage>&#x02013;<lpage>21</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1017/S0952523808080875</pub-id>
<pub-id pub-id-type="pmid">19216819</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Perrinet</surname><given-names>LU</given-names></name>, <name><surname>Bednar</surname><given-names>JA</given-names></name>. <article-title>Edge co-occurrences can account for rapid categorization of natural versus animal images</article-title>. <source>Sci Rep</source>. <year>2015</year>;<volume>5</volume>:<fpage>11400</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/srep11400</pub-id>
<pub-id pub-id-type="pmid">26096913</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Redies</surname><given-names>C</given-names></name>, <name><surname>Brachmann</surname><given-names>A</given-names></name>, <name><surname>Wagemans</surname><given-names>J</given-names></name>. <article-title>High entropy of edge orientations characterizes visual artworks from diverse cultural backgrounds</article-title>. <source>Vision Res</source>. <year>2017</year>;<volume>133</volume>:<fpage>130</fpage>&#x02013;<lpage>44</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.visres.2017.02.004</pub-id>
<pub-id pub-id-type="pmid">28279713</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Stanischewski</surname><given-names>S</given-names></name>, <name><surname>Altmann</surname><given-names>CS</given-names></name>, <name><surname>Brachmann</surname><given-names>A</given-names></name>, <name><surname>Redies</surname><given-names>C</given-names></name>. <article-title>Aesthetic perception of line patterns: effect of edge-orientation entropy and curvilinear shape</article-title>. <source>Iperception</source>. <year>2020</year>;<volume>11</volume>(<issue>5</issue>):<fpage>2041669520950749</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/2041669520950749</pub-id>
<pub-id pub-id-type="pmid">33062240</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Teller</surname><given-names>DY</given-names></name>. <article-title>The forced-choice preferential looking procedure: a psychophysical technique for use with human infants</article-title>. <source>Infant Behav Dev</source>. <year>1979</year>;<volume>2</volume>:<fpage>135</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s0163-6383(79)80016-8</pub-id></mixed-citation></ref><ref id="pone.0316555.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Banks</surname><given-names>MS</given-names></name>, <name><surname>Stephens</surname><given-names>BR</given-names></name>, <name><surname>Hartmann</surname><given-names>EE</given-names></name>. <article-title>The development of basic mechanisms of pattern vision: spatial frequency channels</article-title>. <source>J Exp Child Psychol</source>. <year>1985</year>;<volume>40</volume>(<issue>3</issue>):<fpage>501</fpage>&#x02013;<lpage>27</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/0022-0965(85)90080-3</pub-id>
<pub-id pub-id-type="pmid">4078545</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Oakes</surname><given-names>LM</given-names></name>, <name><surname>Hayes</surname><given-names>TR</given-names></name>, <name><surname>Klotz</surname><given-names>SM</given-names></name>, <name><surname>Pomaranski</surname><given-names>KI</given-names></name>, <name><surname>Henderson</surname><given-names>JM</given-names></name>. <article-title>The role of local meaning in infants&#x02019; fixations of natural scenes</article-title>. <source>Infancy</source>. <year>2024</year>;<volume>29</volume>(<issue>2</issue>):<fpage>284</fpage>&#x02013;<lpage>98</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/infa.12582</pub-id>
<pub-id pub-id-type="pmid">38183667</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>van Renswoude</surname><given-names>DR</given-names></name>, <name><surname>Raijmakers</surname><given-names>MEJ</given-names></name>, <name><surname>Visser</surname><given-names>I</given-names></name>. <article-title>Looking (for) patterns: similarities and differences between infant and adult free scene-viewing patterns</article-title>. <source>J Eye Mov Res</source>. <year>2020</year>;<volume>13</volume>(<issue>1</issue>): <comment>doi: </comment><pub-id pub-id-type="doi">10.16910/jemr.13.1.2</pub-id>
<pub-id pub-id-type="pmid">33828784</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Balas</surname><given-names>B</given-names></name>, <name><surname>Saville</surname><given-names>A</given-names></name>, <name><surname>Schmidt</surname><given-names>J</given-names></name>. <article-title>Neural sensitivity to natural texture statistics in infancy</article-title>. <source>Dev Psychobiol</source>. <year>2018</year>;<volume>60</volume>(<issue>7</issue>):<fpage>765</fpage>&#x02013;<lpage>74</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/dev.21764</pub-id>
<pub-id pub-id-type="pmid">30033613</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Ellemberg</surname><given-names>D</given-names></name>, <name><surname>Hansen</surname><given-names>BC</given-names></name>, <name><surname>Johnson</surname><given-names>A</given-names></name>. <article-title>The developing visual system is not optimally sensitive to the spatial statistics of natural images</article-title>. <source>Vision Res</source>. <year>2012</year>;<volume>67</volume><fpage>1</fpage>&#x02013;<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.visres.2012.06.018</pub-id>
<pub-id pub-id-type="pmid">22766478</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Skelton</surname><given-names>AE</given-names></name>, <name><surname>Franklin</surname><given-names>A</given-names></name>, <name><surname>Bosten</surname><given-names>JM</given-names></name>. <article-title>Colour vision is aligned with natural scene statistics at 4 months of age</article-title>. <source>Dev Sci</source>. <year>2023</year>;<volume>26</volume>(<issue>6</issue>):<fpage>e13402</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/desc.13402</pub-id>
<pub-id pub-id-type="pmid">37138516</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Braun</surname><given-names>J</given-names></name>, <name><surname>Amirshahi</surname><given-names>SA</given-names></name>, <name><surname>Denzler</surname><given-names>J</given-names></name>, <name><surname>Redies</surname><given-names>C</given-names></name>. <article-title>Statistical image properties of print advertisements, visual artworks and images of architecture</article-title>. <source>Front Psychol</source>. <year>2013</year>;<volume>4</volume>:<fpage>808</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00808</pub-id>
<pub-id pub-id-type="pmid">24204353</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref034"><label>34</label><mixed-citation publication-type="journal"><collab>ITU</collab>. <article-title>RECOMMENDATION ITU-R BT</article-title>. <source>601-7 &#x02013; Studio encoding parameters of digital television for standard</source>
<volume>4</volume>:<fpage>3</fpage> and wide-screen 16:9 aspect ratios. <year>2017</year>.</mixed-citation></ref><ref id="pone.0316555.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Olshausen</surname><given-names>BA</given-names></name>, <name><surname>Field</surname><given-names>DJ</given-names></name>. <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source>. <year>1996</year>;<volume>381</volume>(<issue>6583</issue>):<fpage>607</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/381607a0</pub-id>
<pub-id pub-id-type="pmid">8637596</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Jones</surname><given-names>JP</given-names></name>, <name><surname>Palmer</surname><given-names>LA</given-names></name>. <article-title>An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex</article-title>. <source>J Neurophysiol</source>. <year>1987</year>;<volume>58</volume>(<issue>6</issue>):<fpage>1233</fpage>&#x02013;<lpage>58</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1152/jn.1987.58.6.1233</pub-id>
<pub-id pub-id-type="pmid">3437332</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Skelton</surname><given-names>A</given-names></name>, <name><surname>Floyd</surname><given-names>S</given-names></name>, <name><surname>Maule</surname><given-names>J</given-names></name>, <name><surname>Wozniak</surname><given-names>B</given-names></name>, <name><surname>Majid</surname><given-names>A</given-names></name>, <name><surname>Franklin</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Is color discrimination influenced by the chromatic statistics of different visual environments?</article-title>. <source>J Vision</source>. <year>2021</year>;<volume>21</volume>(<issue>9</issue>):<fpage>1945</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1167/jov.21.9.1945</pub-id></mixed-citation></ref><ref id="pone.0316555.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Bosten</surname><given-names>JM</given-names></name>, <name><surname>Beer</surname><given-names>RD</given-names></name>, <name><surname>MacLeod</surname><given-names>DIA</given-names></name>. <article-title>What is white?</article-title>. <source>J Vision</source>. <year>2015</year>;<volume>15</volume>:<fpage>5</fpage>&#x02013;<lpage>5</lpage>.</mixed-citation></ref><ref id="pone.0316555.ref039"><label>39</label><mixed-citation publication-type="other">The MathWorks Inc. MATLAB version (R2021a). Natick, Massachusetts, United States: The MathWorks Inc.; 2021. Available: <ext-link xlink:href="https://www.mathworks.com" ext-link-type="uri">https://www.mathworks.com</ext-link>. Entropy function: <ext-link xlink:href="https://www.mathworks.com/" ext-link-type="uri">https://www.mathworks.com/</ext-link></mixed-citation></ref><ref id="pone.0316555.ref040"><label>40</label><mixed-citation publication-type="other">Mather G. Visual statistics of large samples of Western artworks. 2017.</mixed-citation></ref><ref id="pone.0316555.ref041"><label>41</label><mixed-citation publication-type="book"><name><surname>Redies</surname><given-names>C</given-names></name>, <name><surname>Amirshahi</surname><given-names>SA</given-names></name>, <name><surname>Koch</surname><given-names>M</given-names></name>, <name><surname>Denzler</surname><given-names>J.</given-names></name>
<part-title>PHOG-derived aesthetic measures applied to color photographs of artworks, natural scenes and objects</part-title>. In: <name><surname>Fusiello</surname><given-names>A</given-names></name>, <name><surname>Murino</surname><given-names>V</given-names></name>, <name><surname>Cucchiara</surname><given-names>R</given-names></name>, editors. <source>Computer Vision &#x02013; ECCV 2012 Workshops and Demonstrations</source>. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2012</year>. p. <fpage>522</fpage>&#x02013;<lpage>31</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/978-3-642-33863-2_54</pub-id></mixed-citation></ref><ref id="pone.0316555.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Cupchik</surname><given-names>GC</given-names></name>, <name><surname>Gebotys</surname><given-names>RJ</given-names></name>. <article-title>Interest and Pleasure as Dimensions of Aesthetic Response</article-title>. <source>Emp Stud Arts</source>. <year>1990</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>14</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2190/l789-tppy-bd2q-t7tw</pub-id></mixed-citation></ref><ref id="pone.0316555.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Rousselet</surname><given-names>GA</given-names></name>, <name><surname>Pernet</surname><given-names>CR</given-names></name>, <name><surname>Wilcox</surname><given-names>RR</given-names></name>. <article-title>An introduction to the bootstrap: a versatile method to make inferences by using data-driven simulations</article-title>. <underline><ext-link xlink:href="http://PsyArXiv" ext-link-type="uri">PsyArXiv</ext-link></underline>; <year>2019</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.31234/osf.io/h8ft7</pub-id></mixed-citation></ref><ref id="pone.0316555.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Seibold</surname><given-names>DR</given-names></name>, <name><surname>McPHEE</surname><given-names>RD</given-names></name>. <article-title>commonality analysis: a method for decomposing explained variance in multiple regression analyses</article-title>. <source>Human Comm Res</source>. <year>1979</year>;<volume>5</volume>(<issue>4</issue>):<fpage>355</fpage>&#x02013;<lpage>65</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/j.1468-2958.1979.tb00649.x</pub-id></mixed-citation></ref><ref id="pone.0316555.ref045"><label>45</label><mixed-citation publication-type="journal"><name><surname>Dunkler</surname><given-names>D</given-names></name>, <name><surname>Plischke</surname><given-names>M</given-names></name>, <name><surname>Leffondr&#x000e9;</surname><given-names>K</given-names></name>, <name><surname>Heinze</surname><given-names>G</given-names></name>. <article-title>Augmented backward elimination: a pragmatic and purposeful way to develop statistical models</article-title>. <source>PLoS One</source>. <year>2014</year>;<volume>9</volume>(<issue>11</issue>):<fpage>e113677</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0113677</pub-id>
<pub-id pub-id-type="pmid">25415265</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>J</given-names></name>, <name><surname>Monette</surname><given-names>G</given-names></name>. <article-title>Generalized Collinearity Diagnostics</article-title>. <source>J Am Statl As</source>. <year>1992</year>;<volume>87</volume>(<issue>417</issue>):<fpage>178</fpage>&#x02013;<lpage>83</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/01621459.1992.10475190</pub-id></mixed-citation></ref><ref id="pone.0316555.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Graham</surname><given-names>MH</given-names></name>. <article-title>Confronting multicollinearity in ecological multiple regression</article-title>. <source>Ecology</source>. <year>2003</year>;<volume>84</volume>(<issue>11</issue>):<fpage>2809</fpage>&#x02013;<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1890/02-3114</pub-id></mixed-citation></ref><ref id="pone.0316555.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Nadal</surname><given-names>M</given-names></name>, <name><surname>Munar</surname><given-names>E</given-names></name>, <name><surname>Marty</surname><given-names>G</given-names></name>, <name><surname>Cela-Conde</surname><given-names>CJ</given-names></name>. <article-title>Visual complexity and beauty appreciation: explaining the divergence of results</article-title>. <source>Em Stud Arts</source>. <year>2010</year>;<volume>28</volume>(<issue>2</issue>):<fpage>173</fpage>&#x02013;<lpage>91</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2190/em.28.2.d</pub-id></mixed-citation></ref><ref id="pone.0316555.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Juricevic</surname><given-names>I</given-names></name>, <name><surname>Land</surname><given-names>L</given-names></name>, <name><surname>Wilkins</surname><given-names>A</given-names></name>, <name><surname>Webster</surname><given-names>MA</given-names></name>. <article-title>Visual discomfort and natural image statistics</article-title>. <source>Perception</source>. <year>2010</year>;<volume>39</volume>(<issue>7</issue>):<fpage>884</fpage>&#x02013;<lpage>99</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1068/p6656</pub-id>
<pub-id pub-id-type="pmid">20842966</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>P&#x000e1;rraga</surname><given-names>CA</given-names></name>, <name><surname>Troscianko</surname><given-names>T</given-names></name>, <name><surname>Tolhurst</surname><given-names>DJ</given-names></name>. <article-title>The human visual system is optimised for processing the spatial information in natural visual images</article-title>. <source>Curr Biol</source>. <year>2000</year>;<volume>10</volume>(<issue>1</issue>):<fpage>35</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s0960-9822(99)00262-6</pub-id>
<pub-id pub-id-type="pmid">10660301</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Knill</surname><given-names>DC</given-names></name>, <name><surname>Field</surname><given-names>D</given-names></name>, <name><surname>Kersten</surname><given-names>D</given-names></name>. <article-title>Human discrimination of fractal images</article-title>. <source>J Opt Soc Am A</source>. <year>1990</year>;<volume>7</volume>(<issue>6</issue>):<fpage>1113</fpage>&#x02013;<lpage>23</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1364/josaa.7.001113</pub-id>
<pub-id pub-id-type="pmid">2362228</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Field</surname><given-names>DJ</given-names></name>. <article-title>Relations between the statistics of natural images and the response properties of cortical cells</article-title>. <source>J Opt Soc Am A</source>. <year>1987</year>;<volume>4</volume>(<issue>12</issue>):<fpage>2379</fpage>&#x02013;<lpage>94</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1364/josaa.4.002379</pub-id>
<pub-id pub-id-type="pmid">3430225</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Field</surname><given-names>DJ</given-names></name>. <article-title>What is the goal of sensory coding?</article-title>. <source>Neural Comput</source>. <year>1994</year>;<volume>6</volume>(<issue>4</issue>):<fpage>559</fpage>&#x02013;<lpage>601</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/neco.1994.6.4.559</pub-id></mixed-citation></ref><ref id="pone.0316555.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Hansen</surname><given-names>BC</given-names></name>, <name><surname>Essock</surname><given-names>EA</given-names></name>, <name><surname>Zheng</surname><given-names>Y</given-names></name>, <name><surname>Deford</surname><given-names>JK</given-names></name>. <article-title>Perceptual anisotropies in visual processing and their relation to natural image statistics</article-title>. <source>Network: Com Neural Sys</source>. <year>2003</year>;<volume>14</volume>(<issue>3</issue>):<fpage>501</fpage>&#x02013;<lpage>26</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1088/0954-898x_14_3_307</pub-id></mixed-citation></ref><ref id="pone.0316555.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Hansen</surname><given-names>BC</given-names></name>, <name><surname>Essock</surname><given-names>EA</given-names></name>. <article-title>A horizontal bias in human visual processing of orientation and its correspondence to the structural components of natural scenes</article-title>. <source>J Vis</source>. <year>2004</year>;<volume>4</volume>(<issue>12</issue>):<fpage>1044</fpage>&#x02013;<lpage>60</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1167/4.12.5</pub-id>
<pub-id pub-id-type="pmid">15669910</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref056"><label>56</label><mixed-citation publication-type="book"><name><surname>Wainwright</surname><given-names>M</given-names></name>, <name><surname>Schwartz</surname><given-names>O</given-names></name>, <name><surname>Simoncelli</surname><given-names>E.</given-names></name>
<part-title>Natural image statistics and divisive normalization: Modeling nonlinearity and adaptation in cortical neurons</part-title>. In: <name><surname>Rao</surname><given-names>R</given-names></name>, <name><surname>Olshausen</surname><given-names>B</given-names></name>, <name><surname>Lewicki</surname><given-names>M</given-names></name>, editors. <source>Probabilistic models of the brain</source>. <publisher-name>MIT Press</publisher-name>; <year>2002</year>. pp. <fpage>203</fpage>&#x02013;<lpage>22</lpage>.</mixed-citation></ref><ref id="pone.0316555.ref057"><label>57</label><mixed-citation publication-type="journal"><name><surname>Isherwood</surname><given-names>ZJ</given-names></name>, <name><surname>Schira</surname><given-names>MM</given-names></name>, <name><surname>Spehar</surname><given-names>B</given-names></name>. <article-title>The tuning of human visual cortex to variations in the 1/f&#x003b1; amplitude spectra and fractal properties of synthetic noise images</article-title>. <source>Neuroimage</source>. <year>2017</year>;<volume>146</volume>:<fpage>642</fpage>&#x02013;<lpage>57</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.10.013</pub-id>
<pub-id pub-id-type="pmid">27742601</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Graham</surname><given-names>DJ</given-names></name>, <name><surname>Redies</surname><given-names>C</given-names></name>. <article-title>Statistical regularities in art: Relations with visual coding and perception</article-title>. <source>Vision Res</source>. <year>2010</year>;<volume>50</volume>(<issue>16</issue>):<fpage>1503</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.visres.2010.05.002</pub-id>
<pub-id pub-id-type="pmid">20580643</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref059"><label>59</label><mixed-citation publication-type="journal"><name><surname>Renoult</surname><given-names>JP</given-names></name>, <name><surname>Bovet</surname><given-names>J</given-names></name>, <name><surname>Raymond</surname><given-names>M</given-names></name>. <article-title>Beauty is in the efficient coding of the beholder</article-title>. <source>R Soc Open Sci</source>. <year>2016</year>;<volume>3</volume>(<issue>3</issue>):<fpage>160027</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1098/rsos.160027</pub-id>
<pub-id pub-id-type="pmid">27069668</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref060"><label>60</label><mixed-citation publication-type="journal"><name><surname>Spehar</surname><given-names>B</given-names></name>, <name><surname>Wong</surname><given-names>S</given-names></name>, <name><surname>van de Klundert</surname><given-names>S</given-names></name>, <name><surname>Lui</surname><given-names>J</given-names></name>, <name><surname>Clifford</surname><given-names>CWG</given-names></name>, <name><surname>Taylor</surname><given-names>RP</given-names></name>. <article-title>Beauty and the beholder: the role of visual sensitivity in visual preference</article-title>. <source>Front Hum Neurosci</source>. <year>2015</year>;<volume>9</volume><fpage>514</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fnhum.2015.00514</pub-id>
<pub-id pub-id-type="pmid">26441611</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref061"><label>61</label><mixed-citation publication-type="journal"><name><surname>Spehar</surname><given-names>B</given-names></name>, <name><surname>Clifford</surname><given-names>CWG</given-names></name>, <name><surname>Newell</surname><given-names>BR</given-names></name>, <name><surname>Taylor</surname><given-names>RP</given-names></name>. <article-title>Universal aesthetic of fractals</article-title>. <source>Com Graph</source>. <year>2003</year>;<volume>27</volume>(<issue>5</issue>):<fpage>813</fpage>&#x02013;<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s0097-8493(03)00154-7</pub-id></mixed-citation></ref><ref id="pone.0316555.ref062"><label>62</label><mixed-citation publication-type="journal"><name><surname>van Renswoude</surname><given-names>DR</given-names></name>, <name><surname>Visser</surname><given-names>I</given-names></name>, <name><surname>Raijmakers</surname><given-names>MEJ</given-names></name>, <name><surname>Tsang</surname><given-names>T</given-names></name>, <name><surname>Johnson</surname><given-names>SP</given-names></name>. <article-title>Real-world scene perception in infants: What factors guide attention allocation?</article-title>. <source>Infancy</source>. <year>2019</year>;<volume>24</volume>(<issue>5</issue>):<fpage>693</fpage>&#x02013;<lpage>717</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/infa.12308</pub-id>
<pub-id pub-id-type="pmid">32677279</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref063"><label>63</label><mixed-citation publication-type="journal"><name><surname>Kidd</surname><given-names>C</given-names></name>, <name><surname>Piantadosi</surname><given-names>ST</given-names></name>, <name><surname>Aslin</surname><given-names>RN</given-names></name>. <article-title>The Goldilocks effect: human infants allocate attention to visual sequences that are neither too simple nor too complex</article-title>. <source>PLoS One</source>. <year>2012</year>;<volume>7</volume>(<issue>5</issue>):<fpage>e36399</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0036399</pub-id>
<pub-id pub-id-type="pmid">22649492</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref064"><label>64</label><mixed-citation publication-type="journal"><name><surname>Wass</surname><given-names>SV</given-names></name>, <name><surname>Smith</surname><given-names>TJ</given-names></name>. <article-title>Visual motherese? signal-to-noise ratios in toddler-directed television</article-title>. <source>Dev Sci</source>. <year>2015</year>;<volume>18</volume>(<issue>1</issue>):<fpage>24</fpage>&#x02013;<lpage>37</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/desc.12156</pub-id>
<pub-id pub-id-type="pmid">24702791</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref065"><label>65</label><mixed-citation publication-type="journal"><name><surname>Sanguinetti</surname><given-names>G</given-names></name>, <name><surname>Citti</surname><given-names>G</given-names></name>, <name><surname>Sarti</surname><given-names>A</given-names></name>. <article-title>A model of natural image edge co-occurrence in the rototranslation group</article-title>. <source>J Vis</source>. <year>2010</year>;<volume>10</volume>(<issue>14</issue>):<fpage>37</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1167/10.14.37</pub-id>
<pub-id pub-id-type="pmid">21196513</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref066"><label>66</label><mixed-citation publication-type="journal"><name><surname>Spillmann</surname><given-names>L</given-names></name>, <name><surname>Dresp-Langley</surname><given-names>B</given-names></name>, <name><surname>Tseng</surname><given-names>C-H</given-names></name>. <article-title>Beyond the classical receptive field: the effect of contextual stimuli</article-title>. <source>J Vis</source>. <year>2015</year>;<volume>15</volume>(<issue>9</issue>):<fpage>7</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1167/15.9.7</pub-id>
<pub-id pub-id-type="pmid">26200888</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref067"><label>67</label><mixed-citation publication-type="journal"><name><surname>Hunt</surname><given-names>JJ</given-names></name>, <name><surname>Bosking</surname><given-names>WH</given-names></name>, <name><surname>Goodhill</surname><given-names>GJ</given-names></name>. <article-title>Statistical structure of lateral connections in the primary visual cortex</article-title>. <source>Neural Syst Circuits</source>. <year>2011</year>;<volume>1</volume>(<issue>1</issue>):<fpage>3</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/2042-1001-1-3</pub-id>
<pub-id pub-id-type="pmid">22330062</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref068"><label>68</label><mixed-citation publication-type="journal"><name><surname>Burkhalter</surname><given-names>A</given-names></name>. <article-title>Development of forward and feedback connections between areas V1 and V2 of human visual cortex</article-title>. <source>Cereb Cortex</source>. <year>1993</year>;<volume>3</volume>(<issue>5</issue>):<fpage>476</fpage>&#x02013;<lpage>87</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/cercor/3.5.476</pub-id>
<pub-id pub-id-type="pmid">8260814</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref069"><label>69</label><mixed-citation publication-type="journal"><name><surname>Burkhalter</surname><given-names>A</given-names></name>, <name><surname>Bernardo</surname><given-names>KL</given-names></name>, <name><surname>Charles</surname><given-names>V</given-names></name>. <article-title>Development of local circuits in human visual cortex</article-title>. <source>J Neurosci</source>. <year>1993</year>;<volume>13</volume>(<issue>5</issue>):<fpage>1916</fpage>&#x02013;<lpage>31</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-05-01916.1993</pub-id>
<pub-id pub-id-type="pmid">8478684</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref070"><label>70</label><mixed-citation publication-type="journal"><name><surname>Braddick</surname><given-names>O</given-names></name>, <name><surname>Atkinson</surname><given-names>J</given-names></name>. <article-title>Development of human visual function</article-title>. <source>Vision Res</source>. <year>2011</year>;<volume>51</volume>(<issue>13</issue>):<fpage>1588</fpage>&#x02013;<lpage>609</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.visres.2011.02.018</pub-id>
<pub-id pub-id-type="pmid">21356229</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref071"><label>71</label><mixed-citation publication-type="journal"><name><surname>Xie</surname><given-names>S</given-names></name>, <name><surname>Hoehl</surname><given-names>S</given-names></name>, <name><surname>Moeskops</surname><given-names>M</given-names></name>, <name><surname>Kayhan</surname><given-names>E</given-names></name>, <name><surname>Kliesch</surname><given-names>C</given-names></name>, <name><surname>Turtleton</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Visual category representations in the infant brain</article-title>. <source>Curr Biol</source>. <year>2022</year>;<volume>32</volume>(<issue>24</issue>):<fpage>5422-5432.e6</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cub.2022.11.016</pub-id>
<pub-id pub-id-type="pmid">36455560</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref072"><label>72</label><mixed-citation publication-type="journal"><name><surname>Mareschal</surname><given-names>D</given-names></name>, <name><surname>Quinn</surname><given-names>PC</given-names></name>. <article-title>Categorization in infancy</article-title>. <source>Trends Cogn Sci</source>. <year>2001</year>;<volume>5</volume>(<issue>10</issue>):<fpage>443</fpage>&#x02013;<lpage>50</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s1364-6613(00)01752-6</pub-id>
<pub-id pub-id-type="pmid">11707383</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref073"><label>73</label><mixed-citation publication-type="journal"><name><surname>Jayaraman</surname><given-names>S</given-names></name>, <name><surname>Smith</surname><given-names>LB</given-names></name>. <article-title>Faces in early visual environments are persistent not</article-title>
<article-title>just frequent</article-title>. <source>Vision Res</source>. <year>2019</year>;<volume>157</volume>:<fpage>213</fpage>&#x02013;<lpage>21</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.visres.2018.05.005</pub-id>
</mixed-citation></ref><ref id="pone.0316555.ref074"><label>74</label><mixed-citation publication-type="journal"><name><surname>Anderson</surname><given-names>EM</given-names></name>, <name><surname>Candy</surname><given-names>TR</given-names></name>, <name><surname>Gold</surname><given-names>JM</given-names></name>, <name><surname>Smith</surname><given-names>LB</given-names></name>. <article-title>An edge-simplicity bias in the visual input to young infants</article-title>. <source>Sci Adv</source>. <year>2024</year>;<volume>10</volume>(<issue>19</issue>):<fpage>eadj8571</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/sciadv.adj8571</pub-id>
<pub-id pub-id-type="pmid">38728400</pub-id>
</mixed-citation></ref></ref-list></back></article>