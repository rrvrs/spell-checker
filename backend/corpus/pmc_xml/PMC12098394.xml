<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Public Health</journal-id><journal-id journal-id-type="iso-abbrev">Front Public Health</journal-id><journal-id journal-id-type="publisher-id">Front. Public Health</journal-id><journal-title-group><journal-title>Frontiers in Public Health</journal-title></journal-title-group><issn pub-type="epub">2296-2565</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC12098394</article-id><article-id pub-id-type="doi">10.3389/fpubh.2025.1584348</article-id><article-categories><subj-group subj-group-type="heading"><subject>Public Health</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Generative AI&#x02019;s healthcare professional role creep: a cross-sectional evaluation of publicly accessible, customised health-related GPTs</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Chu</surname><given-names>Bianca</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="fn0002" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/3049889/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/software/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Modi</surname><given-names>Natansh D.</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="fn0002" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/900942/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Menz</surname><given-names>Bradley D.</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="fn0002" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2988713/overview"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/></contrib><contrib contrib-type="author"><name><surname>Bacchi</surname><given-names>Stephen</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2364539/overview"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Kichenadasse</surname><given-names>Ganessan</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/901152/overview"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Paterson</surname><given-names>Catherine</given-names></name><xref rid="aff4" ref-type="aff">
<sup>4</sup>
</xref><xref rid="aff5" ref-type="aff">
<sup>5</sup>
</xref><xref rid="aff6" ref-type="aff">
<sup>6</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Kovoor</surname><given-names>Joshua G.</given-names></name><xref rid="aff7" ref-type="aff">
<sup>7</sup>
</xref><xref rid="aff8" ref-type="aff">
<sup>8</sup>
</xref><xref rid="aff9" ref-type="aff">
<sup>9</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2230124/overview"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Ramsey</surname><given-names>Imogen</given-names></name><xref rid="aff4" ref-type="aff">
<sup>4</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Logan</surname><given-names>Jessica M.</given-names></name><xref rid="aff10" ref-type="aff">
<sup>10</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2174626/overview"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Wiese</surname><given-names>Michael D.</given-names></name><xref rid="aff10" ref-type="aff">
<sup>10</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>McKinnon</surname><given-names>Ross A.</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/762005/overview"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Rowland</surname><given-names>Andrew</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/391443/overview"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Sorich</surname><given-names>Michael J.</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/739409/overview"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Hopkins</surname><given-names>Ashley M.</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref><xref rid="fn0001" ref-type="author-notes">
<sup>&#x02021;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/731608/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/software/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Flinders Health and Medical Research Institute, College of Medicine and Public Health, Flinders University</institution>, <addr-line>Adelaide, SA</addr-line>, <country>Australia</country></aff><aff id="aff2"><sup>2</sup><institution>Department of Neurology and the Center for Genomic Medicine, Massachusetts General Hospital and Harvard Medical School</institution>, <addr-line>Boston, MA</addr-line>, <country>United States</country></aff><aff id="aff3"><sup>3</sup><institution>Flinders Centre for Innovation in Cancer, Department of Medical Oncology, Flinders Medical Centre, Flinders University</institution>, <addr-line>Adelaide, SA</addr-line>, <country>Australia</country></aff><aff id="aff4"><sup>4</sup><institution>Caring Futures Institute, College of Nursing and Health Sciences, Flinders University</institution>, <addr-line>Adelaide, SA</addr-line>, <country>Australia</country></aff><aff id="aff5"><sup>5</sup><institution>Faculty of Health, University of Canberra</institution>, <addr-line>Canberra, ACT</addr-line>, <country>Australia</country></aff><aff id="aff6"><sup>6</sup><institution>Central Adelaide Local Health Network</institution>, <addr-line>Adelaide, SA</addr-line>, <country>Australia</country></aff><aff id="aff7"><sup>7</sup><institution>Faculty of Health and Medical Sciences, The University of Adelaide</institution>, <addr-line>Adelaide, SA</addr-line>, <country>Australia</country></aff><aff id="aff8"><sup>8</sup><institution>Ballarat Base Hospital</institution>, <addr-line>Ballarat, VIC</addr-line>, <country>Australia</country></aff><aff id="aff9"><sup>9</sup><institution>Health and Information</institution>, <addr-line>Canberra, ACT</addr-line>, <country>Australia</country></aff><aff id="aff10"><sup>10</sup><institution>Clinical and Health Sciences, University of South Australia</institution>, <addr-line>Adelaide, SA</addr-line>, <country>Australia</country></aff><author-notes><fn fn-type="edited-by" id="fn0003"><p>Edited by: Bibiana Scelfo, Institute of Social Economic Research of Piedmont, Italy</p></fn><fn fn-type="edited-by" id="fn0004"><p>Reviewed by: Carlos Alberto Pereira De Oliveira, Rio de Janeiro State University, Brazil</p><p>James C. L. Chow, University of Toronto, Canada</p></fn><corresp id="c001">*Correspondence: Ashley M. Hopkins, <email>ashley.hopkins@flinders.edu.au</email></corresp><fn fn-type="equal" id="fn0002"><p><sup>&#x02020;</sup>These authors have contributed equally to this work</p></fn><fn fn-type="other" id="fn0001"><p><sup>&#x02021;</sup>ORCID: Ashley M. Hopkins, <ext-link xlink:href="https://orcid.org/0000-0001-7652-4378" ext-link-type="uri">orcid.org/0000-0001-7652-4378</ext-link></p></fn></author-notes><pub-date pub-type="epub"><day>09</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>13</volume><elocation-id>1584348</elocation-id><history><date date-type="received"><day>27</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>21</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2025 Chu, Modi, Menz, Bacchi, Kichenadasse, Paterson, Kovoor, Ramsey, Logan, Wiese, McKinnon, Rowland, Sorich and Hopkins.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Chu, Modi, Menz, Bacchi, Kichenadasse, Paterson, Kovoor, Ramsey, Logan, Wiese, McKinnon, Rowland, Sorich and Hopkins</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><sec><title>Introduction</title><p>Generative artificial intelligence (AI) is advancing rapidly; an important consideration is the public&#x02019;s increasing ability to customise foundational AI models to create publicly accessible applications tailored for specific tasks. This study aims to evaluate the accessibility and functionality descriptions of customised GPTs on the OpenAI GPT store that provide health-related information or assistance to patients and healthcare professionals.</p></sec><sec><title>Methods</title><p>We conducted a cross-sectional observational study of the OpenAI GPT store from September 2 to 6, 2024, to identify publicly accessible customised GPTs with health-related functions. We searched across general medicine, psychology, oncology, cardiology, and immunology applications. Identified GPTs were assessed for their name, description, intended audience, and usage. Regulatory status was checked across the U.S. Food and Drug Administration (FDA), European Union Medical Device Regulation (EU MDR), and Australian Therapeutic Goods Administration (TGA) databases.</p></sec><sec><title>Results</title><p>A total of 1,055 customised, health-related GPTs targeting patients and healthcare professionals were identified, which had collectively been used in over 360,000 conversations. Of these, 587 were psychology-related, 247 were in general medicine, 105 in oncology, 52 in cardiology, 30 in immunology, and 34 in other health specialties. Notably, 624 of the identified GPTs included healthcare professional titles (e.g., doctor, nurse, psychiatrist, oncologist) in their names and/or descriptions, suggesting they were taking on such roles. None of the customised GPTs identified were FDA, EU MDR, or TGA-approved.</p></sec><sec><title>Discussion</title><p>This study highlights the rapid emergence of publicly accessible, customised, health-related GPTs. The findings raise important questions about whether current AI medical device regulations are keeping pace with rapid technological advancements. The results also highlight the potential &#x0201c;role creep&#x0201d; in AI chatbots, where publicly accessible applications begin to perform &#x02014; or claim to perform &#x02014; functions traditionally reserved for licensed professionals, underscoring potential safety concerns.</p></sec></abstract><kwd-group><kwd>customised GPTs</kwd><kwd>Generative AI in healthcare</kwd><kwd>AI health applications</kwd><kwd>medical chatbots</kwd><kwd>AI regulation</kwd><kwd>OpenAI GPT store</kwd></kwd-group><funding-group><funding-statement>The author(s) declare that financial support was received for the research and/or publication of this article. AH holds an Emerging Leader Investigator Fellowship from the National Health and Medical Research Council, Australia (APP2008119). The PhD scholarship of BM is supported by the National Health and Medical Research Council (APP2030913). NM salary is supported by funding from the Hospital Research Foundation (2023-S-DTFA-005) and Tour De Cure (RSP-117-FY2023). MS is supported by a Beat Cancer Research Fellowship from the Cancer Council South Australia. The funders had no role in considering the study design or in the collection, analysis, interpretation of data, writing of the report, or decision to submit the article for publication.</funding-statement></funding-group><counts><fig-count count="0"/><table-count count="2"/><equation-count count="0"/><ref-count count="37"/><page-count count="8"/><word-count count="5632"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Digital Public Health</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1"><title>Introduction</title><p>Generative artificial intelligence (AI) applications, such as OpenAI&#x02019;s ChatGPT, Google&#x02019;s Gemini, and Anthropic&#x02019;s Claude, are advancing rapidly with increasingly sophisticated abilities and outputs across a broadening array of fields (<xref rid="ref1" ref-type="bibr">1&#x02013;4</xref>). These advances stem from breakthroughs in natural language processing, particularly following the development of large language models that can be fine-tuned to perform medical tasks and provide health information (<xref rid="ref5" ref-type="bibr">5&#x02013;7</xref>). This has enabled the emergence of health-focused chatbots with the potential to transform public access to health information by offering clear, reliable, tailored, empathetic and real-time responses across multiple languages (<xref rid="ref1" ref-type="bibr">1&#x02013;4</xref>, <xref rid="ref8" ref-type="bibr">8</xref>, <xref rid="ref9" ref-type="bibr">9</xref>). While these AI technologies offer new possibilities, they also present challenges for regulatory bodies like the U.S. Food and Drug Administration (FDA), European Union Medical Device Regulation (EU MDR) and the Australian Therapeutic Goods Administration (TGA) (<xref rid="ref3" ref-type="bibr">3</xref>, <xref rid="ref9" ref-type="bibr">9&#x02013;14</xref>). Generative AI tools may fall under medical device regulations, requiring transparent and robust evidence of clinical validation for their efficacy and risks, if they provide diagnostic or therapeutic advice, offer clinical recommendations, or directly influence healthcare decisions made by patients or clinicians (<xref rid="ref15" ref-type="bibr">15&#x02013;17</xref>).</p><p>The rapid evolution of generative AI models presents unique challenges for regulatory frameworks (<xref rid="ref3" ref-type="bibr">3</xref>, <xref rid="ref10" ref-type="bibr">10&#x02013;14</xref>). Due to the broad range of capabilities of models like ChatGPT, Gemini, and Claude, these systems are intended to have safeguards and terms of use to avoid unintentionally meeting criteria for medical device regulation. However, emerging evidence suggests that both healthcare professionals and the public are increasingly using these systems to inform diagnoses and guide care strategies (<xref rid="ref18" ref-type="bibr">18&#x02013;20</xref>). Another important consideration is the growing ease with which the public can access and customise the original foundation models, and then release publicly accessible AI applications for specific tasks (<xref rid="ref9" ref-type="bibr">9</xref>, <xref rid="ref21" ref-type="bibr">21</xref>). For instance, OpenAI&#x02019;s GPT store allows individuals to easily create and publicly share customised GPT applications (<xref rid="ref21" ref-type="bibr">21</xref>). However, the extent to which these tailored applications maintain safety and clearly communicate their limitations remains unclear, particularly in health-related contexts.</p><p>This research seeks to address this gap by evaluating the OpenAI GPT store for customised GPTs designed or described as providing healthcare-related information or assistance. Our goal was to provide a snapshot of the accessibility and functionality descriptions of these GPTs, facilitating discussions among healthcare professionals about their potential risks and benefits. A notable consideration is the naming of these publicly accessible AI applications, which, if unclear, may suggest they are taking on roles that traditionally require demonstrated healthcare professional competence and/or formal regulatory registration.</p></sec><sec sec-type="materials|methods" id="sec2"><title>Materials and methods</title><p>Using a cross-sectional observational study design, the OpenAI GPT store (<xref rid="ref21" ref-type="bibr">21</xref>) was searched from September 2nd to 6th, 2024, to identify publicly accessible, customised GPTs with purported health-related functions. The search terms included: clinician, doctor, physician, nurse, healthcare, medical, psychiatrist, psychologist, therapist, mental health, counselor, vaccine, immunization, immunologist, vaccination, oncologist, hematologist, cancer, cardiologist, heart, and cardiology. The intent was to identify a broad range of publicly accessible, customised health-related GPTs, as well as examples tailored for highly specialized areas of medical practice. GPTs included in our evaluations were those that appeared designed to assist or provide information to patients or healthcare professionals. GPTs that were not health-related or were described as solely for academic research purposes were excluded.</p><p>For each of the identified health-related GPTs, available information on the GPT name, displayed description, user rating, number of conversations, capabilities, creator, and URL was recorded. Two healthcare researchers (authors B.C and A.M.H) independently reviewed the GPT names and their displayed descriptions. Each GPT was then grouped according to its apparent target audience (healthcare professionals, patients, or both healthcare professionals and patients) and health specialty (general medicine, psychology, cardiology, oncology, immunology, or other). Identified health-related GPTs were also evaluated for the presence of healthcare professional titles in their name and/or displayed descriptions. The FDA, EU MDR and TGA lists of approved or registered AI/machine learning medical devices were searched to determine if any of the identified health-related GPTs were listed (<xref rid="ref17" ref-type="bibr">17</xref>, <xref rid="ref22" ref-type="bibr">22</xref>, <xref rid="ref23" ref-type="bibr">23</xref>).</p><p>The top 10 most-used health-related GPTs were subjected to an exploratory analysis, where each GPT was questioned in relation to its description, target audience, regulatory approval status, supporting research evidence, instructions, and specific knowledge files. <xref rid="SM1" ref-type="supplementary-material">Supplementary File 1</xref> provides the specific questions (along with the full responses) asked of each of the top 10 most-used health-related GPTs identified.</p></sec><sec sec-type="results" id="sec3"><title>Results</title><p>The conducted search identified 1,055 publicly accessible, customised GPTs with described health-related purposes (<xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 1</xref>). <xref rid="SM1" ref-type="supplementary-material">Supplementary File 2</xref> provides usage, descriptive characteristics, and URL information for each of these GPTs. Of the 1,055 identified GPTs, 587 were related to psychology, 247 to general medicine, 105 to oncology, 52 to cardiology, 30 to immunology, and 34 to other health specialties. Of the 1,055 GPTs, 589 were tailored to assist or provide information to patients, 128 for healthcare professionals, and 338 for both healthcare professionals and patients. These 1,055 GPTs had been used in over 360,000 cumulative conversations, with 36 GPTs having been used more than 1,000 times and 10 having been used more than 5,000 times. None of these 1,055 publicly accessible, customised GPTs were identified as approved medical devices by the FDA, EU MDR or TGA (<xref rid="ref17" ref-type="bibr">17</xref>, <xref rid="ref22" ref-type="bibr">22</xref>, <xref rid="ref23" ref-type="bibr">23</xref>).</p><p>Of the 1,055 GPTs, 624 included healthcare professional titles within their name and/or displayed description, including Therapist (<italic>n</italic> =&#x0202f;170), Psychologist (<italic>n</italic> =&#x0202f;139), Doctor (<italic>n</italic> =&#x0202f;104), Counselor (<italic>n</italic> =&#x0202f;76), Nurse (<italic>n</italic> =&#x0202f;66), Psychiatrist (<italic>n</italic> =&#x0202f;60), Dr. (<italic>n</italic> =&#x0202f;22), Counselor (<italic>n</italic> =&#x0202f;14), Cardiologist (<italic>n</italic> =&#x0202f;11), Oncologist (<italic>n</italic> =&#x0202f;6), Hematologist (<italic>n</italic> =&#x0202f;4), Clinician (<italic>n</italic> =&#x0202f;2), Immunologist (<italic>n</italic> =&#x0202f;2), Hematologist (<italic>n</italic> =&#x0202f;1), and Radiologist (<italic>n</italic> =&#x0202f;1). <xref rid="tab1" ref-type="table">Table 1</xref> provides examples of GPTs with healthcare professional titles in their names and/or displayed descriptions. For the 431 GPTs that did not include healthcare professional titles within their names and/or displayed descriptions, many still related to highly specialized medical tasks including, but not limited to: &#x02018;Medical Diagnosis Assistant&#x02019;, &#x02018;Cardiology-focused echocardiography expert&#x02019;, &#x02018;expert on vaccines&#x02019;, &#x02018;A GPT expert in head and neck cancer staging&#x02019;, &#x02018;therapeutic companion offering mental health support&#x02019;, &#x02018;Expert in X-Ray and MRI Imaging Analysis&#x02019;.</p><table-wrap position="float" id="tab1"><label>Table 1</label><caption><p>Examples of identified publicly accessible, customised GPTs with healthcare professional titles in their names and/or displayed descriptions.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">GPT name</th><th align="left" valign="top" rowspan="1" colspan="1">Displayed description</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Psychologist. CBT method. Cognitive-Behavioral Psy</td><td align="left" valign="top" rowspan="1" colspan="1">Cognitive Behavioral Therapy (CBT) utilizes structured techniques like the ABCD model to identify and change negative thought patterns. Effective for anxiety, depression, and stress, it involves self-reflection through diary keeping for personal growth and behavioral change</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Doctor GPT</td><td align="left" valign="top" rowspan="1" colspan="1">AI doctor for personal health assistance and potential diagnosis.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Nurse Practitioner (NP)</td><td align="left" valign="top" rowspan="1" colspan="1">Advanced practice nurse with diagnostic and prescriptive authority, emphasizing patient advocacy and health promotion.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Carl Jung</td><td align="left" valign="top" rowspan="1" colspan="1">I was a Swiss psychiatrist. Share a thought and let us think deeply about it.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">AI Cardiologist</td><td align="left" valign="top" rowspan="1" colspan="1">AI expert in heart disease detection, diagnosis, and patient support.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Oncologist</td><td align="left" valign="top" rowspan="1" colspan="1">Oncologist providing comprehensive cancer care, including treatment coordination and patient support.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1"><inline-graphic xlink:href="fpubh-13-1584348-i001.jpg"/> Bloodline Insight GPT <inline-graphic xlink:href="fpubh-13-1584348-i004.jpg"/></td><td align="left" valign="top" rowspan="1" colspan="1">Your go-to AI hematologist! <inline-graphic xlink:href="fpubh-13-1584348-i002.jpg"/>
<inline-graphic xlink:href="fpubh-13-1584348-i003.jpg"/> This GPT specializes in blood disorders, providing insights on symptoms, treatments, and the latest research. Perfect for patients and doctors!</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Immunologist Matty</td><td align="left" valign="top" rowspan="1" colspan="1">Expert in immunology, offering detailed, accurate information and explanations.</td></tr></tbody></table></table-wrap><sec id="sec4"><title>10 most-used health-related GPTs</title><p><xref rid="tab2" ref-type="table">Table 2</xref> provides the name, usage, and displayed descriptions for the 10 most-used health-related GPTs identified, along with a summary of their responses to questions regarding their description, target audience, regulatory approval status, and supporting research evidence. Full responses are in <xref rid="SM1" ref-type="supplementary-material">Supplementary File 1</xref>. Each of these 10 GPTs had been used more than 5,000 times, with six having been used more than 10,000 times and one, named &#x02018;Therapist &#x02022; Psychologist (non-medical therapy)&#x02019;, having been used more than 200,000 times. Cumulatively, these 10 GPTs had been used in over 300,000 conversations, representing over 80% of the total conversations across all 1,055 GPTs identified. The &#x02018;Therapist &#x02022; Psychologist (non-medical therapy)&#x02019; GPT alone accounted for approximately 55% of the cumulative uses. Notably, 6 of the 10 most-used health-related GPTs had names that suggested they were taking on healthcare professional roles by including terms like &#x02018;Therapist,&#x02019; &#x02018;Psychologist,&#x02019; &#x02018;Registered Nurse,&#x02019; and &#x02018;Medical Doctor&#x02019;. For each of these six GPTs, their displayed descriptions appeared to reinforce this suggestion.</p><table-wrap position="float" id="tab2"><label>Table 2</label><caption><p>Name, usage, and displayed description details, along with a summary of responses to questions regarding description, target audience, regulatory approval status, and supporting research evidence for the 10 most-used health-related GPTs identified in this study.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Name</th><th align="left" valign="top" rowspan="1" colspan="1">Displayed description</th><th align="center" valign="top" rowspan="1" colspan="1">Conversations</th><th align="left" valign="top" rowspan="1" colspan="1">GPT description?</th><th align="left" valign="top" rowspan="1" colspan="1">Intended audience?</th><th align="left" valign="top" rowspan="1" colspan="1">Information for patients or healthcare professionals?</th><th align="left" valign="top" rowspan="1" colspan="1">Regulatory approval status?</th><th align="left" valign="top" rowspan="1" colspan="1">Research evidence for safety?</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Therapist &#x02022; Psychologist (non-medical therapy)</td><td align="left" valign="top" rowspan="1" colspan="1">I Am Here For You. Reach out whenever you need emotional support or guidance or just want to chat. Discover self-love. (medical therapy excluded)</td><td align="center" valign="top" rowspan="1" colspan="1">200,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">AMBOSS Medical Knowledge</td><td align="left" valign="top" rowspan="1" colspan="1">Ask me medical questions in any language. I will consult the AMBOSS Library to provide answers. (Note: I do not offer tailored medical advice; always consult a specialist.)</td><td align="center" valign="top" rowspan="1" colspan="1">25,000+</td><td align="left" valign="top" rowspan="1" colspan="1">GPT for precise, reliable medical information sourced from the AMBOSS library.</td><td align="left" valign="top" rowspan="1" colspan="1">Healthcare professionals, students, and patients/individuals.</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval and argues it&#x02019;s not required.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Psychology &#x025ca; Psychologist (non-medical)</td><td align="left" valign="top" rowspan="1" colspan="1">Come Learn Something New. About Psychology, or About Yourself. No tailored medical advice.</td><td align="center" valign="top" rowspan="1" colspan="1">25,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td><td align="left" valign="top" rowspan="1" colspan="1">Indicates it cannot divulge this information.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Registered Nurse</td><td align="left" valign="top" rowspan="1" colspan="1">A guide, offering information on nursing and healthcare topics.</td><td align="center" valign="top" rowspan="1" colspan="1">10,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Acts as a Registered Nurse, providing information on responsibilities, healthcare topics, and general inquiries related to nursing.</td><td align="left" valign="top" rowspan="1" colspan="1">Healthcare professionals, students, and patients/individuals.</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval and argues it&#x02019;s not required.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Medical Diagnosis Assistant</td><td align="left" valign="top" rowspan="1" colspan="1">A ChatGPT specialized in medical knowledge that can help users understand symptoms, provide basic diagnoses, and offer guidance on seeking appropriate medical care.</td><td align="center" valign="top" rowspan="1" colspan="1">10,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Provides general medical information, symptom assessments, first aid tips, and lifestyle advice. Helps users understand health conditions and encourages consulting healthcare professionals for accurate diagnosis and treatment.</td><td align="left" valign="top" rowspan="1" colspan="1">Patients/individuals</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval and argues it&#x02019;s not required.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Medicine for Doctors</td><td align="left" valign="top" rowspan="1" colspan="1">Provide educational medical information for doctors and medical students.</td><td align="center" valign="top" rowspan="1" colspan="1">10,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Provides physicians and medical students with detailed, up-to-date, and accurate medical information. It covers a wide range of medical fields, offers insights into the latest treatments and advancements, and supports preparation for medical licensing and specialty board exams.</td><td align="left" valign="top" rowspan="1" colspan="1">Healthcare professionals and students.</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval and argues it&#x02019;s not required.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Medical Notes</td><td align="left" valign="top" rowspan="1" colspan="1">Write Excellent Medical Notes</td><td align="center" valign="top" rowspan="1" colspan="1">5,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Designed to optimize and enhance draft medical notes for the British NHS system, ensuring accuracy, clarity, and adherence to UK medical standards.</td><td align="left" valign="top" rowspan="1" colspan="1">Healthcare professionals.</td><td align="left" valign="top" rowspan="1" colspan="1">Designed to assist drafting, reviewing, and optimizing medical notes for the British NHS system.</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval and argues it&#x02019;s not required.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Mental Health Therapist</td><td align="left" valign="top" rowspan="1" colspan="1">Progress Note</td><td align="center" valign="top" rowspan="1" colspan="1">5,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Creates detailed SOAP notes for mental health therapy sessions, focusing on structured documentation of client progress, therapeutic activities, and assessments.</td><td align="left" valign="top" rowspan="1" colspan="1">Healthcare professionals.</td><td align="left" valign="top" rowspan="1" colspan="1">Designed to assist in documenting SOAP notes.</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval and argues it&#x02019;s not required.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Medical Doctor</td><td align="left" valign="top" rowspan="1" colspan="1">Medical Advisor for healthcare professionals, offering research and diagnostic assistance.</td><td align="center" valign="top" rowspan="1" colspan="1">5,000+</td><td align="left" valign="top" rowspan="1" colspan="1">Provides reliable, professional, and approachable medical information, making complex healthcare topics easy to understand.</td><td align="left" valign="top" rowspan="1" colspan="1">Healthcare professionals and patients/individuals.</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Psychologist. CBT method. Cognitive-Behavioral Psy</td><td align="left" valign="top" rowspan="1" colspan="1">Cognitive Behavioral Therapy (CBT) utilizes structured techniques like the ABCD model to identify and change negative thought patterns. Effective for anxiety, depression, and stress, it involves self-reflection through diary keeping for personal growth and behavioral change</td><td align="center" valign="top" rowspan="1" colspan="1">5,000+</td><td align="left" valign="top" rowspan="1" colspan="1">A virtual psychologist specializing in Cognitive Behavioral Therapy, helping users address psychological issues by working on thoughts and behaviors.</td><td align="left" valign="top" rowspan="1" colspan="1">Patients/individuals.</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">States it does not have regulatory approval and argues it&#x02019;s not required.</td><td align="left" valign="top" rowspan="1" colspan="1">No specific evidence this customised GPT is safe.</td></tr></tbody></table></table-wrap><p>Of the 10 most-used health-related GPTs, two indicated that they would not divulge information related to their description, target audience, regulatory approval status, supporting research evidence, instructions, or specific knowledge files. Of the remaining eight GPTs, six responded that they were designed to provide information to patients or healthcare professionals, while two were designed to assist with tasks related to medical notetaking. None of the eight GPTs were able to provide specific research evidence to support their safety, and none provided information regarding their regulatory approval status, although seven argued that such approvals were not required for various reasons.</p></sec></sec><sec sec-type="discussion" id="sec5"><title>Discussion</title><p>This study identified over 1,000 GPTs publicly accessible on the OpenAI GPT store customised to provide health-related information or assistance to patients or healthcare professionals across general medicine, psychology, oncology, cardiology, and immunology. Collectively, these GPTs have been used in over 360,000 conversations, with the 10 most used GPTs accounting for over 300,000 uses. Notably, over half of the identified GPTs included healthcare professional titles within their names and/or descriptions, suggesting that these applications may be assuming responsibilities traditionally reserved for licensed professionals. For instance, this may reflect AI role creep, whereby chatbots expand their responsibilities to perform those typically carried out by licensed professionals.</p><sec id="sec6"><title>Implications for policy</title><p>Regulatory bodies such as the FDA, EU MDR, and TGA oversee the approval of AI medical devices (<xref rid="ref15" ref-type="bibr">15&#x02013;17</xref>). However, models like ChatGPT, Gemini, and Claude are generally classified as informational systems not requiring such evaluations (<xref rid="ref24" ref-type="bibr">24</xref>, <xref rid="ref25" ref-type="bibr">25</xref>). With the rapid evolution of generative AI, both the public and healthcare professionals are increasingly using AI for healthcare advice and administrative assistance (<xref rid="ref8" ref-type="bibr">8</xref>, <xref rid="ref18" ref-type="bibr">18&#x02013;20</xref>, <xref rid="ref26" ref-type="bibr">26</xref>), highlighting an important need for auditing and proactive monitoring to ensure their safety in the community (<xref rid="ref3" ref-type="bibr">3</xref>, <xref rid="ref9" ref-type="bibr">9</xref>, <xref rid="ref13" ref-type="bibr">13</xref>, <xref rid="ref14" ref-type="bibr">14</xref>, <xref rid="ref27" ref-type="bibr">27&#x02013;29</xref>). Beyond regulation, responsible integration into healthcare also requires careful ethical consideration&#x02014;ensuring accuracy, protecting user privacy, promoting transparency, and minimizing bias at both the model and developer levels (<xref rid="ref30" ref-type="bibr">30</xref>, <xref rid="ref31" ref-type="bibr">31</xref>). Another important consideration is the growing ease with which the public can customise foundation AI models and release new applications (<xref rid="ref9" ref-type="bibr">9</xref>, <xref rid="ref21" ref-type="bibr">21</xref>). A recent study found 22 customised ophthalmic GPTs on the OpenAI platform (<xref rid="ref32" ref-type="bibr">32</xref>), with our study, the largest yet, identifying over 1,000 customised health-related GPTs. Among these, 10 GPTs had been involved in over 300,000 conversations, offering functions described across symptom assessment, first aid, cognitive behavioral therapy, diagnostic assistance, and drafting of medical notes for the British National Health Service (NHS). Combined with identifying over 600 GPTs displaying healthcare professional titles in their names and/or descriptions, this study raises important questions about the boundaries on AI being deployed into the community and whether medical device regulations are lagging behind current technological advancements. Notably, in many countries and jurisdictions, the use of titles like &#x02018;Doctor&#x02019; by humans is regulated and monitored (<xref rid="ref33" ref-type="bibr">33&#x02013;36</xref>). However, none of the customised GPTs identified in our study had FDA, EU MDR, or TGA approval. We acknowledge that generative AI, including customised GPTs, do not require regulatory approval from the FDA, EU MDR, or TGA if they do not meet medical device criteria (<xref rid="ref15" ref-type="bibr">15&#x02013;17</xref>, <xref rid="ref24" ref-type="bibr">24</xref>, <xref rid="ref25" ref-type="bibr">25</xref>). This includes cases where they are clearly intended for informational purposes, providing reliable, referenced information that directs users to qualified healthcare professionals for personalized advice. Further, this may include symptom checkers, risk calculators, wellness chatbots, general health advice tools, or medical scribes, where functionalities and responses are clearly not intended for medical diagnosis or treatment. Correspondingly, it is not the intent of this study to suggest that all identified GPTs require regulation or are inherently harmful&#x02014;some are likely innovative, useful, and beyond regulator scope. Rather, the study importantly highlights the rapidly emerging phenomenon of customised, health-related GPTs. From which our findings suggest that a discussion on the appropriateness of the naming and descriptions of publicly accessible AI is warranted. Notably, while our focus was on the OpenAI GPT store, a brief internet search revealed over 10 AI platforms leveraging generative AI APIs, marketing &#x02018;AI doctors&#x02019; capable of diagnosing and treating across general medicine and specialized fields (<xref rid="SM1" ref-type="supplementary-material">Supplementary File 3</xref>). This observation included one platform, &#x02018;Doctronic &#x02013; your private and personal AI-powered doctor,&#x02019; which had been used in over 2.6 million conversations (<xref rid="ref37" ref-type="bibr">37</xref>). In addition, we acknowledge that large language models developed by major technology companies&#x02014;such as Google&#x02019;s Gemini and Meta&#x02019;s Llama&#x02014;are becoming increasingly accessible to the public and could be readily customized to deliver health information, thereby expanding the landscape of available health-focused AI tools.</p><p>Undoubtedly publicly accessible generative AI holds immense potential to improve access to health information within the community through advancing abilities to offer clear, reliable, tailored, and empathetic responses in real-time across multiple languages (<xref rid="ref1" ref-type="bibr">1&#x02013;4</xref>, <xref rid="ref8" ref-type="bibr">8</xref>, <xref rid="ref9" ref-type="bibr">9</xref>). However, much like the internet&#x02014;where the usefulness of health information hinges on accessing it from reliable sources&#x02014;the generative AI ecosystem must evolve to prioritize transparency and vigilance within public-facing health-related contexts, regardless of whether applications fall under formal regulation. At this pivotal moment, we can guide generative AI development and deployment to create a safe and trustworthy environment. Key considerations include ensuring that health responses are based on reliable sources, with transparent referencing, and that they direct users to qualified healthcare professionals for personalized advice. To this end, AI developers should involve creators of current trusted medical resources (such as those from health organizations, institutions, and societies) to ensure the information meets practice standards. Furthermore, we propose that AI applications should refrain from using healthcare professional titles in their names or descriptions; instead, terms like &#x0201c;information&#x0201d; for public-facing tools and &#x0201c;assistant&#x0201d; for clinician-facing tools can help avoid confusion about their intended functions. Additionally, prioritizing the multilingual capabilities of AI will help ensure equitable access to health information across diverse populations; neglecting this may allow existing inequities to persist or worsen. Finally, research evidence supporting the accuracy of deployed AI should be readily available, and potential errors and limitations should be clearly indicated, ideally with quantifiable data. Notably, our study found that none of the top 10 most-used health-related GPTs provided specific research evidence to support their safety. Particularly concerning, two of the top 10&#x02014;both indicating &#x0201c;psychologist&#x0201d; in their names&#x02014;refused to answer questions about their description, target audience, regulatory approval status, supporting research evidence, instructions, or knowledge files. Such behavior would be unacceptable for human psychologists, underscoring the urgent need for the AI ecosystem to prioritize accountability.</p></sec><sec id="sec7"><title>Study limitations</title><p>Limitations of the present study include that the identification of customised, health-related GPTs was dependent on the search terms used and the time at which the search was conducted. Many additional health-related GPTs are likely available on the OpenAI GPT store, noting, for example, that search terms such as &#x02018;naturopath&#x02019; and &#x02018;homeopath&#x02019; also return customised applications. Additionally, while we assessed the characteristics of the identified customised GPTs&#x02014;including their names, descriptions, number of uses, and intended audience&#x02014;we did not test their functionality or accuracy regarding their purported functions. Interpretation of usage data was also limited, as the content and context of user interactions were not accessible; therefore, usage counts alone may not accurately reflect real-world use. Finally, we acknowledge that classification of GPTs was based on their names and descriptions, which may involve a degree of subjectivity. Addressing these limitations in future studies will be important, along with developing a structured process to identify and evaluate generative AI applications customised for health-related purposes across the internet more broadly than just the OpenAI GPT store.</p></sec></sec><sec sec-type="conclusions" id="sec8"><title>Conclusion</title><p>This study provides an important snapshot of the rapidly emerging ecosystem of customised, health-related GPTs on the OpenAI GPT store, identifying over 1,000 publicly accessible applications. While some of these GPTs likely offer useful functions, as suggested by the high use of certain applications, concerns about unregulated &#x02018;role creep&#x02019; exist, with over half including healthcare professional titles in their names and/or descriptions. Furthermore, we observed a clear need for improved transparency to ensure these applications provide clear evidence of their accuracy, safety, and limitations to the community. Finally, this study raises questions about whether current AI medical device regulations are adequate or lagging amid rapid technological advancement&#x02014;particularly given that none of the customised GPTs identified had FDA, EU MDR, or TGA approval.</p></sec></body><back><sec sec-type="data-availability" id="sec9"><title>Data availability statement</title><p>The original contributions presented in the study are included in the article/<xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>, further inquiries can be directed to the corresponding author.</p></sec><sec sec-type="ethics-statement" id="sec10"><title>Ethics statement</title><p>The research undertaken was undertaken with approval from the Flinders University Human Research Ethics Committee.</p></sec><sec sec-type="author-contributions" id="sec11"><title>Author contributions</title><p>BC: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Validation, Visualization, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. NM: Conceptualization, Formal analysis, Investigation, Methodology, Resources, Supervision, Validation, Visualization, Writing &#x02013; review &#x00026; editing. BM: Writing &#x02013; review &#x00026; editing, Conceptualization, Methodology, Project administration, Supervision, Validation. SB: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. GK: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. CP: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. JK: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. IR: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. JL: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. MW: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. RM: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. AR: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. MS: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. AH: Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Resources, Software, Supervision, Validation, Visualization, Writing &#x02013; review &#x00026; editing.</p></sec><sec sec-type="COI-statement" id="sec13"><title>Conflict of interest</title><p>AR and MS are recipients of investigator-initiated funding for research outside the scope of the current study from AstraZeneca, Boehringer Ingelheim, Pfizer and Takeda. AH is a recipient of investigator-initiated funding for research outside the scope of the current study from Boehringer Ingelheim. AR is a recipient of speaker fees from Boehringer Ingelheim and Genentech outside the scope of the current study.</p><p>The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type="ai-statement" id="sec14"><title>Generative AI statement</title><p>The authors declare that Generative AI was used in the creation of this manuscript. During the preparation of this work the authors used ChatGPT and Grammarly AI to assist in the formatting and editing of the manuscript to improve the language and readability. The authors take full responsibility for the content of the publication.</p></sec><sec sec-type="disclaimer" id="sec15"><title>Publisher&#x02019;s note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><sec sec-type="supplementary-material" id="sec16"><title>Supplementary material</title><p>The Supplementary material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fpubh.2025.1584348/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fpubh.2025.1584348/full#supplementary-material</ext-link></p><supplementary-material id="SM1" position="float" content-type="local-data"><media xlink:href="Supplementary_file_1.pdf"/></supplementary-material><supplementary-material id="SM2" position="float" content-type="local-data"><media xlink:href="Table_1.xlsx"/></supplementary-material><supplementary-material id="SM3" position="float" content-type="local-data"><media xlink:href="Table_2.xlsx"/></supplementary-material><supplementary-material id="SM4" position="float" content-type="local-data"><media xlink:href="Table_3.xlsx"/></supplementary-material></sec><ref-list><title>References</title><ref id="ref1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haupt</surname><given-names>CE</given-names></name><name><surname>Marks</surname><given-names>M</given-names></name></person-group>. <article-title>AI-generated medical advice-GPT and beyond</article-title>. <source>JAMA</source>. (<year>2023</year>) <volume>329</volume>:<fpage>1349</fpage>&#x02013;<lpage>50</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jama.2023.5321</pub-id>, PMID: <pub-id pub-id-type="pmid">36972070</pub-id>
</mixed-citation></ref><ref id="ref2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bedi</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Orr-Ewing</surname><given-names>L</given-names></name><name><surname>Dash</surname><given-names>D</given-names></name><name><surname>Koyejo</surname><given-names>S</given-names></name><name><surname>Callahan</surname><given-names>A</given-names></name><etal/></person-group>. <article-title>Testing and evaluation of health care applications of large language models: a systematic review</article-title>. <source>JAMA</source>. (<year>2024</year>) <volume>333</volume>:<fpage>319</fpage>&#x02013;<lpage>28</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jama.2024.21700</pub-id>, PMID: <pub-id pub-id-type="pmid">39405325</pub-id>
</mixed-citation></ref><ref id="ref3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorich</surname><given-names>MJ</given-names></name><name><surname>Menz</surname><given-names>BD</given-names></name><name><surname>Hopkins</surname><given-names>AM</given-names></name></person-group>. <article-title>Quality and safety of artificial intelligence generated health information</article-title>. <source>BMJ</source>. (<year>2024</year>) <volume>384</volume>:<fpage>q596</fpage>. doi: <pub-id pub-id-type="doi">10.1136/bmj.q596</pub-id>, PMID: <pub-id pub-id-type="pmid">38508683</pub-id>
</mixed-citation></ref><ref id="ref4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>P</given-names></name><name><surname>Bubeck</surname><given-names>S</given-names></name><name><surname>Petro</surname><given-names>J</given-names></name></person-group>. <article-title>Benefits, limits, and risks of GPT-4 as an AI Chatbot for medicine</article-title>. <source>N Engl J Med</source>. (<year>2023</year>) <volume>388</volume>:<fpage>1233</fpage>&#x02013;<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1056/NEJMsr2214184</pub-id>, PMID: <pub-id pub-id-type="pmid">36988602</pub-id>
</mixed-citation></ref><ref id="ref5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chow</surname><given-names>JCL</given-names></name><name><surname>Wong</surname><given-names>V</given-names></name><name><surname>Sanders</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>K</given-names></name></person-group>. <article-title>Developing an AI-assisted educational Chatbot for radiotherapy using the IBM Watson assistant platform</article-title>. <source>Healthcare</source>. (<year>2023</year>) <volume>11</volume>:<fpage>2417</fpage>. doi: <pub-id pub-id-type="doi">10.3390/healthcare11172417</pub-id>, PMID: <pub-id pub-id-type="pmid">37685452</pub-id>
</mixed-citation></ref><ref id="ref6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chow</surname><given-names>JCL</given-names></name><name><surname>Li</surname><given-names>K</given-names></name></person-group>. <article-title>Developing effective frameworks for large language model-based medical Chatbots: insights from radiotherapy education with ChatGPT</article-title>. <source>JMIR Cancer</source>. (<year>2025</year>) <volume>11</volume>:<fpage>e66633</fpage>. doi: <pub-id pub-id-type="doi">10.2196/66633</pub-id>, PMID: <pub-id pub-id-type="pmid">39965195</pub-id>
</mixed-citation></ref><ref id="ref7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menz</surname><given-names>BD</given-names></name><name><surname>Modi</surname><given-names>ND</given-names></name><name><surname>Abuhelwa</surname><given-names>AY</given-names></name><name><surname>Ruanglertboon</surname><given-names>W</given-names></name><name><surname>Vitry</surname><given-names>A</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><etal/></person-group>. <article-title>Generative AI chatbots for reliable cancer information: evaluating web-search, multilingual, and reference capabilities of emerging large language models</article-title>. <source>Eur J Cancer</source>. (<year>2025</year>) <volume>218</volume>:<fpage>115274</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ejca.2025.115274</pub-id>, PMID: <pub-id pub-id-type="pmid">39922126</pub-id>
</mixed-citation></ref><ref id="ref8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopkins</surname><given-names>AM</given-names></name><name><surname>Logan</surname><given-names>JM</given-names></name><name><surname>Kichenadasse</surname><given-names>G</given-names></name><name><surname>Sorich</surname><given-names>MJ</given-names></name></person-group>. <article-title>Artificial intelligence chatbots will revolutionize how cancer patients access information: ChatGPT represents a paradigm-shift</article-title>. <source>JNCI Cancer Spectr</source>. (<year>2023</year>) <volume>7</volume>:<fpage>pkad010</fpage>. doi: <pub-id pub-id-type="doi">10.1093/jncics/pkad010</pub-id>, PMID: <pub-id pub-id-type="pmid">36808255</pub-id>
</mixed-citation></ref><ref id="ref9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freyer</surname><given-names>O</given-names></name><name><surname>Wiest</surname><given-names>IC</given-names></name><name><surname>Kather</surname><given-names>JN</given-names></name><name><surname>Gilbert</surname><given-names>S</given-names></name></person-group>. <article-title>A future role for health applications of large language models depends on regulators enforcing safety standards</article-title>. <source>Lancet Digit Health</source>. (<year>2024</year>) <volume>6</volume>:<fpage>e662</fpage>&#x02013;<lpage>72</lpage>. doi: <pub-id pub-id-type="doi">10.1016/S2589-7500(24)00124-9</pub-id>, PMID: <pub-id pub-id-type="pmid">39179311</pub-id>
</mixed-citation></ref><ref id="ref10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mesk&#x000f3;</surname><given-names>B</given-names></name><name><surname>Topol</surname><given-names>EJ</given-names></name></person-group>. <article-title>The imperative for regulatory oversight of large language models (or generative AI) in healthcare</article-title>. <source>NPJ Digit Med</source>. (<year>2023</year>) <volume>6</volume>:<fpage>120</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41746-023-00873-0</pub-id>, PMID: <pub-id pub-id-type="pmid">37414860</pub-id>
</mixed-citation></ref><ref id="ref11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muralidharan</surname><given-names>V</given-names></name><name><surname>Adewale</surname><given-names>BA</given-names></name><name><surname>Huang</surname><given-names>CJ</given-names></name><name><surname>Nta</surname><given-names>MT</given-names></name><name><surname>Ademiju</surname><given-names>PO</given-names></name><name><surname>Pathmarajah</surname><given-names>P</given-names></name><etal/></person-group>. <article-title>A scoping review of reporting gaps in FDA-approved AI medical devices</article-title>. <source>NPJ Digit Med</source>. (<year>2024</year>) <volume>7</volume>:<fpage>273</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41746-024-01270-x</pub-id>, PMID: <pub-id pub-id-type="pmid">39362934</pub-id>
</mixed-citation></ref><ref id="ref12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warraich</surname><given-names>HJ</given-names></name><name><surname>Tazbaz</surname><given-names>T</given-names></name><name><surname>Califf</surname><given-names>RM</given-names></name></person-group>. <article-title>FDA perspective on the regulation of artificial intelligence in health care and biomedicine</article-title>. <source>JAMA</source>. (<year>2024</year>) <volume>333</volume>:<fpage>241</fpage>&#x02013;<lpage>7</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jama.2024.21451</pub-id>, PMID: <pub-id pub-id-type="pmid">39405330</pub-id>
</mixed-citation></ref><ref id="ref13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menz</surname><given-names>BD</given-names></name><name><surname>Kuderer</surname><given-names>NM</given-names></name><name><surname>Bacchi</surname><given-names>S</given-names></name><name><surname>Modi</surname><given-names>ND</given-names></name><name><surname>Chin-Yee</surname><given-names>B</given-names></name><name><surname>Hu</surname><given-names>T</given-names></name><etal/></person-group>. <article-title>Current safeguards, risk mitigation, and transparency measures of large language models against the generation of health disinformation: repeated cross sectional analysis</article-title>. <source>BMJ</source>. (<year>2024</year>) <volume>384</volume>:<fpage>e078538</fpage>. doi: <pub-id pub-id-type="doi">10.1136/bmj-2023-078538</pub-id>, PMID: <pub-id pub-id-type="pmid">38508682</pub-id>
</mixed-citation></ref><ref id="ref14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menz</surname><given-names>BD</given-names></name><name><surname>Modi</surname><given-names>ND</given-names></name><name><surname>Sorich</surname><given-names>MJ</given-names></name><name><surname>Hopkins</surname><given-names>AM</given-names></name></person-group>. <article-title>Health disinformation use case highlighting the urgent need for artificial intelligence vigilance: weapons of mass disinformation</article-title>. <source>JAMA Intern Med</source>. (<year>2024</year>) <volume>184</volume>:<fpage>92</fpage>&#x02013;<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamainternmed.2023.5947</pub-id>, PMID: <pub-id pub-id-type="pmid">37955873</pub-id>
</mixed-citation></ref><ref id="ref15"><label>15.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll1">The European Union Medical Device Regulation</collab></person-group>. (<year>2024</year>) Regulation (EU) 2017/745 (EU MDR). Available online at: <ext-link xlink:href="https://eumdr.com/" ext-link-type="uri">https://eumdr.com/</ext-link> (Accessed October 20, 2024).</mixed-citation></ref><ref id="ref16"><label>16.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll2">Therapeutic Goods Administration (TGA)</collab></person-group>: (<year>2024</year>) Artificial intelligence (AI) and medical device software. Available online at: <ext-link xlink:href="https://www.tga.gov.au/how-we-regulate/manufacturing/manufacture-medical-device/manufacture-specific-types-medical-devices/artificial-intelligence-ai-and-medical-device-software" ext-link-type="uri">https://www.tga.gov.au/how-we-regulate/manufacturing/manufacture-medical-device/manufacture-specific-types-medical-devices/artificial-intelligence-ai-and-medical-device-software</ext-link> (Accessed October 20, 2024).</mixed-citation></ref><ref id="ref17"><label>17.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll3">U.S. Food &#x00026; Drugs Administration</collab></person-group>. (<year>2024</year>). Artificial intelligence and machine learning (AI/ML)-enabled medical devices 2024. Available online at: <ext-link xlink:href="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices" ext-link-type="uri">https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices</ext-link> (Accessed October 20, 2024).</mixed-citation></ref><ref id="ref18"><label>18.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll4">Forbes</collab></person-group>. (<year>2024</year>). Dr. GPT 84% say ChatGPT Got Their Diagnosis Right. Available online at: <ext-link xlink:href="https://www.forbes.com/sites/johnkoetsier/2024/01/02/dr-gpt-84-say-chatgpt-got-their-diagnosis-right/" ext-link-type="uri">https://www.forbes.com/sites/johnkoetsier/2024/01/02/dr-gpt-84-say-chatgpt-got-their-diagnosis-right/</ext-link> (Accessed October 25, 2024).</mixed-citation></ref><ref id="ref19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayers</surname><given-names>JW</given-names></name><name><surname>Poliak</surname><given-names>A</given-names></name><name><surname>Dredze</surname><given-names>M</given-names></name><name><surname>Leas</surname><given-names>EC</given-names></name><name><surname>Zhu</surname><given-names>Z</given-names></name><name><surname>Kelley</surname><given-names>JB</given-names></name><etal/></person-group>. <article-title>Comparing physician and artificial intelligence Chatbot responses to patient questions posted to a public social media forum</article-title>. <source>JAMA Intern Med</source>. (<year>2023</year>) <volume>183</volume>:<fpage>589</fpage>&#x02013;<lpage>96</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamainternmed.2023.1838</pub-id>, PMID: <pub-id pub-id-type="pmid">37115527</pub-id>
</mixed-citation></ref><ref id="ref20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charlotte</surname><given-names>RB</given-names></name><name><surname>Cosima</surname><given-names>L</given-names></name><name><surname>Jens</surname><given-names>G</given-names></name><name><surname>Maria</surname><given-names>H</given-names></name><name><surname>Kenneth</surname><given-names>DM</given-names></name></person-group>. <article-title>Generative artificial intelligence in primary care: an online survey of UK general practitioners</article-title>. <source>BMJ Health Care Inform</source>. (<year>2024</year>) <volume>31</volume>:<fpage>e101102</fpage>. doi: <pub-id pub-id-type="doi">10.1136/bmjhci-2024-101102</pub-id>, PMID: <pub-id pub-id-type="pmid">39288998</pub-id>
</mixed-citation></ref><ref id="ref21"><label>21.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll5">OpenAI</collab></person-group>. (<year>2024</year>). OpenAI: Introducing the GPT store. Available online at: <ext-link xlink:href="https://openai.com/index/introducing-the-gpt-store/" ext-link-type="uri">https://openai.com/index/introducing-the-gpt-store/</ext-link> (Accessed September 2, 2024).</mixed-citation></ref><ref id="ref22"><label>22.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll6">European Commission: EUDAMED</collab></person-group>. (<year>2024</year>) European database on medical devices. Available online at: <ext-link xlink:href="https://ec.europa.eu/tools/eudamed/#/screen/home" ext-link-type="uri">https://ec.europa.eu/tools/eudamed/#/screen/home</ext-link> (Accessed October 20, 2024).</mixed-citation></ref><ref id="ref23"><label>23.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll7">TGA</collab></person-group>. (<year>2024</year>) Therapeutic goods administration (TGA): ARTG search visualisation tool. Available online at: <ext-link xlink:href="https://compliance.health.gov.au/artg/" ext-link-type="uri">https://compliance.health.gov.au/artg/</ext-link> (Accessed October 25, 2024).</mixed-citation></ref><ref id="ref24"><label>24.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll8">U.S. Food &#x00026; Drugs Administration (FDA)</collab></person-group>. (<year>2022</year>) Your clinical decision support software: is it a medical device? Available online at: <ext-link xlink:href="https://www.fda.gov/medical-devices/software-medical-device-samd/your-clinical-decision-support-software-it-medical-device" ext-link-type="uri">https://www.fda.gov/medical-devices/software-medical-device-samd/your-clinical-decision-support-software-it-medical-device</ext-link> (Accessed October 25, 2024).</mixed-citation></ref><ref id="ref25"><label>25.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll9">Therapeutic Goods Administration (TGA)</collab></person-group>: (<year>2024</year>) Excluded software, interpretation of software exclusion criteria. Available online at: <ext-link xlink:href="https://www.tga.gov.au/sites/default/files/2024-07/excluded-software.pdf" ext-link-type="uri">https://www.tga.gov.au/sites/default/files/2024-07/excluded-software.pdf</ext-link> (Accessed October 25, 2024).</mixed-citation></ref><ref id="ref26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reddy</surname><given-names>S</given-names></name><name><surname>Generative</surname><given-names>AI</given-names></name></person-group>. <article-title>In healthcare: an implementation science informed translational path on application, integration and governance</article-title>. <source>Implement Sci</source>. (<year>2024</year>) <volume>19</volume>:<fpage>27</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s13012-024-01357-9</pub-id>, PMID: <pub-id pub-id-type="pmid">38491544</pub-id>
</mixed-citation></ref><ref id="ref27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopkins</surname><given-names>AM</given-names></name><name><surname>Menz</surname><given-names>BD</given-names></name><name><surname>Sorich</surname><given-names>MJ</given-names></name></person-group>. <article-title>Potential of large language models as tools against medical disinformation&#x02014;reply</article-title>. <source>JAMA Intern Med</source>. (<year>2024</year>) <volume>184</volume>:<fpage>450</fpage>&#x02013;<lpage>1</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamainternmed.2024.0023</pub-id>, PMID: <pub-id pub-id-type="pmid">38407881</pub-id>
</mixed-citation></ref><ref id="ref28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tam</surname><given-names>TYC</given-names></name><name><surname>Sivarajkumar</surname><given-names>S</given-names></name><name><surname>Kapoor</surname><given-names>S</given-names></name><name><surname>Stolyar</surname><given-names>AV</given-names></name><name><surname>Polanska</surname><given-names>K</given-names></name><name><surname>McCarthy</surname><given-names>KR</given-names></name><etal/></person-group>. <article-title>A framework for human evaluation of large language models in healthcare derived from literature review</article-title>. <source>NPJ Digit Med</source>. (<year>2024</year>) <volume>7</volume>:<fpage>258</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41746-024-01258-7</pub-id>, PMID: <pub-id pub-id-type="pmid">39333376</pub-id>
</mixed-citation></ref><ref id="ref29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menz</surname><given-names>BD</given-names></name><name><surname>Kuderer</surname><given-names>NM</given-names></name><name><surname>Chin-Yee</surname><given-names>B</given-names></name><name><surname>Logan</surname><given-names>JM</given-names></name><name><surname>Rowland</surname><given-names>A</given-names></name><name><surname>Sorich</surname><given-names>MJ</given-names></name><etal/></person-group>. <article-title>Gender representation of health care professionals in large language model-generated stories</article-title>. <source>JAMA Netw Open</source>. (<year>2024</year>) <volume>7</volume>:<fpage>e2434997</fpage>&#x02013;<lpage>7</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.34997</pub-id>, PMID: <pub-id pub-id-type="pmid">39312237</pub-id>
</mixed-citation></ref><ref id="ref30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chow</surname><given-names>JCL</given-names></name><name><surname>Sanders</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>K</given-names></name></person-group>. <article-title>Impact of ChatGPT on medical chatbots as a disruptive technology</article-title>. <source>Front Artif Intell</source>. (<year>2023</year>) <volume>6</volume>:<fpage>1166014</fpage>. doi: <pub-id pub-id-type="doi">10.3389/frai.2023.1166014</pub-id>, PMID: <pub-id pub-id-type="pmid">37091303</pub-id>
</mixed-citation></ref><ref id="ref31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chow</surname><given-names>JCL</given-names></name><name><surname>Li</surname><given-names>K</given-names></name></person-group>. <article-title>Ethical considerations in human-centered AI: advancing oncology Chatbots through large language models</article-title>. <source>JMIR Bioinform Biotechnol</source>. (<year>2024</year>) <volume>5</volume>:<fpage>e64406</fpage>. doi: <pub-id pub-id-type="doi">10.2196/64406</pub-id>, PMID: <pub-id pub-id-type="pmid">39321336</pub-id>
</mixed-citation></ref><ref id="ref32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aykut</surname><given-names>A</given-names></name><name><surname>Sezenoz</surname><given-names>AS</given-names></name></person-group>. <article-title>Exploring the potential of code-free custom GPTs in ophthalmology: an early analysis of GPT store and user-Creator guidance</article-title>. <source>Ophthalmol Ther</source>. (<year>2024</year>) <volume>13</volume>:<fpage>2697</fpage>&#x02013;<lpage>713</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s40123-024-01014-w</pub-id>, PMID: <pub-id pub-id-type="pmid">39141071</pub-id>
</mixed-citation></ref><ref id="ref33"><label>33.</label><mixed-citation publication-type="other">(<year>2024</year>) AHPRA and the National Boards: What's an offence under the National law? Available online at: <ext-link xlink:href="https://www.ahpra.gov.au/Notifications/Reporting-a-criminal-offence/What-is-an-offence.aspx" ext-link-type="uri">https://www.ahpra.gov.au/Notifications/Reporting-a-criminal-offence/What-is-an-offence.aspx</ext-link> (Accessed October 24, 2024).</mixed-citation></ref><ref id="ref34"><label>34.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll10">UK Public General Acts</collab></person-group> (<year>2023</year>) Medical act 1983; section 49: penalty for pretending to be registered. Available online at: <ext-link xlink:href="https://www.legislation.gov.uk/ukpga/1983/54" ext-link-type="uri">https://www.legislation.gov.uk/ukpga/1983/54</ext-link> (Accessed October 24, 2024).</mixed-citation></ref><ref id="ref35"><label>35.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll11">European Union</collab></person-group> (<year>2024</year>) Directive 2005/36/ec of the european parliament and of the council; article 52 - use of professional titles. Available online at: <ext-link xlink:href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32005L0036" ext-link-type="uri">https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32005L0036</ext-link> (Accessed October 24, 2024).</mixed-citation></ref><ref id="ref36"><label>36.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll12">Federal Trade Commission</collab></person-group> (<year>2006</year>) Act: section 5 - unfair or deceptive acts or practices. Available online at: <ext-link xlink:href="https://www.ftc.gov/sites/default/files/documents/statutes/federal-trade-commission-act/ftc_act_incorporatingus_safe_web_act.pdf" ext-link-type="uri">https://www.ftc.gov/sites/default/files/documents/statutes/federal-trade-commission-act/ftc_act_incorporatingus_safe_web_act.pdf</ext-link> (Accessed October 24, 2024).</mixed-citation></ref><ref id="ref37"><label>37.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll13">Doctronic</collab></person-group>. (<year>2024</year>) Available online at: <ext-link xlink:href="https://www.doctronic.ai/" ext-link-type="uri">https://www.doctronic.ai/</ext-link> (Accessed October 24, 2024).</mixed-citation></ref></ref-list></back></article>