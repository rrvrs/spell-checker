<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Med (Lausanne)</journal-id><journal-id journal-id-type="iso-abbrev">Front Med (Lausanne)</journal-id><journal-id journal-id-type="publisher-id">Front. Med.</journal-id><journal-title-group><journal-title>Frontiers in Medicine</journal-title></journal-title-group><issn pub-type="epub">2296-858X</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC12098612</article-id><article-id pub-id-type="doi">10.3389/fmed.2025.1567440</article-id><article-categories><subj-group subj-group-type="heading"><subject>Medicine</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Global trends and hotspots in artificial intelligence for high myopia: a bibliometric analysis</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Wang</surname><given-names>Xuze</given-names></name><xref rid="fn0002" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2875646/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/software/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Wumaier</surname><given-names>Ailixiati</given-names></name><xref rid="fn0002" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/software/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Jun</given-names></name><uri xlink:href="https://loop.frontiersin.org/people/1596891/overview"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/></contrib><contrib contrib-type="author"><name><surname>Song</surname><given-names>Dejuan</given-names></name><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/></contrib><contrib contrib-type="author"><name><surname>Cai</surname><given-names>Yiting</given-names></name><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/></contrib><contrib contrib-type="author"><name><surname>Han</surname><given-names>Jin</given-names></name><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Han</surname><given-names>Wei</given-names></name><xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2065881/overview"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Fang</surname><given-names>Zhi</given-names></name><xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref><xref rid="fn0001" ref-type="author-notes">
<sup>&#x02021;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/1890802/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/software/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff><institution>Zhejiang Provincial Key Laboratory of Ophthalmology, Zhejiang Provincial Clinical Research Center for Eye Diseases, School of Medicine, Eye Center of Second Affiliated Hospital, Zhejiang Provincial Engineering Institute on Eye Diseases, Zhejiang University</institution>, <addr-line>Hangzhou</addr-line>, <country>China</country></aff><author-notes><fn fn-type="edited-by" id="fn0003"><p>Edited by: Shujun Wang, Hong Kong Polytechnic University, Hong Kong SAR, China</p></fn><fn fn-type="edited-by" id="fn0004"><p>Reviewed by: Arun Govindaiah, iHealthscreen Inc., United States</p><p>Nanxi Yu, Hong Kong Polytechnic University, Hong Kong SAR, China</p><p>Jun Zhu, Affiliated Eye Hospital to Wenzhou Medical University, China</p></fn><corresp id="c001">*Correspondence: Wei Han, <email>hanweidr@zju.edu.cn</email>; Zhi Fang, <email>angelfang1990@zju.edu.cn</email></corresp><fn fn-type="equal" id="fn0002"><p><sup>&#x02020;</sup>These authors have contributed equally to this work and share first authorship</p></fn><fn fn-type="other" id="fn0001"><p><sup>&#x02021;</sup>ORCID: Zhi Fang, <ext-link xlink:href="https://orcid.org/0000-0003-2008-9359" ext-link-type="uri">orcid.org/0000-0003-2008-9359</ext-link></p></fn></author-notes><pub-date pub-type="epub"><day>09</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>12</volume><elocation-id>1567440</elocation-id><history><date date-type="received"><day>27</day><month>1</month><year>2025</year></date><date date-type="accepted"><day>24</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2025 Wang, Wumaier, Wang, Song, Cai, Han, Han and Fang.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Wang, Wumaier, Wang, Song, Cai, Han, Han and Fang</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><sec id="sec1"><title>Purpose</title><p>This study aims to conduct a bibliometric analysis of global publications on the application of artificial intelligence (AI) in high myopia (HM).</p></sec><sec id="sec2"><title>Methods</title><p>We retrieved publications on AI in HM from the Web of Science Core Collection (WoSCC) database, MEDLINE and Chinese Science Citation Database (CSCD) with data up to 2024. The analysis focused on publication and citation trends, identifying key articles, influential countries, institutions, authors, and journals. Additionally, we explored research domains and emerging keywords.</p></sec><sec id="sec3"><title>Results</title><p>A total of 167 relevant publications were included. The first AI-related paper on HM was published in 2017, with a significant surge in 2021, followed by a consistent increase in publication and citation counts over the next 3 years. China emerged as the most productive country, with the most extensive international collaboration. East Asian authors dominated the top 10 most influential authors. Yang, Weihua and Investigative Ophthalmology &#x00026; Visual Science (IOVS) contributed the most publications among authors and institutions, respectively. Keyword analysis revealed that retinal imaging-related terms remained a consistent research focus, while newly emerging keywords included &#x0201c;automated detection&#x0201d; and &#x0201c;childhood.&#x0201d;</p></sec><sec id="sec4"><title>Conclusion</title><p>Recent advancements in AI applications for HM have been significant and are expected to continue. Future research will likely focus on multimodal imaging and improving algorithm accessibility. Our findings offered the first comprehensive overview of global research on AI in HM, thus providing valuable insights for researchers to understand the current status and future trends in this field.</p></sec></abstract><kwd-group><kwd>high myopia</kwd><kwd>artificial intelligence</kwd><kwd>global research</kwd><kwd>bibliometric analysis</kwd><kwd>data visualization</kwd></kwd-group><funding-group><funding-statement>The author(s) declare that financial support was received for the research and/or publication of this article. This work was supported by the Key Research and Development Program of Zhejiang Province (Award No. 2024C03205) and the National Natural Science Foundation of China (Award No. 82301163).</funding-statement></funding-group><counts><fig-count count="8"/><table-count count="4"/><equation-count count="0"/><ref-count count="96"/><page-count count="14"/><word-count count="9008"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Ophthalmology</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec5"><title>Introduction</title><p>Myopia is one of the significant global healthcare challenges, with high myopia (HM) being a particular concern (<xref rid="ref1" ref-type="bibr">1&#x02013;3</xref>). HM is defined as a condition in which the spherical equivalent refractive error is &#x02264; &#x02212;6.00 D when ocular accommodation is relaxed (<xref rid="ref4" ref-type="bibr">4</xref>). By 2050, HM is expected to affect 9.8% of the global population (<xref rid="ref5" ref-type="bibr">5</xref>). The axial elongation associated with HM increases the risk of structural changes in the posterior segment of the eye, including posterior staphyloma, myopic maculopathy, and HM-related optic neuropathy (<xref rid="ref3" ref-type="bibr">3</xref>, <xref rid="ref4" ref-type="bibr">4</xref>, <xref rid="ref6" ref-type="bibr">6</xref>). These changes may lead to a decline in best-corrected visual acuity (<xref rid="ref7" ref-type="bibr">7</xref>). Additionally, HM serves as a foundational ocular condition for many other eye diseases, complicating their diagnosis and treatment (<xref rid="ref6" ref-type="bibr">6&#x02013;9</xref>). Therefore, research into HM is of significant importance.</p><p>Artificial intelligence (AI) has gained significant global attention in recent years (<xref rid="ref10" ref-type="bibr">10</xref>). AI offers unique advantages in medical imaging analysis by enabling systems to extract valuable information from digital images for advanced analysis (<xref rid="ref11" ref-type="bibr">11</xref>, <xref rid="ref12" ref-type="bibr">12</xref>). Since ocular imaging is fundamental to ophthalmology, AI holds enormous potential in this field (<xref rid="ref11" ref-type="bibr">11</xref>, <xref rid="ref13" ref-type="bibr">13&#x02013;15</xref>). AI-based large language models (LLMs) also contribute to the equitable distribution of ophthalmic healthcare resources and community monitoring of chronic eye diseases (<xref rid="ref16" ref-type="bibr">16</xref>). HM research is especially well-suited for AI, with applications like fundus image analysis for HM-related retinopathy and deep learning models (DLMs) predicting HM progression and complications (<xref rid="ref11" ref-type="bibr">11&#x02013;13</xref>, <xref rid="ref16" ref-type="bibr">16</xref>). In fact, numerous studies have already been published in this area.</p><p>Bibliometric analysis is a statistical method that quantitatively assesses research achievements and identifies hotspots by evaluating the research status of countries, institutions, authors, and journals (<xref rid="ref17" ref-type="bibr">17</xref>, <xref rid="ref18" ref-type="bibr">18</xref>). With a history spanning over a century, bibliometric analysis has been widely applied in medicine to explore its development and emerging trends (<xref rid="ref19" ref-type="bibr">19</xref>, <xref rid="ref20" ref-type="bibr">20</xref>). While bibliometric studies on myopia and HM have been conducted (<xref rid="ref21" ref-type="bibr">21</xref>, <xref rid="ref22" ref-type="bibr">22</xref>), there is a lack of bibliometric analysis on AI in HM. This gap has become even more pronounced as AI-related HM research has surged in recent years, making it challenging to identify key areas and current trends (<xref rid="ref23" ref-type="bibr">23&#x02013;25</xref>). This highlights the urgent need for a bibliometric analysis of AI-related HM research. Therefore, our study aims to address this challenge by retrieving relevant papers from the Web of Science Core Collection (WoSCC), MEDLINE and Chinese Science Citation Database (CSCD), providing an overview of global AI-related HM research, identifying key themes, and predicting future trends. These insights are valuable for ophthalmic clinicians and researchers.</p></sec><sec sec-type="methods" id="sec6"><title>Methods</title><sec id="sec7"><title>Data collection</title><p>The WoSCC is known for its rigorous selection criteria and high-quality coverage across multiple disciplines, including journals, conference papers, and patents (<xref rid="ref26" ref-type="bibr">26</xref>, <xref rid="ref27" ref-type="bibr">27</xref>). MEDLINE, as a core component of PubMed, offers over 31 million biomedical references and is widely recognized in life sciences research (<xref rid="ref28" ref-type="bibr">28</xref>). The CSCD provides structured and accurate data on Chinese academic output (<xref rid="ref27" ref-type="bibr">27</xref>). All three databases are considered ideal for bibliometric analysis due to their authority, broad coverage, and data quality. To search for relevant data, we combined at least one keyword related to HM and at least one keyword related to AI to form the query. The detailed query formulation was as follows: TS&#x0202f;=&#x0202f;(&#x0201c;AI&#x0201d; OR &#x0201c;artificial intelligence&#x0201d; OR &#x0201c;intelligent&#x0201d; OR &#x0201c;data learning&#x0201d; OR &#x0201c;robotic*&#x0201d; OR &#x0201c;computer vision&#x0201d; OR &#x0201c;machine learning&#x0201d; OR &#x0201c;deep learning&#x0201d; OR &#x0201c;deep network*&#x0201d; OR &#x0201c;neural learning&#x0201d; OR &#x0201c;algorithm&#x0201d; OR &#x0201c;neural network*&#x0201d; OR &#x0201c;expert* system*&#x0201d; OR &#x0201c;large language model*&#x0201d; OR &#x0201c;LLM&#x0201d; OR &#x0201c;multimodal model*&#x0201d; OR &#x0201c;multimodal learning&#x0201d; OR &#x0201c;transformer model*&#x0201d; OR &#x0201c;AI* classification&#x0201d; OR &#x0201c;image segmentation&#x0201d; OR &#x0201c;domain adaptation&#x0201d; OR &#x0201c;model generalization&#x0201d; OR &#x0201c;feature extraction&#x0201d; OR &#x0201c;object detection&#x0201d; OR &#x0201c;model interpretability&#x0201d; OR &#x0201c;transfer learning&#x0201d;) AND TS&#x0202f;=&#x0202f;(&#x0201c;high myopia&#x0201d; OR &#x0201c;pathologic myopia&#x0201d; OR &#x0201c;degenerative myopia&#x0201d; OR &#x0201c;progressive myopia&#x0201d; OR &#x0201c;myopic maculopathy&#x0201d; OR &#x0201c;myopic choroidopathy&#x0201d; OR &#x0201c;myopic degeneration&#x0201d; OR &#x0201c;highly myopic eyes&#x0201d; OR &#x0201c;high myopic patients&#x0201d; OR &#x0201c;high degree myopia&#x0201d; OR &#x0201c;severe myopia&#x0201d;). The search timeframe was extended until December 31, 2024, and the document types were limited to articles and proceedings papers. The final search was conducted on April 14, 2025. A total of 356 documents were identified for further screening.</p></sec><sec id="sec8"><title>Data screening</title><p>To exclude irrelevant documents from the retrieved set, we established the following inclusion criteria: (i) involvement of AI technology, including deep learning, machine learning, and LLM, etc.; (ii) the focus should be on HM or its related complications, diagnoses, and treatments, etc. If the study included multiple diseases, HM condition should be the primary focus. After a careful review of their titles and abstracts by two ophthalmologists, Wang Xuze and Fang Zhi, 167 documents were included for the bibliometric analysis.</p></sec><sec id="sec9"><title>Bibliometric analysis</title><p>All the data were extracted from the three aforementioned databases, including metrics of publication numbers, countries and regions, authors, citations, self-citations, and H-indexes. The H-index serves as a reference metric, reflecting the impact of a researcher, country, institution, or journal on the development of a specific scientific field (<xref rid="ref29" ref-type="bibr">29</xref>). Descriptive indices were extracted from databases, and the co-occurrence network was constructed using VOSviewer (software, version 1.6.20) (<xref rid="ref30" ref-type="bibr">30</xref>). R (programming language, version 4.4.2) and its Biblioshiny tool (package, version 4.1.2) were employed to create word-cloud maps and analyze word trends (<xref rid="ref31" ref-type="bibr">31</xref>). CiteSpace (software, version 6.3.1) was used to generate keyword burst detection maps (<xref rid="ref32" ref-type="bibr">32</xref>).</p></sec></sec><sec sec-type="results" id="sec10"><title>Results</title><sec id="sec11"><title>Analysis of publications and citations</title><p>Based on the search strategy and inclusion criteria, 167 documents were included (<xref rid="fig1" ref-type="fig">Figure 1</xref>), consisting of 144 articles and 23 conference proceedings, published between 2017 and 2024. We conducted a second review of 32 articles published before 2017 from the results retrieved using the above search strategy. They were excluded since HM was not the primary focus or lacking of AI. <xref rid="fig2" ref-type="fig">Figure 2</xref> illustrated the annual trends in publications and citations related to AI in HM. Before 2020, research on AI in HM was limited, but there was a significant increase in publications since then, particularly in the past 3 years, with annual publications consistently exceeding 30. The total number of citations reached 1,402, with an average of 8.40 citations per article and an H-index of 20. Polynomial regression analysis was performed to model the publication and citation trends. The fitting curves, y&#x0202f;=&#x0202f;0.3393&#x000d7;2-1363.9x&#x0202f;+&#x0202f;1E+06 (<italic>R</italic><sup>2</sup>&#x0202f;=&#x0202f;0.9248) and y&#x0202f;=&#x0202f;15.964&#x000d7;2-64431x&#x0202f;+&#x0202f;7E+07 (<italic>R</italic><sup>2</sup>&#x0202f;=&#x0202f;0.9738), represented the publication and citation numbers over time, respectively. Both trends were similar, indicating that AI in the HM field attracted widespread attention from researchers in the past 5 years, with rapid development now reaching a stable phase.</p><fig position="float" id="fig1"><label>Figure 1</label><caption><p>Detailed flowchart of this study.</p></caption><graphic xlink:href="fmed-12-1567440-g001" position="float"/></fig><fig position="float" id="fig2"><label>Figure 2</label><caption><p>Trends in the number of AI-related publications and citations in HM.</p></caption><graphic xlink:href="fmed-12-1567440-g002" position="float"/></fig><p><xref rid="tab1" ref-type="table">Table 1</xref> highlighted the 10 most-cited papers in the field. The most impactful study, conducted by Yizhi Liu and his team at Sun Yat-sen University, was published in 2018 in PLOS Medicine (<xref rid="ref33" ref-type="bibr">33</xref>). This paper detailed the application of big data and machine learning technology to develop an algorithm capable of predicting the onset and prognosis of HM among Chinese school-aged children. The remaining top 10 most-cited papers primarily focused on the retinal conditions associated with HM and related AI applications.</p><table-wrap position="float" id="tab1"><label>Table 1</label><caption><p>Top 10 papers with the most citations relevant to AI applications in HM.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Title</th><th align="left" valign="top" rowspan="1" colspan="1">Corresponding authors</th><th align="left" valign="top" rowspan="1" colspan="1">Journal</th><th align="left" valign="top" rowspan="1" colspan="1">Publication year</th><th align="left" valign="top" rowspan="1" colspan="1">Annual citations</th><th align="left" valign="top" rowspan="1" colspan="1">Total citations</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Prediction of myopia development among Chinese school-aged children using refraction data from electronic medical records: A retrospective, multicenter machine learning study</td><td align="left" valign="top" rowspan="1" colspan="1">Liu, YZ</td><td align="left" valign="top" rowspan="1" colspan="1">PLOS MEDICINE</td><td align="left" valign="top" rowspan="1" colspan="1">2018/11</td><td align="left" valign="top" rowspan="1" colspan="1">14.5</td><td align="left" valign="top" rowspan="1" colspan="1">113</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Retinal photograph-based deep learning algorithms for myopia and a blockchain platform to facilitate artificial intelligence medical research: a retrospective multicohort study</td><td align="left" valign="top" rowspan="1" colspan="1">Ting, DSW</td><td align="left" valign="top" rowspan="1" colspan="1">LANCET DIGITAL HEALTH</td><td align="left" valign="top" rowspan="1" colspan="1">2021/5</td><td align="left" valign="top" rowspan="1" colspan="1">20</td><td align="left" valign="top" rowspan="1" colspan="1">91</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Hybrid Intelligence-Driven Medical Image Recognition for Remote Patient Diagnosis in Internet of Medical Things</td><td align="left" valign="top" rowspan="1" colspan="1">Yu, KP</td><td align="left" valign="top" rowspan="1" colspan="1">IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</td><td align="left" valign="top" rowspan="1" colspan="1">2022/12</td><td align="left" valign="top" rowspan="1" colspan="1">23.5</td><td align="left" valign="top" rowspan="1" colspan="1">91</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Association Between Optic Nerve Head Deformation and Retinal Microvasculature in High Myopia</td><td align="left" valign="top" rowspan="1" colspan="1">Park, SW</td><td align="left" valign="top" rowspan="1" colspan="1">AMERICAN JOURNAL OF OPHTHALMOLOGY</td><td align="left" valign="top" rowspan="1" colspan="1">2018/4</td><td align="left" valign="top" rowspan="1" colspan="1">7.75</td><td align="left" valign="top" rowspan="1" colspan="1">59</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Deep Learning Approach for Automated Detection of Myopic Maculopathy and Pathologic Myopia in Fundus Images</td><td align="left" valign="top" rowspan="1" colspan="1">Ohno-Matsui, K</td><td align="left" valign="top" rowspan="1" colspan="1">OPHTHALMOLOGY RETINA</td><td align="left" valign="top" rowspan="1" colspan="1">2021/12</td><td align="left" valign="top" rowspan="1" colspan="1">10.6</td><td align="left" valign="top" rowspan="1" colspan="1">50</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Development and validation of a deep learning system to screen vision-threatening conditions in high myopia using optical coherence tomography images</td><td align="left" valign="top" rowspan="1" colspan="1">Lin, HT</td><td align="left" valign="top" rowspan="1" colspan="1">BRITISH JOURNAL OF OPHTHALMOLOGY</td><td align="left" valign="top" rowspan="1" colspan="1">2022/5</td><td align="left" valign="top" rowspan="1" colspan="1">11.25</td><td align="left" valign="top" rowspan="1" colspan="1">45</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Pathological myopia classification with simultaneous lesion segmentation using deep learning</td><td align="left" valign="top" rowspan="1" colspan="1">De Boever, P</td><td align="left" valign="top" rowspan="1" colspan="1">COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE</td><td align="left" valign="top" rowspan="1" colspan="1">2021/2</td><td align="left" valign="top" rowspan="1" colspan="1">9</td><td align="left" valign="top" rowspan="1" colspan="1">41</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Accuracy of a deep convolutional neural network in the detection of myopic macular diseases using swept-source optical coherence tomography</td><td align="left" valign="top" rowspan="1" colspan="1">Mitamura, Y</td><td align="left" valign="top" rowspan="1" colspan="1">PLOS ONE</td><td align="left" valign="top" rowspan="1" colspan="1">2020/4</td><td align="left" valign="top" rowspan="1" colspan="1">7.6</td><td align="left" valign="top" rowspan="1" colspan="1">35</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Accuracy of Artificial Intelligence Formulas and Axial Length Adjustments for Highly Myopic Eyes</td><td align="left" valign="top" rowspan="1" colspan="1">Wu, MX</td><td align="left" valign="top" rowspan="1" colspan="1">AMERICAN JOURNAL OF OPHTHALMOLOGY</td><td align="left" valign="top" rowspan="1" colspan="1">2021/3</td><td align="left" valign="top" rowspan="1" colspan="1">6.33</td><td align="left" valign="top" rowspan="1" colspan="1">35</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">AI-Model for Identifying Pathologic Myopia Based on Deep Learning Algorithms of Myopic Maculopathy Classification and &#x0201c;Plus&#x0201d; Lesion Detection in Fundus Images</td><td align="left" valign="top" rowspan="1" colspan="1">Han, W</td><td align="left" valign="top" rowspan="1" colspan="1">FRONTIERS IN CELL AND DEVELOPMENTAL BIOLOGY</td><td align="left" valign="top" rowspan="1" colspan="1">2021/10</td><td align="left" valign="top" rowspan="1" colspan="1">7</td><td align="left" valign="top" rowspan="1" colspan="1">31</td></tr></tbody></table></table-wrap></sec><sec id="sec12"><title>Analysis of top productive countries and their collaboration networks</title><p>A total of 29 countries contributed to the research on this topic. Mainland China led with 111 publications (66.5%), followed by the United States with 20 papers (12.0%) and Singapore with 18 papers (10.8%). <xref rid="fig3" ref-type="fig">Figure 3</xref> showed the publication trends of AI-related HM research in the top 3 productive countries. It highlighted that China experienced the fastest increase in the number of publications since 2020. This trend indicated that China was likely to maintain its leadership in this field, with a continued and steady rise in publication numbers.</p><fig position="float" id="fig3"><label>Figure 3</label><caption><p>Publication trends and prediction curve of global and leading countries in AI-related HM research. This figure uses full counting, meaning each country listed in a paper contributes a weight of 1.</p></caption><graphic xlink:href="fmed-12-1567440-g003" position="float"/></fig><p>Co-occurrence analysis of countries was also performed, revealing five distinct clusters (<xref rid="fig4" ref-type="fig">Figure 4</xref>): (1) Mainland China, the USA, and Australia; (2) the UK, Italy, South Korea, and France; (3) Austria, Germany, Japan, Russia, Singapore, Switzerland, and Taiwan China; (4) Saudi Arabia, Pakistan, and Egypt; (5) Canada and India. Countries with limited international collaboration were not represented in the network.</p><fig position="float" id="fig4"><label>Figure 4</label><caption><p>Co-authorship network visualization map of countries and regions. Each node represents a country or region, with the circle size reflecting the number of publications. Connecting lines represent collaboration between countries and regions.</p></caption><graphic xlink:href="fmed-12-1567440-g004" position="float"/></fig></sec><sec id="sec13"><title>Analysis of top productive institutions and their collaboration networks</title><p>A total of 318 institutions participated in the research. Notably, Capital Medical University (22, 13.2%), National University of Singapore (16, 9.6%), Singapore National Eye Center (16, 9.6%), and Shanghai Jiao Tong University (16, 9.6%) made substantial contributions. <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 1</xref> presented the co-authorship network of institutions. While there was frequent collaboration within institutions, institutional collaborations across different countries remained less cohesive. <xref rid="fig5" ref-type="fig">Figure 5</xref> offered a closer look at the cooperation among the top productive institutions.</p><fig position="float" id="fig5"><label>Figure 5</label><caption><p>Chord diagram of co-authorship among the top institutions. Node data are arranged radially along the circumference, with weighted arcs (indicating collaboration strength) connecting the nodes.</p></caption><graphic xlink:href="fmed-12-1567440-g005" position="float"/></fig></sec><sec id="sec14"><title>The leading journals, and authors</title><p>The journals publishing AI-related HM papers were quite diverse (<xref rid="tab2" ref-type="table">Table 2</xref>). The journal Investigative Ophthalmology and Visual Science (IOVS) published the highest number of papers (12, 7.2%), followed by Translational Vision Science and Technology (TVST) and Frontiers in Medicine, with 11 (6.6%) and 6 (3.6%) publications, respectively. Among the top 10 journals, 8 were ranked Q1 in JCR (2023). Nearly half of the AI-related HM papers were published in ophthalmology journals (<xref rid="tab3" ref-type="table">Table 3</xref>).</p><table-wrap position="float" id="tab2"><label>Table 2</label><caption><p>Top 10 productive journals ranked by publication count.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Source title</th><th align="left" valign="top" rowspan="1" colspan="1">Record count (%)</th><th align="left" valign="top" rowspan="1" colspan="1">Citations</th><th align="left" valign="top" rowspan="1" colspan="1">H-index</th><th align="left" valign="top" rowspan="1" colspan="1">IF (2023)</th><th align="left" valign="top" rowspan="1" colspan="1">JCR (2023)</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Investigative Ophthalmology and Visual Science</td><td align="left" valign="top" rowspan="1" colspan="1">12 (7.19)</td><td align="left" valign="top" rowspan="1" colspan="1">51</td><td align="left" valign="top" rowspan="1" colspan="1">4</td><td align="left" valign="top" rowspan="1" colspan="1">5.0</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Translational Vision Science and Technology</td><td align="left" valign="top" rowspan="1" colspan="1">11 (6.59)</td><td align="left" valign="top" rowspan="1" colspan="1">124</td><td align="left" valign="top" rowspan="1" colspan="1">6</td><td align="left" valign="top" rowspan="1" colspan="1">2.6</td><td align="left" valign="top" rowspan="1" colspan="1">Q2</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Frontiers in Medicine</td><td align="left" valign="top" rowspan="1" colspan="1">6 (3.59)</td><td align="left" valign="top" rowspan="1" colspan="1">37</td><td align="left" valign="top" rowspan="1" colspan="1">4</td><td align="left" valign="top" rowspan="1" colspan="1">3.1</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Scientific Reports</td><td align="left" valign="top" rowspan="1" colspan="1">6 (3.59)</td><td align="left" valign="top" rowspan="1" colspan="1">80</td><td align="left" valign="top" rowspan="1" colspan="1">4</td><td align="left" valign="top" rowspan="1" colspan="1">3.8</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Eye</td><td align="left" valign="top" rowspan="1" colspan="1">5 (2.99)</td><td align="left" valign="top" rowspan="1" colspan="1">39</td><td align="left" valign="top" rowspan="1" colspan="1">3</td><td align="left" valign="top" rowspan="1" colspan="1">2.8</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Journal of Translational Medicine</td><td align="left" valign="top" rowspan="1" colspan="1">4 (2.40)</td><td align="left" valign="top" rowspan="1" colspan="1">17</td><td align="left" valign="top" rowspan="1" colspan="1">3</td><td align="left" valign="top" rowspan="1" colspan="1">6.1</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Frontiers in Cell and Developmental Biology</td><td align="left" valign="top" rowspan="1" colspan="1">4 (2.40)</td><td align="left" valign="top" rowspan="1" colspan="1">54</td><td align="left" valign="top" rowspan="1" colspan="1">4</td><td align="left" valign="top" rowspan="1" colspan="1">4.6</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">American Journal of Ophthalmology</td><td align="left" valign="top" rowspan="1" colspan="1">4 (2.40)</td><td align="left" valign="top" rowspan="1" colspan="1">94</td><td align="left" valign="top" rowspan="1" colspan="1">2</td><td align="left" valign="top" rowspan="1" colspan="1">4.1</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Eye and Vision</td><td align="left" valign="top" rowspan="1" colspan="1">4 (2.40)</td><td align="left" valign="top" rowspan="1" colspan="1">25</td><td align="left" valign="top" rowspan="1" colspan="1">2</td><td align="left" valign="top" rowspan="1" colspan="1">4.1</td><td align="left" valign="top" rowspan="1" colspan="1">Q1</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">International Journal of Ophthalmology</td><td align="left" valign="top" rowspan="1" colspan="1">4 (2.40)</td><td align="left" valign="top" rowspan="1" colspan="1">8</td><td align="left" valign="top" rowspan="1" colspan="1">3</td><td align="left" valign="top" rowspan="1" colspan="1">1.9</td><td align="left" valign="top" rowspan="1" colspan="1">Q2</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">BMC Ophthalmology</td><td align="left" valign="top" rowspan="1" colspan="1">4 (2.40)</td><td align="left" valign="top" rowspan="1" colspan="1">7</td><td align="left" valign="top" rowspan="1" colspan="1">2</td><td align="left" valign="top" rowspan="1" colspan="1">1.7</td><td align="left" valign="top" rowspan="1" colspan="1">Q3</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tab3"><label>Table 3</label><caption><p>Top 10 Web of Science categories of journals on AI-related HM research.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Field: Web of Science categories</th><th align="left" valign="top" rowspan="1" colspan="1">Record count (%)</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Ophthalmology</td><td align="left" valign="top" rowspan="1" colspan="1">71 (42.52)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Computer Science</td><td align="left" valign="top" rowspan="1" colspan="1">26 (15.57)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Engineering</td><td align="left" valign="top" rowspan="1" colspan="1">19 (11.38)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">General Internal Medicine</td><td align="left" valign="top" rowspan="1" colspan="1">18 (10.78)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Research Experimental Medicine</td><td align="left" valign="top" rowspan="1" colspan="1">12 (7.19)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Radiology Nuclear Medicine Medical Imaging</td><td align="left" valign="top" rowspan="1" colspan="1">11 (6.59)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Science Technology Other Topics</td><td align="left" valign="top" rowspan="1" colspan="1">11 (6.59)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Medical Informatics</td><td align="left" valign="top" rowspan="1" colspan="1">6 (3.59)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Imaging Science Photographic Technology</td><td align="left" valign="top" rowspan="1" colspan="1">5 (2.99)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Mathematical Computational Biology</td><td align="left" valign="top" rowspan="1" colspan="1">5 (2.99)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Neurosciences Neurology</td><td align="left" valign="top" rowspan="1" colspan="1">5 (2.99)</td></tr></tbody></table></table-wrap><p>The top 10 authors in this field were listed in <xref rid="tab4" ref-type="table">Table 4</xref> according to the number of publications. The leading contributor in this field was Yang Weihua from Shenzhen Eye Hospital, China, with 10 publications (5.99%) and 84 citations. Closely following was Daniel Ting from the Singapore National Eye Centre, who published 8 papers (5.06%) and received 190 citations in total. Asian authors made up the majority of the top 10 authors list. The cooperation between authors was illustrated in <xref rid="SM2" ref-type="supplementary-material">Supplementary Figure 2</xref>, which was generated based on the Author Contribution Index to minimize potential bias caused by differences in author order (<xref rid="ref34" ref-type="bibr">34</xref>). Although collaboration among authors was generally limited, it was clear that authors from the same country tended to collaborate more closely with one another.</p><table-wrap position="float" id="tab4"><label>Table 4</label><caption><p>Top 10 authors ranked by publication count.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Author</th><th align="left" valign="top" rowspan="1" colspan="1">Country</th><th align="left" valign="top" rowspan="1" colspan="1">Latest affiliation</th><th align="left" valign="top" rowspan="1" colspan="1">Publications (%)</th><th align="left" valign="top" rowspan="1" colspan="1">Citations</th><th align="left" valign="top" rowspan="1" colspan="1">Citations per item</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Yang, Weihua</td><td align="left" valign="top" rowspan="1" colspan="1">China</td><td align="left" valign="top" rowspan="1" colspan="1">Shenzhen Eye Hospital</td><td align="left" valign="top" rowspan="1" colspan="1">10 (5.99)</td><td align="left" valign="top" rowspan="1" colspan="1">84</td><td align="left" valign="top" rowspan="1" colspan="1">8.4</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ting, Daniel</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore National Eye Centre</td><td align="left" valign="top" rowspan="1" colspan="1">8 (5.06)</td><td align="left" valign="top" rowspan="1" colspan="1">190</td><td align="left" valign="top" rowspan="1" colspan="1">23.75</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ohno-Matsui, Kyoko</td><td align="left" valign="top" rowspan="1" colspan="1">Japan</td><td align="left" valign="top" rowspan="1" colspan="1">Tokyo Medical and Dental University</td><td align="left" valign="top" rowspan="1" colspan="1">7 (4.43)</td><td align="left" valign="top" rowspan="1" colspan="1">181</td><td align="left" valign="top" rowspan="1" colspan="1">25.86</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Wong, Tien Yin</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore National Eye Centre</td><td align="left" valign="top" rowspan="1" colspan="1">7 (4.43)</td><td align="left" valign="top" rowspan="1" colspan="1">185</td><td align="left" valign="top" rowspan="1" colspan="1">26.43</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Jonas, Jost B.</td><td align="left" valign="top" rowspan="1" colspan="1">Germany</td><td align="left" valign="top" rowspan="1" colspan="1">Heidelberg University</td><td align="left" valign="top" rowspan="1" colspan="1">7 (4.43)</td><td align="left" valign="top" rowspan="1" colspan="1">107</td><td align="left" valign="top" rowspan="1" colspan="1">15.29</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Chen, Qiuying</td><td align="left" valign="top" rowspan="1" colspan="1">China</td><td align="left" valign="top" rowspan="1" colspan="1">Shanghai Jiao Tong University</td><td align="left" valign="top" rowspan="1" colspan="1">7 (4.43)</td><td align="left" valign="top" rowspan="1" colspan="1">41</td><td align="left" valign="top" rowspan="1" colspan="1">5.86</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Xu, Xun</td><td align="left" valign="top" rowspan="1" colspan="1">China</td><td align="left" valign="top" rowspan="1" colspan="1">Shanghai Jiao Tong University</td><td align="left" valign="top" rowspan="1" colspan="1">7 (4.43)</td><td align="left" valign="top" rowspan="1" colspan="1">36</td><td align="left" valign="top" rowspan="1" colspan="1">5.14</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Saw, Seang-Mei</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore National Eye Centre</td><td align="left" valign="top" rowspan="1" colspan="1">6 (3.80)</td><td align="left" valign="top" rowspan="1" colspan="1">190</td><td align="left" valign="top" rowspan="1" colspan="1">31.67</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Hoang, Quan V.</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore National Eye Centre</td><td align="left" valign="top" rowspan="1" colspan="1">6 (3.80)</td><td align="left" valign="top" rowspan="1" colspan="1">139</td><td align="left" valign="top" rowspan="1" colspan="1">23.17</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Marcus Ang</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore National Eye Centre</td><td align="left" valign="top" rowspan="1" colspan="1">6 (3.80)</td><td align="left" valign="top" rowspan="1" colspan="1">133</td><td align="left" valign="top" rowspan="1" colspan="1">22.17</td></tr></tbody></table></table-wrap><p>We further analyzed the relationships among the top five countries, journals, and authors, and visualized the results with a three-field plot (<xref rid="fig6" ref-type="fig">Figure 6</xref>). This plot revealed the journal preferences among different countries and authors.</p><fig position="float" id="fig6"><label>Figure 6</label><caption><p>Three-field plot analysis displaying the journal preferences of authors from different countries. The three fields represent (1) AU_CO: Country, (2) SO: Source Journal, and (3) AU: Authors. The width of the nodes indicates the number of publications, while the width of the connecting lines reflects the level of collaboration.</p></caption><graphic xlink:href="fmed-12-1567440-g006" position="float"/></fig></sec><sec id="sec15"><title>Research hotspots</title><p>Keyword analysis identified the most frequently used terms and their connections within the field of AI-related HM research. Among 489 automatically recognized keywords we focused on those that appeared more than five times in the included publications. After merging duplicates and excluding irrelevant terms 40 keywords were identified. These were categorized into four primary clusters based on their co-occurrence frequencies (<xref rid="SM3" ref-type="supplementary-material">Supplementary Figure 3</xref>): an AI-focused cluster (red) an epidemiology-related cluster (green) an anatomy-related cluster (yellow) and a cluster associated with HM-related diseases (blue).</p><p>To illustrate the most frequently used keywords, we created word clouds for two time periods: 2017&#x02013;2022 (<xref rid="fig7" ref-type="fig">Figure 7A</xref>) and 2023&#x02013;2024 (<xref rid="fig7" ref-type="fig">Figure 7B</xref>). &#x0201c;High myopia&#x0201d; and &#x0201c;artificial intelligence&#x0201d; were the most dominant keywords throughout the entire period, followed by &#x0201c;deep learning&#x0201d; and &#x0201c;fundus image.&#x0201d; Before 2022, key topics also included &#x0201c;pathologic myopia,&#x0201d; &#x0201c;optical coherence tomography (OCT),&#x0201d; &#x0201c;convolutional neural network,&#x0201d; and &#x0201c;myopic maculopathy.&#x0201d; After 2022, &#x0201c;myopic maculopathy&#x0201d; gained increased attention, while new keywords such as &#x0201c;screening,&#x0201d; &#x0201c;optical coherence tomography angiography (OCTA),&#x0201d; &#x0201c;fundus tessellated density&#x0201d; and &#x0201c;intraocular lens (IOL) power calculation&#x0201d; emerged. We also extracted the most common keywords to generate a trend topics plot using the bibliometrix package in R (<xref rid="SM4" ref-type="supplementary-material">Supplementary Figure 4</xref>).</p><fig position="float" id="fig7"><label>Figure 7</label><caption><p><bold>(A)</bold> Word cloud of the most frequent keywords from 2017 to 2022. <bold>(B)</bold> Word cloud of the most frequent keywords from 2023 to 2024.</p></caption><graphic xlink:href="fmed-12-1567440-g007" position="float"/></fig><p>To further understand when these research hotspots emerged and how they evolved, <xref rid="fig8" ref-type="fig">Figure 8</xref> was generated to display the burst strength of Title-Abstract-Keywords (TS) across different periods. The findings indicated three distinct research focus periods: before 2020 (blood flow and pathological myopia), 2020&#x02013;2022 (biometry, retinopathy, progression, deep convolutional neural network and automatic segmentation), and 2022&#x02013;2024 (automated detection, age and childhood myopia). These findings aligned generally with the trends identified in the trend topic results above.</p><fig position="float" id="fig8"><label>Figure 8</label><caption><p>Burst map of Title-Abstract-Keywords. The numerical columns display the relative burst strength, start, and end times. In the line graph, the red portion represents the burst duration for each time series.</p></caption><graphic xlink:href="fmed-12-1567440-g008" position="float"/></fig></sec></sec><sec sec-type="discussion" id="sec16"><title>Discussion</title><p>This study explored AI research in HM by analyzing the trend of publications, publishing patterns, research activity characteristics, and emerging research hotspots through bibliometric data.</p><p>The rise in scientific publications and citations often reflects advancements in a specific research area. Our analysis indicated that the first AI-related HM paper was published in 2017, with low publication activity over the next few years (fewer than 10 papers per year). However, a significant increase occurred in 2021 (a 300% rise), followed by steady annual growth. According to our prediction model, this upward trend was expected to continue, reaching a plateau around 2028. This growth could be attributed to the rapid advancement of AI technologies and the increasing interest in their application to ophthalmology (<xref rid="ref10" ref-type="bibr">10</xref>, <xref rid="ref16" ref-type="bibr">16</xref>). Additionally, the rise may also be linked to the recent global rise in HM incidence and the growing attention to HM and its complications (<xref rid="ref2" ref-type="bibr">2</xref>, <xref rid="ref35" ref-type="bibr">35</xref>). Since 2022, publication levels remained consistently high (over 30 papers annually), potentially influenced by the release of ChatGPT in that year, which sparked broader interest in AI technologies and fueled the growth of &#x0201c;AI+&#x0201d; academic research (<xref rid="ref36" ref-type="bibr">36</xref>, <xref rid="ref37" ref-type="bibr">37</xref>), including AI-powered disease detection (<xref rid="ref38" ref-type="bibr">38</xref>), personalized treatment strategies (<xref rid="ref39" ref-type="bibr">39</xref>), and drug development (<xref rid="ref39" ref-type="bibr">39</xref>).</p><p>The most influential paper in this field was published by Liu YZ and his team in 2018 (<xref rid="ref33" ref-type="bibr">33</xref>). It marked the first application of machine learning in China to analyze real-world data and develop an algorithm for predicting the onset of HM in school-aged children. The study&#x02019;s high citation rate was largely due to its practical impact, as it demonstrated how big data and machine learning could enhance the prediction of HM outcomes using large-scale electronic health records. Notably, 7 of the top 10 most influential papers in this area involved AI applications for analyzing retinal images related to HM (<xref rid="ref40" ref-type="bibr">40&#x02013;46</xref>). This further suggests that fundus-related research is a key focus in the application of AI to the field of HM.</p><p>The volume of publications from a country or region often reflects its interest and expertise in a particular research area. In the field of AI-related HM studies, China led significantly (111, 66.5%), according to statistics from the WoS intrinsic toolkits, and was expected to maintain its dominance. This can be attributed to the high prevalence of HM in East Asian countries like China (<xref rid="ref47" ref-type="bibr">47</xref>, <xref rid="ref48" ref-type="bibr">48</xref>), along with China&#x02019;s recent national policies and funding initiatives focused on myopia (<xref rid="ref49" ref-type="bibr">49</xref>, <xref rid="ref50" ref-type="bibr">50</xref>). Additionally, the rise of innovative Chinese companies specializing in AI-based fundus image analysis provided advanced tools and technologies (<xref rid="ref51" ref-type="bibr">51</xref>, <xref rid="ref52" ref-type="bibr">52</xref>), further fueling research growth. These factors highlight how external support, alongside disease prevalence, plays a critical role in driving research progress.</p><p>International collaboration has become a preferred approach among researchers. China demonstrated the strongest global partnerships (total link strength of 69), while other countries also engaged in substantial collaborative efforts. This trend was probably driven by HM&#x02019;s status as a global public health challenge (<xref rid="ref53" ref-type="bibr">53</xref>), making joint research an essential strategy. However, AI-related HM studies remained concentrated in North America, Europe, Australia, and East Asia, with limited contributions from less developed regions, despite the significant prevalence of HM in some of these areas. This disparity underscores the need to expand research efforts in underserved regions. The application of AI, telemedicine, and LLMs might improve diagnosis, screening, and routine examinations for HM in these areas, bridging the gap in global research and healthcare equity (<xref rid="ref54" ref-type="bibr">54</xref>, <xref rid="ref55" ref-type="bibr">55</xref>).</p><p>Academic collaboration among institutions mirrors the trend of international partnerships, showing significant activity. Capital Medical University stood out with the highest collaboration network (total link strength of 96) and served as the largest initiator of cooperative efforts, despite none of the top 10 authors being affiliated with it. Among the top 10 authors, nine were based in East Asia. Yang Weihua from Shenzhen Eye Hospital contributed the most publications (9 in English, 1 in Chinese), while Daniel Ting from the Singapore National Eye Centre received the highest total citations (190), averaging 23.75 citations per paper. This highlights the prominent role of East Asian researchers in advancing AI-related HM research.</p><p>The majority of AI-related HM articles were published in ophthalmology journals (71, 42.5%), with a notable portion also appearing in computer science journals (26/167). Among these, IOVS and TVST, both published by the Association for Research in Vision and Ophthalmology, led in publication volume and citation count, respectively. TVST was particularly popular among authors from China and the United States, while researchers from Singapore showed a preference for Investigative Ophthalmology &#x00026; Visual Science. Most studies in this field primarily focused on clinical research, whereas the application of AI to animal models in HM remained limited. Notably, KhalafAllah et al. (<xref rid="ref56" ref-type="bibr">56</xref>) utilized DLMs to explore the significant thinning of peripapillary tissues during the progression of HM in juvenile tree shrews. As reported, AI holds great promise in basic experimental research on HM&#x02014;for instance, it can be integrated with gene-edited animal models and advanced imaging techniques to enhance the precision, efficiency, and scalability of such studies (<xref rid="ref57" ref-type="bibr">57</xref>, <xref rid="ref58" ref-type="bibr">58</xref>). In fact, AI has already demonstrated remarkable success in basic research across other biomedical fields (<xref rid="ref59" ref-type="bibr">59&#x02013;61</xref>), yet its application in HM-related animal studies remains underexplored, highlighting the need for further investigation.</p><p>Thematic analysis of keywords helps clarify current research priorities and emerging trends. Based on VoS clustering and manual review, we categorized the included literature into several key application areas: epidemiology and screening (<xref rid="ref43" ref-type="bibr">43</xref>, <xref rid="ref46" ref-type="bibr">46</xref>, <xref rid="ref62" ref-type="bibr">62</xref>), automated diagnosis (<xref rid="ref42" ref-type="bibr">42</xref>, <xref rid="ref45" ref-type="bibr">45</xref>), disease monitoring and progression prediction (<xref rid="ref33" ref-type="bibr">33</xref>, <xref rid="ref63" ref-type="bibr">63</xref>, <xref rid="ref64" ref-type="bibr">64</xref>), treatment planning (<xref rid="ref65" ref-type="bibr">65&#x02013;67</xref>), retinal image-based quantification (<xref rid="ref68" ref-type="bibr">68&#x02013;70</xref>), and classification and subtyping (<xref rid="ref44" ref-type="bibr">44</xref>, <xref rid="ref71" ref-type="bibr">71</xref>). In parallel, a systematic breakdown of AI task categories revealed the frequent use of classification (<xref rid="ref44" ref-type="bibr">44</xref>, <xref rid="ref71" ref-type="bibr">71</xref>, <xref rid="ref72" ref-type="bibr">72</xref>), segmentation (<xref rid="ref44" ref-type="bibr">44</xref>, <xref rid="ref69" ref-type="bibr">69</xref>), prediction (<xref rid="ref33" ref-type="bibr">33</xref>, <xref rid="ref64" ref-type="bibr">64</xref>, <xref rid="ref65" ref-type="bibr">65</xref>), quantification (<xref rid="ref68" ref-type="bibr">68</xref>, <xref rid="ref69" ref-type="bibr">69</xref>), and multi-task learning (<xref rid="ref70" ref-type="bibr">70</xref>, <xref rid="ref73" ref-type="bibr">73</xref>). These task types were often built on fundus imaging data, which remains central because of its diagnostic value, non-invasive nature, and wide accessibility (<xref rid="ref74" ref-type="bibr">74</xref>, <xref rid="ref75" ref-type="bibr">75</xref>). Co-occurrence analysis further confirmed that HM-related retinopathy remains a consistently prominent research focus, likely due to its significant health burden and its status as a leading cause of best-corrected visual acuity loss worldwide (<xref rid="ref76" ref-type="bibr">76</xref>, <xref rid="ref77" ref-type="bibr">77</xref>). Furthermore, the reliance on fundus image data for the diagnosis and treatment of HM-related retinopathy supported AI-driven analysis (<xref rid="ref78" ref-type="bibr">78&#x02013;80</xref>), facilitating the development of DLMs for improved diagnosis and classification (<xref rid="ref71" ref-type="bibr">71</xref>). Epidemiology-related keywords, such as &#x0201c;screening&#x0201d; and &#x0201c;epidemiology&#x0201d; also gained prominence, likely in response to recent public health initiatives (<xref rid="ref49" ref-type="bibr">49</xref>). The growing availability of real-world clinical data further strengthened AI models by providing rich external training sets (<xref rid="ref33" ref-type="bibr">33</xref>, <xref rid="ref42" ref-type="bibr">42</xref>).</p><p>To better illustrate the evolving focus of research in this field, we divided the analysis into two periods: 2017&#x02013;2022 and 2023&#x02013;2024. This division was based on publication trends (with roughly equal publication volumes before and after 2022) and the significant AI event (<xref rid="ref36" ref-type="bibr">36</xref>) (in December 2022, the release of ChatGPT-3.5 sparked global discussions on AI). In the first period (2017&#x02013;2022), the word cloud prominently featured OCT. This can be attributed to its widespread use in ophthalmology in this period and its unique capability to capture high-quality fundus images (<xref rid="ref81" ref-type="bibr">81&#x02013;83</xref>). Researchers such as Sogawa et al. (<xref rid="ref45" ref-type="bibr">45</xref>) and Ye et al. (<xref rid="ref62" ref-type="bibr">62</xref>) aimed to develop DLMs to identify retinopathy in HM patients using OCT images, with AUC values exceeding 0.95. Liu et al. (<xref rid="ref69" ref-type="bibr">69</xref>) and Wang et al. (<xref rid="ref72" ref-type="bibr">72</xref>) also created AI models using OCT images to analyze choroidal parameters in HM cases. Notably, Yoo et al. (<xref rid="ref84" ref-type="bibr">84</xref>) introduced a DLM to predict uncorrected refractive errors from posterior segment OCT images, further showcasing the potential of OCT-based AI applications in this field. In the second period (2023&#x02013;2024), keywords became more varied, with no single term taking a clear lead. However, emerging topics like IOL implantation power calculation and screening suggested an increasing interest in applying AI to HM patients of different age groups. This included AI-assisted IOL implantation for age-related cataracts in the elderly (<xref rid="ref65" ref-type="bibr">65&#x02013;67</xref>, <xref rid="ref85" ref-type="bibr">85</xref>) and AI models supporting HM screening in school-aged children (<xref rid="ref63" ref-type="bibr">63</xref>, <xref rid="ref68" ref-type="bibr">68</xref>, <xref rid="ref86" ref-type="bibr">86&#x02013;88</xref>). Additionally, other emerging keywords, such as OCTA, highlighted the progression of retinal imaging techniques for HM, from basic fundus photography to OCT, wide-field OCT, and OCTA (<xref rid="ref83" ref-type="bibr">83</xref>). This trend underscores the increasing sophistication and diversity of diagnostic technologies in this field.</p><p>Our analysis of TS burst trends aligned with the previous findings. Before 2022, research primarily focused on fundus-related topics in HM. Among the key terms, &#x0201c;blood flow&#x0201d; emerged as an early and enduring hotspot. For instance, Zhou et al. (<xref rid="ref89" ref-type="bibr">89</xref>) employed OCT with a split-spectrum amplitude-decorrelation angiography algorithm to evaluate parameters, such as the foveal avascular zone area and macular blood flow, in HM patients. After 2022, the focus shifted toward &#x0201c;age,&#x0201d; with an emphasis on pediatric HM populations. Zhao et al. (<xref rid="ref86" ref-type="bibr">86</xref>), for example, developed an AI-based fully automated system for analyzing retinal vascular morphology in children with HM. This shift might be driven by an evolving understanding of HM-related diseases, with a growing emphasis on early diagnosis and intervention before complications arise. At the same time, there was increasing awareness of the need to integrate HM management into long-term care strategies across all age groups. For instance, Wang et al. (<xref rid="ref64" ref-type="bibr">64</xref>) developed models to accurately predict long-term visual acuity in HM eyes based on clinical and imaging data. These evolving trends highlight the expanding and increasingly specialized applications of AI in HM research.</p><p>Despite the promising potential of AI in HM, several challenges persist. First, many studies using DLMs are confined to their own datasets and have not been widely applied or validated in real-world clinical settings. This gap may be attributed to multiple factors, including data privacy concerns, regulatory barriers, limited clinician acceptance, and the inconsistent quality of real-world data&#x02014;particularly imaging. For example, in Zhao et al.&#x02019;s pediatric HM screening model (<xref rid="ref86" ref-type="bibr">86</xref>), although the reported accuracy reached 94.19%, its strict requirements for image quality significantly limited its applicability in routine ophthalmic practice, where such ideal conditions are not always met. Second, as previously mentioned, most AI applications in HM focus on clinical research, with a notable lack of foundational studies. This is likely due to the lack of animal models that can accurately replicate the pathological features of HM in human eyes, thus limiting AI&#x02019;s potential. Additionally, the absence of large-scale public datasets of HM hinders the development of models and algorithms. We advocate for open-source data sharing to accelerate progress in this field. This could include forming international consortiums for multi-center data collection and establishing standardized, ethical frameworks for secure data sharing (<xref rid="ref90" ref-type="bibr">90</xref>). Finally, the application of AI in HM also raises ethical concerns, such as the lack of transparency in how AI models make clinical decisions, which may reduce clinician trust and patient acceptance (<xref rid="ref91" ref-type="bibr">91</xref>, <xref rid="ref92" ref-type="bibr">92</xref>). Incorporating interpretable AI models and clear reporting of decision-making processes can help improve transparency and support ethical integration into clinical practice (<xref rid="ref93" ref-type="bibr">93</xref>).</p><p>Several key areas remain to be explored in the future. First, there is an urgent need to develop DLMs for multimodal imaging of HM, which would enable more precise and comprehensive diagnosis and treatment (<xref rid="ref70" ref-type="bibr">70</xref>, <xref rid="ref73" ref-type="bibr">73</xref>). Currently, this remains an underexplored area. Second, improving the accessibility of these algorithmic models is crucial. HM, as a chronic condition requiring long-term follow-up (<xref rid="ref94" ref-type="bibr">94</xref>), often coexists with other eye diseases, including glaucoma (<xref rid="ref9" ref-type="bibr">9</xref>). This increases the demand for healthcare resources, which are unevenly distributed across the globe (<xref rid="ref95" ref-type="bibr">95</xref>, <xref rid="ref96" ref-type="bibr">96</xref>). Barriers such as poor internet connectivity, limited computing infrastructure, and a lack of trained personnel hinder AI adoption in low-income regions. Developing low-cost, efficient models could help bridge this gap and support wider clinical use. Lastly, there is a growing demand for an integrated model that can diagnose, classify, guide treatment, and predict postoperative outcomes, addressing the full spectrum of clinical needs rather than focusing solely on one aspect of HM.</p><p>This study represented the first bibliometric analysis of AI-related research in HM, particularly in the context of the global rise in AI interest following the advent of technologies like ChatGPT. Our findings will offer valuable insights into the evolution of this field, helping researchers identify key trends and focus areas for future investigations. However, the study does have some limitations. First, although we included two major medical databases&#x02014;WoSCC and MEDLINE&#x02014;and added CSCD to reflect China&#x02019;s leading role in the field, some non-English databases were still excluded. Among them, only WoSCC provided comprehensive bibliometric data, while others may lack complete publication statistics. Additionally, differences in author positions may introduce bias in evaluating individual influence and collaboration networks. As there is currently no universally accepted method to quantify author contributions by position, we referred to the percentage-based Author Contribution Index to construct the author collaboration network (<xref rid="SM2" ref-type="supplementary-material">Supplementary Figure 2</xref>). Furthermore, when calculating publication counts for countries using the WoS built-in toolkit, internationally co-authored articles were counted for all listed countries, as the tool only supports full counting. This resulted in an inflated representation of each country&#x02019;s publication count. The same approach was also applied to the analysis of institutions and authors. To provide a more accurate representation of relative proportions, the global total publication count in <xref rid="fig3" ref-type="fig">Figure 3</xref> was calculated by summing the publication counts of each country.</p></sec><sec sec-type="conclusions" id="sec17"><title>Conclusion</title><p>This study provided an overview of global research on AI in the field of HM for the first time. Recent advancements in AI applications for HM have been significant, and this trend is expected to continue. Future research will likely focus on multimodal imaging and improving algorithm availability.</p></sec></body><back><sec sec-type="data-availability" id="sec18"><title>Data availability statement</title><p>The original contributions presented in the study are included in the article/<xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>, further inquiries can be directed to the corresponding author.</p></sec><sec sec-type="author-contributions" id="sec19"><title>Author contributions</title><p>XW: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Supervision, Validation, Visualization, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. AW: Resources, Writing &#x02013; review &#x00026; editing, Data curation, Methodology, Software, Validation, Writing &#x02013; original draft. JW: Investigation, Visualization, Writing &#x02013; review &#x00026; editing, Data curation, Formal analysis. DS: Visualization, Writing &#x02013; review &#x00026; editing, Formal analysis. YC: Visualization, Writing &#x02013; review &#x00026; editing, Methodology. JH: Visualization, Resources, Writing &#x02013; review &#x00026; editing. WH: Resources, Conceptualization, Funding acquisition, Project administration, Supervision, Writing &#x02013; review &#x00026; editing. ZF: Conceptualization, Funding acquisition, Investigation, Methodology, Project administration, Resources, Software, Supervision, Visualization, Writing &#x02013; review &#x00026; editing.</p></sec><sec sec-type="COI-statement" id="sec21"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type="ai-statement" id="sec22"><title>Generative AI statement</title><p>The authors declare that no Gen AI was used in the creation of this manuscript.</p></sec><sec sec-type="disclaimer" id="sec23"><title>Publisher&#x02019;s note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><sec sec-type="supplementary-material" id="sec24"><title>Supplementary material</title><p>The Supplementary material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fmed.2025.1567440/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fmed.2025.1567440/full#supplementary-material</ext-link></p><supplementary-material id="SM1" position="float" content-type="local-data"><label>Supplementary Figure 1</label><caption><p>Co-authorship network visualization map of institutions. Each node represents an institution, with the circle size reflecting the number of publications. Connecting lines represent collaboration between institutions.</p></caption><media xlink:href="Image_1.JPEG"/></supplementary-material><supplementary-material id="SM2" position="float" content-type="local-data"><label>Supplementary Figure 2</label><caption><p>Co-authorship network visualization map of authors. Each node represents an author, with the circle size reflecting the number of publications. Connecting lines represent collaboration between authors.</p></caption><media xlink:href="Image_2.JPEG"/></supplementary-material><supplementary-material id="SM3" position="float" content-type="local-data"><label>Supplementary Figure 3</label><caption><p>Keyword co-occurrence map showing five clusters: an AI-focused cluster (red), an epidemiology-related cluster (green), an anatomy-related cluster (yellow), and a cluster related to HM-associated diseases (blue). Node size represents frequency, and connecting lines show co-occurrence between keywords.</p></caption><media xlink:href="Image_3.JPEG"/></supplementary-material><supplementary-material id="SM4" position="float" content-type="local-data"><label>Supplementary Figure 4</label><caption><p>Trend topics of author&#x02019;s keywords. The position of the circles on the timeline indicates the median year of high-frequency keywords, with circle size representing frequency. The blue segments illustrate the time range between the first and third quartile of keyword usage.</p></caption><media xlink:href="Image_4.JPEG"/></supplementary-material></sec><ref-list><title>References</title><ref id="ref1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ng Yin Ling</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Ang</surname><given-names>M</given-names></name></person-group>. <article-title>Artificial intelligence in myopia in children: current trends and future directions</article-title>. <source>Curr Opin Ophthalmol</source>. (<year>2024</year>) <volume>35</volume>:<fpage>463</fpage>&#x02013;<lpage>71</lpage>. doi: <pub-id pub-id-type="doi">10.1097/ICU.0000000000001086</pub-id>, PMID: <pub-id pub-id-type="pmid">39259652</pub-id>
</mixed-citation></ref><ref id="ref2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>R</given-names></name><name><surname>Xie</surname><given-names>S</given-names></name><name><surname>Igarashi-Yokoi</surname><given-names>T</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name><name><surname>Uramoto</surname><given-names>K</given-names></name><name><surname>Takahashi</surname><given-names>H</given-names></name><etal/></person-group>. <article-title>Continued increase of axial length and its risk factors in adults with high myopia</article-title>. <source>JAMA Ophthalmol</source>. (<year>2021</year>) <volume>139</volume>:<fpage>1096</fpage>&#x02013;<lpage>103</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamaophthalmol.2021.3303</pub-id>, PMID: <pub-id pub-id-type="pmid">34436537</pub-id>
</mixed-citation></ref><ref id="ref3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>IG</given-names></name><name><surname>Ohno-Matsui</surname><given-names>K</given-names></name><name><surname>Saw</surname><given-names>SM</given-names></name></person-group>. <article-title>Myopia</article-title>. <source>Lancet</source>. (<year>2012</year>) <volume>379</volume>:<fpage>1739</fpage>&#x02013;<lpage>48</lpage>. doi: <pub-id pub-id-type="doi">10.1016/S0140-6736(12)60272-4</pub-id><pub-id pub-id-type="pmid">22559900</pub-id>
</mixed-citation></ref><ref id="ref4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flitcroft</surname><given-names>DI</given-names></name><name><surname>He</surname><given-names>M</given-names></name><name><surname>Jonas</surname><given-names>JB</given-names></name><name><surname>Jong</surname><given-names>M</given-names></name><name><surname>Naidoo</surname><given-names>K</given-names></name><name><surname>Ohno-Matsui</surname><given-names>K</given-names></name><etal/></person-group>. <article-title>IMI-defining and classifying myopia: a proposed set of standards for clinical and epidemiologic studies</article-title>. <source>Invest Ophthalmol Vis Sci</source>. (<year>2019</year>) <volume>60</volume>:<fpage>M20</fpage>&#x02013;<lpage>m30</lpage>. doi: <pub-id pub-id-type="doi">10.1167/iovs.18-25957</pub-id>, PMID: <pub-id pub-id-type="pmid">30817826</pub-id>
</mixed-citation></ref><ref id="ref5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holden</surname><given-names>BA</given-names></name><name><surname>Fricke</surname><given-names>TR</given-names></name><name><surname>Wilson</surname><given-names>DA</given-names></name><name><surname>Jong</surname><given-names>M</given-names></name><name><surname>Naidoo</surname><given-names>KS</given-names></name><name><surname>Sankaridurg</surname><given-names>P</given-names></name><etal/></person-group>. <article-title>Global prevalence of myopia and high myopia and temporal trends from 2000 through 2050</article-title>. <source>Ophthalmology</source>. (<year>2016</year>) <volume>123</volume>:<fpage>1036</fpage>&#x02013;<lpage>42</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ophtha.2016.01.006</pub-id>, PMID: <pub-id pub-id-type="pmid">26875007</pub-id>
</mixed-citation></ref><ref id="ref6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohno-Matsui</surname><given-names>K</given-names></name><name><surname>Wu</surname><given-names>PC</given-names></name><name><surname>Yamashiro</surname><given-names>K</given-names></name><name><surname>Vutipongsatorn</surname><given-names>K</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Cheung</surname><given-names>CMG</given-names></name><etal/></person-group>. <article-title>IMI pathologic myopia</article-title>. <source>Invest Ophthalmol Vis Sci</source>. (<year>2021</year>) <volume>62</volume>:<fpage>5</fpage>. doi: <pub-id pub-id-type="doi">10.1167/iovs.62.5.5</pub-id>, PMID: <pub-id pub-id-type="pmid">33909033</pub-id>
</mixed-citation></ref><ref id="ref7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia-Valenzuela</surname><given-names>E</given-names></name><name><surname>Kaufman</surname><given-names>LM</given-names></name></person-group>. <article-title>High myopia associated with retinopathy of prematurity is primarily lenticular</article-title>. <source>J AAPOS</source>. (<year>2005</year>) <volume>9</volume>:<fpage>121</fpage>&#x02013;<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jaapos.2004.12.018</pub-id>, PMID: <pub-id pub-id-type="pmid">15838438</pub-id>
</mixed-citation></ref><ref id="ref8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Kong</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>P</given-names></name><etal/></person-group>. <article-title>Optic neuropathy in high myopia: Glaucoma or high myopia or both?</article-title>
<source>Prog Retin Eye Res</source>. (<year>2024</year>) <volume>99</volume>:<fpage>101246</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.preteyeres.2024.101246</pub-id>, PMID: <pub-id pub-id-type="pmid">38262557</pub-id>
</mixed-citation></ref><ref id="ref9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>MT</given-names></name><name><surname>Tran</surname><given-names>M</given-names></name><name><surname>Singh</surname><given-names>K</given-names></name><name><surname>Chang</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name></person-group>. <article-title>Glaucoma and myopia: diagnostic challenges</article-title>. <source>Biomol Ther</source>. (<year>2023</year>) <volume>13</volume>:<fpage>3</fpage>. doi: <pub-id pub-id-type="doi">10.3390/biom13030562</pub-id>, PMID: <pub-id pub-id-type="pmid">36979497</pub-id>
</mixed-citation></ref><ref id="ref10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamet</surname><given-names>P</given-names></name><name><surname>Tremblay</surname><given-names>J</given-names></name></person-group>. <article-title>Artificial intelligence in medicine</article-title>. <source>Metabolism</source>. (<year>2017</year>) <volume>69s</volume>:<fpage>S36</fpage>&#x02013;<lpage>s40</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.metabol.2017.01.011</pub-id>, PMID: <pub-id pub-id-type="pmid">28126242</pub-id>
</mixed-citation></ref><ref id="ref11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ting</surname><given-names>DSW</given-names></name><name><surname>Pasquale</surname><given-names>LR</given-names></name><name><surname>Peng</surname><given-names>L</given-names></name><name><surname>Campbell</surname><given-names>JP</given-names></name><name><surname>Lee</surname><given-names>AY</given-names></name><name><surname>Raman</surname><given-names>R</given-names></name><etal/></person-group>. <article-title>Artificial intelligence and deep learning in ophthalmology</article-title>. <source>Br J Ophthalmol</source>. (<year>2019</year>) <volume>103</volume>:<fpage>167</fpage>&#x02013;<lpage>75</lpage>. doi: <pub-id pub-id-type="doi">10.1136/bjophthalmol-2018-313173</pub-id>, PMID: <pub-id pub-id-type="pmid">30361278</pub-id>
</mixed-citation></ref><ref id="ref12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ting</surname><given-names>DSW</given-names></name><name><surname>Peng</surname><given-names>L</given-names></name><name><surname>Varadarajan</surname><given-names>AV</given-names></name><name><surname>Keane</surname><given-names>PA</given-names></name><name><surname>Burlina</surname><given-names>PM</given-names></name><name><surname>Chiang</surname><given-names>MF</given-names></name><etal/></person-group>. <article-title>Deep learning in ophthalmology: the technical and clinical considerations</article-title>. <source>Prog Retin Eye Res</source>. (<year>2019</year>) <volume>72</volume>:<fpage>100759</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.preteyeres.2019.04.003</pub-id>, PMID: <pub-id pub-id-type="pmid">31048019</pub-id>
</mixed-citation></ref><ref id="ref13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balyen</surname><given-names>L</given-names></name><name><surname>Peto</surname><given-names>T</given-names></name></person-group>. <article-title>Promising artificial intelligence-machine learning-deep learning algorithms in ophthalmology</article-title>. <source>Asia Pac J Ophthalmol (Phila)</source>. (<year>2019</year>) <volume>8</volume>:<fpage>264</fpage>&#x02013;<lpage>72</lpage>. doi: <pub-id pub-id-type="doi">10.22608/APO.2018479</pub-id>, PMID: <pub-id pub-id-type="pmid">31149787</pub-id>
</mixed-citation></ref><ref id="ref14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ting</surname><given-names>DSJ</given-names></name><name><surname>Foo</surname><given-names>VH</given-names></name><name><surname>Yang</surname><given-names>LWY</given-names></name><name><surname>Sia</surname><given-names>JT</given-names></name><name><surname>Ang</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>H</given-names></name><etal/></person-group>. <article-title>Artificial intelligence for anterior segment diseases: emerging applications in ophthalmology</article-title>. <source>Br J Ophthalmol</source>. (<year>2021</year>) <volume>105</volume>:<fpage>158</fpage>&#x02013;<lpage>68</lpage>. doi: <pub-id pub-id-type="doi">10.1136/bjophthalmol-2019-315651</pub-id>, PMID: <pub-id pub-id-type="pmid">32532762</pub-id>
</mixed-citation></ref><ref id="ref15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Shi</surname><given-names>S</given-names></name><name><surname>Tang</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>Z</given-names></name><name><surname>Ye</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><etal/></person-group>. <article-title>A deep learning-based image analysis for assessing the extent of abduction in abducens nerve palsy patients before and after strabismus surgery</article-title>. <source>Adv Ophthalmol Pract Res</source>. (<year>2024</year>) <volume>4</volume>:<fpage>202</fpage>&#x02013;<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.aopr.2024.06.004</pub-id>, PMID: <pub-id pub-id-type="pmid">39484054</pub-id>
</mixed-citation></ref><ref id="ref16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popescu Patoni</surname><given-names>SI</given-names></name><name><surname>Mu&#x0015f;at</surname><given-names>AAM</given-names></name><name><surname>Patoni</surname><given-names>C</given-names></name><name><surname>Popescu</surname><given-names>MN</given-names></name><name><surname>Munteanu</surname><given-names>M</given-names></name><name><surname>Costache</surname><given-names>IB</given-names></name><etal/></person-group>. <article-title>Artificial intelligence in ophthalmology</article-title>. <source>Rom J Ophthalmol</source>. (<year>2023</year>) <volume>67</volume>:<fpage>207</fpage>&#x02013;<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.22336/rjo.2023.37</pub-id>, PMID: <pub-id pub-id-type="pmid">37876505</pub-id>
</mixed-citation></ref><ref id="ref17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donthu</surname><given-names>N</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Mukherjee</surname><given-names>D</given-names></name><name><surname>Pandey</surname><given-names>N</given-names></name><name><surname>Lim</surname><given-names>WM</given-names></name></person-group>. <article-title>How to conduct a bibliometric analysis: an overview and guidelines</article-title>. <source>J Bus Res</source>. (<year>2021</year>) <volume>133</volume>:<fpage>285</fpage>&#x02013;<lpage>96</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jbusres.2021.04.070</pub-id></mixed-citation></ref><ref id="ref18"><label>18.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hulme</surname><given-names>EW</given-names></name></person-group>. <source>Statistical bibliography in relation to the growth of modern civilization</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Grafton</publisher-name> (<year>1923</year>).</mixed-citation></ref><ref id="ref19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>JR</given-names></name><name><surname>Lorenzo</surname><given-names>D</given-names></name><name><surname>Salerno</surname><given-names>J</given-names></name><name><surname>Yeh</surname><given-names>VM</given-names></name><name><surname>Mitrani</surname><given-names>VB</given-names></name><name><surname>Kripalani</surname><given-names>S</given-names></name></person-group>. <article-title>Current applications of precision medicine: a bibliometric analysis</article-title>. <source>Per Med</source>. (<year>2019</year>) <volume>16</volume>:<fpage>351</fpage>&#x02013;<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.2217/pme-2018-0089</pub-id>, PMID: <pub-id pub-id-type="pmid">31267841</pub-id>
</mixed-citation></ref><ref id="ref20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arakeri</surname><given-names>G</given-names></name><name><surname>Patil</surname><given-names>S</given-names></name><name><surname>Quadri</surname><given-names>MFA</given-names></name><name><surname>Alqahtani</surname><given-names>KM</given-names></name><name><surname>Rao Us</surname><given-names>V</given-names></name><name><surname>Paiva Fonseca</surname><given-names>F</given-names></name><etal/></person-group>. <article-title>A bibliometric analysis of the top 100 most-cited articles in the journal of Oral Pathology &#x00026; Medicine (1972-2020)</article-title>. <source>J Oral Pathol Med</source>. (<year>2021</year>) <volume>50</volume>:<fpage>649</fpage>&#x02013;<lpage>59</lpage>. doi: <pub-id pub-id-type="doi">10.1111/jop.13181</pub-id>, PMID: <pub-id pub-id-type="pmid">33811413</pub-id>
</mixed-citation></ref><ref id="ref21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>XY</given-names></name><name><surname>Fang</surname><given-names>HH</given-names></name><name><surname>Xu</surname><given-names>YW</given-names></name><name><surname>Zhang</surname><given-names>YL</given-names></name><name><surname>Zhang</surname><given-names>SC</given-names></name><name><surname>Yang</surname><given-names>WH</given-names></name></person-group>. <article-title>Bibliometric analysis of hotspots and trends of global myopia research</article-title>. <source>Int J Ophthalmol</source>. (<year>2024</year>) <volume>17</volume>:<fpage>940</fpage>&#x02013;<lpage>50</lpage>. doi: <pub-id pub-id-type="doi">10.18240/ijo.2024.05.20</pub-id>, PMID: <pub-id pub-id-type="pmid">38766336</pub-id>
</mixed-citation></ref><ref id="ref22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Yu</surname><given-names>W</given-names></name><name><surname>Dai</surname><given-names>R</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name></person-group>. <article-title>Global trends and frontiers of research on pathologic myopia since the millennium: a bibliometric analysis</article-title>. <source>Front Public Health</source>. (<year>2022</year>) <volume>10</volume>:<fpage>1047787</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fpubh.2022.1047787</pub-id>, PMID: <pub-id pub-id-type="pmid">36561853</pub-id>
</mixed-citation></ref><ref id="ref23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Zhu</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><etal/></person-group>. <article-title>Applications of artificial intelligence in myopia: current and future directions</article-title>. <source>Front Med (Lausanne)</source>. (<year>2022</year>) <volume>9</volume>:<fpage>840498</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fmed.2022.840498</pub-id>, PMID: <pub-id pub-id-type="pmid">35360739</pub-id>
</mixed-citation></ref><ref id="ref24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Yip</surname><given-names>MYT</given-names></name><name><surname>Ting</surname><given-names>DSW</given-names></name><name><surname>Ang</surname><given-names>M</given-names></name></person-group>. <article-title>Artificial intelligence and digital solutions for myopia</article-title>. <source>Taiwan J Ophthalmol</source>. (<year>2023</year>) <volume>13</volume>:<fpage>142</fpage>&#x02013;<lpage>50</lpage>. doi: <pub-id pub-id-type="doi">10.4103/tjo.TJO-D-23-00032</pub-id>, PMID: <pub-id pub-id-type="pmid">37484621</pub-id>
</mixed-citation></ref><ref id="ref25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Zou</surname><given-names>H</given-names></name></person-group>. <article-title>Insights into artificial intelligence in myopia management: from a data perspective</article-title>. <source>Graefes Arch Clin Exp Ophthalmol</source>. (<year>2024</year>) <volume>262</volume>:<fpage>3</fpage>&#x02013;<lpage>17</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00417-023-06101-5</pub-id>, PMID: <pub-id pub-id-type="pmid">37231280</pub-id>
</mixed-citation></ref><ref id="ref26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>K</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Qi</surname><given-names>H</given-names></name></person-group>. <article-title>Digital health literacy: bibliometric analysis</article-title>. <source>J Med Internet Res</source>. (<year>2022</year>) <volume>24</volume>:<fpage>e35816</fpage>. doi: <pub-id pub-id-type="doi">10.2196/35816</pub-id>, PMID: <pub-id pub-id-type="pmid">35793141</pub-id>
</mixed-citation></ref><ref id="ref27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>M</given-names></name><name><surname>Xie</surname><given-names>D</given-names></name><name><surname>Ni</surname><given-names>J</given-names></name><name><surname>Meng</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><etal/></person-group>. <article-title>Research trend analysis of composting based on web of science database</article-title>. <source>Environ Sci Pollut Res Int</source>. (<year>2021</year>) <volume>28</volume>:<fpage>59528</fpage>&#x02013;<lpage>41</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s11356-021-16377-x</pub-id>, PMID: <pub-id pub-id-type="pmid">34505241</pub-id>
</mixed-citation></ref><ref id="ref28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenhalgh</surname><given-names>T</given-names></name></person-group>. <article-title>How to read a paper. The Medline database</article-title>. <source>BMJ</source>. (<year>1997</year>) <volume>315</volume>:<fpage>180</fpage>&#x02013;<lpage>3</lpage>. doi: <pub-id pub-id-type="doi">10.1136/bmj.315.7101.180</pub-id>, PMID: <pub-id pub-id-type="pmid">9251552</pub-id>
</mixed-citation></ref><ref id="ref29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mondal</surname><given-names>H</given-names></name><name><surname>Deepak</surname><given-names>KK</given-names></name><name><surname>Gupta</surname><given-names>M</given-names></name><name><surname>Kumar</surname><given-names>R</given-names></name></person-group>. <article-title>The h-index: understanding its predictors, significance, and criticism</article-title>. <source>J Family Med Prim Care</source>. (<year>2023</year>) <volume>12</volume>:<fpage>2531</fpage>&#x02013;<lpage>7</lpage>. doi: <pub-id pub-id-type="doi">10.4103/jfmpc.jfmpc_1613_23</pub-id>, PMID: <pub-id pub-id-type="pmid">38186773</pub-id>
</mixed-citation></ref><ref id="ref30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Eck</surname><given-names>NJ</given-names></name><name><surname>Waltman</surname><given-names>L</given-names></name></person-group>. <article-title>Software survey: VOSviewer, a computer program for bibliometric mapping</article-title>. <source>Scientometrics</source>. (<year>2010</year>) <volume>84</volume>:<fpage>523</fpage>&#x02013;<lpage>38</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s11192-009-0146-3</pub-id>, PMID: <pub-id pub-id-type="pmid">20585380</pub-id>
</mixed-citation></ref><ref id="ref31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aria</surname><given-names>M</given-names></name><name><surname>Cuccurullo</surname><given-names>C</given-names></name></person-group>. <article-title>Bibliometrix: an R-tool for comprehensive science mapping analysis</article-title>. <source>J Informet</source>. (<year>2017</year>) <volume>11</volume>:<fpage>959</fpage>&#x02013;<lpage>75</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.joi.2017.08.007</pub-id></mixed-citation></ref><ref id="ref32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C</given-names></name></person-group>. <article-title>Cite space II: detecting and visualizing emerging trends and transient patterns in scientific literature</article-title>. <source>J Am Soc Inf Sci Technol</source>. (<year>2006</year>) <volume>57</volume>:<fpage>359</fpage>&#x02013;<lpage>77</lpage>. doi: <pub-id pub-id-type="doi">10.1002/asi.20317</pub-id></mixed-citation></ref><ref id="ref33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>H</given-names></name><name><surname>Long</surname><given-names>E</given-names></name><name><surname>Ding</surname><given-names>X</given-names></name><name><surname>Diao</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Liu</surname><given-names>R</given-names></name><etal/></person-group>. <article-title>Prediction of myopia development among Chinese school-aged children using refraction data from electronic medical records: a retrospective, multicentre machine learning study</article-title>. <source>PLoS Med</source>. (<year>2018</year>) <volume>15</volume>:<fpage>e1002674</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pmed.1002674</pub-id>, PMID: <pub-id pub-id-type="pmid">30399150</pub-id>
</mixed-citation></ref><ref id="ref34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyer</surname><given-names>S</given-names></name><name><surname>Ikeda</surname><given-names>T</given-names></name><name><surname>Lefort</surname><given-names>MC</given-names></name><name><surname>Malumbres-Olarte</surname><given-names>J</given-names></name><name><surname>Schmidt</surname><given-names>JM</given-names></name></person-group>. <article-title>Percentage-based author contribution index: a universal measure of author contribution to scientific articles</article-title>. <source>Res Integr Peer Rev</source>. (<year>2017</year>) <volume>2</volume>:<fpage>18</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s41073-017-0042-y</pub-id>, PMID: <pub-id pub-id-type="pmid">29451536</pub-id>
</mixed-citation></ref><ref id="ref35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theophanous</surname><given-names>C</given-names></name><name><surname>Modjtahedi</surname><given-names>BS</given-names></name><name><surname>Batech</surname><given-names>M</given-names></name><name><surname>Marlin</surname><given-names>DS</given-names></name><name><surname>Luong</surname><given-names>TQ</given-names></name><name><surname>Fong</surname><given-names>DS</given-names></name></person-group>. <article-title>Myopia prevalence and risk factors in children</article-title>. <source>Clin Ophthalmol</source>. (<year>2018</year>) <volume>12</volume>:<fpage>1581</fpage>&#x02013;<lpage>7</lpage>. doi: <pub-id pub-id-type="doi">10.2147/OPTH.S164641</pub-id>, PMID: <pub-id pub-id-type="pmid">30214142</pub-id>
</mixed-citation></ref><ref id="ref36"><label>36.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Chui</surname><given-names>M</given-names></name><name><surname>Yee</surname><given-names>L</given-names></name><name><surname>Hall</surname><given-names>B</given-names></name><name><surname>Singla</surname><given-names>A</given-names></name></person-group>. <source>The state of AI in 2023: Generative AI&#x02019;s breakout year</source>. (<year>2023</year>).</mixed-citation></ref><ref id="ref37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ali</surname><given-names>H</given-names></name><name><surname>ul Mustafa</surname><given-names>A</given-names></name><name><surname>Aysan</surname><given-names>AF</given-names></name></person-group>. <article-title>Global adoption of generative AI: what matters Most?</article-title>
<source>J Econ Technol</source>. (<year>2024</year>) <volume>3</volume>:<fpage>166</fpage>&#x02013;<lpage>76</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ject.2024.10.002</pub-id>, PMID: <pub-id pub-id-type="pmid">40276772</pub-id>
</mixed-citation></ref><ref id="ref38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akkus</surname><given-names>Z</given-names></name><name><surname>Cai</surname><given-names>J</given-names></name><name><surname>Boonrod</surname><given-names>A</given-names></name><name><surname>Zeinoddini</surname><given-names>A</given-names></name><name><surname>Weston</surname><given-names>AD</given-names></name><name><surname>Philbrick</surname><given-names>KA</given-names></name><etal/></person-group>. <article-title>A survey of deep-learning applications in ultrasound: artificial intelligence-powered ultrasound for improving clinical workflow</article-title>. <source>J Am Coll Radiol</source>. (<year>2019</year>) <volume>16</volume>:<fpage>1318</fpage>&#x02013;<lpage>28</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jacr.2019.06.004</pub-id>, PMID: <pub-id pub-id-type="pmid">31492410</pub-id>
</mixed-citation></ref><ref id="ref39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gui</surname><given-names>Y</given-names></name><name><surname>He</surname><given-names>X</given-names></name><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Jing</surname><given-names>J</given-names></name></person-group>. <article-title>Artificial intelligence-assisted transcriptomic analysis to advance cancer immunotherapy</article-title>. <source>J Clin Med</source>. (<year>2023</year>) <volume>12</volume>:<fpage>1279</fpage>. doi: <pub-id pub-id-type="doi">10.3390/jcm12041279</pub-id>, PMID: <pub-id pub-id-type="pmid">36835813</pub-id>
</mixed-citation></ref><ref id="ref40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>TE</given-names></name><name><surname>Anees</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>Z</given-names></name><etal/></person-group>. <article-title>Retinal photograph-based deep learning algorithms for myopia and a blockchain platform to facilitate artificial intelligence medical research: a retrospective multicohort study</article-title>. <source>Lancet Digit Health</source>. (<year>2021</year>) <volume>3</volume>:<fpage>e317</fpage>&#x02013;<lpage>29</lpage>. doi: <pub-id pub-id-type="doi">10.1016/S2589-7500(21)00055-8</pub-id>, PMID: <pub-id pub-id-type="pmid">33890579</pub-id>
</mixed-citation></ref><ref id="ref41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sung</surname><given-names>MS</given-names></name><name><surname>Lee</surname><given-names>TH</given-names></name><name><surname>Heo</surname><given-names>H</given-names></name><name><surname>Park</surname><given-names>SW</given-names></name></person-group>. <article-title>Association between optic nerve head deformation and retinal microvasculature in high myopia</article-title>. <source>Am J Ophthalmol</source>. (<year>2018</year>) <volume>188</volume>:<fpage>81</fpage>&#x02013;<lpage>90</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ajo.2018.01.033</pub-id>, PMID: <pub-id pub-id-type="pmid">29421295</pub-id>
</mixed-citation></ref><ref id="ref42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>R</given-names></name><name><surname>Xie</surname><given-names>S</given-names></name><name><surname>Fang</surname><given-names>Y</given-names></name><name><surname>Igarashi-Yokoi</surname><given-names>T</given-names></name><name><surname>Moriyama</surname><given-names>M</given-names></name><name><surname>Ogata</surname><given-names>S</given-names></name><etal/></person-group>. <article-title>Deep learning approach for automated detection of myopic maculopathy and pathologic myopia in fundus images</article-title>. <source>Ophthalmol Retina</source>. (<year>2021</year>) <volume>5</volume>:<fpage>1235</fpage>&#x02013;<lpage>44</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.oret.2021.02.006</pub-id>, PMID: <pub-id pub-id-type="pmid">33610832</pub-id>
</mixed-citation></ref><ref id="ref43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>W</given-names></name><name><surname>Zhao</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>B</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Chi</surname><given-names>W</given-names></name><etal/></person-group>. <article-title>Development and validation of a deep learning system to screen vision-threatening conditions in high myopia using optical coherence tomography images</article-title>. <source>Br J Ophthalmol</source>. (<year>2022</year>) <volume>106</volume>:<fpage>633</fpage>&#x02013;<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1136/bjophthalmol-2020-317825</pub-id>, PMID: <pub-id pub-id-type="pmid">33355150</pub-id>
</mixed-citation></ref><ref id="ref44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hemelings</surname><given-names>R</given-names></name><name><surname>Elen</surname><given-names>B</given-names></name><name><surname>Blaschko</surname><given-names>MB</given-names></name><name><surname>Jacob</surname><given-names>J</given-names></name><name><surname>Stalmans</surname><given-names>I</given-names></name><name><surname>De Boever</surname><given-names>P</given-names></name></person-group>. <article-title>Pathological myopia classification with simultaneous lesion segmentation using deep learning</article-title>. <source>Comput Methods Prog Biomed</source>. (<year>2021</year>) <volume>199</volume>:<fpage>105920</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cmpb.2020.105920</pub-id>, PMID: <pub-id pub-id-type="pmid">33412285</pub-id>
</mixed-citation></ref><ref id="ref45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vavvas</surname><given-names>DG</given-names></name><name><surname>Sogawa</surname><given-names>T</given-names></name><name><surname>Tabuchi</surname><given-names>H</given-names></name><name><surname>Nagasato</surname><given-names>D</given-names></name><name><surname>Masumoto</surname><given-names>H</given-names></name><name><surname>Ikuno</surname><given-names>Y</given-names></name><etal/></person-group>. <article-title>Accuracy of a deep convolutional neural network in the detection of myopic macular diseases using swept-source optical coherence tomography</article-title>. <source>PLoS One</source>. (<year>2020</year>) <volume>15</volume>:<fpage>e0227240</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0227240</pub-id>, PMID: <pub-id pub-id-type="pmid">32298265</pub-id>
</mixed-citation></ref><ref id="ref46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>KJ</given-names></name><name><surname>Choi</surname><given-names>JE</given-names></name><name><surname>Roh</surname><given-names>HC</given-names></name><name><surname>Eun</surname><given-names>JS</given-names></name><name><surname>Kim</surname><given-names>JM</given-names></name><name><surname>Shin</surname><given-names>YK</given-names></name><etal/></person-group>. <article-title>Deep learning models for screening of high myopia using optical coherence tomography</article-title>. <source>Sci Rep</source>. (<year>2021</year>) <volume>11</volume>:<fpage>21663</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41598-021-00622-x</pub-id>, PMID: <pub-id pub-id-type="pmid">34737335</pub-id>
</mixed-citation></ref><ref id="ref47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>PC</given-names></name><name><surname>Huang</surname><given-names>HM</given-names></name><name><surname>Yu</surname><given-names>HJ</given-names></name><name><surname>Fang</surname><given-names>PC</given-names></name><name><surname>Chen</surname><given-names>CT</given-names></name></person-group>. <article-title>Epidemiology of myopia</article-title>. <source>Asia Pac J Ophthalmol (Phila)</source>. (<year>2016</year>) <volume>5</volume>:<fpage>386</fpage>&#x02013;<lpage>93</lpage>. doi: <pub-id pub-id-type="doi">10.1097/APO.0000000000000236</pub-id><pub-id pub-id-type="pmid">27898441</pub-id>
</mixed-citation></ref><ref id="ref48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name><name><surname>Xuan</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><etal/></person-group>. <article-title>Axial elongation trajectories in Chinese children and adults with high myopia</article-title>. <source>JAMA Ophthalmol</source>. (<year>2024</year>) <volume>142</volume>:<fpage>87</fpage>&#x02013;<lpage>94</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamaophthalmol.2023.5835</pub-id>, PMID: <pub-id pub-id-type="pmid">38153745</pub-id>
</mixed-citation></ref><ref id="ref49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jan</surname><given-names>C</given-names></name><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Keay</surname><given-names>L</given-names></name><name><surname>Stafford</surname><given-names>RS</given-names></name><name><surname>Congdon</surname><given-names>N</given-names></name><name><surname>Morgan</surname><given-names>I</given-names></name></person-group>. <article-title>Prevention of myopia, China</article-title>. <source>Bull World Health Organ</source>. (<year>2020</year>) <volume>98</volume>:<fpage>435</fpage>&#x02013;<lpage>7</lpage>. doi: <pub-id pub-id-type="doi">10.2471/BLT.19.240903</pub-id>, PMID: <pub-id pub-id-type="pmid">32514219</pub-id>
</mixed-citation></ref><ref id="ref50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jan</surname><given-names>CL</given-names></name><name><surname>Congdon</surname><given-names>N</given-names></name></person-group>. <article-title>Chinese national policy initiative for the management of childhood myopia</article-title>. <source>Lancet Child Adolesc Health</source>. (<year>2018</year>) <volume>2</volume>:<fpage>845</fpage>&#x02013;<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1016/S2352-4642(18)30318-3</pub-id>, PMID: <pub-id pub-id-type="pmid">30449312</pub-id>
</mixed-citation></ref><ref id="ref51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>F</given-names></name><name><surname>Deng</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>He</surname><given-names>J</given-names></name><name><surname>Ye</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><etal/></person-group>. <article-title>Advances in swept-source optical coherence tomography and optical coherence tomography angiography</article-title>. <source>Adv Ophthalmol Pract Res</source>. (<year>2023</year>) <volume>3</volume>:<fpage>67</fpage>&#x02013;<lpage>79</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.aopr.2022.10.005</pub-id>, PMID: <pub-id pub-id-type="pmid">37846376</pub-id>
</mixed-citation></ref><ref id="ref52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Lin</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>Z</given-names></name><name><surname>Ning</surname><given-names>R</given-names></name><name><surname>Li</surname><given-names>K</given-names></name><etal/></person-group>. <article-title>Evaluation of a new dynamic real-time visualization 25 kHz swept-source optical coherence tomography based biometer</article-title>. <source>Eye Vis (Lond)</source>. (<year>2024</year>) <volume>11</volume>:<fpage>9</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s40662-024-00377-2</pub-id>, PMID: <pub-id pub-id-type="pmid">38433240</pub-id>
</mixed-citation></ref><ref id="ref53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>R</given-names></name><name><surname>Vlasak</surname><given-names>N</given-names></name><name><surname>Evans</surname><given-names>BJW</given-names></name></person-group>. <article-title>High myopia: reviews of myopia control strategies and myopia complications</article-title>. <source>Ophthalmic Physiol Opt</source>. (<year>2024</year>) <volume>44</volume>:<fpage>1248</fpage>&#x02013;<lpage>60</lpage>. doi: <pub-id pub-id-type="doi">10.1111/opo.13366</pub-id>, PMID: <pub-id pub-id-type="pmid">39082137</pub-id>
</mixed-citation></ref><ref id="ref54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>A</given-names></name><name><surname>Vijayan</surname><given-names>TB</given-names></name><name><surname>John</surname><given-names>S</given-names></name></person-group>. <article-title>Diagnosing cataracts in the digital age: a survey on AI, Metaverse, and digital twin applications</article-title>. <source>Semin Ophthalmol</source>. (<year>2024</year>) <volume>39</volume>:<fpage>562</fpage>&#x02013;<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1080/08820538.2024.2403436</pub-id>, PMID: <pub-id pub-id-type="pmid">39300918</pub-id>
</mixed-citation></ref><ref id="ref55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holtz</surname><given-names>BE</given-names></name><name><surname>Urban</surname><given-names>FA</given-names></name><name><surname>Oesterle</surname><given-names>J</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name><name><surname>Henry</surname><given-names>A</given-names></name></person-group>. <article-title>The promise of remote patient monitoring</article-title>. <source>Telemed J E Health</source>. (<year>2024</year>) <volume>30</volume>:<fpage>2776</fpage>&#x02013;<lpage>81</lpage>. doi: <pub-id pub-id-type="doi">10.1089/tmj.2024.0521</pub-id>, PMID: <pub-id pub-id-type="pmid">39535888</pub-id>
</mixed-citation></ref><ref id="ref56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khalaf Allah</surname><given-names>MT</given-names></name><name><surname>Fuchs</surname><given-names>PA</given-names></name><name><surname>Nugen</surname><given-names>F</given-names></name><name><surname>El Hamdaoui</surname><given-names>M</given-names></name><name><surname>Levy</surname><given-names>AM</given-names></name><name><surname>Samuels</surname><given-names>BC</given-names></name><etal/></person-group>. <article-title>Heterogenous thinning of peripapillary tissues occurs early during high myopia development in juvenile tree shrews</article-title>. <source>Exp Eye Res</source>. (<year>2024</year>) <volume>240</volume>:<fpage>109824</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.exer.2024.109824</pub-id>, PMID: <pub-id pub-id-type="pmid">38336167</pub-id>
</mixed-citation></ref><ref id="ref57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghosh</surname><given-names>A</given-names></name><name><surname>Choudhary</surname><given-names>G</given-names></name><name><surname>Medhi</surname><given-names>B</given-names></name></person-group>. <article-title>The pivotal role of artificial intelligence in enhancing experimental animal model research: a machine learning perspective</article-title>. <source>Indian J Pharmacol</source>. (<year>2024</year>) <volume>56</volume>:<fpage>1</fpage>&#x02013;<lpage>3</lpage>. doi: <pub-id pub-id-type="doi">10.4103/ijp.ijp_81_24</pub-id>, PMID: <pub-id pub-id-type="pmid">38454581</pub-id>
</mixed-citation></ref><ref id="ref58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chu</surname><given-names>WT</given-names></name><name><surname>Reza</surname><given-names>SMS</given-names></name><name><surname>Anibal</surname><given-names>JT</given-names></name><name><surname>Landa</surname><given-names>A</given-names></name><name><surname>Crozier</surname><given-names>I</given-names></name><name><surname>Ba&#x0011f;ci</surname><given-names>U</given-names></name><etal/></person-group>. <article-title>Artificial intelligence and infectious disease imaging</article-title>. <source>J Infect Dis</source>. (<year>2023</year>) <volume>228</volume>:<fpage>S322</fpage>&#x02013;<lpage>36</lpage>. doi: <pub-id pub-id-type="doi">10.1093/infdis/jiad158</pub-id>, PMID: <pub-id pub-id-type="pmid">37788501</pub-id>
</mixed-citation></ref><ref id="ref59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdoli Shadbad</surname><given-names>M</given-names></name><name><surname>Hemmat</surname><given-names>N</given-names></name><name><surname>Khaze Shahgoli</surname><given-names>V</given-names></name><name><surname>Derakhshani</surname><given-names>A</given-names></name><name><surname>Baradaran</surname><given-names>F</given-names></name><name><surname>Brunetti</surname><given-names>O</given-names></name><etal/></person-group>. <article-title>A systematic review on PD-1 blockade and PD-1 gene-editing of CAR-T cells for glioma therapy: from deciphering to personalized medicine</article-title>. <source>Front Immunol</source>. (<year>2021</year>) <volume>12</volume>:<fpage>788211</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fimmu.2021.788211</pub-id>, PMID: <pub-id pub-id-type="pmid">35126356</pub-id>
</mixed-citation></ref><ref id="ref60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanemura</surname><given-names>Y</given-names></name><name><surname>Kanazawa</surname><given-names>M</given-names></name><name><surname>Hashimoto</surname><given-names>S</given-names></name><name><surname>Hayashi</surname><given-names>Y</given-names></name><name><surname>Fujiwara</surname><given-names>E</given-names></name><name><surname>Suzuki</surname><given-names>A</given-names></name><etal/></person-group>. <article-title>Assessment of skin inflammation using near-infrared Raman spectroscopy combined with artificial intelligence analysis in an animal model</article-title>. <source>Analyst</source>. (<year>2022</year>) <volume>147</volume>:<fpage>2843</fpage>&#x02013;<lpage>50</lpage>. doi: <pub-id pub-id-type="doi">10.1039/D2AN00193D</pub-id>, PMID: <pub-id pub-id-type="pmid">35621375</pub-id>
</mixed-citation></ref><ref id="ref61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Fu</surname><given-names>YV</given-names></name></person-group>. <article-title>Combination of an artificial intelligence approach and laser tweezers Raman spectroscopy for microbial identification</article-title>. <source>Anal Chem</source>. (<year>2020</year>) <volume>92</volume>:<fpage>6288</fpage>&#x02013;<lpage>96</lpage>. doi: <pub-id pub-id-type="doi">10.1021/acs.analchem.9b04946</pub-id>, PMID: <pub-id pub-id-type="pmid">32281780</pub-id>
</mixed-citation></ref><ref id="ref62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ye</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>YQ</given-names></name><name><surname>Lv</surname><given-names>Z</given-names></name><name><surname>He</surname><given-names>SC</given-names></name><name><surname>Mao</surname><given-names>JB</given-names></name><etal/></person-group>. <article-title>Automatic screening and identifying myopic maculopathy on optical coherence tomography images using deep learning</article-title>. <source>Transl Vis Sci Technol</source>. (<year>2021</year>) <volume>10</volume>:<fpage>10</fpage>. doi: <pub-id pub-id-type="doi">10.1167/tvst.10.13.10</pub-id>, PMID: <pub-id pub-id-type="pmid">34751744</pub-id>
</mixed-citation></ref><ref id="ref63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>YZ</given-names></name><name><surname>Li</surname><given-names>YM</given-names></name><name><surname>Li</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Jian</surname><given-names>WJ</given-names></name><etal/></person-group>. <article-title>Development and validation of predictive models for myopia onset and progression using extensive 15-year refractive data in children and adolescents</article-title>. <source>J Transl Med</source>. (<year>2024</year>) <volume>22</volume>:<fpage>289</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s12967-024-05075-0</pub-id>, PMID: <pub-id pub-id-type="pmid">38494492</pub-id>
</mixed-citation></ref><ref id="ref64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Du</surname><given-names>R</given-names></name><name><surname>Xie</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Lu</surname><given-names>H</given-names></name><name><surname>Xiong</surname><given-names>J</given-names></name><etal/></person-group>. <article-title>Machine learning models for predicting Long-term visual acuity in highly myopic eyes</article-title>. <source>JAMA Ophthalmol</source>. (<year>2023</year>) <volume>141</volume>:<fpage>1117</fpage>&#x02013;<lpage>24</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamaophthalmol.2023.4786</pub-id>, PMID: <pub-id pub-id-type="pmid">37883115</pub-id>
</mixed-citation></ref><ref id="ref65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cione</surname><given-names>F</given-names></name><name><surname>De Bernardo</surname><given-names>M</given-names></name><name><surname>Di Paola</surname><given-names>I</given-names></name><name><surname>Caputo</surname><given-names>A</given-names></name><name><surname>Graziano</surname><given-names>M</given-names></name><name><surname>Rosa</surname><given-names>N</given-names></name></person-group>. <article-title>IOL power calculation in long eyes: selection of the best axial length adjustement factor using the most common formulas</article-title>. <source>Heliyon</source>. (<year>2024</year>) <volume>10</volume>:<fpage>e36609</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.heliyon.2024.e36609</pub-id>, PMID: <pub-id pub-id-type="pmid">39281644</pub-id>
</mixed-citation></ref><ref id="ref66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mo</surname><given-names>ER</given-names></name><name><surname>Chen</surname><given-names>ZX</given-names></name><name><surname>Feng</surname><given-names>K</given-names></name><name><surname>Zhu</surname><given-names>ZH</given-names></name><name><surname>Xu</surname><given-names>JL</given-names></name><name><surname>Zhu</surname><given-names>CY</given-names></name><etal/></person-group>. <article-title>Accuracy of modern intraocular Lens formulas in highly myopic eyes implanted with plate-haptic intraocular lenses</article-title>. <source>Am J Ophthalmol</source>. (<year>2024</year>) <volume>265</volume>:<fpage>105</fpage>&#x02013;<lpage>16</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ajo.2024.04.017</pub-id>, PMID: <pub-id pub-id-type="pmid">38703800</pub-id>
</mixed-citation></ref><ref id="ref67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Dai</surname><given-names>MH</given-names></name><name><surname>Sun</surname><given-names>LY</given-names></name><name><surname>Tang</surname><given-names>XY</given-names></name><name><surname>Zhou</surname><given-names>L</given-names></name><name><surname>Tang</surname><given-names>ZY</given-names></name><etal/></person-group>. <article-title>The accuracy of intraocular lens power calculation formulas based on artificial intelligence in highly myopic eyes: a systematic review and network meta-analysis</article-title>. <source>Front Public Health</source>. (<year>2023</year>) <volume>11</volume>:<fpage>1279718</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fpubh.2023.1279718</pub-id>, PMID: <pub-id pub-id-type="pmid">38026369</pub-id>
</mixed-citation></ref><ref id="ref68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gong</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>JJ</given-names></name><name><surname>Deng</surname><given-names>JJ</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zhu</surname><given-names>ZT</given-names></name><name><surname>Seth</surname><given-names>I</given-names></name><etal/></person-group>. <article-title>Quantification of fundus tessellation reflects early myopic maculopathy in a large-scale population of children and adolescents</article-title>. <source>Transl Vis Sci Technol</source>. (<year>2024</year>) <volume>13</volume>:<fpage>22</fpage>. doi: <pub-id pub-id-type="doi">10.1167/tvst.13.6.22</pub-id>, PMID: <pub-id pub-id-type="pmid">38922627</pub-id>
</mixed-citation></ref><ref id="ref69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>XD</given-names></name><name><surname>Jin</surname><given-names>K</given-names></name><name><surname>Yang</surname><given-names>ZH</given-names></name><name><surname>Yan</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>YQ</given-names></name><etal/></person-group>. <article-title>A curriculum learning-based fully automated system for quantification of the choroidal structure in highly myopic patients</article-title>. <source>Phys Med Biol</source>. (<year>2022</year>) <volume>67</volume>:<fpage>125015</fpage>. doi: <pub-id pub-id-type="doi">10.1088/1361-6560/ac749b</pub-id>, PMID: <pub-id pub-id-type="pmid">35636398</pub-id>
</mixed-citation></ref><ref id="ref70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfau</surname><given-names>M</given-names></name><name><surname>K&#x000fc;nzel</surname><given-names>SH</given-names></name><name><surname>Pfau</surname><given-names>K</given-names></name><name><surname>Schmitz-Valckenberg</surname><given-names>S</given-names></name><name><surname>Fleckenstein</surname><given-names>M</given-names></name><name><surname>Holz</surname><given-names>FG</given-names></name></person-group>. <article-title>Multimodal imaging and deep learning in geographic atrophy secondary to age-related macular degeneration</article-title>. <source>Acta Ophthalmol</source>. (<year>2023</year>) <volume>101</volume>:<fpage>881</fpage>&#x02013;<lpage>90</lpage>. doi: <pub-id pub-id-type="doi">10.1111/aos.15796</pub-id>, PMID: <pub-id pub-id-type="pmid">37933610</pub-id>
</mixed-citation></ref><ref id="ref71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Cai</surname><given-names>W</given-names></name><name><surname>Xie</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Lei</surname><given-names>B</given-names></name><etal/></person-group>. <article-title>Predicting optical coherence tomography-derived high myopia grades from fundus photographs using deep learning</article-title>. <source>Front Med (Lausanne)</source>. (<year>2022</year>) <volume>9</volume>:<fpage>842680</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fmed.2022.842680</pub-id>, PMID: <pub-id pub-id-type="pmid">35308524</pub-id>
</mixed-citation></ref><ref id="ref72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>YY</given-names></name><name><surname>Chen</surname><given-names>SS</given-names></name><name><surname>Lin</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name><name><surname>Huang</surname><given-names>HM</given-names></name><name><surname>Fan</surname><given-names>X</given-names></name><etal/></person-group>. <article-title>Vascular changes of the choroid and their correlations with visual acuity in pathological myopia</article-title>. <source>Invest Ophthalmol Vis Sci</source>. (<year>2022</year>) <volume>63</volume>:<fpage>20</fpage>. doi: <pub-id pub-id-type="doi">10.1167/iovs.63.12.20</pub-id>, PMID: <pub-id pub-id-type="pmid">36378132</pub-id>
</mixed-citation></ref><ref id="ref73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parravano</surname><given-names>M</given-names></name><name><surname>Cennamo</surname><given-names>G</given-names></name><name><surname>Di Antonio</surname><given-names>L</given-names></name><name><surname>Grassi</surname><given-names>MO</given-names></name><name><surname>Lupidi</surname><given-names>M</given-names></name><name><surname>Rispoli</surname><given-names>M</given-names></name><etal/></person-group>. <article-title>Multimodal imaging in diabetic retinopathy and macular edema: an update about biomarkers</article-title>. <source>Surv Ophthalmol</source>. (<year>2024</year>) <volume>69</volume>:<fpage>893</fpage>&#x02013;<lpage>904</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.survophthal.2024.06.006</pub-id>, PMID: <pub-id pub-id-type="pmid">38942124</pub-id>
</mixed-citation></ref><ref id="ref74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muthukumar</surname><given-names>KA</given-names></name><name><surname>Nandi</surname><given-names>D</given-names></name><name><surname>Ranjan</surname><given-names>P</given-names></name><name><surname>Ramachandran</surname><given-names>K</given-names></name><name><surname>Pj</surname><given-names>S</given-names></name><name><surname>Ghosh</surname><given-names>A</given-names></name><etal/></person-group>. <article-title>Integrating electrocardiogram and fundus images for early detection of cardiovascular diseases</article-title>. <source>Sci Rep</source>. (<year>2025</year>) <volume>15</volume>:<fpage>4390</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41598-025-87634-z</pub-id>, PMID: <pub-id pub-id-type="pmid">39910082</pub-id>
</mixed-citation></ref><ref id="ref75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abr&#x000e0;moff</surname><given-names>MD</given-names></name><name><surname>Garvin</surname><given-names>MK</given-names></name><name><surname>Sonka</surname><given-names>M</given-names></name></person-group>. <article-title>Retinal imaging and image analysis</article-title>. <source>IEEE Rev Biomed Eng</source>. (<year>2010</year>) <volume>3</volume>:<fpage>169</fpage>&#x02013;<lpage>208</lpage>. doi: <pub-id pub-id-type="doi">10.1109/RBME.2010.2084567</pub-id>, PMID: <pub-id pub-id-type="pmid">22275207</pub-id>
</mixed-citation></ref><ref id="ref76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>N&#x000e9;meth</surname><given-names>J</given-names></name><name><surname>Tapaszt&#x000f3;</surname><given-names>B</given-names></name><name><surname>Aclimandos</surname><given-names>WA</given-names></name><name><surname>Kestelyn</surname><given-names>P</given-names></name><name><surname>Jonas</surname><given-names>JB</given-names></name><name><surname>De Faber</surname><given-names>JHN</given-names></name><etal/></person-group>. <article-title>Update and guidance on management of myopia. European Society of Ophthalmology in cooperation with international myopia institute</article-title>. <source>Eur J Ophthalmol</source>. (<year>2021</year>) <volume>31</volume>:<fpage>853</fpage>&#x02013;<lpage>83</lpage>. doi: <pub-id pub-id-type="doi">10.1177/1120672121998960</pub-id>, PMID: <pub-id pub-id-type="pmid">33673740</pub-id>
</mixed-citation></ref><ref id="ref77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saw</surname><given-names>SM</given-names></name><name><surname>Matsumura</surname><given-names>S</given-names></name><name><surname>Hoang</surname><given-names>QV</given-names></name></person-group>. <article-title>Prevention and Management of Myopia and Myopic Pathology</article-title>. <source>Invest Ophthalmol Vis Sci</source>. (<year>2019</year>) <volume>60</volume>:<fpage>488</fpage>&#x02013;<lpage>99</lpage>. doi: <pub-id pub-id-type="doi">10.1167/iovs.18-25221</pub-id>, PMID: <pub-id pub-id-type="pmid">30707221</pub-id>
</mixed-citation></ref><ref id="ref78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verkicharla</surname><given-names>PK</given-names></name><name><surname>Ohno-Matsui</surname><given-names>K</given-names></name><name><surname>Saw</surname><given-names>SM</given-names></name></person-group>. <article-title>Current and predicted demographics of high myopia and an update of its associated pathological changes</article-title>. <source>Ophthalmic Physiol Opt</source>. (<year>2015</year>) <volume>35</volume>:<fpage>465</fpage>&#x02013;<lpage>75</lpage>. doi: <pub-id pub-id-type="doi">10.1111/opo.12238</pub-id>, PMID: <pub-id pub-id-type="pmid">26303444</pub-id>
</mixed-citation></ref><ref id="ref79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>HL</given-names></name><name><surname>Liu</surname><given-names>YX</given-names></name><name><surname>Chen</surname><given-names>XY</given-names></name><name><surname>Ling</surname><given-names>SG</given-names></name><name><surname>Qi</surname><given-names>Y</given-names></name><name><surname>Xiong</surname><given-names>Y</given-names></name><etal/></person-group>. <article-title>Fundus tessellated density of pathologic myopia</article-title>. <source>Asia Pac J Ophthalmol (Phila)</source>. (<year>2023</year>) <volume>12</volume>:<fpage>604</fpage>&#x02013;<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.1097/APO.0000000000000642</pub-id>, PMID: <pub-id pub-id-type="pmid">38079255</pub-id>
</mixed-citation></ref><ref id="ref80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name><name><surname>Gregori</surname><given-names>G</given-names></name><name><surname>Roisman</surname><given-names>L</given-names></name><name><surname>Zheng</surname><given-names>F</given-names></name><etal/></person-group>. <article-title>Retinal microvascular network and microcirculation assessments in high myopia</article-title>. <source>Am J Ophthalmol</source>. (<year>2017</year>) <volume>174</volume>:<fpage>56</fpage>&#x02013;<lpage>67</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ajo.2016.10.018</pub-id>, PMID: <pub-id pub-id-type="pmid">27818204</pub-id>
</mixed-citation></ref><ref id="ref81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>La&#x000ed;ns</surname><given-names>I</given-names></name><name><surname>Wang</surname><given-names>JC</given-names></name><name><surname>Cui</surname><given-names>Y</given-names></name><name><surname>Katz</surname><given-names>R</given-names></name><name><surname>Vingopoulos</surname><given-names>F</given-names></name><name><surname>Staurenghi</surname><given-names>G</given-names></name><etal/></person-group>. <article-title>Retinal applications of swept source optical coherence tomography (OCT) and optical coherence tomography angiography (OCTA)</article-title>. <source>Prog Retin Eye Res</source>. (<year>2021</year>) <volume>84</volume>:<fpage>100951</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.preteyeres.2021.100951</pub-id>, PMID: <pub-id pub-id-type="pmid">33516833</pub-id>
</mixed-citation></ref><ref id="ref82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barteselli</surname><given-names>G</given-names></name><name><surname>Bartsch</surname><given-names>DU</given-names></name><name><surname>Weinreb</surname><given-names>RN</given-names></name><name><surname>Camacho</surname><given-names>N</given-names></name><name><surname>Nezgoda</surname><given-names>JT</given-names></name><name><surname>Marvasti</surname><given-names>AH</given-names></name><etal/></person-group>. <article-title>REAL-TIME FULL-DEPTH VISUALIZATION OF POSTERIOR OCULAR STRUCTURES: comparison between full-Depth imaging spectral domain optical coherence tomography and swept-source optical coherence tomography</article-title>. <source>Retina</source>. (<year>2016</year>) <volume>36</volume>:<fpage>1153</fpage>&#x02013;<lpage>61</lpage>. doi: <pub-id pub-id-type="doi">10.1097/IAE.0000000000000842</pub-id>, PMID: <pub-id pub-id-type="pmid">26562563</pub-id>
</mixed-citation></ref><ref id="ref83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vira</surname><given-names>J</given-names></name><name><surname>Marchese</surname><given-names>A</given-names></name><name><surname>Singh</surname><given-names>RB</given-names></name><name><surname>Agarwal</surname><given-names>A</given-names></name></person-group>. <article-title>Swept-source optical coherence tomography imaging of the retinochoroid and beyond</article-title>. <source>Expert Rev Med Devices</source>. (<year>2020</year>) <volume>17</volume>:<fpage>413</fpage>&#x02013;<lpage>26</lpage>. doi: <pub-id pub-id-type="doi">10.1080/17434440.2020.1755256</pub-id>, PMID: <pub-id pub-id-type="pmid">32275451</pub-id>
</mixed-citation></ref><ref id="ref84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname><given-names>TK</given-names></name><name><surname>Ryu</surname><given-names>IH</given-names></name><name><surname>Kim</surname><given-names>JK</given-names></name><name><surname>Lee</surname><given-names>IS</given-names></name></person-group>. <article-title>Deep learning for predicting uncorrected refractive error using posterior segment optical coherence tomography images</article-title>. <source>Eye</source>. (<year>2022</year>) <volume>36</volume>:<fpage>1959</fpage>&#x02013;<lpage>65</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41433-021-01795-5</pub-id>, PMID: <pub-id pub-id-type="pmid">34611313</pub-id>
</mixed-citation></ref><ref id="ref85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hao</surname><given-names>YX</given-names></name><name><surname>Fu</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>D</given-names></name></person-group>. <article-title>Comparing the accuracy of intraocular lens power calculation formulas using artificial intelligence and traditional formulas in highly myopic patients: a meta-analysis</article-title>. <source>Int Ophthalmol</source>. (<year>2024</year>) <volume>44</volume>:<fpage>242</fpage>. doi: <pub-id pub-id-type="doi">10.1007/s10792-024-03227-1</pub-id>, PMID: <pub-id pub-id-type="pmid">38904666</pub-id>
</mixed-citation></ref><ref id="ref86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>YZ</given-names></name><name><surname>Zhao</surname><given-names>ZH</given-names></name><name><surname>Yang</surname><given-names>JJ</given-names></name><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Nasseri</surname><given-names>MA</given-names></name><name><surname>Zapp</surname><given-names>D</given-names></name></person-group>. <article-title>AI-based fully automatic analysis of retinal vascular morphology in pediatric high myopia</article-title>. <source>BMC Ophthalmol</source>. (<year>2024</year>) <volume>24</volume>:<fpage>415</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s12886-024-03682-5</pub-id>, PMID: <pub-id pub-id-type="pmid">39334037</pub-id>
</mixed-citation></ref><ref id="ref87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>HR</given-names></name><name><surname>Li</surname><given-names>JQ</given-names></name><name><surname>Cheng</surname><given-names>WX</given-names></name><name><surname>Zhao</surname><given-names>LN</given-names></name><name><surname>Guan</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>ZS</given-names></name><etal/></person-group>. <article-title>Automatic diagnosis of pediatric high myopia via attention-based patch residual shrinkage network</article-title>. <source>Expert Syst Appl</source>. (<year>2024</year>) <volume>255</volume>:<fpage>124704</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.eswa.2024.124704</pub-id></mixed-citation></ref><ref id="ref88"><label>88.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xuan</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>DC</given-names></name><name><surname>Xiao</surname><given-names>O</given-names></name><name><surname>Guo</surname><given-names>XX</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Yin</surname><given-names>QX</given-names></name><etal/></person-group>. <article-title>Choroidal vascularity and axial length elongation in highly myopic children: a 2-year longitudinal investigation</article-title>. <source>Invest Ophthalmol Vis Sci</source>. (<year>2024</year>) <volume>65</volume>:<fpage>7</fpage>. doi: <pub-id pub-id-type="doi">10.1167/iovs.65.10.7</pub-id>, PMID: <pub-id pub-id-type="pmid">39102263</pub-id>
</mixed-citation></ref><ref id="ref89"><label>89.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>YF</given-names></name><name><surname>Zhou</surname><given-names>MW</given-names></name><name><surname>Gao</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>HY</given-names></name><name><surname>Sun</surname><given-names>XD</given-names></name></person-group>. <article-title>Factors affecting the foveal avascular zone area in healthy eyes among young Chinese adults</article-title>. <source>Biomed Res Int</source>. (<year>2020</year>) <volume>2020</volume>:<fpage>8</fpage>. doi: <pub-id pub-id-type="doi">10.1155/2020/7361492</pub-id>, PMID: <pub-id pub-id-type="pmid">32280700</pub-id>
</mixed-citation></ref><ref id="ref90"><label>90.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meier</surname><given-names>P</given-names></name></person-group>. <article-title>Accelerating progress in cardiology: embracing open science</article-title>. <source>Open Heart</source>. (<year>2024</year>) <volume>11</volume>:<fpage>e002587</fpage>. doi: <pub-id pub-id-type="doi">10.1136/openhrt-2023-002587</pub-id>, PMID: <pub-id pub-id-type="pmid">38233043</pub-id>
</mixed-citation></ref><ref id="ref91"><label>91.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fehr</surname><given-names>J</given-names></name><name><surname>Citro</surname><given-names>B</given-names></name><name><surname>Malpani</surname><given-names>R</given-names></name><name><surname>Lippert</surname><given-names>C</given-names></name><name><surname>Madai</surname><given-names>VI</given-names></name></person-group>. <article-title>A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare</article-title>. <source>Front Digit Health</source>. (<year>2024</year>) <volume>6</volume>:<fpage>1267290</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fdgth.2024.1267290</pub-id>, PMID: <pub-id pub-id-type="pmid">38455991</pub-id>
</mixed-citation></ref><ref id="ref92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fehr</surname><given-names>J</given-names></name><name><surname>Jaramillo-Gutierrez</surname><given-names>G</given-names></name><name><surname>Oala</surname><given-names>L</given-names></name><name><surname>Gr&#x000f6;schel</surname><given-names>MI</given-names></name><name><surname>Bierwirth</surname><given-names>M</given-names></name><name><surname>Balachandran</surname><given-names>P</given-names></name><etal/></person-group>. <article-title>Piloting a survey-based assessment of transparency and trustworthiness with three medical AI tools</article-title>. <source>Healthcare (Basel)</source>. (<year>2022</year>) <volume>10</volume>:<fpage>1923</fpage>. doi: <pub-id pub-id-type="doi">10.3390/healthcare10101923</pub-id>, PMID: <pub-id pub-id-type="pmid">36292369</pub-id>
</mixed-citation></ref><ref id="ref93"><label>93.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>ZM</given-names></name></person-group>. <article-title>Ethics and governance of trustworthy medical artificial intelligence</article-title>. <source>BMC Med Inform Decis Mak</source>. (<year>2023</year>) <volume>23</volume>:<fpage>7</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s12911-023-02103-9</pub-id>, PMID: <pub-id pub-id-type="pmid">36639799</pub-id>
</mixed-citation></ref><ref id="ref94"><label>94.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greene</surname><given-names>PR</given-names></name><name><surname>Greene</surname><given-names>JM</given-names></name></person-group>. <article-title>Advanced myopia, prevalence and incidence analysis</article-title>. <source>Int Ophthalmol</source>. (<year>2018</year>) <volume>38</volume>:<fpage>869</fpage>&#x02013;<lpage>74</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s10792-017-0510-x</pub-id>, PMID: <pub-id pub-id-type="pmid">28378148</pub-id>
</mixed-citation></ref><ref id="ref95"><label>95.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kido</surname><given-names>M</given-names></name><name><surname>Ikoma</surname><given-names>K</given-names></name><name><surname>Kobayashi</surname><given-names>Y</given-names></name><name><surname>Maki</surname><given-names>M</given-names></name><name><surname>Ohashi</surname><given-names>S</given-names></name><name><surname>Shoda</surname><given-names>K</given-names></name><etal/></person-group>. <article-title>The inter-prefectural regional disparity of healthcare resources and representative surgical procedures in orthopaedics and general surgery: a nationwide study in Japan during 2015-2019</article-title>. <source>BMC Musculoskelet Disord</source>. (<year>2023</year>) <volume>24</volume>:<fpage>726</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s12891-023-06820-0</pub-id>, PMID: <pub-id pub-id-type="pmid">37700283</pub-id>
</mixed-citation></ref><ref id="ref96"><label>96.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><collab id="coll1">GBD 2021 Causes of Death Collaborators</collab></person-group>. <article-title>Global burden of 288 causes of death and life expectancy decomposition in 204 countries and territories and 811 subnational locations, 1990-2021: a systematic analysis for the global burden of disease study 2021</article-title>. <source>Lancet</source>. (<year>2024</year>) <volume>403</volume>:<fpage>2100</fpage>&#x02013;<lpage>32</lpage>. doi: <pub-id pub-id-type="doi">10.1016/S0140-6736(24)00367-2</pub-id>, PMID: <pub-id pub-id-type="pmid">38582094</pub-id>
</mixed-citation></ref></ref-list></back></article>