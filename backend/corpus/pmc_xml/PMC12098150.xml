<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="data-paper" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Data Brief</journal-id><journal-id journal-id-type="iso-abbrev">Data Brief</journal-id><journal-title-group><journal-title>Data in Brief</journal-title></journal-title-group><issn pub-type="epub">2352-3409</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC12098150</article-id><article-id pub-id-type="pii">S2352-3409(25)00299-9</article-id><article-id pub-id-type="doi">10.1016/j.dib.2025.111567</article-id><article-id pub-id-type="publisher-id">111567</article-id><article-categories><subj-group subj-group-type="heading"><subject>Data Article</subject></subj-group></article-categories><title-group><article-title>ZASCA-sum: A dataset of the South Africa supreme courts of appeal judgments and media summaries for legal documents summarization research</article-title></title-group><contrib-group><contrib contrib-type="author" id="au0001"><name><surname>Abdulmumin</surname><given-names>Idris</given-names></name><email>idris.abdulmumin@up.ac.za</email><ext-link ext-link-type="uri" xlink:href="https://twitter.com/abumafrim">@abumafrim</ext-link><xref rid="cor0001" ref-type="corresp">&#x0204e;</xref></contrib><contrib contrib-type="author" id="au0002"><name><surname>Marivate</surname><given-names>Vukosi</given-names></name><email>vukosi.marivate@up.ac.za</email><ext-link ext-link-type="uri" xlink:href="https://twitter.com/vukosi">@vukosi</ext-link></contrib><aff id="aff0001">Data Science for Social Impact Research Group, Department of Computer Science, University of Pretoria, Lynnwood Road, Pretoria 0028, Gauteng, South Africa</aff></contrib-group><author-notes><corresp id="cor0001"><label>&#x0204e;</label>Corresponding author. <email>idris.abdulmumin@up.ac.za</email><ext-link ext-link-type="uri" xlink:href="https://twitter.com/abumafrim">@abumafrim</ext-link></corresp></author-notes><pub-date pub-type="pmc-release"><day>19</day><month>4</month><year>2025</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><month>6</month><year>2025</year></pub-date><pub-date pub-type="epub"><day>19</day><month>4</month><year>2025</year></pub-date><volume>60</volume><elocation-id>111567</elocation-id><history><date date-type="received"><day>21</day><month>11</month><year>2024</year></date><date date-type="rev-recd"><day>10</day><month>4</month><year>2025</year></date><date date-type="accepted"><day>11</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 The Authors</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p></license></permissions><abstract id="abs0001"><p>This paper presents ZASCA-Sum, a novel dataset comprising judgments from the South Africa Supreme Court of Appeal and their manually curated media summaries. The dataset, collected from the court's official website, includes 4171 judgments, of which 2118 have summary pairs. The judgments and summaries have been extracted and prepared to support legal document summarization tasks across supervised, semi-supervised, and unsupervised settings. This paper provides a detailed description of the dataset, covering the data collection process, timeline, processing, and potential applications in the field. We provide the token-count distribution and analysis of the judgments and summaries that can be accommodated off-the-shelf by current summarization models with the largest input token size. The dataset, split into training, validation, and test sets, is made publicly available to encourage research in legal summarization. In addition to document summarization, researchers can use this data to localize English-centric models to support the South African dialect.</p></abstract><kwd-group id="keys0001"><title>Keywords</title><kwd>Natural language processing</kwd><kwd>Document summarization</kwd><kwd>Legal summarization</kwd><kwd>Summarization corpora</kwd><kwd>Supreme Court of Appeal of South Africa</kwd></kwd-group></article-meta></front><body><p id="para0002">Specifications Table<table-wrap position="float" id="utbl0001"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">Subject</td><td valign="top">Computer Science</td></tr><tr><td valign="top">Specific subject area</td><td valign="top">Document Summarization - subfield of natural language processing/computational linguistics/human language technology</td></tr><tr><td valign="top">Type of data</td><td valign="top">Raw and processed aligned and unaligned text (UTF8). The dataset contains the following types of data:<list list-type="simple" id="celist1002"><list-item id="celistitem1006"><label>&#x02013;</label><p id="para1016"><bold>Processed</bold>:<list list-type="simple" id="celist0223"><list-item id="celistitem2006"><label>&#x02013;</label><p id="para2016">tab-separated value (.tsv) files split into</p></list-item><list-item id="celistitem3006"><label>&#x02013;</label><p id="para3016">With summaries: <bold>train, test</bold>, and <bold>dev</bold> [column names: id, type, year, input (judgment), output (summary)]</p></list-item><list-item id="celistitem4006"><label>&#x02013;</label><p id="para4016">Without summaries: <bold>all_data</bold> [column names: id, type, year, input (judgment)]</p></list-item><list-item id="celistitem5006"><label>&#x02013;</label><p id="para5016">JavaScript Object Notation (.json) files:</p></list-item></list></p></list-item><list-item id="celistitem6006"><label>&#x02013;</label><p id="para6016"><bold>Raw</bold>: zipped portable document format (.pdf) files arranged into folders: with and without summaries &#x02192; type of judgment (electoral and non-electoral) &#x02192; each judgment (with or without summary file) in a folder labeled with the judgment name.</p></list-item><list-item id="celistitem7006"><label>&#x02013;</label><p id="para7016"><bold>Python files</bold>: .py files containing codes that we used to (1) extract the raw files, (2) transform the pdf files into the processed tsv files, and (3) describe the formatted data.</p></list-item></list></td></tr><tr><td valign="top">Data collection</td><td valign="top">The dataset was collected by scrapping the judgments webpage of the Supreme Court of Appeal of South Africa website. The collected judgments and summaries were each in a portable document format, making their automatic extraction more challenging. We extracted each judgment document automatically and reviewed a random sample to ensure accuracy and completeness. We paired the judgments with summaries and saved them with other identifying metadata. For the judgments without summaries, we extracted them to a separate file along with their metadata. We provide both the curated and raw datasets for reproducibility and other analysis.</td></tr><tr><td valign="top">Data source location</td><td valign="top"><bold>Institution:</bold> South Africa Supreme Court of Appeal website<break/><bold>Location:</bold><ext-link ext-link-type="uri" xlink:href="https://www.supremecourtofappeal.org.za/index.php/component/jdownloads" id="interref0001b">https://www.supremecourtofappeal.org.za/index.php/component/jdownloads</ext-link></td></tr><tr><td valign="top">Data accessibility</td><td valign="top"><bold>Repository:</bold> University of Pretoria Research Data (Figshare), GitHub, and Huggingface<break/><bold>DOI:</bold><break/><bold>Huggingface</bold>: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57967/hf/3565" id="interref0001a">10.57967/hf/3565</ext-link><break/><bold>UP Data</bold>: <ext-link ext-link-type="uri" xlink:href="http://10.25403/UPresearchdata.27371520.v2" id="interref0002">10.25403/UPresearchdata.27371520.v2</ext-link><break/><bold>Direct URL to data:</bold><break/><bold>Huggingface</bold>: <ext-link ext-link-type="uri" xlink:href="https://huggingface.co/datasets/dsfsi/zasca-sum" id="interref0003">https://huggingface.co/datasets/dsfsi/zasca-sum</ext-link><break/>GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/dsfsi/zasca-sum" id="interref0004">https://github.com/dsfsi/zasca-sum</ext-link><break/><bold>UP Data:</bold><ext-link ext-link-type="uri" xlink:href="https://researchdata.up.ac.za/articles/journal_contribution/ZASCA-Sum_a_dataset_of_the_South_Africa_Supreme_Court_of_Appeal_judgments_and_media_summaries_for_legal_documents_summarization_research/27371520" id="interref0005">https://researchdata.up.ac.za/articles/journal_contribution/ZASCA-Sum_a_dataset_of_the_South_Africa_Supreme_Court_of_Appeal_judgments_and_media_summaries_for_legal_documents_summarization_research/27371520</ext-link><break/><bold>Instructions for accessing these data</bold>: open access</td></tr><tr><td valign="top">Related research article</td><td valign="top"><bold>None</bold></td></tr></tbody></table></table-wrap></p><sec id="sec0002"><label>1</label><title>Value of the Data</title><p id="para0003">The following are the values of the presented dataset:<list list-type="simple" id="celist0001"><list-item id="celistitem0001"><label>&#x02022;</label><p id="para0004">The dataset enables localizing general and legal summarization models into the South African legal domain, improving their performance in South African legal cases. This is the first dataset on the continent, to the best of our knowledge.</p></list-item><list-item id="celistitem0002"><label>&#x02022;</label><p id="para0005">The media summaries, crafted by legal experts, provide concise and accurate reporting, allowing models to learn how to condense complex legal language while retaining critical details.</p></list-item><list-item id="celistitem0003"><label>&#x02022;</label><p id="para0006">The dataset's parallel component is ideal for supervised learning. It offers a benchmark for building new models and evaluating the effectiveness of and adapting current summarization models in the legal domain.</p></list-item><list-item id="celistitem0004"><label>&#x02022;</label><p id="para0007">The unaligned component of the dataset can be used for unsupervised learning, enabling researchers to explore novel approaches to legal summarization without relying on labeled data.</p></list-item><list-item id="celistitem0005"><label>&#x02022;</label><p id="para0008">The dataset, written in South African English, is also a valuable resource when training or localizing other Natural Language Processing (NLP) models to generate content in this dialect.</p></list-item></list></p></sec><sec id="sec0003"><label>2</label><title>Background</title><p id="para0009">Legal text summarization is a challenging task that involves compressing long legal documents into concise summaries while preserving key facts and legal reasoning [<xref rid="bib0001" ref-type="bibr">1</xref>]. These judgments are often detailed, sometimes spanning thousands of words, making them difficult for non-experts to understand. Without layman summaries, it becomes harder for the public to grasp court decisions. The media also faces challenges in accurately reporting these judgments without such summaries. A good legal summary must strike a balance between simplicity and accuracy, ensuring that key aspects of the judgment are conveyed clearly without oversimplifying the legal reasoning behind the decision. Several datasets and models have been developed to support automatic summarization. Examples of such datasets include the US litigation releases<xref rid="cit_1" ref-type="fn">1</xref>, and datasets from the Indian and UK Supreme Courts [<xref rid="bib0001" ref-type="bibr">1</xref>]. Additionally, summarization models like the Longformer Encoder-Decoder (LED) [<xref rid="bib0002" ref-type="bibr">2</xref>] and Pegasus [<xref rid="bib0003" ref-type="bibr">3</xref>] have been adapted<xref rid="cit_2" ref-type="fn">2</xref><sup>,</sup><xref rid="cit_3" ref-type="fn">3</xref> to aid legal document summarization. However, none of these resources cover any country in Africa.</p><p id="para0013">In this work, we present a new dataset of judgment-summary pairs of the South African Supreme Court of Appeal (SCA), called ZaSCA-Sum. The SCA plays a crucial role in interpreting and applying the law in South Africa. Its judgments are often accompanied by layman summaries designed for media reporting. The dataset was collected from the Supreme Court&#x02019;s website<xref rid="cit_4" ref-type="fn">4</xref>, extracted into readable and structured format for downstream applications such as natural language processing (NLP) or text analysis. The dataset is made of electoral and non-electoral decisions and is suitable for text summarization, and other applications such as model adaptation and other text-intensive tasks. The word clouds in <xref rid="fig0001" ref-type="fig">Fig. 1</xref> illustrate the domain of the ZaSCA-Sum dataset. The most relevant words in the dataset are high court, South Africa, court, appeal, supreme court, appellant, claim, respondent, summary judgment, media summary, case, applicant, set aside, pty (proprietary), and ltd. To the best of our knowledge, this dataset is the first of its kind on the African continent.<fig id="fig0001"><label>Fig. 1</label><caption><p>Word clouds generated from the judgments and summaries respectively.</p></caption><alt-text id="alt0001">Fig 1</alt-text><graphic xlink:href="gr1" id="celink0001"/></fig></p></sec><sec id="sec0004"><label>3</label><title>Data Description</title><p id="para0015">The dataset and accompanying scripts are arranged as subfolders in a folder labeled: &#x0201c;zasca.&#x0201d; Snapshots of the file and folder structure are presented in <xref rid="fig0008" ref-type="fig">Fig. A.1</xref>, <xref rid="fig0009" ref-type="fig">Fig. A.2</xref>. The structure is explained as follows: The processed data is in the first two folders as follows, then followed by the zipped raw files and the scripts folders.<list list-type="simple" id="celist0002"><list-item id="celistitem0006"><label>&#x02022;</label><p id="para0016"><bold>With_summaries</bold>: This directory contains all the judgments that have been processed and the accompanying summaries. This data component is split into 3 tab-separated value (.tsv) files named &#x02013; <bold>train.tsv, dev.tsv</bold> and <bold>test.tsv</bold> representing train, validation, and test files, respectively. The tsv files have the id, judgment type, judgment year, judgment text (input), and summary text (output) as column names.</p></list-item><list-item id="celistitem0007"><label>&#x02022;</label><p id="para0017"><bold>Without_summaries</bold>: This directory contains all the processed standalone judgments without accompanying summaries. This data component is contained in one file named <bold>all_data.tsv</bold> and has the id, judgment type, judgment year, and judgment text (input) as column names.</p></list-item><list-item id="celistitem0008"><label>&#x02022;</label><p id="para0018"><bold>Raw.zip</bold>: this is a zip folder containing all the raw files in portable document format (pdf). The folder has subdirectories as follows:<list list-type="simple" id="celist0003"><list-item id="celistitem0009"><label>&#x025cb;</label><p id="para0019"><bold>With_summaries</bold>: This directory contains all judgments that have summaries. This folder contains two subfolders named electoral and non-electoral, indicating the type of judgments as such. Each subfolder contains a list of the judgment and summary folders labeled by year_id-judgments-year, e.g., 95-judgments-2024. Contained within each judgment year subfolders are folders labeled by the judgment names. A 150-character length restriction was used, and the words in the judgment name were concatenated by &#x02018;-&#x02019; to form the name string. Each of these folders contains two pdf files labeled as main-judgement.pdf and media-summary.pdf.</p></list-item><list-item id="celistitem0010"><label>&#x025cb;</label><p id="para0020"><bold>Without_summaries</bold>: similar directory structure as with_summaries, except that each of the last folders contains only one pdf file labeled as main-judgement.pdf.</p></list-item></list></p></list-item><list-item id="celistitem0011"><label>&#x02022;</label><p id="para0021"><bold>Scripts</bold>: these code files are used in processing the raw data, and they are explained as follows:<list list-type="simple" id="celist0004"><list-item id="celistitem0012"><label>&#x025cb;</label><p id="para0022"><bold>describe.py</bold>: python script that computes the statistical analysis of the processed dataset.</p></list-item><list-item id="celistitem0013"><label>&#x025cb;</label><p id="para0023"><bold>downloads.sh</bold>: download the GloVe embeddings for data analysis.</p></list-item><list-item id="celistitem0014"><label>&#x025cb;</label><p id="para0024"><bold>extract.py</bold>: python script that extracts the zipped files and folders and extracts and processes the text from the judgment and summary pdf files into the final tsv files contained within the processed folder above.</p></list-item><list-item id="celistitem0015"><label>&#x025cb;</label><p id="para0025"><bold>requirements.txt</bold>: a text file containing all the required library dependencies to run the Python scripts.</p></list-item><list-item id="celistitem0016"><label>&#x025cb;</label><p id="para0026"><bold>utils.py</bold>: a Python utility script containing all the classes and functions needed for data extraction and loading, file management, and text processing and analysis.</p></list-item></list></p></list-item></list></p><p id="para0027">The ZaSCA-Sum dataset consists of 4171 judgments, with about 51 % (or 2118) containing a corresponding media summary. Of these, 99% of the data are generic (non-electoral) with the other 1% making up the electoral cases. <xref rid="fig0010" ref-type="fig">Fig. B.1</xref> shows the judgment-type distribution.</p><p id="para0028"><xref rid="tbl0001" ref-type="table">Table 1</xref> presents a detailed statistical description of the dataset, showing the sentence-, token-, and character-level statistics, detailing the total counts across all documents, the average, standard deviation, maximum and minimum words and sentences in the documents.<table-wrap position="float" id="tbl0001"><label>Table 1</label><caption><p>A detailed description of the statistical information of the collected and processed dataset.</p></caption><alt-text id="alt0002">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="top">stats</th><th colspan="2" align="left" valign="top">Sentences<hr/></th><th colspan="2" align="left" valign="top">Words (tokens)<hr/></th><th colspan="2" align="left" valign="top">Characters<hr/></th></tr><tr><th valign="top">Judgments</th><th valign="top">Summaries</th><th valign="top">Judgments</th><th valign="top">Summaries</th><th valign="top">Judgments</th><th valign="top">Summaries</th></tr></thead><tbody><tr><td valign="top">count</td><td valign="top">418,327</td><td valign="top">40,562</td><td valign="top">13,939,214</td><td valign="top">1,372,001</td><td valign="top">60,938,673</td><td valign="top">6,193,849</td></tr><tr><td valign="top">mean</td><td valign="top">197.79</td><td valign="top">19.18</td><td valign="top">6590.64</td><td valign="top">648.70</td><td valign="top">28,812.61</td><td valign="top">2928.53</td></tr><tr><td valign="top">std</td><td valign="top">159.05</td><td valign="top">13.61</td><td valign="top">4,988.11</td><td valign="top">439.64</td><td valign="top">21,896.36</td><td valign="top">1,941.70</td></tr><tr><td valign="top">min</td><td valign="top">10</td><td valign="top">1</td><td valign="top">420</td><td valign="top">83</td><td valign="top">1,942</td><td valign="top">379</td></tr><tr><td valign="top">90 %</td><td valign="top">350.00</td><td valign="top">35.00</td><td valign="top">11,633.80</td><td valign="top">1156.40</td><td valign="top">51,175.40</td><td valign="top">5156.40</td></tr><tr><td valign="top">max</td><td valign="top">2573</td><td valign="top">238</td><td valign="top">73,612</td><td valign="top">7014</td><td valign="top">323,723</td><td valign="top">238</td></tr></tbody></table></table-wrap></p><p id="para0029">The table shows that the judgments can be as long as 73,612 tokens and the summaries as long as 7014. The major challenge of most deep learning models is their ability to accommodate long sequences [<xref rid="bib0004" ref-type="bibr">4</xref>]. Currently, the state-of-the-art sequence-to-sequence (seq-2-seq) models for automatic summarization can accommodate as long as 16,384 tokens and generate up to 1024 tokens [<xref rid="bib0002" ref-type="bibr">2</xref>,<xref rid="bib0003" ref-type="bibr">3</xref>]. Off-the-shelf, therefore, these models can fully utilize more than 90% of the judgments and just below 90% of the available summaries. With the increasing capacity of large language models (LLMs), the ZaSCA-Sum dataset can be fully utilized for fine-tuning and, in some models, few-shot prompting to generate the target summaries.</p><p id="para0030"><xref rid="fig0002" ref-type="fig">Fig. 2</xref>, <xref rid="fig0003" ref-type="fig">Fig. 3</xref> show the sentence, word, and character distributions of the judgment and summary texts. It can be observed that the judgments are about 10 times more than the summaries. <xref rid="fig0011" ref-type="fig">Fig. C.1</xref> shows the sentence and word density distribution, calculated by dividing each sentence and words by the number of words and characters respectively and averaging. The densities are similar in both the judgment and summary texts.<fig id="fig0002"><label>Fig. 2</label><caption><p>Sentence, word, and character distributions of the judgments.</p></caption><alt-text id="alt0003">Fig 2</alt-text><graphic xlink:href="gr2" id="celink0002"/></fig><fig id="fig0003"><label>Fig. 3</label><caption><p>Sentence, word, and character distributions of the summaries.</p></caption><alt-text id="alt0004">Fig 3</alt-text><graphic xlink:href="gr3" id="celink0003"/></fig></p><p id="para0031"><xref rid="fig0004" ref-type="fig">Fig. 4</xref> shows the difference between the lengths of the judgments and summaries, with rectangular markings showing the judgments and summaries that can be accommodated off-the-shelf by the largest available seq-2-seq models. It also shows the line of best fit (trendline) between the lengths of the judgments and summaries.<fig id="fig0004"><label>Fig. 4</label><caption><p>Sentence, word, and character distributions of the summaries.</p></caption><alt-text id="alt0005">Fig 4</alt-text><graphic xlink:href="gr4" id="celink0004"/></fig></p><p id="para0032">Finally, <xref rid="fig0012" ref-type="fig">Figs. D.1</xref>, <xref rid="fig0013" ref-type="fig">D.2</xref>, <xref rid="fig0014" ref-type="fig">D.3</xref>, and <xref rid="fig0015" ref-type="fig">D.4</xref> show the part of speech tag words, stopwords, and unknown words in the ZaSCA-Sum dataset. Identifying the prevalent stopwords and unknown words gives an understanding of the preprocessing needed in the dataset especially when training machine learning models. We used the NLTK [<xref rid="bib0005" ref-type="bibr">5</xref>] toolkit&#x02019;s pos_tag function to extract the POS words with the universal tagset [<xref rid="bib0006" ref-type="bibr">6</xref>]. Adjectives such as few, long-standing, and best, adpositions such as in, under, and by, adverbs such as extremely, adequately, and purely, conjunctions such as and, neither, and or, determinants such as a, an, and the, and nouns such as The Supreme Court of South Africa, Roodepoort, November, and Child Care Act are some of the tagged words in the dataset. We used the list of punctuation provided in the Python string library to analyze the punctuation in the dataset, and for the stopwords, we used the English stopwords in NLTK. Stopwords such as the, because, and yourself were found in the dataset. Finally, we used the vocabulary of the GloVe [<xref rid="bib0007" ref-type="bibr">7</xref>] embeddings, containing 400,000 word vectors, to identify unknown words. Most of the identified unknown words are local names and entities such as firstrand, mhlantla, mathopo, and saripa.</p><p id="para0033">Finally, we employed BERTopic, a state-of-the-art topic modeling approach, to uncover meaningful insights within the dataset. This analysis revealed the most relevant topics in both the judgment and summary texts, see <xref rid="fig0005" ref-type="fig">Fig. 5</xref>, providing a clear understanding of the key themes present in the data. Common topics include judgment appeal, banks credit and debit agreements, company and business recuse agreements, insurance disputes, Zuma&#x02019;s prosecution and appeal, etc. Additionally, we generated a heatmap in <xref rid="fig0006" ref-type="fig">Fig. 6</xref> comparing the top 12 topics derived from the judgment texts and their corresponding summaries, offering a visual representation of the alignment and differences between these two elements. See <xref rid="fig0016" ref-type="fig">Fig. E.1</xref>, <xref rid="fig0017" ref-type="fig">Fig. E.2</xref> for the actual top 12 topics for comparison.<fig id="fig0005"><label>Fig. 5</label><caption><p>Top 12 topics extracted from combined judgment and summary texts.</p></caption><alt-text id="alt0006">Fig 5</alt-text><graphic xlink:href="gr5" id="celink0005"/></fig><fig id="fig0006"><label>Fig. 6</label><caption><p>Heatmap showing overlap between the top 12 topics in judgment and summary texts.</p></caption><alt-text id="alt0007">Fig 6</alt-text><graphic xlink:href="gr6" id="celink0006"/></fig></p></sec><sec id="sec0005"><label>4</label><title>Experimental Design, Materials and Methods</title><p id="para0034"><xref rid="fig0007" ref-type="fig">Fig. 7</xref> illustrates the data collection, extraction, and processing processes. The data collection, extraction, and processing scripts are provided in the data repository. The dataset was collected between February 19, 2024, and November 5, 2024.<fig id="fig0007"><label>Fig. 7</label><caption><p>Data collection, extraction, and processing methodologies.</p></caption><alt-text id="alt0008">Fig 7</alt-text><graphic xlink:href="gr7" id="celink0007"/></fig></p><sec id="sec0006"><label>4.1</label><title>Data collection</title><p id="para0035">The dataset was collected from the website<xref rid="cit_5" ref-type="fn">5</xref> of the South African Supreme Court of Appeal (ZaSCA) using a Python script written specifically for this task. The script used the &#x0201c;requests&#x0201d; and &#x0201c;BeautifulSoup&#x0201d; libraries to extract the available judgments and summaries (if present) from each judgment page.</p><p id="para0037">The process began by sending an HTTP GET request to each of the electoral<xref rid="cit_6" ref-type="fn">6</xref> and non-electoral<xref rid="cit_7" ref-type="fn">7</xref> base URLs to fetch the pages&#x02019; HTML contents. The text response was then parsed using BeautifulSoup with the LXML parser to enable structured navigation of the HTML document. The find_all method was then used to locate all &#x0003c;div&#x0003e; elements with the class ``jd_categories_title_v46'', returning a list of these elements. For each div in the extracted divs, the href attribute of the anchor tag (&#x0003c;a&#x0003e;) within the div was collected and the list of the URLs was sorted by year, that was extracted within the links. These are the links of all the available judgment years.</p><p id="para0040">For each extracted link, a folder was created and labeled using the extracted year and year_id. The script then fetches the main page of each year using the requests.get method and parses it with BeautifulSoup. If the page includes pagination, identified by the presence of a &#x0003c;li&#x0003e; element with the class ``pagination-end'', the largest index&#x02014;indicating the final page of judgments for that year&#x02014;was extracted. The pages were iteratively accessed using a calculated range of pages (&#x0003c; largest page index), incremented by n = 10 (the highest number of judgments on one page). For each judgment page, the scrapper fetches the page content, and extracts &#x0003c;div&#x0003e; elements with the class ``jd_download_wrapper'', which contain judgment links. From each &#x0003c;div&#x0003e;, the scrapper attempts to extract two links: the main judgment and an optional media summary. Finally, all valid links were saved for files download.</p><p id="para0041">For each valid judgment (and summary) link(s), the script created a folder, named after the judgment. The judgment name was truncated to 150 characters, if longer. It then checked if the main judgment file (main-judgement.pdf) already exists, and if so, it skipped downloading. If unavailable, it downloads the main judgment and saved it as main-judgement.pdf. It also checks if a media summary file exists, and if available, it was downloaded and saved as media-summary.pdf.</p><p id="para0042">The script includes error handling to skip missing URLs, handle unavailable pages, and manage cases where media summaries are not present.</p></sec><sec id="sec0007"><label>4.2</label><title>Data extraction and processing</title><p id="para0043">A utility class was designed to extract and clean text from the collected PDF documents. The class uses the PyMuPDF library (fitz) to extract raw text from each page of a PDF and then processes the text to remove irrelevant elements, such as numeric strings or uninformative lines, while reconstructing coherent paragraphs. First, a method in this class is called &#x0201c;extract_text&#x0201d; opens the PDF file and extracts text from all pages. Each page's text is passed through a cleaning pipeline (&#x0201c;_clean_line&#x0201d;), which splits the text into sentences, removes excess whitespace, and filters out unwanted numeric strings (e.g., page numbers or indices) based on a threshold. Once cleaned, the sentences are passed to the &#x0201c;_combine_paragraphs&#x0201d; method, which merges lines that are part of the same paragraph. This is determined by markers such as square brackets containing digits (e.g., [<xref rid="bib0001" ref-type="bibr">1</xref>]), which indicate continuity. The cleaned and reconstructed text is finally joined into a single string, ready for use. To ensure accurate filtering, two helper methods were used: &#x0201c;_is_numeric_string&#x0201d; and &#x0201c;_is_paragraph_marker&#x0201d;. The function &#x0201c;_is_numeric_string&#x0201d; identifies lines containing only numeric values, commonly used for page numbers, and discards them. Note that a line containing any other character other than a numeric value is not discarded. The function &#x0201c;_is_paragraph_marker&#x0201d; checks for specific patterns, such as bracketed numbers, that signal paragraph continuation. By integrating these methods, the utility class was designed to streamline the process of converting the PDF text of the judgments and summaries into a clean, human-readable format. The extracted texts along with their associated metadata are saved to a .tsv file.</p></sec></sec><sec id="sec0008"><title>Limitations</title><p id="para0044">The dataset is limited in size. South Africa is a low-resource country in terms of NLP resources. All indigenous languages and South African dialects of foreign languages are not well represented in available NLP datasets and models. Therefore, even though the dataset is much smaller than available document summarization datasets, it is still a significant amount of data. Also, other English models can easily be adapted to cater for the South African dialect and legal domains. Furthermore, the dataset was collected from the Supreme Court of Appeal website, and more content is still being uploaded, making the data potentially high resource in the future.</p></sec><sec id="sec0009"><title>Ethics Statement</title><p id="para0045">The authors have read and followed the ethical requirements for publication in Data in Brief and confirmed that the current work does not involve human subjects, animal experiments, or data collected from social media platforms. The source data is a public document and is exempt from copyright protection: in accordance with Section 12(8)(a) of the South African Copyright Act (Act No. 98 of 1978), no copyright shall subsist in official texts of a legislative, administrative, or legal nature, official translations of such texts, speeches of a political nature, speeches delivered in the course of legal proceedings, or in news of the day that are mere items of press information. This provision ensures that court judgments and similar legal documents are part of the public domain and may be freely reused for academic and research purposes<xref rid="cit_8" ref-type="fn">8</xref></p></sec><sec id="sec0010"><title>Credit Author Statement</title><p id="para0047"><bold>Idris Abdulmumin:</bold> Conceptualization, Methodology, Software, Writing - Original Draft. <bold>Vukosi Marivate:</bold> Supervision, Writing - Original Draft.</p></sec></body><back><ref-list id="cebibl1"><title>References</title><ref id="bib0001"><label>1</label><element-citation publication-type="book" id="sbref0001"><person-group person-group-type="author"><name><surname>Shukla</surname><given-names>A.</given-names></name><etal/></person-group><part-title>Legal case document summarization: extractive and abstractive methods and their evaluation</part-title><person-group person-group-type="editor"><name><surname>He</surname><given-names>Y.</given-names></name><name><surname>Ji</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>S.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Chang</surname><given-names>C.-H.</given-names></name></person-group><source>Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing</source><volume>1</volume><year>2022</year><publisher-name>Association for Computational Linguistics</publisher-name><fpage>1048</fpage><lpage>1064</lpage></element-citation><note><p><ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/2022.aacl-main.77" id="interref0014">https://aclanthology.org/2022.aacl-main.77</ext-link>.</p></note></ref><ref id="bib0002"><label>2</label><element-citation publication-type="book" id="sbref0002"><person-group person-group-type="author"><name><surname>Beltagy</surname><given-names>I.</given-names></name><name><surname>Peters</surname><given-names>M.E.</given-names></name><name><surname>Cohan</surname><given-names>A.</given-names></name></person-group><part-title>Longformer: The Long-Document Transformer</part-title><year>2020</year></element-citation></ref><ref id="bib0003"><label>3</label><element-citation publication-type="book" id="sbref0003"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Saleh</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>P.J.</given-names></name></person-group><part-title>PEGASUS: pre-training with extracted gap-sentences for abstractive summarization</part-title><source>ICML&#x02019;20: Proceedings of the 37th International Conference on Machine Learning</source><year>Jul. 2020</year><publisher-name>ACM</publisher-name><fpage>11328</fpage><lpage>11339</lpage><pub-id pub-id-type="doi">10.5555/3524938.3525989</pub-id></element-citation></ref><ref id="bib0004"><label>4</label><mixed-citation publication-type="other" id="tboref0001">W. Kry&#x0015b;ci&#x00144;ski, N. Rajani, D. Agarwal, C. Xiong, and D. Radev, BookSum: a collection of datasets for long-form narrative summarization, in Y. Goldberg, Z. Kozareva, Y. Zhang (Eds.), Findings of the Association of Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, 2022, pp. 6536-6558 [Online]. Available. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/2022.findings-emnlp.488/" id="new0002">https://aclanthology.org/2022.findings-emnlp.488/</ext-link>.</mixed-citation></ref><ref id="bib0005"><label>5</label><element-citation publication-type="book" id="sbref0005"><person-group person-group-type="author"><name><surname>Bird</surname><given-names>S.</given-names></name><name><surname>Loper</surname><given-names>E.</given-names></name></person-group><part-title>NLTK: the natural language toolkit</part-title><source>Proceedings of the ACL Interactive Poster and Demonstration Sessions</source><year>2004</year><publisher-name>Association for Computational Linguistics</publisher-name><publisher-loc>Barcelona, Spain</publisher-loc><fpage>214</fpage><lpage>217</lpage><comment>[Online]. Available</comment></element-citation><note><p><ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/P04-3031" id="interref0015">https://aclanthology.org/P04-3031</ext-link>.</p></note></ref><ref id="bib0006"><label>6</label><element-citation publication-type="book" id="sbref0006"><person-group person-group-type="author"><name><surname>Petrov</surname><given-names>S.</given-names></name><name><surname>Das</surname><given-names>D.</given-names></name><name><surname>McDonald</surname><given-names>R.</given-names></name></person-group><part-title>A universal part-of-speech tagset</part-title><person-group person-group-type="editor"><name><surname>Calzolari</surname><given-names>N.</given-names></name><name><surname>Choukri</surname><given-names>K.</given-names></name><name><surname>Declerck</surname><given-names>T.</given-names></name><name><surname>Do&#x0011f;an</surname><given-names>M.U.</given-names></name><name><surname>Maegaard</surname><given-names>B.</given-names></name><name><surname>Mariani</surname><given-names>J.</given-names></name><name><surname>Moreno</surname><given-names>A.</given-names></name><name><surname>Odijk</surname><given-names>J.</given-names></name><name><surname>Piperidis</surname><given-names>S.</given-names></name></person-group><source>Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&#x02019;12)</source><year>2012</year><publisher-name>European Language Resources Association (ELRA)</publisher-name><publisher-loc>Istanbul, Turkey</publisher-loc><fpage>2089</fpage><lpage>2096</lpage><comment>[Online]. Available</comment></element-citation><note><p><ext-link ext-link-type="uri" xlink:href="http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf" id="interref0016">http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf</ext-link>.</p></note></ref><ref id="bib0007"><label>7</label><element-citation publication-type="book" id="sbref0007"><person-group person-group-type="author"><name><surname>Pennington</surname><given-names>J.</given-names></name><name><surname>Socher</surname><given-names>R.</given-names></name><name><surname>Manning</surname><given-names>C.</given-names></name></person-group><part-title>GloVe: global vectors for word representation</part-title><person-group person-group-type="editor"><name><surname>Moschitti</surname><given-names>A.</given-names></name><name><surname>Pang</surname><given-names>B.</given-names></name><name><surname>Daelemans</surname><given-names>W.</given-names></name></person-group><source>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</source><year>Oct. 2014</year><publisher-name>Association for Computational Linguistics</publisher-name><publisher-loc>Doha, Qatar</publisher-loc><fpage>1532</fpage><lpage>1543</lpage><pub-id pub-id-type="doi">10.3115/v1/D14-1162</pub-id></element-citation></ref></ref-list><sec id="sec0011"><title>Appendix</title><p id="para0050">
<bold>A &#x02013; Dataset Directory Structure</bold>
<fig id="fig0008"><label>Fig. A.1</label><caption><p>The directory structure of the ZaSCA-Sum dataset.</p></caption><alt-text id="alt0009">Fig A1</alt-text><graphic xlink:href="gr8" id="celink0008"/></fig><fig id="fig0009"><label>Fig. A.2</label><caption><p>The directory structure of the unzipped raw data folder in the ZaSCA-Sum dataset.</p></caption><alt-text id="alt0010">Fig A2</alt-text><graphic xlink:href="gr9" id="celink0009"/></fig></p><p id="para0051">
<bold>B &#x02013; Distribution of Judgment Types</bold>
<fig id="fig0010"><label>Fig. B.1</label><caption><p>Judgment-type distribution.</p></caption><alt-text id="alt0011">Fig B1</alt-text><graphic xlink:href="gr10" id="celink0010"/></fig></p><p id="para0052">
<bold>C &#x02013; Judgments and Summaries Density Distribution</bold>
<fig id="fig0011"><label>Fig. C.1</label><caption><p>Sentence and word density distributions.</p></caption><alt-text id="alt0012">Fig C1</alt-text><graphic xlink:href="gr11" id="celink0011"/></fig></p><p id="para0053">
<bold>D &#x02013; Unknown words, Stop words, Punctuation and Part-of-Speech Tags</bold>
<fig id="fig0012"><label>Fig. D.1</label><caption><p>Part of Speech Tags in Judgment Texts.</p></caption><alt-text id="alt0013">Fig D1</alt-text><graphic xlink:href="gr12" id="celink0012"/></fig><fig id="fig0013"><label>Fig. D.2</label><caption><p>Part of Speech Tags in Summary Texts.</p></caption><alt-text id="alt0014">Fig D2</alt-text><graphic xlink:href="gr13" id="celink0013"/></fig><fig id="fig0014"><label>Fig. D.3</label><caption><p>Stopwords in judgment and summary texts.</p></caption><alt-text id="alt0015">Fig D3</alt-text><graphic xlink:href="gr14" id="celink0014"/></fig><fig id="fig0015"><label>Fig. D.4</label><caption><p>Unknown words in judgment and summary texts.</p></caption><alt-text id="alt0016">Fig D4</alt-text><graphic xlink:href="gr15" id="celink0015"/></fig></p><p id="para0054">
<bold>E &#x02013; Topics in Judgments and Summaries extracted by BERTopic</bold>
<fig id="fig0016"><label>Fig. E.1</label><caption><p>Top 12 topics in judgment texts.</p></caption><alt-text id="alt0017">Fig E1</alt-text><graphic xlink:href="gr16" id="celink0016"/></fig><fig id="fig0017"><label>Fig. E.2</label><caption><p>Top 12 topics in summary texts.</p></caption><alt-text id="alt0018">Fig E2</alt-text><graphic xlink:href="gr17" id="celink0017"/></fig></p></sec><sec sec-type="data-availability" id="refdata001"><title>Data Availability</title><p id="para9001">
<list list-type="simple" id="dacelist0001"><list-item id="rdlistitem0001"><p id="para9002">Huggingface<ext-link ext-link-type="uri" xlink:href="https://huggingface.co/datasets/dsfsi/zasca-sum" id="interref0001">ZASCA-Sum: A Dataset of the South Africa Supreme Courts of Appeal Judgments and Media Summaries for Legal Documents Summarization Research (Original data)</ext-link>.</p></list-item></list>
</p></sec><ack id="ack0001"><title>Acknowledgments</title><p id="para0048">This work acknowledges the legal guidance on publishing the dataset from Dr Chijioke Okorie of the Data Science Law Lab of the University of Pretoria. Idris Abdulmumin gratefully acknowledges the ABSA UP Chair of Data Science for funding his postdoctoral research. This research received no specific grant from funding agencies in the public, commercial, or not-for-profit sectors.</p><sec id="sec2009"><title>Declaration of Competing Interest</title><p id="para0049">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></sec></ack><fn-group><fn id="cit_1"><label>1</label><p id="notep0001"><ext-link ext-link-type="uri" xlink:href="https://www.sec.gov/enforcement-litigation/litigation-releases" id="interref0006">https://www.sec.gov/enforcement-litigation/litigation-releases</ext-link>.</p></fn><fn id="cit_2"><label>2</label><p id="notep0002"><ext-link ext-link-type="uri" xlink:href="https://huggingface.co/nsi319/legal-pegasus" id="interref0007">https://huggingface.co/nsi319/legal-pegasus</ext-link>.</p></fn><fn id="cit_3"><label>3</label><p id="notep0003"><ext-link ext-link-type="uri" xlink:href="https://huggingface.co/nsi319/legal-led-base-16384" id="interref0008">https://huggingface.co/nsi319/legal-led-base-16384</ext-link>.</p></fn><fn id="cit_4"><label>4</label><p id="notep0004"><ext-link ext-link-type="uri" xlink:href="https://www.supremecourtofappeal.org.za/index.php/component/jdownloads" id="interref0009">https://www.supremecourtofappeal.org.za/index.php/component/jdownloads</ext-link>. Accessed between February 19, 2024, and November 5, 2024.</p></fn><fn id="cit_5"><label>5</label><p id="notep0005"><ext-link ext-link-type="uri" xlink:href="https://www.supremecourtofappeal.org.za/index.php/component/jdownloads" id="interref0010">https://www.supremecourtofappeal.org.za/index.php/component/jdownloads</ext-link>.</p></fn><fn id="cit_6"><label>6</label><p id="notep0006"><ext-link ext-link-type="uri" xlink:href="https://www.supremecourtofappeal.org.za/index.php/judgements/electoral-court-judgments/category/36-electoral-court-judgments" id="interref0011">https://www.supremecourtofappeal.org.za/index.php/judgements/electoral-court-judgments/category/36-electoral-court-judgments</ext-link>.</p></fn><fn id="cit_7"><label>7</label><p id="notep0007"><ext-link ext-link-type="uri" xlink:href="https://www.supremecourtofappeal.org.za/index.php/judgements/category/4-judgments" id="interref0012">https://www.supremecourtofappeal.org.za/index.php/judgements/category/4-judgments</ext-link>.</p></fn><fn id="cit_8"><label>8</label><p id="notep0008"><ext-link ext-link-type="uri" xlink:href="https://www.gov.za/sites/default/files/gcis_document/201504/act-98-1978.pdf" id="interref0013">https://www.gov.za/sites/default/files/gcis_document/201504/act-98-1978.pdf</ext-link>.</p></fn></fn-group></back></article>