<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><?properties manuscript?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-journal-id">101730678</journal-id><journal-id journal-id-type="pubmed-jr-id">47808</journal-id><journal-id journal-id-type="nlm-ta">Conf Comput Commun Secur</journal-id><journal-id journal-id-type="iso-abbrev">Conf Comput Commun Secur</journal-id><journal-title-group><journal-title>Conference on Computer and Communications Security : proceedings of the ... conference on computer and communications security. ACM Conference on Computer and Communications Security</journal-title></journal-title-group><issn pub-type="epub">1543-7221</issn></journal-meta><article-meta><article-id pub-id-type="pmid">40401199</article-id><article-id pub-id-type="pmc">PMC12094715</article-id><article-id pub-id-type="doi">10.1145/3658644.3690279</article-id><article-id pub-id-type="manuscript">NIHMS2081474</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Ruixuan</given-names></name><aff id="A1">Emory University, Atlanta, USA</aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Tianhao</given-names></name><aff id="A2">University of Virginia, Charlottesville, USA</aff></contrib><contrib contrib-type="author"><name><surname>Cao</surname><given-names>Yang</given-names></name><aff id="A3">Tokyo Institute of Technology, Tokyo, Japan</aff></contrib><contrib contrib-type="author"><name><surname>Xiong</surname><given-names>Li</given-names></name><aff id="A4">Emory University, Atlanta, USA</aff></contrib></contrib-group><author-notes><corresp id="CR1">
<email>ruixuan.liu2@emory.edu</email>
</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>15</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="ppub"><month>10</month><year>2024</year></pub-date><pub-date pub-type="epub"><day>9</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>21</day><month>5</month><year>2025</year></pub-date><volume>2024</volume><fpage>3511</fpage><lpage>3524</lpage><permissions><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a Creative Commons Attribution International 4.0 License.</license-p></license></permissions><abstract id="ABS1"><p id="P1">The pre-training and fine-tuning paradigm has demonstrated its effectiveness and has become the standard approach for tailoring language models to various tasks. Currently, community-based platforms offer easy access to various pre-trained models, as anyone can publish without strict validation processes. However, a released pre-trained model can be a privacy trap for fine-tuning datasets if it is carefully designed. In this work, we propose PreCurious framework to reveal the new attack surface where the attacker releases the pre-trained model and gets a black-box access to the final fine-tuned model. PreCurious aims to escalate the general privacy risk of both membership inference and data extraction on the fine-tuning dataset. The key intuition behind PreCurious is to manipulate the memorization stage of the pre-trained model and guide fine-tuning with a seemingly legitimate configuration. While empirical and theoretical evidence suggests that parameter-efficient and differentially private fine-tuning techniques can defend against privacy attacks on a fine-tuned model, PreCurious demonstrates the possibility of breaking up this invulnerability in a stealthy manner compared to fine-tuning on a benign pre-trained model. While DP provides some mitigation for membership inference attack, by further leveraging a sanitized dataset, PreCurious demonstrates potential vulnerabilities for targeted data extraction even under differentially private tuning with a strict privacy budget e.g. <inline-formula><mml:math id="M1" display="inline"><mml:mi>&#x003f5;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula>. Thus, PreCurious raises warnings for users on the potential risks of downloading pre-trained models from unknown sources, relying solely on tutorials or common-sense defenses, and releasing sanitized datasets even after perfect scrubbing.</p></abstract><kwd-group><kwd>Privacy Attack</kwd><kwd>Language Model</kwd><kwd>Pre-Training</kwd></kwd-group></article-meta></front><body><sec id="S1"><label>1</label><title>Introduction</title><p id="P2">The pre-training and fine-tuning paradigm has become the standard approach for tailoring language models (LMs) to various tasks, such as the medical domain [<xref rid="R15" ref-type="bibr">15</xref>, <xref rid="R22" ref-type="bibr">22</xref>]. In this approach, a language model is pre-trained on a large, general dataset and then fine-tuned on a smaller, domain-specific dataset. Privacy risks arise when the fine-tuning data is private and the fine-tuned model can be accessed as a service [<xref rid="R34" ref-type="bibr">34</xref>]. One realistic scenario is that a hospital fine-tunes a model using local Electronic Health Record (EHR) data and then shares the API with other hospitals that lack such expertise. Existing works broadly explore the privacy risks of training data via black-box access of the model [<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R6" ref-type="bibr">6</xref>, <xref rid="R41" ref-type="bibr">41</xref>], which is also applicable to the fine-tuned model.</p><p id="P3">In this paper, we reveal a new privacy attack surface where an attacker aims to escalate the privacy risk of the fine-tuning data from a fine-tuned model by manipulating the pre-trained language model loaded by the user before fine-tuning and then getting the black-box access to the fine-tuned model. This is realistic since anyone can publish models on community-based platforms (e.g., Huggingface [<xref rid="R2" ref-type="bibr">2</xref>], GitHub [<xref rid="R1" ref-type="bibr">1</xref>]) without stringent validation processes. A fine-tuning user may inadvertently download an untrusted pretrained model from compromised sources, especially when popular models have different variants on platforms like Hugging Face. For instance, a victim could make a typo during the download process or fall for a malicious higher-version package registered with the same name as a legitimate model.</p><p id="P4">Previous work [<xref rid="R44" ref-type="bibr">44</xref>] explored additional adversarial access besides the black box access of the model by injecting poisoned data in the training dataset to amplify the privacy risk, which requires the adversarial capability of accessing/crafting training data. A recent work [<xref rid="R43" ref-type="bibr">43</xref>] manipulates pre-trained (upstream) image classification model for increasing the privacy risk of downstream models, but is limited to property inference attacks that infer whether images with a specific attribute are used for training. In our threat model, the attacker aims to escalate the privacy risk by manipulating the released pre-trained model, without assuming access to the fine-tuning process or fine-tuning dataset. Our adversarial goal is to amplify fundamental privacy threats of membership inference attack [<xref rid="R3" ref-type="bibr">3</xref>] and data extraction [<xref rid="R6" ref-type="bibr">6</xref>] in the fine-tuned language model, compared to the one fine-tuned from a benign pre-trained model.</p><p id="P5">It is non-trivial to achieve our privacy risk amplification goal since parameter-efficient fine-tuning (PEFT) techniques such as Adapter [<xref rid="R37" ref-type="bibr">37</xref>] and LoRA [<xref rid="R14" ref-type="bibr">14</xref>] have been established to have a privacy invulnerability property [<xref rid="R34" ref-type="bibr">34</xref>, <xref rid="R46" ref-type="bibr">46</xref>]. This is demonstrated in <xref rid="F1" ref-type="fig">Figure 1</xref> which shows the privacy vulnerability (measured in membership inference attack (MIA) effectiveness in AUC) for different fine-tuning methods vs. the fine-tuning epochs (left) and utility of the fine-tuned model (right) (measured in validation perplexity (PPL)). We can see that the Adaptor fine-tuning (Adaptor-FT) exhibit a very low vulnerability. At the same time, the training efficiency introduced by PEFT [<xref rid="R12" ref-type="bibr">12</xref>, <xref rid="R26" ref-type="bibr">26</xref>] makes it broadly applicable for LMs, especially encouraging differentially private (DP) fine-tuning for a large model [<xref rid="R24" ref-type="bibr">24</xref>], which makes the privacy attacks on the fine-tuned model more challenging.</p><p id="P6">Our key intuition is to manipulate the memorization level of the pre-trained model by exploiting PEFT. Since the majority of the pre-trained model is frozen during PEFT, we can better influence the behavior of the trainable modules for amplifying risks in the fine-tuned model. <xref rid="F2" ref-type="fig">Figure 2</xref> illustrates our proposed framework where an attacker downloads a benign large model, manipulates it by an auxiliary dataset, and uploads it to an untrusted source for victims. We exploit side information such as the stopping criterion and the fine-tuning method by implicitly guiding the fine-tuning victims through documents or tutorials, proposing <italic toggle="yes">lagging</italic> or <italic toggle="yes">accelerating</italic> strategies for cases with or without early stopping and <italic toggle="yes">anti-freezing</italic> strategy when fine-tuning method is known. Additionally, we attempt to make full use of the public information, for example, a released de-identified dataset, to further enhance the attack capability.</p><p id="P7">We demonstrate that our attack can successfully amplify various privacy risks. <xref rid="F1" ref-type="fig">Figure 1</xref> illustrates the increased privacy vulnerability of MIA by our methods on both Head-FT and Adaptor-FT. More generally, for MIA, we compare PreCurious with benign GPT-2 [<xref rid="R38" ref-type="bibr">38</xref>] on the same black-box attack and demonstrate that by manipulating the pre-trained model, the true-positive-rate (TPR) at a false-positive-rate (FPR) of 0.01% on Enron [<xref rid="R21" ref-type="bibr">21</xref>], PubMed [<xref rid="R9" ref-type="bibr">9</xref>] and PTB [<xref rid="R31" ref-type="bibr">31</xref>] datasets is boosted by 8&#x000d7;, 131&#x000d7; and 36&#x000d7;, respectively. For untargeted data extraction attack, we increase the times for a less duplicated sub-sequence shown in the pool of filtered generations by around 10&#x000d7;. For targeted data extraction attack on Enron dataset, fine-tuning over benign model initialization cannot expose any secrets when fine-tuning with a strong DP level <inline-formula><mml:math id="M37" display="inline"><mml:mo>(</mml:mo><mml:mi>&#x003f5;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> while <italic toggle="yes">PreCurious</italic> can extract 3 target email addresses with valid exposure values. As advocated by previous work [<xref rid="R44" ref-type="bibr">44</xref>], we also audit the stealthiness of <italic toggle="yes">PreCurious</italic> and propose a mitigation method to make it more stealthy.</p><p id="P8">Our contribution can be summarized as follows:</p><list list-type="bullet" id="L2"><list-item><p id="P9">We propose a framework <italic toggle="yes">PreCurious</italic> to amplify the privacy risk of both membership inference and data extraction in the pre-training and fine-tuning paradigm, revealing the risk of fine-tuning over an unofficially released pre-trained LM.</p></list-item><list-item><p id="P10">We propose two memorization manipulating strategies to craft the pre-trained model for fine-tuning with or without early-stopping. We further exploit the side-information of PEFT or sanitized dataset to enhance the attack effectiveness.</p></list-item><list-item><p id="P11">We demonstrate the underestimated vulnerability of commonsense defenses, including regularization, differentially private fine-tuning, and deduplication with <italic toggle="yes">PreCurious</italic>, particularly highlighting risks for users who rely on common-sense defenses without auditing privacy and training dynamics.</p></list-item><list-item><p id="P12">We demonstrate the risks of publishing de-identified datasets solely by removing personally identifiable information (PII), as <italic toggle="yes">PreCurious</italic> can exploit the context to extract targeted secrets if the original datasets are involved in future fine-tuning, underscoring significant vulnerabilities in the data release.</p></list-item></list></sec><sec id="S2"><label>2</label><title>Threat Model and Preliminaries</title><p id="P13">We formulate the threat model and preliminaries in this section. The attack framework of <italic toggle="yes">PreCurious</italic> sits in the pre-training and fine-tuning paradigm of language models (LMs) to amplify data leakage in the fine-tuning stage.</p><p id="P14">Our target victim model is fine-tuned with the basic next-token prediction task. The model aims to predict the next token <inline-formula><mml:math id="M38" display="inline"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> given the previous tokens <inline-formula><mml:math id="M39" display="inline"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> for a given text sequence with <inline-formula><mml:math id="M40" display="inline"><mml:mi>T</mml:mi></mml:math></inline-formula> tokens. The fine-tuning involves minimizing the objective: <inline-formula><mml:math id="M41" display="inline"><mml:mi>&#x02112;</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula><mml:math id="M42" display="inline"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> is the probability of <inline-formula><mml:math id="M43" display="inline"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> from the softmax output of the model <inline-formula><mml:math id="M44" display="inline"><mml:mi>&#x003b8;</mml:mi></mml:math></inline-formula>. The trained model can generate new text by iteratively sampling <inline-formula><mml:math id="M45" display="inline"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>&#x002c6;</mml:mi></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and feeding it to sample the next token.</p><sec id="S3"><label>2.1</label><title>Parameter-Efficient Fine-tuning (PEFT)</title><p id="P15">Denoting the fine-tuned model as <inline-formula><mml:math id="M46" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02218;</mml:mo><mml:mi>&#x003a6;</mml:mi></mml:math></inline-formula>, the key idea of PEFT is only optimizing over small modules <inline-formula><mml:math id="M47" display="inline"><mml:mi>&#x003a6;</mml:mi></mml:math></inline-formula> while freezing <inline-formula><mml:math id="M48" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, which transfers the fine-tuning objective as <inline-formula><mml:math id="M49" display="inline"><mml:mi>&#x02112;</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003a6;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p><p id="P16">One line of <italic toggle="yes">selective</italic> PEFT selects a portion of parameters in <inline-formula><mml:math id="M50" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> as <inline-formula><mml:math id="M51" display="inline"><mml:mi>&#x003a6;</mml:mi></mml:math></inline-formula>, such as Head-FT with a few top layers [<xref rid="R10" ref-type="bibr">10</xref>] and Bitfit-FT with the bias terms of the model [<xref rid="R52" ref-type="bibr">52</xref>]. The other line of PEFT introduces new randomly initialized modules as <inline-formula><mml:math id="M52" display="inline"><mml:mi>&#x003a6;</mml:mi></mml:math></inline-formula> as plug-in for <inline-formula><mml:math id="M53" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. For example, <italic toggle="yes">additive</italic> method Adapter-FT [<xref rid="R13" ref-type="bibr">13</xref>] inserts small and trainable fully connected networks <inline-formula><mml:math id="M54" display="inline"><mml:mi>&#x003a6;</mml:mi></mml:math></inline-formula> after transformer sub-layers in <inline-formula><mml:math id="M55" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. The <italic toggle="yes">reparameterization-based</italic> method LoRA-FT [<xref rid="R14" ref-type="bibr">14</xref>] employs a low-rank matrix decomposition to parameterize the weight updates, and <inline-formula><mml:math id="M56" display="inline"><mml:mi>&#x003a6;</mml:mi></mml:math></inline-formula> indicates parameters for the low-rank matrices.</p></sec><sec id="S4"><label>2.2</label><title>Threat Model</title><p id="P17"><italic toggle="yes">PreCurious</italic> indicates the <underline>pre</underline>-trained model releaser is <underline>curious</underline> about the private fine-tuning dataset <inline-formula><mml:math id="M57" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>&#x1d49f;</mml:mi></mml:math></inline-formula>. We consider the model fine-tuner as the challenger <inline-formula><mml:math id="M58" display="inline"><mml:mi>C</mml:mi></mml:math></inline-formula> (or victim), and pre-trained model publisher as the adversary <inline-formula><mml:math id="M59" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula>.</p><sec id="S5"><label>2.2.1</label><title>Adversarial Capabilities.</title><p id="P18">We make two common adversarial capability assumptions. First, we follow a common assumption [<xref rid="R32" ref-type="bibr">32</xref>, <xref rid="R39" ref-type="bibr">39</xref>, <xref rid="R48" ref-type="bibr">48</xref>, <xref rid="R50" ref-type="bibr">50</xref>] that the adversary can query the loss value for a given sample via black-box access. Second, following previous works [<xref rid="R17" ref-type="bibr">17</xref>, <xref rid="R34" ref-type="bibr">34</xref>, <xref rid="R39" ref-type="bibr">39</xref>, <xref rid="R41" ref-type="bibr">41</xref>, <xref rid="R44" ref-type="bibr">44</xref>, <xref rid="R45" ref-type="bibr">45</xref>, <xref rid="R48" ref-type="bibr">48</xref>], we assume the adversary has an auxiliary dataset <inline-formula><mml:math id="M60" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>&#x1d49f;</mml:mi></mml:math></inline-formula> drawn from the same distribution but disjoint from the fine-tuning dataset <inline-formula><mml:math id="M61" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Different from capabilities in backdoor attacks on the pre-trained model, we do not assume either access to pre-training dataset of the original backbone [<xref rid="R18" ref-type="bibr">18</xref>] or the access to the samples in downstream dataset [<xref rid="R53" ref-type="bibr">53</xref>]. Additionally, we do not require capability of injecting poisoned data [<xref rid="R44" ref-type="bibr">44</xref>] or tampering the fine-tuning process.</p><p id="P19">Distinguished from all existing works, the adversary in <italic toggle="yes">PreCurious</italic> releases the pre-trained model with seemingly legitimate configuration documents, which is very common when sharing customized models on open-sourced platforms. We also note that even for popular pre-trained models, the victim may inadvertently download an untrusted <inline-formula><mml:math id="M62" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. In this case, attackers could use the official model&#x02019;s default configuration in tutorials, which victims assume as correct. First, typographical errors during the search and download process, such as <monospace>hf_hub_download(repo_id=NAME_WITH_TYPO)</monospace> in Hugging Face, could lead to the acquisition of a malicious model. Second, attackers could register publicly available higher-version packages with the same name as the legitimate model, which could be automatically installed via library management tools. Finally, the attacker could compromise the repository&#x02019;s infrastructure and replacing the legitimate pre-trained model with a malicious one.</p><p id="P20">The seemingly legitimate configuration <inline-formula><mml:math id="M63" display="inline"><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>stop</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>peft</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> includes: 1) stopping criterion <inline-formula><mml:math id="M64" display="inline"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>stop</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext>epoch</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext>perf</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> of stopping-by-epochs or early-stopping-by-performance without imposing fixed hyper-parameters, and 2) PEFT strategy <inline-formula><mml:math id="M65" display="inline"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>peft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> like Adapter-FT or LoRA-FT that can be easily set using open-source frameworks [<xref rid="R37" ref-type="bibr">37</xref>]. <inline-formula><mml:math id="M66" display="inline"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>peft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is optional and only used for an accelerated variant in <xref rid="S18" ref-type="sec">Section 3.2.2</xref>.</p><p id="P21">We do not require the adversarial capability to pre-train a language model from scratch. Thus, we assume the released pre-trained model <inline-formula><mml:math id="M67" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> is crafted from a benign model <inline-formula><mml:math id="M68" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> downloaded from a trusted source.</p></sec><sec id="S6"><label>2.2.2</label><title>Privacy Game.</title><p id="P22">Now we construct the general privacy game between a challenger <inline-formula><mml:math id="M69" display="inline"><mml:mi>C</mml:mi></mml:math></inline-formula> (the model fine-tuner) and an adversary <inline-formula><mml:math id="M70" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> (the pre-trained model publisher) in Game 1.</p><p id="P23">Game 1 (Privacy game in <italic toggle="yes">PreCurious</italic>).</p><list list-type="bullet" id="L4"><list-item><p id="P24"><italic toggle="yes">The adversary crafts and releases model with a suggested configuration</italic>
<inline-formula><mml:math id="M71" display="inline"><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">aux</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">benign</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p></list-item><list-item><p id="P25"><italic toggle="yes">The challenger samples a training dataset</italic>
<inline-formula><mml:math id="M72" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>D</mml:mi></mml:math></inline-formula>
<italic toggle="yes">and a secret</italic>
<inline-formula><mml:math id="M73" display="inline"><mml:mi>z</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>&#x1d4b0;</mml:mi></mml:math></inline-formula>
<italic toggle="yes">(such that <inline-formula><mml:math id="M74" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02229;</mml:mo><mml:mi>&#x1d4b0;</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x02205;</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula></italic>, <italic toggle="yes">combining as <inline-formula><mml:math id="M75" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0222a;</mml:mo><mml:mo>{</mml:mo><mml:mi>z</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula></italic></p></list-item><list-item><p id="P26"><italic toggle="yes">The challenger loads <inline-formula><mml:math id="M76" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula></italic> as the model initialization, follows <inline-formula><mml:math id="M77" display="inline"><mml:mi>C</mml:mi></mml:math></inline-formula>
<italic toggle="yes">in fine-tuning and releases the black-box access to the final model</italic>
<inline-formula><mml:math id="M78" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p></list-item><list-item><p id="P27"><italic toggle="yes">The adversary queries <inline-formula><mml:math id="M79" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and emits a guess <inline-formula><mml:math id="M80" display="inline"><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>&#x002c6;</mml:mi></mml:mover><mml:mo>&#x02208;</mml:mo><mml:mi>&#x1d4b0;</mml:mi></mml:math></inline-formula></italic>.</p></list-item><list-item><p id="P28"><italic toggle="yes">The adversary wins the game if</italic>
<inline-formula><mml:math id="M81" display="inline"><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>&#x002c6;</mml:mi></mml:mover><mml:mo>=</mml:mo><mml:mi>z</mml:mi></mml:math></inline-formula>.</p></list-item></list><p id="P29">We use <inline-formula><mml:math id="M82" display="inline"><mml:mi>&#x1d4b0;</mml:mi></mml:math></inline-formula> to denote the secret universe of <inline-formula><mml:math id="M83" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Removing the procedures in red and replacing <inline-formula><mml:math id="M84" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> with a benign model <inline-formula><mml:math id="M85" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> reduces Game 1 to a conventional privacy game.</p></sec><sec id="S7"><label>2.2.3</label><title>Adversarial Goal.</title><p id="P30">The adversary aims to increase the privacy risk in the fine-tuning training dataset <inline-formula><mml:math id="M86" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. We focus on two representative privacy notions as follows:</p><list list-type="bullet" id="L6"><list-item><p id="P31"><bold>Membership Priavcy</bold> [<xref rid="R41" ref-type="bibr">41</xref>] is defined on the existence of a given sample in the fine-tuning dataset <inline-formula><mml:math id="M87" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p></list-item><list-item><p id="P32"><bold>Extraction Privacy</bold> [<xref rid="R6" ref-type="bibr">6</xref>] is defined on the verbatim extraction of a subsequence in <inline-formula><mml:math id="M88" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. The extraction is targeted if the attacker defines the format of secrets before the attack.</p></list-item></list><p id="P33">Concretely, <inline-formula><mml:math id="M89" display="inline"><mml:mi>&#x1d4b0;</mml:mi></mml:math></inline-formula> covers both membership privacy and extraction privacy by different instantiations. For example, for membership inference, <inline-formula><mml:math id="M90" display="inline"><mml:mi>&#x1d4b0;</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x022a5;</mml:mo><mml:mo>}</mml:mo></mml:math></inline-formula> denotes two cases where a sample x is or is not in <inline-formula><mml:math id="M91" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. For data extraction, <inline-formula><mml:math id="M92" display="inline"><mml:mi>&#x1d4b0;</mml:mi></mml:math></inline-formula> consists of the collection of all candidate secrets for a piece of text in <inline-formula><mml:math id="M93" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p id="P34">Furthermore, the adversary aims to amplify the privacy risk in <inline-formula><mml:math id="M94" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> compared to fine-tuning from a benign model, as formally defined in Definition 2.1.</p><p id="P35">Definition 2.1 (Successful privacy risk amplification). <italic toggle="yes">Given the same fine-tuning procedure <inline-formula><mml:math id="M95" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> based on a benign model <inline-formula><mml:math id="M96" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula></italic>, <italic toggle="yes">and considering two privacy games differentiated by <inline-formula><mml:math id="M97" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> as</italic>
<inline-formula><mml:math id="M98" display="inline"><mml:mi>&#x1d4a2;</mml:mi><mml:msub><mml:mrow><mml:mo>&#x02243;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mspace width="0.5em"/><mml:msup><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <italic toggle="yes">the privacy risk is amplified by</italic>
<inline-formula><mml:math id="M99" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>
<italic toggle="yes">when the adversarial gain:</italic>
<disp-formula id="FD1">
<mml:math id="M100" display="block"><mml:mi>&#x00394;</mml:mi><mml:mtext mathvariant="italic">Ad</mml:mtext><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x1d4a2;</mml:mi><mml:msub><mml:mrow><mml:mo>&#x02243;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ft</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">Ad</mml:mtext><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>&#x1d49c;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ft</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mspace linebreak="newline"/><mml:mo>-</mml:mo><mml:mtext mathvariant="italic">Ad</mml:mtext><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>&#x1d49c;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ft</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">benign</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:math>
</disp-formula></p><p id="P36">The <inline-formula><mml:math id="M101" display="inline"><mml:msub><mml:mrow><mml:mtext>Adv</mml:mtext></mml:mrow><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>&#x1d49c;</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x022c5;</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula> can be a success metric for reflecting the adversary&#x02019;s advantage for a specific attack, for example, <inline-formula><mml:math id="M102" display="inline"><mml:msub><mml:mrow><mml:mtext>Adv</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow><mml:mrow><mml:mtext>MIA</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>&#x1d49c;</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x022c5;</mml:mo><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x022c5;</mml:mo><mml:mtext>Pr</mml:mtext><mml:mo>[</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mi>&#x002c6;</mml:mi></mml:mover><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:mo>]</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> for MIA [<xref rid="R40" ref-type="bibr">40</xref>].</p><p id="P37">Meanwhile, the adversary should avoid suspicions from victims that the pre-trained model <inline-formula><mml:math id="M103" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> will increase privacy risks in <inline-formula><mml:math id="M104" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. As defined in Definition 2.2, we simulates the risk auditing based on the most ideal assumption for victims to have a benign model. Note that Definition 2.1 is computed on the fine-tuned model, while Definition 2.2 is measured on the pre-trained model.</p><p id="P38">Definition 2.2 (Privacy risk amplification stealthiness). <italic toggle="yes">The pre-trained model <inline-formula><mml:math id="M105" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> output by a crafting algorithm</italic>
<inline-formula><mml:math id="M106" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>
<italic toggle="yes">is stealthy when the adversarial gain compared to</italic>
<inline-formula><mml:math id="M107" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> satisfies:
<disp-formula id="FD2">
<mml:math id="M108" display="block"><mml:mi>&#x00394;</mml:mi><mml:mi>A</mml:mi><mml:mi>d</mml:mi><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x1d4a2;</mml:mi><mml:mo>&#x02243;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>&#x1d49c;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">adv</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mspace linebreak="newline"/><mml:mo>-</mml:mo><mml:mi>A</mml:mi><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>&#x1d4a2;</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>&#x1d49c;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">benign</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x02248;</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:math>
</disp-formula></p><p id="P39">For stealth, the simplest but most effective way is not involving any fine-tuning samples in the crafting phase, which is consistent with the adversarial capabilities defined in <xref rid="S5" ref-type="sec">Section 2.2.1</xref> that <inline-formula><mml:math id="M109" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> knows no exact samples in <inline-formula><mml:math id="M110" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M111" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is disjoint from <inline-formula><mml:math id="M112" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. As models cannot memorize secret before seeing it, the adversarial gain compared to the benign model for <inline-formula><mml:math id="M113" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> should satisfy Definition 2.1.</p></sec></sec><sec id="S8"><label>2.3</label><title>Success Metrics</title><p id="P40">Now we introduce concrete attack effectiveness metrics for different attacks and propose stealthiness metrics for victims to audit the pre-trained model.</p><sec id="S9"><label>2.3.1</label><title>Membership Inference Attack.</title><p id="P41">We use AUC &#x02191; to measure the effectiveness of the attack (&#x02191; means the higher the value the more desirable the metric). As suggested by previous work [<xref rid="R3" ref-type="bibr">3</xref>], we also present results for MIA with <inline-formula><mml:math id="M114" display="inline"><mml:mtext>TPR</mml:mtext><mml:mo>@</mml:mo><mml:mtext>FPR</mml:mtext><mml:mi>&#x003b1;</mml:mi><mml:mo>%</mml:mo></mml:math></inline-formula> &#x02191; given a small <inline-formula><mml:math id="M115" display="inline"><mml:mi>&#x003b1;</mml:mi></mml:math></inline-formula>. A lower <inline-formula><mml:math id="M116" display="inline"><mml:mi>&#x003b1;</mml:mi></mml:math></inline-formula> emphasizes the cost of false positives.</p></sec><sec id="S10"><label>2.3.2</label><title>Data Extraction Attack.</title><p id="P42">For untargeted data extraction, we follow previous work [<xref rid="R23" ref-type="bibr">23</xref>] to capture the portion <inline-formula><mml:math id="M117" display="inline"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> &#x02191; of sub-sequences emitted by the target model that are included in the fine-tuning dataset <inline-formula><mml:math id="M118" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. For targeted data extraction, we use the exposure [<xref rid="R5" ref-type="bibr">5</xref>] to measure if a targeted secret such as a phone number or email address can be reliably extracted.</p></sec><sec id="S11"><label>2.3.3</label><title>Stealthiness.</title><p id="P43">Following Definition 2.2, we propose three representative metrics as indicators of the adversarial gain, and the difference compared with a benign model reflects the stealthiness of the released model.</p><p id="P44">First, we simulate MIA with a non-membership dataset drawn from the same distribution to audit the stealthiness <inline-formula><mml:math id="M119" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mia</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> by using MIA success metrics such as AUC in <xref rid="S9" ref-type="sec">Section 2.3.1</xref>.</p><p id="P45">Second, for simulating the data extraction attack in an efficient way [<xref rid="R4" ref-type="bibr">4</xref>], we use the <inline-formula><mml:math id="M120" display="inline"><mml:mi>k</mml:mi></mml:math></inline-formula>-extractable rate as <inline-formula><mml:math id="M121" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mem</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mtext>-extract</mml:mtext></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula><mml:math id="M122" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">I</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mtext>-extract</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> indicates if the model can generate the suffix <inline-formula><mml:math id="M123" display="inline"><mml:mi>s</mml:mi></mml:math></inline-formula> given a <inline-formula><mml:math id="M124" display="inline"><mml:mi>k</mml:mi></mml:math></inline-formula>-length prefix <inline-formula><mml:math id="M125" display="inline"><mml:mi mathvariant="bold">x</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mi>p</mml:mi><mml:mo>&#x02016;</mml:mo><mml:mi>s</mml:mi><mml:mo>]</mml:mo></mml:math></inline-formula>.</p><p id="P46">Lastly, as overfitting is considered as an important cause of various privacy attacks, the victim may calculate the performance difference <inline-formula><mml:math id="M126" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> between the training and validation dataset as a signal of overfitting: <inline-formula><mml:math id="M127" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>PPL</mml:mtext><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>val</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mtext>PPL</mml:mtext><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, where PPL is a standard performance metric of LMs.</p><p id="P47">Assuming the benign model derives the baseline stealthiness metric <inline-formula><mml:math id="M128" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mia</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula> for AUC, <inline-formula><mml:math id="M129" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mem</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>, and <inline-formula><mml:math id="M130" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>, our goal is to ensure a low gap for <inline-formula><mml:math id="M131" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> compared to the baseline.</p></sec></sec></sec><sec id="S12"><label>3</label><title>Amplifying Privacy Risk with PreCurious</title><p id="P48">In this section, we introduce the <italic toggle="yes">PreCurious</italic> framework shown in <xref rid="F2" ref-type="fig">Figure 2</xref>, crafting methodologies, and the inference pipelines.</p><sec id="S13"><label>3.1</label><title>Attack Overview</title><sec id="S14"><label>3.1.1</label><title>PreCurious Framework.</title><p id="P49">We begin with a high-level overview of the pre-curious attack which involves the following three stages. 1) <bold>Crafting</bold>: the adversary carefully crafts the backbone model before releasing it as a pre-trained model. 2) <bold>Fine-tuning</bold>: the victim initializes the model with the released parameters and starts normal fine-tuning over the private training dataset. 3) <bold>Inferring</bold>: the adversary queries the target model and guesses secrets in <inline-formula><mml:math id="M132" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p id="P50"><italic toggle="yes">PreCurious</italic> focuses on designing the crafting stage for increasing the attack advantage and thus stands as a general framework for a wide range of inferring strategies.</p></sec><sec id="S15"><label>3.1.2</label><title>Key Intuition.</title><p id="P51">From the feasible and limited capabilities in <xref rid="S5" ref-type="sec">Section 2.2.1</xref>, we notice that the one more thing that <inline-formula><mml:math id="M133" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> can manipulate than a conventional attacker is the model initialization in the <bold>crafting</bold> stage. Thus, we can first focus on the design of the model initialization in crafting and keep a basic inferring phase for now.</p><p id="P52">Based on previous lessons on memorization [<xref rid="R4" ref-type="bibr">4</xref>, <xref rid="R34" ref-type="bibr">34</xref>], it is intuitive that using a better trained model as initialization induces over-fitting on fine-tuning data, leading to higher privacy leakage via MIA or data extraction. However, if we consider two models that achieve the same performance after fine-tuning, but one spends more iterations and the other spends fewer iterations, the intuition turns into the opposite: initializing with a less trained model may have a higher privacy risk because it will take more iterations for the model to achieve the same desired performance and the model will have seen the data more times and the influence of a sample is greater. Both directions seem reasonable, we use the toy example in <xref rid="F3" ref-type="fig">Figure 3</xref> to show that the stopping criterion <inline-formula><mml:math id="M134" display="inline"><mml:mi>C</mml:mi></mml:math></inline-formula> is crucial for which intuition can lead to the success defined in Definition 2.1.</p><list list-type="bullet" id="L8"><list-item><p id="P53"><bold>Case I.</bold> In our default setting with the criterion <inline-formula><mml:math id="M135" display="inline"><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext>epoch</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, fine-tuning stops within arbitrary fixed epochs known only to the victim. We expect a model initialization with higher memorization level leads to a higher privacy risk. The <bold>left</bold> figure in <xref rid="F3" ref-type="fig">Figure 3</xref> confirms this intuition, since the privacy risk of <italic toggle="yes">Accelerated Init</italic> given the same number of fine-tuning epochs is higher.</p></list-item><list-item><p id="P54"><bold>Case II</bold>. We consider another case where performance based early-stopping is used to avoid overfitting, for example, the fine-tuning stops when the validation performance achieves a certain level. In the <bold>right</bold> figure of <xref rid="F3" ref-type="fig">Figure 3</xref>, we can observe that the <italic toggle="yes">Lagging Init</italic> has a higher privacy risk given the same validation PPL. Our insight is that a lagging initialization pushes fine-tuners to train more iterations for achieving the same performance, implicitly increasing the number of duplicates for training samples, which has been shown as a cause of higher privacy risk [<xref rid="R23" ref-type="bibr">23</xref>].</p></list-item></list><p id="P55">By considering the stopping criterion when crafting the model initialization, our key intuition is to control the memorization stage for the model initialization on <italic toggle="yes">Lagging</italic> and <italic toggle="yes">Accelerated</italic> directions accordingly for achieving Definition 2.1.</p></sec></sec><sec id="S16"><label>3.2</label><title>Methodology for Crafting</title><p id="P56">Starting from the key intuition, we now introduce methodologies for controlling the two directions. The accelerating by warm-up (<xref rid="S17" ref-type="sec">Section 3.2.1</xref>) and anti-freezing strategy (<xref rid="S18" ref-type="sec">Section 3.2.2</xref>) are proposed for <bold>Case I</bold> while the lagging strategy (<xref rid="S19" ref-type="sec">Section 3.2.3</xref>) is proposed for <bold>Case II</bold>.</p><sec id="S17"><label>3.2.1</label><title>Accelerating by Warm-up (Case I).</title><p id="P57">With no knowledge of specific PEFT methods in <inline-formula><mml:math id="M136" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, we propose a basic method for accelerating the memorization stage in the fine-tuning data domain <inline-formula><mml:math id="M137" display="inline"><mml:mi>&#x1d49f;</mml:mi></mml:math></inline-formula> by fully fine-tuning on <inline-formula><mml:math id="M138" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Thus, for <italic toggle="yes">selective</italic> PEFTs such as Head-FT or Bitfit-FT, the starting point for these trainable parts is already optimized for the domain <inline-formula><mml:math id="M139" display="inline"><mml:mi>&#x1d49f;</mml:mi></mml:math></inline-formula>, further tuning on these parameters can focus on learning the residuals or adjustments necessary to adapt the already domain-tuned representations of the base model to the nuances of <inline-formula><mml:math id="M140" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p id="P58">For <italic toggle="yes">additive</italic> PEFTs such as Adapter [<xref rid="R13" ref-type="bibr">13</xref>] and <italic toggle="yes">reparameterization-based</italic> PEFTs such as LoRA [<xref rid="R14" ref-type="bibr">14</xref>], the inserted modules and low-rank matrices are usually randomly initialized by the victim. It will take some iterations for these randomized parts to fit and enter the memorization-only stage, but it is still faster than fine-tuning on <inline-formula><mml:math id="M141" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> that is pre-trained over the out-of-domain public data.</p></sec><sec id="S18"><label>3.2.2</label><title>Accelerating by Anti-freezing (Case I).</title><p id="P59">When the victim follows the guidance provided by <inline-formula><mml:math id="M142" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> on the choice of PEFT, <inline-formula><mml:math id="M143" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> can utilize this side information for pushing the released model initialization <inline-formula><mml:math id="M144" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> to the memorization-only stage with a more aggressive acceleration.</p><p id="P60">In typical <italic toggle="yes">addictive</italic> and <italic toggle="yes">selective</italic> PEFT training, only the small and random inserted modules are trainable while keeping the rest pretrained parameters frozen. On the contrary, we freeze the inserted / reparameterized modules and tune the backbone in our crafting stage. The intuition is to make the released model equipped with a known PEFT module perfectly fit the data domain at the first step of <inline-formula><mml:math id="M145" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Thus, the first fine-tuning step enters the memorization-only stage [<xref rid="R34" ref-type="bibr">34</xref>] and the privacy risk will increase rapidly.</p><p id="P61">It should be noted that there is still a small amount of randomness because the PEFT modules initialized in <inline-formula><mml:math id="M146" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> by the adversary are different from the one initialized in <inline-formula><mml:math id="M147" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> by the victim if the random seed is not fixed. Thus, we shift the seed in the two stages when performing the accelerated experiments for considering the influence of randomness. By our observation, changing the seed causes subtle differences and does not affect the effectiveness, which may be because the randomly initialized modules are drawn from a common distribution.</p></sec><sec id="S19"><label>3.2.3</label><title>Lagging by Weight Scaling (Case II).</title><p id="P62">In the opposite direction, for creating a lagging model initialization for privacy risk amplification in Case II, the intuitive idea is to make <inline-formula><mml:math id="M148" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> perform worse or farther away from the data domain.</p><p id="P63">Ideally, learning a well-performed model is hard but hurting the utility is easy to achieve by simply spoiling the pre-trained parameters in <inline-formula><mml:math id="M149" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> with random noise, which does not even need the auxiliary knowledge <inline-formula><mml:math id="M150" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. However, an even perturbation on a well generalized pre-trained model cannot specifically manipulate the memorization stage on the fine-tuning domain.</p><p id="P64">For better control of the memorization stage towards the fine-tuning domain, we propose scaling a portion of parameters in the warmed-up backbone with a scaling factor <inline-formula><mml:math id="M151" display="inline"><mml:mi>&#x003b2;</mml:mi></mml:math></inline-formula>, which can be seen as an approximation of dropout [<xref rid="R42" ref-type="bibr">42</xref>]. In each layer of a transformer-based backbone, there is a crucial component of multi-head self-attention (MHA). Given a sequence of <inline-formula><mml:math id="M152" display="inline"><mml:mi>l</mml:mi></mml:math></inline-formula> vectors <inline-formula><mml:math id="M153" display="inline"><mml:mi mathvariant="bold">C</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and a query vector <inline-formula><mml:math id="M154" display="inline"><mml:mi mathvariant="bold">q</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, the MHA output is:
<disp-formula id="FD3">
<label>(1)</label>
<mml:math id="M155" display="block"><mml:mrow><mml:mtext>Attn</mml:mtext><mml:mfenced><mml:mrow><mml:mtext mathvariant="bold">Q</mml:mtext><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mtext mathvariant="bold">K</mml:mtext><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mtext mathvariant="bold">V</mml:mtext></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mtext>softmax</mml:mtext><mml:mfenced><mml:mrow><mml:mfrac><mml:mrow><mml:mtext mathvariant="bold">Q</mml:mtext><mml:msup><mml:mtext mathvariant="bold">K</mml:mtext><mml:mo>&#x022a4;</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mstyle mathvariant="bold"><mml:mi>V</mml:mi></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD4">
<label>(2)</label>
<mml:math id="M156" display="block"><mml:mrow><mml:msub><mml:mrow><mml:mtext>head</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>Attn</mml:mtext><mml:mfenced><mml:mrow><mml:mtext mathvariant="bold">q</mml:mtext><mml:msubsup><mml:mtext mathvariant="bold">W</mml:mtext><mml:mi>q</mml:mi><mml:mrow><mml:mfenced><mml:mi>i</mml:mi></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext mathvariant="bold">C</mml:mtext><mml:msubsup><mml:mtext mathvariant="bold">W</mml:mtext><mml:mi>k</mml:mi><mml:mrow><mml:mfenced><mml:mi>i</mml:mi></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext mathvariant="bold">C</mml:mtext><mml:msubsup><mml:mtext mathvariant="bold">W</mml:mtext><mml:mi>v</mml:mi><mml:mrow><mml:mfenced><mml:mi>i</mml:mi></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD5">
<label>(3)</label>
<mml:math id="M157" display="block"><mml:mrow><mml:mtext>MHA</mml:mtext><mml:mfenced><mml:mrow><mml:mtext mathvariant="bold">C</mml:mtext><mml:mo>,</mml:mo><mml:mtext mathvariant="bold">q</mml:mtext></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mtext>Concat</mml:mtext><mml:mfenced><mml:mrow><mml:msub><mml:mrow><mml:mtext>head</mml:mtext></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mtext>head</mml:mtext></mml:mrow><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>W</mml:mi></mml:mstyle><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M158" display="inline"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="M159" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>.</p><p id="P65">Thus, if we use <inline-formula><mml:math id="M160" display="inline"><mml:mi>&#x003b2;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula> to scale weights <inline-formula><mml:math id="M161" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the magnitudes of the Q, K, and V vectors in <xref rid="FD3" ref-type="disp-formula">Equation (1)</xref> will decrease by a factor of <inline-formula><mml:math id="M162" display="inline"><mml:mi>&#x003b2;</mml:mi></mml:math></inline-formula>. And the attention weights are more evenly distributed. Additionally, scaling down <inline-formula><mml:math id="M163" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> reduces the output magnitude and also hurts the expressiveness. Therefore, a pre-trained model after weight scaling will result in a worse initial performance compared to a benign model. We can apply the weight scaling strategy on the checkpoint after basic warm-up or after the accelerated strategy of anti-freezing for making the memorization degradation more specific to the domain <inline-formula><mml:math id="M164" display="inline"><mml:mi>&#x1d49f;</mml:mi></mml:math></inline-formula>.</p><p id="P66">On the one hand, it makes the model run more iterations to achieve the required performance. On the other hand, the inserted small PEFT modules are encouraged to compensate for the reduced magnitude and expressiveness with a larger gradient magnitude.</p></sec><sec id="S20"><label>3.2.4</label><title>Rewinding for Stealthiness.</title><p id="P67">Since the victim might be suspicious of the crafting behavior, we propose to evade the abnormal values on proposed stealthiness metrics in <xref rid="S11" ref-type="sec">Section 2.3.3</xref>. Rewinding [<xref rid="R30" ref-type="bibr">30</xref>] has been taken as a way to diagnose memorization in a neural network by replacing the weights of a single layer with an old version during training.</p><p id="P68">Our intuition for ensuring stealthiness is to find a controller for balancing the crafted version and a benign version. Thus, for a crafted model <inline-formula><mml:math id="M165" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, we rewind a layer to its old version in <inline-formula><mml:math id="M166" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>. By controlling which layer and how many layers are rewound, we can trade off between stealthiness and attack effectiveness.</p></sec></sec><sec id="S21"><label>3.3</label><title>Inference Pipeline</title><sec id="S22"><label>3.3.1</label><title>Membership Inference Pipeline.</title><p id="P69">In the inferring stage, we consider two standard membership scores for maximizing the adversary advantage in distinguishing the IN-world when <inline-formula><mml:math id="M167" display="inline"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">x</mml:mi></mml:math></inline-formula> and OUT-world when <inline-formula><mml:math id="M168" display="inline"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x022a5;</mml:mo></mml:math></inline-formula>.</p><p id="P70">For the weakest adversary with no auxiliary dataset, loss value is a conventional signal for classifying samples as a member [<xref rid="R50" ref-type="bibr">50</xref>]:
<disp-formula id="FD6">
<label>(4)</label>
<mml:math id="M169" display="block"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">I</mml:mi><mml:mo>[</mml:mo><mml:mi>&#x02112;</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>)</mml:mo><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo>]</mml:mo><mml:mo>.</mml:mo></mml:math>
</disp-formula>
For an adversary with an auxiliary dataset or equally the predominant adversary <inline-formula><mml:math id="M170" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> in our case, we follow the state-of-the-art attacks [<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R34" ref-type="bibr">34</xref>, <xref rid="R39" ref-type="bibr">39</xref>, <xref rid="R48" ref-type="bibr">48</xref>] and calibrate the membership score with a difficulty score, which can be estimated with an OUT-world reference model <inline-formula><mml:math id="M171" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> trained with the auxiliary dataset. Thus, the signal for classification becomes:
<disp-formula id="FD7">
<label>(5)</label>
<mml:math id="M172" display="block"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">I</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>&#x02112;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>;</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>&#x02112;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x0003c;</mml:mo><mml:mi>&#x003b3;</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math>
</disp-formula></p><p id="P71">As previous works [<xref rid="R33" ref-type="bibr">33</xref>, <xref rid="R34" ref-type="bibr">34</xref>], we threshold the above two signals by setting <inline-formula><mml:math id="M173" display="inline"><mml:mi>&#x003b3;</mml:mi></mml:math></inline-formula> as the highest value of which the false positive rate over all samples would not exceed <inline-formula><mml:math id="M174" display="inline"><mml:mi>&#x003b1;</mml:mi></mml:math></inline-formula> for reporting the TPR with a given <inline-formula><mml:math id="M175" display="inline"><mml:mi>&#x003b1;</mml:mi></mml:math></inline-formula> FPR. We omit the discussion on estimating the difficulty score by a pool of reference samples [<xref rid="R32" ref-type="bibr">32</xref>] because loss-value and reference-model scores have already covered the lower and upper bound of empirical MIA performance. With the efficiency bottleneck on training multiple reference models, we limit the capability with only one reference model in all comparisons.</p></sec><sec id="S23"><label>3.3.2</label><title>Data Extraction Pipeline.</title><p id="P72">We perform the data extraction in the inferring stage based on a state-of-the-art pipeline [<xref rid="R6" ref-type="bibr">6</xref>] with two phases. In the generation phase, the adversary will query the target model to generate a large amount of text with or without a given prefix. In the membership inference phase, the adversary will sort the generated samples concerning <xref rid="FD6" ref-type="disp-formula">Equation (4)</xref> or <xref rid="FD7" ref-type="disp-formula">Equation (5)</xref> after deduplicating abnormally repeated samples.</p></sec></sec></sec><sec id="S24"><label>4</label><title>Experiments</title><sec id="S25"><label>4.1</label><title>Experimental Setup</title><sec id="S26"><title>Datasets.</title><p id="P73">We run experiments on benchmark datasets from financial, email, and medical domains due to the confidential properties of the content, including Penn Treebank [<xref rid="R31" ref-type="bibr">31</xref>] (PTB), Enron [<xref rid="R21" ref-type="bibr">21</xref>] and Pubmed [<xref rid="R9" ref-type="bibr">9</xref>].</p><p id="P74">We split the original training dataset equally into three partitions as <inline-formula><mml:math id="M176" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, and the non-member dataset <inline-formula><mml:math id="M177" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>non</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Thus, we avoid a false sense of attack effectiveness from the potential data shift [<xref rid="R16" ref-type="bibr">16</xref>]. To control the strength of this adversarial knowledge, we vary the data size ratio between the auxiliary dataset and the fine-tuning dataset <inline-formula><mml:math id="M178" display="inline"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and by default <inline-formula><mml:math id="M179" display="inline"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> as the other work [<xref rid="R44" ref-type="bibr">44</xref>]. For a fair comparison, we ensure same datasets are used in comparisons.</p></sec><sec id="S27"><title>Models and Parameter-Efficient Fine-Tuning.</title><p id="P75">For the scalability to different backbone model sizes, we perform experiments on GPT-2 (12-layer, 117M), GPT-2-medium (24-layer, 345M), and GPT-2-large (36-layer, 774M) models. Except for fully fine-tuning (Full-FT), we extend our evaluation to two <italic toggle="yes">selective</italic> methods of Bitfit-FT and Head-FT, one <italic toggle="yes">addictive</italic> method of Adapter-FT in the output layer with a reduction factor as 16 and one <italic toggle="yes">reparameterization</italic>-<italic toggle="yes">based</italic> method of LoRA-FT with <inline-formula><mml:math id="M180" display="inline"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>16</mml:mn></mml:math></inline-formula>.</p><p id="P76">We set a default learning rate <inline-formula><mml:math id="M181" display="inline"><mml:mi>&#x003b7;</mml:mi></mml:math></inline-formula> in Full-FT, Adapter-FT, LoRA-FT, Bitfit-FT, and Head-FT as <inline-formula><mml:math id="M182" display="inline"><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> with the linear scheduler in all baselines for a fair comparison. By default, we train the model with <inline-formula><mml:math id="M183" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula> on GPT-2, <inline-formula><mml:math id="M184" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math></inline-formula> for GPT-2-medium/large and stop without overfitting.</p></sec><sec id="S28"><title>Baselines.</title><p id="P77">For the main goal of verifying if <italic toggle="yes">PreCurious</italic> enlarges the adversarial gain as we defined in Definition 2.1, we compare the privacy risk of <inline-formula><mml:math id="M185" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M186" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>.</p><p id="P78">For all fine-tuned models, we use results w/ <inline-formula><mml:math id="M187" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> to show risks for <inline-formula><mml:math id="M188" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> who is the prominent adversary and the pretrained model publisher who has <inline-formula><mml:math id="M189" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Results w/o <inline-formula><mml:math id="M190" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> reflect risks from the potential weaker adversary <inline-formula><mml:math id="M191" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d49c;</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that can be anyone who queries the model but has no <inline-formula><mml:math id="M192" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Thus, we could see the maximum secrets that can be inferred, as well as the attacking lower bound for the maximum coverage of potential adversaries.</p><p id="P79">As for <inline-formula><mml:math id="M193" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, we use the model initialization as a default reference model, which is denoted as Base-Ref. To control influence from calibration, we use <inline-formula><mml:math id="M194" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> trained over the same <inline-formula><mml:math id="M195" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> for benign baseline, which is denoted as Full-Ref. By default, we evaluate baselines under <bold>Case I</bold> and discuss <bold>Case II</bold> in <xref rid="S36" ref-type="sec">Section 4.2.6</xref> for the early-stopping scenario.</p></sec><sec id="S29"><title>Metrics.</title><p id="P80">We use the perplexity on validation dataset Val-PPL &#x02193; to measure the utility of the fine-tuned model. As shown in <xref rid="S11" ref-type="sec">Section 2.3.3</xref>, we use <inline-formula><mml:math id="M196" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mia</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02193;</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mem</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02193;</mml:mo></mml:math></inline-formula>, and <inline-formula><mml:math id="M197" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02193;</mml:mo></mml:math></inline-formula> with suffix token length as 10 to measure the stealthiness of the released model. For privacy budget, we follow the widely applied setting <inline-formula><mml:math id="M198" display="inline"><mml:mi>&#x003b4;</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1.1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> for all <inline-formula><mml:math id="M199" display="inline"><mml:msup><mml:mrow><mml:mi>&#x003f5;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>. For AUC &#x02191; and TPR@FPR <inline-formula><mml:math id="M2000" display="inline"><mml:mi>&#x003b1;</mml:mi><mml:mo>%</mml:mo><mml:mo>&#x02191;</mml:mo></mml:math></inline-formula> in MIA, we vary the FPR from 0.0001 to 0.1. For untargeted data extraction, we vary the sub-sequence length by <inline-formula><mml:math id="M201" display="inline"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>40</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>50</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula>. For <inline-formula><mml:math id="M202" display="inline"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02191;</mml:mo></mml:math></inline-formula> in targeted data extraction, we calculate the valid exposure threshold with the secret length of <inline-formula><mml:math id="M203" display="inline"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mtext>secret</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> characters.</p></sec></sec><sec id="S30"><label>4.2</label><title>Effectiveness on Membership Inference</title><p id="P81">In this section, we would like to measure the effectiveness of <italic toggle="yes">PreCurious</italic> on amplifying the membership inference risk with the following questions:</p><list list-type="bullet" id="L10"><list-item><p id="P82"><bold>RQ1:</bold> What is the extent of the advantage gained through <italic toggle="yes">PreCurious</italic> initialization compared to a benign one within the same iterations? (<xref rid="S31" ref-type="sec">Section 4.2.1</xref>)</p></list-item><list-item><p id="P83"><bold>RQ2:</bold> How does the choice of model initialization and reference model influence the adversarial advantage and interfere with each other? (<xref rid="S32" ref-type="sec">Section 4.2.2</xref>)</p></list-item><list-item><p id="P84"><bold>RQ3:</bold> Is the crafted backbone stealthy compared to the benign model? Which layer has more influence on stealthiness? (<xref rid="S33" ref-type="sec">Section 4.2.3</xref>)</p></list-item><list-item><p id="P85"><bold>RQ4:</bold> Which conventional defenses fail on mitigating privacy risk when applying <italic toggle="yes">PreCurious</italic>? (<xref rid="S34" ref-type="sec">Section 4.2.4</xref>)</p></list-item><list-item><p id="P86"><bold>RQ5:</bold> Does the risk amplification effect on MIA highly rely on the duplication between <inline-formula><mml:math id="M204" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M205" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>? (<xref rid="S35" ref-type="sec">Section 4.2.5</xref>)</p></list-item><list-item><p id="P87"><bold>RQ6:</bold> Can we break up the privacy-utility trade-off when early stopping is applied? (<xref rid="S36" ref-type="sec">Section 4.2.6</xref>)</p></list-item></list><p id="P88">Denoting the learning rate, epochs in the <bold>crafting</bold> stage as <inline-formula><mml:math id="M206" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, we now clarify variants of <italic toggle="yes">PreCurious</italic> as :</p><list list-type="bullet" id="L12"><list-item><p id="P89"><bold>Basic</bold> indicates the basic accelerating by warm-up (<xref rid="S17" ref-type="sec">Section 3.2.1</xref>).</p></list-item><list-item><p id="P90"><bold>Accelerated</bold> indicates accelerating by anti-freezing (<xref rid="S18" ref-type="sec">Section 3.2.2</xref>).</p></list-item><list-item><p id="P91"><bold>Lagging</bold> means releasing the model with inferior performance on the domain (<xref rid="S19" ref-type="sec">Section 3.2.3</xref>). By default, it means the combination of anti-freezing backbone and weight scaling.</p></list-item><list-item><p id="P92"><bold>Stealthy</bold> is the stealthier version for <italic toggle="yes">Basic</italic> by rewinding the head in the crafted backbone to the benign version (<xref rid="S20" ref-type="sec">Section 3.2.4</xref>).</p></list-item></list><sec id="S31"><label>4.2.1</label><title>Performance Comparison.</title><p id="P93">First, we summarize MIA performance between <inline-formula><mml:math id="M207" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M208" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> in <xref rid="T1" ref-type="table">Table 1</xref> from the lens of the prominent adversary <inline-formula><mml:math id="M209" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula>. Using a <inline-formula><mml:math id="M210" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> trained over <inline-formula><mml:math id="M211" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> significantly improves the attacking effectiveness on the benign baseline as shown in previous works [<xref rid="R34" ref-type="bibr">34</xref>, <xref rid="R39" ref-type="bibr">39</xref>, <xref rid="R44" ref-type="bibr">44</xref>]. Comparing with the state-of-the-art Full-Ref, we can see the adversary advantage is significantly amplified with a basic warm-up model initialization. This is because the <italic toggle="yes">PreCurious</italic>-Basic model initialization induces the fine-tuning process to start from a point close to the memorization-only stage [<xref rid="R34" ref-type="bibr">34</xref>] where membership inference risk increases rapidly and results in a higher privacy risk within given epochs.</p><p id="P94">Then, we evaluate the effectiveness of different backbones in <xref rid="T2" ref-type="table">Table 2</xref>. We use the same reference model for Basic and Full-Ref for fair comparison, and we set <inline-formula><mml:math id="M212" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math></inline-formula> on the two larger models to avoid showing results after overfitting. Comparing GPT-2 Medium with GPT-2 Large, under the same configurations, we can see that the Val-PPL and the MIA performance w/ or w/o <inline-formula><mml:math id="M213" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> scales up with model size. Comparing <italic toggle="yes">PreCurious</italic>-Basic with Benign-Full-Ref, we can see that using a basic warm-up speeds up memorization and boosts the TPR@0.01%FPR for PTB dataset by &#x000d7;18.84.</p><p id="P95">In addition, we observe the advantage introduced by model initialization in <xref rid="T3" ref-type="table">Table 3</xref> by comparing Benign with Basic and the more aggressive Accelerated. We set <inline-formula><mml:math id="M214" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> as a safe choice for the accelerated version on all datasets. There is a clear trend that the Val-PPL is decreasing and the privacy risk is increasing from Benign to Basic to Accelerated. The Accelerated is indeed a more aggressive strategy that pushes the starting point to memorization-only stage.</p><list list-type="simple" id="L14"><list-item><p id="P96"><bold>RQ1-Response:</bold> Whether with or without <inline-formula><mml:math id="M215" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, the accelerated strategy of <italic toggle="yes">PreCurious</italic> enhances the MIA advantage across different PEFTs and model sizes within the given number of iterations.</p></list-item></list></sec><sec id="S32"><label>4.2.2</label><title>Ablation Study.</title><p id="P97">To show the independent advantage gained from the crafted initialization <inline-formula><mml:math id="M216" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and the reference model <inline-formula><mml:math id="M217" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, we perform an ablation study in <xref rid="F4" ref-type="fig">Figure 4</xref>, in which we choose the best reference model for achieving the highest MIA AUC on Benign-Full-Ref baseline. First, the loss distribution shows the MIA signal distribution can be distinguished more significantly between members and non-members by adversarially crafting the initialization. Then, comparing the ROC curve of PreCurious with Benign-FullRef, we can see the small advantage w/o <inline-formula><mml:math id="M218" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> in <xref rid="T3" ref-type="table">Table 3</xref> is amplified after calibration. And we notice that the performance of calibration is highly sensitive to the choice of <inline-formula><mml:math id="M219" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, as shown in <xref rid="F5" ref-type="fig">Figure 5</xref>.</p><p id="P98">Now we would like to discuss the best choice of <inline-formula><mml:math id="M220" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M221" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> for maximizing the MIA signal distinguishability, using PreCurious-Basic as an instance for the accelerated version. To understand how different choice of model initialization and reference model influence the adversarial advantage, we combine different warming-up checkpoints as <inline-formula><mml:math id="M222" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M223" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> in <xref rid="F6" ref-type="fig">Figure 6</xref>. First, we find a consistent rule that the best <inline-formula><mml:math id="M224" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M225" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> combination for achieving the maximum advantage across different MIA metrics, datasets, and PEFTs is <monospace>aux1e4-aux1e4</monospace>. Also, there is a clear trend that diagonal combinations yield higher risk, indicating the best <inline-formula><mml:math id="M226" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is <inline-formula><mml:math id="M227" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> or the one that has a slightly better performance to <inline-formula><mml:math id="M228" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>. Since the attack effectiveness of referenced model-based MIA is significantly influenced by the choice on <inline-formula><mml:math id="M229" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, our finding solves the challenge by providing a simple rule of choosing <inline-formula><mml:math id="M230" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><list list-type="simple" id="L16"><list-item><p id="P99"><bold>RQ2-Response: <inline-formula><mml:math id="M231" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula></bold> is suggested to use the just-fit model as <inline-formula><mml:math id="M232" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M233" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> in accelerated <italic toggle="yes">PreCurious</italic>.</p></list-item></list></sec><sec id="S33"><label>4.2.3</label><title>Stealthiness.</title><p id="P100">Now we suppose the victim doubts the motivation of <inline-formula><mml:math id="M234" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and the victim can query the benign <inline-formula><mml:math id="M235" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> for auditing. Thus, we compare the stealthiness metrics across benign backbone and <italic toggle="yes">PreCurious</italic> backbones in <xref rid="T4" ref-type="table">Table 4</xref>. First, the proposed stealthiness metrics are possible to raise suspicion for <inline-formula><mml:math id="M236" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> if the victim is sensitive to the subtle differences. <inline-formula><mml:math id="M237" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mem</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> gives a more consistent detection compared to <inline-formula><mml:math id="M238" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mia</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> or <inline-formula><mml:math id="M239" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Second, <italic toggle="yes">Stealthy</italic> is effective in enhancing the stealthiness of <italic toggle="yes">Basic. Accelerated</italic> is also stealthier than the <italic toggle="yes">Basic</italic> because auditing is performed on the backbone instead of composing with inserted modules. But as shown in <xref rid="T1" ref-type="table">Table 1</xref>, <italic toggle="yes">Stealthy</italic> sacrifices the attack effectiveness with the slight improvement on stealthiness. Third, <italic toggle="yes">Lagging</italic> has <inline-formula><mml:math id="M240" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mem</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> and may successfully evade with <inline-formula><mml:math id="M241" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mia</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula> and low <inline-formula><mml:math id="M242" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, except for <inline-formula><mml:math id="M243" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> on Enron. The high <inline-formula><mml:math id="M244" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> results from the randomness of the poor initial utility. Performing layer-wise rewinding in <xref rid="F7" ref-type="fig">Figure 7</xref>, we observe that rewinding the last block can achieve the best stealthiness-risk trade-off.</p><list list-type="simple" id="L18"><list-item><p id="P101"><bold>RQ3-Response:</bold>
<italic toggle="yes">PreCurious</italic> increases stealthiness metrics very subtly and <inline-formula><mml:math id="M245" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> can rewind the last block to further enhance the stealthiness.</p></list-item></list></sec><sec id="S34"><label>4.2.4</label><title>Effectiveness under Defense.</title><p id="P102">Under the representative defense strategy of weight decay, we show in <xref rid="T5" ref-type="table">Table 5</xref> that <italic toggle="yes">PreCurious</italic> is robust on privacy risk amplification even with a high coefficient that exceeds the typical selection.</p><p id="P103">Under the strict defense of DP fine-tuning [<xref rid="R24" ref-type="bibr">24</xref>, <xref rid="R51" ref-type="bibr">51</xref>], we show in <xref rid="T6" ref-type="table">Table 6</xref> that <italic toggle="yes">PreCurious</italic> model increases the AUC compared to the Benign model but has a smaller TPR@0.01FPR and better utility due to the warming-up. The overall risk compared to non-DP fine-tuning in <xref rid="T1" ref-type="table">Table 1</xref> is significantly mitigated by DP, supported by more results w.r.t. various budgets in the <xref rid="T8" ref-type="table">Appendix Table 8</xref>.</p><p id="P104">In <xref rid="F8" ref-type="fig">Figure 8</xref>, we evaluate the MIA effectivenss of Benign and PreCurious under deduplication defense [<xref rid="R20" ref-type="bibr">20</xref>, <xref rid="R23" ref-type="bibr">23</xref>]. As shown in the duplicate statistics at the top, a sub-sequence in <inline-formula><mml:math id="M246" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> may appear multiple times and make it easier to memorize [<xref rid="R20" ref-type="bibr">20</xref>]. Deduplication can be instantiated with suffix array-based algorithm [<xref rid="R23" ref-type="bibr">23</xref>] for finding and mitigating repeated sub-sequences in <inline-formula><mml:math id="M247" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p id="P105">By deduplicating repeated sub-sequence of length <inline-formula><mml:math id="M248" display="inline"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>40</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula> in <inline-formula><mml:math id="M249" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, we find a consistent trend that <italic toggle="yes">PreCurious</italic> still causes a higher MIA risk than Benign initialization. Taking original <inline-formula><mml:math id="M250" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> as members, heavier deduplication leads to less privacy risk. But we note that <italic toggle="yes">PreCurious</italic> with a heavy deduplication such as <inline-formula><mml:math id="M251" display="inline"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> still causes more privacy leakage than Benign baseline without deduplication. Also, deduplication helps <inline-formula><mml:math id="M252" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> to be more stealthier and results in a higher perplexity (worse utility-privacy trade-off), because the auxiliary dataset is not deduplicated. When taking samples in deduplicated <inline-formula><mml:math id="M253" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> as members, the MIA risk is increasing for a heavier deduplication due to a larger distribution shift. This is also because the data size used for fine-tuning is diminished and the deduplication essentially induces training samples to become outliers and more vulnerable to be inferred [<xref rid="R44" ref-type="bibr">44</xref>]. The ideal case where attackers can approximate deduplicated texts in MIA inference can be seen as a corner case for deduplication defense to fail.</p><list list-type="simple" id="L20"><list-item><p id="P106"><bold>RQ4-Response:</bold>
<italic toggle="yes">PreCurious</italic> still effectively amplifies the privacy risk under defenses and is even stealthier under deduplication.</p></list-item></list></sec><sec id="S35"><label>4.2.5</label><title>Duplicates Investigation.</title><p id="P107">In previous experiments, we use a randomly split dataset as <inline-formula><mml:math id="M254" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> for launching <italic toggle="yes">PreCurious</italic>. However, <inline-formula><mml:math id="M255" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> may have partially overlapped sub-sequence as in <inline-formula><mml:math id="M256" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, which might be the reason for a successful privacy risk amplification. To understand whether the risk amplification effect is highly dependent on the duplication between the two datasets <inline-formula><mml:math id="M257" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M258" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, we control the overlapping level of <inline-formula><mml:math id="M259" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> with cross-deduplication:
<list list-type="bullet" id="L22"><list-item><p id="P108">For <inline-formula><mml:math id="M260" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dedup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>, we <bold>drop</bold> all <inline-formula><mml:math id="M261" display="inline"><mml:mi>L</mml:mi></mml:math></inline-formula>-length sub-sequences that overlaps with <inline-formula><mml:math id="M262" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> on the default <inline-formula><mml:math id="M263" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p></list-item><list-item><p id="P109">For <inline-formula><mml:math id="M264" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>, we find all cross-duplicated <inline-formula><mml:math id="M265" display="inline"><mml:mi>L</mml:mi></mml:math></inline-formula>-length sub-sequences and <bold>keep</bold> them to construct it.</p></list-item></list>
By varying over different <inline-formula><mml:math id="M266" display="inline"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>40</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mn>60</mml:mn><mml:mo>}</mml:mo></mml:math></inline-formula>, we get <inline-formula><mml:math id="M267" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M268" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dedup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> with various auxiliary dataset sizes. It should be noted that this experiment is designed for analysis instead of a &#x0201c;real&#x0201d; attack as we are manipulating the adversary capability with <inline-formula><mml:math id="M269" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p id="P111">As shown in <xref rid="F9" ref-type="fig">Figure 9</xref>, we control the duplication level by increasing <inline-formula><mml:math id="M270" display="inline"><mml:mi>L</mml:mi></mml:math></inline-formula> for <inline-formula><mml:math id="M271" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dedup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and decreasing <inline-formula><mml:math id="M272" display="inline"><mml:mi>L</mml:mi></mml:math></inline-formula> for <inline-formula><mml:math id="M273" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> from left to right. We can observe that using the auxiliary knowledge with <inline-formula><mml:math id="M274" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dedup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> has superior attack performance than <inline-formula><mml:math id="M275" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>, which indicates that the privacy risk amplification of <italic toggle="yes">PreCurious</italic> does not solely rely on the cross-duplicated parts between <inline-formula><mml:math id="M276" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M277" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. Then, we observe a clear trend for all datasets that the adversarial advantage of <italic toggle="yes">PreCurious</italic> with auxiliary knowledge <inline-formula><mml:math id="M278" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dedup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> increases with a moderate level of cross-deduplication, with a similar trend shown for Benign baseline with <inline-formula><mml:math id="M279" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. In addition, by only using the duplicated parts, which are typically the very common sub-sequences in the domain <inline-formula><mml:math id="M280" display="inline"><mml:mi>&#x1d49f;</mml:mi></mml:math></inline-formula>, even the adversarial gain from <inline-formula><mml:math id="M281" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is poor, warming up with a batch of common fragments also helps to amplify the MIA risk, which weakens the required assumption on <inline-formula><mml:math id="M282" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><list list-type="simple" id="L24"><list-item><p id="P112"><bold>RQ5-Response:</bold>
<italic toggle="yes">PreCurious</italic> does not heavily rely on the duplicates between <inline-formula><mml:math id="M283" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M284" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p></list-item></list></sec><sec id="S36"><label>4.2.6</label><title>Breaking-up the trade-off.</title><p id="P113">As shown in <xref rid="F11" ref-type="fig">Figure 11</xref>, we can use lagging <italic toggle="yes">PreCurious</italic> to break up the privacy-utility trade-off and amplify the risk for Case II. We compare all baselines with loss signals to avoid the influence of <inline-formula><mml:math id="M285" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. We can observe that <italic toggle="yes">PreCurious</italic>-Lagging w/ <inline-formula><mml:math id="M286" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is possible to amplify the risk. But only weight scaling on a benign backbone is not as effective as scaling with the same level on a warmed-up model to distinguish the loss signal distribution at the end, validating the effectiveness of anti-freezing.</p><p id="P114">It is seen that <italic toggle="yes">PreCurious</italic>-Accelerated shows a consistent tendency to amplify risk given fixed epochs <inline-formula><mml:math id="M287" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. While <italic toggle="yes">PreCurious</italic>-Lagging is robust in breaking up the privacy-utility trade-off, resulting in either poor model performance or high privacy risk, which validates our key intuition of increasing risk by increasing the required iterations to achieve the same utility. One different observation is that applying a lagging initialization for LoRA-FT does not show the same sign to amplify risk given a fixed epoch as expected. In addition, we find weight scaling with <inline-formula><mml:math id="M288" display="inline"><mml:mi>&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math></inline-formula> on <monospace>attn.c_attn.weight</monospace> is effective while the effective choice for Adapter-FT is <monospace>attn.c_proj.weight</monospace>, which are exactly where PEFT modules are applied, indicating the importance of fine-tuning side-information for the lagging strategy.</p><p id="P115">In addition, we address the privacy-utility trade-off issue in <xref rid="T6" ref-type="table">Table 6</xref> with the lagging strategy as shown in <xref rid="F10" ref-type="fig">Figure 10</xref>. Even when the worst-case privacy is bounded by a strict DP, we show that <inline-formula><mml:math id="M289" display="inline"><mml:mi>&#x003f5;</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> is still not a perfect protection. This success is due to more iterations for achieving the same utility, and also because the larger gradient norm derived from <italic toggle="yes">PreCurious</italic>-lagging fully exploits the per-sample sensitivity to reflect the influence of each sample.</p><list list-type="simple" id="L26"><list-item><p id="P116"><bold>RQ6-Response: <inline-formula><mml:math id="M290" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula></bold> is suggested to apply Lagging-<italic toggle="yes">PreCurious</italic> for breaking-up utility-privacy trade-off when early stopping is applied.</p></list-item></list></sec></sec><sec id="S37"><label>4.3</label><title>Effectiveness on Data Extraction</title><p id="P117">Now we evaluate the effectiveness of <italic toggle="yes">PreCurious</italic> on data extraction. As previous work [<xref rid="R5" ref-type="bibr">5</xref>, <xref rid="R20" ref-type="bibr">20</xref>, <xref rid="R23" ref-type="bibr">23</xref>] conclude, less duplicated secrets are more challenging to be extracted, thus we raise questions:</p><list list-type="bullet" id="L28"><list-item><p id="P118"><bold>RQ7:</bold> Are less deduplicated training samples safe with DP training and constraint of limited query times? (<xref rid="S38" ref-type="sec">Section 4.3.1</xref>)</p></list-item><list-item><p id="P119"><bold>RQ8:</bold> How bad is <italic toggle="yes">PreCuious</italic> when maximizing the auxiliary knowledge? (<xref rid="S39" ref-type="sec">Section 4.3.2</xref>)</p></list-item></list><sec id="S38"><label>4.3.1</label><title>Untargeted Extraction.</title><p id="P120">For <bold>RQ7</bold>, we focus on the effectiveness of samples of less duplication in <inline-formula><mml:math id="M291" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and assume the victim applies DP fine-tuning with <inline-formula><mml:math id="M292" display="inline"><mml:mi>&#x003f5;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula> and the target can only query for limited 1,000 generations. We perform the untargeted extraction in <xref rid="S23" ref-type="sec">Section 3.3.2</xref> for both Benign and <italic toggle="yes">PreCurious</italic> by: 1) generating samples with a maximum length of 512 via length 200-length prefixes, and 2) deduplicating and ranking by MIA signals in <xref rid="FD7" ref-type="disp-formula">Equation (5)</xref> to filter 100 samples. The prefixes are constructed by using the top frequent phrases shown in <inline-formula><mml:math id="M293" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> as we suppose the short but common parts can be transferred to <inline-formula><mml:math id="M294" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p id="P121">In <xref rid="F12" ref-type="fig">Figure 12</xref>, we use the <inline-formula><mml:math id="M295" display="inline"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> to denote the extraction level for <bold>each sample</bold> in <inline-formula><mml:math id="M296" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, which counts the total times of its sub-sequences shown in all generated outputs. The averaged performance measure by <inline-formula><mml:math id="M297" display="inline"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is shown in <xref rid="T9" ref-type="table">Appendix Table 9</xref>. <inline-formula><mml:math id="M298" display="inline"><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow><mml:mrow><mml:mtext>self</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M299" display="inline"><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> indicate the total times of its sub-sequences shown in <inline-formula><mml:math id="M300" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M301" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, respectively. In <xref rid="F12" ref-type="fig">Figure 12</xref>, there is a clear trend that <inline-formula><mml:math id="M302" display="inline"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> increases with larger <inline-formula><mml:math id="M303" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow><mml:mrow><mml:mtext>self</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M304" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>, thus extracting less duplicates are indeed more challenging. But <italic toggle="yes">PreCurious</italic> can significantly improve the success on less duplicated samples, even under strict privacy defense given limited query times.</p><list list-type="simple" id="L30"><list-item><p id="P122"><bold>RQ7-Response:</bold>
<italic toggle="yes">PreCurious</italic> can still increase leakage of fewer-duplicated secrets even with DP fine-tuning.</p></list-item></list></sec><sec id="S39"><label>4.3.2</label><title>Targeted Extraction.</title><p id="P123">To investigate the threat when <inline-formula><mml:math id="M305" display="inline"><mml:mi>&#x1d49c;</mml:mi></mml:math></inline-formula> in <italic toggle="yes">PreCurious</italic>, we design the targeted extraction with the Enron dataset and take the phone number and email addresses as our targeted secrets. For maximizing the auxiliary knowledge, we take a masked version of <inline-formula><mml:math id="M306" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> as the <inline-formula><mml:math id="M307" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, which is bold but possible because releasing de-identified text data is taken as a common practice [<xref rid="R19" ref-type="bibr">19</xref>]. After that, we apply <italic toggle="yes">PreCurious</italic>-Basic and evaluate the exposure on our targeted secretes for both <inline-formula><mml:math id="M308" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext>adv</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M309" display="inline"><mml:msubsup><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula>. Following previous works [<xref rid="R5" ref-type="bibr">5</xref>, <xref rid="R34" ref-type="bibr">34</xref>], we use the skew-normal distribution [<xref rid="R36" ref-type="bibr">36</xref>] to model the perplexity distribution of secrets for efficiently approximating the exposure. The precise exposure is upper-bounded by <inline-formula><mml:math id="M310" display="inline"><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.5em"/><mml:mo>|</mml:mo><mml:mi>&#x0211b;</mml:mi><mml:mo>|</mml:mo></mml:math></inline-formula> when the target secret ranks the first among the whole set of possible secrets <inline-formula><mml:math id="M311" display="inline"><mml:mi>&#x0211b;</mml:mi></mml:math></inline-formula>. Thereby, the threshold <inline-formula><mml:math id="M312" display="inline"><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.5em"/><mml:mo>|</mml:mo><mml:mi>&#x0211b;</mml:mi><mml:mo>|</mml:mo></mml:math></inline-formula> on the approximated exposure discriminates the case where a secret is only marginally the most likely or the case a secret is beyond the most likely. A secret is only reliably extracted from the model with an exposure above the threshold [<xref rid="R5" ref-type="bibr">5</xref>]. More specifically, we take secret as 10 digits in phone numbers and 10 English characters in email, thus derive <inline-formula><mml:math id="M313" display="inline"><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>&#x02248;</mml:mo><mml:mn>33</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="M314" display="inline"><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mn>26</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>&#x02248;</mml:mo><mml:mn>47</mml:mn></mml:math></inline-formula> as the valid exposure threshold. We can draw the following conclusion from <xref rid="F13" ref-type="fig">Figure 13</xref>.</p><list list-type="simple" id="L32"><list-item><p id="P124"><bold>RQ8-Response</bold>: <italic toggle="yes">PreCurious</italic> can use sanitization text to expose originally safe secrets even when scrubbing is perfect.</p></list-item></list></sec></sec></sec><sec id="S40"><label>5</label><title>Related Work</title><p id="P125">We discuss the most related attacks and privacy risk amplification.</p><sec id="S41"><title>Membership Inference Attack.</title><p id="P126">MIA in machine learning context [<xref rid="R41" ref-type="bibr">41</xref>, <xref rid="R48" ref-type="bibr">48</xref>] aims to predict whether a given sample is involved in training. Considering the inefficiency of LLM training, we focus on threshold-based MIA as it is more practical than attack-model-based MIA [<xref rid="R8" ref-type="bibr">8</xref>, <xref rid="R25" ref-type="bibr">25</xref>, <xref rid="R35" ref-type="bibr">35</xref>, <xref rid="R41" ref-type="bibr">41</xref>]. The key idea of threshold-based MIA is formalizing a hypothesis test with the posterior distribution assumptions about the model parameters [<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R27" ref-type="bibr">27</xref>, <xref rid="R48" ref-type="bibr">48</xref>], by observing the signals from loss value [<xref rid="R50" ref-type="bibr">50</xref>] or the loss calibrated by other models or samples [<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R28" ref-type="bibr">28</xref>, <xref rid="R32" ref-type="bibr">32</xref>, <xref rid="R34" ref-type="bibr">34</xref>, <xref rid="R39" ref-type="bibr">39</xref>, <xref rid="R45" ref-type="bibr">45</xref>]. Our evaluations integrate both conventional loss signal [<xref rid="R50" ref-type="bibr">50</xref>] and the state-of-the-art reference-model calibrated signal [<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R34" ref-type="bibr">34</xref>, <xref rid="R48" ref-type="bibr">48</xref>] without retraining or multiple queries for each sample for a practical adversarial capability assumption.</p></sec><sec id="S42"><title>Data Extraction.</title><p id="P127">Instead of extracting artificial canaries [<xref rid="R5" ref-type="bibr">5</xref>], a previous work [<xref rid="R6" ref-type="bibr">6</xref>] formulates the paradigm of extracting verbatim subsequence from the pre-training dataset of GPT-2 by filtering and ranking generated samples. We evaluate the verbatim extraction on real secrets under this paradigm.</p></sec><sec id="S43"><title>Privacy Risk Amplification.</title><p id="P128">The key idea of privacy risk amplification is to manipulate model or data integrity for more privacy leakage, as in representative works listed in <xref rid="T7" ref-type="table">Table 7</xref>. Prior works [<xref rid="R7" ref-type="bibr">7</xref>, <xref rid="R29" ref-type="bibr">29</xref>, <xref rid="R44" ref-type="bibr">44</xref>] investigate the privacy risk amplification via data poisoning, which requires the control of the training dataset. Recent work [<xref rid="R43" ref-type="bibr">43</xref>] attempts to enlarge the property inference effect by manipulating the pre-trained encoder for image classification. Our attack does not require control over the target training dataset and aims to plant a privacy backdoor in pre-trained model for amplifying general privacy risks in LLMs. Concurrent works [<xref rid="R11" ref-type="bibr">11</xref>, <xref rid="R47" ref-type="bibr">47</xref>] also introduce privacy backdoors for pre-trained models, but [<xref rid="R11" ref-type="bibr">11</xref>] is not comparable to ours as they focus on classification task and mainly assume stronger capabilities of white-box and architecture modification. The other attack [<xref rid="R47" ref-type="bibr">47</xref>] is close to our basic version. Our advanced strategies further consider random PEFT initialization and early-stopping performed by the victim.</p></sec></sec><sec id="S44"><label>6</label><title>Discussion</title><sec id="S45"><title>Countermeasures.</title><p id="P129">We now discuss the countermeasures to PreCurious for the wide range of users and regularization designers.</p><sec id="S46"><title>Be careful to download models from unknown sources.</title><p id="P130">The amplified risk from <italic toggle="yes">PreCurious</italic> justifies the importance of model integrity in pre-training and fine-tuning pipeline. Therefore, we recommend that fine-tuners download pre-trained models from trusted sources rather than from anonymous users on open-source platforms. Users should check the download link and be aware when automatic library management tools upgrade to higher version packages.</p></sec><sec id="S47"><title>Be careful when following fine-tuning instructions.</title><p id="P131">With the rapid development of language models, users with different backgrounds can get started on building their models easily by following tutorials from the community. However, the success of <italic toggle="yes">PreCurious</italic> reveals additional side information that can be exploited by the adversary to infer private information. Users should not rely heavily on common settings shared in a tutorial, but instead be aware of the training dynamics in fine-tuning (e.g., epochs, stopping criteria, PEFT choices), even as the validation loss continues to decrease.</p></sec><sec id="S48"><title>Be careful on auditing risks even under defense.</title><p id="P132"><italic toggle="yes">PreCurious</italic> demonstrates that regularization defense, DP fine-tuning, and deduplication are not perfect. For example, DP even with a strict budget cannot lead to a random guess attack under <italic toggle="yes">PreCurious</italic>; deduplication fails when attackers can approximate the deduplicated text in MIA, or when <italic toggle="yes">PreCurious-lagging</italic> implicitly increases the number of repetitions for all samples. Thus, we suggest that users remain vigilant and audit the privacy dynamics during fine-tuning closely [<xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R5" ref-type="bibr">5</xref>, <xref rid="R34" ref-type="bibr">34</xref>] even when reasonable defenses are applied.</p></sec><sec id="S49"><title>Be careful to share sanitized text by masking PII.</title><p id="P133"><italic toggle="yes">PreCurious</italic> demonstrates the feasibility of increasing the risk of secret exposure by using a public sanitized dataset to improve the auxiliary knowledge. Thus, we claim that unless we can ensure that sensitive information is removed for each future training, it is not safe to publish sanitized datasets, even if the sensitive secrets are masked or replaced, which is important when researchers in high-stakes domains publish benchmark datasets.</p></sec></sec><sec id="S50"><title>Implications for future works.</title><p id="P134">A recent work [<xref rid="R49" ref-type="bibr">49</xref>] investigates the influence of model initialization on the worst-case privacy risk scales with the gradient difference on neighboring datasets and the iterations. <italic toggle="yes">PreCuious</italic> fills the gap between the theoretical discussion on model initialization from scratch and the practical use of pre-trained LMs and PEFT technique from an average case perspective. It is interesting for future work to improve the theoretical understanding of worst-case privacy when applying model efficiency techniques, as well as to exploit other side information to explore potential vulnerabilities for evaluating existing defenses.</p><p id="P135">From <italic toggle="yes">PreCurious</italic>, we note that memorization-based privacy backdoors on either accelerating or lagging direction should be coupled with the stopping criteria to derive the final risk amplification effect. Since there is no privacy attack considered to improve risks when victims perform early stopping, we bring new perspectives for future attacks and defenses under this realistic scenario. In addition, <italic toggle="yes">PreCurious</italic> reveals the vulnerability and identifies corner cases of existing defenses, providing a critical call for stronger defenses.</p></sec></sec><sec id="S51"><label>7</label><title>Conclusion</title><p id="P136">In this paper, we introduced <italic toggle="yes">PreCurious</italic>, a novel privacy risk amplification framework that increases the privacy risk of fine-tuning dataset by manipulating the pre-trained model&#x02019;s memorization level and releasing a crafted model, showing the importance of model integrity from the privacy lens. We are among the first to investigate privacy backdoors, throughly exploring cases of PEFT and early-stopping by leveraging the side information in fine-tuning guideline. Our findings show that <italic toggle="yes">PreCurious</italic> breaks up the privacy-invulnerability property for PEFT, and common-sense defenses are possible to be subverted. Our work takes the step to understand the interplay between model memorization, efficiency and privacy risks, while also raises an interesting perspective to break up privacy-utility trade-off. This research is a critical call to action, urging the community to improve safeguards and reevaluate the security protocols around the use of pre-trained models, particularly those sourced from unverified platforms.</p></sec></body><back><ack id="S52"><title>Acknowledgments</title><p id="P137">We would like to thank reviewers for their constructive comments and efforts in improving our paper and artifacts. This work was supported in part by National Science Foundation grants (CNS-2125530, CNS-2124104, IIS-2302968, CNS-2350333), National Institutes of Health grants (R01LM013712, R01ES033241), JSPS KAK-ENHI JP23K24851, JST PRESTO JPMJPR23P5, and JST CREST JPMJCR21M2.</p></ack><fn-group><fn id="FN2"><label>1</label><p id="P142">
<ext-link xlink:href="https://github.com/lxuechen/private-transformers.git" ext-link-type="uri">https://github.com/lxuechen/private-transformers.git</ext-link>
</p></fn><fn id="FN3"><label>2</label><p id="P143">
<ext-link xlink:href="https://github.com/Emory-AIMS/PreCurious" ext-link-type="uri">https://github.com/Emory-AIMS/PreCurious</ext-link>
</p></fn></fn-group><app-group><app id="APP1"><title>A Experimental Setup and More Results</title><p id="P138">Our experiments were conducted on an Ubuntu 20.04.6 system with 8 NVIDIA Quadro RTX 8000 GPUs. The source code and other artifacts have been made available<sup><xref rid="FN3" ref-type="fn">2</xref></sup>.</p><table-wrap position="anchor" id="T8"><label>Table 8:</label><caption><p id="P139">MIA effectiveness under DP-SGD defense on PTB dataset with AdapterFT.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="M315" display="inline"><mml:mi>&#x003f5;</mml:mi></mml:math>
</inline-formula>
</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">MIA metric</th><th align="center" valign="middle" rowspan="1" colspan="1">TPR@0.01FPR</th><th align="center" valign="middle" rowspan="1" colspan="1">TPR@0.1FPR</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" rowspan="1" colspan="1">Val-PPL</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.05</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>2.29%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.03%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">51.99%</td><td align="center" valign="middle" rowspan="1" colspan="1">73.64</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.05</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" rowspan="1" colspan="1">0.86%</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>12.89%</bold>
</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<bold>53.53%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>27.64</bold>
</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.5</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1.72%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.03%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">52.03%</td><td align="center" valign="middle" rowspan="1" colspan="1">70.41</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.5</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" rowspan="1" colspan="1">1.43%</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>13.47%</bold>
</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<bold>55.09%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>26.42</bold>
</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1.72%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.03%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">52.05%</td><td align="center" valign="middle" rowspan="1" colspan="1">68.61</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" rowspan="1" colspan="1">0.86%</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14.04%</bold>
</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<bold>54.84%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>25.94</bold>
</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1.72%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">9.74%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">52.01%</td><td align="center" valign="middle" rowspan="1" colspan="1">66.59</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" rowspan="1" colspan="1">1.15%</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14.33%</bold>
</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<bold>54.58%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>25.47</bold>
</td></tr></tbody></table></table-wrap><table-wrap position="anchor" id="T9"><label>Table 9:</label><caption><p id="P140">Untargeted <inline-formula><mml:math id="M316" display="inline"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>ext</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02191;</mml:mo></mml:math></inline-formula> on PTB with Adapter-FT.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th rowspan="2" align="center" valign="top" style="border-right: solid 1px" colspan="1">
<inline-formula>
<mml:math id="M317" display="inline"><mml:mi>&#x003f5;</mml:mi></mml:math>
</inline-formula>
</th><th align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">Pre-trained model</th><th colspan="4" align="center" valign="top" style="border-bottom: solid 1px" rowspan="1">Subsequence Length</th></tr><tr><th align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">(w/ or w/o Ref)</th><th align="center" valign="top" rowspan="1" colspan="1">2</th><th align="center" valign="top" rowspan="1" colspan="1">5</th><th align="center" valign="top" rowspan="1" colspan="1">10</th><th align="center" valign="top" rowspan="1" colspan="1">50</th></tr></thead><tbody><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">0.05</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious w/ Ref</td><td align="center" valign="top" rowspan="1" colspan="1">91.78%</td><td align="center" valign="top" rowspan="1" colspan="1">57.85%</td><td align="center" valign="top" rowspan="1" colspan="1">39.43%</td><td align="center" valign="top" rowspan="1" colspan="1">18.10%</td></tr><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">0.05</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious w/o Ref</td><td align="center" valign="top" rowspan="1" colspan="1">56.95%</td><td align="center" valign="top" rowspan="1" colspan="1">49.65%</td><td align="center" valign="top" rowspan="1" colspan="1">37.10%</td><td align="center" valign="top" rowspan="1" colspan="1">19.80%</td></tr><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">0.05</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">Benign w/ Ref</td><td align="center" valign="top" rowspan="1" colspan="1">65.68%</td><td align="center" valign="top" rowspan="1" colspan="1">39.20%</td><td align="center" valign="top" rowspan="1" colspan="1">37.08%</td><td align="center" valign="top" rowspan="1" colspan="1">20.94%</td></tr><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">0.05</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">Benign w/o Ref</td><td align="center" valign="top" rowspan="1" colspan="1">46.67%</td><td align="center" valign="top" rowspan="1" colspan="1">41.34%</td><td align="center" valign="top" rowspan="1" colspan="1">36.84%</td><td align="center" valign="top" rowspan="1" colspan="1">18.33%</td></tr><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">8</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious w/ Ref</td><td align="center" valign="top" rowspan="1" colspan="1">92.88%</td><td align="center" valign="top" rowspan="1" colspan="1">58.81%</td><td align="center" valign="top" rowspan="1" colspan="1">39.04%</td><td align="center" valign="top" rowspan="1" colspan="1">18.67%</td></tr><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">8</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious w/o Ref</td><td align="center" valign="top" rowspan="1" colspan="1">65.43%</td><td align="center" valign="top" rowspan="1" colspan="1">57.67%</td><td align="center" valign="top" rowspan="1" colspan="1">37.13%</td><td align="center" valign="top" rowspan="1" colspan="1">19.92%</td></tr><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">8</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">Benign w/ Ref</td><td align="center" valign="top" rowspan="1" colspan="1">62.53%</td><td align="center" valign="top" rowspan="1" colspan="1">39.21%</td><td align="center" valign="top" rowspan="1" colspan="1">37.20%</td><td align="center" valign="top" rowspan="1" colspan="1">21.32%</td></tr><tr><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">8</td><td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">Benign w/o Ref</td><td align="center" valign="top" rowspan="1" colspan="1">44.11%</td><td align="center" valign="top" rowspan="1" colspan="1">39.20%</td><td align="center" valign="top" rowspan="1" colspan="1">36.88%</td><td align="center" valign="top" rowspan="1" colspan="1">18.84%</td></tr></tbody></table></table-wrap></app></app-group><ref-list><title>References</title><ref id="R1"><label>[1]</label><mixed-citation publication-type="webpage">Accessed: <date-in-citation>2023-12-07</date-in-citation>. <source>Github</source>. <ext-link xlink:href="https://github.com" ext-link-type="uri">https://github.com</ext-link>.</mixed-citation></ref><ref id="R2"><label>[2]</label><mixed-citation publication-type="webpage">Accessed: <date-in-citation>2023-12-07</date-in-citation>. <source>Hugging Face Models</source>. <ext-link xlink:href="https://huggingface.co/models" ext-link-type="uri">https://huggingface.co/models</ext-link>.</mixed-citation></ref><ref id="R3"><label>[3]</label><mixed-citation publication-type="book"><name><surname>Carlini</surname><given-names>Nicholas</given-names></name>, <name><surname>Chien</surname><given-names>Steve</given-names></name>, <name><surname>Nasr</surname><given-names>Milad</given-names></name>, <name><surname>Song</surname><given-names>Shuang</given-names></name>, <name><surname>Terzis</surname><given-names>Andreas</given-names></name>, and <name><surname>Tramer</surname><given-names>Florian</given-names></name>. <year>2022</year>. <part-title>Membership inference attacks from first principles</part-title>. In <source>2022 IEEE Symposium on Security and Privacy (SP)</source>. <publisher-name>IEEE</publisher-name>, <fpage>1897</fpage>&#x02013;<lpage>1914</lpage>.</mixed-citation></ref><ref id="R4"><label>[4]</label><mixed-citation publication-type="journal"><name><surname>Carlini</surname><given-names>Nicholas</given-names></name>, <name><surname>Ippolito</surname><given-names>Daphne</given-names></name>, <name><surname>Jagielski</surname><given-names>Matthew</given-names></name>, <name><surname>Lee</surname><given-names>Katherine</given-names></name>, <name><surname>Tramer</surname><given-names>Florian</given-names></name>, and <name><surname>Zhang</surname><given-names>Chiyuan</given-names></name>. <year>2022</year>. <article-title>Quantifying memorization across neural language models</article-title>. <source>arXiv</source> preprint arXiv:2202.07646 (2022).</mixed-citation></ref><ref id="R5"><label>[5]</label><mixed-citation publication-type="journal"><name><surname>Carlini</surname><given-names>Nicholas</given-names></name>, <name><surname>Liu</surname><given-names>Chang</given-names></name>, <name><surname>Erlingsson</surname><given-names>&#x000da;lfar</given-names></name>, <name><surname>Kos</surname><given-names>Jernej</given-names></name>, and <name><surname>Song</surname><given-names>Dawn</given-names></name>. <year>2019</year>. <article-title>The secret sharer: Evaluating and testing unintended memorization in neural networks</article-title>. In <source>28th USENIX Security Symposium (USENIX Security 19)</source>. <fpage>267</fpage>&#x02013;<lpage>284</lpage>.</mixed-citation></ref><ref id="R6"><label>[6]</label><mixed-citation publication-type="journal"><name><surname>Carlini</surname><given-names>Nicholas</given-names></name>, <name><surname>Tramer</surname><given-names>Florian</given-names></name>, <name><surname>Wallace</surname><given-names>Eric</given-names></name>, <name><surname>Jagielski</surname><given-names>Matthew</given-names></name>, <name><surname>Herbert-Voss</surname><given-names>Ariel</given-names></name>, <name><surname>Lee</surname><given-names>Katherine</given-names></name>, <name><surname>Roberts</surname><given-names>Adam</given-names></name>, <name><surname>Brown</surname><given-names>Tom</given-names></name>, <name><surname>Song</surname><given-names>Dawn</given-names></name>, <name><surname>Erlingsson</surname><given-names>Ulfar</given-names></name>, <etal/>
<year>2021</year>. <article-title>Extracting training data from large language models</article-title>. In <source>30th USENIX Security Symposium (USENIX Security 21)</source>. <fpage>2633</fpage>&#x02013;<lpage>2650</lpage>.</mixed-citation></ref><ref id="R7"><label>[7]</label><mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Yufei</given-names></name>, <name><surname>Shen</surname><given-names>Chao</given-names></name>, <name><surname>Shen</surname><given-names>Yun</given-names></name>, <name><surname>Wang</surname><given-names>Cong</given-names></name>, and <name><surname>Zhang</surname><given-names>Yang</given-names></name>. <year>2022</year>. <article-title>Amplifying membership exposure via data poisoning</article-title>. <source>Advances in Neural Information Processing Systems</source>
<volume>35</volume> (<issue>2022</issue>), <fpage>29830</fpage>&#x02013;<lpage>29844</lpage>.</mixed-citation></ref><ref id="R8"><label>[8]</label><mixed-citation publication-type="confproc"><name><surname>Choquette-Choo</surname><given-names>Christopher A</given-names></name>, <name><surname>Tramer</surname><given-names>Florian</given-names></name>, <name><surname>Carlini</surname><given-names>Nicholas</given-names></name>, and <name><surname>Papernot</surname><given-names>Nicolas</given-names></name>. <year>2021</year>. <article-title>Label-only membership inference attacks</article-title>. In <conf-name>International conference on machine learning</conf-name>. PMLR, <fpage>1964</fpage>&#x02013;<lpage>1974</lpage>.</mixed-citation></ref><ref id="R9"><label>[9]</label><mixed-citation publication-type="book"><name><surname>Cohan</surname><given-names>Arman</given-names></name>, <name><surname>Dernoncourt</surname><given-names>Franck</given-names></name>, <name><surname>Kim</surname><given-names>Doo Soon</given-names></name>, <name><surname>Bui</surname><given-names>Trung</given-names></name>, <name><surname>Kim</surname><given-names>Seokhwan</given-names></name>, <name><surname>Chang</surname><given-names>Walter</given-names></name>, and <name><surname>Goharian</surname><given-names>Nazli</given-names></name>. <year>2018</year>. <part-title>A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents</part-title>. In <source>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</source>. <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>New Orleans, Louisiana</publisher-loc>, <fpage>615</fpage>&#x02013;<lpage>621</lpage>. <pub-id pub-id-type="doi">10.18653/v1/N18-2097</pub-id></mixed-citation></ref><ref id="R10"><label>[10]</label><mixed-citation publication-type="confproc"><name><surname>Donahue</surname><given-names>Jeff</given-names></name>, <name><surname>Jia</surname><given-names>Yangqing</given-names></name>, <name><surname>Vinyals</surname><given-names>Oriol</given-names></name>, <name><surname>Hoffman</surname><given-names>Judy</given-names></name>, <name><surname>Zhang</surname><given-names>Ning</given-names></name>, <name><surname>Tzeng</surname><given-names>Eric</given-names></name>, and <name><surname>Darrell</surname><given-names>Trevor</given-names></name>. <year>2014</year>. <article-title>Decaf: A deep convolutional activation feature for generic visual recognition</article-title>. In <conf-name>International conference on machine learning</conf-name>. PMLR, <fpage>647</fpage>&#x02013;<lpage>655</lpage>.</mixed-citation></ref><ref id="R11"><label>[11]</label><mixed-citation publication-type="journal"><name><surname>Feng</surname><given-names>Shanglun</given-names></name> and <name><surname>Tram&#x000e8;r</surname><given-names>Florian</given-names></name>. <year>2024</year>. <article-title>Privacy Backdoors: Stealing Data with Corrupted Pretrained Models</article-title>. <source>arXiv</source> preprint arXiv:2404.00473 (2024).</mixed-citation></ref><ref id="R12"><label>[12]</label><mixed-citation publication-type="journal"><name><surname>He</surname><given-names>Junxian</given-names></name>, <name><surname>Zhou</surname><given-names>Chunting</given-names></name>, <name><surname>Ma</surname><given-names>Xuezhe</given-names></name>, <name><surname>Berg-Kirkpatrick</surname><given-names>Taylor</given-names></name>, and <name><surname>Neubig</surname><given-names>Graham</given-names></name>. <year>2021</year>. <article-title>Towards a unified view of parameter-efficient transfer learning</article-title>. <source>arXiv</source> preprint arXiv:2110.04366 (2021).</mixed-citation></ref><ref id="R13"><label>[13]</label><mixed-citation publication-type="confproc"><name><surname>Houlsby</surname><given-names>Neil</given-names></name>, <name><surname>Giurgiu</surname><given-names>Andrei</given-names></name>, <name><surname>Jastrzebski</surname><given-names>Stanislaw</given-names></name>, <name><surname>Morrone</surname><given-names>Bruna</given-names></name>, <name><surname>De Laroussilhe</surname><given-names>Quentin</given-names></name>, <name><surname>Gesmundo</surname><given-names>Andrea</given-names></name>, <name><surname>Attariyan</surname><given-names>Mona</given-names></name>, and <name><surname>Gelly</surname><given-names>Sylvain</given-names></name>. <year>2019</year>. <article-title>Parameter-efficient transfer learning for NLP</article-title>. In <conf-name>International Conference on Machine Learning</conf-name>. PMLR, <fpage>2790</fpage>&#x02013;<lpage>2799</lpage>.</mixed-citation></ref><ref id="R14"><label>[14]</label><mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>Edward J</given-names></name>, <name><surname>Shen</surname><given-names>Yelong</given-names></name>, <name><surname>Wallis</surname><given-names>Phillip</given-names></name>, <name><surname>Allen-Zhu</surname><given-names>Zeyuan</given-names></name>, <name><surname>Li</surname><given-names>Yuanzhi</given-names></name>, <name><surname>Wang</surname><given-names>Shean</given-names></name>, <name><surname>Wang</surname><given-names>Lu</given-names></name>, and <name><surname>Chen</surname><given-names>Weizhu</given-names></name>. <year>2021</year>. <article-title>Lora: Low-rank adaptation of large language models</article-title>. <source>arXiv</source> preprint arXiv:2106.09685 (2021).</mixed-citation></ref><ref id="R15"><label>[15]</label><mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>Kexin</given-names></name>, <name><surname>Altosaar</surname><given-names>Jaan</given-names></name>, and <name><surname>Ranganath</surname><given-names>Rajesh</given-names></name>. <year>2019</year>. <article-title>Clinicalbert: Modeling clinical notes and predicting hospital readmission</article-title>. <source>arXiv</source> preprint arXiv:1904.05342 (2019).</mixed-citation></ref><ref id="R16"><label>[16]</label><mixed-citation publication-type="book"><name><surname>Humphries</surname><given-names>Thomas</given-names></name>, <name><surname>Oya</surname><given-names>Simon</given-names></name>, <name><surname>Tulloch</surname><given-names>Lindsey</given-names></name>, <name><surname>Rafuse</surname><given-names>Matthew</given-names></name>, <name><surname>Goldberg</surname><given-names>Ian</given-names></name>, <name><surname>Hengartner</surname><given-names>Urs</given-names></name>, and <name><surname>Kerschbaum</surname><given-names>Florian</given-names></name>. <year>2023</year>. <part-title>Investigating membership inference attacks under data dependencies</part-title>. In <source>2023 IEEE 36th Computer Security Foundations Symposium (CSF)</source>. <publisher-name>IEEE</publisher-name>, <fpage>473</fpage>&#x02013;<lpage>488</lpage>.</mixed-citation></ref><ref id="R17"><label>[17]</label><mixed-citation publication-type="journal"><name><surname>Jayaraman</surname><given-names>Bargav</given-names></name>, <name><surname>Wang</surname><given-names>Lingxiao</given-names></name>, <name><surname>Knipmeyer</surname><given-names>Katherine</given-names></name>, <name><surname>Gu</surname><given-names>Quanquan</given-names></name>, and <name><surname>Evans</surname><given-names>David</given-names></name>. <year>2020</year>. <article-title>Revisiting membership inference under realistic assumptions</article-title>. <source>arXiv</source> preprint arXiv:2005.10881 (2020).</mixed-citation></ref><ref id="R18"><label>[18]</label><mixed-citation publication-type="book"><name><surname>Jia</surname><given-names>Jinyuan</given-names></name>, <name><surname>Liu</surname><given-names>Yupei</given-names></name>, and <name><surname>Gong</surname><given-names>Neil Zhenqiang</given-names></name>. <year>2022</year>. <part-title>Badencoder: Backdoor attacks to pre-trained encoders in self-supervised learning</part-title>. In <source>2022 IEEE Symposium on Security and Privacy (SP)</source>. <publisher-name>IEEE</publisher-name>, <fpage>2043</fpage>&#x02013;<lpage>2059</lpage>.</mixed-citation></ref><ref id="R19"><label>[19]</label><mixed-citation publication-type="other"><name><surname>Johnson</surname><given-names>Alistair</given-names></name>, <name><surname>Pollard</surname><given-names>Tom</given-names></name>, <name><surname>Horng</surname><given-names>Steven</given-names></name>, <name><surname>Celi</surname><given-names>Leo Anthony</given-names></name>, and <name><surname>Mark</surname><given-names>Roger</given-names></name>. <year>2023</year>. <source>MIMIC-IV-Note: Deidentified free-text clinical notes</source>.</mixed-citation></ref><ref id="R20"><label>[20]</label><mixed-citation publication-type="confproc"><name><surname>Kandpal</surname><given-names>Nikhil</given-names></name>, <name><surname>Wallace</surname><given-names>Eric</given-names></name>, and <name><surname>Raffel</surname><given-names>Colin</given-names></name>. <year>2022</year>. <article-title>Deduplicating training data mitigates privacy risks in language models</article-title>. In <conf-name>International Conference on Machine Learning</conf-name>. PMLR, <fpage>10697</fpage>&#x02013;<lpage>10707</lpage>.</mixed-citation></ref><ref id="R21"><label>[21]</label><mixed-citation publication-type="book"><name><surname>Klimt</surname><given-names>Bryan</given-names></name> and <name><surname>Yang</surname><given-names>Yiming</given-names></name>. <year>2004</year>. <part-title>The Enron Corpus: A New Dataset for Email Classification Research</part-title>. In <source>Proceedings of the 15th European Conference on Machine Learning (Pisa, Italy) (ECML&#x02019;04)</source>. <publisher-name>Springer-Verlag</publisher-name>, <publisher-loc>Berlin, Heidelberg</publisher-loc>, <fpage>217</fpage>&#x02013;<lpage>226</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-540-30115-8_22</pub-id></mixed-citation></ref><ref id="R22"><label>[22]</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>Jinhyuk</given-names></name>, <name><surname>Yoon</surname><given-names>Wonjin</given-names></name>, <name><surname>Kim</surname><given-names>Sungdong</given-names></name>, <name><surname>Kim</surname><given-names>Donghyeon</given-names></name>, <name><surname>Kim</surname><given-names>Sunkyu</given-names></name>, <name><surname>So</surname><given-names>Chan Ho</given-names></name>, and <name><surname>Kang</surname><given-names>Jaewoo</given-names></name>. <year>2020</year>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>
<volume>36</volume>, <issue>4</issue> (2020), <fpage>1234</fpage>&#x02013;<lpage>1240</lpage>.<pub-id pub-id-type="pmid">31501885</pub-id>
</mixed-citation></ref><ref id="R23"><label>[23]</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>Katherine</given-names></name>, <name><surname>Ippolito</surname><given-names>Daphne</given-names></name>, <name><surname>Nystrom</surname><given-names>Andrew</given-names></name>, <name><surname>Zhang</surname><given-names>Chiyuan</given-names></name>, <name><surname>Eck</surname><given-names>Douglas</given-names></name>, <name><surname>Callison-Burch</surname><given-names>Chris</given-names></name>, and <name><surname>Carlini</surname><given-names>Nicholas</given-names></name>. <year>2021</year>. <article-title>Deduplicating training data makes language models better</article-title>. <source>arXiv</source> preprint arXiv:2107.06499 (2021).</mixed-citation></ref><ref id="R24"><label>[24]</label><mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Xuechen</given-names></name>, <name><surname>Tramer</surname><given-names>Florian</given-names></name>, <name><surname>Liang</surname><given-names>Percy</given-names></name>, and <name><surname>Hashimoto</surname><given-names>Tatsunori</given-names></name>. <year>2021</year>. <article-title>Large language models can be strong differentially private learners</article-title>. <source>arXiv</source> preprint arXiv:2110.05679 (2021).</mixed-citation></ref><ref id="R25"><label>[25]</label><mixed-citation publication-type="confproc"><name><surname>Li</surname><given-names>Zheng</given-names></name> and <name><surname>Zhang</surname><given-names>Yang</given-names></name>. <year>2021</year>. <article-title>Membership leakage in label-only exposures</article-title>. In <conf-name>Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security</conf-name>. <fpage>880</fpage>&#x02013;<lpage>895</lpage>.</mixed-citation></ref><ref id="R26"><label>[26]</label><mixed-citation publication-type="journal"><name><surname>Lialin</surname><given-names>Vladislav</given-names></name>, <name><surname>Deshpande</surname><given-names>Vijeta</given-names></name>, and <name><surname>Rumshisky</surname><given-names>Anna</given-names></name>. <year>2023</year>. <article-title>Scaling down to scale up: A guide to parameter-efficient fine-tuning</article-title>. <source>arXiv</source> preprint arXiv:2303.15647 (2023).</mixed-citation></ref><ref id="R27"><label>[27]</label><mixed-citation publication-type="journal"><name><surname>Long</surname><given-names>Yunhui</given-names></name>, <name><surname>Bindschaedler</surname><given-names>Vincent</given-names></name>, <name><surname>Wang</surname><given-names>Lei</given-names></name>, <name><surname>Bu</surname><given-names>Diyue</given-names></name>, <name><surname>Wang</surname><given-names>Xiaofeng</given-names></name>, <name><surname>Tang</surname><given-names>Haixu</given-names></name>, <name><surname>Gunter</surname><given-names>Carl A</given-names></name>, and <name><surname>Chen</surname><given-names>Kai</given-names></name>. <year>2018</year>. <article-title>Understanding membership inferences on well-generalized learning models</article-title>. <source>arXiv</source> preprint arXiv:1802.04889 (2018).</mixed-citation></ref><ref id="R28"><label>[28]</label><mixed-citation publication-type="book"><name><surname>Long</surname><given-names>Yunhui</given-names></name>, <name><surname>Wang</surname><given-names>Lei</given-names></name>, <name><surname>Bu</surname><given-names>Diyue</given-names></name>, <name><surname>Bindschaedler</surname><given-names>Vincent</given-names></name>, <name><surname>Wang</surname><given-names>Xiaofeng</given-names></name>, <name><surname>Tang</surname><given-names>Haixu</given-names></name>, <name><surname>Gunter</surname><given-names>Carl A</given-names></name>, and <name><surname>Chen</surname><given-names>Kai</given-names></name>. <year>2020</year>. <part-title>A pragmatic approach to membership inferences on machine learning models</part-title>. In <source>2020 IEEE European Symposium on Security and Privacy (EuroS&#x00026;P)</source>. <publisher-name>IEEE</publisher-name>, <fpage>521</fpage>&#x02013;<lpage>534</lpage>.</mixed-citation></ref><ref id="R29"><label>[29]</label><mixed-citation publication-type="book"><name><surname>Mahloujifar</surname><given-names>Saeed</given-names></name>, <name><surname>Ghosh</surname><given-names>Esha</given-names></name>, and <name><surname>Chase</surname><given-names>Melissa</given-names></name>. <year>2022</year>. <part-title>Property inference from poisoning</part-title>. In <source>2022 IEEE Symposium on Security and Privacy (SP)</source>. <publisher-name>IEEE</publisher-name>, <fpage>1120</fpage>&#x02013;<lpage>1137</lpage>.</mixed-citation></ref><ref id="R30"><label>[30]</label><mixed-citation publication-type="journal"><name><surname>Maini</surname><given-names>Pratyush</given-names></name>, <name><surname>Mozer</surname><given-names>Michael C</given-names></name>, <name><surname>Sedghi</surname><given-names>Hanie</given-names></name>, <name><surname>Lipton</surname><given-names>Zachary C</given-names></name>, <name><surname>Kolter</surname><given-names>J Zico</given-names></name>, and <name><surname>Zhang</surname><given-names>Chiyuan</given-names></name>. <year>2023</year>. <article-title>Can neural network memorization be localized?</article-title>
<source>arXiv</source> preprint arXiv:2307.09542 (2023).</mixed-citation></ref><ref id="R31"><label>[31]</label><mixed-citation publication-type="journal"><name><surname>Marcus</surname><given-names>Mitchell P.</given-names></name>, <name><surname>Santorini</surname><given-names>Beatrice</given-names></name>, and <name><surname>Marcinkiewicz</surname><given-names>Mary Ann</given-names></name>. <year>1993</year>. <article-title>Building a Large Annotated Corpus of English: The Penn Treebank</article-title>. <source>Computational Linguistics</source>
<volume>19</volume>, <issue>2</issue> (1993), <fpage>313</fpage>&#x02013;<lpage>330</lpage>. <ext-link xlink:href="https://www.aclweb.org/anthology/J93-2004" ext-link-type="uri">https://www.aclweb.org/anthology/J93-2004</ext-link></mixed-citation></ref><ref id="R32"><label>[32]</label><mixed-citation publication-type="journal"><name><surname>Mattern</surname><given-names>Justus</given-names></name>, <name><surname>Mireshghallah</surname><given-names>Fatemehsadat</given-names></name>, <name><surname>Jin</surname><given-names>Zhijing</given-names></name>, <name><surname>Sch&#x000f6;lkopf</surname><given-names>Bernhard</given-names></name>, <name><surname>Sachan</surname><given-names>Mrinmaya</given-names></name>, and <name><surname>Berg-Kirkpatrick</surname><given-names>Taylor</given-names></name>. <year>2023</year>. <article-title>Membership Inference Attacks against Language Models via Neighbourhood Comparison</article-title>. <source>arXiv</source> preprint arXiv:2305.18462 (2023).</mixed-citation></ref><ref id="R33"><label>[33]</label><mixed-citation publication-type="journal"><name><surname>Mireshghallah</surname><given-names>Fatemehsadat</given-names></name>, <name><surname>Goyal</surname><given-names>Kartik</given-names></name>, <name><surname>Uniyal</surname><given-names>Archit</given-names></name>, <name><surname>Berg-Kirkpatrick</surname><given-names>Taylor</given-names></name>, and <name><surname>Shokri</surname><given-names>Reza</given-names></name>. <year>2022</year>. <article-title>Quantifying privacy risks of masked language models using membership inference attacks</article-title>. <source>arXiv</source> preprint arXiv:2203.03929 (2022).</mixed-citation></ref><ref id="R34"><label>[34]</label><mixed-citation publication-type="journal"><name><surname>Mireshghallah</surname><given-names>Fatemehsadat</given-names></name>, <name><surname>Uniyal</surname><given-names>Archit</given-names></name>, <name><surname>Wang</surname><given-names>Tianhao</given-names></name>, <name><surname>Evans</surname><given-names>David</given-names></name>, and <name><surname>Berg-Kirkpatrick</surname><given-names>Taylor</given-names></name>. <year>2022</year>. <article-title>Memorization in nlp fine-tuning methods</article-title>. <source>arXiv</source> preprint arXiv:2205.12506 (2022).</mixed-citation></ref><ref id="R35"><label>[35]</label><mixed-citation publication-type="book"><name><surname>Nasr</surname><given-names>Milad</given-names></name>, <name><surname>Shokri</surname><given-names>Reza</given-names></name>, and <name><surname>Houmansadr</surname><given-names>Amir</given-names></name>. <year>2019</year>. <part-title>Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning</part-title>. In <source>2019 IEEE symposium on security and privacy (SP)</source>. <publisher-name>IEEE</publisher-name>, <fpage>739</fpage>&#x02013;<lpage>753</lpage>.</mixed-citation></ref><ref id="R36"><label>[36]</label><mixed-citation publication-type="journal"><name><surname>O&#x02019;hagan</surname><given-names>A</given-names></name> and <name><surname>Leonard</surname><given-names>Tom</given-names></name>. <year>1976</year>. <article-title>Bayes estimation subject to uncertainty about parameter constraints</article-title>. <source>Biometrika</source>
<volume>63</volume>, <issue>1</issue> (1976), <fpage>201</fpage>&#x02013;<lpage>203</lpage>.</mixed-citation></ref><ref id="R37"><label>[37]</label><mixed-citation publication-type="journal"><name><surname>Pfeiffer</surname><given-names>Jonas</given-names></name>, <name><surname>R&#x000fc;ckl&#x000e9;</surname><given-names>Andreas</given-names></name>, <name><surname>Poth</surname><given-names>Clifton</given-names></name>, <name><surname>Kamath</surname><given-names>Aishwarya</given-names></name>, <name><surname>Vuli&#x00107;</surname><given-names>Ivan</given-names></name>, <name><surname>Ruder</surname><given-names>Sebastian</given-names></name>, <name><surname>Cho</surname><given-names>Kyunghyun</given-names></name>, and <name><surname>Gurevych</surname><given-names>Iryna</given-names></name>. <year>2020</year>. <article-title>Adapterhub: A framework for adapting transformers</article-title>. <source>arXiv</source> preprint arXiv:2007.07779 (2020).</mixed-citation></ref><ref id="R38"><label>[38]</label><mixed-citation publication-type="journal"><name><surname>Radford</surname><given-names>Alec</given-names></name>, <name><surname>Wu</surname><given-names>Jeffrey</given-names></name>, <name><surname>Child</surname><given-names>Rewon</given-names></name>, <name><surname>Luan</surname><given-names>David</given-names></name>, <name><surname>Amodei</surname><given-names>Dario</given-names></name>, <name><surname>Sutskever</surname><given-names>Ilya</given-names></name>, <etal/>
<year>2019</year>. <article-title>Language models are unsupervised multitask learners</article-title>. <source>OpenAI blog</source>
<volume>1</volume>, <issue>8</issue> (2019), <fpage>9</fpage>.</mixed-citation></ref><ref id="R39"><label>[39]</label><mixed-citation publication-type="confproc"><name><surname>Sablayrolles</surname><given-names>Alexandre</given-names></name>, <name><surname>Douze</surname><given-names>Matthijs</given-names></name>, <name><surname>Schmid</surname><given-names>Cordelia</given-names></name>, <name><surname>Ollivier</surname><given-names>Yann</given-names></name>, and <name><surname>J&#x000e9;gou</surname><given-names>Herv&#x000e9;</given-names></name>. <year>2019</year>. <article-title>White-box vs black-box: Bayes optimal strategies for membership inference</article-title>. In <conf-name>International Conference on Machine Learning</conf-name>. PMLR, <fpage>5558</fpage>&#x02013;<lpage>5567</lpage>.</mixed-citation></ref><ref id="R40"><label>[40]</label><mixed-citation publication-type="book"><name><surname>Salem</surname><given-names>Ahmed</given-names></name>, <name><surname>Cherubin</surname><given-names>Giovanni</given-names></name>, <name><surname>Evans</surname><given-names>David</given-names></name>, <name><surname>K&#x000f6;pf</surname><given-names>Boris</given-names></name>, <name><surname>Paverd</surname><given-names>Andrew</given-names></name>, <name><surname>Suri</surname><given-names>Anshuman</given-names></name>, <name><surname>Tople</surname><given-names>Shruti</given-names></name>, and <name><surname>Zanella-B&#x000e9;guelin</surname><given-names>Santiago</given-names></name>. <year>2023</year>. <part-title>SoK: Let the privacy games begin! A unified treatment of data inference privacy in machine learning</part-title>. In <source>2023 IEEE Symposium on Security and Privacy (SP)</source>. <publisher-name>IEEE</publisher-name>, <fpage>327</fpage>&#x02013;<lpage>345</lpage>.</mixed-citation></ref><ref id="R41"><label>[41]</label><mixed-citation publication-type="book"><name><surname>Shokri</surname><given-names>Reza</given-names></name>, <name><surname>Stronati</surname><given-names>Marco</given-names></name>, <name><surname>Song</surname><given-names>Congzheng</given-names></name>, and <name><surname>Shmatikov</surname><given-names>Vitaly</given-names></name>. <year>2017</year>. <part-title>Membership inference attacks against machine learning models</part-title>. In <source>2017 IEEE symposium on security and privacy (SP)</source>. <publisher-name>IEEE</publisher-name>, <fpage>3</fpage>&#x02013;<lpage>18</lpage>.</mixed-citation></ref><ref id="R42"><label>[42]</label><mixed-citation publication-type="journal"><name><surname>Srivastava</surname><given-names>Nitish</given-names></name>, <name><surname>Hinton</surname><given-names>Geoffrey</given-names></name>, <name><surname>Krizhevsky</surname><given-names>Alex</given-names></name>, <name><surname>Sutskever</surname><given-names>Ilya</given-names></name>, and <name><surname>Salakhutdinov</surname><given-names>Ruslan</given-names></name>. <year>2014</year>. <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>The journal of machine learning research</source>
<volume>15</volume>, <issue>1</issue> (2014), <fpage>1929</fpage>&#x02013;<lpage>1958</lpage>.</mixed-citation></ref><ref id="R43"><label>[43]</label><mixed-citation publication-type="confproc"><name><surname>Tian</surname><given-names>Yulong</given-names></name>, <name><surname>Suya</surname><given-names>Fnu</given-names></name>, <name><surname>Suri</surname><given-names>Anshuman</given-names></name>, <name><surname>Xu</surname><given-names>Fengyuan</given-names></name>, and <name><surname>Evans</surname><given-names>David</given-names></name>. <year>2023</year>. <article-title>Manipulating Transfer Learning for Property Inference</article-title>. In <conf-name>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</conf-name>. <fpage>15975</fpage>&#x02013;<lpage>15984</lpage>.</mixed-citation></ref><ref id="R44"><label>[44]</label><mixed-citation publication-type="confproc"><name><surname>Tram&#x000e8;r</surname><given-names>Florian</given-names></name>, <name><surname>Shokri</surname><given-names>Reza</given-names></name>, <name><surname>Joaquin</surname><given-names>Ayrton San</given-names></name>, <name><surname>Le</surname><given-names>Hoang</given-names></name>, <name><surname>Jagielski</surname><given-names>Matthew</given-names></name>, <name><surname>Hong</surname><given-names>Sanghyun</given-names></name>, and <name><surname>Carlini</surname><given-names>Nicholas</given-names></name>. <year>2022</year>. <article-title>Truth serum: Poisoning machine learning models to reveal their secrets</article-title>. In <conf-name>Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</conf-name>. <fpage>2779</fpage>&#x02013;<lpage>2792</lpage>.</mixed-citation></ref><ref id="R45"><label>[45]</label><mixed-citation publication-type="journal"><name><surname>Watson</surname><given-names>Lauren</given-names></name>, <name><surname>Guo</surname><given-names>Chuan</given-names></name>, <name><surname>Cormode</surname><given-names>Graham</given-names></name>, and <name><surname>Sablayrolles</surname><given-names>Alex</given-names></name>. <year>2021</year>. <article-title>On the importance of difficulty calibration in membership inference attacks</article-title>. <source>arXiv</source> preprint arXiv:2111.08440 (2021).</mixed-citation></ref><ref id="R46"><label>[46]</label><mixed-citation publication-type="journal"><name><surname>Wen</surname><given-names>Rui</given-names></name>, <name><surname>Wang</surname><given-names>Tianhao</given-names></name>, <name><surname>Backes</surname><given-names>Michael</given-names></name>, <name><surname>Zhang</surname><given-names>Yang</given-names></name>, and <name><surname>Salem</surname><given-names>Ahmed</given-names></name>. <year>2023</year>. <article-title>Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning</article-title>. <source>arXiv</source> preprint arXiv:2310.11397 (2023).</mixed-citation></ref><ref id="R47"><label>[47]</label><mixed-citation publication-type="journal"><name><surname>Wen</surname><given-names>Yuxin</given-names></name>, <name><surname>Marchyok</surname><given-names>Leo</given-names></name>, <name><surname>Hong</surname><given-names>Sanghyun</given-names></name>, <name><surname>Geiping</surname><given-names>Jonas</given-names></name>, <name><surname>Goldstein</surname><given-names>Tom</given-names></name>, and <name><surname>Carlini</surname><given-names>Nicholas</given-names></name>. <year>2024</year>. <article-title>Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models</article-title>. <source>arXiv</source> preprint arXiv:2404.01231 (2024).</mixed-citation></ref><ref id="R48"><label>[48]</label><mixed-citation publication-type="confproc"><name><surname>Ye</surname><given-names>Jiayuan</given-names></name>, <name><surname>Maddi</surname><given-names>Aadyaa</given-names></name>, <name><surname>Murakonda</surname><given-names>Sasi Kumar</given-names></name>, <name><surname>Bindschaedler</surname><given-names>Vincent</given-names></name>, and <name><surname>Shokri</surname><given-names>Reza</given-names></name>. <year>2022</year>. <article-title>Enhanced membership inference attacks against machine learning models</article-title>. In <conf-name>Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</conf-name>. <fpage>3093</fpage>&#x02013;<lpage>3106</lpage>.</mixed-citation></ref><ref id="R49"><label>[49]</label><mixed-citation publication-type="journal"><name><surname>Ye</surname><given-names>Jiayuan</given-names></name>, <name><surname>Zhu</surname><given-names>Zhenyu</given-names></name>, <name><surname>Liu</surname><given-names>Fanghui</given-names></name>, <name><surname>Shokri</surname><given-names>Reza</given-names></name>, and <name><surname>Cevher</surname><given-names>Volkan</given-names></name>. <year>2023</year>. <article-title>Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks</article-title>. <source>arXiv</source> preprint arXiv:2310.20579 (2023).</mixed-citation></ref><ref id="R50"><label>[50]</label><mixed-citation publication-type="book"><name><surname>Yeom</surname><given-names>Samuel</given-names></name>, <name><surname>Giacomelli</surname><given-names>Irene</given-names></name>, <name><surname>Fredrikson</surname><given-names>Matt</given-names></name>, and <name><surname>Jha</surname><given-names>Somesh</given-names></name>. <year>2018</year>. <part-title>Privacy risk in machine learning: Analyzing the connection to overfitting</part-title>. In <source>2018 IEEE 31st computer security foundations symposium (CSF)</source>. <publisher-name>IEEE</publisher-name>, <fpage>268</fpage>&#x02013;<lpage>282</lpage>.</mixed-citation></ref><ref id="R51"><label>[51]</label><mixed-citation publication-type="journal"><name><surname>Yu</surname><given-names>Da</given-names></name>, <name><surname>Naik</surname><given-names>Saurabh</given-names></name>, <name><surname>Backurs</surname><given-names>Arturs</given-names></name>, <name><surname>Gopi</surname><given-names>Sivakanth</given-names></name>, <name><surname>Inan</surname><given-names>Huseyin A</given-names></name>, <name><surname>Kamath</surname><given-names>Gautam</given-names></name>, <name><surname>Kulkarni</surname><given-names>Janardhan</given-names></name>, <name><surname>Yin Tat Lee</surname><given-names>Andre Manoel</given-names></name>, <name><surname>Wutschitz</surname><given-names>Lukas</given-names></name>, <etal/>
<year>2021</year>. <article-title>Differentially private fine-tuning of language models</article-title>. <source>arXiv</source> preprint arXiv:2110.06500 (2021).</mixed-citation></ref><ref id="R52"><label>[52]</label><mixed-citation publication-type="journal"><name><surname>Zaken</surname><given-names>Elad Ben</given-names></name>, <name><surname>Ravfogel</surname><given-names>Shauli</given-names></name>, and <name><surname>Goldberg</surname><given-names>Yoav</given-names></name>. <year>2021</year>. <article-title>Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models</article-title>. <source>arXiv</source> preprint arXiv:2106.10199 (2021).</mixed-citation></ref><ref id="R53"><label>[53]</label><mixed-citation publication-type="book"><name><surname>Zhang</surname><given-names>Xinyang</given-names></name>, <name><surname>Zhang</surname><given-names>Zheng</given-names></name>, <name><surname>Ji</surname><given-names>Shouling</given-names></name>, and <name><surname>Wang</surname><given-names>Ting</given-names></name>. <year>2021</year>. <part-title>Trojaning language models for fun and profit</part-title>. In <source>2021 IEEE European Symposium on Security and Privacy (EuroS&#x00026;P)</source>. <publisher-name>IEEE</publisher-name>, <fpage>179</fpage>&#x02013;<lpage>197</lpage>.</mixed-citation></ref></ref-list></back><floats-group><fig position="float" id="F1"><label>Figure 1:</label><caption><p id="P144">The privacy vulnerability for target models fine-tuned by various methods ranks as Head-FT &#x0003e; Full &#x0003e; Adapter-FT. <italic toggle="yes">PreCurious</italic> increases the privacy risk for each iteration and ruins the privacy-utility trade-off, as demonstrated with Head-FT and Adapter-FT. <inline-formula><mml:math id="M2" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> indicates the fine-tuning epochs and lower validation perplexity means better performance.</p></caption><graphic xlink:href="nihms-2081474-f0007" position="float"/></fig><fig position="float" id="F2"><label>Figure 2:</label><caption><p id="P145">Framework overview of <italic toggle="yes">PreCurious</italic>. The dashed gray line indicates extra side information that can be utilized: 1) the stopping criterion, 2) the fine-tuning method, and 3) the released sanitized data by masking the secret. We design <italic toggle="yes">Accelerated</italic> and <italic toggle="yes">Lagging</italic> strategies for stopping by epoch or by performance. We propose an aggressive anti-freezing strategy when the victim uses the given fine-tuning method. We utilize a released sanitized dataset in targeted data extraction experiments.</p></caption><graphic xlink:href="nihms-2081474-f0008" position="float"/></fig><fig position="float" id="F3"><label>Figure 3:</label><caption><p id="P146">Privacy risk for different model initialization status. Each point indicates the fine-tuned checkpoint for the Enron dataset with Adapter-FT. We use <email>TPR@0.1FPR</email> as the proxy metric to measure the privacy risk of the model based on the scoring method in <xref rid="FD6" ref-type="disp-formula">Equation (4)</xref>. We fully-finetuned the benign GPT-2 model on the auxiliary dataset for <inline-formula><mml:math id="M3" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="M4" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math></inline-formula> separately for <italic toggle="yes">Lagging Init</italic> and <italic toggle="yes">Accelerated Init</italic> with learning rate <inline-formula><mml:math id="M5" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> as model initialization.</p></caption><graphic xlink:href="nihms-2081474-f0009" position="float"/></fig><fig position="float" id="F4"><label>Figure 4:</label><caption><p id="P147">Ablation study of PreCurious on the crafted initialization and reference model with Enron and Adapter-FT GPT-2. Loss distributions for Benign initialization w/o <inline-formula><mml:math id="M6" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>, benign initialization w/ Full-Ref, and PreCurious initialization w/ Full-Ref.</p></caption><graphic xlink:href="nihms-2081474-f0010" position="float"/></fig><fig position="float" id="F5"><label>Figure 5:</label><caption><p id="P148">ROC-AUC curve for Enron on Adapter-FT GPT-2. <monospace>Base-Full</monospace> indicates calibrating with a benign model cannot even beat <monospace>Loss-Att</monospace> with the same benign initialization.</p></caption><graphic xlink:href="nihms-2081474-f0011" position="float"/></fig><fig position="float" id="F6"><label>Figure 6:</label><caption><p id="P149">Influence of initialization and reference model choices on MIA success metrics (AdapterFT-Enron). <monospace>aux1e1</monospace> (under-fit), <monospace>aux1e4</monospace> (just-fit) and <monospace>aux1e50</monospace> (over-fit) denotes checkpoints warmed up on <inline-formula><mml:math id="M7" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> with Full-FT in the crafting stage of <italic toggle="yes">PreCurious</italic> to represent different overfitting levels on <inline-formula><mml:math id="M8" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. We set a default <inline-formula><mml:math id="M9" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b7;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> for fully fine-tuning in <inline-formula><mml:math id="M10" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> to reduce the required <inline-formula><mml:math id="M11" display="inline"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> when simulating the overfitting status here.</p></caption><graphic xlink:href="nihms-2081474-f0012" position="float"/></fig><fig position="float" id="F7"><label>Figure 7:</label><caption><p id="P150">Stealthiness-Risk trade-off via rewinding layers on Enron dataset with Adapter-FT.</p></caption><graphic xlink:href="nihms-2081474-f0013" position="float"/></fig><fig position="float" id="F8"><label>Figure 8:</label><caption><p id="P151">Duplication statistics and MIA effectiveness with Full-Ref under deduplication defense on <inline-formula><mml:math id="M12" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> for PTB. The stealthiness metric <inline-formula><mml:math id="M13" display="inline"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x00394;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ppl</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is linearly scaled for clear visualization. We randomly subsample non-membership samples for keeping the same size as the deduplicated <inline-formula><mml:math id="M14" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> in MIA evaluation.</p></caption><graphic xlink:href="nihms-2081474-f0014" position="float"/></fig><fig position="float" id="F9"><label>Figure 9:</label><caption><p id="P152">MIA effectiveness on PTB dataset with <inline-formula><mml:math id="M15" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dedup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M16" display="inline"><mml:msubsup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow><mml:mrow><mml:mtext>dup</mml:mtext></mml:mrow></mml:msubsup></mml:math></inline-formula> as auxiliary data for training <inline-formula><mml:math id="M1500" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> in Benign or <inline-formula><mml:math id="M17" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre/ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> in PreCurious, and <inline-formula><mml:math id="M18" display="inline"><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>dedup</mml:mtext><mml:mo>/</mml:mo><mml:mtext>dup</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> denotes the default <inline-formula><mml:math id="M19" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> w/o deduplication.</p></caption><graphic xlink:href="nihms-2081474-f0015" position="float"/></fig><fig position="float" id="F10"><label>Figure 10:</label><caption><p id="P153">Breaking up privacy-utility trade-off under DP.</p></caption><graphic xlink:href="nihms-2081474-f0016" position="float"/></fig><fig position="float" id="F11"><label>Figure 11:</label><caption><p id="P154">MIA effectiveness for Enron and PTB datasets with Adapter-FT. The baseline of Lagging w/ <inline-formula><mml:math id="M20" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> indicates anti-freezing on <inline-formula><mml:math id="M21" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and then applying weight scaling with <inline-formula><mml:math id="M200" display="inline"><mml:mi>&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math></inline-formula>. We use different seeds when randomly initializing adapter module parameters for <inline-formula><mml:math id="M22" display="inline"><mml:msub><mml:mrow><mml:mi>&#x1d4af;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mspace width="0.5em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.5em"/><mml:mi>&#x1d4af;</mml:mi></mml:math></inline-formula>. Lagging w/o <inline-formula><mml:math id="M23" display="inline"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>aux</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> performs the weight scaling directly on the benign <inline-formula><mml:math id="M24" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>benign</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>.</p></caption><graphic xlink:href="nihms-2081474-f0017" position="float"/></fig><fig position="float" id="F12"><label>Figure 12:</label><caption><p id="P155">Untargeted Data Extraction for Adapter-FT model with <inline-formula><mml:math id="M25" display="inline"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mtext>sub</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> for for Enron (top) and <inline-formula><mml:math id="M26" display="inline"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mtext>sub</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> PTB (bottom).</p></caption><graphic xlink:href="nihms-2081474-f0018" position="float"/></fig><fig position="float" id="F13"><label>Figure 13:</label><caption><p id="P156">Targeted data extraction on Enron with Adapter-FT and <inline-formula><mml:math id="M27" display="inline"><mml:mi>&#x003f5;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula> for DP-SGD. No secret&#x02019;s exposure is above the valid threshold for fine-tuned benign model under DP.</p></caption><graphic xlink:href="nihms-2081474-f0019" position="float"/></fig><table-wrap position="float" id="T1" orientation="landscape"><label>Table 1:</label><caption><p id="P157">Membership inference evaluation on GPT-2 with various PEFTs <inline-formula><mml:math id="M28" display="inline"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>Pre</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula>. <monospace>Loss-Att</monospace> indicates loss-value based MIA in <xref rid="FD6" ref-type="disp-formula">Equation (4)</xref> and <monospace>Full-Ref</monospace> indicates reference-model-based MIA in <xref rid="FD7" ref-type="disp-formula">Equation (5)</xref>. PreCurious shows amplified risk on all datasets, all PEFT methods in all MIA success metrics, while slightly increases the model performance measured by Val-PPL. PreCurious-Stealthy has an inferior attack performance than Basic but still amplifies risks compared to benign models.</p></caption><table frame="hsides" rules="none"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><tbody><tr><th colspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1">Dataset</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">Enron</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">PubMed</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">PTB</th></tr><tr><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Adapter-FT</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">17.19</td><td align="center" valign="middle" rowspan="1" colspan="1">92.89%</td><td align="center" valign="middle" rowspan="1" colspan="1">16.17%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">2.40%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">15.93</td><td align="center" valign="middle" rowspan="1" colspan="1">99.59%</td><td align="center" valign="middle" rowspan="1" colspan="1">92.34%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">68.33%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">23.16</td><td align="center" valign="middle" rowspan="1" colspan="1">99.79%</td><td align="center" valign="middle" rowspan="1" colspan="1">96.85%</td><td align="center" valign="middle" rowspan="1" colspan="1">92.84%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">17.86</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">82.42%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">7.63%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">1.80%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">18.78</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">60.74%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">2.66%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.57%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">25.37</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">93.00%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">46.70%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">14.90%</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Loss-Att</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">19.84</td><td align="center" valign="middle" rowspan="1" colspan="1">55.00%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.05%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">18.71</td><td align="center" valign="middle" rowspan="1" colspan="1">56.04%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.47%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">30.43</td><td align="center" valign="middle" rowspan="1" colspan="1">56.97%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.58%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.29%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">19.84</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">81.24%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">8.53%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.30%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">18.71</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">75.25%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">11.46%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.52%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">30.43</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">70.11%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">16.62%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">2.58%</td></tr></tbody><tbody><tr><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Bitfit-FT</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">17.33</td><td align="center" valign="middle" rowspan="1" colspan="1">76.20%</td><td align="center" valign="middle" rowspan="1" colspan="1">3.89%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.75%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">16.00</td><td align="center" valign="middle" rowspan="1" colspan="1">76.01%</td><td align="center" valign="middle" rowspan="1" colspan="1">6.70%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">1.62%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">23.18</td><td align="center" valign="middle" rowspan="1" colspan="1">94.90%</td><td align="center" valign="middle" rowspan="1" colspan="1">50.72%</td><td align="center" valign="middle" rowspan="1" colspan="1">40.40%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">18.77</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">59.06%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">3.89%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.45%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">17.00</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">61.21%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">3.80%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.19%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">25.99</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">71.24%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">5.16%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">1.72%</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Loss-Att</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">22.07</td><td align="center" valign="middle" rowspan="1" colspan="1">52.55%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.20%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">21.57</td><td align="center" valign="middle" rowspan="1" colspan="1">51.51%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.19%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">35.74</td><td align="center" valign="middle" rowspan="1" colspan="1">52.14%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.29%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.01%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">22.07</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">58.06%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">4.64%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.15%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">21.57</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">55.08%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">2.04%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">35.74</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">65.14%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">6.02%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">0.86%</td></tr></tbody><tbody><tr><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">LoRA-FT</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">17.06</td><td align="center" valign="middle" rowspan="1" colspan="1">93.76%</td><td align="center" valign="middle" rowspan="1" colspan="1">17.37%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">1.95%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">16.83</td><td align="center" valign="middle" rowspan="1" colspan="1">94.12%</td><td align="center" valign="middle" rowspan="1" colspan="1">52.73%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">22.35%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">23.06</td><td align="center" valign="middle" rowspan="1" colspan="1">99.94%</td><td align="center" valign="middle" rowspan="1" colspan="1">97.99%</td><td align="center" valign="middle" rowspan="1" colspan="1">93.98%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">17.97</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">81.38%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">8.83%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">2.10%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">15.94</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">99.72%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">93.87%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">69.42%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">25.91</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">91.48%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">36.39%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">17.48%</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Loss-Att</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">20.12</td><td align="center" valign="middle" rowspan="1" colspan="1">54.74%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.05%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">19.24</td><td align="center" valign="middle" rowspan="1" colspan="1">55.86%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.38%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">32.02</td><td align="center" valign="middle" rowspan="1" colspan="1">56.82%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.87%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.29%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">20.12</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">75.96%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">3.14%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.30%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">19.24</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">86.64%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">26.63%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.38%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">32.02</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">85.30%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">36.68%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">15.76%</td></tr></tbody><tbody><tr><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Head-FT</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">18.56</td><td align="center" valign="middle" rowspan="1" colspan="1">96.63%</td><td align="center" valign="middle" rowspan="1" colspan="1">21.71%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">2.40%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">17.69</td><td align="center" valign="middle" rowspan="1" colspan="1">98.77%</td><td align="center" valign="middle" rowspan="1" colspan="1">80.93%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">24.49%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">28.06</td><td align="center" valign="middle" rowspan="1" colspan="1">99.32%</td><td align="center" valign="middle" rowspan="1" colspan="1">74.79%</td><td align="center" valign="middle" rowspan="1" colspan="1">47.85%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">19.18</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">94.41%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">18.86%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.30%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">18.20</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">95.35%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">58.39%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">19.50%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">29.02</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">99.70%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">87.39%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">79.94%</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Loss-Att</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">35.93</td><td align="center" valign="middle" rowspan="1" colspan="1">54.72%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.20%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">30.57</td><td align="center" valign="middle" rowspan="1" colspan="1">52.97%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.24%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">50.31</td><td align="center" valign="middle" rowspan="1" colspan="1">54.79%</td><td align="center" valign="middle" rowspan="1" colspan="1">3.44%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.72%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">35.93</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">57.26%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">6.29%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.45%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">30.57</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">56.56%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">0.02%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">50.31</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">68.18%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">4.30%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">2.29%</td></tr></tbody><tbody><tr><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Full-FT</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">16.68</td><td align="center" valign="middle" rowspan="1" colspan="1">96.49%</td><td align="center" valign="middle" rowspan="1" colspan="1">30.24%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">1.95%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">15.46</td><td align="center" valign="middle" rowspan="1" colspan="1">99.99%</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">99.95%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">22.31</td><td align="center" valign="middle" rowspan="1" colspan="1">99.99%</td><td align="center" valign="middle" rowspan="1" colspan="1">100.00%</td><td align="center" valign="middle" rowspan="1" colspan="1">99.43%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">16.84</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">96.17%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">35.03%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">2.10%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">17.45</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">72.92%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">7.56%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">1.24%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">23.07</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">99.97%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">99.71%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">97.99%</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-right: solid 1px" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Loss-Att</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">18.49</td><td align="center" valign="middle" rowspan="1" colspan="1">62.95%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.20%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">17.42</td><td align="center" valign="middle" rowspan="1" colspan="1">64.85%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.81%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">27.67</td><td align="center" valign="middle" rowspan="1" colspan="1">66.79%</td><td align="center" valign="middle" rowspan="1" colspan="1">4.58%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.87%</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">18.49</td><td align="center" valign="middle" rowspan="1" colspan="1">91.56%</td><td align="center" valign="middle" rowspan="1" colspan="1">14.22%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">1.35%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">17.42</td><td align="center" valign="middle" rowspan="1" colspan="1">98.93%</td><td align="center" valign="middle" rowspan="1" colspan="1">90.16%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">73.04%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">27.67</td><td align="center" valign="middle" rowspan="1" colspan="1">93.39%</td><td align="center" valign="middle" rowspan="1" colspan="1">66.48%</td><td align="center" valign="middle" rowspan="1" colspan="1">64.18%</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T2" orientation="landscape"><label>Table 2:</label><caption><p id="P158">Membership inference evaluation on GPT-2 medium and GPT-2 large with AdapterFT <inline-formula><mml:math id="M29" display="inline"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula></p></caption><table frame="hsides" rules="none"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><tbody><tr><th colspan="2" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">Adapter-FT</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">Enron</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">PubMed</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">PTB</th></tr><tr><th colspan="2" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">GPT-2 Medium</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">14.18</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">84.31%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">6.29%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.75%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">13.01</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">96.48%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">51.93%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">2.38%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">20.11</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">97.47%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">67.05%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">48.71%</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom: solid 1px" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Loss-Att</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">17.17</td><td align="center" valign="middle" rowspan="1" colspan="1">53.48%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.20%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.15%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">14.82</td><td align="center" valign="middle" rowspan="1" colspan="1">54.68%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.19%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">26.97</td><td align="center" valign="middle" rowspan="1" colspan="1">53.62%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.72%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.15%</td></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">17.17</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">58.12%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">2.40%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.75%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">14.82</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">73.39%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">9.89%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">1.14%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">26.97</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">62.81%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">5.16%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">2.58%</td></tr></tbody><tbody><tr><th colspan="2" align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1">GPT-2 Large</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th></tr><tr><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">12.39</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">87.24%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">29.34%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">5.54%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">11.64</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">98.25%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">73.99%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">0.05%</td><td align="center" valign="middle" style="border-bottom: solid 1px;border-right: solid 1px" rowspan="1" colspan="1">16.94</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">99.40%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">97.99%</td><td align="center" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1">96.56%</td></tr><tr><td rowspan="2" align="center" valign="middle" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Loss-Att</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">14.92</td><td align="center" valign="middle" rowspan="1" colspan="1">57.01%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.05%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.15%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">12.82</td><td align="center" valign="middle" rowspan="1" colspan="1">59.47%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.81%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">21.66</td><td align="center" valign="middle" rowspan="1" colspan="1">60.79%</td><td align="center" valign="middle" rowspan="1" colspan="1">3.15%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.29%</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">14.92</td><td align="center" valign="middle" rowspan="1" colspan="1">62.55%</td><td align="center" valign="middle" rowspan="1" colspan="1">6.44%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">2.25%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">12.82</td><td align="center" valign="middle" rowspan="1" colspan="1">85.66%</td><td align="center" valign="middle" rowspan="1" colspan="1">24.68%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">21.66</td><td align="center" valign="middle" rowspan="1" colspan="1">78.78%</td><td align="center" valign="middle" rowspan="1" colspan="1">31.81%</td><td align="center" valign="middle" rowspan="1" colspan="1">24.07%</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T3" orientation="landscape"><label>Table 3:</label><caption><p id="P159">Membership inference evaluation on GPT-2 with Adapter-FT w/o <inline-formula><mml:math id="M30" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>ft</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula></p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr style="border-bottom: solid 1px"><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Dataset</th><th align="center" valign="middle" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" rowspan="1">Enron</th><th align="center" valign="middle" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" rowspan="1">PubMed</th><th align="center" valign="middle" rowspan="1" colspan="1"/><th colspan="3" align="center" valign="middle" rowspan="1">PTB</th></tr><tr><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Adapter-FT</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">@FPR0.01%</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Val-PPL</th><th align="center" valign="middle" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" rowspan="1" colspan="1">@FPR1%</th><th align="center" valign="middle" rowspan="1" colspan="1">@FPR0.01%</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious-Accelerated</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">18.11</td><td align="center" valign="middle" rowspan="1" colspan="1">55.59%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.20%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">16.08</td><td align="center" valign="middle" rowspan="1" colspan="1">56.78%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.10%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">26.70</td><td align="center" valign="middle" rowspan="1" colspan="1">58.03%</td><td align="center" valign="middle" rowspan="1" colspan="1">3.73%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.01%</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious-Basic</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">18.17</td><td align="center" valign="middle" rowspan="1" colspan="1">55.34%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.20%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">16.09</td><td align="center" valign="middle" rowspan="1" colspan="1">56.63%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.19%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">26.54</td><td align="center" valign="middle" rowspan="1" colspan="1">57.25%</td><td align="center" valign="middle" rowspan="1" colspan="1">3.15%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.72%</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">19.84</td><td align="center" valign="middle" rowspan="1" colspan="1">55.00%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.05%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">18.71</td><td align="center" valign="middle" rowspan="1" colspan="1">56.04%</td><td align="center" valign="middle" rowspan="1" colspan="1">1.47%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">0.00%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">30.43</td><td align="center" valign="middle" rowspan="1" colspan="1">56.97%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.58%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.29%</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T4"><label>Table 4:</label><caption><p id="P160">Stealthiness on crafted <inline-formula><mml:math id="M31" display="inline"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>pre</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>. The red cell denotes &#x02018;suspicious&#x02019; and green cell indicates &#x02018;evaded&#x02019;.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Dataset</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Released Model</th><th align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="M32" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mia</mml:mtext></mml:mrow></mml:msub></mml:math>
</inline-formula>
</th><th align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="M33" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mtext>mem</mml:mtext></mml:mrow></mml:msub></mml:math>
</inline-formula>
</th><th align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="M34" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mtext>gap</mml:mtext></mml:mrow></mml:msub></mml:math>
</inline-formula>
</th></tr></thead><tbody><tr><td rowspan="5" align="center" valign="middle" style="border-right: solid 1px;border-bottom: solid 1px" colspan="1">Enron</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">0.5130</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">0.0359</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">
<bold>&#x02212;3.7130</bold>
</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Accelerated</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>0.5008</bold>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">0.0255</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>-0.8853</underline>
</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">0.5054</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0494</underline>
</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>-0.8963</underline>
</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">0.5090</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0479</underline>
</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>-1.1640</underline>
</td></tr><tr style="border-bottom: solid 1px"><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Lagging</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>0.5008</bold>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>0.0000</bold>
</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>12.9240</underline>
</td></tr><tr><td rowspan="5" align="center" valign="middle" style="border-right: solid 1px;border-bottom: solid 1px" colspan="1">Pubmed</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">
<bold>0.5010</bold>
</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">0.0005</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">&#x02212;0.0650</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Accelerated</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.5084</underline>
</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0029</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">&#x02212;0.0940</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.5071</underline>
</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0029</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">&#x02212;0.0974</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.5060</underline>
</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0024</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">&#x02212;0.1105</td></tr><tr style="border-bottom: solid 1px"><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Lagging</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.5049</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>0.0000</bold>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>&#x02212;1.2530</bold>
</td></tr><tr><td rowspan="5" align="center" valign="middle" style="border-right: solid 1px;border-bottom: solid 1px" colspan="1">Ptb</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">0.4834</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">0.0057</td><td align="center" valign="middle" style="background-color:#ECECEC" rowspan="1" colspan="1">6.5190</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Accelerated</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>0.4805</bold>
</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0086</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">2.5140</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">0.4819</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0086</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">3.0630</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Stealthy</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">0.4816</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.0086</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>2.3150</bold>
</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Lagging</td><td align="center" valign="middle" style="background-color:#FFCCCC" rowspan="1" colspan="1">
<underline>0.5019</underline>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">
<bold>0.0000</bold>
</td><td align="center" valign="middle" style="background-color:#CCFFCC" rowspan="1" colspan="1">3.8090</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T5"><label>Table 5:</label><caption><p id="P161">MIA effectiveness under weight-decaying on Enron dataset with LoRA-FT (w/ weight decay factor 0.5).</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Model Init.</th><th align="center" valign="middle" rowspan="1" colspan="1">AUC w/o <inline-formula><mml:math id="M35" display="inline"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="center" valign="middle" rowspan="1" colspan="1">@0.01FPR</th><th align="center" valign="middle" rowspan="1" colspan="1">@0.1FPR</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Tr-PPL</th><th align="center" valign="middle" rowspan="1" colspan="1">Val-PPL</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" rowspan="1" colspan="1">54.37%</td><td align="center" valign="middle" rowspan="1" colspan="1">2.40%</td><td align="center" valign="middle" rowspan="1" colspan="1">38.32%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">73.48%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">20.18</td><td align="center" valign="middle" rowspan="1" colspan="1">20.19</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>55.18%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>15.57%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>85.63%</bold>
</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<bold>92.70%</bold>
</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<bold>16.61</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>17.07</bold>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T6"><label>Table 6:</label><caption><p id="P162">MIA effectiveness under DP fine-tuning defense on PTB dataset with Adapter-FT <inline-formula><mml:math id="M36" display="inline"><mml:mo>(</mml:mo><mml:mi>&#x003f5;</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:math></inline-formula>.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Model Init.</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Strategy</th><th align="center" valign="middle" rowspan="1" colspan="1">@0.01FPR</th><th align="center" valign="middle" rowspan="1" colspan="1">@0.1FPR</th><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">AUC</th><th align="center" valign="middle" rowspan="1" colspan="1">Val-PPL</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Benign</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Full-Ref</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>1.72%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">10.03%</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">52.05%</td><td align="center" valign="middle" rowspan="1" colspan="1">68.61</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">PreCurious</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Basic</td><td align="center" valign="middle" rowspan="1" colspan="1">0.86%</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>14.04%</bold>
</td><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">
<bold>54.84%</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>25.94</bold>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T7"><label>Table 7:</label><caption><p id="P163">Comparison with related works that manipulate integrity for privacy risk amplification. Manipulate: &#x025cb;/ &#x025d0; / <inline-graphic xlink:href="nihms-2081474-ig0001.jpg"/> represents manipulating model parameters/model/training data; PEFT: &#x025cb;/ &#x025d0; / <inline-graphic xlink:href="nihms-2081474-ig0002.jpg"/> represents no/evaluated/evaluated and investigated. Case II: whether considering comparison cases when the fine-tuner applies early stopping. Stealthy: whether considering stealthiness control.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Method</th><th align="center" valign="middle" rowspan="1" colspan="1">Attacker&#x02019;s Goal</th><th align="center" valign="middle" rowspan="1" colspan="1">Victim&#x02019;s Task</th><th align="center" valign="middle" rowspan="1" colspan="1">Manipulate</th><th align="center" valign="middle" rowspan="1" colspan="1">Case II</th><th align="center" valign="middle" rowspan="1" colspan="1">Stealthy</th><th align="center" valign="middle" rowspan="1" colspan="1">PEFT</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">[<xref rid="R7" ref-type="bibr">7</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">MIA</td><td align="center" valign="middle" rowspan="1" colspan="1">Discriminative</td><td align="center" valign="middle" rowspan="1" colspan="1">
<graphic xlink:href="nihms-2081474-t0003" position="float"/>
</td><td align="center" valign="middle" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" rowspan="1" colspan="1">yes</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">[<xref rid="R29" ref-type="bibr">29</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">Property inference</td><td align="center" valign="middle" rowspan="1" colspan="1">Discriminative</td><td align="center" valign="middle" rowspan="1" colspan="1">
<graphic xlink:href="nihms-2081474-t0004" position="float"/>
</td><td align="center" valign="middle" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" rowspan="1" colspan="1">no</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td></tr><tr style="border-bottom: solid 1px"><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">[<xref rid="R44" ref-type="bibr">44</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">MIA+Extraction</td><td align="center" valign="middle" rowspan="1" colspan="1">Generative</td><td align="center" valign="middle" rowspan="1" colspan="1">
<graphic xlink:href="nihms-2081474-t0005" position="float"/>
</td><td align="center" valign="middle" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" rowspan="1" colspan="1">no</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">[<xref rid="R43" ref-type="bibr">43</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">Property inference</td><td align="center" valign="middle" rowspan="1" colspan="1">Discriminative</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td><td align="center" valign="middle" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" rowspan="1" colspan="1">yes</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">[<xref rid="R11" ref-type="bibr">11</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">Reconstruction</td><td align="center" valign="middle" rowspan="1" colspan="1">Discriminative</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025d0;</td><td align="center" valign="middle" rowspan="1" colspan="1">N/A</td><td align="center" valign="middle" rowspan="1" colspan="1">no</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td></tr><tr style="border-bottom: solid 1px"><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">[<xref rid="R47" ref-type="bibr">47</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">MIA</td><td align="center" valign="middle" rowspan="1" colspan="1">Generative</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td><td align="center" valign="middle" rowspan="1" colspan="1">no</td><td align="center" valign="middle" rowspan="1" colspan="1">yes</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025d0;</td></tr><tr><td align="center" valign="middle" style="border-right: solid 1px" rowspan="1" colspan="1">Ours</td><td align="center" valign="middle" rowspan="1" colspan="1">MIA+Extraction</td><td align="center" valign="middle" rowspan="1" colspan="1">Generative</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x025cb;</td><td align="center" valign="middle" rowspan="1" colspan="1">yes</td><td align="center" valign="middle" rowspan="1" colspan="1">yes</td><td align="center" valign="middle" rowspan="1" colspan="1">
<graphic xlink:href="nihms-2081474-t0006" position="float"/>
</td></tr></tbody></table></table-wrap><boxed-text id="BX1" position="float"><caption><title>CCS Concepts</title></caption><p id="P164">&#x02022; Security and privacy; &#x02022; Computing methodologies &#x02192; Artificial intelligence;</p></boxed-text></floats-group></article>