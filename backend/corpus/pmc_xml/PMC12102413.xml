<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Health Inf Sci Syst</journal-id><journal-id journal-id-type="iso-abbrev">Health Inf Sci Syst</journal-id><journal-title-group><journal-title>Health Information Science and Systems</journal-title></journal-title-group><issn pub-type="epub">2047-2501</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC12102413</article-id><article-id pub-id-type="publisher-id">353</article-id><article-id pub-id-type="doi">10.1007/s13755-025-00353-7</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>A high-precision hierarchical registration approach for stain- and scanner-independent colocalization on whole slide images in histopathology</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7743-0792</contrib-id><name><surname>Bisson</surname><given-names>Tom</given-names></name><address><email>tom.bisson@charite.de</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0112-709X</contrib-id><name><surname>Franz</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0616-7082</contrib-id><name><surname>Kiehl</surname><given-names>Tim-Rasmus</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9921-4284</contrib-id><name><surname>Boor</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6810-586X</contrib-id><name><surname>Hufnagl</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0314-3037</contrib-id><name><surname>Zerbe</surname><given-names>Norman</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref><xref ref-type="aff" rid="Aff5">5</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/001w7jn25</institution-id><institution-id institution-id-type="GRID">grid.6363.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2218 4662</institution-id><institution>Charit&#x000e9; &#x02013; Universit&#x000e4;tsmedizin Berlin, corporate member of Freie Universit&#x000e4;t Berlin and Humboldt-Universit&#x000e4;t zu Berlin, </institution><institution>Institute of Medical Informatics, </institution></institution-wrap>Invalidenstra&#x000df;e 90, 10115 Berlin, Germany </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/001w7jn25</institution-id><institution-id institution-id-type="GRID">grid.6363.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2218 4662</institution-id><institution>Charit&#x000e9; &#x02013; Universit&#x000e4;tsmedizin Berlin, corporate member of Freie Universit&#x000e4;t Berlin and Humboldt-Universit&#x000e4;t zu Berlin, </institution><institution>Institute of Pathology, </institution></institution-wrap>Virchowweg 15, 10117 Berlin, Germany </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0493xsw21</institution-id><institution-id institution-id-type="GRID">grid.484013.a</institution-id><institution>Berlin Institute of Health at Charit&#x000e9; &#x02013; Universit&#x000e4;tsmedizin Berlin, </institution></institution-wrap>Charit&#x000e9;platz 1, 10117 Berlin, Germany </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04xfq0f34</institution-id><institution-id institution-id-type="GRID">grid.1957.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 0728 696X</institution-id><institution>University Clinic Aachen, </institution><institution>RWTH University, </institution></institution-wrap>Aachen, Germany </aff><aff id="Aff5"><label>5</label>EMPAIA International e.V., Berlin, Germany </aff></contrib-group><pub-date pub-type="epub"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>12</month><year>2025</year></pub-date><volume>13</volume><issue>1</issue><elocation-id>38</elocation-id><history><date date-type="received"><day>4</day><month>7</month><year>2024</year></date><date date-type="accepted"><day>30</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Purpose</title><p id="Par1">The paper presents a high-precision hierarchical registration method to accurately align image coordinates across Whole Slide Images of histopathological slides. The proposed technique was designed to achieve robust and pixel-precise stain- and scanner-independent colocalization. It addresses well-known challenges of histopathological imaging and differences arising from various staining protocols and digitization processes.</p></sec><sec><title>Methods</title><p id="Par2">Our method leverages the Elastix registration framework to achieve exceptionally precise colocalization of cell nuclei and other similarly sized tissue structures. By utilizing the pyramidal data structure of Whole Slide Images, we developed a hierarchical, multi-stage registration algorithm in which the transformation is gradually refined from a macroscopic to a microscopic scale.</p></sec><sec><title>Results</title><p id="Par3">Unlike other work in the field, our approach focuses on the colocalization of tissue structures rather than the alignment of the image data. The algorithm achieved sub-micrometer accuracy in colocalization, outperforming state-of-the-art solutions. We propose two distinct registration strategies to minimize the computation time, considering the spatial distribution of the coordinates.</p></sec><sec><title>Conclusion</title><p id="Par4">This algorithm is designed exclusively to compute point cloud transformations within Whole Slide Images, achieving a high accuracy at the expense of computation time. Consequently, it should be considered a highly specialized solution tailored to a specific subset of the registration problems occurring in digital pathology.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Image registration</kwd><kwd>Colocalization</kwd><kwd>Histopathology</kwd><kwd>Whole slide imaging</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100021130</institution-id><institution>Bundesministerium f&#x000fc;r Wirtschaft und Klimaschutz</institution></institution-wrap></funding-source><award-id>FKZ 01MK20002A</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium f&#x000fc;r Bildung und Forschung</institution></institution-wrap></funding-source><award-id>01IS18082D</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>Charit&#x000e9; - Universit&#x000e4;tsmedizin Berlin (3093)</institution></funding-source></award-group><open-access><p>Open Access funding enabled and organized by Projekt DEAL.</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Switzerland AG 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><sec id="Sec2"><title>Motivation</title><p id="Par5">In computer science, image registration is an iterative process to arrive at a geometric transformation that provides the best alignment of one or more images to a reference image. In medical imaging, the need for image alignment arose from the requirement to examine temporal or spatial alterations in anatomical structures visually or to allow comparison of similar objects from different modalities or specimens. While in radiological images, excessive deviations between the individual image contents are primarily caused by physiological processes, patient movements, or the imaging system itself, the reasons for alignment and content differences in histopathological images are partly different. High-resolution scans of histological images, prepared from fixed tissue of biopsies or resections, are generally used in this context. These digitized slides may differ, for instance, in terms of tissue type, staining, focus, or scanning device. Furthermore, preparation and digitization can both introduce artifacts that must be intercepted during registration. In addition to a more sophisticated understanding of the three-dimensional orientation of tissue structures, the registration of slide sections for the colocalization of various biomarkers is an essential tool.</p></sec><sec id="Sec3"><title>Challenges</title><p id="Par6">For image registration, robust algorithms and toolboxes have been developed to solve more complex problems, such as missing object fragments, wrapped and overlapping structures, or strongly diverging intensity distributions. However, most of these problems are complex and cannot be solved with a linear, out-of-the-box approach. Depending on the dataset characteristics, a tailored approach is required for each use case. For example, a set of parameters may be successful for a particular dataset but fail completely for another, slightly different one. Therefore, registration methods previously developed cannot be applied to image data in digital pathology without some adaptation. High-resolution scans of histological sections, so-called Whole Slide Images (WSIs), commonly have resolutions of around 0.25&#x000a0;&#x003bc;m per pixel, which causes a 1 cm<sup>2</sup> piece of tissue to require about 4.5&#x000a0;GB of memory. If a WSI contains a particularly large resection or several large pieces of tissue, it easily reaches file sizes that exceed the usual memory capacities in personal computers or workstations. However, even with smaller file sizes, fast and efficient image data processing is only possible to a limited extent. One approach to working with such high-resolution images is to store the image in different resolution levels and to additionally tessellate these individual levels, i.e., to split the image into several tiles to enable fast and targeted access to relevant image sections. However, there are also particular challenges concerning the image content. These include the fact that the images to be registered can differ significantly in terms of staining, saturation, and intensity. Even if the two slides are standard hematoxylin and eosin (H&#x00026;E) stains, they may differ considerably depending on the respective laboratory. The differences will be even more significant if the slides come in different tinctorial stains. The scanners and respective scanning profiles used in each case also significantly affect the appearance of the WSIs. Furthermore, variations arise during the preparation of the histological sections, such as different orientations on the slide or damage to the tissue, including tears, folds, or overlaps, introducing additional challenges during registration.</p></sec><sec id="Sec4"><title>Related work</title><p id="Par7">A significant achievement for the registration of medical image data has been the Elastix framework [<xref ref-type="bibr" rid="CR1">1</xref>], which provides a modularized and highly configurable toolbox for rigid and non-rigid registration based on the ITK framework [<xref ref-type="bibr" rid="CR2">2</xref>]. Although its main focus is on radiology, the framework is intended for use in any imaging modality and also beyond the scope of medical imaging. The registration of WSIs is particularly challenging, as image sizes of more than 100,000&#x02009;&#x000d7;&#x02009;100,000 pixels are common. Due to these large dimensions, Elastix cannot be used directly to perform image registration on higher resolution levels. A common approach is to use downsampled versions of the WSI, which may already be sufficient for many applications. Moreover, it is not always necessary to use the entire tissue area. In a hierarchical procedure, a coarse global registration at low resolution can be performed first, followed by the registration of smaller patches at a higher resolution, using the gathered co-localized information from the higher hierarchical level. This way, Elastix could already be used on WSIs of consecutive histologic slides to co-localize tissue structures [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>] and to perform 3D reconstruction [<xref ref-type="bibr" rid="CR5">5</xref>]. Furthermore, pathological and radiological image data could be correlated by multi-sensor registration of WSIs on MRI images [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>]. In addition to the primarily intensity-based registration methods, feature-based techniques have become quite popular in pathology. For instance, consecutive sections with different stains have been successfully registered using the patented SIFT feature descriptor [<xref ref-type="bibr" rid="CR8">8</xref>]. Other descriptors, some of them open source, such as ORB, SURF and KAZE, were also able to demonstrate their capabilities [<xref ref-type="bibr" rid="CR8">8</xref>]. However, maximizing accuracy has not been the primary focus in all cases. In clinical routine diagnostic work, there are applications where fast digital processing of histologic image data is critical. For example, Mueller et al. developed a time-efficient method that allows parallel viewing of consecutive tissue sections based on a single global registration [<xref ref-type="bibr" rid="CR9">9</xref>]. Pixel-precise registration is not even necessary here since pathologists will never be pixel-precise when switching between individual WSIs and will have to reorient either way. For precise gigapixel-wise registrations of WSIs, Chandler et al. [<xref ref-type="bibr" rid="CR10">10</xref>] presented a novel pipeline that iteratively aligns and rewrites WSI images in the Open Microscopy Environment (OMERO) file format. Furthermore, Wodzinski et al. [<xref ref-type="bibr" rid="CR11">11</xref>] implemented a pluggable framework operating on larger image dimensions. However, it is important to note that the primary focus is on the comprehensive transformation of WSIs, and the tools are primarily designed for visualization purposes. </p></sec><sec id="Sec5"><title>Contributions</title><p id="Par8">The classical approach to image registration results in one or more sets of transformation parameters that can be used to map one image to another entirely. In pathology, however, it is not always practical to fully transform WSI tissue sections. This is partly because distortions, tissue defects or larger gaps between tissue fragments can occur during the various histological processing steps. Thus, when two consecutive sections are taken from the same tissue block or when the same section is stained and scanned multiple times, the images may not necessarily be congruently superimposable. If the transformation parameters are then optimized regardless, a loss of precision may occur in the areas that actually coincide. Although this loss is minimized in the optimization phase, it cannot be eliminated entirely. Consequently, instead of following the classical registration approach and transforming large regions or even the entire tissue, we follow the co-localization approach for re-stained and re-scanned tissue slides, where the corresponding structures on the images to be registered are mapped to each other individually. Our approach, therefore, aims at maximum accuracy, which is again achieved at the expense of computational time. These correspondences can then be further used depending on the specific problem to be solved.</p></sec></sec><sec id="Sec6"><title>Materials and methods</title><sec id="Sec7"><title>Data</title><p id="Par9">The dataset used to develop the registration algorithm includes over 200 histological specimens from a breast cancer cohort. All slides were initially stained with standard H&#x00026;E and digitized using five different scanners from 3DHISTECH (Budapest, Hungary), Hamamatsu Photonics (Hamamatsu, Japan) and Leica Biosystems (Wetzlar, Germany) at three different research centers. A 3DHistech P1000 scanner was used to acquire WSIs at 80&#x000d7;&#x02009;magnification, while the other four devices were used for scans at 40x. Subsequently, these slides were re-stained with an immunohistochemical (IHC) stain for phospho-histone H3 (PHH3) and re-scanned with the P1000 at 80x.</p><p id="Par10">There are several known challenges when working with WSIs. Guerrero et al. [<xref ref-type="bibr" rid="CR12">12</xref>] have subdivided these into three categories: biological variation, technological variation, and pathological variation. Of these, the technical aspects are particularly important for image registration of histopathological slide sections. These tend to occur during the preparation of histological sections, i.e., artifacts such as tissue folds, tears, or even differences in staining intensities, and are further exacerbated in the image acquisition process. Another class of problems arises in the context of digitization, where, for example, blurring, illumination, and contrast problems may arise [<xref ref-type="bibr" rid="CR13">13</xref>]. Beyond these obvious and identifiable artifacts, there may be other digitization problems that only become relevant when working with images from different WSI scanners. Indeed, there can be significant differences between WSIs generated from the same histological slide but using different scanners. Three of the main differences between the scanners are shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Varying WSI appearance between five scanners, depending on the specific device and manufacturer</p></caption><graphic xlink:href="13755_2025_353_Fig1_HTML" id="MO1"/></fig></p><p id="Par11">Depending on the scanner, the visual appearance of WSIs can vary significantly in intensity and coloration. Since these differences are not equally prominent for all tissue structures present, the possibilities of intensity-based registration are already limited. Given that scanners of different manufacturers produce WSIs with varying base coordinate systems and initial orientations, it is a crucial step to address this initial displacement prior to the actual registration process to avoid unnecessarily complicating the optimization of the transformation. However, a more severe problem arises from the preprocessed, automated tissue segmentation of the scanner devices used to determine the area to be scanned. When scanning IHC sections, brighter areas with only a few to no darker signals (e.g., stained nuclei) may be incorrectly classified as background and therefore not scanned. This problem also occurs in HE slides, particularly in areas with a lot of fatty tissue, which have poor contrast to the background. Furthermore, scratches, dust, or other contamination can cause a larger area of the slide to be scanned. If this area differs between several WSIs of the same section, this must also be intercepted during registration.</p><p id="Par12">Despite the same magnification on four of the five scanners, the resolution of the WSIs varies between scanners, with the largest difference being between the Hamamatsu XR at 0.2272 mpp (micrometer per pixel) and the 3DHISTECH P150 at 0.2744 mpp (see Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>), resulting in structures appearing roughly 20% larger on the P150.<table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>Final WSI resolutions in the dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Scanner</th><th align="left">Leica AT2</th><th align="left">Hamamatsu XR</th><th align="left">3DHISTECH P150</th><th align="left">3DHISTECH P1000 I (40x)</th><th align="left">3DHISTECH P1000 II (80x)</th></tr></thead><tbody><tr><td align="left">Resolution</td><td align="left">0.2514 mpp</td><td align="left">0.2272 mpp</td><td align="left">0.2744 mpp</td><td align="left">0.2454 mpp</td><td align="left">0.1213 mpp</td></tr></tbody></table></table-wrap></p><p id="Par13">This shows that scaling for inter-scanner registration is inevitable, even when the same tissue is scanned at the same magnification level. On the scanned slide sections, 8334 mitoses were annotated in selected tumor regions on H&#x00026;E WSIs (scanned by a 3DHISTECH P1000 with 40&#x000d7;&#x02009;magnification) and 2533 mitosis on the PHH3 WSIs (scanned by a 3DHISTECH P1000 with 80&#x000d7;&#x02009;magnification).</p><p id="Par14">Much more striking morphological differences may occur between different stains. In standard H&#x00026;E staining, for example, the cell nuclei are highlighted by the blueish hematoxylin. In IHC stains, hematoxylin is the usual counterstain to the brownish Diaminobenzidine (DAB) chromogen that labels the specific antigen of interest. Therefore, even when re-staining a slide, the DAB may bind beyond the edge of the nucleus and cause a change in the visual appearance of that same morphological structure. Furthermore, the process of re-staining a slide can lead to further deformations. In this process, antigen unmasking steps, such as microwaving or citric acid treatment, may cause part of the tissue to be washed off the slide. However, more frequently, minor deformations, such as tears or tissue displacement, resulting from the mechanical treatment of the slide are the consequence (see Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>).<fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>Minor tissue deformations occurring when the original H&#x00026;E slide (left) is re-stained for PHH3 (right)</p></caption><graphic xlink:href="13755_2025_353_Fig2_HTML" id="MO2"/></fig></p></sec><sec id="Sec8"><title>Concept</title><p id="Par15">Based on the available dataset and the observations made during the manual and automatic digitization of the slide sections, we searched for a novel registration method to generate valid point or annotation mappings from one coordinate system of a reference image I_F, called fixed image to another coordinate system of a corresponding image I_M, namely moving image. In this context, the base layer of a WSI represents the actual image data scanned with the maximum magnification. Since the image data on this base layer usually exceeds common image data sizes and thus usual memory capacities, we have to resort to a hierarchical tile-based approach, both for accessing the image data and for image registration and transformation. Reading and viewing WSIs is mostly implemented in a pyramid-shaped form containing different levels of resolution of the base image, usually sampled down as powers of two, as is done by most slide scanner vendors [<xref ref-type="bibr" rid="CR14">14</xref>]. Most registration frameworks support multi-resolution strategies that process images from coarse to fine resolution. Still, these cannot be easily applied to images with the dimensions mentioned above, as this would consume considerable memory resources. However, we can take advantage of this strategy by combining the hierarchical approach with a tile-based method on the base layer or a respective level with a similar detailed resolution. This requires a multi-staged registration, starting with a coarse alignment of the whole tissue fragment on a downsampled magnification level (for instance, with a 5&#x000d7;&#x02009;magnification), resulting in an initial transformation that gives a good first estimated alignment of the depicted objects. Crucial for this step, however, is an initial segmentation and detection of the scanned region on which the specimen is located. As mentioned earlier, the actual scanned area of the slide can vary dramatically from scanner to scanner due to internal detection algorithms or configuration profiles. To compensate for these discrepancies, a pre-segmentation is applied before the coarse registration is performed. If the automated segmentation fails and the desired results are far off, the tooling should allow subsequent manual adjustment of the recognized image region. Since the area to be aligned with should be kept as small as possible, the region of interest (ROI) should be tightly bound to the relevant object&#x02019;s shape. The overview images of these regions will then serve as input images for the initial coarse registration, whereby the respective resolution level is dependent on the magnification of the particular slide scans. This means that for a slide scanned at 80&#x000d7;&#x02009;magnification, an initial resolution level of 5, and thus a downsampling factor of 2<sup>5</sup>, would be reasonable. In contrast, for a corresponding slide scanned at 40&#x000d7;&#x02009;magnification, a resolution level of 4, and thus a downsampling factor of 2<sup>4</sup> would be reasonable. Therefore, anatomical structures on the fixed image should roughly match the size of these structures on the moving image. This is achieved by a similarity transformation during registration. The resulting transformation parameters are then used to obtain corresponding image tiles on the base layer of our moving WSI and will be used in the subsequent registration step, which is necessary to further correct and refine the already computed transformations. While for most applications, either the correction or the refinement step is already sufficient to achieve a high degree of accuracy, in certain cases, it may be useful to perform a prior refinement step before computing the final correction parameters.</p><p id="Par16">The whole process is outlined in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> and described in the following sections. The process is subdivided into three major components, starting with preprocessing to harmonize the image data to a common technical and digital presentation. Moreover, the computation (registration) and application (transformation) of the resulting transformation parameters are separated. This allows logical separation and, thus, the application of registration and transformation independently of the underlying dataset. Thus, preprocessed transformation matrices can eventually be applied to an arbitrary point set in the fixed image domain. Since the core process is primarily aimed at pixel-wise registration, non-rigid registration techniques can be avoided in most cases, which only prolong the computation time and may give incorrect and discontinuous transformation results. The entire process is illustrated as pseudocode in Algorithm 1.<fig id="Fig3"><label>Fig.&#x000a0;3</label><caption><p>Overview of the general registration workflow. I_F and I_M mark the fixed and moving image, while T is the transformation parameter set mapping points from I_F to I_M</p></caption><graphic xlink:href="13755_2025_353_Fig3_HTML" id="MO3"/></fig><fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>Pseudocode illustrates the global process of mapping image coordinates from one WSI to another</p></caption><graphic position="anchor" xlink:href="13755_2025_353_Figa_HTML" id="MO4"/></fig></p></sec><sec id="Sec9"><title>Preprocessing</title><p id="Par17">Several requirements that we defined in the previous sections, Data and Concept, must be met in advance to create a common internal representation to process WSI data independently of the origin, the characteristics or other inferences related to the underlying technical entity of the virtual slide or the tissue itself. This first includes a uniform interface to read image data and associated metadata from proprietary WSI files and provides a convenient way to access the algorithm. Since we depend on the support of certain proprietary file formats due to the heterogenous input data (e.g.,.svs for Leica Aperio GT450,.ndpi for Hamamatsu XR and.mrxs for 3DHistech P1000/P250), we initially opted for a closed-source library (Virtual Slide SDK by VMscope) instead of an open-source framework such as OpenSlide.<xref ref-type="fn" rid="Fn1">1</xref> Despite this limitation, the tool is decoupled to such an extent that the library for reading the image data can be exchanged without problems.</p><p id="Par18">Despite having scanned the same tissue, it may differ in its initial orientation and presentation due to scanner-inherent processes, compensation for major differences between fixed and moving image domains is required. Through segmentation, the rough outlines of the objects to be aligned can be assessed to create an initial region of interest for the corresponding image slides. Pre-segmentation of the tissue is performed by a rather naive segmentation approach in which the relevant tissue is separated from the background using Otsu thresholding and morphological operations (e.g., dilation followed by erosion and filling of holes). The relevance of the individual contours, to be considered as a particle of interest, is determined by the mean size and its standard deviation as well as by its distance from the mass center of the contours, ensuring that most irrelevant small tissue fragments and artifacts on the scanned slide region will be excluded. Due to tissue alterations during the restaining process or generally distinct expressed tissue structures, the segmentation algorithm is not entirely robust and reliable, demanding manual corrections of the bounding boxes surrounding the relevant tissue in some cases. Additionally, significant orientation discrepancies, such as 90-degree rotations or vertical and horizontal flips of the WSI, as well as major magnification differences, need to be configured as application runtime parameters. All of these operations necessitate pre-transformation of the coordinates of the input annotations on the fixed image, accordingly.</p></sec><sec id="Sec10"><title>Registration</title><p id="Par19">In the preliminary steps, the WSIs and related coordinates were processed in a way that allowed the registration of the actual tissue regions without having to deal with the particularities of the different scanners and image formats. The relevant image regions are defined as coordinates of a rectangle <italic>Rec[roi_fixed]</italic> and <italic>Rec[roi_moving]</italic> in the corresponding WSI coordinate system. The actual image data on a specific resolution level is then obtained by sampling down the rectangle coordinates and passing it to the data access interface.</p><p id="Par20">The primary step is a rough and fast registration of the overview images at a reasonably low-resolution level that produces a good initial approximation of the transformation. Therefore, a simple rigid registration is sufficient at this step as the results will be refined in further iterations. The registration process itself relies on a multi-resolution strategy as well. The coarse resolution level is configurable and should be chosen depending on the size of the image data and the available memory. As there might still be a slight magnification offset due to different size interpretations and minor mechanical imprecisions of scanning devices, we perform the coarse registration based on a similarity transform model, compounded by a rigid body transformation and an isotropic scaling where the moving image is initialized at the geometrical center of the fixed image. The basic transformation is then defined by an equation that considers a scalar scaling vector, a 2D rotation matrix and a translation vector. By including the center of rotation in this equation, this results in a parameterization vector of size four [<xref ref-type="bibr" rid="CR15">15</xref>]. To optimize the transformation of the moving image, an adaptive stochastic gradient descent approach (ASGD) is used, a robust and fast optimization method [<xref ref-type="bibr" rid="CR16">16</xref>]. A variant of Mutual Information (MI) by Mattes is applied for similarity measure, utilizing the Parzen Windows technique to estimate continuous histogram densities with a random sampling strategy [<xref ref-type="bibr" rid="CR17">17</xref>]. MI is a useful metric when dealing with images from different modalities, in our case, different stains, as it measures similarity based on the occurrences of intensity probabilities and not on actual intensity values. To prevent the mapping to non-pixel coordinates, a BSpline-interpolation technique is used, ensuring a high accuracy grade of pixel interpolation. The same methods are used for the subsequent refinement step, only deviating in the specific parametrization. The default parameters can be overwritten anytime by defining an external parameter file and stating it in the application&#x02019;s configuration.</p><p id="Par21">Afterward, the calculated parameters need to be extrapolated to fit the dimensions of the base layer, and the previous pre-modifications (mapping to the ROI, large gap rotations or flips) have to be included in this transformation schema. The parameter map will serve as a base transformation for the additional and subsequent registration of detailed image structures or partial regions of the WSI. In detail, the preprocessed transformation parameters need to be applied to the upscaled and transformed coordinates of the moving image on the base layer, where particularly the initial rotation and translation differences are compensated. First, the region&#x02019;s coordinates are translated in x and y directions to equalize the ROI&#x02019;s absolute position on the WSI and are then rotated by the initially calculated rotation angle. Figure&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> sketches the idea of this procedure. On this occasion, the geometrical centers of our initial ROIs serve as the center of rotation.<fig id="Fig4"><label>Fig.&#x000a0;4</label><caption><p>Transformation of a region of interest and its bounding box (purple rectangle) concerning the absolute coordinate system of the corresponding Whole Slide Images</p></caption><graphic xlink:href="13755_2025_353_Fig4_HTML" id="MO5"/></fig></p><p id="Par22">This process results in two roughly equal regions on the reference and corresponding WSI that can be used for the subsequent refinement registration steps. However, the challenge lies in the fact that only rectangular, horizontally and vertically centered image tiles can be obtained from the data formats and processed using respective libraries. That means that the ROI&#x02019;s rotation must be considered and thus needs to be wrapped in a bounding box to retrieve the extended image region from the slide image library. As this image section is subsequently used for registration, the image tile&#x02019;s rotation has to be compensated and then cropped again to the size of the preceding ROIs&#x02019; dimension while using the geometric center of the image as the ROIs center of mass. In the following, we will present two strategies to enhance the coarse initial registration results. The drawbacks and advantages of these strategies will then be evaluated and discussed in the results section.</p></sec><sec id="Sec11"><title>Strategy I: clustered coordinates refinement registration</title><p id="Par23">The first refinement approach focuses on the registration of large image sections to quickly transfer a potentially large number of spatially clustered annotations into a target coordinate system. Therefore, the fixed image is divided into equally sized image regions and will thus open up a grid depending on a) the number of sections or b) the fixed size of these grid tiles. The grid coordinates are then mapped, based on the previously calculated coarse transformation parameters, to the moving image coordinate system, resulting in a rough mapping between fixed (T_I) and moving tiles (T_M). Once again, the region must be extracted with its global dimensions from the moving WSI, taking into account scaling and rotations from previous transformations. However, this also means that the rotation parameter of the transformation has to be compensated and the image region cropped accordingly. The resulting image section is then used again as input to the subsequent refinement registration, serving as the moving image. The fixed image is the respective region of our previously rigidly created grid tile. Since these two image inputs are already well positioned due to the previous coarse alignment, the registration parameters can be strongly optimized, especially with regard to the number of optimization steps, sampling points or resolution levels, which greatly reduces the overall computation time. Nevertheless, this has to be decided on an individual basis since the result is strongly dependent on the absolute size of the image regions and the content included. With very large image sections, there may be discrepancies between the histological structures of the tissue, becoming even more pronounced in edge areas of the image regions, which is why the use of a non-rigid registration may be useful here. These increasing inaccuracies, amplifying from the image center to the corner regions, occur because the geometrical center of the image is used as the initial origin of the registration. For instance, using the upper left or the center of mass as the origin would result in similar effects at different parts of the transformed image.</p><p id="Par24">The method allows for fast computation of a transformation rule to map a large number of coordinates from one image coordinate system into another. As long as these coordinates are mostly bound to a particular fixed region, the number of processable image tiles will be relatively low. Conversely, when annotations have been distributed homogeneously on the slide, the processing time might easily increase exponentially. In both cases, it is reasonable to determine certain image regions (e.g., region of interest) beforehand and pass them as input parameters to the registration algorithm.</p></sec><sec id="Sec12"><title>Strategy II: single coordinate refinement registration</title><p id="Par25">As previously described, the transformation of homogeneously distributed annotations on the tissue can cause a considerable consumption of time and resources when using Strategy I. Therefore, we introduce a second approach dedicated to the accuracy of single annotations rather than large bulk transformations in a reasonable time. Thus, the initially coarse-transformed annotation coordinates are iterated, retrieving tiny image sections from the base layer (or, in the case of different magnification levels, the respective maximum resolution level) of both the fixed and moving WSI and performing a fast rigid registration. These small image patches are ideally squares and have a fixed width and height with the annotation coordinate as the center of the patch. We propose an edge length of about 128 to 256 pixels. These patch sizes were sufficient for our experiments in terms of accuracy and computation speed. As stated previously, a user might want to align two slides scanned at different magnification (e.g., 40&#x000d7;&#x02009;vs. 20x). In this case, we use the base layer of the slide with the lower resolution as the reference base layer and select the respective layer with an equivalent magnification level for registration. However, before retrieving the plain image data, the initial orientation of the WSIs must be taken into account here, as otherwise, an image section will be obtained that is far off the actual coordinate locations. In addition, the inverse rotation of the previously calculated coarse transformation parameters must be applied to the image section to include the rough registration in the further registration step since the WSI access utilities do not allow the retrieval of rotated image regions. Subsequently, the registration correction step can be performed, where only the displacement, rotation and similarity between fixed and moving images are computed (affine registration). The resulting transformation parameters are then added to the overall parameter list, serving as input for the transformation step.</p></sec><sec id="Sec13"><title>Transformation</title><p id="Par26">The transformation of the coordinates is decoupled from the actual registration process, whereby the calculation of the transformation parameters can occur independently of applying the computed transformation to concrete coordinates. This allows to compute a comprehensive point-precise mapping without knowing the coordinates to be transformed in advance. Thus, differentially classified annotations (e.g., tumor or non-tumor) can be processed independently using the same transformation parameters without increasing the execution time for additional annotation classes. However, this scenario can only be realized with the first registration strategy.</p><p id="Par27">The transformation parameters are successively applied to the individual coordinates in the same order in which they were created. The interpolation of the resulting continuous coordinates is performed after all displacement alterations are applied. To map the continuous points to discrete coordinates in the target coordinate system, we use a cubic interpolation with BSpline polynomials and a resample order of three [<xref ref-type="bibr" rid="CR15">15</xref>].</p></sec><sec id="Sec14"><title>Limitations</title><p id="Par28">A major limitation of this workflow is the high manual effort required when dealing with very heterogeneous datasets, which is inherently the case in digital microscopy. This is not only due to the manual processing route of slide preparation but also to the heterogeneity of the slide scanner landscape, scan profiles, and staining or tissue-related features. An important influencing factor is the geometric orientation of the tissue, both on the physical slide and within the digital data structure. Right angle rotations or mirrored image data are challenging to detect with conventional image processing algorithms and are already a hard-to-solve problem in their own domain. Further complications arise from the different magnification levels of the slides (e.g., 40&#x000d7;&#x02009;vs. 80x) or even visible discrepancies between slides with theoretically equal magnification levels, which is mainly due to the barely standardized nature of digital pathology. In addition to resolution-related and spatial influences, artifacts such as foreign objects on the slide, destroyed tissue such as tears, washed-out tissue or overlaps and digitization artifacts are further sources of error when automating the registration process. </p></sec></sec><sec id="Sec15"><title>Results</title><p id="Par29">The evaluation of registration algorithms is commonly performed using metrics to measure distances between fiducial markers and their average distribution around a mean or median error in variance, such as the target registration error (TRE) [<xref ref-type="bibr" rid="CR18">18</xref>]. For the approach presented, such a procedure proves less meaningful in two different ways. First, the TRE (or similar metrics based on the correspondence of point pairs) refers to the totality of points transformed by a single parameter set. In patch-based approaches, this is similar in that multiple sets of points are each transformed by a single parameter set. Although the presented approach is also based on a patch-based registration, the final correction step gives each individual point coordinate a unique transformation rule. Second, our registration achieves such high accuracy that the corresponding points would have to be annotated with sub-pixel precision. Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> shows why this is not even possible with the existing data.<fig id="Fig5"><label>Fig.&#x000a0;5</label><caption><p><bold>a</bold> H&#x00026;E to H&#x00026;E registration; <bold>b</bold> H&#x00026;E to PHH3 registration; 1) Mitosis per scanner, comparing one half of each image; 2) Enlarged center of the combined images; These images highlight the challenge of providing pixel-precise annotations and segmentations. At lower resolution, the border between mitoses and stroma appears relatively distinct. At pixel level, however, it becomes impossible to perfectly distinguish between mitoses and stroma pixels.</p></caption><graphic xlink:href="13755_2025_353_Fig5_HTML" id="MO6"/></fig></p><p id="Par30">It is clearly visible that the mitosis has a slightly different morphological shape depending on the scanner. This can be attributed to both the installed camera sensors/software (e.g., sampling, interpolation or color corrections) and the focal plane determined as sharped-edged by the scanning software. If two scanners capture the same mitosis at different points along the Z-axis, the mitosis will inevitably appear different, and a pixel-precise correspondence can no longer be achieved.</p><p id="Par31">Other metrics typically used are Jaccard Index (JI), Dice Coefficient (DC) and Hausdorff Distance (HD). JI and DC are based on the overlap of regions in the registered images, while HD represents the maximum distance between corresponding coordinates in two pointsets. All these metrics require accurate segmentation. However, as mentioned before, achieving such accurate, pixel-precise segmentation at the nuclei-scale is not feasible. To evaluate our algorithm performance, we registered all PHH3-based annotations (created on 100 slides and digitized with the 3D Histech P1000 II) to the corresponding H&#x00026;E WSIs from each scanner and assessed the structural similarity index metric (SSIM) between the H&#x00026;E regions. To minimize slide-based biases, we used the same number of annotations for each slide, based on the slides with the lowest number of annotations (n&#x02009;=&#x02009;1). SSIM, which ranges from &#x02212;&#x000a0;1 to 1, quantifies the similarity between two images. Values below 0 indicate dissimilarity, while values between 0 and 1 indicate similarity. For SSIM assessment, we created patches centered on the registered coordinates, rescaled them to the fit the patch dimensions of the scanner with the lowest resolution (3D Histech P150), and cropped the first and last rows and columns, accounting for uneven tile dimensions after resizing due to slight differences in resolution along the x- and y-axis in the 3D Histech P1000. The overall performance is shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>.<fig id="Fig6"><label>Fig.&#x000a0;6</label><caption><p>Overall SSIM between the five scanners assessed by colocalizing PHH3-based annotations to the five H&#x00026;E WSI sets</p></caption><graphic xlink:href="13755_2025_353_Fig6_HTML" id="MO7"/></fig></p><p id="Par32">An in-depth analysis of the achieved SSIM scores was conducted to identify outliers and investigate their causes. For each annotation, we calculated the lowest SSIM for each scanner by comparing it with all the other scanners (details are provided in Appendix 1). The lowest observed SSIM was 0.31, which is in theory still interpreted as similar. However, 20% of the annotations fell below an SSIM of 0.5 and were visualized for further inspection (see Appendix 2). Using QuPath and manual measurement, the poorest results revealed offsets of approximately 33&#x000a0;&#x003bc;m (slide ID 32, SSIM 0.31), 20&#x000a0;&#x003bc;m (slide ID 37, SSIM 0.47), 9&#x000a0;&#x003bc;m (slide ID 1, SSIM 0.44) and 8&#x000a0;&#x003bc;m (slide ID 55, SSIM 0.42). In contrast, most other slides showed comparably lower or even negligible offsets. For cases with no offset, variations in tissue texture appearance or blurry image tiles were observed as contributing factors. The memory requirement and computation time are influenced by both the number of coordinates to be transformed and the distribution of these coordinates over the tissue. In scenarios with densely populated annotations, the previously introduced Strategy I aims to reduce execution time using fewer but, therefore, larger image tiles during the refinement step. Although this may introduce minimal distortion near the tile edges, it is a meaningful trade-off. Sparsely distributed annotations, with large distances between these annotations, on the contrary, indicate the use of Strategy II, which is tailored to using smaller tiles during the refinement step to circumvent unnecessary calculations. To illustrate the effectiveness of these strategies, we applied them to two WSIs of the same H&#x00026;E-stained slide containing invasive breast cancer with sizes of approximately 28,000&#x02009;&#x000d7;&#x02009;46,000 pixels. For Strategy I, 100 annotations were placed within a compact area of 3500&#x02009;&#x000d7;&#x02009;3500 pixels, while for Strategy II, 100 annotations were placed across the entire tissue, covering an area of 12,000&#x02009;&#x000d7;&#x02009;20,000 pixels. The code was executed via Powershell on a system running Windows 10, with an Intel i7 CPU and 64&#x000a0;GB RAM. These experimental setups illustrate the nuanced considerations required for optimizing memory usage and calculation efficiency in diverse annotation scenarios. The resulting durations for the calculation using different parameters can be examined in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table&#x000a0;2</label><caption><p>Overview of computation time for the refinement step performing registration of 10 densely packed (registration strategy I) or strongly dispersed (registration strategy II) annotations</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2">Tile Size</th><th align="left">1024&#x02009;&#x000d7;&#x02009;1024</th><th align="left">2048&#x02009;&#x000d7;&#x02009;2048</th><th align="left">4096&#x02009;&#x000d7;&#x02009;4096</th></tr></thead><tbody><tr><td align="left" rowspan="3">Strategy I: dense annotations</td><td align="left">Number of Tiles</td><td align="left">19</td><td align="left">8</td><td align="left">4</td></tr><tr><td align="left">Number of Pixels</td><td align="left">19.92 million</td><td align="left">33.55 million</td><td align="left">67.11 million</td></tr><tr><td align="left">Duration</td><td align="left">55&#x000a0;min</td><td align="left">21&#x000a0;min</td><td align="left">14&#x000a0;min</td></tr><tr><td align="left" rowspan="3">Strategy II: sparse annotations</td><td align="left">Number of Tiles</td><td align="left">10</td><td align="left">10</td><td align="left">10</td></tr><tr><td align="left">Number of Pixels</td><td align="left">10.46 million</td><td align="left">41.94 million</td><td align="left">167.77 million</td></tr><tr><td align="left">Duration</td><td align="left">25&#x000a0;min</td><td align="left">37&#x000a0;min</td><td align="left">43&#x000a0;min</td></tr></tbody></table></table-wrap></p><p id="Par33">The computation time and memory requirement for the correction step depend solely on the number of annotations and chosen tile size. Consequently, the distribution of annotations within the tissue does not impact this particular step. While larger tile sizes necessitate more computation time per annotation, they facilitate higher accuracy by incorporating more mutual information. However, we would not recommend using tiles larger than 512&#x02009;&#x000d7;&#x02009;512 pixels to keep a balance between computational effort and actual added value. Table <xref rid="Tab3" ref-type="table">3</xref> provides the computation time per tile size during the correction step.<table-wrap id="Tab3"><label>Table&#x000a0;3</label><caption><p>Computation time for the correction step for differently sized image tiles</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" rowspan="2">Correction</td><td align="left">Tile Size</td><td align="left">128&#x02009;&#x000d7;&#x02009;128</td><td align="left">256&#x02009;&#x000d7;&#x02009;256</td><td align="left">512&#x02009;&#x000d7;&#x02009;512</td></tr><tr><td align="left">Duration per Annotation</td><td align="left">1.8&#x000a0;s</td><td align="left">5&#x000a0;s</td><td align="left">9.5&#x000a0;s</td></tr></tbody></table></table-wrap></p><p id="Par34">It is apparent that the tile size for the refinement step should be selected in accordance with the distribution of the annotations. With Strategy I, increasing the tile size leads to a significant increase in the total number of registered pixels, but the reduced overhead for each individual tile ultimately reduces the computation time by a factor of almost 4. In the case of Strategy II, a contrary effect can be observed. The larger the tile size selected and, therefore, the more pixels registered, the longer the total computation time. This is due to the fact that the annotations are so far apart that two individual annotations do not lie within the same image tile. An increase in the tile size therefore only results in more pixels being registered and thus increases the total computing time without adding additional value. The data shows that a tile size of 2048&#x02009;&#x000d7;&#x02009;2048 could not achieve the fastest computing time with either of the two strategies. However, this does not mean that there is no distribution of annotations for which this might be the case.</p></sec><sec id="Sec16"><title>Discussion</title><p id="Par35">Depending on the staining of the tissue and the focal plane of the respective scanner, the acquired objects to be registered may show morphologically relevant differences [<xref ref-type="bibr" rid="CR19">19</xref>]. The presented approach is robust to these deviations and can still achieve sub-micrometer level accuracy when aligning WSIs from different scanners or in different staining. However, this high accuracy is paid for with heavy memory allocation and protracted computation time since registration is performed on two hierarchical levels. First, a global registration is performed to get a rough alignment of the relevant image parts. This step is subsequently followed by a tile-based registration on the base layer of the WSI. Depending on the use case (e.g., high vs. low-density annotation distribution), this is achieved either by a coarse, rigid grid on the base layer or by very small individual image tiles at the respective annotation position on the WSI (see Strategy I vs. II). These two strategies can be regarded as two extremes when approaching the same registration problem. For larger datasets with significant computation time, we recommend investing some time in understanding how to configure the parameters concerning the specific dataset.</p><p id="Par36">Before this, however, some pre-processing must be performed to compute a rough pre-registration, which is indispensable for using Elastix [<xref ref-type="bibr" rid="CR1">1</xref>]. For this, aspects such as tissue segmentation or the rotation or mirroring of the respective scanner results must be taken into account. Pre-segmentation to leverage the accuracy of a coarse registration has proven challenging. On histological slides, smaller ablated tissue particles may be present in addition to the main tissue. Furthermore, parts of the tissue may be missing, or various artifacts may cause additional objects to be visible on the WSI of a section. Depending on the scanner, the WSIs may have varying content, which can be problematic for pre-registration because the segmented content is not congruent. In addition, if several slices have been combined on one physical slide, a manual visual inspection of the preregistration becomes necessary. This opens opportunities for further improvements, optimizing the workflow and minimizing manual effort.</p><p id="Par37">It is possible to perform a complete registration of all the image tiles generated in the second step. This has the advantage that a global registration matrix can be pre-computed, and the transformation of the points can be done at a later time. If it is expected that multiple sets of points are to be registered between these WSIs, this can save time since the first two compute-intensive substeps only need to be performed once. However, since the last substep, where the respective points are registered again in their local neighborhood, is also quite time-consuming, this only leads to significant time improvement if a) different sets of points are registered and b) these are distributed over a larger area of the WSIs.</p><p id="Par38">During H&#x00026;E and subsequent IHC staining, we observed various forms of damage to the tissue. Sometimes, the tissue has completely detached from the slide, making the sections unusable afterward. In most cases, however, minor tears and deformations occurred. These can no longer be compensated for with affine transformations, so it seems reasonable to investigate further transformations with B-splines. Another source for potential variability within the image data can be found in the scanners. Several components in photoimaging devices, such as sensors or light sources, may degrade, reducing the color quality of the acquired pictures. However, recent studies showed that for digital pathology, these variances are still within an acceptable range [<xref ref-type="bibr" rid="CR20">20</xref>].</p><p id="Par39">While our high precision may make it difficult to give exact values, it can be shown quite well that it is significantly higher than the approaches previously described in the literature. However, such comparison might be considered inequitable, as these approaches are not designed to operate on the same re-stained tissue slides but rather on consecutive slides. The approaches presented in [<xref ref-type="bibr" rid="CR3">3</xref>] and [<xref ref-type="bibr" rid="CR4">4</xref>] achieve a deviation of 3.4&#x000a0;&#x003bc;m and 5&#x000a0;&#x003bc;m, respectively, in the best case. In the approach presented in [<xref ref-type="bibr" rid="CR5">5</xref>], the accuracy is given as a percentage of the image diagonal, which, in the case of our sample WSI considered in the results section, would be 27&#x000a0;&#x003bc;m. However, if their algorithm performs equally well on a tile size of 128&#x02009;&#x000d7;&#x02009;128 pixels, they would achieve a deviation of 1&#x000a0;&#x003bc;m. Considering the smallest deviation of 3.4&#x000a0;&#x003bc;m for a WSI, this would correspond to 13.6 pixels for a WSI with a resolution of 0.25 mpp. A minority of our results performed worse than these numbers, the majority outperformed them. SSIM is typically used in radiology to evaluate registration improvement or to compare algorithm performance with other approaches [<xref ref-type="bibr" rid="CR21">21</xref>&#x02013;<xref ref-type="bibr" rid="CR23">23</xref>]. In pathology, however, its use is rather limited [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], with other metrics such as TRE, Dice Coefficient or Normalized Gradient Fields being more commonly employed. From our perspective, providing sufficiently accurate reference data for reliable algorithm performance assessment is not feasible. Instead, we outlined our approach to assessing the SSIM in a mutli-scanner, multi-stain registration problem and encourage others to adopt and incorporate SSIM in performance evaluations. Comparing the computation times between these algorithms and our solution is highly dependent on the slides and annotation distribution. The approaches outlined in [<xref ref-type="bibr" rid="CR3">3</xref>] and [<xref ref-type="bibr" rid="CR4">4</xref>] share similarities with our solution. In [<xref ref-type="bibr" rid="CR3">3</xref>], various parameter sets are systematically evaluated to select the most efficient configuration, an aspect that could potentially be integrated into our setup. In [<xref ref-type="bibr" rid="CR4">4</xref>], a two-level hierarchical approach using Elastix is employed, with non-linear transformations applied both for coarse registration and for patch-wise registration at higher resolution. If the same configuration were used in our approach, the computations would align with those reported in their paper. In [<xref ref-type="bibr" rid="CR5">5</xref>], a significantly faster registration is reported. However, this algorithm, like the others, is designed to work on different tissue slides rather than optimized to work on the same but re-stained slides.</p><p id="Par40">The novelty of our approach does not lie in the hierarchical use of Elastix but rather in its application to our specific use case. Our test data included two different stains, WSIs digitized with five different scanners per slide, located at three different university hospitals, with release dates spanning 2010 to 2018. All slides underwent quality control to exclude those with out-of-focus tumor regions. Further investigations into noise robustness regarding lab-specific H&#x00026;E staining, other IHC markers with significantly differing DAB-to-Hematoxylin ratios, additional scanning devices and the impact of out-of-focus regions would provide deeper insights into our approach&#x02019;s performance.</p></sec><sec id="Sec17"><title>Conclusion</title><p id="Par41">The registration method presented here can achieve submicrometer accuracy, even in the presence of tissue deformations or staining- and scanner-induced morphological variability. This is achieved by a three-stage procedure that uses a global transformation, a subsequent registration of the individual WSI tiles and finally, another registration of the respective points based on their local neighborhood. This method can transform arbitrary point clouds between WSIs but is not intended to transform entire WSIs. However, the transformed points can be used to establish a correspondence between the WSIs, which then can be used as a basis for an image transformation. The high accuracy of this method is mainly achieved by immense computational power and duration, which can amount to several hours per WSI pair. Thus, the method is not necessarily the first choice when viewing multiple registered WSIs or when a fast operation is the main concern, thereby narrowing its applicability. However, when generating a ground truth for training AI algorithms, for example, neither a complete image transformation nor a fast execution is relevant, which is why this method is highly relevant in this context. </p></sec></body><back><app-group><app id="App1"><sec id="Sec18"><title>Appendix</title><sec id="Sec19"><title>Appendix 1</title><p id="Par44">Lowest Structual Similarity Index Metric (SSIM) from one scanner to the other scanners for each regarded annotation. Color Map is set to the range from 0 to 1 (instead of -1 to 1) for better interpretability.<graphic position="anchor" xlink:href="13755_2025_353_Figb_HTML" id="MO8"/></p></sec><sec id="Sec20"><title>Appendix 2</title><p id="Par45">Annotations with a SSIM of less than 0.50.<graphic position="anchor" xlink:href="13755_2025_353_Figc_HTML" id="MO9"/></p><p id="Par46">
<graphic position="anchor" xlink:href="13755_2025_353_Figd_HTML" id="MO10"/></p></sec></sec></app></app-group><fn-group><fn id="Fn1"><label>1</label><p id="Par47"><underline>github.com/openslide.</underline></p></fn><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author contributions</title><p>All authors contributed to the development and implementation. Conceptualization, implementation and validation were performed by Tom Bisson, Michael Franz and Norman Zerbe. Data collection and curation were performed by Tom Bisson and Rasmus Kiehl. Funding acquisition and supervision were performed by Peter Hufnagl, Norman Zerbe and Peter Boor. The first draft of the manuscript was written by Tom Bisson and Michael Franz, and all authors commented on previous versions of the manuscript. All authors read and approved the final manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open Access funding enabled and organized by Projekt DEAL. The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was funded by the German Federal Ministry for Economic Affairs and Climate Action (BMWK) [Project &#x0201c;EMPAIA&#x0201d;; FKZ 01MK20002A] and by the German Federal Ministry of Education and Research (BMBF) [Project &#x0201c;MAI&#x0201d;; FKZ 01IS18082D].</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>All data used in this study were generated under an inpatient treatment contract and are governed by the Berlin State Hospital Act (Berliner Landeskrankenhausgesetz). As such, the data are subject to strict confidentiality and data protection regulations and cannot be shared publicly. Access to the data requires prior approval from the Charit&#x000e9; &#x02013; Universit&#x000e4;tsmedizin Berlin Ethics Committee.</p></notes><notes><title>Declarations</title><notes id="FPar1" notes-type="COI-statement"><title>Conflict of interest</title><p id="Par42">Michael Franz is an employee of the EMPAIA International GmbH. The work presented in this manuscript has been carried before his employment and falls outside the company&#x02019;s commercial focus. The other authors have no competing interests to declare that are relevant to the content of this article.</p></notes><notes id="FPar2"><title>Ethical approval</title><p id="Par43">The study was approved by the ethics committee at the Charit&#x000e9; &#x02013; Universit&#x000e4;tsmedizin Berlin (approval no. EA1/122/20).</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>S</given-names></name><name><surname>Staring</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Viergever</surname><given-names>MA</given-names></name><name><surname>Pluim</surname><given-names>JP</given-names></name></person-group><article-title>Elastix: a toolbox for intensity-based medical image registration</article-title><source>IEEE Trans Med Imaging</source><year>2010</year><volume>29</volume><issue>1</issue><fpage>196</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1109/TMI.2009.2035616</pub-id><pub-id pub-id-type="pmid">19923044</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Klein S, Staring M, Murphy K, Viergever MA, Pluim JP. Elastix: a toolbox for intensity-based medical image registration. IEEE Trans Med Imaging. 2010;29(1):196&#x02013;205. 10.1109/TMI.2009.2035616.<pub-id pub-id-type="pmid">19923044</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Avants</surname><given-names>BB</given-names></name><name><surname>Tustison</surname><given-names>NJ</given-names></name><name><surname>Stauffer</surname><given-names>M</given-names></name><name><surname>Song</surname><given-names>G</given-names></name><name><surname>Wu</surname><given-names>B</given-names></name><name><surname>Gee</surname><given-names>JC</given-names></name></person-group><article-title>The Insight ToolKit image registration framework</article-title><source>Front Neuroinform</source><year>2014</year><volume>8</volume><fpage>44</fpage><pub-id pub-id-type="doi">10.3389/fninf.2014.00044</pub-id><pub-id pub-id-type="pmid">24817849</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Avants BB, Tustison NJ, Stauffer M, Song G, Wu B, Gee JC. The Insight ToolKit image registration framework. Front Neuroinform. 2014;8:44. 10.3389/fninf.2014.00044.<pub-id pub-id-type="pmid">24817849</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Moles Lopez</surname><given-names>X</given-names></name><name><surname>Barbot</surname><given-names>P</given-names></name><name><surname>Van Eycke</surname><given-names>YR</given-names></name><name><surname>Verset</surname><given-names>L</given-names></name><name><surname>Tr&#x000e9;pant</surname><given-names>AL</given-names></name><name><surname>Larbanoix</surname><given-names>L</given-names></name><name><surname>Salmon</surname><given-names>I</given-names></name><name><surname>Decaestecker</surname><given-names>C</given-names></name></person-group><article-title>Registration of whole immunohistochemical slide images: an efficient way to characterize biomarker colocalization</article-title><source>J Am Med Inform Assoc</source><year>2015</year><volume>22</volume><issue>1</issue><fpage>86</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1136/amiajnl-2014-002710</pub-id><pub-id pub-id-type="pmid">25125687</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Moles Lopez X, Barbot P, Van Eycke YR, Verset L, Tr&#x000e9;pant AL, Larbanoix L, Salmon I, Decaestecker C. Registration of whole immunohistochemical slide images: an efficient way to characterize biomarker colocalization. J Am Med Inform Assoc. 2015;22(1):86&#x02013;99. 10.1136/amiajnl-2014-002710.<pub-id pub-id-type="pmid">25125687</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Lotz</surname><given-names>J</given-names></name><name><surname>Olesch</surname><given-names>J</given-names></name><name><surname>Muller</surname><given-names>B</given-names></name><name><surname>Polzin</surname><given-names>T</given-names></name><name><surname>Galuschka</surname><given-names>P</given-names></name><name><surname>Lotz</surname><given-names>JM</given-names></name><name><surname>Heldmann</surname><given-names>S</given-names></name><name><surname>Laue</surname><given-names>H</given-names></name><name><surname>Gonzalez-Vallinas</surname><given-names>M</given-names></name><name><surname>Warth</surname><given-names>A</given-names></name><name><surname>Lahrmann</surname><given-names>B</given-names></name><name><surname>Grabe</surname><given-names>N</given-names></name><name><surname>Sedlaczek</surname><given-names>O</given-names></name><name><surname>Breuhahn</surname><given-names>K</given-names></name><name><surname>Modersitzki</surname><given-names>J</given-names></name></person-group><article-title>Patch-based nonlinear image registration for Gigapixel whole slide images</article-title><source>IEEE Trans Biomed Eng</source><year>2016</year><volume>63</volume><issue>9</issue><fpage>1812</fpage><lpage>1819</lpage><pub-id pub-id-type="doi">10.1109/TBME.2015.2503122</pub-id><pub-id pub-id-type="pmid">26625400</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Lotz J, Olesch J, Muller B, Polzin T, Galuschka P, Lotz JM, Heldmann S, Laue H, Gonzalez-Vallinas M, Warth A, Lahrmann B, Grabe N, Sedlaczek O, Breuhahn K, Modersitzki J. Patch-based nonlinear image registration for Gigapixel whole slide images. IEEE Trans Biomed Eng. 2016;63(9):1812&#x02013;9. 10.1109/TBME.2015.2503122.<pub-id pub-id-type="pmid">26625400</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Venet</surname><given-names>L</given-names></name><name><surname>Pati</surname><given-names>S</given-names></name><name><surname>Feldman</surname><given-names>MD</given-names></name><name><surname>Nasrallah</surname><given-names>MP</given-names></name><name><surname>Yushkevich</surname><given-names>P</given-names></name><name><surname>Bakas</surname><given-names>S</given-names></name></person-group><article-title>Accurate and robust alignment of differently stained histologic images based on greedy diffeomorphic registration</article-title><source>Appl Sci (Basel)</source><year>2021</year><volume>11</volume><issue>4</issue><fpage>1892</fpage><pub-id pub-id-type="doi">10.3390/app11041892</pub-id><pub-id pub-id-type="pmid">34290888</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Venet L, Pati S, Feldman MD, Nasrallah MP, Yushkevich P, Bakas S. Accurate and robust alignment of differently stained histologic images based on greedy diffeomorphic registration. Appl Sci (Basel). 2021;11(4):1892. 10.3390/app11041892.<pub-id pub-id-type="pmid">34290888</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Samavati</surname><given-names>N</given-names></name><name><surname>McGrath</surname><given-names>DM</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>van der Kwast</surname><given-names>T</given-names></name><name><surname>Jewett</surname><given-names>M</given-names></name><name><surname>M&#x000e3; Nard</surname><given-names>C</given-names></name><name><surname>Pluim</surname><given-names>J</given-names></name><name><surname>Brock</surname><given-names>KK</given-names></name></person-group><article-title>SU-E-J-95: towards optimum boundary conditions for biomechanical model based deformable registration using intensity based image matching for prostate correlative pathology</article-title><source>Med Phys</source><year>2012</year><volume>39</volume><fpage>3674</fpage><pub-id pub-id-type="doi">10.1118/1.4734931</pub-id></element-citation><mixed-citation id="mc-CR6" publication-type="journal">Samavati N, McGrath DM, Lee J, van der Kwast T, Jewett M, M&#x000e3; Nard C, Pluim J, Brock KK. SU-E-J-95: towards optimum boundary conditions for biomechanical model based deformable registration using intensity based image matching for prostate correlative pathology. Med Phys. 2012;39:3674. 10.1118/1.4734931.</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Rusu</surname><given-names>M</given-names></name><name><surname>Golden</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Gow</surname><given-names>A</given-names></name><name><surname>Madabhushi</surname><given-names>A</given-names></name></person-group><article-title>Framework for 3D histologic reconstruction and fusion with in vivo MRI: preliminary results of characterizing pulmonary inflammation in a mouse model</article-title><source>Med Phys</source><year>2015</year><volume>42</volume><issue>8</issue><fpage>4822</fpage><lpage>4832</lpage><pub-id pub-id-type="doi">10.1118/1.4923161</pub-id><pub-id pub-id-type="pmid">26233209</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Rusu M, Golden T, Wang H, Gow A, Madabhushi A. Framework for 3D histologic reconstruction and fusion with in vivo MRI: preliminary results of characterizing pulmonary inflammation in a mouse model. Med Phys. 2015;42(8):4822&#x02013;32. 10.1118/1.4923161.<pub-id pub-id-type="pmid">26233209</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Hoque</surname><given-names>MZ</given-names></name><name><surname>Keskinarkaus</surname><given-names>A</given-names></name><name><surname>Nyberg</surname><given-names>P</given-names></name><name><surname>Mattila</surname><given-names>T</given-names></name><name><surname>Sepp&#x000e4;nen</surname><given-names>T</given-names></name></person-group><article-title>Whole slide image registration via multi-stained feature matching</article-title><source>Comput Biol Med</source><year>2022</year><volume>144</volume><fpage>105301</fpage><pub-id pub-id-type="doi">10.1016/j.compbiomed.2022.105301</pub-id><pub-id pub-id-type="pmid">35255294</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Hoque MZ, Keskinarkaus A, Nyberg P, Mattila T, Sepp&#x000e4;nen T. Whole slide image registration via multi-stained feature matching. Comput Biol Med. 2022;144:105301. 10.1016/j.compbiomed.2022.105301.<pub-id pub-id-type="pmid">35255294</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Mueller</surname><given-names>D</given-names></name><name><surname>Vossen</surname><given-names>D</given-names></name><name><surname>Hulsken</surname><given-names>B</given-names></name></person-group><article-title>Real-time deformable registration of multi-modal whole slides for digital pathology</article-title><source>Comput Med Imaging Graph</source><year>2011</year><volume>35</volume><issue>7&#x02013;8</issue><fpage>542</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1016/j.compmedimag.2011.06.006</pub-id><pub-id pub-id-type="pmid">21715143</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Mueller D, Vossen D, Hulsken B. Real-time deformable registration of multi-modal whole slides for digital pathology. Comput Med Imaging Graph. 2011;35(7&#x02013;8):542&#x02013;56. 10.1016/j.compmedimag.2011.06.006.<pub-id pub-id-type="pmid">21715143</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Gatenbee</surname><given-names>CD</given-names></name><name><surname>Baker</surname><given-names>AM</given-names></name><name><surname>Prabhakaran</surname><given-names>S</given-names></name><name><surname>Swinyard</surname><given-names>O</given-names></name><name><surname>Slebos</surname><given-names>RJC</given-names></name><name><surname>Mandal</surname><given-names>G</given-names></name><name><surname>Mulholland</surname><given-names>E</given-names></name><name><surname>Andor</surname><given-names>N</given-names></name><name><surname>Marusyk</surname><given-names>A</given-names></name><name><surname>Leedham</surname><given-names>S</given-names></name><name><surname>Conejo-Garcia</surname><given-names>JR</given-names></name><name><surname>Chung</surname><given-names>CH</given-names></name><name><surname>Robertson-Tessi</surname><given-names>M</given-names></name><name><surname>Graham</surname><given-names>TA</given-names></name><name><surname>Anderson</surname><given-names>ARA</given-names></name></person-group><article-title>Virtual alignment of pathology image series for multi-gigapixel whole slide images</article-title><source>Nat Commun</source><year>2023</year><volume>14</volume><issue>1</issue><fpage>4502</fpage><pub-id pub-id-type="doi">10.1038/s41467-023-40218-9</pub-id><pub-id pub-id-type="pmid">37495577</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Gatenbee CD, Baker AM, Prabhakaran S, Swinyard O, Slebos RJC, Mandal G, Mulholland E, Andor N, Marusyk A, Leedham S, Conejo-Garcia JR, Chung CH, Robertson-Tessi M, Graham TA, Anderson ARA. Virtual alignment of pathology image series for multi-gigapixel whole slide images. Nat Commun. 2023;14(1):4502. 10.1038/s41467-023-40218-9.<pub-id pub-id-type="pmid">37495577</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Wodzinski M., Marini N., Atzori M., M&#x000fc;ller H. DeeperHistReg: Robust whole slide images registration framework. 2024. 10.48550/arXiv.2404.14434. Accessed 20 Dec 2024.</mixed-citation></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Escobar D&#x000ed;az Guerrero</surname><given-names>R</given-names></name><name><surname>Carvalho</surname><given-names>L</given-names></name><name><surname>Bocklitz</surname><given-names>T</given-names></name><name><surname>Popp</surname><given-names>J</given-names></name><name><surname>Oliveira</surname><given-names>JL</given-names></name></person-group><article-title>Software tools and platforms in digital pathology: a review for clinicians and computer scientists</article-title><source>J Pathol Inform</source><year>2022</year><pub-id pub-id-type="doi">10.1016/j.jpi.2022.100103</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Escobar D&#x000ed;az Guerrero R, Carvalho L, Bocklitz T, Popp J, Oliveira JL. Software tools and platforms in digital pathology: a review for clinicians and computer scientists. J Pathol Inform. 2022. 10.1016/j.jpi.2022.100103.</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Janowczyk</surname><given-names>A</given-names></name><name><surname>Zuo</surname><given-names>R</given-names></name><name><surname>Gilmore</surname><given-names>H</given-names></name><name><surname>Feldman</surname><given-names>M</given-names></name><name><surname>Madabhushi</surname><given-names>A</given-names></name></person-group><article-title>HistoQC: an open-source quality control tool for digital pathology slides</article-title><source>JCO Clin Cancer Inform</source><year>2019</year><volume>3</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1200/CCI.18.00157</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Janowczyk A, Zuo R, Gilmore H, Feldman M, Madabhushi A. HistoQC: an open-source quality control tool for digital pathology slides. JCO Clin Cancer Inform. 2019;3:1&#x02013;7. 10.1200/CCI.18.00157.</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Goode</surname><given-names>A</given-names></name><name><surname>Gilbert</surname><given-names>B</given-names></name><name><surname>Harkes</surname><given-names>J</given-names></name><name><surname>Jukic</surname><given-names>D</given-names></name><name><surname>Satyanarayanan</surname><given-names>M</given-names></name></person-group><article-title>OpenSlide: a vendor-neutral software foundation for digital pathology</article-title><source>J Pathol Inform</source><year>2013</year><volume>4</volume><fpage>27</fpage><pub-id pub-id-type="doi">10.4103/2153-3539.119005</pub-id><pub-id pub-id-type="pmid">24244884</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Goode A, Gilbert B, Harkes J, Jukic D, Satyanarayanan M. OpenSlide: a vendor-neutral software foundation for digital pathology. J Pathol Inform. 2013;4:27. 10.4103/2153-3539.119005.<pub-id pub-id-type="pmid">24244884</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Klein S., Staring M. Elastix-the manual. 2023 elastix.dev. <ext-link ext-link-type="uri" xlink:href="https://elastix.lumc.nl/download/elastix-5.1.0-manual.pdf">https://elastix.lumc.nl/download/elastix-5.1.0-manual.pdf</ext-link>. Accessed 20 Dec 2024</mixed-citation></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>S</given-names></name><name><surname>Pluim</surname><given-names>JP</given-names></name><name><surname>Staring</surname><given-names>M</given-names></name><name><surname>Viergever</surname><given-names>MA</given-names></name></person-group><article-title>Adaptive stochastic gradient descent optimisation for image registration</article-title><source>Int J Comput Vis</source><year>2009</year><volume>81</volume><fpage>227</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1007/s11263-008-0168-y</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Klein S, Pluim JP, Staring M, Viergever MA. Adaptive stochastic gradient descent optimisation for image registration. Int J Comput Vis. 2009;81:227&#x02013;39. 10.1007/s11263-008-0168-y.</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Mattes D., Haynor D. R., Vesselle H., Lewellyn T. K., Eubank W. Nonrigid multimodality image registration. Proceedings medical imaging 2001: image processing (Vol. 4322, p. 1609&#x02013;1620), 2001. 10.1117/12.431046</mixed-citation></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Fitzpatrick</surname><given-names>JM</given-names></name><name><surname>West</surname><given-names>JB</given-names></name></person-group><article-title>The distribution of target registration error in rigid-body point-based registration</article-title><source>IEEE Trans Med Imaging</source><year>2001</year><volume>20</volume><issue>9</issue><fpage>917</fpage><lpage>927</lpage><pub-id pub-id-type="doi">10.1109/42.952729</pub-id><pub-id pub-id-type="pmid">11585208</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Fitzpatrick JM, West JB. The distribution of target registration error in rigid-body point-based registration. IEEE Trans Med Imaging. 2001;20(9):917&#x02013;27. 10.1109/42.952729.<pub-id pub-id-type="pmid">11585208</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>CW</given-names></name><name><surname>Lee</surname><given-names>YC</given-names></name><name><surname>Khalil</surname><given-names>MA</given-names></name><name><surname>Lin</surname><given-names>KY</given-names></name><name><surname>Yu</surname><given-names>CP</given-names></name><name><surname>Lien</surname><given-names>HC</given-names></name></person-group><article-title>Fast cross-staining alignment of gigapixel whole slide images with application to prostate cancer and breast cancer analysis</article-title><source>Sci Rep</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>11623</fpage><pub-id pub-id-type="doi">10.1038/s41598-022-15962-5</pub-id><pub-id pub-id-type="pmid">35803996</pub-id>
</element-citation><mixed-citation id="mc-CR19" publication-type="journal">Wang CW, Lee YC, Khalil MA, Lin KY, Yu CP, Lien HC. Fast cross-staining alignment of gigapixel whole slide images with application to prostate cancer and breast cancer analysis. Sci Rep. 2022;12(1):11623. 10.1038/s41598-022-15962-5.<pub-id pub-id-type="pmid">35803996</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Kubota</surname><given-names>A</given-names></name><name><surname>Shibata</surname><given-names>M</given-names></name><name><surname>Kikuchi</surname><given-names>S</given-names></name><name><surname>Yoneyama</surname><given-names>T</given-names></name></person-group><article-title>Colour reproduction evaluation of whole-slide imaging scanners for digital pathology</article-title><source>Comput Methods Biomech Biomed Eng Imaging Vis</source><year>2024</year><volume>12</volume><issue>1</issue><fpage>2359396</fpage><pub-id pub-id-type="doi">10.1080/21681163.2024.2359396</pub-id></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Kubota A, Shibata M, Kikuchi S, Yoneyama T. Colour reproduction evaluation of whole-slide imaging scanners for digital pathology. Comput Methods Biomech Biomed Eng Imaging Vis. 2024;12(1):2359396. 10.1080/21681163.2024.2359396.</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuji</surname><given-names>T</given-names></name><name><surname>Yoshida</surname><given-names>S</given-names></name><name><surname>Hommyo</surname><given-names>M</given-names></name><name><surname>Oyama</surname><given-names>A</given-names></name><name><surname>Kumagai</surname><given-names>S</given-names></name><name><surname>Shiraishi</surname><given-names>K</given-names></name><name><surname>Kotoku</surname><given-names>J</given-names></name></person-group><article-title>Cone beam computed tomography image-quality improvement using "one-shot" super-resolution</article-title><source>J Imaging Inform Med</source><year>2024</year><pub-id pub-id-type="doi">10.1007/s10278-024-01346-w</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Tsuji T, Yoshida S, Hommyo M, Oyama A, Kumagai S, Shiraishi K, Kotoku J. Cone beam computed tomography image-quality improvement using &#x0201c;one-shot&#x0201d; super-resolution. J Imaging Inform Med. 2024. 10.1007/s10278-024-01346-w.</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Thummerer</surname><given-names>A</given-names></name><name><surname>Schmidt</surname><given-names>L</given-names></name><name><surname>Hofmaier</surname><given-names>J</given-names></name><name><surname>Corradini</surname><given-names>S</given-names></name><name><surname>Belka</surname><given-names>C</given-names></name><name><surname>Landry</surname><given-names>G</given-names></name><name><surname>Kurz</surname><given-names>C</given-names></name></person-group><article-title>Deep learning based super-resolution for CBCT dose reduction in radiotherapy</article-title><source>Med Phys</source><year>2024</year><pub-id pub-id-type="doi">10.1002/mp.17557</pub-id></element-citation><mixed-citation id="mc-CR22" publication-type="journal">Thummerer A, Schmidt L, Hofmaier J, Corradini S, Belka C, Landry G, Kurz C. Deep learning based super-resolution for CBCT dose reduction in radiotherapy. Med Phys. 2024. 10.1002/mp.17557.</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000f6;hler</surname><given-names>C</given-names></name><name><surname>Kuntke</surname><given-names>P</given-names></name><name><surname>Sahoo</surname><given-names>P</given-names></name><name><surname>Wahl</surname><given-names>H</given-names></name><name><surname>Deoni</surname><given-names>SCL</given-names></name><name><surname>G&#x000e4;rtner</surname><given-names>J</given-names></name><name><surname>Dreha-Kulaczewski</surname><given-names>S</given-names></name><name><surname>Kitzler</surname><given-names>HH</given-names></name></person-group><article-title>Atlas-based assessment of hypomyelination: quantitative MRI in Pelizaeus&#x02013;Merzbacher disease</article-title><source>Hum Brain Mapp</source><year>2024</year><volume>45</volume><issue>13</issue><fpage>e70014</fpage><pub-id pub-id-type="doi">10.1002/hbm.70014</pub-id><pub-id pub-id-type="pmid">39230009</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">K&#x000f6;hler C, Kuntke P, Sahoo P, Wahl H, Deoni SCL, G&#x000e4;rtner J, Dreha-Kulaczewski S, Kitzler HH. Atlas-based assessment of hypomyelination: quantitative MRI in Pelizaeus&#x02013;Merzbacher disease. Hum Brain Mapp. 2024;45(13): e70014. 10.1002/hbm.70014.<pub-id pub-id-type="pmid">39230009</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Rana</surname><given-names>A</given-names></name><name><surname>Lowe</surname><given-names>A</given-names></name><name><surname>Lithgow</surname><given-names>M</given-names></name><name><surname>Horback</surname><given-names>K</given-names></name><name><surname>Janovitz</surname><given-names>T</given-names></name><name><surname>Da Silva</surname><given-names>A</given-names></name><name><surname>Tsai</surname><given-names>H</given-names></name><name><surname>Shanmugam</surname><given-names>V</given-names></name><name><surname>Bayat</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>P</given-names></name></person-group><article-title>Use of deep learning to develop and analyze computational hematoxylin and eosin staining of prostate core biopsy images for tumor diagnosis</article-title><source>JAMA Netw Open</source><year>2020</year><volume>3</volume><issue>5</issue><fpage>e205111</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2020.5111</pub-id><pub-id pub-id-type="pmid">32432709</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Rana A, Lowe A, Lithgow M, Horback K, Janovitz T, Da Silva A, Tsai H, Shanmugam V, Bayat A, Shah P. Use of deep learning to develop and analyze computational hematoxylin and eosin staining of prostate core biopsy images for tumor diagnosis. JAMA Netw Open. 2020;3(5): e205111. 10.1001/jamanetworkopen.2020.5111.<pub-id pub-id-type="pmid">32432709</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Treanor</surname><given-names>D</given-names></name><name><surname>Bulpitt</surname><given-names>AJ</given-names></name><name><surname>Wijayathunga</surname><given-names>N</given-names></name><name><surname>Roberts</surname><given-names>N</given-names></name><name><surname>Wilcox</surname><given-names>R</given-names></name><name><surname>Magee</surname><given-names>DR</given-names></name></person-group><article-title>Unsupervised content classification based nonrigid registration of differently stained histology images</article-title><source>IEEE Trans Biomed Eng</source><year>2014</year><volume>61</volume><issue>1</issue><fpage>96</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1109/TBME.2013.2277777</pub-id><pub-id pub-id-type="pmid">23955690</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Song Y, Treanor D, Bulpitt AJ, Wijayathunga N, Roberts N, Wilcox R, Magee DR. Unsupervised content classification based nonrigid registration of differently stained histology images. IEEE Trans Biomed Eng. 2014;61(1):96&#x02013;108. 10.1109/TBME.2013.2277777.<pub-id pub-id-type="pmid">23955690</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>