<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Hum Behav</journal-id><journal-id journal-id-type="iso-abbrev">Nat Hum Behav</journal-id><journal-title-group><journal-title>Nature Human Behaviour</journal-title></journal-title-group><issn pub-type="epub">2397-3374</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39604572</article-id><article-id pub-id-type="pmc">PMC11860209</article-id>
<article-id pub-id-type="publisher-id">2046</article-id><article-id pub-id-type="doi">10.1038/s41562-024-02046-9</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Large language models surpass human experts in predicting neuroscience results</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5297-2114</contrib-id><name><surname>Luo</surname><given-names>Xiaoliang</given-names></name><address><email>xiao.luo.17@ucl.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0009-0009-9991-4577</contrib-id><name><surname>Rechardt</surname><given-names>Akilles</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5886-056X</contrib-id><name><surname>Sun</surname><given-names>Guangzhi</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-4441-5517</contrib-id><name><surname>Nejad</surname><given-names>Kevin K.</given-names></name><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9598-0616</contrib-id><name><surname>Y&#x000e1;&#x000f1;ez</surname><given-names>Felipe</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8824-0345</contrib-id><name><surname>Yilmaz</surname><given-names>Bati</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7760-8079</contrib-id><name><surname>Lee</surname><given-names>Kangjoo</given-names></name><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3116-3529</contrib-id><name><surname>Cohen</surname><given-names>Alexandra O.</given-names></name><xref ref-type="aff" rid="Aff8">8</xref></contrib><contrib contrib-type="author"><name><surname>Borghesani</surname><given-names>Valentina</given-names></name><xref ref-type="aff" rid="Aff9">9</xref></contrib><contrib contrib-type="author"><name><surname>Pashkov</surname><given-names>Anton</given-names></name><xref ref-type="aff" rid="Aff10">10</xref><xref ref-type="aff" rid="Aff11">11</xref><xref ref-type="aff" rid="Aff12">12</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9803-0122</contrib-id><name><surname>Marinazzo</surname><given-names>Daniele</given-names></name><xref ref-type="aff" rid="Aff13">13</xref></contrib><contrib contrib-type="author"><name><surname>Nicholas</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="Aff14">14</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2311-8645</contrib-id><name><surname>Salatiello</surname><given-names>Alessandro</given-names></name><xref ref-type="aff" rid="Aff15">15</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4121-7479</contrib-id><name><surname>Sucholutsky</surname><given-names>Ilia</given-names></name><xref ref-type="aff" rid="Aff16">16</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8442-602X</contrib-id><name><surname>Minervini</surname><given-names>Pasquale</given-names></name><xref ref-type="aff" rid="Aff17">17</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4651-8852</contrib-id><name><surname>Razavi</surname><given-names>Sepehr</given-names></name><xref ref-type="aff" rid="Aff18">18</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9017-8088</contrib-id><name><surname>Rocca</surname><given-names>Roberta</given-names></name><xref ref-type="aff" rid="Aff19">19</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7227-839X</contrib-id><name><surname>Yusifov</surname><given-names>Elkhan</given-names></name><xref ref-type="aff" rid="Aff20">20</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0009-0009-1688-6655</contrib-id><name><surname>Okalova</surname><given-names>Tereza</given-names></name><xref ref-type="aff" rid="Aff21">21</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8474-0836</contrib-id><name><surname>Gu</surname><given-names>Nianlong</given-names></name><xref ref-type="aff" rid="Aff22">22</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4031-6398</contrib-id><name><surname>Ferianc</surname><given-names>Martin</given-names></name><xref ref-type="aff" rid="Aff23">23</xref></contrib><contrib contrib-type="author"><name><surname>Khona</surname><given-names>Mikail</given-names></name><xref ref-type="aff" rid="Aff24">24</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0289-5480</contrib-id><name><surname>Patil</surname><given-names>Kaustubh R.</given-names></name><xref ref-type="aff" rid="Aff25">25</xref><xref ref-type="aff" rid="Aff26">26</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8016-9468</contrib-id><name><surname>Lee</surname><given-names>Pui-Shee</given-names></name><xref ref-type="aff" rid="Aff27">27</xref><xref ref-type="aff" rid="Aff28">28</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1679-906X</contrib-id><name><surname>Mata</surname><given-names>Rui</given-names></name><xref ref-type="aff" rid="Aff29">29</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5599-3044</contrib-id><name><surname>Myers</surname><given-names>Nicholas E.</given-names></name><xref ref-type="aff" rid="Aff30">30</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6605-2362</contrib-id><name><surname>Bizley</surname><given-names>Jennifer K.</given-names></name><xref ref-type="aff" rid="Aff31">31</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8896-639X</contrib-id><name><surname>Musslick</surname><given-names>Sebastian</given-names></name><xref ref-type="aff" rid="Aff32">32</xref><xref ref-type="aff" rid="Aff33">33</xref></contrib><contrib contrib-type="author"><name><surname>Bilgin</surname><given-names>Isil Poyraz</given-names></name><xref ref-type="aff" rid="Aff34">34</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5872-8924</contrib-id><name><surname>Niso</surname><given-names>Guiomar</given-names></name><xref ref-type="aff" rid="Aff35">35</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2089-1563</contrib-id><name><surname>Ales</surname><given-names>Justin M.</given-names></name><xref ref-type="aff" rid="Aff36">36</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4442-5778</contrib-id><name><surname>Gaebler</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="Aff37">37</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2191-797X</contrib-id><name><surname>Ratan Murty</surname><given-names>N. Apurva</given-names></name><xref ref-type="aff" rid="Aff38">38</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3241-6492</contrib-id><name><surname>Loued-Khenissi</surname><given-names>Leyla</given-names></name><xref ref-type="aff" rid="Aff39">39</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7129-7006</contrib-id><name><surname>Behler</surname><given-names>Anna</given-names></name><xref ref-type="aff" rid="Aff40">40</xref></contrib><contrib contrib-type="author"><name><surname>Hall</surname><given-names>Chloe M.</given-names></name><xref ref-type="aff" rid="Aff41">41</xref><xref ref-type="aff" rid="Aff42">42</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2540-0927</contrib-id><name><surname>Dafflon</surname><given-names>Jessica</given-names></name><xref ref-type="aff" rid="Aff43">43</xref><xref ref-type="aff" rid="Aff44">44</xref><xref ref-type="aff" rid="Aff47">47</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4804-3379</contrib-id><name><surname>Bao</surname><given-names>Sherry Dongqi</given-names></name><xref ref-type="aff" rid="Aff45">45</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7883-7076</contrib-id><name><surname>Love</surname><given-names>Bradley C.</given-names></name><address><email>b.love@ucl.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff46">46</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02jx3x895</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2190 1201</institution-id><institution>Department of Experimental Psychology, </institution><institution>University College London, </institution></institution-wrap>London, UK </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/013meh722</institution-id><institution-id institution-id-type="GRID">grid.5335.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2188 5934</institution-id><institution>Department of Engineering, </institution><institution>University of Cambridge, </institution></institution-wrap>Cambridge, UK </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/052gg0110</institution-id><institution-id institution-id-type="GRID">grid.4991.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8948</institution-id><institution>Department of Physiology, Anatomy and Genetics, </institution><institution>University of Oxford, </institution></institution-wrap>Oxford, UK </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0524sp257</institution-id><institution-id institution-id-type="GRID">grid.5337.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7603</institution-id><institution>Department of Computer Science, </institution><institution>University of Bristol, </institution></institution-wrap>Bristol, UK </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02yjyfs84</institution-id><institution>Max Planck Institute for Neurobiology of Behavior &#x02013; caesar, </institution></institution-wrap>Bonn, Germany </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02vh8a032</institution-id><institution-id institution-id-type="GRID">grid.18376.3b</institution-id><institution-id institution-id-type="ISNI">0000 0001 0723 2427</institution-id><institution>National Magnetic Resonance Research Center (UMRAM), </institution><institution>Bilkent University, </institution></institution-wrap>Ankara, Turkey </aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03v76x132</institution-id><institution-id institution-id-type="GRID">grid.47100.32</institution-id><institution-id institution-id-type="ISNI">0000000419368710</institution-id><institution>Department of Psychiatry, </institution><institution>Yale University School of Medicine, </institution></institution-wrap>New Haven, CT USA </aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03czfpz43</institution-id><institution-id institution-id-type="GRID">grid.189967.8</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7398</institution-id><institution>Department of Psychology, </institution><institution>Emory University, </institution></institution-wrap>Atlanta, GA USA </aff><aff id="Aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01swzsf04</institution-id><institution-id institution-id-type="GRID">grid.8591.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 2175 2154</institution-id><institution>Faculty of Psychology and Educational Sciences, </institution><institution>Universit&#x000e9; de Gen&#x000e8;ve, </institution></institution-wrap>Geneva, Switzerland </aff><aff id="Aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00d167n54</institution-id><institution-id institution-id-type="GRID">grid.445341.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0467 3915</institution-id><institution>Department of Neurosurgery, </institution><institution>Novosibirsk State Medical University, </institution></institution-wrap>Novosibirsk, Russia </aff><aff id="Aff11"><label>11</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04tmsfn31</institution-id><institution-id institution-id-type="GRID">grid.512435.4</institution-id><institution>Federal Center of Neurosurgery, </institution><institution>FSBI, </institution></institution-wrap>Novosibirsk, Russia </aff><aff id="Aff12"><label>12</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01b2f6h61</institution-id><institution-id institution-id-type="GRID">grid.77667.37</institution-id><institution>Department of Data Collection and Processing Systems, </institution><institution>Novosibirsk State Technical University, </institution></institution-wrap>Novosibirsk, Russia </aff><aff id="Aff13"><label>13</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00cv9y106</institution-id><institution-id institution-id-type="GRID">grid.5342.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2069 7798</institution-id><institution>Department of Data Analysis, </institution><institution>Ghent University, </institution></institution-wrap>Ghent, Belgium </aff><aff id="Aff14"><label>14</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0190ak572</institution-id><institution-id institution-id-type="GRID">grid.137628.9</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8753</institution-id><institution>Department of Psychology, </institution><institution>New York University, </institution></institution-wrap>New York, NY USA </aff><aff id="Aff15"><label>15</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03a1kwz48</institution-id><institution-id institution-id-type="GRID">grid.10392.39</institution-id><institution-id institution-id-type="ISNI">0000 0001 2190 1447</institution-id><institution>Department of Cognitive Neurology, </institution><institution>University of T&#x000fc;bingen, </institution></institution-wrap>T&#x000fc;bingen, Germany </aff><aff id="Aff16"><label>16</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00hx57361</institution-id><institution-id institution-id-type="GRID">grid.16750.35</institution-id><institution-id institution-id-type="ISNI">0000 0001 2097 5006</institution-id><institution>Department of Computer Science, </institution><institution>Princeton University, </institution></institution-wrap>Princeton, NJ USA </aff><aff id="Aff17"><label>17</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01nrxwf90</institution-id><institution-id institution-id-type="GRID">grid.4305.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7988</institution-id><institution>ILCC, </institution><institution>University of Edinburgh, </institution></institution-wrap>Edinburgh, UK </aff><aff id="Aff18"><label>18</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01nrxwf90</institution-id><institution-id institution-id-type="GRID">grid.4305.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7988</institution-id><institution>Philosophy, Psychology, and Language Sciences, </institution><institution>The University of Edinburgh, </institution></institution-wrap>Edinburgh, UK </aff><aff id="Aff19"><label>19</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01aj84f44</institution-id><institution-id institution-id-type="GRID">grid.7048.b</institution-id><institution-id institution-id-type="ISNI">0000 0001 1956 2722</institution-id><institution>Department of Culture, Cognition and Computation, </institution><institution>Aarhus University, </institution></institution-wrap>Aarhus, Denmark </aff><aff id="Aff20"><label>20</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02crff812</institution-id><institution-id institution-id-type="GRID">grid.7400.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0650</institution-id><institution>Department of Molecular Life Sciences, </institution><institution>University of Zurich, </institution></institution-wrap>Zurich, Switzerland </aff><aff id="Aff21"><label>21</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00b30xv10</institution-id><institution-id institution-id-type="GRID">grid.25879.31</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8972</institution-id><institution>Department of Bioengineering, </institution><institution>University of Pennsylvania, </institution></institution-wrap>Philadelphia, PA USA </aff><aff id="Aff22"><label>22</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02crff812</institution-id><institution-id institution-id-type="GRID">grid.7400.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0650</institution-id><institution>Linguistic Research Infrastructure, </institution><institution>University of Zurich, </institution></institution-wrap>Zurich, Switzerland </aff><aff id="Aff23"><label>23</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02jx3x895</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2190 1201</institution-id><institution>Department of Electronic and Electrical Engineering, </institution><institution>University College London, </institution></institution-wrap>London, UK </aff><aff id="Aff24"><label>24</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/042nb2s44</institution-id><institution-id institution-id-type="GRID">grid.116068.8</institution-id><institution-id institution-id-type="ISNI">0000 0001 2341 2786</institution-id><institution>Department of Brain and Cognitive Sciences, </institution><institution>Massachusetts Institute of Technology, </institution></institution-wrap>Cambridge, MA USA </aff><aff id="Aff25"><label>25</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02nv7yv05</institution-id><institution-id institution-id-type="GRID">grid.8385.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 2297 375X</institution-id><institution>Institute of Neuroscience and Medicine, INM-7: Brain and Behaviour, </institution><institution>Research Centre J&#x000fc;lich, </institution></institution-wrap>J&#x000fc;lich, Germany </aff><aff id="Aff26"><label>26</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/024z2rq82</institution-id><institution-id institution-id-type="GRID">grid.411327.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 2176 9917</institution-id><institution>Medical Faculty, Institute of Systems Neuroscience, </institution><institution>Heinrich Heine University D&#x000fc;sseldorf, </institution></institution-wrap>D&#x000fc;sseldorf, Germany </aff><aff id="Aff27"><label>27</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05591te55</institution-id><institution-id institution-id-type="GRID">grid.5252.0</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 973X</institution-id><institution>Graduate School of Systemic Neurosciences, </institution><institution>Ludwig-Maximilians-University Munich, </institution></institution-wrap>Planegg-Martinsried, Germany </aff><aff id="Aff28"><label>28</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02kkvpp62</institution-id><institution-id institution-id-type="GRID">grid.6936.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 2322 2966</institution-id><institution>Institute of Neuronal Cell Biology, </institution><institution>Technical University of Munich, </institution></institution-wrap>Munich, Germany </aff><aff id="Aff29"><label>29</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02s6k3f65</institution-id><institution-id institution-id-type="GRID">grid.6612.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0642</institution-id><institution>Faculty of Psychology, </institution><institution>University of Basel, </institution></institution-wrap>Basel, Switzerland </aff><aff id="Aff30"><label>30</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01ee9ar58</institution-id><institution-id institution-id-type="GRID">grid.4563.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8868</institution-id><institution>School of Psychology, </institution><institution>University of Nottingham, </institution></institution-wrap>Nottingham, UK </aff><aff id="Aff31"><label>31</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02jx3x895</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2190 1201</institution-id><institution>Ear Institute, </institution><institution>University College London, </institution></institution-wrap>London, UK </aff><aff id="Aff32"><label>32</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04qmmjx98</institution-id><institution-id institution-id-type="GRID">grid.10854.38</institution-id><institution-id institution-id-type="ISNI">0000 0001 0672 4366</institution-id><institution>Institute of Cognitive Science, </institution><institution>University of Osnabr&#x000fc;ck, </institution></institution-wrap>Osnabr&#x000fc;ck, Germany </aff><aff id="Aff33"><label>33</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05gq02987</institution-id><institution-id institution-id-type="GRID">grid.40263.33</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9094</institution-id><institution>Department of Cognitive, Linguistic, and Psychological Sciences, </institution><institution>Brown University, </institution></institution-wrap>Providence, RI USA </aff><aff id="Aff34"><label>34</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/031z68d90</institution-id><institution-id institution-id-type="GRID">grid.294071.9</institution-id><institution-id institution-id-type="ISNI">0000 0000 9199 9374</institution-id><institution>D&#x000e9;partement de psychologie, </institution><institution>Centre de recherche de l&#x02019;Institut universitaire de g&#x000e9;riatrie de Montr&#x000e9;al, </institution></institution-wrap>Montreal, Quebec Canada </aff><aff id="Aff35"><label>35</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/012gwbh42</institution-id><institution-id institution-id-type="GRID">grid.419043.b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2177 5516</institution-id><institution>Instituto Cajal, </institution><institution>CSIC, </institution></institution-wrap>Madrid, Spain </aff><aff id="Aff36"><label>36</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02wn5qz54</institution-id><institution-id institution-id-type="GRID">grid.11914.3c</institution-id><institution-id institution-id-type="ISNI">0000 0001 0721 1626</institution-id><institution>School of Psychology and Neuroscience, </institution><institution>University of St Andrews, </institution></institution-wrap>St Andrews, UK </aff><aff id="Aff37"><label>37</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0387jng26</institution-id><institution-id institution-id-type="GRID">grid.419524.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 0041 5028</institution-id><institution>Department of Neurology, </institution><institution>Max Planck Institute for Human Cognitive and Brain Sciences, </institution></institution-wrap>Leipzig, Germany </aff><aff id="Aff38"><label>38</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01zkghx44</institution-id><institution-id institution-id-type="GRID">grid.213917.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 2097 4943</institution-id><institution>Department of Psychology, </institution><institution>Georgia Institute of Technology, </institution></institution-wrap>Atlanta, GA USA </aff><aff id="Aff39"><label>39</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05a353079</institution-id><institution-id institution-id-type="GRID">grid.8515.9</institution-id><institution-id institution-id-type="ISNI">0000 0001 0423 4662</institution-id><institution>D&#x000e9;partement des Neurosciences Cliniques, </institution><institution>Lausanne University Hospital, </institution></institution-wrap>Lausanne, Switzerland </aff><aff id="Aff40"><label>40</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00eae9z71</institution-id><institution-id institution-id-type="GRID">grid.266842.c</institution-id><institution-id institution-id-type="ISNI">0000 0000 8831 109X</institution-id><institution>School of Psychological Science, </institution><institution>The University of Newcastle, </institution></institution-wrap>Newcastle, New South Wales Australia </aff><aff id="Aff41"><label>41</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00q1fsf04</institution-id><institution-id institution-id-type="GRID">grid.410607.4</institution-id><institution>Institute of Physiology, </institution><institution>University Medical Center of the Johannes Gutenberg University, </institution></institution-wrap>Mainz, Germany </aff><aff id="Aff42"><label>42</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/023b0x485</institution-id><institution-id institution-id-type="GRID">grid.5802.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 1941 7111</institution-id><institution>Institute for Quantitative and Computational Biosciences, </institution><institution>Johannes Gutenberg University, </institution></institution-wrap>Mainz, Germany </aff><aff id="Aff43"><label>43</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04xeg9z08</institution-id><institution-id institution-id-type="GRID">grid.416868.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 0464 0574</institution-id><institution>Data Science and Sharing Team, Functional Magnetic Resonance Imaging Facility, </institution><institution>National Institute of Mental Health, </institution></institution-wrap>Bethesda, MD USA </aff><aff id="Aff44"><label>44</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04xeg9z08</institution-id><institution-id institution-id-type="GRID">grid.416868.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 0464 0574</institution-id><institution>Machine Learning Team, Functional Magnetic Resonance Imaging Facility, </institution><institution>National Institute of Mental Health, </institution></institution-wrap>Bethesda, MD USA </aff><aff id="Aff45"><label>45</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02crff812</institution-id><institution-id institution-id-type="GRID">grid.7400.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0650</institution-id><institution>Zurich Center for Neuroeconomics, Department of Economics, </institution><institution>University of Zurich, </institution></institution-wrap>Zurich, Switzerland </aff><aff id="Aff46"><label>46</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/035dkdb55</institution-id><institution-id institution-id-type="GRID">grid.499548.d</institution-id><institution-id institution-id-type="ISNI">0000 0004 5903 3632</institution-id><institution>The Alan Turing Institute, </institution></institution-wrap>London, UK </aff><aff id="Aff47"><label>47</label>Present Address: Valence Labs, Montreal, Qu&#x000e9;bec Canada </aff></contrib-group><pub-date pub-type="epub"><day>27</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>27</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2025</year></pub-date><volume>9</volume><issue>2</issue><fpage>305</fpage><lpage>315</lpage><history><date date-type="received"><day>19</day><month>3</month><year>2024</year></date><date date-type="accepted"><day>2</day><month>10</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Scientific discoveries often hinge on synthesizing decades of research, a task that potentially outstrips human information processing capacities. Large language models (LLMs) offer a solution. LLMs trained on the vast scientific literature could potentially integrate noisy yet interrelated findings to forecast novel results better than human experts. Here, to evaluate this possibility, we created BrainBench, a forward-looking benchmark for predicting neuroscience results. We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs indicated high confidence in their predictions, their responses were more likely to be correct, which presages a future where LLMs assist humans in making discoveries. Our approach is not neuroscience specific and is transferable to other knowledge-intensive endeavours.</p></abstract><abstract id="Abs2" abstract-type="web-summary"><p id="Par2">Large language models (LLMs) can synthesize vast amounts of information. Luo et al. show that LLMs&#x02014;especially BrainGPT, an LLM the authors tuned on the neuroscience literature&#x02014;outperform experts in predicting neuroscience results and could assist scientists in making future discoveries.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Neuroscience</kwd><kwd>Scientific community</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000269</institution-id><institution>RCUK | Economic and Social Research Council (ESRC)</institution></institution-wrap></funding-source><award-id>ES/W007347/1</award-id><principal-award-recipient><name><surname>Love</surname><given-names>Bradley C.</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000288</institution-id><institution>Royal Society</institution></institution-wrap></funding-source><award-id>Wolfson Fellowship (18302)</award-id><principal-award-recipient><name><surname>Love</surname><given-names>Bradley C.</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution>Microsoft (Accelerate Foundation Models Research Program)</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Main</title><p id="Par3">Keeping up with the exponentially increasing<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> scientific literature is a superhuman challenge. Potentially disruptive findings go unnoticed in the deluge of articles<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Processing and integrating the myriad of relevant findings may already surpass humans&#x02019; abilities.</p><p id="Par4">One path forward involves human scientists leveraging advanced machines. This approach could take several forms, including specialist solutions that address specific challenges, such as in protein folding<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, drug discovery<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> and materials science<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. Alternatively, general models of the scientific literature could help guide human scientists&#x02019; predictions and study designs. We consider this possibility.</p><p id="Par5">It is an open question whether large language models (LLMs), trained on general text and scientific articles, can predict the outcomes of experiments. If LLMs&#x02019; predictions surpassed human experts, the practice of science and the pace of discovery would radically change. We consider this question for neuroscience, which is a large and interdisciplinary field. Prediction in neuroscience should be challenging for human experts for several reasons: (1) there are often many thousands of relevant scientific articles, (2) an individual study can be noisy or unreliable and may not replicate, (3) neuroscience is a multi-level endeavour<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, spanning behaviour and molecular mechanisms, (4) and the analysis methods are diverse and can be complex<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, (5) as are the methods used, which include different brain imaging techniques, lesion studies, gene modification, pharmacological interventions and so forth.</p><p id="Par6">Can LLMs meet these challenges? In other domains, LLMs have performed impressively. Upon its release, OpenAI&#x02019;s ChatGPT<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> captured the public&#x02019;s imagination with its abilities. Most LLMs are based on the transformer architecture<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>. These models contain billions and sometimes trillions of weights<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, which are tuned during training in a self-supervised manner to predict the next token, such as the next word in a text passage.</p><p id="Par7">LLMs have displayed remarkable capabilities, including passing professional exams, reasoning (although not without limitations), translation, solving mathematics problems and even writing computer code<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>. By constructing a statistical model during their training to predict the next token, whether that token is a word, pixel or protein sequence<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, and by capturing patterns in the training data, including subtle and imperfect ones, the generative LLMs can potentially generalize to novel situations and predict outcomes of future events.</p><p id="Par8">How can we formally evaluate the predictive abilities of LLMs in neuroscience? With the rise of LLMs, there has been a surge in evaluation benchmarks, many of which focus on assessing LLMs&#x02019; capabilities in scientific domains. Most benchmarks evaluate core knowledge retrieval and reasoning abilities, which are typically backward-looking (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Backward-looking benchmarks include MMLU<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, PubMedQA<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> and MedMCQA<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. These benchmarks are structured in a question-and-answer format, where models must demonstrate extensive world knowledge, retrieve relevant information based on the context of the question, and answer correctly. However, none of these benchmarks is suitable for evaluating the ability of models to predict novel outcomes, which is inherently forward-looking (Fig. <xref rid="Fig1" ref-type="fig">1</xref>).<fig id="Fig1"><label>Fig. 1</label><caption><title>Backward-looking and forward-looking evaluations.</title><p><bold>a</bold>, Backward-looking benchmarks involve recalling factual information. For example, a student retrieves a fact about the Gettysburg Address that they learned during a history class. Existing benchmarks in scientific domains are in essence backward-looking as they emphasize retrieving accepted facts for question answering and reasoning tasks. <bold>b</bold>, Forward-looking benchmarks involve predicting novel outcomes on the basis of past data. Two forms of uncertainty, aleatoric (due to intrinsic randomness) and epistemic (due to lack of knowledge), may be present. For example, a table tennis fan predicts which player will win the next set on the basis of their knowledge of the players, how they have played so far today and so forth. Inherent random factors, such as a breeze affecting the ball&#x02019;s flight, will also be present.</p></caption><graphic xlink:href="41562_2024_2046_Fig1_HTML" id="d33e1032"/></fig></p><p id="Par9">To address this need, we developed BrainBench to test LLMs&#x02019; ability to predict neuroscience findings (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). LLMs have been trained extensively on the scientific literature, including neuroscience. BrainBench evaluates whether LLMs have seized on the fundamental patterning of methods and results that underlie the structure of neuroscience. Can LLMs outperform human experts on this forward-looking benchmark? In particular, BrainBench evaluates how well the test-taker can predict neuroscience results from methods by presenting two versions of an abstract from a recent journal article. The test-taker&#x02019;s task is to predict the study&#x02019;s outcome, choosing between the original and an altered version. The altered abstract substantially changes the study&#x02019;s outcome (that is, results) while maintaining overall coherence.<fig id="Fig2"><label>Fig. 2</label><caption><title>BrainBench is a forward-looking benchmark for neuroscience.</title><p>BrainBench evaluates test-takers' ability to predict neuroscience results. BrainBench&#x02019;s test cases were sourced from recent <italic>Journal of Neuroscience</italic> abstracts across five neuroscience domains: behavioural/cognitive, systems/circuits, neurobiology of disease, cellular/molecular and developmental/plasticity/repair. Test-takers chose between the original abstract and one altered to substantially change the result while maintaining coherency. Human experts and LLMs were tasked with selecting the correct (that is, original) version from the two options. Human experts made choices and provided confidence and expertise ratings in an online study. LLMs were scored as choosing the abstract with the lower perplexity (that is, the text passage that was less surprising to the model), and their confidence was proportional to the difference in perplexity between the two options.</p></caption><graphic xlink:href="41562_2024_2046_Fig2_HTML" id="d33e1049"/></fig></p><p id="Par10">To appreciate how BrainBench qualitatively differs from existing benchmarks, consider a perceived limitation of LLMs, namely, their tendency to generate erroneous information, a phenomenon commonly referred to as &#x02018;hallucination&#x02019; by LLM researchers. Unlike knowledge graphs that store verified facts, LLMs may not be trustworthy for backward-looking tasks such as summarizing research papers or providing accurate citations<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. However, for forward-looking tasks, such as predicting results from a novel experiment, we view this tendency to mix and integrate information from large and noisy datasets as a virtue. What is a hallucination in a backward-looking task is a generalization or prediction in a forward-looking task (for example, BrainBench). BrainBench provides a way to quantify this forward-looking ability and compare with human experts. To foreshadow our results, LLMs surpassed human experts on BrainBench by a substantial margin, and this margin increased when we provided additional training in neuroscience to an LLM, which we refer to as &#x02018;BrainGPT&#x02019;.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>General-purpose LLMs best neuroscientists on BrainBench</title><p id="Par11">On each benchmark trial (Fig. <xref rid="Fig2" ref-type="fig">2</xref>), both the LLMs<sup><xref ref-type="bibr" rid="CR18">18</xref>&#x02013;<xref ref-type="bibr" rid="CR21">21</xref></sup> and human experts were tasked with selecting which of two versions of an abstract was correct (that is, the original version). Human neuroscience experts were screened for their expertise and engagement (<xref rid="Sec11" ref-type="sec">Methods</xref>) with 171 out of 202 participants passing all checks and included in our analyses.</p><p id="Par12">Every LLM outperformed human experts on BrainBench with LLMs averaging 81.4% accuracy and human experts averaging 63.4% (<italic>t</italic>(14)&#x02009;=&#x02009;25.8, <italic>P</italic>&#x02009;&#x0003c;&#x02009;0.001, Cohen&#x02019;s <italic>d</italic>&#x02009;=&#x02009;9.27, 95% confidence interval (CI) 0.17&#x02013;0.2; two-sided; Fig. <xref rid="Fig3" ref-type="fig">3a</xref>). When restricting human responses to those in the top 20% of self-reported expertise for that test item, accuracy rose to 66.2%, still below the level of LLMs.<fig id="Fig3"><label>Fig. 3</label><caption><title>Performance of human experts and LLMs on BrainBench.</title><p><bold>a</bold>, LLMs outperformed human experts on BrainBench (<italic>t</italic>(14)&#x02009;=&#x02009;25.8, <italic>P</italic>&#x02009;&#x0003c;&#x02009;0.001, Cohen&#x02019;s <italic>d</italic>&#x02009;=&#x02009;9.27, 95% CI 0.17&#x02013;0.2; two-sided). Smaller models are on par with larger models. Base versions of models outperformed chat and instruct versions (<italic>t</italic>(5)&#x02009;=&#x02009;5.38, <italic>P</italic>&#x02009;=&#x02009;0.002, Cohen&#x02019;s <italic>d</italic>&#x02009;=&#x02009;0.77, 95% CI 0.02&#x02013;0.04; two-sided), which were tuned to be conversational with humans. The error bars represent the standard error of the accuracy. Each model was evaluated on 200 BrainBench test cases. In total, 171 human experts were evaluated on the same test cases over 1,011 trials. <bold>b</bold>, The distribution of test cases across neuroscience subfields roughly mirrors the distribution of articles in the <italic>Journal of Neuroscience</italic> with behaviour/cognitive overrepresented. The average performance of 15 LLMs and human experts is shown. LLMs outperformed human experts in every subfield (see Supplemetary Fig. <xref rid="MOESM1" ref-type="media">5</xref> for the full results). <bold>c</bold>, The participants were predoctoral students (<italic>n</italic><sub>trial</sub>&#x02009;=&#x02009;104), doctoral students (<italic>n</italic><sub>trial</sub>&#x02009;=&#x02009;300), postdoctoral researchers (<italic>n</italic><sub>trial</sub>&#x02009;=&#x02009;255), faculty/academic staff (<italic>n</italic><sub>trial</sub>&#x02009;=&#x02009;256), research scientists (<italic>n</italic><sub>trial</sub>&#x02009;=&#x02009;72) and others (<italic>n</italic><sub>trial</sub>&#x02009;=&#x02009;24). The error bars represent the standard error of the accuracy.</p></caption><graphic xlink:href="41562_2024_2046_Fig3_HTML" id="d33e1156"/></fig></p><p id="Par13">Smaller models such as Llama2-7B and Mistral-7B with 7 billion parameters performed comparably to larger models (Fig. <xref rid="Fig3" ref-type="fig">3a</xref>) while besting even smaller models (Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref>) that may lack the capacity to capture key data patterns. Chat or instruction-optimized models performed worse than their base model counterparts (<italic>t</italic>(5)&#x02009;=&#x02009;5.38, <italic>P</italic>&#x02009;=&#x02009;0.002, Cohen&#x02019;s <italic>d</italic>&#x02009;=&#x02009;0.77, 95% CI 0.02&#x02013;0.04; two-sided). We suspect that aligning LLMs to engage in natural language conversations hinders their scientific inference abilities (<xref rid="Sec10" ref-type="sec">Discussion</xref>).</p><p id="Par14">The previous analyses involved benchmark items created by co-authors who are neuroscience experts (<xref rid="Sec11" ref-type="sec">Methods</xref>). We conducted the same analyses using test cases generated by a LLM, namely, GPT-4 (<xref rid="Sec11" ref-type="sec">Methods</xref>), and observed similar results (Supplementary Figs. <xref rid="MOESM1" ref-type="media">20</xref>, <xref rid="MOESM1" ref-type="media">21</xref> and <xref rid="MOESM1" ref-type="media">23</xref>).</p><sec id="Sec4"><title>Performance breakdown by subfield and by participant type</title><p id="Par15">BrainBench encompasses test cases from five distinct neuroscience domains: behavioural/cognitive, cellular/molecular, systems/circuits, neurobiology of disease and development/plasticity/repair. Some domains, particularly behavioural/cognitive, are overrepresented both in BrainBench (Fig. <xref rid="Fig3" ref-type="fig">3B</xref>) and in the <italic>Journal of Neuroscience</italic> from which we drew our test cases (<xref rid="Sec11" ref-type="sec">Methods</xref>).</p><p id="Par16">On average, LLMs performed better than human experts in every subfield (Fig. <xref rid="Fig3" ref-type="fig">3b</xref>), as did each individual LLM (Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>). Most human experts were doctoral students, postdoctoral researchers or faculty/academic staff (Fig. <xref rid="Fig3" ref-type="fig">3c</xref>). Please refer to <xref rid="MOESM1" ref-type="media">Supplementary Information</xref> for more detailed demographic information including years of experience in neuroscience research about the human experts and distributions of self-reported expertise by subfield (Supplementary Fig. <xref rid="MOESM1" ref-type="media">17</xref>).</p></sec><sec id="Sec5"><title>Do judgements from LLMs and human experts align?</title><p id="Par17">We considered whether human experts and LLMs found the same benchmark items difficult. For humans, we calculated the mean accuracy for each of the 200 test cases. For LLMs, we calculated the signed differences in perplexity between incorrect and correct abstracts for each test case. Perplexity measures how surprising a text passage is to an LLM. Using these measures (Supplementary Fig. <xref rid="MOESM1" ref-type="media">6</xref>), the mean Spearman correlation between an LLM and human experts was 0.15 (&#x000b1;0.03), whereas the mean Spearman correlation between LLMs was 0.75 (&#x000b1;0.08).</p></sec><sec id="Sec6"><title>LLMs can integrate information across context</title><p id="Par18">To better understand the basis for the remarkable performance of LLMs (see Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref> for results), we investigated whether their performance was achieved by integrating information throughout the abstract (including the method used) or by solely relying on the local context in the results passages that differed between the original and altered abstract (Fig. <xref rid="Fig2" ref-type="fig">2</xref>)</p><p id="Par19">We reevaluated the LLMs on individual sentences containing only the altered results passage (that is, local context only). LLMs performed much worse when restricted to this local context (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>), which provides strong evidence that LLMs are integrating information across the abstract, including information on background and methods. LLM&#x02019;s superior performance relative to human experts appears to arise from integrating information across the abstract.</p><p id="Par20">In addition, we analysed whether LLMs benefitted from a general neuroscience context (similar to few-shot prompting) rather than integrating study-relevant information. We tested models using abstracts with sentences randomly swapped from within the same neuroscience subfield. Both original and altered abstracts were used to reevaluate LLMs&#x02019; performance. As shown in Supplementary Fig. <xref rid="MOESM1" ref-type="media">4</xref>, there was a significant performance decline with coherent versus swapped contexts, indicating that LLMs only partially benefit from accurate, domain-specific but non-study-relevant context.</p></sec><sec id="Sec7"><title>LLM performance is not driven by data memorization</title><p id="Par21">When LLMs perform well on a benchmark, one general concern is that the benchmark itself was part of the training set, allowing the LLM to memorize the correct answers. To address this concern, we used a commonly applied measure, the zlib&#x02013;perplexity ratio, for evaluating whether LLMs have memorized passages<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. This ratio gauges the difference between a data-agnostic compression rate of text and data-specific perplexity computed by an LLM (<xref rid="Sec11" ref-type="sec">Methods</xref>). Passages that are hard to compress but have low perplexity are indicative of memorization.</p><p id="Par22">We found no indication that BrainBench was memorized by LLMs (Supplementary Fig. <xref rid="MOESM1" ref-type="media">7</xref>). For comparison, we calculated the zlib&#x02013;perplexity ratio for a passage that we suspected would be memorized by LLMs, namely, the Gettysburg Address. The Gettysburg Address should appear multiple times in an LLM&#x02019;s training set, and indeed, it showed signs of memorization (Supplementary Fig. <xref rid="MOESM1" ref-type="media">7</xref>). Interestingly, for some LLMs, we know exactly what they were trained on (Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref>). For these models, the distribution of zlib&#x02013;perplexity ratios heavily overlapped for items that we knew were in the training set and for items, including BrainBench, that we knew were not in the training set. We suspect that the overlap may indicate that scientific articles, which are unlikely to repeat in training sets, are stored in LLMs as general patterns, similar to human schemas, supporting performance on tasks requiring generalization (for example, BrainBench). This hypothesis invites future study.</p><p id="Par23">As a final check (<xref rid="Sec11" ref-type="sec">Methods</xref> and Supplementary Fig. <xref rid="MOESM1" ref-type="media">8</xref>), we confirmed that LLMs do not perform better on items published earlier in 2023 (for example, January 2023 versus October 2023), which addresses the concern that early items are more likely to have a preprint or other precursor appear in the training set that affected BrainBench performance. Likewise, an LLM trained from scratch on the published neuroscience literature, in a manner that eliminated any possible overlap between training data and BrainBench, displayed superhuman performance<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. All our checks indicated that BrainBench items were novel for the LLMs.</p></sec></sec><sec id="Sec8"><title>LLMs and human experts are calibrated</title><p id="Par24">To assess whether LLMs&#x02019; predictions are calibrated, we examined how well their confidence tracked their accuracy, a crucial characteristic for a trustworthy prediction system. We estimated LLMs&#x02019; confidence using the ranked absolute difference in perplexities between two abstracts (Fig. <xref rid="Fig2" ref-type="fig">2</xref> and <xref rid="Sec11" ref-type="sec">Methods</xref>) and found that, like human experts, all LLMs exhibited a positive correlation between accuracy and confidence. When LLMs are confident in their decisions, they are more likely to be correct (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). In addition, we fitted logistic regressions between model perplexity differences to their correctness as well as human confidences to their correctness on the individual level. We observed significant positive correlations, confirming both models and humans are calibrated (Supplementary Table <xref rid="MOESM1" ref-type="media">3</xref>).<fig id="Fig4"><label>Fig. 4</label><caption><title>Accuracy and confidence are calibrated for human experts and LLMs.</title><p>When human experts and LLMs are confident in their BrainBench judgements, they are more likely to be correct. Confidence ratings were sorted and placed in equally sized bins with the mean accuracy for items in that bin plotted. The positive slope of the black regression lines for human experts and all LLMs indicates that confidence is well calibrated (that is, higher confidence corresponds to higher accuracy). Calibration is beneficial for building human&#x02013;machine ensembles.</p></caption><graphic xlink:href="41562_2024_2046_Fig4_HTML" id="d33e1309"/></fig></p></sec><sec id="Sec9"><title>Augmenting LLMs with neuroscience knowledge to create BrainGPT</title><p id="Par25">Pre-trained LLMs can provide a foundation for further training in neuroscience with the aim of improving performance, as assessed by BrainBench. We used low-rank adaptation (LoRA)<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> to augment a pre-trained LLM, Mistral-7B-v0.1, with additional neuroscience knowledge.</p><p id="Par26">LoRA is a parameter-efficient fine-tuning technique that inserts low-rank adapter matrices into LLM transformer blocks (Supplementary Fig. <xref rid="MOESM1" ref-type="media">19</xref>) and trains only these LoRA weights to update the model&#x02019;s behaviour. In our case, we fine-tuned Mistral-7B-v0.1 using over 1.3 billion tokens from neuroscience publications spanning 100 journals between 2002 and 2022 (<xref rid="Sec11" ref-type="sec">Methods</xref>), which significantly improved performance by 3% on BrainBench (Fig. <xref rid="Fig5" ref-type="fig">5a</xref>).</p><p id="Par27">LoRA tuning dramatically shifted (<italic>t</italic>(199)&#x02009;=&#x02009;15.7, <italic>P</italic>&#x02009;&#x0003c;&#x02009;0.001, Cohen&#x02019;s <italic>d</italic>&#x02009;=&#x02009;0.25, 95% CI 0.42&#x02013;0.55; two-sided) the perplexity of correct responses (Fig. <xref rid="Fig5" ref-type="fig">5b</xref>), which is indicative of the LLM specializing for neuroscience material. LoRA introduced 629,145,600 new weights, which is 8% of the total number of weights in Mistral-7B-v0.1. These results indicate that BrainGPT models can efficiently be derived by extending existing LLMs.<fig id="Fig5"><label>Fig. 5</label><caption><title>Fine-tuning a pre-trained LLM on neuroscience knowledge.</title><p>Mistral-7B-v0.1 was fine-tuned using LoRA on neuroscience articles from 2002 to 2022 (a total of 1.3 billion tokens). <bold>a</bold>, The fine-tuned model improved by 3% on BrainBench. <bold>b</bold>, The fine-tuning process substantially shifted the perplexity distribution of correct responses, indicative of the LLM specializing in neuroscience.</p></caption><graphic xlink:href="41562_2024_2046_Fig5_HTML" id="d33e1357"/></fig></p></sec></sec><sec id="Sec10" sec-type="discussion"><title>Discussion</title><p id="Par28">We considered whether LLMs can forecast the outcome of neuroscience experiments. By training on the vast scientific literature, we hoped LLMs could build a generative model that captured the patterns underlying neuroscience. To evaluate this possibility, we constructed a new forward-looking (Fig. <xref rid="Fig2" ref-type="fig">2</xref>) benchmark, BrainBench.</p><p id="Par29">BrainBench assesses a test-taker&#x02019;s ability to select which of two versions of a neuroscience abstract contains the actual results of the study (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). We found that LLMs outperform human experts on BrainBench by a considerable margin (Fig. <xref rid="Fig3" ref-type="fig">3a</xref>) across all neuroscience subfields we considered (Fig. <xref rid="Fig3" ref-type="fig">3b</xref>). Moreover, when LLMs indicated high confidence in their predictions, they were more likely to be correct (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). LLMs&#x02019; superior performance arose from their ability to integrate information throughout the abstract, such as text pertaining to the method and study design. When access to such information was removed, LLM performance drastically declined (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>).</p><p id="Par30">We found no indication that LLMs had been exposed to and memorized BrainBench items during their training. Instead, our analyses suggested that LLMs discovered the fundamental patterns that underlie neuroscience studies, which enabled LLMs to predict the outcomes of studies that were novel to them. These conclusions were supported by a widely employed technique<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> to determine text membership within an LLMs&#x02019; training set (Supplementary Fig. <xref rid="MOESM1" ref-type="media">7</xref>). The Galactica<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> LLMs were particularly illuminating because we know which articles were not in the training set versus ones that might be. Interestingly, there was no indication of memorization in models such as Galactica for scientific articles that were in its training set, consistent with the notion that LLMs learn broad patterns underlying scientific fields. While passages that frequently repeat in the training set, such as the Gettysburg Address, may be memorized (Supplementary Fig. <xref rid="MOESM1" ref-type="media">7</xref>), scientific articles that occur infrequently (most likely once) in the training set appear to support LLM&#x02019;s forward-looking predictive abilities. As a final check, we trained a relatively small LLM from scratch<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> on the published neuroscience literature (excluding preprints and BrainBench items), which eliminated any possible overlap between training data and BrainBench, and found superhuman performance on BrainBench (Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref>).</p><p id="Par31">LLM&#x02019;s impressive forward-looking capabilities suggest a future in which LLMs help scientists make discoveries. To be effective, LLMs need to be kept up to date with the rapidly expanding literature. We found that LLMs could efficiently be augmented with neuroscience knowledge using LoRA<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, boosting performance on BrainBench (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). LoRA provides a way to create BrainGPT models by reorienting general-purpose LLMs for use in neuroscience. One can easily imagine a future in which BrainGPT is near continuously updated with new knowledge using LoRA, along with complementary approaches such as retrieval-augmented generation<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. Retrieval-augmented generation could be used to query a database of relevant and up-to-date scientific articles for the task at hand.</p><p id="Par32">In addition to keeping LLMs up to date, benchmarks should routinely be refreshed and expanded to address current needs. One challenge is that creating forward-looking benchmarks, such as BrainBench, is labour intensive and requires human expertise. To address this potential bottleneck, we created and evaluated 100 test cases using GPT-4 through a largely automated process (<xref rid="Sec11" ref-type="sec">Methods</xref>). Although there is room for improvement, these items were close in quality to the human-created ones with 8 of the 100 items being word-for-word matches with the human-created versions. These efforts should pave the way for the rapid creation of other forward-looking benchmarks in neuroscience, as well as benchmarks for other knowledge-intensive fields. We believe high-quality forward-looking benchmarks will be critical to developing LLMs as tools for scientific discovery.</p><p id="Par33">For LLMs to serve as trustworthy and effective tools or to form ensembles with humans<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, LLMs&#x02019; outputs should include indicators of the certainty or confidence levels associated with their predictions. Fortunately, we found that LLMs&#x02019; confidence is well calibrated. When LLMs were confident in their predictions, they were more likely to be correct (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). A second ingredient for effective teams is being diverse or complementary. LLMs have potential here as well, as the items they found difficult did not highly correlate with those human experts found difficult (Supplementary Fig. <xref rid="MOESM1" ref-type="media">6</xref>). These two ingredients, being well calibrated and complementary, allow systems that combine human and machine judgements to outperform either alone<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>,which holds for BrainBench<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>.</p><p id="Par34">All our results, including those for calibrated confidence, were possible only because we had access to LLM weights to calculate the perplexity of passages (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Our approach diverged from the popular approach of prompting models for responses through natural language (that is, chat). Prompting in natural language may yield less reliable judgements and degrade model competency compared with using model probability scores or training separate classifiers directly from internal representations<sup><xref ref-type="bibr" rid="CR28">28</xref>&#x02013;<xref ref-type="bibr" rid="CR31">31</xref></sup>. These observations underscore the importance of working with models that are as open as possible, ideally making both the weights and training set publicly available. Accordingly, we make BrainGPT available on the Huggingface platform (<ext-link ext-link-type="uri" xlink:href="https://huggingface.co/BrainGPT">https://huggingface.co/BrainGPT</ext-link>).</p><p id="Par35">Beyond serving as a tool for neuroscientists, BrainGPT can help reveal the structure of the field. In particular, we can vary BrainGPT&#x02019;s training set and observe the effect on BrainBench. For example, what is the effect of including training data from related fields such as psychology? In terms of supporting prediction, we can quantify how interrelated fields are. Does it help to weight articles in the training set by their recency, citations or impact factor? In addition to these training manipulations, we can vary how testing is conducted. For example, would step-by-step thinking via chain-of-thought reasoning<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> benefit BrainGPT? If prediction in neuroscience is akin to a deductive reasoning process, then it should. If instead, as we suspect, prediction in neuroscience is a function of many noisy intertwined signals across subfields, then chain-of-thought reasoning will not help. BrainGPT and BrainBench can help answer these meta-science questions.</p><p id="Par36">We foresee a future in which LLMs serve as forward-looking generative models of the scientific literature. LLMs can be part of larger systems that assist researchers in determining the best experiment to conduct next. One key step towards achieving this vision is demonstrating that LLMs can identify likely results. For this reason, BrainBench involved a binary choice between two possible results. LLMs excelled at this task, which brings us closer to systems that are practically useful. In the future, rather than simply selecting the most likely result for a study, LLMs can generate a set of possible results and judge how likely each is. Scientists may interactively use these future systems to guide the design of their experiments.</p><p id="Par37">One risk is that scientists do not pursue studies when their predictions run counter to those of an LLM. In some cases, this might be a sensible course of action, whereas in other cases the LLM might have identified potential gaps or errors in the scientific literature. In the latter situation, conducting the study might result in a significant breakthrough. Conversely, a study result that was predicted with high confidence by an LLM might be viewed as an incremental advance.</p><p id="Par38">LLMs&#x02019; predictions are informed by a vast scientific literature that no human could read in their lifetime. As LLMs improve, so should their ability to provide accurate predictions. In this contribution, we focused on neuroscience but our aims are broader; we hope to provide a template for any knowledge-intensive field. None of the approaches we adopted is neuroscience specific. Indeed, the degree of efficacy of our approach may depend on the underlying structure of the domain. For instance, disciplines like mathematics, which rely heavily on logical deduction, might not benefit as much as other scientific fields that involve pattern-based reasoning.</p><p id="Par39">We hope to democratize the use of LLMs in science and increase reproducibility by highlighting the use of relatively small models that can be run locally and whose weights are accessible, which contrasts with commercial products. Finally, while LLMs appear poised to supplant humans at prediction, we foresee a role for human experts in providing the accompanying scientific explanations. Prediction is very important, but not everything.</p></sec><sec id="Sec11"><title>Methods</title><p id="Par40">We confirm that our research complies with all relevant ethical regulations. Experimental Psychology Ethics Board (University College London) approved the study protocol (ethics protocol EP/2017/011). We confirm that informed consent was obtained from all human participants. Participant compensation is not applicable to the current study. None of our studies was pre-registered.</p><sec id="Sec12"><title>Dataset creation</title><p id="Par41">Co-authors (Supplementary Table <xref rid="MOESM1" ref-type="media">5</xref>) and GPT-4 (Azure OpenAI API; version 2023-05-15) created test cases that formed BrainBench. All test cases were sourced from <italic>Journal of Neuroscience</italic> abstracts published in 2023 under the Creative Commons Attribution 4.0 International License (CC-BY). The abstracts are organized into five sections, namely, behavioural/cognitive, systems/circuits, neurobiology of disease, development/plasticity/repair and cellular/molecular. In constructing BrainBench, we incorporated a total of 200 test cases crafted by human experts and an additional 100 test cases generated by GPT-4 (Azure OpenAI API; version 2023-05-15). All test cases were subjected to extensive quality control by human experts and GPT-4. For the distribution of test cases among subfields, refer to Fig. <xref rid="Fig3" ref-type="fig">3</xref> for human-created cases and Supplementary Fig. <xref rid="MOESM1" ref-type="media">23</xref> for GPT-4 generated cases.</p><p id="Par42">To create a test case, a published abstract was modified to create an altered version. The altered version substantially changed the results without changing the methods and background. Minimal changes were made that changed the basic result. For example, the altered abstract, compared with the original, could switch around the role of two brain regions in the results, reverse the direction of a result (for example, replace &#x02018;decreases&#x02019; with &#x02018;increases&#x02019;) and so on. Any changes maintained the coherency of the abstract, which sometimes required multiple changes (for example, replacing multiple &#x02018;decreases&#x02019; with &#x02018;increases&#x02019;). In other words, the altered abstracts needed to be empirically different but not logically incoherent. Both volunteers and GPT-4 are given instructions that follow the essential criteria above. The exact wordings to prompt GPT-4 were slightly adjusted to obtain good-quality test cases. We include the instructions given to GPT-4 verbatim below.</p><sec id="Sec13"><title>GPT-4 test creation prompt</title><p id="Par43">&#x02018;Your task is to modify an abstract from a neuroscience research paper such that the changes significantly alter the result of the study without changing the methods and background. This way we can test the Artificial Intelligence understanding of the abstract&#x02019;s subject area.</p><p id="Par44">Please read the instructions below and ensure you follow them one by one while you are modifying the abstracts:</p><p id="Par45">- The format to submit is putting double brackets around the change with the first element being the original and the second element being your edit. E.g., [[original passage, modified passage]]. Always remember to wrap your edits with the double brackets; there should not be any other edits outside the brackets to the original abstract. - If you change a single word, never wrap the entire sentence inside the double brackets. For example, &#x02018;&#x02026; exhibit [[enhanced LTP and deficits in LTD, impaired LTP and enhanced LTD]].&#x02019; is a wrong format, the correct format is: &#x02018;&#x02026; exhibit [[enhanced, impaired]] LTP and [[deficits, enhanced]] in LTD.&#x02019; - The beginning of an abstract is the background and methods, so you should not alter those parts of the abstract. Do not alter the first couple sentences. - We want the abstract to become empirically wrong, but not logically incoherent. - To find the original result of the paper, one should require some neuroscience insight, not just general reasoning ability. So it is critical that the changes you make don&#x02019;t evaluate the Artificial Intelligence reasoning ability, but its knowledge of neuroscience and how the brain works. - Watch out for making changes that alter the results, but may still have occurred in the authors&#x02019; study. For example, an fMRI abstract on learning might mention the hippocampus and not the striatum. Nevertheless, the striatum might have also been active and not reported in the abstract because it was not the focus of the study. - The changes you make should not be identifiable or decodable from the rest of the abstract. Hence, if you make a change, make sure you change everything that can reveal the original abstract. For example, &#x02018;activation of neurons in the visual cortex [[increases, decreases]] the activity in the motor cortex. This decrease in the activity of the visual cortex was followed by an increase in task performance.&#x02019;. In this case it is very clear that the correct word is &#x02018;decreases&#x02019; as the next sentence (&#x02018;This decrease in the activity of the visual cortex&#x02019;) reveals that. - Be mindful of the article when you change words. For example, if you change the word &#x02018;decline&#x02019; to &#x02018;enhancement&#x02019;, you must change the article as well, so the change will be [[a decline, an enhancement]]. - Ensure that your edits maintain inter-sentence consistency and proper syntax. The changes should not contradict or confuse the overall meaning of the abstract. - Avoid making trivial edits that do not require understanding of scientific concepts. The edits should reflect a deep understanding of the subject matter. - Do not miss any crucial results or findings in the abstract while making the edits. Every significant point should be addressed in your modifications.</p><p id="Par46">To generate better responses, you can use the topic of their study and purpose of studies in those topics. This knowledge helps you to find what modification you should do in the abstract. Topics are: - Behavioral/Cognitive: To understand how the brain influences behavior, cognition, and emotion, and to apply this understanding in diagnosing and treating neurological and psychiatric disorders.</p><p id="Par47">- Cellular/Molecular: To study are to understand the functions and mechanisms of neurons at a cellular and molecular level, which includes investigating the biology of nerve cells, their genetic makeup, and how they form complex circuits, ultimately contributing to our understanding of brain function, behavior, and the development of treatments for neurological disorders.</p><p id="Par48">- Neurobiology of Disease: To understand the biological basis of various neurological and psychiatric disorders in order to develop effective treatments and preventative measures.</p><p id="Par49">- Development/Plasticity/Repair: to understand the mechanisms of brain development, adaptation, and repair in response to injury or disease, with the goal of developing strategies and treatments to enhance brain recovery and function.</p><p id="Par50">- Systems/Circuits: to understand how neural circuits in the brain interact and coordinate to process information, control behavior, and support cognitive functions.</p><p id="Par51">Here are two examples of the edited abstract by human experts which can help you to understand the task:</p><p id="Par52">Example 1: &#x0003c; example_1 &#x0003e;</p><p id="Par53">Example 2: &#x0003c; example_2 &#x0003e;</p><p id="Par54">These are some common mistakes you have made in the past. So keep them in mind whilst generating your responses: - You misunderstood/ignore the information provided at the beginning of the abstract. - The edits you have made are not what we are aiming for, you tweaked a portion of the studies with non-significant findings, so there&#x02019;s no significant alternation of results occurring. Make sure your edit changes the main results of the studies, not trivial changes. - Lack of inter-sentence consistency in the prompt - You made edits as early as the first sentence. THe first few sentence are general knowledge and are not result of the study. So you shouldn&#x02019;t make any change in the beginning. - Most of your edits contradict the conclusion. Make sure your changes do not contradit the conclusions or any part of the abstract. - You only modified verbs the understanding of which does not require understanding of scientific concepts &#x00026; names of compounds, which makes the edits less likely to do wrong as long as reasons logically - One of your edits contradicts all other edits. - Your edit is inconsistent with the beginning of the sentence - You failed to change the first part of the conclusion for consistency - You missed out on one change. - You misunderstood the purpose of the study. Although in the abstract it explicitly states the purpose of the study.</p><p id="Par55">Below, you are given an abstract with its topic. Follow the instructions given to you and return the modified abstract. Remember to use double brackets to show the changes ([[original, modified]] and keep the rest of the abstract unchanged. Also, pay attention to all the information you were given above as well as the common mistakes you have made before.</p><p id="Par56">Abstract to edit: Topic: &#x0003c; abstract_topic &#x0003e;</p><p id="Par57">Abstract: &#x0003c; abstract_to_edit &#x0003e; &#x02019;</p></sec></sec><sec id="Sec14"><title>Evaluations</title><p id="Par58">We tested human participants and LLMs on the BrainBench dataset. Both human experts and models were presented with two versions of the abstract, one with the actual results and one that was altered. The task was to determine which is which. Below, we detail how LLMs and human participants were tested.</p><sec id="Sec15"><title>Model evaluation</title><p id="Par59">We tested LLMs by adapting the Eleuther AI Language Model Evaluation Harness framework<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>, which evaluates LLMs using a multiple choice setting. We presented LLMs with two versions of the abstracts from each test case separately. We prefixed each abstract with the prompt &#x02018;You are a neuroscientist with deep knowledge in neuroscience. Here is an abstract from a neuroscience publication:&#x02019; and applied model-specific instruction templates where appropriate. We then measured the perplexity of both passages and used perplexity as the indicator of whether LLMs favour one abstract or the other.</p><p id="Par60">Perplexity (PPL) is one of the most common metrics for evaluating LLMs. Perplexity measures the degree of uncertainty of a model when generating a particular sequence of text. Formally, perplexity is defined as the exponentiated average negative log-likelihood of a tokenized sequence. If we have a tokenized abstract <italic>X</italic>&#x02009;=&#x02009;(<italic>x</italic><sub>0</sub>, <italic>x</italic><sub>1</sub>, &#x02026;, <italic>x</italic><sub><italic>t</italic></sub>), then the perplexity of <italic>X</italic>, given a LLM parameterized by <italic>&#x003b8;</italic>, is<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{PPL}}(X)=\exp \left\{-\frac{1}{t}\mathop{\sum }\limits_{i}^{t}\log {p}_{\theta }({x}_{i}| {x}_{ &#x0003c; i})\right\},$$\end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi mathvariant="normal">PPL</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munderover><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="41562_2024_2046_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\log {p}_{\theta }({x}_{i}| {x}_{ &#x0003c; i})$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mi>log</mml:mi><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41562_2024_2046_Article_IEq1.gif"/></alternatives></inline-formula> is the log-likelihood of the <italic>i</italic>th token conditioned on the preceding tokens <italic>x</italic><sub>&#x0003c;<italic>i</italic></sub> according to the LLM. Given both the original abstract <italic>X</italic><sub>orig</sub> and the altered abstract <italic>X</italic><sub>alt</sub>, we followed the decision rule<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{{\mathrm{chosen}}}=\left\{\begin{array}{ll}{X}_{{\mathrm{orig}}},\quad &#x00026;\,\text{if}\,\,{\mathrm{PPL}}({X}_{{\mathrm{orig}}}) &#x0003c; {\mathrm{PPL}}({X}_{{\mathrm{alt}}})\\ {X}_{{\mathrm{alt}}},\quad &#x00026;\,\text{otherwise}\,\end{array}\right.$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">chosen</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">orig</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1.0em"/></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>if</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">PPL</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">orig</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:mi mathvariant="normal">PPL</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">alt</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">alt</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1.0em"/></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>otherwise</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41562_2024_2046_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>and evaluated the overall accuracy over the entire BrainBench accordingly.</p><sec id="FPar1"><title>Accuracy</title><p id="Par61">Accuracy is the primary metric for reporting LLM performance on BrainBench. A correct response was when the model produces a lower perplexity for the original abstract than the altered abstract.</p></sec><sec id="FPar2"><title>Confidence calibration</title><p id="Par62">We used the absolute difference of perplexities of two versions of the abstract as a measure of model confidence. To assess the calibration of LLMs, we compared their accuracies with their confidence levels. First, we ranked and sorted model confidence across all test cases. Subsequently, we created 20 bins based on this sort. Within each bin, we calculated the mean accuracy. A well-calibrated model will exhibit a higher accuracy in bins associated with higher confidence rankings. We fit a linear regression model using the bin number as the independent variable and the mean accuracy of each bin as the dependent variable to evaluate calibration.</p></sec><sec id="FPar3"><title>Performance correlation across LLMs</title><p id="Par63">We assessed the correlation in performance among different LLMs by examining how they rank the relative difficulty of test cases. To determine difficulty, we calculated the difference in perplexity between incorrect and correct abstracts for each test case. Intuitively, a large positive difference in the perplexity between incorrect and correct versions of an abstract should indicate that the test case is easy from the LLM&#x02019;s perspective. We calculated the Spearman correlation coefficient of these difficulty measures to assess the agreement between two LLMs.</p></sec><sec id="FPar4"><title>Integration analysis</title><p id="Par64">To investigate the extent to which LLMs can integrate broad context from abstracts, we conducted an experiment involving the removal of contextual information from BrainBench test cases. Following the same evaluation procedure as previously outlined for full abstract cases, we assessed the models using individual sentences extracted from abstracts containing at least one result alternation. In cases with multiple alternations, we computed the mean accuracy across these alternations as the final accuracy for the abstract. We then compared the level of performance degradation when LLMs were evaluated on full-length abstracts versus individual sentences where background and method information from the abstracts was removed.</p><p id="Par65">In addition, we tested models using abstracts whose results (in terms of complete sentences) are randomly swapped from abstracts within the same neuroscience subfield. Importantly, in these &#x02018;swapped&#x02019; abstracts, the number of results remained consistent with the original. We applied the swapping to both original and altered abstracts and reevaluated LLMs&#x02019; performance.</p></sec><sec id="FPar5"><title>LLM training data memorization analysis</title><p id="Par66">One concern regarding LLMs outperforming human experts on BrainBench is the possibility that LLMs were exposed to the original abstracts during their pre-training. If LLMs have simply memorized the training data, they would naturally assign lower perplexity scores to the correct abstracts.</p><p id="Par67">To address this concern, we employed a common method from the literature to determine whether a given text is part of LLM&#x02019;s training data<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR33">33</xref></sup>. This method involves calculating the zlib entropy and the perplexity ratio (equation (<xref rid="Equ3" ref-type="disp-formula">3</xref>)) of a text sequence to infer its membership status:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{ratio}}=\frac{{\mathrm{ZLIB}}(X\;)}{{\mathrm{PPL}}(X\;)}.$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mi mathvariant="normal">ratio</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">ZLIB</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mspace width="0.16em"/></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">PPL</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mspace width="0.16em"/></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="41562_2024_2046_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>Zlib entropy is computed using the zlib text compression algorithm<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>, which measures the level of uncertainty in a text when compressed. It is a data-agnostic way of evaluating text. On the other hand, LLM perplexity depends on the specific training data and, thus, is data dependent. In general, if a piece of text surprises zlib but not LLM, it is probably part of the training data.</p><p id="Par68">To conduct this test, we carefully chose data sources that are either known to be part of LLMs&#x02019; pre-training or reasonably assumed to be excluded from it (refer to Supplementary Tables <xref rid="MOESM1" ref-type="media">1</xref> and <xref rid="MOESM1" ref-type="media">2</xref>). We then applied zlib compression and LLM perplexity calculations to text samples from these selected sources.</p><p id="Par69">In addition, we introduced the Gettysburg Address as a special anchor point to contrast with the zlib&#x02013;perplexity ratio distribution across multiple data sources. This is because we expect the Gettysburg Address to exhibit a high zlib score due to its non-modern form of English, coupled with a low perplexity, given its probably frequent exposure during LLM pre-training.</p><p id="Par70">Finally, we analysed the Spearman correlation between the publication dates of the abstracts that make up BrainBench test cases against the test cases&#x02019; difficulties to LLMs. This was to address the concern that early items are more likely to have a preprint or other precursor appear in the training set memorized by LLMs. If there was memorization, we would expect a negative correlation between publication date and difficulty. We determined difficulty by using the difference in perplexity between incorrect and correct abstracts for each test case.</p></sec></sec><sec id="Sec16"><title>Human evaluation</title><sec id="FPar6"><title>Participants</title><p id="Par71">We recruited 202 neuroscience experts via social media and an email newsletter. We excluded 31 participants for failing to answer both catch trials correctly, not providing confidence or expertise ratings during the entire experiment, and self-reported cheating. The remaining 171 participants consisted of 51 doctoral students, 43 faculty/academic staff, 43 postdoctoral researchers, 18 predoctoral students, 12 research scientists and 4 classified as &#x02018;other&#x02019;. Participants&#x02019; mean experience in neuroscience was 10.1&#x02009;years. Participants identified as follows: 62.5% male, 34.5% female and 0.6% gender variant/non-conforming. The mean age was 35.2&#x02009;years (standard deviation 9.4&#x02009;years).</p></sec><sec id="FPar7"><title>Procedure</title><p id="Par72">First, participants were briefed on the experimental task and provided their informed consent to proceed to the experiment. Demographic information was then collected, including gender identity, age, country, current position and years of experience in neuroscience research, broadly construed. Next, participants completed a practice trial using the same testing format as the actual test cases. This trial was used to familiarize participants with the format of the task, with the screen proceeding only once participants had made the correct choice based on common sense. Following this, nine test trials and two catch trials commenced, where participants selected one version of each trial abstract. Out of the nine test trials, six were randomly sampled human-created test cases and three were randomly sampled from the pool of machine-created items. We ensured that each test case is sampled approximately an equal number of times across all participants. To achieve this, we maintained a global counter that keeps track of how frequently each test case has been used. As a result, the next participant&#x02019;s sample will always be drawn from those test cases that have been used less frequently. Notably, the number of alterations varies between test cases, but the design allowed a single click to automatically select between the two abstract options (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>). Participants made one decision per test case, regardless of the number of alternations.</p><p id="Par73">Subsequently, participants were required to rate their confidence and expertise using slider bars. The confidence slider had a range from &#x02018;lower&#x02019; on the left to &#x02018;higher&#x02019; on the right, while the expertise slider spanned from &#x02018;not at all&#x02019; on the left to &#x02018;very much so&#x02019; on the right, both internally implementing a 1&#x02013;100 scaling. In addition, participants indicated whether they had encountered the study previously before proceeding to the next trial. Upon completing the 11 trials, participants were debriefed on which trials they got correct and were subsequently asked to indicate whether they engaged in any form of cheating during the study. We hosted the study entirely on the Gorilla platform<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>.</p></sec><sec id="FPar8"><title>Exclusion criteria</title><p id="Par74">For participant selection and data analysis, we apply several exclusion criteria. First, individuals who failed to answer both catch trials correctly were not included in the data analyses. Second, participants who did not make adjustments to the sliders (that is, expertise and confidence) during any of the trials were excluded. In addition, trials where participants recognized the abstract content were omitted from the analysis. Furthermore, trials with reaction times less than 5&#x02009;s were excluded. Lastly, participants who admitted to using external resources or engaging in cheating behaviours, as indicated by a checkbox in the debriefing form, were not considered in the final data analysis.</p></sec><sec id="FPar9"><title>Performance correlation between humans and LLMs</title><p id="Par75">We assessed the agreement between humans and LLMs using a similar approach as we did when evaluating the correlation among LLMs. For LLMs, the procedure for determining item difficulty was identical to that described above. For human experts, item difficulty was calculated as the mean accuracy for that item. Finally, the Spearman correlation of these difficulty measures was calculated to assess agreement.</p></sec></sec></sec><sec id="Sec17"><title>Fine-tuning on neuroscience corpora</title><p id="Par76">The LLMs we considered had been pre-training on a diverse range of text corpora, including Internet sources, Wikipedia, books, code repositories and arXiv papers. While these pre-trained models are designed to be versatile and capable of handling various tasks, our approach for creating BrainGPT involved enhancing base models with domain-specific expertise, specifically in neuroscience.</p><p id="Par77">To accomplish this, we employed the LoRA technique (Supplementary Fig. <xref rid="MOESM1" ref-type="media">19</xref> and ref. <sup><xref ref-type="bibr" rid="CR24">24</xref></sup>). LoRA efficiently extends the capabilities of general-purpose LLMs by introducing low-rank trainable parameters (referred to as &#x02018;adapters&#x02019;) into the existing model. This process effectively fine-tunes the model for downstream tasks without the need for prohibitively resource-intensive training of the entire model.</p><sec id="Sec18"><title>Training data</title><p id="Par78">We collected training data from PubMed for abstracts and PubMed Central Open Access Subset (PMC OAS) for full-text articles using the Entrez Programming Utilities (E-utilities) API (application programming interface) and the pubget Python package, respectively. The data span publication dates from 2002 to 2022. For science general journals, we applied a keyword filter of &#x02018;Neuroscience&#x02019; (see all sourced journals in Supplementary Table <xref rid="MOESM1" ref-type="media">4</xref>).</p><p id="Par79">Our data extraction efforts yielded 332,807 abstracts and 123,085 full-text articles, totalling 1.3 billion tokens. We excluded figures and tables and randomly allocated 90% of the data for training, reserving the remaining 10% for validation.</p></sec><sec id="Sec19"><title>Training details</title><p id="Par80">We fine-tuned Mistral-7B-v0.1<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> using weights available on Huggingface (<ext-link ext-link-type="uri" xlink:href="https://huggingface.co/mistralai/Mistral-7B-v0.1">https://huggingface.co/mistralai/Mistral-7B-v0.1</ext-link>). We used a batch size of 1 and a chunk size of 2,048. Training involved the use of the AdamW optimizer<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> with a learning rate of 2&#x02009;&#x000d7;&#x02009;10<sup>&#x02212;5</sup> and gradient accumulation steps set at 8. Two training epochs were performed, along with a warm-up step of 0.03 and a weight decay rate of 0.001. The learning rate was controlled using a cosine learning rate scheduler. LoRA adapters, characterized by a rank of 256, an alpha value of 512 and a dropout rate of 0.1, were applied after all self-attention blocks and fully connected layers. This results in total 629,145,600 trainable parameters, roughly 8% of the entire parameters of the base model. To optimize training performance, bf16 mixed precision training and data parallelism were employed. We used four Nvidia A100 (80&#x02009;GB) graphics processing units hosted on the Microsoft Azure platform. An epoch of training takes roughly 65 graphics processing unit hours.</p></sec><sec id="Sec20"><title>Evaluation</title><p id="Par81">We tested the fine-tuned model on BrainBench using the same procedure as before. To verify the significance of performance improvement, we performed a paired <italic>t</italic>-test with respect to the perplexity of the correct options before and after fine-tuning.</p></sec></sec><sec id="Sec21"><title>Reporting summary</title><p id="Par82">Further information on research design is available in the <xref rid="MOESM2" ref-type="media">Nature Portfolio Reporting Summary</xref> linked to this article.</p></sec></sec><sec id="Sec22" sec-type="supplementary-material"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41562_2024_2046_MOESM1_ESM.pdf"><label>Supplementary Information</label><caption><p>Supplementary Discussion, Tables 1&#x02013;5 and Figs. 1&#x02013;26.</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41562_2024_2046_MOESM2_ESM.pdf"><caption><p>Reporting Summary</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41562-024-02046-9.</p></sec><ack><title>Acknowledgements</title><p>This work was supported the ESRC (ES/W007347/1), Microsoft (Accelerate Foundation Models Research Program) and a Royal Society Wolfson Fellowship (18302) to B.C.L. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript. We thank M. Garvert, P. R. Raamana, T. Hare, Y. Kessler, O. Robinson and D.R. for their assistance. We thank the 202 participants of the online study, including: G. Molinaro, J. Zhu, M. Abdallah, Y. G. Pavlov, J. Lee, A. Harris, Z. Li, R. Kessler, L. Zhang, M. Szul, P. Gupta, S. Bhattacharya, J. Prinsen, C. Gallagher, M. Anes, M. Laroy, T. Ackels, C. Forster, P. Gon&#x000e7;alves, T. Mcconnell, D. Whitmer, D. Kundu, B. Pasquereau, J. Manning, M. Szul, A. Hussain, N. Clairis, I. Vega-V&#x000e1;squez, K. Chen, J. Hogeveen, S. Salehi, S. Duraivel, E. Guevara, Z. Zhang, T. J. Younts, M. Muszy&#x00144;ski, L. Dalla Porta, T. Gureckis, P. Rafei, F.-C. Chou, K. Temple, A. Altunkaya, A. Tan, J. H. Yun, A. Marin-Llobet, B. Lord, D. Lindh, S. Besson-Girard, E. Irmak, E. &#x000c7;elik, A. Maharjan and I. S. Plank.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>X.L. and B.C.L. were responsible for primary writing. Test case creation was handled by B.Y., I.P.B., A.P., T.O., A.O.C., F.Y., E.Y., N.A.R.M., K.L., V.B., S.R., J.M.A., R.M., M.G., G.N., L.L.-K., A.B., K.R.P., M.K., R.R., K.K.N., A.S., J.N., D.M., C.M.H., P.-S.L., S.M., N.E.M., J.K.B., S.D.B., N.G., J.D. and B.C.L. Quality control was conducted by B.Y., K.K.N., D.M., P.-S.L., N.G., C.M.H., K.L., S.M., A.R., N.A.R.M., I.S., G.N., I.P.B., R.M., T.O., M.K., J.M.A., M.G., E.Y., L.L.-K., J.D., J.N., F.Y., R.R., V.B., S.D.B., A.O.C., A.S., X.L. and B.C.L. GPT-4 case creation was managed by K.K.N., X.L. and B.C.L. Human&#x02013;machine teaming involved F.Y., X.L. and B.C.L. LoRA fine-tuning was performed by G.S., X.L. and B.C.L. Model evaluation was executed by X.L., G.S., M.F. and B.C.L. Building the experiment was carried out by A.R., X.L. and B.C.L. Data analysis was done by X.L., A.R. and B.C.L. Conceptualization and strategy were undertaken by X.L. and B.C.L. Figure creation was the work of X.L., B.Y., I.B., C.M.H., G.N. and B.C.L. Useful input and suggestions on the project were provided by all authors. Commenting and editing on the manuscript were also done by all authors. For a table breakdown, see Supplementary Table <xref rid="MOESM1" ref-type="media">5</xref>. X.L., A.R., G.S., K.K.N., F.Y., B.Y. and B.C.L. were major contributors; the other authors are listed in random order.</p></notes><notes notes-type="peer-review"><title>Peer review</title><sec id="FPar10"><title>Peer review information</title><p id="Par83"><italic>Nature Human Behaviour</italic> thanks Andrew Lampinen, Patrick Mineault and Max Pellert for their contribution to the peer review of this work.</p></sec></notes><notes notes-type="data-availability"><title>Data availability</title><p>Human participant data, and intermediate data generated via simulations and analyses, are publicly available via GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/braingpt-lovelab/BrainBench">https://github.com/braingpt-lovelab/BrainBench</ext-link>. Model weights and training data are available at <ext-link ext-link-type="uri" xlink:href="https://huggingface.co/BrainGPT">https://huggingface.co/BrainGPT</ext-link>. Model training data are sourced from PubMed and PubMed Central Open Access Subset (PMC OAS) using the Entrez Programming Utilities (E-utilities) API and the pubget Python package, respectively.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>All computer code associated with this work including model training, evaluation, data processing and analyses are publicly available via GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/braingpt-lovelab/BrainBench">https://github.com/braingpt-lovelab/BrainBench</ext-link>.</p></notes><notes id="FPar11" notes-type="COI-statement"><title>Competing interests</title><p id="Par84">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Bornmann</surname><given-names>L</given-names></name><name><surname>Mutz</surname><given-names>R</given-names></name></person-group><article-title>Growth rates of modern science: a bibliometric analysis based on the number of publications and cited references</article-title><source>J. Assoc. Inf. Sci. Technol.</source><year>2015</year><volume>66</volume><fpage>2215</fpage><lpage>2222</lpage><pub-id pub-id-type="doi">10.1002/asi.23329</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Bornmann, L. &#x00026; Mutz, R. Growth rates of modern science: a bibliometric analysis based on the number of publications and cited references. <italic>J. Assoc. Inf. Sci. Technol.</italic><bold>66</bold>, 2215&#x02013;2222 (2015).</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Chu</surname><given-names>JSG</given-names></name><name><surname>Evans</surname><given-names>JA</given-names></name></person-group><article-title>Slowed canonical progress in large fields of science</article-title><source>Proc. Natl Acad. Sci. USA</source><year>2021</year><volume>118</volume><fpage>e2021636118</fpage><pub-id pub-id-type="doi">10.1073/pnas.2021636118</pub-id><pub-id pub-id-type="pmid">34607941</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Chu, J. S. G. &#x00026; Evans, J. A. Slowed canonical progress in large fields of science. <italic>Proc. Natl Acad. Sci. USA</italic><bold>118</bold>, e2021636118 (2021).<pub-id pub-id-type="pmid">34607941</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Tunyasuvunakool</surname><given-names>K</given-names></name><etal/></person-group><article-title>Highly accurate protein structure prediction for the human proteome</article-title><source>Nature</source><year>2021</year><volume>596</volume><fpage>590</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03828-1</pub-id><pub-id pub-id-type="pmid">34293799</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Tunyasuvunakool, K. et al. Highly accurate protein structure prediction for the human proteome. <italic>Nature</italic><bold>596</bold>, 590&#x02013;596 (2021).<pub-id pub-id-type="pmid">34293799</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhavoronkov</surname><given-names>A</given-names></name><etal/></person-group><article-title>Deep learning enables rapid identification of potent DDR1 kinase inhibitors</article-title><source>Nat. Biotechnol.</source><year>2019</year><volume>37</volume><fpage>1038</fpage><lpage>1040</lpage><pub-id pub-id-type="doi">10.1038/s41587-019-0224-x</pub-id><pub-id pub-id-type="pmid">31477924</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Zhavoronkov, A. et al. Deep learning enables rapid identification of potent DDR1 kinase inhibitors. <italic>Nat. Biotechnol.</italic><bold>37</bold>, 1038&#x02013;1040 (2019).<pub-id pub-id-type="pmid">31477924</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Tshitoyan</surname><given-names>V</given-names></name><etal/></person-group><article-title>Unsupervised word embeddings capture latent knowledge from materials science literature</article-title><source>Nature</source><year>2019</year><volume>571</volume><fpage>95</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1335-8</pub-id><pub-id pub-id-type="pmid">31270483</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Tshitoyan, V. et al. Unsupervised word embeddings capture latent knowledge from materials science literature. <italic>Nature</italic><bold>571</bold>, 95&#x02013;98 (2019).<pub-id pub-id-type="pmid">31270483</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Mok</surname><given-names>RM</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name></person-group><article-title>A multilevel account of hippocampal function in spatial and concept learning: bmodels of behavior and neural assemblies</article-title><source>Sci. Adv.</source><year>2023</year><volume>9</volume><fpage>eade6903</fpage><pub-id pub-id-type="doi">10.1126/sciadv.ade6903</pub-id><pub-id pub-id-type="pmid">37478189</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Mok, R. M. &#x00026; Love, B. C. A multilevel account of hippocampal function in spatial and concept learning: bmodels of behavior and neural assemblies. <italic>Sci. Adv.</italic><bold>9</bold>, eade6903 (2023).<pub-id pub-id-type="pmid">37478189</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinik-Nezer</surname><given-names>R</given-names></name><etal/></person-group><article-title>Variability in the analysis of a single neuroimaging dataset by many teams</article-title><source>Nature</source><year>2020</year><volume>582</volume><fpage>84</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2314-9</pub-id><pub-id pub-id-type="pmid">32483374</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Botvinik-Nezer, R. et al. Variability in the analysis of a single neuroimaging dataset by many teams. <italic>Nature</italic><bold>582</bold>, 84&#x02013;88 (2020).<pub-id pub-id-type="pmid">32483374</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Liu, Y. et al. Summary of ChatGPT/GPT-4 research and perspective towards the future of large language models. <italic>Meta-Radiology</italic>10.1016/j.metrad.2023.100017 (2023).</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Vaswani, A. et al. Attention is all you need. <italic>Advances in Neural Information Processing Systems 30</italic><ext-link ext-link-type="uri" xlink:href="https://papers.nips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://papers.nips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</ext-link> (NIPS, 2017).</mixed-citation></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Fedus</surname><given-names>W</given-names></name><name><surname>Zoph</surname><given-names>B</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name></person-group><article-title>Switch transformers: scaling to trillion parameter models with simple and efficient sparsity</article-title><source>J. Mach. Learn. Res.</source><year>2022</year><volume>23</volume><fpage>1</fpage><lpage>39</lpage></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Fedus, W., Zoph, B. &#x00026; Shazeer, N. Switch transformers: scaling to trillion parameter models with simple and efficient sparsity. <italic>J. Mach. Learn. Res.</italic><bold>23</bold>, 1&#x02013;39 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Srivastava, A. et al. Beyond the imitation game: quantifying and extrapolating the capabilities of language models. <italic>Trans. Mach. Learn. Res.</italic><ext-link ext-link-type="uri" xlink:href="https://openreview.net/pdf?id=uyTL5Bvosj">https://openreview.net/pdf?id=uyTL5Bvosj</ext-link> (2023).</mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Gunasekar, S. et al. Textbooks are all you need. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2306.11644">https://arxiv.org/abs/2306.11644</ext-link> (2023).</mixed-citation></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Strack</surname><given-names>R</given-names></name></person-group><article-title>Visual proteomics</article-title><source>Nat. Methods</source><year>2023</year><volume>20</volume><fpage>1868</fpage><pub-id pub-id-type="doi">10.1038/s41592-023-02104-6</pub-id><pub-id pub-id-type="pmid">38057521</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Strack, R. Visual proteomics. <italic>Nat. Methods</italic><bold>20</bold>, 1868 (2023).<pub-id pub-id-type="pmid">38057521</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Hendrycks, D. et al. Measuring massive multitask language understanding. In <italic>Proc. of the International Conference on Learning Representations</italic><ext-link ext-link-type="uri" xlink:href="https://openreview.net/pdf?id=d7KBjmI3GmQ">https://openreview.net/pdf?id=d7KBjmI3GmQ</ext-link> (ICLR, 2021).</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Jin, Q., Dhingra, B., Liu, Z., Cohen, W. &#x00026; Lu, X. PubMedQA: a dataset for biomedical research question answering. In <italic>Proc. of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</italic> 2567&#x02013;2577 (ACL, 2019).</mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Pal, A., Umapathi, L. K. &#x00026; Sankarasubbu, M. Medmcqa: a large-scale multi-subject multi-choice dataset for medical domain question answering. In <italic>Proc. of Conference on Health, Inference, and Learning</italic> 248&#x02013;260 (PMLR, 2022).</mixed-citation></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>P</given-names></name><etal/></person-group><article-title>Retrieval-augmented generation for knowledge-intensive nlp tasks</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2020</year><volume>33</volume><fpage>9459</fpage><lpage>9474</lpage></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Lewis, P. et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. <italic>Adv. Neural Inf. Process. Syst.</italic><bold>33</bold>, 9459&#x02013;9474 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Taylor, R. et al. Galactica: a large language model for science. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2211.09085">http://arxiv.org/abs/2211.09085</ext-link> (2022).</mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Almazrouei, E. et al. The Falcon series of open language models. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2311.16867">http://arxiv.org/abs/2311.16867</ext-link> (2023).</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Touvron, H. et al. Llama 2: open foundation and fine-tuned chat models. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2307.09288">https://arxiv.org/abs/2307.09288</ext-link> (2023).</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Jiang, A. Q. et al. Mistral 7B. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2310.06825">http://arxiv.org/abs/2310.06825</ext-link> (2023).</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Carlini, N. et al. Extracting training data from large language models. In <italic>Proc. of the 30th USENIX Security Symposium (USENIX Security 21)</italic> 2633&#x02013;2650 (USENIX, 2021).</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Luo, X., Sun, G. &#x00026; Love, B. C. Matching domain experts by training from scratch on domain knowledge. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2405.09395">http://arxiv.org/abs/2405.09395</ext-link> (2024).</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Hu, E. J. et al. LoRA: low-rank adaptation of large language models. In <italic>Proc. of the International Conference on Learning Representations</italic><ext-link ext-link-type="uri" xlink:href="https://openreview.net/pdf?id=nZeVKeeFYf9">https://openreview.net/pdf?id=nZeVKeeFYf9</ext-link> (ICLR, 2022).</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Y&#x000e1;&#x000f1;ez, F., Luo, X., Minero, O. V. &#x00026; Love, B. C. Confidence-weighted integration of human and machine judgments for superior decision-making. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2408.08083">http://arxiv.org/abs/2408.08083</ext-link> (2024).</mixed-citation></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Steyvers</surname><given-names>M</given-names></name><name><surname>Tejeda</surname><given-names>H</given-names></name><name><surname>Kerrigan</surname><given-names>G</given-names></name><name><surname>Smyth</surname><given-names>P</given-names></name></person-group><article-title>Bayesian modeling of human&#x02013;AI complementarity</article-title><source>Proc. Natl Acad. Sci. USA</source><year>2022</year><volume>119</volume><fpage>e2111547119</fpage><pub-id pub-id-type="doi">10.1073/pnas.2111547119</pub-id><pub-id pub-id-type="pmid">35275788</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Steyvers, M., Tejeda, H., Kerrigan, G. &#x00026; Smyth, P. Bayesian modeling of human&#x02013;AI complementarity. <italic>Proc. Natl Acad. Sci. USA</italic><bold>119</bold>, e2111547119 (2022).<pub-id pub-id-type="pmid">35275788</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Y&#x000e1;&#x000f1;ez, F., Luo, X., Minero, O. V., &#x00026; Love, B. C. Confidence-weighted integration of human and machine judgments for superior decision-making. Preprint at <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2408.08083">https://arxiv.org/abs/2408.08083</ext-link> (2024).</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Zheng, L et al. Judging llm-as-a-judge with mt-bench and chatbot arena. In <italic>Proc. of the 37th Conference on Neural Information Processing Systems</italic> 46595&#x02013;46623 (NeurIPS, 2023).</mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Hu, J. &#x00026; Levy, R. Prompting is not a substitute for probability measurements in large language models. In <italic>Proc. of the 2023 Conference on Empirical Methods in Natural Language Processing</italic> 5040&#x02013;5060 (ACL, 2023).</mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Azaria, A. &#x00026; Mitchell, T. The internal state of an LLM knows when it's lying. In <italic>Proc. of the 2023 Conference on Empirical Methods in Natural Language Processing</italic> 967&#x02013;976 (EMNLP, 2023).</mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Gao, L. et al. A framework for few-shot language model evaluation. <italic>Zenodo</italic> 10.5281/zenodo.5371628 (2023).</mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Wei, J. et al. Chain-of-thought prompting elicits reasoning in large language models. In <italic>Proc. of the 36th Conference on Neural Information Processing Systems</italic> 24824&#x02013;24837 (NeurIPS, 2022).</mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Nasr, M. et al. Scalable extraction of training data from (production) language models. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2311.17035">http://arxiv.org/abs/2311.17035</ext-link> (2023).</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Gailly, J. &#x00026; Adler, M. zlib compression library. <italic>University of Cambridge</italic><ext-link ext-link-type="uri" xlink:href="http://www.dspace.cam.ac.uk/handle/1810/3486">http://www.dspace.cam.ac.uk/handle/1810/3486</ext-link> (2024).</mixed-citation></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Anwyl-Irvine</surname><given-names>AL</given-names></name><name><surname>Massonni&#x000e9;</surname><given-names>J</given-names></name><name><surname>Flitton</surname><given-names>A</given-names></name><name><surname>Kirkham</surname><given-names>N</given-names></name><name><surname>Evershed</surname><given-names>JK</given-names></name></person-group><article-title>Gorilla in our midst: an online behavioral experiment builder</article-title><source>Behav. Res. Methods</source><year>2020</year><volume>52</volume><fpage>388</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.3758/s13428-019-01237-x</pub-id><pub-id pub-id-type="pmid">31016684</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Anwyl-Irvine, A. L., Massonni&#x000e9;, J., Flitton, A., Kirkham, N. &#x00026; Evershed, J. K. Gorilla in our midst: an online behavioral experiment builder. <italic>Behav. Res. Methods</italic><bold>52</bold>, 388&#x02013;407 (2020).<pub-id pub-id-type="pmid">31016684</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Loshchilov, I. &#x00026; Hutter, F. Decoupled weight decay regularization. In <italic>Proc. of the International Conference on Learning Representaions</italic><ext-link ext-link-type="uri" xlink:href="https://openreview.net/pdf?id=Bkg6RiCqY7">https://openreview.net/pdf?id=Bkg6RiCqY7</ext-link> (ICLR, 2019).</mixed-citation></ref></ref-list></back></article>