<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Commun Med (Lond)</journal-id><journal-id journal-id-type="iso-abbrev">Commun Med (Lond)</journal-id><journal-title-group><journal-title>Communications Medicine</journal-title></journal-title-group><issn pub-type="epub">2730-664X</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40394272</article-id><article-id pub-id-type="pmc">PMC12092575</article-id>
<article-id pub-id-type="publisher-id">873</article-id><article-id pub-id-type="doi">10.1038/s43856-025-00873-z</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Development and validation of an artificial intelligence-based pipeline for predicting oral epithelial dysplasia malignant transformation</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0969-2990</contrib-id><name><surname>Shephard</surname><given-names>Adam J.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7159-0368</contrib-id><name><surname>Mahmood</surname><given-names>Hanya</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1097-1738</contrib-id><name><surname>Raza</surname><given-names>Shan E. Ahmed</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Ara&#x000fa;jo</surname><given-names>Anna Lu&#x000ed;za Damaceno</given-names></name><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Santos-Silva</surname><given-names>Alan Roger</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Lopes</surname><given-names>Marcio Ajudarte</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Vargas</surname><given-names>Pablo Agustin</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>McCombe</surname><given-names>Kris D.</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Craig</surname><given-names>Stephanie G.</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6945-6060</contrib-id><name><surname>James</surname><given-names>Jacqueline</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Brooks</surname><given-names>Jill</given-names></name><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4664-6117</contrib-id><name><surname>Nankivell</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><name><surname>Mehanna</surname><given-names>Hisham</given-names></name><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><name><surname>Khurram</surname><given-names>Syed Ali</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6760-1271</contrib-id><name><surname>Rajpoot</surname><given-names>Nasir M.</given-names></name><address><email>n.m.rajpoot@warwick.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01a77tt86</institution-id><institution-id institution-id-type="GRID">grid.7372.1</institution-id><institution-id institution-id-type="ISNI">0000 0000 8809 1613</institution-id><institution>Tissue Image Analytics Centre, Department of Computer Science, </institution><institution>University of Warwick, </institution></institution-wrap>Coventry, UK </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05krs5044</institution-id><institution-id institution-id-type="GRID">grid.11835.3e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9262</institution-id><institution>School of Clinical Dentistry, </institution><institution>University of Sheffield, </institution></institution-wrap>Sheffield, UK </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/036rp1748</institution-id><institution-id institution-id-type="GRID">grid.11899.38</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0722</institution-id><institution>Head and Neck Surgery Department and LIM 28, </institution><institution>University of S&#x000e3;o Paulo Medical School, </institution></institution-wrap>S&#x000e3;o Paulo, State of S&#x000e3;o Paulo Brazil </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04cwrbc27</institution-id><institution-id institution-id-type="GRID">grid.413562.7</institution-id><institution-id institution-id-type="ISNI">0000 0001 0385 1941</institution-id><institution>Hospital Israelita Albert Einstein, </institution></institution-wrap>S&#x000e3;o Paulo, State of S&#x000e3;o Paulo Brazil </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04wffgt70</institution-id><institution-id institution-id-type="GRID">grid.411087.b</institution-id><institution-id institution-id-type="ISNI">0000 0001 0723 2494</institution-id><institution>Faculdade de Odontologia de Piracicaba, </institution><institution>Universidade Estadual de Campinas (FOP-UNICAMP), </institution></institution-wrap>Piracicaba, State of S&#x000e3;o Paulo Brazil </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00hswnk62</institution-id><institution-id institution-id-type="GRID">grid.4777.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0374 7521</institution-id><institution>Precision Medicine Centre, Patrick G. Johnston Centre for Cancer Research, </institution><institution>Queen&#x02019;s University Belfast, </institution></institution-wrap>Belfast, UK </aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03angcq70</institution-id><institution-id institution-id-type="GRID">grid.6572.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7486</institution-id><institution>Institute of Head and Neck Studies and Education, Institute of Cancer and Genomic Sciences, </institution><institution>University of Birmingham, </institution></institution-wrap>Birmingham, UK </aff></contrib-group><pub-date pub-type="epub"><day>20</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>20</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>5</volume><elocation-id>186</elocation-id><history><date date-type="received"><day>19</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>14</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">Oral epithelial dysplasia (OED) is a potentially malignant histopathological diagnosis given to lesions of the oral cavity that are at risk of progression to malignancy. Manual grading of OED is subject to substantial variability and does not reliably predict prognosis, potentially resulting in sub-optimal treatment decisions.</p></sec><sec><title>Method</title><p id="Par2">We developed a Transformer-based artificial intelligence (AI) pipeline for the prediction of malignant transformation from whole-slide images (WSIs) of Haematoxylin and Eosin (H&#x00026;E) stained OED tissue slides, named ODYN (<italic>Oral Dysplasia Network</italic>). ODYN can simultaneously classify OED and assign a predictive score (ODYN-score) to quantify the risk of malignant transformation. The model was trained on a large cohort using three different scanners (Sheffield, 358 OED WSIs, 105 control WSIs) and externally validated on cases from three independent centres (Birmingham and Belfast, UK, and Piracicaba, Brazil; 108 OED WSIs).</p></sec><sec><title>Results</title><p id="Par3">Model testing yielded an F1-score of 0.96 for classification of dysplastic vs non-dysplastic slides, and an AUROC of 0.73 for malignancy prediction, gaining comparable results to clinical grading systems.</p></sec><sec><title>Conclusions</title><p id="Par4">With further large-scale prospective validation, ODYN promises to offer an objective and reliable solution for assessing OED cases, ultimately improving early detection and treatment of oral cancer.</p></sec></abstract><abstract id="Abs2" abstract-type="plain-language-summary"><title>Plain language summary</title><p id="Par5">Oral epithelial dysplasia (OED) is a condition where cells in the mouth show abnormal changes that could lead to cancer. The standard method of diagnosis involves looking at a tissue sample (biopsy) under a microscope. However, this method of diagnosis and prediction of cancer risk can be uncertain, resulting in differences in interpretation. In this study, we developed a computer-based tool called &#x0201c;ODYN&#x0201d; to help improve both diagnosis and cancer risk prediction. ODYN examines images of biopsy samples, identifies abnormal areas, and calculates a score that estimates the risk of cancer development. We show that this tool has similar accuracy to the conventional diagnostic criteria, without human involvement. With further testing, ODYN could provide a more objective way to assess OED, helping doctors make better treatment decisions and improving early cancer detection.</p></abstract><abstract id="Abs3" abstract-type="web-summary"><p id="Par6">Shephard, Mahmood et al. present an AI-based model for diagnosing oral epithelial dysplasia and predicting progression to malignancy. The model is trained and evaluated on a large multicentre dataset, shows similar performance to pathologist-assigned grading and highlights the potential prognostic significance of peri-epithelial lymphocytes.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Oral cancer detection</kwd><kwd>Oral cancer detection</kwd><kwd>Prognostic markers</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000289</institution-id><institution>Cancer Research UK (CRUK)</institution></institution-wrap></funding-source><award-id>C63489/A29674</award-id><award-id>C63489/A29674</award-id><award-id>C63489/A29674</award-id><principal-award-recipient><name><surname>Shephard</surname><given-names>Adam J.</given-names></name><name><surname>Khurram</surname><given-names>Syed Ali</given-names></name><name><surname>Rajpoot</surname><given-names>Nasir M.</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000272</institution-id><institution>DH | National Institute for Health Research (NIHR)</institution></institution-wrap></funding-source><award-id>NIHR300904</award-id><principal-award-recipient><name><surname>Mahmood</surname><given-names>Hanya</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution>The S&#x000e3;o Paulo Research Foundation (2021/14585-7).</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par7">Oral epithelial dysplasia (OED) presents a significant challenge in the realm of oral pathology, where accurate diagnosis and early detection are paramount for effective intervention and prevention of malignant progression. OED is a potentially malignant histopathological diagnosis encompassing various lesions of the oral mucosa, typically manifesting as white (leukoplakia), red (erythroplakia) or mixed red-white (erythroleukoplakia) lesions<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>.</p><p id="Par8">Histopathological grading of Haematoxylin and Eosin (H&#x00026;E) stained tissue using the World Health Organisation (WHO, 2017<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>) classification system remains the current accepted practice for diagnosis and risk stratification of OED lesions. This is a three-tier system for grading OED into mild, moderate and severe grades based on the presence, severity and location of a wide range of cytological and architectural histological features (28 in total<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>). By its nature, this approach suffers from significant intra- and inter-observer variability and has poor predictive value for malignant transformation risk, potentially impacting on patient management. An alternate binary grading system, categorising lesions as low- or high-risk, based on the number of cytological and architectural features (as listed in the WHO criteria) aimed to improve the reproducibility of grading<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup>. However, studies have shown significant variability and unreliability in grading using both systems, highlighting the need for more objective and reproducible methods that can better predict malignant transformation risk in OED<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>.</p><p id="Par9">To address challenges in subjectivity and misclassification of precancerous and cancerous lesions, there is a growing interest in leveraging advanced technologies, particularly deep learning (DL), which has seen extensive use in medical image analysis over the past decade<sup><xref ref-type="bibr" rid="CR10">10</xref>&#x02013;<xref ref-type="bibr" rid="CR12">12</xref></sup>. Several state-of-the-art models, such as U-Net<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> and DeepLab<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, have been developed to perform image classification and segmentation. These models typically use convolutional neural networks (CNN), such as ResNet<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, as feature extractors. Within digital pathology, weakly supervised methods have became popular choices for the analysis of histology images, enabling slide-level classification based on patch-level predictions. These methods typically divide WSIs into smaller patches, before using CNNs to extract patch-level features<sup><xref ref-type="bibr" rid="CR16">16</xref>&#x02013;<xref ref-type="bibr" rid="CR18">18</xref></sup>. However, despite their success, CNN-based models have limitations such as high computational overhead and difficulty in capturing long-range dependencies in images, when being used for either segmentation or classification.</p><p id="Par10">Transformers have gained widespread attention in recent years as they have been successfully applied in several natural language processing and computer vision tasks such as classification<sup><xref ref-type="bibr" rid="CR19">19</xref>&#x02013;<xref ref-type="bibr" rid="CR21">21</xref></sup>. A typical Transformer encoder consists of a multi-head self-attention (MSA) layer, a multi-layer perceptron (MLP), and a layer normalisation (LN). The MSA layer empowers Transformers to capture long-range dependencies, making them a strong candidate for semantic segmentation in medical images<sup><xref ref-type="bibr" rid="CR22">22</xref>&#x02013;<xref ref-type="bibr" rid="CR24">24</xref></sup>. Transformers, therefore, have the potential to overcome some of the limitations of traditional CNNs. However, only a handful of methods have applied Transformers for semantic segmentation in medical images<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR25">25</xref></sup>. Their application in histology has primarily been constrained to classification tasks<sup><xref ref-type="bibr" rid="CR26">26</xref>,<xref ref-type="bibr" rid="CR27">27</xref></sup>, with semantic segmentation left relatively unexplored. This raises the question of whether Transformers can be harnessed for semantic segmentation of histological images.</p><p id="Par11">In this study, we aimed to develop a weakly supervised, DL pipeline that could reliably and objectively segment and classify OED, whilst predicting the risk of malignant transformation in OED, using WSIs of H&#x00026;E-stained OED slides. Specifically, we achieve this using interpretable nuclear features from dysplastic regions on the WSI. Moreover, we conduct a rigorous evaluation of the performance of our pipeline by comparing it to other state-of-the-art methods. To demonstrate the robustness and generalisability of our approach, we have developed our model using a large cohort with extended validation on unseen datasets acquired from three national and international centres (Birmingham and Belfast, UK, and Piracicaba, Brazil).</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Study cohorts</title><sec id="Sec4"><title>Development and internal validation cohort</title><p id="Par12">The training cohort consists of a retrospective sample of histology tissue sections (dating 2008 to 2016, with minimum five-year follow-up data) collected from the Oral and Maxillofacial Pathology archive at the School of Clinical Dentistry, University of Sheffield, UK (referred to as the internal centre, hereafter). During the process of case selection, a Consultant Pathologist (SAK) conducted an initial microscopic inspection of the archived diagnostic slides to confirm the suitability of each case for inclusion. Newly cut 4&#x02009;&#x000b5;m sections of the selected cases were obtained from the original formalin fixed paraffin embedded blocks and stained with H&#x00026;E for analysis. The collection, retrieval and staining of sections were conducted between 2020 and 2023 by the same clinicians using standardised protocols, ensuring consistency in slide preparation.</p><p id="Par13">A purposive sampling method was employed, selecting consecutive cases from the pathology archive within the specified time period. In total, 509 slides were collected from 406 patients. The slides were digitised to high-resolution WSIs at 40&#x000d7; objective power using one of three scanners: NanoZoomer S360 (Hamamatsu Photonics, Japan; 0.2258 mpp), Aperio CS2 (Leica Biosystems, Germany; 0.2520 mpp), Pannoramic 1000 (P1000, 3DHISTECH Ltd, Hungary; 0.2426 mpp). Inclusion criteria required sufficient epithelial tissue, high-quality staining, and complete follow-up data (42 cases did not meet these criteria). Exclusion criteria included cases with ulceration, overlying candidal infection, HPV-related OED, or verrucous lesions (based on morphology on H&#x00026;E). Cases with clinical oral lichen planus (OLP) or coincidental OLP were also excluded. Cases with insufficient tissue, poor staining quality, or incomplete follow-up data were also excluded. Care was taken to ensure a reasonable mix of grades were included.</p><p id="Par14">The resulting cohort comprised 358 WSIs (<italic>n</italic>&#x02009;=&#x02009;277 patients) with a confirmed histological diagnosis of OED and 105 WSIs (<italic>n</italic>&#x02009;=&#x02009;81 patients) confirmed as non-dysplastic (controls). Due to incomplete follow-up data for five patients with OED (7 WSIs), these cases were only used for algorithm training and excluded from clinical outcome analysis. Thus, the final cohort included 351 WSIs (<italic>n</italic>&#x02009;=&#x02009;272 patients) with confirmed diagnosis of OED of which 64 patients (79 WSIs) exhibited malignant transformation. Slides from the same subjects were assigned to the same fold during algorithm training/testing. An overview of the dataset and a CONSORT diagram are given in the Supplementary Information (Table&#x000a0;<xref rid="MOESM2" ref-type="media">S1</xref> and Fig.&#x000a0;<xref rid="MOESM2" ref-type="media">S1</xref>, respectively).</p><p id="Par15">Clinical follow-up data for the OED cohort included patient age (at time of diagnosis), sex, intraoral site, OED grade (using binary and WHO 2017 systems) and transformation status. Transformation was defined as the progression of a dysplastic lesion to OSCC at the same clinical site within the follow-up period, and transformation time was measured in months. To ensure diagnostic consistency, all cases were evaluated by at least two certified pathologists (PMS, PMF, DJB, KH), who provided an initial diagnosis based on the WHO grading system (between 2008&#x02013;2016). To confirm the WHO (2017) grade and assign binary grades, the cases were blindly re-evaluated by SAK and a clinician with a specialist interest and expertise in OED analysis (HM).</p><p id="Par16">Amongst the 358 OED WSIs, HM exhaustively delineated regions of interest (ROI) representative of dysplasia in a large subset of 260 OED WSIs, using in-built annotation tools in the QuPath&#x000ae; software<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. Of the 105 non-dysplastic control WSIs, HM additionally manually delineated the entire epithelium in a subset of 96 WSIs<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>.</p></sec><sec id="Sec5"><title>Independent validation cohorts</title><p id="Par17">The ODYN model was tested on three external datasets acquired from:<list list-type="simple"><list-item><label>i.</label><p id="Par18">Precision Medicine Centre, Patrick G. Johnston Centre for Cancer Research, Queen&#x02019;s University Belfast, UK (47 WSIs)</p></list-item><list-item><label>ii.</label><p id="Par19">Institute of Head and Neck Studies and Education, Institute of Cancer and Genomic Sciences, University of Birmingham, UK (42 WSIs)</p></list-item><list-item><label>iii.</label><p id="Par20">Oral Diagnosis Department, Semiology and Oral Pathology Areas, Piracicaba Dental School University of Campinas (UNICAMP), S&#x000e3;o Paulo, Brazil (19 WSIs)</p></list-item></list></p><p id="Par21">Owing to the limited size of these datasets, we combined them into a single multi-institutional external test set. Prior to the inclusion of external cases in the study, all WSIs were checked for suitability. Slides of poor quality, insufficient epithelium and cases positive for Candida Albicans or suggestive of Human Papilloma Virus infection were excluded. The WSI cohorts from Birmingham and Belfast were scanned at 40&#x000d7; objective power using a Pannoramic 250 (P250, 3DHISTECH Ltd., Hungary; 0.1394 mpp) and Aperio AT2 (Leica Biosystems, Germany; 0.2529 mpp) whole-slide scanner, respectively, to obtain digital WSIs. The Piracicaba cases were scanned at 20&#x000d7; objective power by an Aperio CS (Leica Biosystems, Germany; 0.4928 mpp) scanner. The same clinical follow-up information was collected as that for the development/internal cohort. The external dataset did not include any control cases. Due to incomplete follow-up data for three patients with OED (3 WSIs), these cases were only used for algorithm validation and excluded from clinical outcome analysis. Thus, the final cohort included 105 WSIs (from 105 patients), amongst which 44 patients (44 WSIs) exhibited malignant transformation. A summary of this cohort and a CONSORT diagram are provided in the Supplementary Information (Table&#x000a0;<xref rid="MOESM2" ref-type="media">S1</xref> and Fig.&#x000a0;<xref rid="MOESM2" ref-type="media">S1</xref>, respectively). For model training, HM exhaustively delineated ROIs of dysplasia in 30 cases each from both Birmingham and Belfast, and an additional 18 cases from Piracicaba, using the QuPath&#x000ae; software.</p></sec><sec id="Sec6"><title>Inclusion and ethics statement</title><p id="Par22">Ethical approval for the study was obtained from the NHS Health Research Authority West Midlands (18/WM/0335), and experiments were conducted in compliance with the Declaration of Helsinki. Data collected was fully anonymised. Written consent was not required as data was collected from surplus archived tissue.</p></sec></sec><sec id="Sec7"><title>Analytical workflow</title><sec id="Sec8"><title>Dysplasia segmentation</title><p id="Par23">Since dysplastic changes may not be widespread across the entire tissue section in a slide, the first step of developing the DL pipeline involved identification and localisation of the dysplastic tissue regions for semantic segmentation. To achieve this, we trained a Transformer, based on Trans-UNet<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, to automatically detect and segment the different dysplastic regions in each WSI across the training dataset. The model processes input images of size 512&#x02009;&#x000d7;&#x02009;512 (at 1.0 micron per pixel, mpp, resolution) and outputs a dysplasia segmentation map. Manually annotated ROIs were used as ground truth during training, focusing on areas with confirmed dysplasia in OED cases and the entire epithelium in non-dysplastic controls. These large ROIs typically spanned the entire tissue section in a slide, encompassing both annotated dysplastic epithelium and normal epithelium where present.</p><p id="Par24">For internal model testing, the dataset was split at 80/20, and controlled for both scanner type and OED grade. This resulted in 206 OED and 75 non-dysplastic control WSIs in the training set, and 54 OED and 21 non-dysplastic control WSIs in the internal testing set, with ground truth annotations. Note, a higher proportion of controls were kept in the test set to ensure high specificity of OED segmentation in the non-dysplastic control sample. After tessellating the WSIs and region masks into smaller patches (512&#x02009;&#x000d7;&#x02009;512 pixels, 184 pixels overlap, 10&#x000d7; magnification, 1.0 mpp), a total of 19,063 OED and 11,756 non-dysplastic patches were generated for model training/validation on the internal discovery cohort. This totalled 6,341 patches with ground truth annotations from the 78 WSIs in the external cohort. Various stain augmentation algorithms were tested during the development of the final model, using the TIAToolbox<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>.</p></sec><sec id="Sec9"><title>OED Classification</title><p id="Par25">A pretrained CNN-based HoVer-Net+<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup> model was used to segment the epithelium and the individual nuclei across each WSI. To classify OED, the proportion of the epithelium mask (generated by HoVer-Net+) that was segmented as dysplastic (using Trans-UNet) was calculated. This proportion, referred to as the dysplasia-epithelium ratio (R<sub>Epith</sub>), was used to classify slides as dysplastic vs. non-dysplastic, based on an empirically determined threshold.</p><p id="Par26">The threshold for R<sub>Epith</sub> was selected based on its ability to achieve the highest classification performance (measured by F1-score and AUROC) on the training set of 281 WSIs used for training the Trans-UNet dysplasia segmentation model. This threshold was subsequently validated, internally on the remaining 182 WSIs from Sheffield, and externally on all 108 WSIs. For transparency, the distribution of R<sub>Epith</sub> values across different OED grades and transformation outcomes was analysed, and boxplots were generated to illustrate these distributions.</p><p id="Par27">HoVer-Net+ was used solely for inference in this task and was not further fine-tuned, given its state-of-the-art performance in epithelium and nuclear segmentation and classification. The model has been extensively pre-trained on OED data<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>, which ensured its robustness and reliability for this application.</p></sec><sec id="Sec10"><title>Malignant transformation prediction (ODYN-scoring)</title><p id="Par28">The WSIs were tessellated into smaller patches (512&#x02009;&#x000d7;&#x02009;512 pixels, with 256 pixels overlap at 0.5 mpp) using tissue in the dysplastic regions alone. The nuclear segmentations from HoVer-Net+ were used to generate a total of 168 nuclear-based morphological and spatial features for each (dysplastic) patch. See the Supplementary Information, pp 7, for a list of the features used. These patch-level features were used as input to an MLP to calculate a risk-score for malignant transformation (ODYN-score). Thus, the ODYN-score indicated whether the algorithm predicted the case to have transformed (high-risk) or not transformed (low-risk). The MLP model had three layers with 168 nodes in the input layer, 64 nodes in the hidden layer, and 2 nodes in the output layer. It used a leaky ReLU activation function and dropout (0.2) after the hidden layer. The MLP was trained by Monte Carlo iterative-draw-and-rank sampling (IDaRS<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>), using a symmetric cross-entropy loss function and the Adam optimiser. This loss function was chosen as it has been shown previously to help overcome errors associated with weak labels<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR32">32</xref></sup>. IDaRS sampling was performed with parameter values of <italic>k</italic>&#x02009;=&#x02009;5 for top predictive patches and <italic>r</italic>&#x02009;=&#x02009;45 random patches, using a batch size of 256. On inference, the trained MLP calculated a prediction score for each patch in the dysplastic regions of the WSI, which can be considered the likelihood of a tile belonging to the positive class in the classification task (i.e. transformation). Slide-level scores were then obtained by taking the average prediction score across the top 50% ranked tiles. We used nuclear features with the aim of making the model interpretable. However, we additionally provided comparison to a ResNet34 classifier (trained with Macenko stain augmentation), using deep features, to show the impact on performance (see Supplementary Information, Table&#x000a0;<xref rid="MOESM2" ref-type="media">S3</xref>).</p></sec></sec><sec id="Sec11"><title>Statistics and reproducibility</title><p id="Par29">For the evaluation of OED segmentation, on both internal and external testing, large ROIs centred on the annotated tissue section were generated. Dysplasia segmentation performance (aggregated across all ROIs) was measured by calculating the F1-score, Recall and Precision. For internal testing of controls, a single measure of specificity for OED segmentation was reported, since a single incorrectly predicted pixel (e.g. incorrectly predicted as OED), would result in an F1-score, Recall, and Precision values of 0; thus, not giving an accurate representation of the model performance. For the evaluation of OED classification (dysplastic vs non-dysplastic) the F1-score, Recall, and Precision across all slides were measured. An area under the receiving operating characteristic (AUROC) score was also calculated for internal testing.</p><p id="Par30">We used repeated five-fold cross-validation in our ODYN-scoring internal experiments based on the internal cohort. For each fold of cross-validation, we held one fold back for testing, and used the remaining four folds with a 90/10 split of data for training/validation. Experiments were repeated three times with random seeds. We then tested our model externally, by evaluating each model from internal cross-validation (i.e. all 15 folds) on the external data, and ensembling their predictions.</p><p id="Par31">For the evaluation of the ODYN-scoring pipeline, we provide an AUROC score and an area under the precision-recall curve (AUPRC) score across all slides. Survival analyses were additionally conducted to assess the prognostic significance of the ODYN-score in predicting transformation-free survival. Kaplan-Meier curves were generated, and log-rank tests were used to determine the statistical significance of grading (for ODYN-score, WHO and binary grades). We used concordance index (C-index) to measure the rank correlation between predicted risk scores and patients&#x02019; survival time. The reported C-index is the mean over each repeat of the experiment, whilst the <italic>p</italic>-value is calculated by two times the median <italic>p</italic>-value (from the log-rank test) over all repeats, to get a conservative estimate. A multivariate Cox proportional hazards model was employed, incorporating the ODYN-score, sex and age (and lesion site for internal testing), to predict transformation-free survival. We additionally performed this analysis using the binary and WHO grades in place of the ODYN-score for further comparison. Transformations were right censored at eight years across these analyses to ensure consistency between internal and external cohorts. We used the hazard ratio (HR) and <italic>p</italic>-value output from the multivariate analyses as further metrics for evaluation. For reporting, we focus on the <italic>p</italic>-value from the multivariate analyses, being a more conservative and robust estimate. However, for completeness we also provide the log-rank <italic>p</italic>-value with the Kaplan-Meier curves.</p><p id="Par32">Finally, we generated nuclear counts and area ratios in the ten top-ranked tiles (as correctly predicted by iterative draw and rank sampling for ODYN-scoring). For nuclear counts, we studied dysplastic epithelial nuclei, normal epithelial nuclei, &#x02018;other&#x02019; nuclei from within the epithelium (i.e. intra-epithelial lymphocytes, IELs), and &#x02018;other&#x02019; nuclei outside the epithelium (i.e. peri-epithelial lymphocytes, PELs). For area ratios, we studied the ratio of the patch that was &#x02018;other&#x02019; tissue, dysplastic epithelium, and normal epithelium. We used Shapiro-Wilk tests to check for normality in counts/areas in each analyses. We then performed two-tail Mann-Whitney U tests (with false discovery rate, FDR correction for multiple comparisons) between patches from cases that ODYN correctly predicted to transform vs does not transform, to determine statistical significance. We additionally calculated effect sizes for these tests (rank-biserial correlation coefficient <italic>r</italic><sub><italic>rb</italic></sub>).</p></sec><sec id="Sec12"><title>Reporting summary</title><p id="Par33">Further information on research design is available in the&#x000a0;<xref rid="MOESM6" ref-type="media">Nature Portfolio Reporting Summary</xref> linked to this article.</p></sec></sec><sec id="Sec13" sec-type="results"><title>Results</title><p id="Par34">In this retrospective multi-centric study, we propose an innovative weakly supervised method for predicting the progression of OED lesions to malignancy. We additionally aimed to produce a model that classifies oral tissue slides as being dysplastic vs non-dysplastic. We achieved this by analysing H&#x00026;E-stained WSIs obtained from oral tissue biopsies, using a CNN, a Transformer and an MLP, in what we have called our Oral DYsplasia Network, 'ODYN' (see Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>).<fig id="Fig1"><label>Fig. 1</label><caption><title>Overview of the ODYN pipeline.</title><p>The top left panel shows the study data, whilst the top right panel shows an overview of the ODYN pipeline. The first stage (bottom left) takes an input oral tissue WSI and segments various tissue/cell types. This is done via HoVer-Net+ for epithelial and nuclei segmentation, and Trans-UNet to locate the dysplastic areas of the slide. The second step (bottom middle) diagnoses the input tissue as OED or normal by calculating the ratio of the epithelium that is predicted to be dysplastic. If this is above a threshold (found on model training), then the slide is classified as OED. Finally, the third stage (bottom right) gives a prognosis, i.e. predicts whether the case will become cancerous. To do this, we generate patch-level nuclear features within the dysplastic regions alone and use these within a multi-layer perception (MLP) to predict malignant transformation.</p></caption><graphic xlink:href="43856_2025_873_Fig1_HTML" id="d33e619"/></fig></p><sec id="Sec14"><title>Dysplasia segmentation</title><p id="Par35">In many cases of OED, histological atypia is not present across the entire tissue section, and thus, the first step of this work was to identify only the regions where dysplastic changes were present. We trained a Transformer (based on Trans-UNet<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>) to detect and segment the different dysplastic areas in each WSI. Internal testing of the ODYN dysplasia segmentation model demonstrated an F1-score of 0.81 (Recall&#x02009;=&#x02009;0.85, Precision&#x02009;=&#x02009;0.77) on OED cases and a specificity of 1.00 on non-dysplastic controls. On external testing, the ODYN model achieved a F1-score of 0.71 (Recall&#x02009;=&#x02009;0.76, Precision =&#x02009;&#x02009;0.66). Further, stain augmentation (ODYN-SA, in Supplementary Information, Table&#x000a0;<xref rid="MOESM2" ref-type="media">S2</xref>) did not improve model performance. The results of the ODYN model were superior to that of other state-of-the-art methods including U-Net<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, HoVer-Net+<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>, DeepLabV3+<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, Efficient-UNet<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>, and Swin-UNet<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> (see Supplementary Information, Table&#x000a0;<xref rid="MOESM2" ref-type="media">S2</xref>). Examples of dysplasia segmentation heatmaps are shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>.<fig id="Fig2"><label>Fig. 2</label><caption><title>Dysplasia segmentation heatmap using the ODYN model.</title><p><bold>a</bold> Severe OED (binary grade: high-risk) which transformed; <bold>b</bold> Mild OED (binary grade: low-risk) which did not transform. The green line depicts the ground truth dysplasia segmentation.</p></caption><graphic xlink:href="43856_2025_873_Fig2_HTML" id="d33e674"/></fig></p></sec><sec id="Sec15"><title>OED classification</title><p id="Par36">Next, we used a pretrained CNN, HoVer-Net+<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>, to simultaneously segment the epithelium and segment/classify nuclear instances in WSIs. For OED classification, we calculate the proportion of the epithelium mask (output from HoVer-Net+) that was segmented as dysplastic (output from the dysplasia segmentation Trans-UNet model). We used an empirically determined threshold to classify slides as being dysplastic vs. non-dysplastic. On internal testing, we achieved an F1-score of 0.96 (AUROC&#x02009;=&#x02009;0.93, Recall = 0.94, Precision = 0.97). The performance remained high on external testing, gaining an F1-score = 0.96 (Recall = 0.93, Precision = 1.00), showing the robustness and generalisability of the proposed method.</p><p id="Par37">To further explore the variability of R<sub>Epith</sub>, we analysed its distribution across OED grades and transformation outcomes. Boxplots illustrating these distributions can be seen in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, providing additional insights into how this threshold correlates with prognostic outcomes. Shapiro-Wilk tests found the score to be not normally distributed across internal (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and external (<italic>p</italic>&#x02009;=&#x02009;0.01) testing. To compare these scores across cases, for transformation status and binary grade, we used non-parametric Mann-Whitney U tests with rank-biserial correlation coefficient <italic>r</italic><sub><italic>rb</italic></sub>, as effect size. For the WHO grade, we used Spearman&#x02019;s corelation <italic>&#x003c1;</italic>, with <italic>p</italic>-values calculated via permutation tests. Unless otherwise specified, all continuous variables are reported as medians (M) with interquartile ranges (IQR).<fig id="Fig3"><label>Fig. 3</label><caption><title>The distribution of dysplasia-epithelium ratios across OED cases based on transformation and grade.</title><p>Boxplots showing the distribution of dysplasia-epithelium ratios in OED cases according to: transformation status (left), where transforming cases are red and not transforming are cyan; binary grade (middle), where low-risk cases are cyan and high-risk cases are red; and WHO grade (right), where mild cases are cyan, moderate orange, and severe are red. The top row (<bold>a</bold>) is for internal testing and the bottom row (<bold>b</bold>) is for external testing.</p></caption><graphic xlink:href="43856_2025_873_Fig3_HTML" id="d33e726"/></fig></p><p id="Par38">On internal testing, we found the R<sub>Epith</sub> to be significantly associated with transformation (non-transformed: M&#x02009;=&#x02009;0.26 (IQR&#x02009;=&#x02009;0.17&#x02013;0.35); transformed: 0.39 (0.24&#x02013;0.55); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;0.34, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), binary grade (low-risk: 0.24 (0.15&#x02013;0.33); high-risk: 0.36 (0.26&#x02013;0.52); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;0.42, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), and WHO grade (<italic>&#x003c1;</italic>&#x02009;=&#x02009;0.44, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Similarly on external testing, R<sub>Epith</sub> was significantly associated with transformation (non-transformed: 0.20 (0.15&#x02013;0.32); transformed: 0.35 (0.22&#x02013;0.45); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;0.37, <italic>p</italic>&#x02009;=&#x02009;0.001), binary grade (low-risk: 0.19 (0.13&#x02013;0.31); high-risk: 0.32 (0.18&#x02013;0.44); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;0.36, <italic>p</italic>&#x02009;=&#x02009;0.002), and WHO grade (<italic>&#x003c1;</italic>&#x02009;=&#x02009;0.31, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p></sec><sec id="Sec16"><title>Malignant transformation prediction</title><p id="Par39">We generated patch-level morphological features in the dysplastic regions of OED cases, which were used as input to an MLP to calculate a risk-score for malignancy progression (the ODYN-score). On internal cross-validation, we attained an AUROC of 0.71 for predicting malignant transformation, which remained relatively constant on external validation, rising to 0.73 (see Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). These scores are competitive to existing clinical grading systems including WHO (2017) and binary grades. However, it must be noted that the binary grading system had a higher AUPRC of 0.72 when compared to the ODYN-score. For a complete evaluation, we also compared our ODYN-score to the other grading systems through a survival analysis (see Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). On internal testing, our ODYN-score gained a comparable C-index of 0.66 and hazard ratio of 3.86, when compared to the other grading systems, and was shown to be significant (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). On external testing, the ODYN-score (C-index = 0.63) again attained comparable performance to both the binary grading system (C-index = 0.62) and WHO grading system (G1 stratification; C-index = 0.61), with all three being significant. The ODYN-score continues to surpass the WHO G2 stratification in terms of C-index and hazard ratio on both internal and external testing. Overall, these results show the prognostic significance and utility of the ODYN-score, being comparable to that of a pathologist&#x02019;s binary grade for predicting transformation-free survival.<fig id="Fig4"><label>Fig. 4</label><caption><title>Kaplan-Meier transformation-free survival curves.</title><p>Internal testing is on the left and external testing is on the right. The top row (<bold>a</bold>, <bold>b</bold>) is WHO grade G1 (i.e. Mild vs Moderate/Severe OED), second row (<bold>c</bold>, <bold>d</bold>) is WHO grade G2 (i.e. Mild/Moderate vs Severe OED), followed by the Binary grade (<bold>e</bold>, <bold>f</bold>) and the ODYN-score (<bold>g</bold>, <bold>h</bold>). Confidence intervals supplied are generated by the standard deviation of the model output over repeated runs of the experiment. All cases are right censored at eight years (96 months).</p></caption><graphic xlink:href="43856_2025_873_Fig4_HTML" id="d33e829"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Slide-level results for transformation prediction</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th colspan="5">Internal Validation</th><th colspan="5">External Validation</th></tr><tr><th>Model</th><th>AUROC</th><th>AUPRC</th><th>HR</th><th><italic>p</italic></th><th>C-Index</th><th>AUROC</th><th>AUPRC</th><th>HR</th><th><italic>p</italic></th><th>C-Index</th></tr></thead><tbody><tr><td>WHO grade G1</td><td>0.67 (0.03)</td><td><bold>0.63 (0.07)</bold></td><td><bold>9.16 [3.68</bold><bold>&#x02013;22.80]</bold></td><td><bold>&#x0003c;0.001</bold></td><td>0.66 (0.00)</td><td>0.65 (0.00)</td><td><bold>0.72 (0.00)</bold></td><td>2.43 [1.12&#x02013;5.29]</td><td>0.025</td><td>0.61 (0.00)</td></tr><tr><td>WHO grade G2</td><td>0.61 (0.06)</td><td>0.47 (0.11)</td><td>2.71 [1.73&#x02013;4.26]</td><td><bold>&#x0003c;0.001</bold></td><td>0.62 (0.00)</td><td>0.57 (0.00)</td><td>0.59 (0.00)</td><td>1.62 [0.82&#x02013;3.19]</td><td>0.164</td><td>0.56 (0.00)</td></tr><tr><td>Binary grade</td><td><bold>0.73 (0.05)</bold></td><td>0.62 (0.07)</td><td>6.03 [3.63&#x02013;10.01]</td><td><bold>&#x0003c;0.001</bold></td><td><bold>0.71 (0.00)</bold></td><td>0.68 (0.00)</td><td><bold>0.72 (0.00)</bold></td><td>2.84 [1.36&#x02013;5.92]</td><td>0.005</td><td>0.62 (0.00)</td></tr><tr><td>ODYN-score</td><td>0.71 (0.07)</td><td>0.43 (0.12)</td><td>3.86 [2.04&#x02013;7.69]</td><td><bold>&#x0003c;0.001</bold></td><td>0.66 (0.01)</td><td><bold>0.73 (0.05)</bold></td><td>0.67 (0.05)</td><td><bold>2.95 [1.44</bold><bold>&#x02013;6.02]</bold></td><td><bold>0.003</bold></td><td><bold>0.63 (0.04)</bold></td></tr></tbody></table><table-wrap-foot><p>Best values in bold.</p><p>Here, WHO grade G1 is mild vs moderate/severe cases, whilst WHO grade G2 is mild/moderate vs severe cases. For AUROC, AUPRC and C-Index, the mean value is given with the standard deviation in brackets. For the hazard ratio, HR, we additionally provide the 95% confidence interval in square brackets.</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec17"><title>Feature analysis</title><p id="Par40">For our feature analysis, we compared both nuclear counts and area ratio in the top ten patches from cases that ODYN predicted to transform (i.e. true positives, TPs) against those correctly predicted to not transform (i.e. true negatives, TNs). This analysis was performed on the external data alone, and boxplots are given in the Supplementary Information, Fig.&#x000a0;<xref rid="MOESM2" ref-type="media">S2</xref>. The nuclear counts and area ratios were found to not be normally distributed by Shapiro-Wilk tests (all <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), and thus we used non-parametric Mann-Whitney U tests in the following analyses with a rank-biserial correlation coefficient <italic>r</italic><sub><italic>rb</italic></sub> effect size. Unless otherwise specified, all continuous variables are reported as medians (M) with interquartile ranges (IQR).</p><p id="Par41">The nuclear count analysis found a significantly higher number of &#x02018;other&#x02019; nuclei within the non-epithelial tissue (TN: M&#x02009;=&#x02009;56 (IQR&#x02009;=&#x02009;24&#x02013;104); TP: 183 (93&#x02013;254); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;0.63, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), in TPs when compared to TNs. It also showed a significantly higher number of &#x02018;other&#x02019; nuclei within the epithelium (i.e. intra-epithelial lymphocytes, IELs) in TNs when compared to TPs, however with a weak effect size (TN: 16 (8&#x02013;29); TP: 8 (0&#x02013;25); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;&#x02212;0.27, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). It also displayed a significantly higher number of both dysplastic epithelial nuclei (TN: 128 (85&#x02013;163); TP: 29 (0&#x02013;94); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;&#x02212;0.65, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and normal epithelial nuclei (TN: 39 (12&#x02013;72); TP: 0 (0&#x02013;17); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;&#x02212;0.63, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) within TNs when compared to TPs. The area ratio analysis found a significantly higher number of &#x02018;other&#x02019; tissue in TPs when compared to TNs (TN: 0.13 (0.03&#x02013;0.32); TP: 0.63 (0.20&#x02013;0.97); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;0.59, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Finally, it also showed a significantly higher number of both dysplastic epithelium (TN: 0.15 (0.05&#x02013;0.26); TP: 0.04 (0.00&#x02013;0.17); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;&#x02212;0.36, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and normal epithelium (TN: 0.36 (0.19&#x02013;0.56); TP: 0.05 (0.00&#x02013;0.36); <italic>r</italic><sub><italic>rb</italic></sub>&#x02009;=&#x02009;&#x02212;0.49, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) within TNs compared to TPs.</p></sec></sec><sec id="Sec18" sec-type="discussion"><title>Discussion</title><p id="Par42">Several studies have explored the application of machine learning, including DL, to study OED. The general focus of these methods has been to segment the epithelium (and the nuclei), either manually or via DL models<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup>. These segmentations have then been used in further DL models to predict grade or transformation<sup><xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup> or for pathologist-curated features based on digital images<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>. However, no previous studies have fully integrated segmentation of dysplastic regions into a unified pipeline to further classify OED cases and predict their malignant transformation.</p><p id="Par43">In this study, we introduce ODYN, a Transformer-based pipeline that integrates OED segmentation, classification and malignant transformation prediction into a single automated framework. Unlike previous studies, which focus on individual tasks such as segmentation or transformation prediction, ODYN combines these steps into a unified workflow. This pipeline has been developed using the largest and most diverse multicentric OED dataset to date, digitised using six different scanners. The results obtained through rigorous testing and validation demonstrate the effectiveness of our models in various aspects of OED analysis. We highlight that ODYN is the first model to specifically focus on dysplasia segmentation for downstream prediction of malignant transformation, a key clinical outcome in OED.</p><p id="Par44">The ODYN dysplasia segmentation performance has consistently outperformed other state-of-the-art DL models. We found only one other study to attempt dysplasia segmentation in OED<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. The authors used a DeepLabV3+ model and evaluated it at the patch level on moderate/severe cases from a single centre. Our study improved on this, using a new Transformer-based architecture evaluated at the WSI-level on all types of OED (mild, moderate and severe) from multiple centres, gaining higher F1-scores. Furthermore, the ODYN model has demonstrated good generalisability across external unseen datasets, indicating its robustness and applicability in diverse clinical settings. This highlights the potential of Transformer-based architectures in accurately delineating regions of dysplasia in H&#x00026;E-stained WSIs of oral epithelial tissue and reinforces the clinical value of ODYN&#x02019;s unified pipeline. However, while non-dysplastic controls were included in internal testing to comprehensively assess the dysplasia detector&#x02019;s performance, non-dysplastic control cases were unavailable for external testing, and we acknowledge this as a limitation of our study. Despite this, ODYN&#x02019;s ground-breaking approach has the potential to redefine the landscape of OED diagnosis by providing more precise and consistent results.</p><p id="Par45">ODYN has also demonstrated promising results for OED classification. In this study, we used the predicted dysplastic proportion of the epithelium in a WSI to determine a diagnosis of OED. We chose this method to classify a WSI as dysplastic, rather than classifying a WSI as dysplastic solely based on the presence of any predicted dysplasia. We made this choice because our model predictions often included small areas of false positives. This decision to define a threshold proved to be successful on both internal and external testing. The high precision and recall achieved in classifying OED indicate the potential for automated diagnosis, which has the potential to increase diagnostic efficiency. Moreover, the dysplasia-epithelium ratio (R<sub>Epith</sub>) showed strong correlations with clinically relevant outcomes, including OED grade and transformation status. This highlights its potential not only as a diagnostic tool but also as a prognostic biomarker, further underscoring the utility of ODYN in clinical practice.</p><p id="Par46">The application of ODYN-produced segmentation maps in predicting malignant transformation represents a significant advancement in computational pathology. Notably, this approach outperforms the <italic>OMTscoring</italic> pipeline proposed by Shephard et al.<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> with a substantial improvement in AUROC score (see Supplementary Information, Table&#x000a0;<xref rid="MOESM2" ref-type="media">S3</xref> for comparative results). However, some comments must be made regarding model performance on external testing. Despite the AUROC and AUPRC remaining high for ODYN, there was a substantial drop in C-index. This drop was also seen for the WHO and binary grades, suggesting that this may be attributed to differences between internal and external datasets (i.e. a domain shift). An analysis of the data used for external testing showed a substantially different transformation-free survival rate for external centres. We see only 23% of cases to transform on internal testing. In contrast, nearly 42% of cases transformed in the external cohorts. This variation in the number of events is a clear indication of a type II prior (domain) shift between internal and external cohorts<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> (see Supplementary Information, Fig.&#x000a0;<xref rid="MOESM2" ref-type="media">S3</xref>, for Kaplan-Meier transformation-free survival curves), and is the clinical reality of retrospective cohorts.</p><p id="Par47">Further, on external validation, low-risk ODYN cases demonstrated a 22% malignant transformation rate, highlighting a potential limitation of the model. While the ODYN-score primarily relies on cytonuclear features of atypia, recent evidence suggests that architectural changes, often overlooked in traditional dysplasia grading, play a critical role in predicting malignant transformation<sup><xref ref-type="bibr" rid="CR40">40</xref>,<xref ref-type="bibr" rid="CR41">41</xref></sup>. These findings align with reports that lesions with minimal cytonuclear atypia but significant architectural abnormalities can carry a comparable risk of progression as those with pronounced cytonuclear changes. Future models could be enhanced by incorporating architectural features to improve prognostic accuracy.</p><p id="Par48">The provided approach offers a significant level of explainability; a crucial aspect for translating computational models to clinical practice. Our model used morphological/spatial features within (and around) dysplastic areas to generate a prediction, thus emulating the features used by the pathologist in OED grading. Our feature analysis allowed the exploration of different nuclear types within dysplastic vs normal epithelium. These analyses showed, unsurprisingly perhaps, that more dysplastic nuclei were present in the patches that were predicted to transform (vs not transform). Corroborating this, they additionally showed cases that were correctly predicted to not transform to have more normal epithelial tissue (and nuclei). Moreover, cases that transformed exhibited increased &#x02018;other&#x02019; nuclei in the connective tissue. We posit that this elevated density of &#x02018;other&#x02019; nuclei around the epithelium within transforming cases likely indicates the presence of peri-epithelial lymphocytes (PELs). Furthermore, emerging evidence from Bashir et al.<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> highlights a higher density of PELs in cases undergoing malignant transformation. These findings align with previous research, noting increased immune cell infiltration in tongue lesions progressing to OSCC<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> and identifying distinct immune-related subtypes in moderate and severe OED<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>.</p><p id="Par49">We believe that the application of cutting-edge DL techniques, such as the ODYN pipeline, has huge translational potential which could help improve the accuracy and objectivity of OED diagnosis and grading. By fully integrating segmentation, classification, and transformation prediction in a single pipeline, ODYN simplifies clinical workflows while providing robust results. In addition to this, AI-based pipelines can improve prognostic reliability for prediction of cancer risk to improve patient outcomes. Future research should explore the scalability of the ODYN model to accommodate a broader range of oral conditions (such as those which can mimic OED) and tissue variations to assess whether it can accurately discriminate OED from other similar appearing conditions whilst still accurately predicting malignancy risk. This will enhance the clinical utility of the model and ultimately help provide more personalised patient care.</p><p id="Par50">The authors acknowledge challenges and opportunities for future research based on this study. A potential challenge highlighted by this work is the need to address the interpretability of DL models in clinical practice. We have therefore used an interpretable model for transformation prediction that considers known histological features (e.g. shape and size variations of nuclei) to generate predictions from dysplastic ROIs. We provide heatmaps for each slide to help explain model decisions. We believe such approaches can enhance trust and acceptance amongst healthcare professionals.</p><p id="Par51">We acknowledge that strict inclusion criteria were necessary to ensure data quality and reliability for model training. However, we recognise that this approach may limit immediate clinical translation. Future validation in larger and more heterogeneous datasets, including cases with minor artefacts is required. Future work could also explore the incorporation of automated methods to identify and manage such issues, potentially reducing attrition while preserving data quality. These steps will help address the balance between ensuring robust model training and achieving broader clinical applicability.</p><p id="Par52">The authors additionally acknowledge limitations related to the retrospective nature of the study. It would have been of interest to further explore the model performance for predicting OED recurrence. However, as there is no standardised treatment protocol for OED, there may have been variations in patient management between centres, and it is also difficult to reliably know the difference between true recurrence and field change. We would have additionally liked to incorporate social risk factors (e.g. smoking, alcohol consumption) in the multivariable modelling, however, it was not possible to acquire consistent information between the different centres. These issues could be addressed by a future prospective validation study. Despite this, the external validation of our models across multiple centres and scanners is a notable strength of this study. Future research could explore the application of ODYN in even more diverse clinical settings and expand its utility to other histopathological tasks beyond OED analysis. We suggest testing the method on other head and neck precancerous lesions, such as laryngeal dysplasia, as an interesting future direction of research.</p><p id="Par53">In conclusion, our study signifies a substantial leap forward in the field of digital oral pathology, offering a powerful tool in ODYN for the detection, segmentation, and classification of OED, which we have made publicly available. This technology, underpinned by DL and Transformer-based architectures, showcases the potential of computational pathology to revolutionise the diagnosis and management of OED. The model&#x02019;s exceptional performance in both internal and external testing, along with its ability to improve transformation prediction, underscores its potential to impact clinical practice positively. By addressing challenges and continuing to refine the model, we envision ODYN playing an important role in improving the diagnosis and management of OED and potentially other head and neck precancerous lesions in the future.</p></sec><sec id="Sec19" sec-type="supplementary-material"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="43856_2025_873_MOESM1_ESM.pdf"><caption><p>Transparent Peer Review file</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="43856_2025_873_MOESM2_ESM.docx"><caption><p>Supplementary Information</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="43856_2025_873_MOESM3_ESM.docx"><caption><p>Description of Additional Supplementary Files</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM4"><media xlink:href="43856_2025_873_MOESM4_ESM.xlsx"><caption><p>Supplementary Data 1</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM5"><media xlink:href="43856_2025_873_MOESM5_ESM.xlsx"><caption><p>Supplementary Data 2</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM6"><media xlink:href="43856_2025_873_MOESM6_ESM.pdf"><caption><p>REPORTING SUMMARY</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>These authors contributed equally: Adam J. Shephard, Hanya Mahmood.</p></fn><fn><p>These authors jointly supervised this work: Syed Ali Khurram, Nasir M. Rajpoot.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s43856-025-00873-z.</p></sec><ack><title>Acknowledgements</title><p>This study was supported by a Cancer Research UK Early Detection Project Grant, as part of the ANTICIPATE study (grant no. C63489/A29674) in addition to funding from the National Institute for Health Research (award no. NIHR300904). ALDA was funded by The S&#x000e3;o Paulo Research Foundation (grant no. 2021/14585-7). The authors express their gratitude to Professor Paul Speight (PMS), Professor Paula Farthing (PMF), Dr Daniel Brierley (DJB), and Professor Keith Hunter (KH) for their valuable contribution in providing the initial histological diagnoses. The authors would additionally like to thank Dr Mark Eastwood for his help with the visualisation of cases (and their segmentations) on the tiademos server (<ext-link ext-link-type="uri" xlink:href="https://tiademos.dcs.warwick.ac.uk/">https://tiademos.dcs.warwick.ac.uk/</ext-link>).</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>A.S., Hanya M., S.E.A.R., S.A.K. and N.M.R. designed the study with the help of all co-authors. A.S., Hanya M. and N.M.R. developed the computational methods. A.S. wrote the code and carried out all the experiments. Hanya M. and S.A.K. provided the WSI annotations. S.A.K. and Hanya M. obtained the ethical approval and retrieved the histological and clinical data from Sheffield. K.M., S.C. and J.J. contributed to the collection of the histological and clinical data from Belfast. J.B., P.N. and Hisham M. contributed to the collection of the histological and clinical data from Birmingham. A.L.D.A., A.R.S.S., M.A.L., P.A.V. contributed to the collection of the histological and clinical data from Piracicaba, Brazil. All authors contributed to the writing of the manuscript.</p></notes><notes notes-type="peer-review"><title>Peer review</title><sec id="FPar1"><title>Peer review information</title><p id="Par54"><italic>Communications Medicine</italic> thanks Elisabeth Bloemena and Oscar Maiques for their contribution to the peer review of this work. [Peer review reports are available.]</p></sec></notes><notes notes-type="data-availability"><title>Data availability</title><p>We are unable to share the whole slide images and clinical data due to restrictions in the ethics applications. The source data for Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> is found within Supplementary Data&#x000a0;<xref rid="MOESM4" ref-type="media">1</xref>, and for Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> is in Supplementary Data&#x000a0;<xref rid="MOESM5" ref-type="media">2</xref>.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>In the spirit of reproducibility, we have made the inference code for our pipeline available online, with model weights<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>.</p></notes><notes id="FPar2" notes-type="COI-statement"><title>Competing interests</title><p id="Par55">N.M.R. is the co-founder, CEO and CSO, and a shareholder of Histofy Ltd. He is also the GSK Chair of Computational Pathology and is in receipt of research funding from GSK and AstraZeneca. S.A.K. is a shareholder of Histofy Ltd. All other authors have no competing interests to declare.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Speight</surname><given-names>PM</given-names></name><name><surname>Khurram</surname><given-names>SA</given-names></name><name><surname>Kujan</surname><given-names>O</given-names></name></person-group><article-title>Oral potentially malignant disorders: risk of progression to malignancy</article-title><source>Oral. Surg. Oral. Med. Oral. Pathol. Oral. Radiol.</source><year>2018</year><volume>125</volume><fpage>612</fpage><lpage>627</lpage><pub-id pub-id-type="doi">10.1016/j.oooo.2017.12.011</pub-id><pub-id pub-id-type="pmid">29396319</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Speight, P. M., Khurram, S. A. &#x00026; Kujan, O. Oral potentially malignant disorders: risk of progression to malignancy. <italic>Oral. Surg. Oral. Med. Oral. Pathol. Oral. Radiol.</italic><bold>125</bold>, 612&#x02013;627 (2018).<pub-id pub-id-type="pmid">29396319</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Speight</surname><given-names>PM</given-names></name></person-group><article-title>Update on oral epithelial dysplasia and progression to cancer</article-title><source>Head. Neck Pathol.</source><year>2007</year><volume>1</volume><fpage>61</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1007/s12105-007-0014-5</pub-id><pub-id pub-id-type="pmid">20614284</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Speight, P. M. Update on oral epithelial dysplasia and progression to cancer. <italic>Head. Neck Pathol.</italic><bold>1</bold>, 61&#x02013;66 (2007).<pub-id pub-id-type="pmid">20614284</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">El-Naggar, A. K., Chan, J. K., Grandis, J. R. &#x00026; Others. <italic>WHO classification of head and neck tumours</italic>. (2017).</mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">WHO Classification of Tumours Editorial Board. <italic>Head and neck tumours [Internet]</italic>. (International Agency for Research on Cancer, 2024).</mixed-citation></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>S</given-names></name><name><surname>Tilakaratne</surname><given-names>WM</given-names></name></person-group><article-title>Update from the 5th edition of the World Health Organization classification of head and neck tumors: tumours of the oral cavity and mobile tongue</article-title><source>Head. Neck Pathol.</source><year>2022</year><volume>16</volume><fpage>54</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1007/s12105-021-01402-9</pub-id><pub-id pub-id-type="pmid">35312982</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Muller, S. &#x00026; Tilakaratne, W. M. Update from the 5th edition of the World Health Organization classification of head and neck tumors: tumours of the oral cavity and mobile tongue. <italic>Head. Neck Pathol.</italic><bold>16</bold>, 54&#x02013;62 (2022).<pub-id pub-id-type="pmid">35312982</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Kujan</surname><given-names>O</given-names></name><etal/></person-group><article-title>Evaluation of a new binary system of grading oral epithelial dysplasia for prediction of malignant transformation</article-title><source>Oral. Oncol.</source><year>2006</year><volume>42</volume><fpage>987</fpage><lpage>993</lpage><pub-id pub-id-type="doi">10.1016/j.oraloncology.2005.12.014</pub-id><pub-id pub-id-type="pmid">16731030</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Kujan, O. et al. Evaluation of a new binary system of grading oral epithelial dysplasia for prediction of malignant transformation. <italic>Oral. Oncol.</italic><bold>42</bold>, 987&#x02013;993 (2006).<pub-id pub-id-type="pmid">16731030</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Kujan</surname><given-names>O</given-names></name><etal/></person-group><article-title>Why oral histopathology suffers inter-observer variability on grading oral epithelial dysplasia: an attempt to understand the sources of variation</article-title><source>Oral. Oncol.</source><year>2007</year><volume>43</volume><fpage>224</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1016/j.oraloncology.2006.03.009</pub-id><pub-id pub-id-type="pmid">16931119</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Kujan, O. et al. Why oral histopathology suffers inter-observer variability on grading oral epithelial dysplasia: an attempt to understand the sources of variation. <italic>Oral. Oncol.</italic><bold>43</bold>, 224&#x02013;231 (2007).<pub-id pub-id-type="pmid">16931119</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Odell</surname><given-names>E</given-names></name><name><surname>Kujan</surname><given-names>O</given-names></name><name><surname>Warnakulasuriya</surname><given-names>S</given-names></name><name><surname>Sloan</surname><given-names>P</given-names></name></person-group><article-title>Oral epithelial dysplasia:recognition, grading and clinical significance</article-title><source>Oral. Dis.</source><year>2021</year><volume>27</volume><fpage>1947</fpage><lpage>1976</lpage><pub-id pub-id-type="doi">10.1111/odi.13993</pub-id><pub-id pub-id-type="pmid">34418233</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Odell, E., Kujan, O., Warnakulasuriya, S. &#x00026; Sloan, P. Oral epithelial dysplasia:recognition, grading and clinical significance. <italic>Oral. Dis.</italic><bold>27</bold>, 1947&#x02013;1976 (2021).<pub-id pub-id-type="pmid">34418233</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Nankivell</surname><given-names>P</given-names></name><etal/></person-group><article-title>The binary oral dysplasia grading system: validity testing and suggested improvement</article-title><source>Oral. Surg. Oral. Med. Oral. Pathol. Oral. Radiol.</source><year>2013</year><volume>115</volume><fpage>87</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.oooo.2012.10.015</pub-id><pub-id pub-id-type="pmid">23217539</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Nankivell, P. et al. The binary oral dysplasia grading system: validity testing and suggested improvement. <italic>Oral. Surg. Oral. Med. Oral. Pathol. Oral. Radiol.</italic><bold>115</bold>, 87&#x02013;94 (2013).<pub-id pub-id-type="pmid">23217539</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Litjens</surname><given-names>G</given-names></name><etal/></person-group><article-title>A survey on deep learning in medical image analysis</article-title><source>Med. Image Anal.</source><year>2017</year><volume>42</volume><fpage>60</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1016/j.media.2017.07.005</pub-id><pub-id pub-id-type="pmid">28778026</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Litjens, G. et al. A survey on deep learning in medical image analysis. <italic>Med. Image Anal.</italic><bold>42</bold>, 60&#x02013;88 (2017).<pub-id pub-id-type="pmid">28778026</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Madabhushi</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>G</given-names></name></person-group><article-title>Image analysis and machine learning in digital pathology: Challenges and opportunities</article-title><source>Med. Image Anal.</source><year>2016</year><volume>33</volume><fpage>170</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/j.media.2016.06.037</pub-id><pub-id pub-id-type="pmid">27423409</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Madabhushi, A. &#x00026; Lee, G. Image analysis and machine learning in digital pathology: Challenges and opportunities. <italic>Med. Image Anal.</italic><bold>33</bold>, 170&#x02013;175 (2016).<pub-id pub-id-type="pmid">27423409</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Litjens</surname><given-names>G</given-names></name><etal/></person-group><article-title>Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis</article-title><source>Sci. Rep.</source><year>2016</year><volume>6</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1038/srep26286</pub-id><pub-id pub-id-type="pmid">28442746</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Litjens, G. et al. Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis. <italic>Sci. Rep.</italic><bold>6</bold>, 1&#x02013;11 (2016).<pub-id pub-id-type="pmid">28442746</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Ronneberger, O., Fischer, P. &#x00026; Brox, T. U-net: Convolutional networks for biomedical image segmentation. in <italic>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics</italic>) 9351 234&#x02013;241 (2015).</mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K. &#x00026; Yuille, A. L. Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs. in <italic>International Conference on Learning Representations (ICLR)</italic>10.1109/TPAMI.2017.2699184 (2015).</mixed-citation></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group><article-title>Identity mappings in deep residual networks</article-title><source>Lect. Notes Comput. Sci.</source><year>2016</year><volume>9908 LNCS</volume><fpage>630</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-46493-0_38</pub-id></element-citation><mixed-citation id="mc-CR15" publication-type="journal">He, K., Zhang, X., Ren, S. &#x00026; Sun, J. Identity mappings in deep residual networks. <italic>Lect. Notes Comput. Sci.</italic><bold>9908 LNCS</bold>, 630&#x02013;645 (2016).</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Bilal</surname><given-names>M</given-names></name><etal/></person-group><article-title>Development and validation of a weakly supervised deep learning framework to predict the status of molecular pathways and key mutations in colorectal cancer from routine histology images: a retrospective study</article-title><source>Lancet Digit. Heal.</source><year>2021</year><volume>3</volume><fpage>e763</fpage><lpage>e772</lpage><pub-id pub-id-type="doi">10.1016/S2589-7500(21)00180-1</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Bilal, M. et al. Development and validation of a weakly supervised deep learning framework to predict the status of molecular pathways and key mutations in colorectal cancer from routine histology images: a retrospective study. <italic>Lancet Digit. Heal.</italic><bold>3</bold>, e763&#x02013;e772 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Kather</surname><given-names>JN</given-names></name><etal/></person-group><article-title>Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer</article-title><source>Nat. Med.</source><year>2019</year><volume>25</volume><fpage>1054</fpage><lpage>1056</lpage><pub-id pub-id-type="doi">10.1038/s41591-019-0462-y</pub-id><pub-id pub-id-type="pmid">31160815</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Kather, J. N. et al. Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer. <italic>Nat. Med.</italic><bold>25</bold>, 1054&#x02013;1056 (2019).<pub-id pub-id-type="pmid">31160815</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Campanella</surname><given-names>G</given-names></name><etal/></person-group><article-title>Clinical-grade computational pathology using weakly supervised deep learning on whole slide images</article-title><source>Nat. Med.</source><year>2019</year><volume>25</volume><fpage>1301</fpage><lpage>1309</lpage><pub-id pub-id-type="doi">10.1038/s41591-019-0508-1</pub-id><pub-id pub-id-type="pmid">31308507</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Campanella, G. et al. Clinical-grade computational pathology using weakly supervised deep learning on whole slide images. <italic>Nat. Med.</italic><bold>25</bold>, 1301&#x02013;1309 (2019).<pub-id pub-id-type="pmid">31308507</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Dosovitskiy, A. et al. <italic>An image is worth 16x16 words: transformers for image recognition at scale</italic>. (ICLR, 2020).</mixed-citation></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><etal/></person-group><article-title>Transformers in medical image analysis</article-title><source>Intell. Med.</source><year>2023</year><volume>3</volume><fpage>59</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.imed.2022.07.002</pub-id></element-citation><mixed-citation id="mc-CR20" publication-type="journal">He, K. et al. Transformers in medical image analysis. <italic>Intell. Med.</italic><bold>3</bold>, 59&#x02013;78 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Vaswani, A. et al. Attention is all you need. in <italic>Advances in Neural Information Processing Systems</italic> vols 2017-Decem 5999&#x02013;6009 (2017).</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Chen, J. et al. TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation. <italic>arXiv</italic> 1&#x02013;13 (2021).</mixed-citation></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Dai</surname><given-names>Y</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name></person-group><article-title>TransMed: transformers advance multi-modal medical image classification</article-title><source>Diagnostics</source><year>2021</year><volume>11</volume><fpage>1384</fpage><pub-id pub-id-type="doi">10.3390/diagnostics11081384</pub-id><pub-id pub-id-type="pmid">34441318</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Dai, Y., Gao, Y. &#x00026; Liu, F. TransMed: transformers advance multi-modal medical image classification. <italic>Diagnostics</italic><bold>11</bold>, 1384 (2021).<pub-id pub-id-type="pmid">34441318</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>A</given-names></name><etal/></person-group><article-title>DS-TransUNet: dual swin transformer U-Net for medical image segmentation</article-title><source>IEEE Trans. Instrum. Meas.</source><year>2022</year><volume>71</volume><fpage>1</fpage><lpage>13</lpage></element-citation><mixed-citation id="mc-CR24" publication-type="journal">Lin, A. et al. DS-TransUNet: dual swin transformer U-Net for medical image segmentation. <italic>IEEE Trans. Instrum. Meas.</italic><bold>71</bold>, 1&#x02013;13 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>H</given-names></name><etal/></person-group><article-title>Swin-Unet: Unet-like pure transformer for medical image segmentation</article-title><source>Lect. Notes Comput. Sci.</source><year>2023</year><volume>13803 LNCS</volume><fpage>205</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1007/978-3-031-25066-8_9</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Cao, H. et al. Swin-Unet: Unet-like pure transformer for medical image segmentation. <italic>Lect. Notes Comput. Sci.</italic><bold>13803 LNCS</bold>, 205&#x02013;218 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Myronenko, A., Xu, Z., Yang, D., Roth, H. R. &#x00026; Xu, D. <italic>Accounting for Dependencies in Deep Learning Based Multiple Instance Learning for Whole Slide Imaging</italic>. <italic>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</italic> 12908 LNCS (Springer International Publishing, 2021).</mixed-citation></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Vu</surname><given-names>QD</given-names></name><name><surname>Rajpoot</surname><given-names>K</given-names></name><name><surname>Raza</surname><given-names>SEA</given-names></name><name><surname>Rajpoot</surname><given-names>N</given-names></name></person-group><article-title>Handcrafted Histological Transformer (H2T): Unsupervised representation of whole slide images</article-title><source>Med. Image Anal.</source><year>2023</year><volume>85</volume><fpage>102743</fpage><pub-id pub-id-type="doi">10.1016/j.media.2023.102743</pub-id><pub-id pub-id-type="pmid">36702037</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">Vu, Q. D., Rajpoot, K., Raza, S. E. A. &#x00026; Rajpoot, N. Handcrafted Histological Transformer (H2T): Unsupervised representation of whole slide images. <italic>Med. Image Anal.</italic><bold>85</bold>, 102743 (2023).<pub-id pub-id-type="pmid">36702037</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Bankhead</surname><given-names>P</given-names></name><etal/></person-group><article-title>QuPath: Open source software for digital pathology image analysis</article-title><source>Sci. Rep.</source><year>2017</year><volume>7</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1038/s41598-017-17204-5</pub-id><pub-id pub-id-type="pmid">28127051</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">Bankhead, P. et al. QuPath: Open source software for digital pathology image analysis. <italic>Sci. Rep.</italic><bold>7</bold>, 1&#x02013;7 (2017).<pub-id pub-id-type="pmid">28127051</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Pocock</surname><given-names>J</given-names></name><etal/></person-group><article-title>TIAToolbox as an end-to-end library for advanced tissue image analytics</article-title><source>Commun. Med.</source><year>2022</year><volume>2</volume><fpage>120</fpage><pub-id pub-id-type="doi">10.1038/s43856-022-00186-5</pub-id><pub-id pub-id-type="pmid">36168445</pub-id>
</element-citation><mixed-citation id="mc-CR29" publication-type="journal">Pocock, J. et al. TIAToolbox as an end-to-end library for advanced tissue image analytics. <italic>Commun. Med.</italic><bold>2</bold>, 120 (2022).<pub-id pub-id-type="pmid">36168445</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Shephard</surname><given-names>AJ</given-names></name><etal/></person-group><article-title>Simultaneous nuclear instance and layer segmentation in oral epithelial dysplasia</article-title><source>Proc. IEEE/CVF Int. Conf. Comput. Vis. Work.</source><year>2021</year><volume>October</volume><fpage>552</fpage><lpage>561</lpage></element-citation><mixed-citation id="mc-CR30" publication-type="journal">Shephard, A. J. et al. Simultaneous nuclear instance and layer segmentation in oral epithelial dysplasia. <italic>Proc. IEEE/CVF Int. Conf. Comput. Vis. Work.</italic><bold>October</bold>, 552&#x02013;561 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Shephard</surname><given-names>AJ</given-names></name><etal/></person-group><article-title>A fully automated and explainable algorithm for predicting malignant transformation in oral epithelial dysplasia</article-title><source>npj Precis. Oncol.</source><year>2024</year><volume>8</volume><fpage>137</fpage><pub-id pub-id-type="doi">10.1038/s41698-024-00624-8</pub-id><pub-id pub-id-type="pmid">38942998</pub-id>
</element-citation><mixed-citation id="mc-CR31" publication-type="journal">Shephard, A. J. et al. A fully automated and explainable algorithm for predicting malignant transformation in oral epithelial dysplasia. <italic>npj Precis. Oncol.</italic><bold>8</bold>, 137 (2024).<pub-id pub-id-type="pmid">38942998</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Symmetric cross entropy for robust learning with noisy labels</article-title><source>Proc. IEEE Int. Conf. Comput. Vis.</source><year>2019</year><volume>2019-Octob</volume><fpage>322</fpage><lpage>330</lpage></element-citation><mixed-citation id="mc-CR32" publication-type="journal">Wang, Y. et al. Symmetric cross entropy for robust learning with noisy labels. <italic>Proc. IEEE Int. Conf. Comput. Vis.</italic><bold>2019-Octob</bold>, 322&#x02013;330 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Chen, L.-C., Papandreou, G., Schroff, F. &#x00026; Adam, H. Rethinking Atrous Convolution for Semantic Image Segmentation. <italic>arXiv</italic> (2017).</mixed-citation></ref><ref id="CR34"><label>34.</label><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name><surname>Baheti</surname><given-names>B</given-names></name><name><surname>Innani</surname><given-names>S</given-names></name><name><surname>Gajre</surname><given-names>S</given-names></name><name><surname>Talbar</surname><given-names>S</given-names></name></person-group><article-title>Eff-UNet: A novel architecture for semantic segmentation in unstructured environment</article-title><source>IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Work.</source><year>2020</year><volume>2020-June</volume><fpage>1473</fpage><lpage>1481</lpage></element-citation><mixed-citation id="mc-CR34" publication-type="journal">Baheti, B., Innani, S., Gajre, S. &#x00026; Talbar, S. Eff-UNet: A novel architecture for semantic segmentation in unstructured environment. <italic>IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Work.</italic><bold>2020-June</bold>, 1473&#x02013;1481 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Bashir</surname><given-names>RMS</given-names></name><etal/></person-group><article-title>A digital score of peri-epithelial lymphocytic activity predicts malignant transformation in oral epithelial dysplasia</article-title><source>J. Pathol.</source><year>2023</year><pub-id pub-id-type="doi">10.1002/path.6094</pub-id><pub-id pub-id-type="pmid">37294162</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Bashir, R. M. S. et al. A digital score of peri-epithelial lymphocytic activity predicts malignant transformation in oral epithelial dysplasia. <italic>J. Pathol.</italic>10.1002/path.6094 (2023).<pub-id pub-id-type="pmid">37294162</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Bilodeau</surname><given-names>E</given-names></name><name><surname>Pollack</surname><given-names>B</given-names></name><name><surname>Batmanghelich</surname><given-names>K</given-names></name></person-group><article-title>Automated detection of premalignant oral lesions on whole slide images using convolutional neural networks</article-title><source>Oral. Oncol.</source><year>2022</year><volume>134</volume><fpage>106109</fpage><pub-id pub-id-type="doi">10.1016/j.oraloncology.2022.106109</pub-id><pub-id pub-id-type="pmid">36126604</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal">Liu, Y., Bilodeau, E., Pollack, B. &#x00026; Batmanghelich, K. Automated detection of premalignant oral lesions on whole slide images using convolutional neural networks. <italic>Oral. Oncol.</italic><bold>134</bold>, 106109 (2022).<pub-id pub-id-type="pmid">36126604</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Mahmood, H. et al. Development and validation of a multivariable model for prediction of malignant transformation and recurrence of oral epithelial dysplasia. <italic>Br. J. Cancer</italic>10.1038/s41416-023-02438-0 (2023).</mixed-citation></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name><surname>Mahmood</surname><given-names>H</given-names></name><etal/></person-group><article-title>Prediction of malignant transformation and recurrence of oral epithelial dysplasia using architectural and cytological feature specific prognostic models</article-title><source>Mod. Pathol.</source><year>2022</year><volume>35</volume><fpage>1151</fpage><lpage>1159</lpage><pub-id pub-id-type="doi">10.1038/s41379-022-01067-x</pub-id><pub-id pub-id-type="pmid">35361889</pub-id>
</element-citation><mixed-citation id="mc-CR38" publication-type="journal">Mahmood, H. et al. Prediction of malignant transformation and recurrence of oral epithelial dysplasia using architectural and cytological feature specific prognostic models. <italic>Mod. Pathol.</italic><bold>35</bold>, 1151&#x02013;1159 (2022).<pub-id pub-id-type="pmid">35361889</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Jahanifar, M. et al. Domain generalization in computational pathology: survey and guidelines. <italic>ACM Comput. Surv</italic>. 1&#x02013;38 (2025).</mixed-citation></ref><ref id="CR40"><label>40.</label><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name><surname>Wils</surname><given-names>LJ</given-names></name><etal/></person-group><article-title>The role of differentiated dysplasia in the prediction of malignant transformation of oral leukoplakia</article-title><source>J. Oral. Pathol. Med.</source><year>2023</year><volume>52</volume><fpage>930</fpage><lpage>938</lpage><pub-id pub-id-type="doi">10.1111/jop.13483</pub-id><pub-id pub-id-type="pmid">37749621</pub-id>
</element-citation><mixed-citation id="mc-CR40" publication-type="journal">Wils, L. J. et al. The role of differentiated dysplasia in the prediction of malignant transformation of oral leukoplakia. <italic>J. Oral. Pathol. Med.</italic><bold>52</bold>, 930&#x02013;938 (2023).<pub-id pub-id-type="pmid">37749621</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name><surname>Brouns</surname><given-names>ER</given-names></name><etal/></person-group><article-title>Oral leukoplakia classification and staging system with incorporation of differentiated dysplasia</article-title><source>Oral. Dis.</source><year>2023</year><volume>29</volume><fpage>2667</fpage><lpage>2676</lpage><pub-id pub-id-type="doi">10.1111/odi.14295</pub-id><pub-id pub-id-type="pmid">35765231</pub-id>
</element-citation><mixed-citation id="mc-CR41" publication-type="journal">Brouns, E. R. et al. Oral leukoplakia classification and staging system with incorporation of differentiated dysplasia. <italic>Oral. Dis.</italic><bold>29</bold>, 2667&#x02013;2676 (2023).<pub-id pub-id-type="pmid">35765231</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>Gannot</surname><given-names>G</given-names></name><name><surname>Gannot</surname><given-names>I</given-names></name><name><surname>Vered</surname><given-names>H</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name><name><surname>Keisari</surname><given-names>Y</given-names></name></person-group><article-title>Increase in immune cell infiltration with progression of oral epithelium from hyperkeratosis to dysplasia and carcinoma</article-title><source>Br. J. Cancer</source><year>2002</year><volume>86</volume><fpage>1444</fpage><lpage>1448</lpage><pub-id pub-id-type="doi">10.1038/sj.bjc.6600282</pub-id><pub-id pub-id-type="pmid">11986779</pub-id>
</element-citation><mixed-citation id="mc-CR42" publication-type="journal">Gannot, G., Gannot, I., Vered, H., Buchner, A. &#x00026; Keisari, Y. Increase in immune cell infiltration with progression of oral epithelium from hyperkeratosis to dysplasia and carcinoma. <italic>Br. J. Cancer</italic><bold>86</bold>, 1444&#x02013;1448 (2002).<pub-id pub-id-type="pmid">11986779</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name><surname>Gan</surname><given-names>CP</given-names></name><etal/></person-group><article-title>Transcriptional analysis highlights three distinct immune profiles of high-risk oral epithelial dysplasia</article-title><source>Front. Immunol.</source><year>2022</year><volume>13</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.3389/fimmu.2022.954567</pub-id></element-citation><mixed-citation id="mc-CR43" publication-type="journal">Gan, C. P. et al. Transcriptional analysis highlights three distinct immune profiles of high-risk oral epithelial dysplasia. <italic>Front. Immunol.</italic><bold>13</bold>, 1&#x02013;16 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Shephard, A. et al. odyn_inference. Available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/adamshephard/odyn_inference">https://github.com/adamshephard/odyn_inference</ext-link> (2024).</mixed-citation></ref></ref-list></back></article>