<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Cogn Res Princ Implic</journal-id><journal-id journal-id-type="iso-abbrev">Cogn Res Princ Implic</journal-id><journal-title-group><journal-title>Cognitive Research: Principles and Implications</journal-title></journal-title-group><issn pub-type="epub">2365-7464</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40188224</article-id><article-id pub-id-type="pmc">PMC11972256</article-id><article-id pub-id-type="publisher-id">622</article-id><article-id pub-id-type="doi">10.1186/s41235-025-00622-9</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Evaluating convergence between two data visualization literacy assessments</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8702-239X</contrib-id><name><surname>Brockbank</surname><given-names>Erik</given-names></name><address><email>ebrockbank@stanford.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Verma</surname><given-names>Arnav</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Lloyd</surname><given-names>Hannah</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Huey</surname><given-names>Holly</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Padilla</surname><given-names>Lace</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Fan</surname><given-names>Judith E.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00f54p054</institution-id><institution-id institution-id-type="GRID">grid.168010.e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8956</institution-id><institution>Department of Psychology, </institution><institution>Stanford University, </institution></institution-wrap>Stanford, USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0168r3w48</institution-id><institution-id institution-id-type="GRID">grid.266100.3</institution-id><institution-id institution-id-type="ISNI">0000 0001 2107 4242</institution-id><institution>Department of Psychology, </institution><institution>University of California San Diego, </institution></institution-wrap>La Jolla, USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04t5xt781</institution-id><institution-id institution-id-type="GRID">grid.261112.7</institution-id><institution-id institution-id-type="ISNI">0000 0001 2173 3359</institution-id><institution>Department of Computer Science, </institution><institution>Northeastern University, </institution></institution-wrap>Boston, USA </aff></contrib-group><pub-date pub-type="epub"><day>5</day><month>4</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>5</day><month>4</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>12</month><year>2025</year></pub-date><volume>10</volume><elocation-id>15</elocation-id><history><date date-type="received"><day>13</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>26</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Data visualizations play a crucial role in communicating patterns in quantitative data, making data visualization literacy a key target of STEM education. However, it is currently unclear to what degree different assessments of data visualization literacy measure the same underlying constructs. Here, we administered two widely used graph comprehension assessments (Galesic and Garcia-Retamero in Med Dec Mak 31:444&#x02013;457, 2011; Lee et al. in IEEE Trans Vis Comput Graph 235:51&#x02013;560, 2016) to both a university-based convenience sample and a demographically representative sample of adult participants in the USA (<italic>N</italic>=1,113). Our analysis of individual variability in test performance suggests that overall scores are correlated between assessments and associated with the amount of prior coursework in mathematics. However, further exploration of individual error patterns suggests that these assessments probe somewhat distinct components of data visualization literacy, and we do not find evidence that these components correspond to the categories that guided the design of either test (e.g., questions that require retrieving values rather than making comparisons). Together, these findings suggest opportunities for development of more comprehensive assessments of data visualization literacy that are organized by components that better account for detailed behavioral patterns.</p><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1186/s41235-025-00622-9.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Graph comprehension</kwd><kwd>Graphical literacy</kwd><kwd>Data literacy</kwd><kwd>Psychometric evaluation</kwd><kwd>STEM education</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000173</institution-id><institution>Division of Research on Learning in Formal and Informal Settings</institution></institution-wrap></funding-source><award-id>2400471</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000169</institution-id><institution>Division of Behavioral and Cognitive Sciences</institution></institution-wrap></funding-source><award-id>2047191</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000145</institution-id><institution>Division of Information and Intelligent Systems</institution></institution-wrap></funding-source><award-id>2238175</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000169</institution-id><institution>Division of Behavioral and Cognitive Sciences</institution></institution-wrap></funding-source><award-id>2122174</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000169</institution-id><institution>Division of Behavioral and Cognitive Sciences</institution></institution-wrap></funding-source><award-id>2404706</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Psychonomic Society 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Significance statement</title><p id="Par2">Data visualizations are indispensable for communicating patterns in quantitative data. However, while several test-based measures of data visualization literacy exist, there is not yet clear agreement on what the key components of data visualization literacy are and how to measure them. In this study, we administered two widely used assessments of data visualization literacy to multiple diverse groups of US adult participants. Participants who performed well on one assessment also generally did so on the other, suggesting some degree of convergence between these two measures. Moreover, performance on the combined assessment was associated with how much formal education in mathematics an individual had received, a measure of their convergence with other measures of quantitative literacy. However, it was less clear what underlying components of data visualization literacy these assessments measure. While it seems natural to assume that the ability to answer any question correctly on this assessment would be predicted by the type of graph shown or the type of question being asked, we used tools from machine learning to discover a small (and different) set of latent factors that could explain these patterns much more effectively. These findings lay the groundwork for future efforts to characterize what aspects of data visualization literacy these latent factors represent and to develop improved and unified measures of data visualization literacy.</p></sec><sec id="Sec2"><title>Introduction</title><p id="Par3">Data visualizations&#x02014;also commonly known as <italic>graphs</italic>, <italic>charts</italic>, and/or <italic>plots</italic>&#x02014;provide a powerful and versatile medium for reasoning about data (Bertin, <xref ref-type="bibr" rid="CR8">1981</xref>; Tufte, <xref ref-type="bibr" rid="CR64">1983</xref>; Wilkinson, <xref ref-type="bibr" rid="CR66">2012</xref>). They do so by leveraging color, shape, size, position, and other visual variables to convey quantitative patterns and relationships that might otherwise be difficult to discern when inspecting raw data. Although a relatively recent invention (Playfair, <xref ref-type="bibr" rid="CR55">1801</xref>; Spence, <xref ref-type="bibr" rid="CR63">2006</xref>), data visualizations are now vital for communication both among scientists and between scientists and members of the general public (B&#x000f6;rner et al., <xref ref-type="bibr" rid="CR12">2019</xref>; Franconeri et al., <xref ref-type="bibr" rid="CR27">2021</xref>). As such, the ability to use visualizations to explore and reason about data is a key priority in STEM education (Council, <xref ref-type="bibr" rid="CR20">2014</xref>; Garfield and Gal, <xref ref-type="bibr" rid="CR31">1999</xref>).</p><p id="Par4">However, a key challenge to successfully addressing this priority is a clear definition of what specific competencies are constitutive of the ability to use data visualizations effectively. This ability, often termed &#x0201c;visualization literacy,&#x0201d; encompasses a broad suite of skills involved in the process of linking questions about data (which are often not inherently visual in nature) to visual patterns in graphical representations of those data (Friel et al., <xref ref-type="bibr" rid="CR28">2001</xref>; Shah and Hoeffner, <xref ref-type="bibr" rid="CR61">2002</xref>; Brehmer and Munzner, <xref ref-type="bibr" rid="CR14">2013</xref>; Boy et al., <xref ref-type="bibr" rid="CR13">2014</xref>; B&#x000f6;rner et al., <xref ref-type="bibr" rid="CR16">2016</xref>; Creamer et al., <xref ref-type="bibr" rid="CR22">2024</xref>; Hedayati et al., <xref ref-type="bibr" rid="CR37">2024</xref>). Visualization literacy has been operationalized in a number of different ways across disciplinary contexts, including in education (Friel et al., <xref ref-type="bibr" rid="CR28">2001</xref>; Shah and Hoeffner, <xref ref-type="bibr" rid="CR61">2002</xref>; Maltese et al., <xref ref-type="bibr" rid="CR42">2015</xref>; B&#x000f6;rner et al., <xref ref-type="bibr" rid="CR12">2019</xref>), cognitive psychology (Boy et al., <xref ref-type="bibr" rid="CR13">2014</xref>; Padilla, <xref ref-type="bibr" rid="CR48">2018</xref>), human&#x02013;computer interaction (Brehmer and Munzner, <xref ref-type="bibr" rid="CR14">2013</xref>; Lee et al., <xref ref-type="bibr" rid="CR41">2016</xref>), and public health (Galesic and Garcia-Retamero, <xref ref-type="bibr" rid="CR29">2011</xref>; Ancker et al., <xref ref-type="bibr" rid="CR3">2006</xref>; Padilla et al., <xref ref-type="bibr" rid="CR50">2022</xref>).</p><p id="Par5">While much of the existing work on visualization literacy focuses on the ability to understand formal data visualizations, other lines of work have explored the ability to design new visualizations (Alper et al., <xref ref-type="bibr" rid="CR1">2017</xref>; Berg and Smith, <xref ref-type="bibr" rid="CR7">1994</xref>; Bishop et al., <xref ref-type="bibr" rid="CR10">2019</xref>) or use an existing visualization to make a sound decision (Ruginski et al., <xref ref-type="bibr" rid="CR58">2016</xref>; Price et al., <xref ref-type="bibr" rid="CR57">2016</xref>). Measures of data visualization understanding are especially important because these comprehension skills are foundational for more complex activities, such as visualization design and decision-making with visualizations (B&#x000f6;rner et al., <xref ref-type="bibr" rid="CR12">2019</xref>; Hedayati et al., <xref ref-type="bibr" rid="CR37">2024</xref>). Moreover, reliable and valid measures of data visualization literacy are critical for evaluating the success of any educational intervention intended to improve visualization literacy skills. Finally, reliable measurement is crucial for developing cognitive theories of data visualization literacy&#x02014;that is, theories of how graphs are mentally represented that explain why people find some questions about them easier to answer than others, as well as how the ability to understand graphs develops over time (Pinker, <xref ref-type="bibr" rid="CR54">1990</xref>; Shah and Hoeffner, <xref ref-type="bibr" rid="CR61">2002</xref>; Padilla, <xref ref-type="bibr" rid="CR48">2018</xref>; Padilla et al., <xref ref-type="bibr" rid="CR49">2018</xref>).</p><p id="Par6">Generally speaking, an individual&#x02019;s ability to read and interpret a data visualization is assessed using a sequence of test items, each one posing a question and providing a data visualization to answer it. While there are currently several assessments that adopt this general strategy (DelMas et al., <xref ref-type="bibr" rid="CR24">2005</xref>; Galesic and Garcia-Retamero, <xref ref-type="bibr" rid="CR29">2011</xref>; Maltese et al., <xref ref-type="bibr" rid="CR42">2015</xref>; Boy et al., <xref ref-type="bibr" rid="CR13">2014</xref>; Lee et al., <xref ref-type="bibr" rid="CR41">2016</xref>; B&#x000f6;rner et al., <xref ref-type="bibr" rid="CR16">2016</xref>; Garcia-Retamero et al., <xref ref-type="bibr" rid="CR30">2016</xref>; Okan et al., <xref ref-type="bibr" rid="CR47">2019</xref>; Pandey and Ottley, <xref ref-type="bibr" rid="CR51">2023</xref>; Ge et al., <xref ref-type="bibr" rid="CR32">2023</xref>), they define and operationalize the component skills in different ways. For instance, some assessments group items into a compact hierarchy of abstract abilities, progressing from &#x0201c;reading the data&#x0201d; to &#x0201c;reading beyond the data&#x0201d; (Galesic and Garcia-Retamero, <xref ref-type="bibr" rid="CR29">2011</xref>; Friel et al., <xref ref-type="bibr" rid="CR28">2001</xref>). Others group items into a broader set of tasks that do not necessarily imply strong dependencies between them, such as finding extreme values or making comparisons (Lee et al., <xref ref-type="bibr" rid="CR41">2016</xref>; Pandey and Ottley, <xref ref-type="bibr" rid="CR51">2023</xref>; Boy et al., <xref ref-type="bibr" rid="CR13">2014</xref>). Still others focus on the ability to overcome intentionally misleading data visualizations (Ge et al., <xref ref-type="bibr" rid="CR32">2023</xref>) or misconceptions about distributions that are common among students enrolled in introductory statistics courses (DelMas et al., <xref ref-type="bibr" rid="CR24">2005</xref>).</p><p id="Par7">But because these assessments have not been compared directly, it is unknown to what degree they converge with one another or imply the same decomposition of data visualization literacy into underlying skills. As such, it remains unclear on what basis any given assessment should be preferred to provide the most reliable and valid measure of data visualization literacy. To address this gap, here we compare two widely used assessments that measure data visualization literacy in distinct ways: The 13-item assessment developed by Galesic and Garcia-Retamero (<xref ref-type="bibr" rid="CR29">2011</xref>), which we refer to as <italic>GGR</italic>, and the 53-item Visualization Literacy Assessment Test (<italic>VLAT</italic>; Lee et al. (<xref ref-type="bibr" rid="CR41">2016</xref>)). We focused on these two assessments because, at the time this work was being conducted, they were among the most influential measures of data visualization literacy that could also be combined into a single assessment that could be administered in one session.</p><p id="Par8">The items in GGR are organized into a three-level hierarchy of skills (Friel et al., <xref ref-type="bibr" rid="CR28">2001</xref>): &#x0201c;Level 1: Read the Data&#x0201d; (i.e., finding specific values in a graph); &#x0201c;Level 2: Read Between the Data&#x0201d; (i.e., comparing values in a graph); and &#x0201c;Level 3: Read Beyond the Data&#x0201d; (i.e., extrapolation). On the other hand, the items in VLAT are organized into a suite of eight skills (Brehmer and Munzner, <xref ref-type="bibr" rid="CR14">2013</xref>; Amar et al., <xref ref-type="bibr" rid="CR2">2005</xref>): retrieving a value, finding extreme values, finding anomalies, making comparisons, determining a range, finding correlations and trends, characterizing distributions, and finding clusters.</p><p id="Par9">We administered both assessments to a large and diverse sample of adult participants in the United States (USA). Our analyses of task performance were guided by three objectives. <italic>First</italic>, to characterize performance on the assessments across different sample demographics, as well as to estimate the association between performance on these assessments and the amount of prior coursework in mathematics. <italic>Second</italic>, we investigated the degree to which these two assessments produced convergent estimates of overall data visualization literacy levels, despite having been designed in different ways. <italic>Third,</italic> we sought to measure how well individual variability in test performance could be explained by the skill-based categories used to design each assessment. Taken together, this study offers empirical insights that serve as a foundation for the future development of more comprehensive and well-validated assessments of data visualization literacy.</p></sec><sec id="Sec3"><title>Method</title><sec id="Sec4"><title>Participants</title><p id="Par10">A total of 1,176 participants were recruited: 726 were students recruited from the University of California, San Diego study pool (211 male; mean age=21). 450 adults were recruited using Prolific to obtain a sample that is demographically representative of the USA based on age, sex, and ethnicity (206 male; mean age=45). This total sample size is comparable to the study reported in Galesic and Garcia-Retamero (<xref ref-type="bibr" rid="CR29">2011</xref>), which included 987 participants, and larger than the sample initially recruited in Lee et al. (<xref ref-type="bibr" rid="CR41">2016</xref>), which included 46 participants. All participants provided informed consent in accordance with the University of California, San Diego IRB. Participants were excluded for failing to complete the full assessment and the post-experiment survey of demographics and prior math experience, as well as for any technical issues reported in the post-experiment survey which prevented them from answering the questions. Unless otherwise indicated, we report results from analyzing the combined sample after exclusions (<italic>N</italic>=1,113 participants; US university sample: <italic>N</italic>=714 participants; US general public: <italic>N</italic>=399 participants).</p></sec><sec id="Sec5"><title>Materials</title><p id="Par11">Two assessments were included in our study: <italic>GGR</italic> (Galesic and Garcia-Retamero, <xref ref-type="bibr" rid="CR29">2011</xref>) and <italic>VLAT</italic> (Lee et al., <xref ref-type="bibr" rid="CR41">2016</xref>); see Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>A.</p><p id="Par12"><italic>GGR</italic> is a 13-item assessment containing eight graphs: three <italic>bar charts</italic>, one <italic>pie chart</italic>, three <italic>line plots</italic>, and one <italic>icon array</italic> (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>A, left). All items were assigned by the test developers to three categories: <italic>Level 1: Read the Data</italic>, <italic>Level 2: Read Between the Data</italic>, and <italic>Level 3: Read Beyond the Data</italic>. However, not all graph types were paired with all three types of questions. Nine items were fill-in-the-blank questions, and four were multiple-choice questions with three response options. It was possible to skip any multiple-choice question, but not fill-in-the-blank questions, following the original test administration procedure. For all but one of the fill-in-the-blank items, it was necessary to provide a response that exactly matched the correct answer to be counted as correct; for the remaining item, the test developers allowed responses that fell within a range (i.e., between 23 and 25).</p><p id="Par13"><italic>VLAT</italic> is a 53-item assessment containing 12 graph types: <italic>line chart</italic>, <italic>bar chart</italic>, <italic>stacked bar chart</italic>, <italic>100% stacked bar chart</italic>, <italic>pie chart</italic>, <italic>histogram</italic>, <italic>scatter plot</italic>, <italic>bubble chart</italic>, <italic>area chart</italic>, <italic>stacked area chart</italic>, <italic>choropleth map</italic>, and <italic>tree map</italic> (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>A, right). These items were assigned by the test developers to eight question types: <italic>retrieve value</italic>, <italic>find extremum</italic>, <italic>find anomalies</italic>, <italic>make comparisons</italic>, <italic>determine range</italic>, <italic>find correlations/trends</italic>, <italic>characterize distribution</italic>, and <italic>find clusters</italic>. There were 16 true-false items; the remaining 37 multiple-choice items contained either three options (3 questions) or four options (34 questions). It was possible to skip any question.</p></sec><sec id="Sec6"><title>Procedure</title><p id="Par14">
<fig id="Fig1"><label>Fig. 1</label><caption><p><bold>A</bold> The current study investigates two assessments of data visualization literacy: GGR (Galesic and Garcia-Retamero,&#x000a0;<xref ref-type="bibr" rid="CR29">2011</xref>) and VLAT (Lee et al.,&#x000a0;<xref ref-type="bibr" rid="CR41">2016</xref>). <bold>B</bold> The combined assessment was administered to two groups of participants: A US university sample recruited using a study pool and a US demographically representative sample recruited using an online crowdsourcing platform</p></caption><graphic xlink:href="41235_2025_622_Fig1_HTML" id="MO1"/></fig>
</p><p id="Par15">Participants completed the two assessments in a randomized order during a single session (see, Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>B), and each assessment was administered in a manner as similar to the original procedure as possible. Participants could spend as much time on each assessment as needed. Afterward, they completed an optional post-study questionnaire that asked about their sex, age, ethnicity, and level of educational attainment. The possible responses to the educational attainment item were: &#x0201c;Have not graduated high school,&#x0201d; &#x0201c;High school graduate, diploma or equivalent,&#x0201d; &#x0201c;Associate degree,&#x0201d; &#x0201c;Bachelor&#x02019;s degree,&#x0201d; &#x0201c;Master&#x02019;s degree,&#x0201d; &#x0201c;Professional degree (e.g., M.D., J.D.),&#x0201d; &#x0201c;Doctoral degree (e.g., Ph.D.).&#x0201d; To obtain a proxy for the amount of prior mathematics knowledge participants had, which is especially relevant for tasks involving reasoning about data visualizations, we also prompted participants to indicate how many of the following high school-level math courses they had previously taken: algebra, calculus, and statistics.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Number of participants grouped by how many high school-level math courses they reported having previously taken</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Num math courses</th><th align="left">US representative</th><th align="left">US university</th></tr></thead><tbody><tr><td align="left">0</td><td align="left">39</td><td align="left">9</td></tr><tr><td align="left">1</td><td align="left">136</td><td align="left">46</td></tr><tr><td align="left">2</td><td align="left">116</td><td align="left">146</td></tr><tr><td align="left">3</td><td align="left">108</td><td align="left">513</td></tr><tr><td align="left">Total</td><td align="left">399</td><td align="left">714</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec7"><title>Statistical analyses</title><p id="Par16">Overall, our statistical analyses aim to disentangle different potential sources of variation in how well participants performed on these assessments. The primary tool we use for this is linear regression, and the primary factors we consider are the type of graph used in an item, the type of question asked, prior mathematics knowledge, as well as the population from which participants were recruited (i.e., university study pool vs. demographically representative sample of US crowd workers). To contextualize the degree to which these factors account for the explainable variance in these data, we additionally conducted exploratory factor analysis to infer the latent components that best predict participants&#x02019; individual patterns of correct and incorrect responses. Below we describe the details of the statistical analysis strategy we use toward these ends.</p><sec id="Sec8"><title>Linear models</title><p id="Par17">We construct linear models to test the reliability of the association between several different variables of interest (i.e., graph type, question type, number of math courses, group membership) and test performance. We use nested model comparison because it provides a unified framework for hypothesis testing that generalizes beyond the narrower set of use cases that traditional hypothesis tests (e.g., <italic>t</italic>-tests, ANCOVA) were designed to independently handle. Specifically, to estimate the strength of the relationship between each predictor variable of interest and test performance, we fit mixed-effects logistic-regression models to predict accuracy from that predictor variable, modeled as a fixed effect, and include random intercepts for each participant. We use logistic regression to predict the binary outcomes for individual items (i.e., correct vs. incorrect) because it provides more accurate estimates than using ordinary least squares regression to predict the proportion of correct responses across a set of items. To assess the explanatory value of any given predictor variable, we then use nested model comparison to determine how much more variance in performance could be explained when that variable was included in the linear model than when it was omitted (i.e., the baseline model), accounting for the increase in model complexity when the variable was included. We implement these analyses using the <italic>lmer</italic> package in R (Baayen et al., <xref ref-type="bibr" rid="CR4">2008</xref>; Bates et&#x000a0;al., <xref ref-type="bibr" rid="CR5">2015</xref>) and report <inline-formula id="IEq1"><alternatives><tex-math id="d33e699">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi ^2$$\end{document}</tex-math><mml:math id="d33e704"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq1.gif"/></alternatives></inline-formula> statistics, degrees of freedom, and p-values for each model comparison. The coefficient and standard error estimates accompanying these models can be found in the Supplemental Materials.</p></sec><sec id="Sec9"><title>Exploratory factor analysis</title><p id="Par18">To investigate latent structure within and between assessments that was predictive of test performance, we employed exploratory factor analysis (EFA). EFA is a widely used dimensionality reduction method to uncover the set of latent <italic>factors</italic> that underlie observable patterns in data (Briggs and Cheek, <xref ref-type="bibr" rid="CR15">1986</xref>; Haig, <xref ref-type="bibr" rid="CR35">2005</xref>; Cowen and Keltner, <xref ref-type="bibr" rid="CR21">2017</xref>; Eisenberg et al., <xref ref-type="bibr" rid="CR26">2019</xref>). We apply EFA to the combined assessment in two ways. First, as a tool to infer how many factors are needed to account for the patterns of correct and incorrect responses generated by different participants. Second, we adopt the same formalization to compare existing methods of decomposing assessment items (by question type, graph type, and test) to explain the same error patterns.</p><p id="Par19">To fit a factor model, each response on the combined assessment is modeled as a linear combination of latent factors and measurement error: <inline-formula id="IEq2"><alternatives><tex-math id="d33e731">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X - \mu = LF + \epsilon$$\end{document}</tex-math><mml:math id="d33e736"><mml:mrow><mml:mi>X</mml:mi><mml:mo>-</mml:mo><mml:mi>&#x003bc;</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mi>F</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003f5;</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq2.gif"/></alternatives></inline-formula>, where <italic>X</italic> is an <italic>m</italic> (number of test items: 66) x <italic>n</italic> (number of participants) binary matrix of observed errors and <inline-formula id="IEq3"><alternatives><tex-math id="d33e757">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu$$\end{document}</tex-math><mml:math id="d33e762"><mml:mi>&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq3.gif"/></alternatives></inline-formula> is a matrix containing the mean score for each item. <italic>L</italic> is the <italic>m</italic> x <italic>f</italic> (number of factors) loading matrix, an estimate of how much each item contributes to each latent factor, and <italic>F</italic> is the <italic>f</italic> x <italic>n</italic> matrix of factor scores, an estimate of how much each participant&#x02019;s responses are predicted by each factor. <inline-formula id="IEq4"><alternatives><tex-math id="d33e786">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><mml:math id="d33e791"><mml:mi>&#x003f5;</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq4.gif"/></alternatives></inline-formula> represents measurement error, variance left unexplained by the latent factors.</p><p id="Par20">We first apply EFA to the combined assessment to estimate the number of latent factors needed to account for error patterns while minimizing extraneous factors. Adding more factors improves prediction accuracy, but this often comes at a cost of interpretability. Researchers have proposed several methods for selecting the number of factors that best balances this trade-off in a particular set of data (Preacher et al., <xref ref-type="bibr" rid="CR56">2013</xref>). We use Bayesian Information Criterion (BIC) to identify a minimal set of factors that account for individual patterns of error (Schwarz, <xref ref-type="bibr" rid="CR59">1978</xref>). We then compare this <italic>latent factor</italic> model to several <italic>idealized</italic> factor models based on graph type, question type, and test.</p><p id="Par21">Rather than estimate the loading matrix <italic>L</italic> from participants&#x02019; responses, our idealized factor models specify a loading matrix based on known decompositions of the assessment items. For example, the idealized loading matrix encoding question type information is a 66 x 11 (number of question types) matrix with binary values in each column encoding whether the item in each row belonged to that question type. This specification of <italic>L</italic> embodies the possibility that all of the items that involve the same question type &#x0201c;hang together&#x0201d; to explain error patterns, i.e., an individual who knows how to perform the operation for a particular question type is predicted to get all of those items correct or all of those items incorrect. In addition, encoding each item&#x02019;s question type independently in the loading matrix <italic>L</italic> allows for the <italic>possibility</italic> that different question types are entirely independent of one another, i.e., an individual who knows how to perform one question type task is not more likely to be able to perform another. Critically, structuring the loading matrix in this way does not <italic>enforce</italic> such independence on the idealized factor models. The idealized factor models are derived by estimating the factor scores <italic>F</italic> given an idealized loading matrix <italic>L</italic>&#x02014;in this way, systematic patterns in participants&#x02019; responses that arise from, e.g., similarity across different question types can be expressed in the factor scores assigned to participants for those question types. Our analyses focus on how well idealized models with &#x0201c;manually&#x0201d; encoded loading matrices and freely varying factor scores are able to predict participants&#x02019; responses.</p><p id="Par22">We compare the performance of our fitted latent factor model to idealized factor models encoding test, question type, and graph type information. Each factor model predicts individual responses on all 66 assessment questions. These predictions can be compared to the actual responses to produce a vector of prediction errors for each participant. We calculate each participant&#x02019;s mean squared error (the average of item-level squared errors for each participant). The average of all participant mean squared error (MSE) values for a given model provides a group-level MSE value for that factor model, allowing us to compare models according to their overall predictive accuracy. For the latent factor model, which does not specify a particular factor loading matrix in advance, we obtain this MSE estimate using fivefold cross-validation. We fit a separate factor model to each set of training data folds, then use the loading matrix from the training set to estimate a factor score matrix for the held-out data. This model is used to then predict individual responses in the held-out data. The group-level MSE value for this model is calculated based on the held-out prediction error for each participant. This ensures that evaluation of model performance is always based on splits of the data that are independent from those used to fit the latent factor model&#x02019;s loading matrix.</p></sec><sec id="Sec10"><title>Confidence intervals</title><p id="Par23">To provide quantitative estimates of effect size, we report 95% confidence intervals (CIs) for various quantities of interest (e.g., average test performance). Where we have used linear models to fit the data, these confidence intervals were constructed using estimates of standard error based on the linear model itself. Estimates of mean squared error (MSE) for predictions made by our exploratory factor analysis model are calculated with bootstrap resampling methods, which have the advantage of not depending on parametric assumptions about the sampling distribution of the statistic (Efron and Tibshirani, <xref ref-type="bibr" rid="CR25">1994</xref>). This approach entailed resampling <italic>N</italic>=1,113 individual participant MSE values with replacement and calculating a group-level MSE value from this sample. We repeated this process 10,000 times to estimate a sampling distribution of group-level MSE values from which the 2.5th and 97.5th percentile values could serve as confidence interval endpoints.</p></sec></sec></sec><sec id="Sec11"><title>Results</title><p id="Par24">Our analyses<xref ref-type="fn" rid="Fn1">1</xref> were guided by three main objectives. First, we sought to estimate differences in performance on the combined assessment between groups of participants, depending on how they were recruited and how much prior coursework in mathematics they had completed, providing initial insights into potential sources of variability in performance across individuals. Second, we assessed how strongly performance on one assessment was associated with performance on the other, providing a preliminary measure of these two assessments&#x02019; convergent validity. Third, we evaluated how well variability in performance could be explained by the skill-based categories used to group items in each assessment, such as which type of graph was presented or what type of question was being asked. We compared the predictive value of&#x000a0;these skill-based categories to that of an alternative data-driven decomposition, providing a principled way of assessing the reliability of these categories based on their ability to predict individual error patterns.</p><sec id="Sec12"><title>Comparing performance across groups</title><p id="Par25">
<fig id="Fig2"><label>Fig. 2</label><caption><p><bold>A</bold> Mean performance on each test item in both US university and US demographically representative samples. Each dot is a test item. <bold>B</bold> Overall performance in each group as a function of the number of math courses (i.e., algebra, calculus, statistics) previously taken. Error bars represent standard error of the mean (SEM)</p></caption><graphic xlink:href="41235_2025_622_Fig2_HTML" id="MO2"/></fig>
</p><p id="Par26">On average, participants answered 75.7% of test items correctly (95% CI: [74.9%, 76.5%]), though test performance varied substantially across participants (SD: 14.0%; min: 3.0%; max: 97.0%). These findings indicate both that participants were neither at ceiling nor at floor on these assessments, and that there is meaningful individual variability in performance to explain. We also observed that accuracy for the demographically representative sample (78.6%, 95% CI: [77.4%, 79.7%]) was higher on the combined assessment than for the university sample (73.9%, 95% CI: [72.8%, 75.0%]). Nevertheless, we found that relative performance on individual test items was highly correlated between samples (<inline-formula id="IEq5"><alternatives><tex-math id="d33e877">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\rho$$\end{document}</tex-math><mml:math id="d33e882"><mml:mi>&#x003c1;</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq5.gif"/></alternatives></inline-formula>&#x000a0;= 0.96, 95% CI = [0.94, 0.98], <inline-formula id="IEq6"><alternatives><tex-math id="d33e886">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e891"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq6.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001; Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>A). Together, these results suggest that while the two groups of participants performed at different levels on average, data from both samples provide convergent estimates of the test items&#x02019; relative difficulty.</p><p id="Par27">We next sought to explore the relationship between performance on these assessments and other relevant characteristics of these participants, with a focus on how much high school-level coursework in mathematics they had completed (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Toward that end, we grouped participants by how many math courses they reported having previously taken (among algebra, calculus, and statistics). We found that the number of math courses an individual had taken was a reliable predictor of overall test performance (<inline-formula id="IEq7"><alternatives><tex-math id="d33e903">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e908"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq7.gif"/></alternatives></inline-formula>(3) = 40.04, <inline-formula id="IEq8"><alternatives><tex-math id="d33e914">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e919"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq8.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001), with more prior math courses leading to higher predicted performance (0: 65.1%, 1: 72.5%, 2: 75.9%, 3: 77.1%); the strength of this association did not differ significantly between sample groups (<inline-formula id="IEq9"><alternatives><tex-math id="d33e923">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e928"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq9.gif"/></alternatives></inline-formula>(3) = 3.96, <inline-formula id="IEq10"><alternatives><tex-math id="d33e934">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e939"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq10.gif"/></alternatives></inline-formula>&#x000a0;= .27; see Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>B).<fig id="Fig3"><label>Fig. 3</label><caption><p>Correlation between performance on VLAT and GGR assessments for individual participants</p></caption><graphic xlink:href="41235_2025_622_Fig3_HTML" id="MO3"/></fig></p></sec><sec id="Sec13"><title>Comparing performance across assessments</title><p id="Par28">On average, participants achieved a level of performance that was reliably well above chance, yet below ceiling, on both tests (GGR: 80.4%, 95% CI: [79.5%, 81.3%]; VLAT: 74.6%, 95% CI: [73.7%, 75.5%]). However, there was also substantial individual variability in test performance (GGR <italic>SD</italic> = 15.0%, VLAT <italic>SD</italic> = 15.1%), with an individual&#x02019;s score on one test being moderately predictive of their score on the other (<inline-formula id="IEq11"><alternatives><tex-math id="d33e964">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\rho$$\end{document}</tex-math><mml:math id="d33e969"><mml:mi>&#x003c1;</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq11.gif"/></alternatives></inline-formula>&#x000a0;= 0.56, 95% CI: [0.52, 0.60 ]; Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>). These findings provide an initial estimate of these two assessments&#x02019; ability to reliably measure the same construct. Nevertheless, this analysis does not resolve what underlying factors account for the observed level of convergence between assessments and what accounts for the remainder of the gap between them.<fig id="Fig4"><label>Fig. 4</label><caption><p>Mean proportion correct for every type of graph in the combined assessment, disaggregated by test. Point estimates are plotted for each individual graph, aggregating questions that pertain to the same graph. GGR contains multiple instances of bar plots and line plots, one pie chart and one icon array. VLAT contains exactly one instance of each type graph. The sampling distributions for each point estimate are shown along with error bars representing the standard error of the mean (SEM)</p></caption><graphic xlink:href="41235_2025_622_Fig4_HTML" id="MO4"/></fig></p></sec><sec id="Sec14"><title>Comparing performance across graph type</title><p id="Par29">One possibility that could account for the moderate correlation between scores on each test is the use of similar types of graphs. For instance, some of these graph types might be ones that most individuals know how to interpret, while others are ones that only a minority of individuals are familiar with. Insofar as graph type drives variability in test performance, participants would be expected to achieve higher accuracy on questions involving more familiar graphs, and lower accuracy on questions with less familiar graphs.<fig id="Fig5"><label>Fig. 5</label><caption><p>Mean proportion correct for every question type in the combined assessment, disaggregated by test. The sampling distributions for each point estimate are shown along with error bars representing the standard error of the mean (SEM)</p></caption><graphic xlink:href="41235_2025_622_Fig5_HTML" id="MO5"/></fig></p><p id="Par30">To explore that possibility, we took an inventory of the types of graphs appearing in each assessment. We observed that three graph types appeared in both GGR and VLAT (i.e., <italic>bar chart</italic>, <italic>line graph</italic>, and <italic>pie chart</italic>), while there was one additional graph type that appeared only in GGR (i.e., <italic>icon array</italic>) and nine additional graph types appearing only in VLAT (i.e., <italic>stacked bar</italic>, <italic>100% stacked bar</italic>, <italic>histogram</italic>, <italic>area chart</italic>, <italic>stacked area chart</italic>, <italic>scatter plot</italic>, <italic>bubble chart</italic>, <italic>map</italic>, <italic>treemap</italic>). We found that performance reliably varied across graph types in the combined assessment (<inline-formula id="IEq12"><alternatives><tex-math id="d33e1037">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1042"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq12.gif"/></alternatives></inline-formula>(12) = 5066.18, <inline-formula id="IEq13"><alternatives><tex-math id="d33e1048">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1053"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq13.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001; Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). While both assessments have some overlap in graph types (i.e., bar graphs, line graphs, and pie charts), VLAT uses a broad range of additional graphs; this raises the possibility that the observed effect of graph type on accuracy reflects the combination of the two assessments. However, we find that performance varies significantly by graph type even when considering each assessment individually (<italic>GGR</italic>: <inline-formula id="IEq14"><alternatives><tex-math id="d33e1064">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1069"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq14.gif"/></alternatives></inline-formula>(3) = 125.18, <inline-formula id="IEq15"><alternatives><tex-math id="d33e1075">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1080"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq15.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001; <italic>VLAT</italic>: <inline-formula id="IEq16"><alternatives><tex-math id="d33e1087">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1092"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq16.gif"/></alternatives></inline-formula>(11) = 4919.30, <inline-formula id="IEq17"><alternatives><tex-math id="d33e1098">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1103"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq17.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001). The magnitude of this effect also reliably differed between samples (combined: <inline-formula id="IEq18"><alternatives><tex-math id="d33e1107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1112"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq18.gif"/></alternatives></inline-formula>(12) = 130.93, <inline-formula id="IEq19"><alternatives><tex-math id="d33e1119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1124"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq19.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001; GGR: <inline-formula id="IEq20"><alternatives><tex-math id="d33e1128">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1133"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq20.gif"/></alternatives></inline-formula>(3) = 8.67, <inline-formula id="IEq21"><alternatives><tex-math id="d33e1139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1144"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq21.gif"/></alternatives></inline-formula>&#x000a0;= .03; VLAT: <inline-formula id="IEq22"><alternatives><tex-math id="d33e1148">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1153"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq22.gif"/></alternatives></inline-formula>(11) = 112.01, <inline-formula id="IEq23"><alternatives><tex-math id="d33e1159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1164"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq23.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001), being larger in the demographically representative sample than in the university sample, perhaps reflecting the greater diversity in that sample relative to the university-based sample. Taken together, these results indicate that graph type accounts for a meaningful amount of variation in test performance, suggesting that participants found it easier to answer questions involving some kinds of graphs than others.</p></sec><sec id="Sec15"><title>Comparing performance across question type</title><p id="Par31">An additional factor that might account for variation in test performance is the type of question being asked. Perhaps some questions rely on skills that are more broadly shared across participants in the study, such as <italic>Level 1: Read the Data</italic> from GGR and <italic>retrieve value</italic> from VLAT, while other types of questions require understanding of more advanced statistical concepts that are familiar only to a minority of participants, such as the ability to <italic>find correlations/trends</italic> or <italic>characterize distribution</italic> in VLAT.</p><p id="Par32">Insofar as question type is a driver of variability in test performance, participants would be expected to achieve a higher level of accuracy on some types of questions than others. Consistent with this possibility, we found that performance reliably varied by question type, both when each assessment was analyzed independently (<italic>GGR</italic>: <inline-formula id="IEq24"><alternatives><tex-math id="d33e1189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1194"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq24.gif"/></alternatives></inline-formula>(2) = 1331.61, <inline-formula id="IEq25"><alternatives><tex-math id="d33e1200">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1205"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq25.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001; <italic>VLAT</italic>: <inline-formula id="IEq26"><alternatives><tex-math id="d33e1212">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1217"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq26.gif"/></alternatives></inline-formula>(7) = 1981.92, <inline-formula id="IEq27"><alternatives><tex-math id="d33e1224">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1229"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq27.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001; Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>) and when conducting the same analysis for all 11 question types in both assessments (<inline-formula id="IEq28"><alternatives><tex-math id="d33e1236">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1241"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq28.gif"/></alternatives></inline-formula>(10) = 3585.91, <inline-formula id="IEq29"><alternatives><tex-math id="d33e1247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1252"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq29.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001). In further exploratory analyses, we found that variation in performance associated with question type was greater in the demographically representative sample (overall: <inline-formula id="IEq30"><alternatives><tex-math id="d33e1256">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1261"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq30.gif"/></alternatives></inline-formula>(10) = 94.18, <inline-formula id="IEq31"><alternatives><tex-math id="d33e1267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1272"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq31.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001; GGR: <inline-formula id="IEq32"><alternatives><tex-math id="d33e1277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1282"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq32.gif"/></alternatives></inline-formula>(2) = 1.57, <inline-formula id="IEq33"><alternatives><tex-math id="d33e1288">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1293"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq33.gif"/></alternatives></inline-formula>&#x000a0;= .46; VLAT: <inline-formula id="IEq34"><alternatives><tex-math id="d33e1297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\chi^2$$\end{document}</tex-math><mml:math id="d33e1302"><mml:msup><mml:mi>&#x003c7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq34.gif"/></alternatives></inline-formula>(7) = 71.03, <inline-formula id="IEq35"><alternatives><tex-math id="d33e1308">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="d33e1313"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41235_2025_622_Article_IEq35.gif"/></alternatives></inline-formula>&#x000a0;&#x0003c; .0001), perhaps related to the greater heterogeneity in that sample. The finding that question type accounts for variation in test performance suggests that some types of questions are reliably more difficult than others.</p></sec><sec id="Sec16"><title>Comparing predictive models of performance</title><p id="Par33">Our findings so far provide evidence that both the type of graph used and the type of question being asked account for at least some of the explainable variance in average performance at the group level. However, an even stronger test of the explanatory value of these factors is their ability to account for variation in the <italic>patterns</italic> of errors that different individuals produce. For instance, insofar as the ability to &#x0201c;read the data&#x0201d; is distinct from the ability to &#x0201c;read beyond the data,&#x0201d; with some individuals having mastered one of these, and other individuals having mastered both, we would expect to be able to predict <italic>which</italic> questions are more likely to be answered correctly by some individuals than others in terms of those skills.</p><p id="Par34">To explore how well graph type and question type predict these individual differences in absolute terms, we sought to establish an upper bound for how well individual error patterns could be explained by any decomposition of these assessments. Toward that end, we used exploratory factor analysis (EFA) to infer the decomposition of the combined assessment that best accounted for observed error patterns across all items (see <italic>Exploratory Factor Analysis</italic> in the Methods section for details).<fig id="Fig6"><label>Fig. 6</label><caption><p>Comparing the ability of different factor-based models to predict individual participant error patterns. Inset indicates number of factors needed by best-performing latent factor model (each curve depicts model fit with increasing factors for a different subset of the data)</p></caption><graphic xlink:href="41235_2025_622_Fig6_HTML" id="MO6"/></fig></p><p id="Par35">First, we investigated how many factors would be needed to achieve strong out-of-sample behavioral predictivity without being too complex. When fitting the data with a variable number of factors, we found that a model with three to four factors consistently achieved the best performance, as measured using Bayesian Information Criterion (BIC; Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>, <italic>inset</italic>). These findings suggest that participants&#x02019; error patterns can be explained by a relatively compact set of factors, and far fewer than there are unique types of questions and graphs across VLAT and GGR.</p><p id="Par36">Next, we sought to directly compare the performance of idealized factor models based on graph type (13 factors), question type (11 factors), and test (2 factors) compared with that achieved by this <italic>latent factor</italic> model (4 factors) on held-out data under fivefold cross-validation. We compared the mean squared error (MSE) of the predictions made by each of our models (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>). We find that both the <italic>question type</italic> (MSE = 9.62, 95% CI: [9.09, 10.19]) and <italic>graph type</italic> (MSE = 5.07, 95% CI: [4.83, 5.32]) models perform better than a 2-factor <italic>test type</italic> model (MSE = 11.52, 95% CI: [10.57, 12.57]), suggesting that these features of the assessment items allow for systematic predictions of participants&#x02019; errors relative to the differentiation made by test alone. Further, we find that the 13-factor <italic>graph type</italic> model performs better than the 11-factor <italic>question type</italic> model, suggesting that fluency with some graphs and not others explains more variance in participant responses than their comfort with particular question types (Peebles and Cheng, <xref ref-type="bibr" rid="CR52">2003</xref>). Finally, both the <italic>graph type</italic> and <italic>question type</italic> models perform substantially worse than the 4-factor <italic>latent factor</italic> model (MSE = 0.93, 95% CI: [0.89, 0.96]). Taken together, these results suggest that neither graph type nor question type on their own can account for much of the explainable variation in individual error patterns.<fig id="Fig7"><label>Fig. 7</label><caption><p>Matrix indicating factor loading values across all items based on the latent factor model, grouped by test, question, and graph type. Darker cells reflect higher factor loading values. See Supplemental Materials for numerical loading values</p></caption><graphic xlink:href="41235_2025_622_Fig7_HTML" id="MO7"/></fig></p><p id="Par37">Instead, these error patterns may reflect a more complex interaction between graph type and question type, which is captured by the <italic>latent factor</italic> model. If that were the case, then some combinations of question type and graph type (e.g., <italic>find extremum</italic> for a <italic>histogram</italic>) would be expected to load strongly on a latent factor, while other items involving either just that question type or just that graph type would not. While items involving scatterplots and bubble charts seem to load onto factor 2, perhaps reflecting the similarity between these types of graphs, it is far less clear what unifies the items that load onto the remaining factors (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>; see Supplemental Materials for numerical loading values). Indeed, it seems possible that there are features of these items beyond graph type and question type information that might be needed to better explain these behavioral data. In sum, a small number of factors seems sufficient to account for individual error patterns across VLAT and GGR, but these factors do not obviously reflect the categories often used to differentiate items in these assessments.</p></sec></sec><sec id="Sec17"><title>Discussion</title><p id="Par38">In this study, we administered two widely used assessments of data visualization literacy (Galesic and Garcia-Retamero, <xref ref-type="bibr" rid="CR29">2011</xref>; Lee et al., <xref ref-type="bibr" rid="CR41">2016</xref>) to multiple independently recruited samples of US adult participants. Participants who performed well on one assessment also generally performed well on the other, suggesting some degree of convergence between these two measures. Moreover, performance on the combined assessment was associated with how much formal education in mathematics participants had received, an indicator of these assessments&#x02019; convergence with other measures of quantitative literacy. However, further investigation of individual variability in the patterns of mistakes that participants made suggests that these assessments probe a suite of skills that are only partially aligned with the grouping of items according to the type of question being asked or the type of graph being shown. That is, while there is some variance explained by these two variables, there remains substantial variance that remains unexplained by them and is better explained by an alternative set of factors that does not seem to have been explicitly encoded into the design of these two assessments.</p><p id="Par39">To make sense of these results, it could be helpful to draw a distinction between an abstract framework for organizing the space of skills relevant to data visualization literacy (i.e., graph type, question type) and the concrete measures used to probe that space of skills. Our results could imply limitations in the measures, the underlying framework, or both. However, it is often not feasible to distinguish between these possibilities on the basis of any individual study, including the current one.</p><p id="Par40">Nevertheless, clarifying these issues will likely involve conducting more thorough evaluations that include an expanded set of measures. For example, it might be useful to include assessments that focus on the ability to overcome potentially misleading data visualizations (Ge et al., <xref ref-type="bibr" rid="CR32">2023</xref>), as well as specific misconceptions that are common among students enrolled in introductory statistics courses (DelMas et al., <xref ref-type="bibr" rid="CR24">2005</xref>). However, even this broader set of existing assessments is still limited in several key ways. First, there are only a few examples of each type of graph represented across all of them. As such, the type of graph is almost always confounded with the variables being plotted, leaving it unclear whether variation in performance is attributable to core visualization literacy skills, rather than other factors (e.g., prior knowledge about those variables). Second, each test contains a relatively small and fixed set of items. With so few items, it is challenging to estimate the reliability with which any given skill is being measured. With only fixed sets of items, it is also not feasible to measure changes in data visualization literacy within the same individual, which is critical for assessing the impact of formal instruction.</p><p id="Par41">Thus, it would be valuable to develop new assessments, leveraging both best practices in psychometric research already exemplified by the design of existing tests (Boy et al., <xref ref-type="bibr" rid="CR13">2014</xref>; Lee et al., <xref ref-type="bibr" rid="CR41">2016</xref>), as well as practical strategies from modern machine learning for scaling the generation of test items for inclusion in cognitive assessments (Methani et al., <xref ref-type="bibr" rid="CR44">2020</xref>; Masry et al., <xref ref-type="bibr" rid="CR43">2022</xref>; Zelikman et al., <xref ref-type="bibr" rid="CR68">2023</xref>). In addition, given the broad set of skills that are recruited when interpreting a data visualization, it can be cumbersome to administer complete versions of every test, if the goal is to quickly assess an individual&#x02019;s literacy level. A more efficient alternative might be to use a more targeted set of items identified using item-response theory that are particularly diagnostic (Pandey and Ottley, <xref ref-type="bibr" rid="CR51">2023</xref>), or even use adaptive testing protocols that dynamically propose sequences of items to administer that will be most informative about an individual&#x02019;s literacy level given their responses so far (Cui et al., <xref ref-type="bibr" rid="CR23">2023</xref>). The approach taken in the current study could be used in conjunction with these more targeted and adaptive test development strategies to identify multiple facets of visualization literacy that would be valuable to estimate, which would entail going beyond conceptualizing literacy level as varying along a single dimension. Such improved assessments would be valuable for advancing educational assessment&#x02014;the understanding of how well core data literacy skills are being learned in real-world educational settings.</p><p id="Par42">Separately, our findings are also consistent with the possibility that there might be alternative frameworks for decomposing data visualization literacy that provide both more detailed and generalizable ways of predicting quantitative patterns in task performance. For instance, recent work employing qualitative methods to analyze process-level barriers to correct interpretation of data visualizations in VLAT has emphasized distinctions between errors in translating verbal questions into visual queries and errors in the interpretation of plot elements (Nobre et al., <xref ref-type="bibr" rid="CR46">2024</xref>). Extending such process-level analyses might be a promising route toward clarifying the relationship between the empirically derived decomposition uncovered in the current study and the typologies of data visualization literacy skills proposed in prior work (Friel et al., <xref ref-type="bibr" rid="CR28">2001</xref>; Brehmer and Munzner, <xref ref-type="bibr" rid="CR14">2013</xref>; B&#x000f6;rner et al., <xref ref-type="bibr" rid="CR12">2019</xref>). Measuring those component skills is important because they enable differentiation between individuals who might otherwise seem equally proficient, but actually have different strengths and weaknesses. Reliably diagnosing those strengths and weaknesses makes it possible to then provide instruction that is more effectively tailored to each individual.</p><p id="Par43">Beyond their role in educational assessment and instruction, new measures of data visualization literacy could also be instrumental for advancing fundamental understanding of the cognitive processes involved in the successful interpretation of data visualizations (Pinker, <xref ref-type="bibr" rid="CR54">1990</xref>; Padilla, <xref ref-type="bibr" rid="CR48">2018</xref>; Shah and Hoeffner, <xref ref-type="bibr" rid="CR61">2002</xref>). These processes include the rapid perceptual computations (Cleveland and McGill, <xref ref-type="bibr" rid="CR19">1984</xref>) performed with respect to a known graph schema (Pinker, <xref ref-type="bibr" rid="CR54">1990</xref>), explicit numerical operations (Gillan and Lewis, <xref ref-type="bibr" rid="CR33">1994</xref>) constrained by fintite working memory resources (Padilla et al., <xref ref-type="bibr" rid="CR49">2018</xref>), and interpretive processes that lead to more general insights (Carpenter and Shah, <xref ref-type="bibr" rid="CR18">1998</xref>), which may be influenced by prior content knowledge (Shah and Freedman, <xref ref-type="bibr" rid="CR60">2011</xref>). A more thorough understanding of each of these cognitive processes is a crucial step toward more unified cognitive models of data visualization understanding. One important purpose of such cognitive models is to explain why someone finds some questions easier to answer with one graph than another (Shah and Hoeffner, <xref ref-type="bibr" rid="CR61">2002</xref>; Huey et al., <xref ref-type="bibr" rid="CR39">2023</xref>). Previously developed cognitive models have proposed qualitative accounts of how people reason about data visualizations (Carpenter and Shah, <xref ref-type="bibr" rid="CR18">1998</xref>; Padilla et al., <xref ref-type="bibr" rid="CR49">2018</xref>). A promising avenue for future work is to develop <italic>computational</italic> cognitive models that specify the operations performed in explicit and quantitative terms: the form of the input, the form of the output, and the exact operations applied in between. Computational cognitive models have enabled major advances across several cognitive domains because they not only offer precise specifications of the mental processes involved, but also generate concrete behavioral outputs that can be directly compared to what people produce given the same inputs (Peterson et al., <xref ref-type="bibr" rid="CR53">2021</xref>; Cao and Yamins, <xref ref-type="bibr" rid="CR17">2024</xref>; Bear et al., <xref ref-type="bibr" rid="CR6">2021</xref>; Hu et al., <xref ref-type="bibr" rid="CR38">2022</xref>; Mukherjee et al., <xref ref-type="bibr" rid="CR45">2024</xref>). Future work employing these approaches are especially timely, as computational cognitive models&#x02014;and in particular, AI systems that perform complex real-world tasks&#x02014;have only recently advanced to the point that it is feasible to measure these models&#x02019; behavior on tasks that approach the complexity of those that humans encounter in real-world settings (Bommasani et&#x000a0;al., <xref ref-type="bibr" rid="CR11">2021</xref>).</p><p id="Par44">In the current study, we measured a positive relationship between the number of mathematics courses an individual had previously taken and how well they performed on the combined assessment, consistent with prior work examining the association between formal education and behavior on tasks involving data visualizations (Maltese et al., <xref ref-type="bibr" rid="CR42">2015</xref>; Harsh et al., <xref ref-type="bibr" rid="CR36">2019</xref>). However, while such correlative findings are suggestive, experimental studies are needed to firmly establish any causal relationships between specific learning experiences and subsequent task performance (Koedinger et al., <xref ref-type="bibr" rid="CR40">2023</xref>; Bhatt et&#x000a0;al., <xref ref-type="bibr" rid="CR9">2024</xref>; Solomon et al., <xref ref-type="bibr" rid="CR62">2019</xref>). A promising approach complementing studies with real students might be to conduct so-called <italic>in silico</italic> experiments with computational cognitive models. These models can be used to develop and test hypotheses about what kinds of experience are needed to acquire various data visualization literacy skills. A major advantage of <italic>in silico</italic> experiments is that they enable researchers to efficiently sweep through a wider range of possible learning conditions than can be practically and ethically implemented in real-world educational environments with human learners. By systematically manipulating the amount and type of experience a computational model receives, it is possible to investigate what kinds of experience are needed to succeed on some tasks and generalize to others (Zamir et al., <xref ref-type="bibr" rid="CR67">2018</xref>; Zhuang et al., <xref ref-type="bibr" rid="CR69">2021</xref>; Gupta et al., <xref ref-type="bibr" rid="CR34">2024</xref>). For example, a vision-language model might be pretrained on a suite of visual, language-based, and quantitative reasoning tasks before being evaluated on its ability to accurately interpret data visualizations (Gupta et al., <xref ref-type="bibr" rid="CR34">2024</xref>). Comparisons between this model and others that had been pretrained on only a subset of the same tasks could be used to assess the necessity of certain kinds of prior experience to generalize to reasoning tasks involving data visualizations.</p></sec><sec id="Sec18"><title>Conclusions</title><p id="Par45">In sum, the current study evaluated the convergent validity of two commonly used assessments of data visualization literacy. We found that these two measures exhibited a reasonable degree of convergence, such that people who achieved a high score on one assessment often did so on the other as well. In addition, we observed that individual variability in performance was related to how much formal education in mathematics an individual had received. To gain insight into the component skills that underlie the observed relationship between assessments, we used tools from machine learning to identify latent factors that best predicted individual error patterns. These latent factors achieve high predictive accuracy but do not align with existing typologies that have been used to structure these assessments (i.e., the type of graph, the kind of task being performed), suggesting the need for future work to characterize what component skills these factors identify. In sum, this work lays the groundwork for future efforts to develop improved and unified assessments that provide accurate and reliable estimates of the underlying components of data visualization literacy (Uttal et al., <xref ref-type="bibr" rid="CR65">2024</xref>). Over the long run, the development of unified measures of data visualization literacy is not only crucial for advancing cognitive theories of how people learn to extract meaning from abstract graphical representations, but might also lead to improved ways of teaching graphical literacy skills in real-world educational settings.</p></sec><sec id="Sec19"><title>Open Practices</title><p id="Par46">All data reported in this manuscript, along with analysis scripts used to generate the current results, are publicly available at the following GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/cogtoolslab/visualization_literacy_convergent_validity">https://github.com/cogtoolslab/visualization_literacy_convergent_validity</ext-link>.</p></sec><sec id="Sec20" sec-type="supplementary-material"><title>Supplementary Information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41235_2025_622_MOESM1_ESM.pdf"><caption><p>Supplementary file 1.</p></caption></media></supplementary-material></p></sec></body><back><fn-group><fn id="Fn1"><label>1</label><p id="Par51">All data, along with analysis scripts used to generate the current results, are publicly available at the following GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/cogtoolslab/visualization_literacy_convergent_validity">https://github.com/cogtoolslab/visualization_literacy_convergent_validity</ext-link>.</p></fn><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>Thanks to Amy Rae Fox for helpful feedback on this manuscript.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p><bold>EB</bold> was involved in conceptualization, methodology, software, validation, formal analysis, data curation, writing&#x02014;original draft, writing&#x02014;review and editing, visualization, supervision, and project administration. <bold>AV</bold> took part in, software, validation, formal analysis, data curation, and visualization. <bold>HL</bold> was responsible for conceptualization, methodology, software, validation, formal analysis, investigation, data curation, writing&#x02014;original draft, visualization, supervision, and project administration. <bold>HH</bold> performed methodology, software, investigation, writing&#x02014;original draft, and visualization. <bold>LP</bold> participated in conceptualization, methodology, writing&#x02014;original draft, writing&#x02014;review and editing, supervision, project administration, and funding acquisition. <bold>JEF</bold> was involved in conceptualization, methodology, validation, writing&#x02014;original draft, writing&#x02014;review and editing, visualization, supervision, project administration, and funding acquisition.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>This work was supported by NSF DRL award #2400471 and NSF CAREER award #2047191 to J.E.F. E.B. is supported by NSF SBE Postdoctoral Research Fellowship #2404706. L.P. is also supported by NSF CAREER Award #2238175 and NSF EAGER Award #2122174.</p></notes><notes notes-type="data-availability"><title>Availability of data and materials</title><p>All data described in this manuscript, along with analysis scripts used to generate the current results, are publicly available at the following GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/cogtoolslab/visualization_literacy_convergent_validity">https://github.com/cogtoolslab/visualization_literacy_convergent_validity</ext-link>.</p></notes><notes><title>Declarations</title><notes id="FPar1"><title>Ethics approval and consent to participate</title><p id="Par47">All participants in the experiments reported here provided informed consent in accordance with the University of California, San Diego Institutional Review Board.</p></notes><notes id="FPar2"><title>Consent for publication</title><p id="Par48">Not applicable.</p></notes><notes id="FPar3" notes-type="COI-statement"><title>Competing interests</title><p id="Par49">The authors declare that they have no conflict of interest.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><mixed-citation publication-type="other">Alper, B. , Riche, N.H. , Chevalier, F. , Boy, J. , &#x00026; Sezgin, M. (2017). Visualization literacy at elementary school. Proceedings of the 2017 chi conference on human factors in computing systems (pp. 5485&#x02013;5497).</mixed-citation></ref><ref id="CR2"><mixed-citation publication-type="other">Amar, R. , Eagan, J. , &#x00026; Stasko, J. (2005). Low-level components of analytic activity in information visualization. Ieee symposium on information visualization, 2005. infovis 2005. (pp. 111&#x02013;117).</mixed-citation></ref><ref id="CR3"><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Ancker</surname><given-names>JS</given-names></name><name><surname>Senathirajah</surname><given-names>Y</given-names></name><name><surname>Kukafka</surname><given-names>R</given-names></name><name><surname>Starren</surname><given-names>JB</given-names></name></person-group><article-title>Design features of graphs in health risk communication: A systematic review</article-title><source>Journal of the American Medical Informatics Association</source><year>2006</year><volume>13</volume><issue>6</issue><fpage>608</fpage><lpage>618</lpage><pub-id pub-id-type="pmid">16929039</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Ancker, J. S., Senathirajah, Y., Kukafka, R., &#x00026; Starren, J. B. (2006). Design features of graphs in health risk communication: A systematic review. <italic>Journal of the American Medical Informatics Association,</italic><italic>13</italic>(6), 608&#x02013;618.<pub-id pub-id-type="pmid">16929039</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Baayen</surname><given-names>RH</given-names></name><name><surname>Davidson</surname><given-names>DJ</given-names></name><name><surname>Bates</surname><given-names>DM</given-names></name></person-group><article-title>Mixed-effects modeling with crossed random effects for subjects and items</article-title><source>Journal of memory and language</source><year>2008</year><volume>59</volume><issue>4</issue><fpage>390</fpage><lpage>412</lpage></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Baayen, R. H., Davidson, D. J., &#x00026; Bates, D. M. (2008). Mixed-effects modeling with crossed random effects for subjects and items. <italic>Journal of memory and language,</italic><italic>59</italic>(4), 390&#x02013;412.</mixed-citation></citation-alternatives></ref><ref id="CR5"><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>M&#x000e4;chler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><article-title>Fitting linear mixed-effects models using lme4</article-title><source>Journal of Statistical Software</source><year>2015</year><volume>67</volume><issue>1</issue><fpage>1</fpage><lpage>48</lpage></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Bates, D., M&#x000e4;chler, M., Bolker, B., &#x00026; Walker, S. (2015). Fitting linear mixed-effects models using lme4. <italic>Journal of Statistical Software,</italic><italic>67</italic>(1), 1&#x02013;48.</mixed-citation></citation-alternatives></ref><ref id="CR6"><mixed-citation publication-type="other">Bear, D.M. , Wang, E. , Mrowca, D. , Binder, F.J. , Tung, H.- Y.F. , Pramod, R., ... others (2021). Physion: Evaluating physical prediction from vision in humans and machines. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2106.08261">arXiv:2106.08261</ext-link>,</mixed-citation></ref><ref id="CR7"><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname><given-names>CA</given-names></name><name><surname>Smith</surname><given-names>P</given-names></name></person-group><article-title>Assessing students&#x02019; abilities to construct and interpret line graphs: Disparities between multiple-choice and free-response instruments</article-title><source>Science Education</source><year>1994</year><volume>78</volume><issue>6</issue><fpage>527</fpage><lpage>554</lpage></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Berg, C. A., &#x00026; Smith, P. (1994). Assessing students&#x02019; abilities to construct and interpret line graphs: Disparities between multiple-choice and free-response instruments. <italic>Science Education,</italic><italic>78</italic>(6), 527&#x02013;554.</mixed-citation></citation-alternatives></ref><ref id="CR8"><mixed-citation publication-type="other">Bertin, J. (1981). <italic>Graphics and graphic information processing</italic>. Walter de Gruyter.</mixed-citation></ref><ref id="CR9"><mixed-citation publication-type="other">Bhatt, M.P. , Guryan, J. , Khan, S.A. , LaForest-Tucker, M. , &#x00026; Mishra, B. (2024May). Can technology facilitate scale? evidence from a randomized evaluation of high dosage tutoring Working Paper No. 32510. National Bureau of Economic Research. <ext-link ext-link-type="uri" xlink:href="http://www.nber.org/papers/w32510">http://www.nber.org/papers/w32510</ext-link></mixed-citation></ref><ref id="CR10"><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>F</given-names></name><name><surname>Zagermann</surname><given-names>J</given-names></name><name><surname>Pfeil</surname><given-names>U</given-names></name><name><surname>Sanderson</surname><given-names>G</given-names></name><name><surname>Reiterer</surname><given-names>H</given-names></name><name><surname>Hinrichs</surname><given-names>U</given-names></name></person-group><article-title>Construct-a-vis: Exploring the free-form visualization processes of children</article-title><source>IEEE Transactions on Visualization and Computer Graphics</source><year>2019</year><volume>26</volume><issue>1</issue><fpage>451</fpage><lpage>460</lpage><pub-id pub-id-type="pmid">31443024</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Bishop, F., Zagermann, J., Pfeil, U., Sanderson, G., Reiterer, H., &#x00026; Hinrichs, U. (2019). Construct-a-vis: Exploring the free-form visualization processes of children. <italic>IEEE Transactions on Visualization and Computer Graphics,</italic><italic>26</italic>(1), 451&#x02013;460.<pub-id pub-id-type="pmid">31443024</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><mixed-citation publication-type="other">Bommasani, R. , Hudson, D.A. , Adeli, E. , Altman, R. , Arora, S. , von Arx, S., ... others (2021). On the opportunities and risks of foundation models. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2108.07258">arXiv:2108.07258</ext-link>,</mixed-citation></ref><ref id="CR12"><mixed-citation publication-type="other">Boy, J., Rensink, R. A., Bertini, E., &#x00026; Fekete, J.- D. (2014). A principled way of assessing visualization literacy. <italic>IEEE Transactions on Visualization and Computer Graphics,</italic><italic>20</italic>(12), 1963&#x02013;1972.</mixed-citation></ref><ref id="CR13"><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Brehmer</surname><given-names>M</given-names></name><name><surname>Munzner</surname><given-names>T</given-names></name></person-group><article-title>A multi-level typology of abstract visualization tasks</article-title><source>IEEE Transactions on Visualization and Computer Graphics</source><year>2013</year><volume>19</volume><issue>12</issue><fpage>2376</fpage><lpage>2385</lpage><pub-id pub-id-type="pmid">24051804</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Brehmer, M., &#x00026; Munzner, T. (2013). A multi-level typology of abstract visualization tasks. <italic>IEEE Transactions on Visualization and Computer Graphics,</italic><italic>19</italic>(12), 2376&#x02013;2385.<pub-id pub-id-type="pmid">24051804</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Briggs</surname><given-names>SR</given-names></name><name><surname>Cheek</surname><given-names>JM</given-names></name></person-group><article-title>The role of factor analysis in the development and evaluation of personality scales</article-title><source>Journal of Personality</source><year>1986</year><volume>54</volume><issue>1</issue><fpage>106</fpage><lpage>148</lpage></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Briggs, S. R., &#x00026; Cheek, J. M. (1986). The role of factor analysis in the development and evaluation of personality scales. <italic>Journal of Personality,</italic><italic>54</italic>(1), 106&#x02013;148.</mixed-citation></citation-alternatives></ref><ref id="CR15"><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>B&#x000f6;rner</surname><given-names>K</given-names></name><name><surname>Bueckle</surname><given-names>A</given-names></name><name><surname>Ginda</surname><given-names>M</given-names></name></person-group><article-title>Data visualization literacy: Definitions, conceptual frameworks, exercises, and assessments</article-title><source>Proceedings of the National Academy of Sciences</source><year>2019</year><volume>116</volume><issue>6</issue><fpage>1857</fpage><lpage>1864</lpage></element-citation><mixed-citation id="mc-CR15" publication-type="journal">B&#x000f6;rner, K., Bueckle, A., &#x00026; Ginda, M. (2019). Data visualization literacy: Definitions, conceptual frameworks, exercises, and assessments. <italic>Proceedings of the National Academy of Sciences,</italic><italic>116</italic>(6), 1857&#x02013;1864.</mixed-citation></citation-alternatives></ref><ref id="CR16"><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>B&#x000f8;rner</surname><given-names>K</given-names></name><name><surname>Maltese</surname><given-names>A</given-names></name><name><surname>Balliet</surname><given-names>RN</given-names></name><name><surname>Heimlich</surname><given-names>J</given-names></name></person-group><article-title>Investigating aspects of data visualization literacy using 20 information visualizations and 273 science museum visitors</article-title><source>Information Visualization</source><year>2016</year><volume>15</volume><issue>3</issue><fpage>198</fpage><lpage>213</lpage></element-citation><mixed-citation id="mc-CR16" publication-type="journal">B&#x000f8;rner, K., Maltese, A., Balliet, R. N., &#x00026; Heimlich, J. (2016). Investigating aspects of data visualization literacy using 20 information visualizations and 273 science museum visitors. <italic>Information Visualization,</italic><italic>15</italic>(3), 198&#x02013;213.</mixed-citation></citation-alternatives></ref><ref id="CR17"><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>R</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name></person-group><article-title>Explanatory models in neuroscience, part 1: Taking mechanistic abstraction seriously</article-title><source>Cognitive Systems Research</source><year>2024</year><volume>87</volume><fpage>101244</fpage></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Cao, R., &#x00026; Yamins, D. (2024). Explanatory models in neuroscience, part 1: Taking mechanistic abstraction seriously. <italic>Cognitive Systems Research,</italic><italic>87</italic>, 101244.</mixed-citation></citation-alternatives></ref><ref id="CR18"><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>PA</given-names></name><name><surname>Shah</surname><given-names>P</given-names></name></person-group><article-title>A model of the perceptual and conceptual processes in graph comprehension</article-title><source>Journal of Experimental Psychology: Applied</source><year>1998</year><volume>4</volume><issue>2</issue><fpage>75</fpage></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Carpenter, P. A., &#x00026; Shah, P. (1998). A model of the perceptual and conceptual processes in graph comprehension. <italic>Journal of Experimental Psychology: Applied,</italic><italic>4</italic>(2), 75.</mixed-citation></citation-alternatives></ref><ref id="CR19"><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Cleveland</surname><given-names>WS</given-names></name><name><surname>McGill</surname><given-names>R</given-names></name></person-group><article-title>Graphical perception: Theory, experimentation, and application to the development of graphical methods</article-title><source>Journal of the American Statistical Association</source><year>1984</year><volume>79</volume><issue>387</issue><fpage>531</fpage><lpage>554</lpage></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Cleveland, W. S., &#x00026; McGill, R. (1984). Graphical perception: Theory, experimentation, and application to the development of graphical methods. <italic>Journal of the American Statistical Association,</italic><italic>79</italic>(387), 531&#x02013;554.</mixed-citation></citation-alternatives></ref><ref id="CR20"><mixed-citation publication-type="other">Council, N.R. (2014). Developing assessments for the next generation science standards.</mixed-citation></ref><ref id="CR21"><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Cowen</surname><given-names>AS</given-names></name><name><surname>Keltner</surname><given-names>D</given-names></name></person-group><article-title>Self-report captures 27 distinct categories of emotion bridged by continuous gradients</article-title><source>Proceedings of the National Academy of Sciences</source><year>2017</year><volume>114</volume><issue>38</issue><fpage>E7900</fpage><lpage>E7909</lpage></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Cowen, A. S., &#x00026; Keltner, D. (2017). Self-report captures 27 distinct categories of emotion bridged by continuous gradients. <italic>Proceedings of the National Academy of Sciences,</italic><italic>114</italic>(38), E7900&#x02013;E7909.</mixed-citation></citation-alternatives></ref><ref id="CR22"><mixed-citation publication-type="other">Creamer, M. , Padilla, L. , &#x00026; Borkin, M.A. (2024). Finding gaps in modern visualization literacy.</mixed-citation></ref><ref id="CR23"><mixed-citation publication-type="other">Cui, Y. , Lily, W.G. , Ding, Y. , Yang, F. , Harrison, L. , &#x00026; Kay, M. (2023). Adaptive assessment of visualization literacy. <italic>IEEE Transactions on Visualization and Computer Graphics</italic>,</mixed-citation></ref><ref id="CR24"><mixed-citation publication-type="other">DelMas, R. , Garfield, J. , &#x00026; Ooms, A. (2005). Using assessment items to study students&#x02019; difficulty reading and interpreting graphical representations of distributions. Proceedings of the fourth international research forum on statistical reasoning, thinking and literacy 2005.</mixed-citation></ref><ref id="CR25"><mixed-citation publication-type="other">Efron, B., &#x00026; Tibshirani, R.J. (1994). An introduction to the bootstrap. Chapman and Hall/CRC.</mixed-citation></ref><ref id="CR26"><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Eisenberg</surname><given-names>IW</given-names></name><name><surname>Bissett</surname><given-names>PG</given-names></name><name><surname>Zeynep Enkavi</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>MacKinnon</surname><given-names>DP</given-names></name><name><surname>Marsch</surname><given-names>LA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><article-title>Uncovering the structure of self-regulation through data-driven ontology discovery</article-title><source>Nature Communications</source><year>2019</year><volume>10</volume><issue>1</issue><fpage>2319</fpage><pub-id pub-id-type="pmid">31127115</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Eisenberg, I. W., Bissett, P. G., Zeynep Enkavi, A., Li, J., MacKinnon, D. P., Marsch, L. A., &#x00026; Poldrack, R. A. (2019). Uncovering the structure of self-regulation through data-driven ontology discovery. <italic>Nature Communications,</italic><italic>10</italic>(1), 2319.<pub-id pub-id-type="pmid">31127115</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Franconeri</surname><given-names>SL</given-names></name><name><surname>Padilla</surname><given-names>L</given-names></name><name><surname>Shah</surname><given-names>P</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Hullman</surname><given-names>J</given-names></name></person-group><article-title>The science of visual data communication: What works</article-title><source>Psychological Science in the Public Interest</source><year>2021</year><volume>22</volume><issue>3</issue><fpage>110</fpage><lpage>161</lpage><pub-id pub-id-type="pmid">34907835</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">Franconeri, S. L., Padilla, L., Shah, P., Zacks, J. M., &#x00026; Hullman, J. (2021). The science of visual data communication: What works. <italic>Psychological Science in the Public Interest,</italic><italic>22</italic>(3), 110&#x02013;161.<pub-id pub-id-type="pmid">34907835</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Friel</surname><given-names>SN</given-names></name><name><surname>Curcio</surname><given-names>FR</given-names></name><name><surname>Bright</surname><given-names>GW</given-names></name></person-group><article-title>Making sense of graphs: Critical factors influencing comprehension and instructional implications</article-title><source>Journal for Research in Mathematics Education</source><year>2001</year><volume>32</volume><issue>2</issue><fpage>124</fpage><lpage>158</lpage></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Friel, S. N., Curcio, F. R., &#x00026; Bright, G. W. (2001). Making sense of graphs: Critical factors influencing comprehension and instructional implications. <italic>Journal for Research in Mathematics Education,</italic><italic>32</italic>(2), 124&#x02013;158.</mixed-citation></citation-alternatives></ref><ref id="CR29"><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Galesic</surname><given-names>M</given-names></name><name><surname>Garcia-Retamero</surname><given-names>R</given-names></name></person-group><article-title>Graph literacy: A cross-cultural comparison</article-title><source>Medical Decision Making</source><year>2011</year><volume>31</volume><issue>3</issue><fpage>444</fpage><lpage>457</lpage><pub-id pub-id-type="pmid">20671213</pub-id>
</element-citation><mixed-citation id="mc-CR29" publication-type="journal">Galesic, M., &#x00026; Garcia-Retamero, R. (2011). Graph literacy: A cross-cultural comparison. <italic>Medical Decision Making,</italic><italic>31</italic>(3), 444&#x02013;457.<pub-id pub-id-type="pmid">20671213</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR30"><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia-Retamero</surname><given-names>R</given-names></name><name><surname>Cokely</surname><given-names>ET</given-names></name><name><surname>Ghazal</surname><given-names>S</given-names></name><name><surname>Joeris</surname><given-names>A</given-names></name></person-group><article-title>Measuring graph literacy without a test: A brief subjective assessment</article-title><source>Medical Decision Making</source><year>2016</year><volume>36</volume><issue>7</issue><fpage>854</fpage><lpage>867</lpage><pub-id pub-id-type="pmid">27353824</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Garcia-Retamero, R., Cokely, E. T., Ghazal, S., &#x00026; Joeris, A. (2016). Measuring graph literacy without a test: A brief subjective assessment. <italic>Medical Decision Making,</italic><italic>36</italic>(7), 854&#x02013;867.<pub-id pub-id-type="pmid">27353824</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Garfield</surname><given-names>JB</given-names></name><name><surname>Gal</surname><given-names>I</given-names></name></person-group><article-title>Assessment and statistics education: Current challenges and directions</article-title><source>International Statistical Review</source><year>1999</year><volume>67</volume><issue>1</issue><fpage>1</fpage><lpage>12</lpage></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Garfield, J. B., &#x00026; Gal, I. (1999). Assessment and statistics education: Current challenges and directions. <italic>International Statistical Review,</italic><italic>67</italic>(1), 1&#x02013;12.</mixed-citation></citation-alternatives></ref><ref id="CR32"><mixed-citation publication-type="other">Ge, L.W. , Cui, Y. , &#x00026; Kay, M. (2023). Calvi: Critical thinking assessment for literacy in visualizations. Proceedings of the 2023 chi conference on human factors in computing systems (pp. 1&#x02013;18).</mixed-citation></ref><ref id="CR33"><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Gillan</surname><given-names>DJ</given-names></name><name><surname>Lewis</surname><given-names>R</given-names></name></person-group><article-title>A componential model of human interaction with graphs: 1 linear regression modeling</article-title><source>Human Factors</source><year>1994</year><volume>36</volume><issue>3</issue><fpage>419</fpage><lpage>440</lpage><pub-id pub-id-type="pmid">7989050</pub-id>
</element-citation><mixed-citation id="mc-CR33" publication-type="journal">Gillan, D. J., &#x00026; Lewis, R. (1994). A componential model of human interaction with graphs: 1 linear regression modeling. <italic>Human Factors,</italic><italic>36</italic>(3), 419&#x02013;440.<pub-id pub-id-type="pmid">7989050</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR34"><mixed-citation publication-type="other">Gupta, A. , Gupta, V. , Zhang, S. , He, Y. , Zhang, N. , &#x00026; Shah, S. (2024). Enhancing question answering on charts through effective pre-training tasks. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2406.10085">arXiv:2406.10085</ext-link>,</mixed-citation></ref><ref id="CR35"><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Haig</surname><given-names>BD</given-names></name></person-group><article-title>Exploratory factor analysis, theory generation, and scientific method</article-title><source>Multivariate Behavioral Research</source><year>2005</year><volume>40</volume><issue>3</issue><fpage>303</fpage><lpage>329</lpage><pub-id pub-id-type="pmid">26794686</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Haig, B. D. (2005). Exploratory factor analysis, theory generation, and scientific method. <italic>Multivariate Behavioral Research,</italic><italic>40</italic>(3), 303&#x02013;329.<pub-id pub-id-type="pmid">26794686</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Harsh</surname><given-names>JA</given-names></name><name><surname>Campillo</surname><given-names>M</given-names></name><name><surname>Murray</surname><given-names>C</given-names></name><name><surname>Myers</surname><given-names>C</given-names></name><name><surname>Nguyen</surname><given-names>J</given-names></name><name><surname>Maltese</surname><given-names>AV</given-names></name></person-group><article-title>"seeing" data like an expert: An eye-tracking study using graphical data representations</article-title><source>CBE-Life Sciences Education</source><year>2019</year><volume>18</volume><issue>3</issue><fpage>ar32</fpage><pub-id pub-id-type="pmid">31397653</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal">Harsh, J. A., Campillo, M., Murray, C., Myers, C., Nguyen, J., &#x00026; Maltese, A. V. (2019). &#x0201c;seeing&#x0201d; data like an expert: An eye-tracking study using graphical data representations. <italic>CBE-Life Sciences Education,</italic><italic>18</italic>(3), ar32.<pub-id pub-id-type="pmid">31397653</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><mixed-citation publication-type="other">Hedayati, M. , Hunt, A. , &#x00026; Kay, M. (2024). From pixels to practices: Reconceptualizing visualization literacy.</mixed-citation></ref><ref id="CR38"><mixed-citation publication-type="other">Hu, J. , Floyd, S. , Jouravlev, O. , Fedorenko, E. , &#x00026; Gibson, E. (2022). A fine-grained comparison of pragmatic language understanding in humans and language models. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2212.06801">arXiv:2212.06801</ext-link>,</mixed-citation></ref><ref id="CR39"><mixed-citation publication-type="other">Huey, H. , Oey, L.A. , Lloyd, H. , &#x00026; Fan, J.E. (2023). How do communicative goals guide which data visualizations people think are effective? Proceedings of the annual meeting of the cognitive science society (Vol.45).</mixed-citation></ref><ref id="CR40"><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name><surname>Koedinger</surname><given-names>KR</given-names></name><name><surname>Carvalho</surname><given-names>PF</given-names></name><name><surname>Liu</surname><given-names>R</given-names></name><name><surname>McLaughlin</surname><given-names>EA</given-names></name></person-group><article-title>An astonishing regularity in student learning rate</article-title><source>Proceedings of the National Academy of Sciences</source><year>2023</year><volume>120</volume><issue>13</issue><fpage>e2221311120</fpage></element-citation><mixed-citation id="mc-CR40" publication-type="journal">Koedinger, K. R., Carvalho, P. F., Liu, R., &#x00026; McLaughlin, E. A. (2023). An astonishing regularity in student learning rate. <italic>Proceedings of the National Academy of Sciences,</italic><italic>120</italic>(13), e2221311120.</mixed-citation></citation-alternatives></ref><ref id="CR41"><mixed-citation publication-type="other">Lee, S., &#x00026; Kim, S.- H., &#x00026; Kwon, B.C. (2016). Vlat: Development of a visualization literacy assessment test. <italic>IEEE Transactions on Visualization and Computer Graphics,</italic><italic>23</italic>(1), 551&#x02013;560.</mixed-citation></ref><ref id="CR42"><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>Maltese</surname><given-names>AV</given-names></name><name><surname>Harsh</surname><given-names>JA</given-names></name><name><surname>Svetina</surname><given-names>D</given-names></name></person-group><article-title>Data visualization literacy: Investigating data interpretation along the novice-expert continuum</article-title><source>Journal of College Science Teaching</source><year>2015</year><volume>45</volume><issue>1</issue><fpage>84</fpage><lpage>90</lpage></element-citation><mixed-citation id="mc-CR42" publication-type="journal">Maltese, A. V., Harsh, J. A., &#x00026; Svetina, D. (2015). Data visualization literacy: Investigating data interpretation along the novice-expert continuum. <italic>Journal of College Science Teaching,</italic><italic>45</italic>(1), 84&#x02013;90.</mixed-citation></citation-alternatives></ref><ref id="CR43"><mixed-citation publication-type="other">Masry, A. , Long, D.X. , Tan, J.Q. , Joty, S. , &#x00026; Hoque, E. (2022). Chartqa: A benchmark for question answering about charts with visual and logical reasoning. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2203.10244">arXiv:2203.10244</ext-link>,</mixed-citation></ref><ref id="CR44"><mixed-citation publication-type="other">Methani, N. , Ganguly, P. , Khapra, M.M. , &#x00026; Kumar, P. (2020). Plotqa: Reasoning over scientific plots. Proceedings of the ieee/cvf winter conference on applications of computer vision (pp. 1527&#x02013;1536).</mixed-citation></ref><ref id="CR45"><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name><surname>Mukherjee</surname><given-names>K</given-names></name><name><surname>Huey</surname><given-names>H</given-names></name><name><surname>Lu</surname><given-names>X</given-names></name><name><surname>Vinker</surname><given-names>Y</given-names></name><name><surname>Aguina-Kang</surname><given-names>R</given-names></name><name><surname>Shamir</surname><given-names>A</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name></person-group><article-title>Seva: Leveraging sketches to evaluate alignment between human and machine visual abstraction</article-title><source>Advances in Neural Information Processing Systems</source><year>2024</year><volume>36</volume><fpage>67138</fpage></element-citation><mixed-citation id="mc-CR45" publication-type="journal">Mukherjee, K., Huey, H., Lu, X., Vinker, Y., Aguina-Kang, R., Shamir, A., &#x00026; Fan, J. (2024). Seva: Leveraging sketches to evaluate alignment between human and machine visual abstraction. <italic>Advances in Neural Information Processing Systems,</italic><italic>36</italic>, 67138.</mixed-citation></citation-alternatives></ref><ref id="CR46"><mixed-citation publication-type="other">Nobre, C. , Zhu, K. , M&#x000f6;rth, E. , Pfister, H. , &#x00026; Beyer, J. (2024). Reading between the pixels: Investigating the barriers to visualization literacy. Proceedings of the chi conference on human factors in computing systems (pp. 1&#x02013;17).</mixed-citation></ref><ref id="CR47"><citation-alternatives><element-citation id="ec-CR47" publication-type="journal"><person-group person-group-type="author"><name><surname>Okan</surname><given-names>Y</given-names></name><name><surname>Janssen</surname><given-names>E</given-names></name><name><surname>Galesic</surname><given-names>M</given-names></name><name><surname>Waters</surname><given-names>EA</given-names></name></person-group><article-title>Using the short graph literacy scale to predict precursors of health behavior change</article-title><source>Medical Decision Making</source><year>2019</year><volume>39</volume><fpage>183</fpage><lpage>195</lpage><pub-id pub-id-type="pmid">30845893</pub-id>
</element-citation><mixed-citation id="mc-CR47" publication-type="journal">Okan, Y., Janssen, E., Galesic, M., &#x00026; Waters, E. A. (2019). Using the short graph literacy scale to predict precursors of health behavior change. <italic>Medical Decision Making,</italic><italic>39</italic>, 183&#x02013;195.<pub-id pub-id-type="pmid">30845893</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR48"><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name><surname>Padilla</surname><given-names>L</given-names></name><name><surname>Creem-Regehr</surname><given-names>SH</given-names></name><name><surname>Hegarty</surname><given-names>M</given-names></name><name><surname>Stefanucci</surname><given-names>JK</given-names></name></person-group><article-title>Decision making with visualizations: A cognitive framework across disciplines</article-title><source>Cognitive Research: Principles and Implications</source><year>2018</year><volume>3</volume><issue>1</issue><fpage>1</fpage><lpage>25</lpage><pub-id pub-id-type="pmid">29399620</pub-id>
</element-citation><mixed-citation id="mc-CR48" publication-type="journal">Padilla, L., Creem-Regehr, S. H., Hegarty, M., &#x00026; Stefanucci, J. K. (2018). Decision making with visualizations: A cognitive framework across disciplines. <italic>Cognitive Research: Principles and Implications,</italic><italic>3</italic>(1), 1&#x02013;25.<pub-id pub-id-type="pmid">29399620</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR49"><citation-alternatives><element-citation id="ec-CR49" publication-type="journal"><person-group person-group-type="author"><name><surname>Padilla</surname><given-names>L</given-names></name><name><surname>Hosseinpour</surname><given-names>H</given-names></name><name><surname>Fygenson</surname><given-names>R</given-names></name><name><surname>Howell</surname><given-names>J</given-names></name><name><surname>Chunara</surname><given-names>R</given-names></name><name><surname>Bertini</surname><given-names>E</given-names></name></person-group><article-title>Impact of covid-19 forecast visualizations on pandemic risk perceptions</article-title><source>Scientific Reports</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>2014</fpage><pub-id pub-id-type="pmid">35132079</pub-id>
</element-citation><mixed-citation id="mc-CR49" publication-type="journal">Padilla, L., Hosseinpour, H., Fygenson, R., Howell, J., Chunara, R., &#x00026; Bertini, E. (2022). Impact of covid-19 forecast visualizations on pandemic risk perceptions. <italic>Scientific Reports,</italic><italic>12</italic>(1), 2014.<pub-id pub-id-type="pmid">35132079</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR50"><mixed-citation publication-type="other">Padilla, L. (2018). A case for cognitive models in visualization research: Position paper. 2018 IEEE evaluation and beyond-methodological approaches for visualization (beliv) (pp. 69&#x02013;77).</mixed-citation></ref><ref id="CR51"><mixed-citation publication-type="other">Pandey, S., &#x00026; Ottley, A. (2023). Mini-vlat: A short and effective measure of visualization literacy. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2304.07905">arXiv:2304.07905</ext-link>,</mixed-citation></ref><ref id="CR52"><mixed-citation publication-type="other">Peebles, D., &#x00026; Cheng, P.C.- H. (2003). Modeling the effect of task and graphical representation on response latency in a graph reading task. <italic>Human Factors,</italic><italic>45</italic>(1), 28&#x02013;46.</mixed-citation></ref><ref id="CR53"><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>JC</given-names></name><name><surname>Bourgin</surname><given-names>DD</given-names></name><name><surname>Agrawal</surname><given-names>M</given-names></name><name><surname>Reichman</surname><given-names>D</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name></person-group><article-title>Using large-scale experiments and machine learning to discover theories of human decision-making</article-title><source>Science</source><year>2021</year><volume>372</volume><issue>6547</issue><fpage>1209</fpage><lpage>1214</lpage><pub-id pub-id-type="pmid">34112693</pub-id>
</element-citation><mixed-citation id="mc-CR53" publication-type="journal">Peterson, J. C., Bourgin, D. D., Agrawal, M., Reichman, D., &#x00026; Griffiths, T. L. (2021). Using large-scale experiments and machine learning to discover theories of human decision-making. <italic>Science,</italic><italic>372</italic>(6547), 1209&#x02013;1214.<pub-id pub-id-type="pmid">34112693</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR54"><mixed-citation publication-type="other">Pinker, S. (1990). A theory of graph comprehension. <italic>Artificial intelligence and the future of testing</italic>73&#x02013;126,</mixed-citation></ref><ref id="CR55"><mixed-citation publication-type="other">Playfair, W. (1801). The commercial and political atlas: Representing, by means of stained copper-plate charts, the progress of the commerce, revenues, expenditure and debts of england during the whole of the eighteenth century. T. Burton.</mixed-citation></ref><ref id="CR56"><citation-alternatives><element-citation id="ec-CR56" publication-type="journal"><person-group person-group-type="author"><name><surname>Preacher</surname><given-names>KJ</given-names></name><name><surname>Zhang</surname><given-names>G</given-names></name><name><surname>Kim</surname><given-names>C</given-names></name><name><surname>Mels</surname><given-names>G</given-names></name></person-group><article-title>Choosing the optimal number of factors in exploratory factor analysis: A model selection perspective</article-title><source>Multivariate Behavioral Research</source><year>2013</year><volume>48</volume><issue>1</issue><fpage>28</fpage><lpage>56</lpage><pub-id pub-id-type="pmid">26789208</pub-id>
</element-citation><mixed-citation id="mc-CR56" publication-type="journal">Preacher, K. J., Zhang, G., Kim, C., &#x00026; Mels, G. (2013). Choosing the optimal number of factors in exploratory factor analysis: A model selection perspective. <italic>Multivariate Behavioral Research,</italic><italic>48</italic>(1), 28&#x02013;56.<pub-id pub-id-type="pmid">26789208</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR57"><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname><given-names>MM</given-names></name><name><surname>Crumley-Branyon</surname><given-names>JJ</given-names></name><name><surname>Leidheiser</surname><given-names>WR</given-names></name><name><surname>Pak</surname><given-names>R</given-names></name></person-group><article-title>Effects of information visualization on older adults&#x02019; decision-making performance in a medicare plan selection task: A comparative usability study</article-title><source>JMIR Human Factors</source><year>2016</year><volume>3</volume><issue>1</issue><fpage>e5106</fpage></element-citation><mixed-citation id="mc-CR57" publication-type="journal">Price, M. M., Crumley-Branyon, J. J., Leidheiser, W. R., &#x00026; Pak, R. (2016). Effects of information visualization on older adults&#x02019; decision-making performance in a medicare plan selection task: A comparative usability study. <italic>JMIR Human Factors,</italic><italic>3</italic>(1), e5106.</mixed-citation></citation-alternatives></ref><ref id="CR58"><citation-alternatives><element-citation id="ec-CR58" publication-type="journal"><person-group person-group-type="author"><name><surname>Ruginski</surname><given-names>IT</given-names></name><name><surname>Boone</surname><given-names>AP</given-names></name><name><surname>Padilla</surname><given-names>LM</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Heydari</surname><given-names>N</given-names></name><name><surname>Kramer</surname><given-names>HS</given-names></name><name><surname>Creem-Regehr</surname><given-names>SH</given-names></name></person-group><article-title>Non-expert interpretations of hurricane forecast uncertainty visualizations</article-title><source>Spatial Cognition &#x00026; Computation</source><year>2016</year><volume>16</volume><issue>2</issue><fpage>154</fpage><lpage>172</lpage></element-citation><mixed-citation id="mc-CR58" publication-type="journal">Ruginski, I. T., Boone, A. P., Padilla, L. M., Liu, L., Heydari, N., Kramer, H. S., &#x00026; Creem-Regehr, S. H. (2016). Non-expert interpretations of hurricane forecast uncertainty visualizations. <italic>Spatial Cognition &#x00026; Computation,</italic><italic>16</italic>(2), 154&#x02013;172.</mixed-citation></citation-alternatives></ref><ref id="CR59"><mixed-citation publication-type="other">Schwarz, G. (1978). Estimating the dimension of a model. <italic>The annals of statistics</italic>461&#x02013;464,</mixed-citation></ref><ref id="CR60"><citation-alternatives><element-citation id="ec-CR60" publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>P</given-names></name><name><surname>Freedman</surname><given-names>EG</given-names></name></person-group><article-title>Bar and line graph comprehension: An interaction of top-down and bottom-up processes</article-title><source>Topics in Cognitive Science</source><year>2011</year><volume>3</volume><issue>3</issue><fpage>560</fpage><lpage>578</lpage><pub-id pub-id-type="pmid">25164403</pub-id>
</element-citation><mixed-citation id="mc-CR60" publication-type="journal">Shah, P., &#x00026; Freedman, E. G. (2011). Bar and line graph comprehension: An interaction of top-down and bottom-up processes. <italic>Topics in Cognitive Science,</italic><italic>3</italic>(3), 560&#x02013;578.<pub-id pub-id-type="pmid">25164403</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR61"><citation-alternatives><element-citation id="ec-CR61" publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>P</given-names></name><name><surname>Hoeffner</surname><given-names>J</given-names></name></person-group><article-title>Review of graph comprehension research: Implications for instruction</article-title><source>Educational Psychology Review</source><year>2002</year><volume>14</volume><issue>1</issue><fpage>47</fpage><lpage>69</lpage></element-citation><mixed-citation id="mc-CR61" publication-type="journal">Shah, P., &#x00026; Hoeffner, J. (2002). Review of graph comprehension research: Implications for instruction. <italic>Educational Psychology Review,</italic><italic>14</italic>(1), 47&#x02013;69.</mixed-citation></citation-alternatives></ref><ref id="CR62"><citation-alternatives><element-citation id="ec-CR62" publication-type="journal"><person-group person-group-type="author"><name><surname>Solomon</surname><given-names>T</given-names></name><name><surname>Dupuis</surname><given-names>A</given-names></name><name><surname>O&#x02019;Hara</surname><given-names>A</given-names></name><name><surname>Hockenberry</surname><given-names>M-N</given-names></name><name><surname>Lam</surname><given-names>J</given-names></name><name><surname>Goco</surname><given-names>G</given-names></name><name><surname>Tannock</surname><given-names>R</given-names></name></person-group><article-title>A cluster-randomized controlled trial of the effectiveness of the jump math program of math instruction for improving elementary math achievement</article-title><source>PloS One</source><year>2019</year><volume>14</volume><issue>14</issue><fpage>e0223049</fpage><pub-id pub-id-type="pmid">31665143</pub-id>
</element-citation><mixed-citation id="mc-CR62" publication-type="journal">Solomon, T., Dupuis, A., O&#x02019;Hara, A., &#x00026; Hockenberry, M.- N., Lam, J., Goco, G., Tannock, R. (2019). A cluster-randomized controlled trial of the effectiveness of the jump math program of math instruction for improving elementary math achievement. <italic>PloS One,</italic><italic>14</italic>(10), e0223049.<pub-id pub-id-type="pmid">31665143</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR63"><mixed-citation publication-type="other">Spence, I. (2006). William playfair and the psychology of graphs. Proceedings of the american statistical association, section on statistical graphics (pp. 2426&#x02013;2436).</mixed-citation></ref><ref id="CR64"><mixed-citation publication-type="other">Tufte, E.R. (1983). The visual display of quantitative information (Vol.2). Graphics press Cheshire, CT.</mixed-citation></ref><ref id="CR65"><citation-alternatives><element-citation id="ec-CR65" publication-type="journal"><person-group person-group-type="author"><name><surname>Uttal</surname><given-names>DH</given-names></name><name><surname>McKee</surname><given-names>K</given-names></name><name><surname>Simms</surname><given-names>N</given-names></name><name><surname>Hegarty</surname><given-names>M</given-names></name><name><surname>Newcombe</surname><given-names>NS</given-names></name></person-group><article-title>How can we best assess spatial skills? practical and conceptual challenges</article-title><source>Journal of Intelligence</source><year>2024</year><volume>12</volume><issue>1</issue><fpage>8</fpage><pub-id pub-id-type="pmid">38248906</pub-id>
</element-citation><mixed-citation id="mc-CR65" publication-type="journal">Uttal, D. H., McKee, K., Simms, N., Hegarty, M., &#x00026; Newcombe, N. S. (2024). How can we best assess spatial skills? practical and conceptual challenges. <italic>Journal of Intelligence,</italic><italic>12</italic>(1), 8.<pub-id pub-id-type="pmid">38248906</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR66"><citation-alternatives><element-citation id="ec-CR66" publication-type="book"><person-group person-group-type="author"><name><surname>Wilkinson</surname><given-names>L</given-names></name></person-group><source>The grammar of graphics</source><year>2012</year><publisher-name>Springer</publisher-name></element-citation><mixed-citation id="mc-CR66" publication-type="book">Wilkinson, L. (2012). <italic>The grammar of graphics</italic>. Springer.</mixed-citation></citation-alternatives></ref><ref id="CR67"><mixed-citation publication-type="other">Zamir, A.R. , Sax, A. , Shen, W. , Guibas, L.J. , Malik, J. , &#x00026; Savarese, S. (2018). Taskonomy: Disentangling task transfer learning. Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3712&#x02013;3722).</mixed-citation></ref><ref id="CR68"><mixed-citation publication-type="other">Zelikman, E. , Ma, W.A. , Tran, J.E. , Yang, D. , Yeatman, J.D. , &#x00026; Haber, N. (2023). Generating and evaluating tests for k-12 students with language model simulations: A case study on sentence reading efficiency. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2310.06837">arXiv:2310.06837</ext-link>,</mixed-citation></ref><ref id="CR69"><citation-alternatives><element-citation id="ec-CR69" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhuang</surname><given-names>C</given-names></name><name><surname>Yan</surname><given-names>S</given-names></name><name><surname>Nayebi</surname><given-names>A</given-names></name><name><surname>Schrimpf</surname><given-names>M</given-names></name><name><surname>Frank</surname><given-names>MC</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Yamins</surname><given-names>DL</given-names></name></person-group><article-title>Unsupervised neural network models of the ventral visual stream</article-title><source>Proceedings of the National Academy of Sciences</source><year>2021</year><volume>118</volume><issue>3</issue><fpage>e2014196118</fpage></element-citation><mixed-citation id="mc-CR69" publication-type="journal">Zhuang, C., Yan, S., Nayebi, A., Schrimpf, M., Frank, M. C., DiCarlo, J. J., &#x00026; Yamins, D. L. (2021). Unsupervised neural network models of the ventral visual stream. <italic>Proceedings of the National Academy of Sciences,</italic><italic>118</italic>(3), e2014196118.</mixed-citation></citation-alternatives></ref></ref-list></back></article>