<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">JAMA Netw Open</journal-id><journal-id journal-id-type="iso-abbrev">JAMA Netw Open</journal-id><journal-title-group><journal-title>JAMA Network Open</journal-title></journal-title-group><issn pub-type="epub">2574-3805</issn><publisher><publisher-name>American Medical Association</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40408109</article-id><article-id pub-id-type="pmc">PMC12102709</article-id>
<article-id pub-id-type="doi">10.1001/jamanetworkopen.2025.11922</article-id><article-id pub-id-type="publisher-id">zoi250402</article-id><article-categories><subj-group subj-group-type="category" specific-use="electronic"><subject>Research</subject></subj-group><subj-group subj-group-type="heading"><subject>Original Investigation</subject></subj-group><subj-group subj-group-type="online-only"><subject>Online Only</subject></subj-group><subj-group subj-group-type="subject-area"><subject>Psychiatry</subject></subj-group></article-categories><title-group><article-title>Large Language Models and Text Embeddings for Detecting Depression and Suicide in Patient Narratives</article-title><alt-title alt-title-type="headline">LLMs and Text Embeddings to Detect Depression and Suicide in Patient Narratives</alt-title><alt-title alt-title-type="running-head">LLMs and Text Embeddings to Detect Depression and Suicide in Patient Narratives</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Lho</surname><given-names>Silvia Kyungjin</given-names></name><degrees>MD</degrees><degrees>PhD</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Park</surname><given-names>Sang-Cheol</given-names></name><degrees>PhD</degrees><xref rid="zoi250402aff2" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Lee</surname><given-names>Hahyun</given-names></name><degrees>BA</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="zoi250402aff3" ref-type="aff">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Oh</surname><given-names>Da Young</given-names></name><degrees>MA</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Kim</surname><given-names>Hyeonjin</given-names></name><degrees>PhD</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Jang</surname><given-names>Soomin</given-names></name><degrees>MD</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Jung</surname><given-names>Hee Yeon</given-names></name><degrees>MD</degrees><degrees>PhD</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="zoi250402aff4" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Yoo</surname><given-names>So Young</given-names></name><degrees>MD</degrees><degrees>PhD</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="zoi250402aff4" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Park</surname><given-names>Su Mi</given-names></name><degrees>PhD</degrees><xref rid="zoi250402aff5" ref-type="aff">
<sup>5</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Lee</surname><given-names>Jun-Young</given-names></name><degrees>MD</degrees><degrees>PhD</degrees><xref rid="zoi250402aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="zoi250402aff3" ref-type="aff">
<sup>3</sup>
</xref><xref rid="zoi250402aff4" ref-type="aff">
<sup>4</sup>
</xref></contrib></contrib-group><aff id="zoi250402aff1"><label>1</label>Department of Psychiatry, Seoul Metropolitan Government&#x02013;Seoul National University Boramae Medical Center, Seoul, Republic of Korea</aff><aff id="zoi250402aff2"><label>2</label>Institute for Biomaterials, Korea University, Seoul, Republic of Korea</aff><aff id="zoi250402aff3"><label>3</label>Interdisciplinary Program in Cognitive Science, Seoul National University, Seoul, Republic of Korea</aff><aff id="zoi250402aff4"><label>4</label>Department of Psychiatry, Seoul National University College of Medicine, Seoul, Republic of Korea</aff><aff id="zoi250402aff5"><label>5</label>Department of Counseling Psychology, Hannam University, Daejeon, Republic of Korea</aff><author-notes><title>Article Information</title><p><bold>Accepted for Publication:</bold> March 21, 2025.</p><p content-type="published-online"><bold>Published:</bold> May 23, 2025. doi:<uri content-type="doi">10.1001/jamanetworkopen.2025.11922</uri></p><p content-type="open-access-note"><bold>Open Access:</bold> This is an open access article distributed under the terms of the <ext-link xlink:href="https://jamanetwork.com/pages/cc-by-license-permissions" ext-link-type="uri">CC-BY License</ext-link>. &#x000a9; 2025 Lho SK et al. <italic>JAMA Network Open</italic>.</p><corresp id="zoi250402cor1"><bold>Corresponding Authors:</bold> Jun-Young Lee, MD, PhD, Department of Psychiatry, Seoul Metropolitan Government-Seoul National University, Boramae Medical Center, 20 Boramae-ro 5-gil, Dongjak-gu, Seoul 07061, Republic of Korea (<email xlink:href="benji@snu.ac.kr">benji@snu.ac.kr</email>); Su Mi Park, PhD, Department of Counseling Psychology, Hannam University, 70 Hannamro, Daedeok-Gu Daejeon 34430, Republic of Korea (<email xlink:href="sumipark@hnu.kr">sumipark@hnu.kr</email>).</corresp><p content-type="author-contributions"><bold>Author Contributions:</bold> Drs Lho and J.-Y. Lee had full access to all of the data in the study and take responsibility for the integrity of the data and the accuracy of the data analysis.</p><p><italic>Concept and design:</italic> Lho, S.-C. Park, S. M. Park, J.-Y. Lee.</p><p><italic>Acquisition, analysis, or interpretation of data:</italic> All authors.</p><p><italic>Drafting of the manuscript:</italic> Lho.</p><p><italic>Critical review of the manuscript for important intellectual content:</italic> All authors.</p><p><italic>Statistical analysis:</italic> Lho, S.-C. Park.</p><p><italic>Obtained funding:</italic> S. M. Park, J.-Y. Lee.</p><p><italic>Administrative, technical, or material support:</italic> All authors.</p><p><italic>Supervision:</italic> Lho, S.-C. Park, Jang, Jung, Yoo, S. M. Park, J.-Y. Lee.</p><p content-type="COI-statement"><bold>Conflict of Interest Disclosures:</bold> None reported.</p><p content-type="funding-statement"><bold>Funding/Support:</bold> This work was supported by the National Research Foundation of Korea (NRF) grants NRF-2021R1G1A1092763 and RS-2024-00457381 funded by the Korean government.</p><p><bold>Role of the Funder/Sponsor:</bold> The funding source had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.</p><p content-type="data-sharing-statement"><bold>Data Sharing Statement:</bold> See <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 2</xref>.</p></author-notes><pub-date pub-type="epub" iso-8601-date="2025-05-23T10:00"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>5</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>23</day><month>5</month><year>2025</year></pub-date><!--PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>.--><volume>8</volume><issue>5</issue><elocation-id>e2511922</elocation-id><history><date date-type="received"><day>27</day><month>11</month><year>2024</year></date><date date-type="accepted"><day>21</day><month>3</month><year>2025</year></date></history><permissions><copyright-statement>Copyright 2025 Lho SK et al. <italic>JAMA Network Open</italic>.</copyright-statement><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the CC-BY License.</license-p></license></permissions><self-uri content-type="pdf-version" xlink:href="jamanetwopen-e2511922.pdf">jamanetwopen-e2511922.pdf</self-uri><self-uri content-type="silverchair" xlink:href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2025.11922"/><abstract abstract-type="key-points"><title>Key Points</title><sec id="ab-zoi250402-1"><title>Question</title><p>Can large language models (LLMs) and text-embedding models detect depression and suicide risk based on sentence completion test (SCT) narratives of psychiatric patients?</p></sec><sec id="ab-zoi250402-2"><title>Findings</title><p>In this cross-sectional study of SCT datasets from 1064 patients (52&#x02009;627 completed responses), both LLMs and text-embedding models showed strong performance, with areas under the receiver operating characteristic curve greater than 0.7 in detecting clinically significant depression and high risk of suicide, particularly based on self-concept narratives.</p></sec><sec id="ab-zoi250402-3"><title>Meaning</title><p>This study suggests that LLMs and text-embedding models have potential to detect mental health risks, including depression and suicide, but further performance improvement and addressing ethical concerns are essential for clinical application.</p></sec></abstract><abstract><sec id="ab-zoi250402-4"><title>Importance</title><p>Large language models (LLMs) and text-embedding models have shown potential in assessing mental health risks based on narrative data from psychiatric patients.</p></sec><sec id="ab-zoi250402-5"><title>Objective</title><p>To assess whether LLMs and text-embedding models can identify depression and suicide risk based on sentence completion test (SCT) narratives of psychiatric patients.</p></sec><sec id="ab-zoi250402-6"><title>Design, Setting, and Participants</title><p>This cross-sectional study, conducted at Seoul Metropolitan Government-Seoul National University Boramae Medical Center, analyzed SCT data collected from April 1, 2016, to September 30, 2021. Participants included psychiatric patients aged 18 to 39 years who completed SCT and self-assessments for depression (Beck Depression Inventory&#x02013;II or Zung Self-Rating Depression Scale) and/or suicide (Beck Scale for Suicidal Ideation). Patients confirmed to have an IQ below 70 were excluded, leaving 1064 eligible SCT datasets (52&#x02009;627 completed responses). Data processing with LLMs (GPT-4o, May 13, 2024, version; OpenAI [hereafter, <italic>LLM1</italic>]; gemini-1.0-pro, February 2024 version; Google DeepMind [hereafter, <italic>LLM2</italic>]; and GPT-3.5-turbo-16k, January 25, 2024, version; OpenAI) and text-embedding models (text-embedding-3-large, OpenAI [hereafter, <italic>text-embedding 1</italic>]; text-embedding3-small; OpenAI; and text-embedding-ada-002; OpenAI) was performed between July 4 and September 30, 2024.</p></sec><sec id="ab-zoi250402-7"><title>Main Outcomes and Measures</title><p>Outcomes included the performance of LLMs and text-embedding models in detecting depression and suicide, as measured by the area under the receiver operating characteristic curve (AUROC), balanced accuracy, and macro F1-score. Performance was evaluated across concatenated narratives of SCT, including self-concept, family, gender perception, and interpersonal relations narratives.</p></sec><sec id="ab-zoi250402-8"><title>Results</title><p>Based on SCT narratives from 1064 patients (mean [SD] age, 25.4 [5.5] years; 673 men [63.3%]), LLM1 showed strong performance in zero-shot learning, with an AUROC of 0.720 (95% CI, 0.689-0.752) for depression and 0.731 (95% CI, 0.704-0.762) for suicide risk using self-concept narratives. Few-shot learning for depression further improved the performance of LLM1 (AUROC, 0.754 [95% CI, 0.721-0.784]) and LLM2 (AUROC, 0.736 [95% CI, 0.704-0.770]). The text-embedding 1 model paired with extreme gradient boosting outperformed other models, achieving an AUROC of 0.841 (95% CI, 0.783-0.897) for depression and 0.724 (95% CI, 0.650-0.795) for suicide risk. Overall, self-concept narratives showed the most accurate detections across all models.</p></sec><sec id="ab-zoi250402-9"><title>Conclusions and Relevance</title><p>This cross-sectional study of SCT narratives from psychiatric patients suggests that LLMs and text-embedding models may effectively detect depression and suicide risk, particularly using self-concept narratives. However, while these models demonstrated potential for detecting mental health risks, further improvements in performance and safety are essential before clinical application.</p></sec></abstract><abstract abstract-type="teaser" specific-use="electronic"><p>This cross-sectional study assesses whether large language models (LLMs) and text-embedding models can detect clinically significant depression and high risk of suicide based on sentence completion test narratives of psychiatric patients.</p></abstract></article-meta></front><body><sec id="H1-1-ZOI250402"><title>Introduction</title><p>After the release of Chat Generative Pre-trained Transformer (ChatGPT) in November 2022, ChatGPT has demonstrated capabilities such as passing the United States Medical Licensing Examination<sup><xref rid="zoi250402r1" ref-type="bibr">1</xref>,<xref rid="zoi250402r2" ref-type="bibr">2</xref>,<xref rid="zoi250402r3" ref-type="bibr">3</xref></sup> and excelling in clinical reasoning and diagnosing across various medical fields.<sup><xref rid="zoi250402r4" ref-type="bibr">4</xref>,<xref rid="zoi250402r5" ref-type="bibr">5</xref>,<xref rid="zoi250402r6" ref-type="bibr">6</xref>,<xref rid="zoi250402r7" ref-type="bibr">7</xref>,<xref rid="zoi250402r8" ref-type="bibr">8</xref>,<xref rid="zoi250402r9" ref-type="bibr">9</xref></sup> The psychiatric field has emerged as a particularly promising area for the implementation of artificial intelligence (AI) models, especially large language models (LLMs), because psychiatric evaluation relies heavily on qualitative and nuanced verbal narratives provided by patients.<sup><xref rid="zoi250402r10" ref-type="bibr">10</xref>,<xref rid="zoi250402r11" ref-type="bibr">11</xref></sup></p><p>To date, natural language processing (NLP) and machine learning (ML) techniques have proven value in extracting specific key words related to psychiatric symptoms from patients&#x02019; narratives, aiding in diagnostic evaluation.<sup><xref rid="zoi250402r12" ref-type="bibr">12</xref></sup> The evolution from traditional NLP to modern LLMs represents a natural progression in this field, leading to sophisticated applications. For example, domain-specific ML models, such as MentalBERT,<sup><xref rid="zoi250402r13" ref-type="bibr">13</xref></sup> have been developed for detecting stress, depression, or suicide risk based on social media content.<sup><xref rid="zoi250402r13" ref-type="bibr">13</xref>,<xref rid="zoi250402r14" ref-type="bibr">14</xref>,<xref rid="zoi250402r15" ref-type="bibr">15</xref>,<xref rid="zoi250402r16" ref-type="bibr">16</xref></sup> More recently, researchers have explored the capabilities of LLMs in detecting depression and suicidal tendencies using online data.<sup><xref rid="zoi250402r17" ref-type="bibr">17</xref>,<xref rid="zoi250402r18" ref-type="bibr">18</xref></sup> Notably, Bartal et al<sup><xref rid="zoi250402r19" ref-type="bibr">19</xref></sup> used Generative Pre-trained Transformer 3.5 (GPT-3.5 [OpenAI]) and text-embedding models to identify childbirth-related posttraumatic stress disorder based on childbirth narratives, showing potential of LLMs for mental health risk assessment.</p><p>Despite these advancements, a gap remains in applying the latest language models to detect mental health risks based on patients&#x02019; narratives in clinical settings. Although domain-specific pretraining has been considered necessary for strong performance, the primary challenge may lie in the narrative quality and structure rather than model specialization. Properly structured and targeted narratives could enable general-purpose language models to effectively screen for mental health risks. The cognitive triad of Beck,<sup><xref rid="zoi250402r20" ref-type="bibr">20</xref></sup> which suggests that individuals with depression possess negative views of the self, future, and world, supports the idea that patients&#x02019; narratives can serve as a basis for diagnostic evaluation. In this context, the sentence completion test (SCT), a projective test developed for assessing intelligence and personality,<sup><xref rid="zoi250402r21" ref-type="bibr">21</xref>,<xref rid="zoi250402r22" ref-type="bibr">22</xref></sup> offers a unique opportunity providing more targeted narratives by eliciting attitudes toward the self, others, and the world. Although SCT use has declined in Western countries following trends toward evidence-based diagnoses,<sup><xref rid="zoi250402r23" ref-type="bibr">23</xref>,<xref rid="zoi250402r24" ref-type="bibr">24</xref>,<xref rid="zoi250402r25" ref-type="bibr">25</xref>,<xref rid="zoi250402r26" ref-type="bibr">26</xref></sup> it remains popular in Asia, including South Korea,<sup><xref rid="zoi250402r25" ref-type="bibr">25</xref>,<xref rid="zoi250402r26" ref-type="bibr">26</xref>,<xref rid="zoi250402r27" ref-type="bibr">27</xref></sup> valued for uncovering hidden thoughts and attitudes critical to psychiatric diagnosis.<sup><xref rid="zoi250402r21" ref-type="bibr">21</xref>,<xref rid="zoi250402r22" ref-type="bibr">22</xref></sup></p><p>This study investigates whether LLMs and text-embedding models can detect clinically significant depression and high risk of suicide based on SCT narratives. We aim to assess general-purpose models with prompt engineering, eliminating the need for domain-specific pretraining, while using text-embedding models to extract vectors for training ML models tailored to our dataset. We hypothesize that LLMs and text-embedding models can analyze SCT narratives to detect depression and suicide risk. In addition, we hypothesize that specific topics, such as self-concept narratives, may provide more targeted information aligned with Beck&#x02019;s cognitive triad of depression.</p></sec><sec id="H1-2-ZOI250402"><title>Methods</title><p>Procedures for this cross-sectional study were approved by the institutional review board of the Seoul Metropolitan Government&#x02013;Seoul National University Boramae Medical Center. Informed consent was waived by the institutional review board as the study had a retrospective design and used anonymized clinical data. We followed the Strengthening the Reporting of Observational Studies in Epidemiology (<ext-link xlink:href="http://www.equator-network.org/reporting-guidelines/strobe/" ext-link-type="uri">STROBE</ext-link>) reporting guideline for cross-sectional studies.</p><sec id="H2-1-ZOI250402"><title>Data Source</title><p>We conducted a retrospective observational study as part of an evaluation of the efficiency of the diagnosis and treatment prognosis of psychological assessment at the Seoul Metropolitan Government&#x02013;Seoul National University Boramae Medical Center. Psychiatric patients aged 18 to 39 years, who completed psychological evaluation between April 1, 2016, and September 30, 2021, were included. Patients were excluded if they lacked self-assessment depression scores (the Korean version of the Beck Depression Inventory&#x02013;II [K-BDI-II] or Zung Self-Rating Depression Scale [SDS]), had incomplete SCT items (missing more than one-third of items), or had a confirmed Full Scale Intelligence Quotient (FSIQ) below 70.</p></sec><sec id="H2-2-ZOI250402"><title>Clinical Measures and Defining Mental Health Risk</title><p>The SCT, a semiprojective psychological test, involves completing a series of incomplete sentences to reflect an individual&#x02019;s self-concept and attitudes toward various aspects.<sup><xref rid="zoi250402r21" ref-type="bibr">21</xref></sup> The Sacks Sentence Completion Test (SSCT), the most widely used version,<sup><xref rid="zoi250402r21" ref-type="bibr">21</xref>,<xref rid="zoi250402r22" ref-type="bibr">22</xref></sup> was adapted for a Korean version of the SSCT, consisting of 50 items categorized into 4 areas: self-concept (16 items), family (10 items), gender perception (15 items), and interpersonal relations (9 items).<sup><xref rid="zoi250402r22" ref-type="bibr">22</xref></sup> A translated version of the Korean SCT is presented in eTable 1 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>. Items in each area were concatenated into 4 narratives for each participant.</p><p>Depression was assessed using the K-BDI-II or SDS. The K-BDI-II<sup><xref rid="zoi250402r28" ref-type="bibr">28</xref>,<xref rid="zoi250402r29" ref-type="bibr">29</xref></sup> is a 21-item scale (total score, 0-63; 0-13 indicates indicating minimal depression, 14-19 indicates mild depression, 20-28 indicates moderate depression, and 29-63 indicates severe depression. The SDS<sup><xref rid="zoi250402r30" ref-type="bibr">30</xref>,<xref rid="zoi250402r31" ref-type="bibr">31</xref></sup> is a 20-item scale (total score, 25-100; where 25-49 indicates no depression, 50-59 indicates mild depression, 60-69 indicates moderate to marked depression, and 70-100 indicates severe to extreme major depression. We used the cutoff values for moderate depression of both scales to define clinically significant depression.</p><p>The Korean version of the Beck Scale for Suicidal Ideation is a 19-item self-assessment scale evaluating suicidal ideation over the past week, with scores ranging from 0 to 38, where higher scores indicate greater suicide risk.<sup><xref rid="zoi250402r32" ref-type="bibr">32</xref>,<xref rid="zoi250402r33" ref-type="bibr">33</xref>,<xref rid="zoi250402r34" ref-type="bibr">34</xref></sup> Although the original Beck Scale for Suicidal Ideation developers did not establish a validated cutoff score,<sup><xref rid="zoi250402r33" ref-type="bibr">33</xref></sup> several studies have proposed practical cutoff values.<sup><xref rid="zoi250402r34" ref-type="bibr">34</xref>,<xref rid="zoi250402r35" ref-type="bibr">35</xref>,<xref rid="zoi250402r36" ref-type="bibr">36</xref></sup> Based on Korean validation studies,<sup><xref rid="zoi250402r37" ref-type="bibr">37</xref></sup> we used a score of 15 or higher to define high risk of suicide. The FSIQ was assessed using the Korean Wechsler Adult Intelligence Scale, Fourth Edition (K-WAIS-IV),<sup><xref rid="zoi250402r38" ref-type="bibr">38</xref></sup> which is the Korean adaption of the original WAIS-IV.<sup><xref rid="zoi250402r39" ref-type="bibr">39</xref></sup> The FSIQ is a composite score of multiple subtests, with scores ranging from 40 to 160, where higher scores indicate greater cognitive ability. The workflow of the study is shown in <xref rid="zoi250402f1" ref-type="fig">Figure 1</xref>.</p><fig position="float" id="zoi250402f1" fig-type="figure"><label>Figure 1. </label><caption><title>Workflow for Depression and Suicide Risk Detection Using Large Language Models (LLMs) and Text-Embedding Models</title><p>Preprocessing involved concatenating sentence completion test (SCT) narratives and defining clinically significant depression or high risk of suicide using Beck Depression Index (BDI) and/or Zung Self-Rating Depression Scale (SDS) or Beck Suicidal Severity Index (BSSI). Detecting mental health risks included the use of large language models (LLMs) and embedding-based machine learning (ML) models (support vector machine [SVM], logistic regression [LR], extreme grading boosting [XGB], and neural network [NN]). The evaluation process assesses model performance using area under the receiver operating characteristic curve (AUROC), accuracy, and macro F1-score. LLM1 indicates GPT-4o (May 13, 2024, version; OpenAI); LLM2, gemini-1.0-pro (February 2024 version; Google); LLM3, GPT-3.5-turbo-16k (January 25, 2024, version; OpenAI); text-embedding 1, text-embedding-3-large (OpenAI), text-embedding 2, text-embedding-3-small (OpenAI), and text-embedding 3, text-embedding-002-ada (OpenAI).</p></caption><graphic xlink:href="jamanetwopen-e2511922-g001" position="float"/></fig></sec><sec id="H2-3-ZOI250402"><title>Data Preprocessing</title><p>To protect patient privacy, SCT narratives were deidentified before being processed by LLMs and text-embedding models, following the Health Insurance Portability and Accountability Act guidelines.<sup><xref rid="zoi250402r40" ref-type="bibr">40</xref></sup> A manual review of all 50 items across SCT data identified 42 responses containing patient or relative names in 41 SCT datasets. We developed an NLP-based system using the MeCab (Python Software Foundation) tokenizer for Korean language, flagging proper nouns (2-4 characters) through part-of-speech tagging and noun extraction. In addition, the system identified sensitive information such as dates and numeric identifiers. From 720 flagged cases, manual review confirmed 19 sensitive responses (18 names and 1 birth date) in 14 SCT data items. All 61 responses were deidentified through pseudonymization and generalization. Reidentification risk was assessed by designating the 4 concatenated narratives as quasi-identifiers and analyzing them with TF-IDF (term frequency&#x02013;inverse document frequency) vectors and pairwise cosine distances using k-nearest neighbor analysis (k&#x02009;=&#x02009;5). Manual review of flagged records confirmed minimal reidentification risk. Python, version 3.10.12 (Python Software Foundation), was used for data preprocessing and all subsequent analyses, except for specified statistical analyses.</p></sec><sec id="H2-4-ZOI250402"><title>Detecting Mental Health Risk Using LLMs and Text-Embedding Models</title><p>Following the methodology of Bartal et al,<sup><xref rid="zoi250402r19" ref-type="bibr">19</xref></sup> we evaluated leading LLMs with zero-shot and few-shot learning as well as embedding-based ML models in detecting depression and suicide risk. For LLM evaluation, we used GPT-4o (May 13, 2024, version; OpenAI [hereafter, <italic>LLM1</italic>]), gemini-1.0-pro (February 2024 version; Google [hereafter, <italic>LLM2</italic>]), and GPT-3.5-turbo-16k (January 25, 2024, version; OpenAI [hereafter, <italic>LLM3</italic>]). GPT-4 (June 13, 2024, version) and gemini-1.5-pro (May 2024 version) were excluded due to higher costs and lower performance in the preliminary evaluation. For zero-shot learning, we adapted the prompt from previous studies,<sup><xref rid="zoi250402r18" ref-type="bibr">18</xref>,<xref rid="zoi250402r19" ref-type="bibr">19</xref></sup> as shown in <xref rid="zoi250402t1" ref-type="table">Table 1</xref>, with temperature set to 0 for deterministic responses. In few-shot learning, we provided 4 narrative examples for each task: 2 from participants with clinically significant depression and 2 with subclinical or no depression for the depression task, and 2 from high-risk and 2 from low-risk participants for the suicide task, along with their labels. In preliminary testing, 1 narrative per class showed lower performance, while more than 2 had no additional benefit. Thus, we selected 2 narratives per class for cost-effectiveness. Model performance was evaluated using the area under the receiver operating characteristic curve (AUROC), accuracy, and macro F1-score, all reported with 95% CIs.</p><table-wrap position="float" id="zoi250402t1"><label>Table 1. </label><caption><title>Prompts Used for Zero-Shot and Few-Shot Learning for LLM1, LLM2, and LLM3</title></caption><table frame="hsides" rules="groups"><col width="24.89%" span="1"/><col width="75.11%" span="1"/><thead><tr><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Mental health risk and category</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Prompts</th></tr></thead><tbody><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Depression</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Zero-shot</td><td valign="top" align="left" rowspan="1" colspan="1">You are an experienced psychiatrist specializing in diagnosing and treating depression. I will provide you with narratives from a participant&#x02019;s sentence completion test (SCT). Your task is to decide whether the participant is at high risk of depression (Label 1) or lower risk of depression (Label 0). Provide only &#x02018;1&#x02019; or &#x02018;0&#x02019; based on a reasonable explanation.</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Few-shot</td><td valign="top" align="left" rowspan="1" colspan="1">You are an experienced psychiatrist specializing in diagnosing and treating depression. I will provide you with narratives from a participant&#x02019;s sentence completion test (SCT). Your task is to decide whether the participant is at high risk of depression (Label 1) or lower risk of depression (Label 0). Provide only &#x02018;1&#x02019; or &#x02018;0&#x02019; based on a reasonable explanation. Here are a few examples of narratives and their labels. ###&#x0003c;Narrative&#x0003e;: example&#x0003c;Label&#x0003e;: 1 ###&#x0003c;Narrative&#x0003e;: example&#x0003c;Label&#x0003e;: 0</td></tr><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Suicide</td><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Zero-shot</td><td valign="top" align="left" rowspan="1" colspan="1">You are an experienced psychiatrist specializing in diagnosing and treating suicidal patient. I will provide you with narratives from a participant&#x02019;s sentence completion test (SCT). Your task is to decide whether the participant is at high risk of suicide (Label 1) or lower risk of suicide (Label 0). Provide only &#x02018;1&#x02019; or &#x02018;0&#x02019; based on a reasonable explanation.</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Few-shot</td><td valign="top" align="left" rowspan="1" colspan="1">You are an experienced psychiatrist specializing in diagnosing and treating suicidal patient. I will provide you with narratives from a participant&#x02019;s sentence completion test (SCT). Your task is to decide whether the participant is at high risk of suicide (Label 1) or lower risk of suicide (Label 0). Provide only &#x02018;1&#x02019; or &#x02018;0&#x02019; based on a reasonable explanation. Here are a few examples of narratives and their labels. ###&#x0003c;Narrative&#x0003e;: example&#x0003c;Label&#x0003e;: 1 ###&#x0003c;Narrative&#x0003e;: example&#x0003c;Label&#x0003e;: 0</td></tr></tbody></table><table-wrap-foot><p>Abbreviations: LLM1, GPT-4o (May 13, 2024, version; OpenAI); LLM2, gemini-1.0-pro (February 2024 version; Google); LLM3, GPT-3.5-turbo-16k (January 25, 2024, version; OpenAI).</p></table-wrap-foot></table-wrap><p>For embedding-based ML models, we used OpenAI&#x02019;s text-embedding models (text-embedding-3-large [hereafter, <italic>text-embedding 1</italic>], text-embedding-3-small [hereafter, <italic>text-embedding 2</italic>], and text-embedding-002-ada [hereafter, <italic>text-embedding 3</italic>]) to extract embeddings with dimensions of 3072, 1536, and 1536, respectively. After splitting the data into training and testing sets (80:20) and applying standard scaling, we trained support vector machines (SVMs) and logistic regression (LR) using Scikit-learn (Python),<sup><xref rid="zoi250402r41" ref-type="bibr">41</xref></sup> and extreme gradient boosting (XGB) models using XGBoost<sup><xref rid="zoi250402r42" ref-type="bibr">42</xref></sup> with the class weight set to &#x0201c;balanced&#x0201d; to handle class imbalances. Each model underwent 5-fold stratified cross-validation and was evaluated on the test set for the AUROC, accuracy, and macro F1-score. In addition, we implemented a neural network (NN) using TensorFlow/Keras<sup><xref rid="zoi250402r43" ref-type="bibr">43</xref></sup> with 3 hidden layers (256, 128, and 64 units), dropout layers, and L2 regularization to prevent overfitting. The network was compiled with the Adam optimizer and trained with early stopping on the scaled embedding vectors. The binary cross-entropy loss was used for training. The NN was evaluated on the same metrics as the other ML models.</p></sec><sec id="H2-5-ZOI250402"><title>Statistical Analysis</title><p>Data processing with LLMs and text-embedding models was performed between July 4 and September 30, 2024. Demographic and clinical characteristics between groups were compared using an independent <italic>t</italic> test for continuous variables and &#x003c7;<sup>2</sup> analysis for the categorical data. All <italic>P</italic> values were from 2-sided tests and results were deemed statistically significant at <italic>P</italic>&#x02009;&#x0003c;&#x02009;.05. Analyses were conducted using IBM SPSS, version 23 (IBM Corp). The AUC scores of LLMs, evaluated on the entire dataset, were compared separately from those of embedding-based ML models, evaluated on a test dataset. Because probability scores were unavailable for the LLMs, whose detections were associated with the prompt when making detections, we used bootstrapping with 1000 resamples to estimate 95% CIs for AUROC scores. In each iteration, we randomly sampled the dataset with replacement, maintaining the original sample size, and calculated the AUROC. The 95% CI was derived from the 2.5th and 97.5th percentiles of the AUROC distribution. We then calculated mean AUROC differences between models. Statistical significance was determined by whether the 95% CI of the mean AUROC difference included zero. The Cochran <italic>Q</italic> test assessed overall differences in accuracy between LLMs, followed by McNemar tests with Bonferroni correction for pairwise comparison (<italic>P</italic>&#x02009;&#x0003c;&#x02009;.05/15, comparing 6 models) using IBM SPSS, version 23.</p><p>We performed qualitative analysis on 3 representative cases including 4 narratives to examine factors associated with model performance. Using a comparative case analysis approach, we examined narratives in which LLM1 either detected or failed to detect depression. We analyzed thematic content and psychological characteristics to identify factors possibly associated with model performance. A modified prompt was used to elicit the reasoning process of LLM1. Detailed methods, specific prompt, and narratives are provided in the eMethods and eTable 9 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>.</p></sec></sec><sec id="H1-3-ZOI250402"><title>Results</title><sec id="H2-6-ZOI250402"><title>Patient Characteristics</title><p>From the initial 2443 patients, 1532 patients participated in SCTs. We excluded 349 patients due to a lack of self-assessment depression scores or incomplete SCT items and 119 patients with an IQ below 70. This resulted in 1064 patients (mean [SD] age, 25.4 [5.5] years; 673 men [63.3%] and 391 women [36.7%]; mean [SD] education, 14.1 [1.9] years), with a total of 52&#x02009;627 completed item responses across all patients for the final analysis (<xref rid="zoi250402t2" ref-type="table">Table 2</xref>). Depression detection was conducted on all 1064 SCT datasets, while suicide risk assessment was performed on 882 SCT datasets.</p><table-wrap position="float" id="zoi250402t2"><label>Table 2. </label><caption><title>Patient Demographic and Clinical Characteristics</title></caption><table frame="hsides" rules="groups"><col width="17.74%" span="1"/><col width="8.53%" span="1"/><col width="13.82%" span="1"/><col width="13.82%" span="1"/><col width="8.93%" span="1"/><col width="8.48%" span="1"/><col width="10.24%" span="1"/><col width="8.48%" span="1"/><col width="9.96%" span="1"/><thead><tr><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Characteristic</th><th colspan="4" valign="top" align="left" scope="colgroup" rowspan="1">Depression</th><th colspan="4" valign="top" align="left" scope="colgroup" rowspan="1">Suicide</th></tr><tr><th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">Total (n&#x02009;=&#x02009;1064)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">No or subclinical depression (n&#x02009;=&#x02009;254)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Clinically significant depression (n&#x02009;=&#x02009;810)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1"><italic>P</italic> value<xref rid="zoi250402t2n1" ref-type="table-fn"><sup>a</sup></xref></th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Total (n&#x02009;=&#x02009;882)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Low risk (n&#x02009;=&#x02009;470)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">High risk (n&#x02009;=&#x02009;412)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1"><italic>P</italic> value<xref rid="zoi250402t2n1" ref-type="table-fn"><sup>a</sup></xref></th></tr></thead><tbody><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Age, mean (SD), y</td><td valign="top" align="left" rowspan="1" colspan="1">25.4 (5.5)</td><td valign="top" align="left" rowspan="1" colspan="1">26.4 (6.1)</td><td valign="top" align="left" rowspan="1" colspan="1">25.1 (5.3)</td><td valign="top" align="left" rowspan="1" colspan="1">.003</td><td valign="top" align="left" rowspan="1" colspan="1">25.6 (5.6)</td><td valign="top" align="left" rowspan="1" colspan="1">26.2 (6.0)</td><td valign="top" align="left" rowspan="1" colspan="1">24.9 (5.1)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0003c;.001</td></tr><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Sex, No (%)</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Male</td><td valign="top" align="left" rowspan="1" colspan="1">673 (63.3)</td><td valign="top" align="left" rowspan="1" colspan="1">174 (68.5)</td><td valign="top" align="left" rowspan="1" colspan="1">499 (61.6)</td><td rowspan="2" valign="top" align="left" colspan="1">.05</td><td valign="top" align="left" rowspan="1" colspan="1">556 (63.0)</td><td valign="top" align="left" rowspan="1" colspan="1">299 (63.6)</td><td valign="top" align="left" rowspan="1" colspan="1">257 (62.4)</td><td rowspan="2" valign="middle" align="left" colspan="1">.70</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> Female</td><td valign="top" align="left" rowspan="1" colspan="1">391 (36.7)</td><td valign="top" align="left" rowspan="1" colspan="1">80 (31.5)</td><td valign="top" align="left" rowspan="1" colspan="1">311 (38.4)</td><td valign="top" colspan="1" align="left" rowspan="1">326 (37.0)</td><td valign="top" align="left" rowspan="1" colspan="1">171 (36.4)</td><td valign="top" align="left" rowspan="1" colspan="1">155 (37.6)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Education, mean (SD), y<xref rid="zoi250402t2n2" ref-type="table-fn"><sup>b</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">14.1 (1.9)</td><td valign="top" align="left" rowspan="1" colspan="1">14.4 (1.9)</td><td valign="top" align="left" rowspan="1" colspan="1">14.0 (1.9)</td><td valign="top" align="left" rowspan="1" colspan="1">.004</td><td valign="top" align="left" rowspan="1" colspan="1">14.1 (1.9)</td><td valign="top" align="left" rowspan="1" colspan="1">13.9 (1.9)</td><td valign="top" align="left" rowspan="1" colspan="1">14.2 (1.9)</td><td valign="top" align="left" rowspan="1" colspan="1">.002</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">BDI-II score, mean (SD)<xref rid="zoi250402t2n2" ref-type="table-fn"><sup>b</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">28.3 (15.1)</td><td valign="top" align="left" rowspan="1" colspan="1">10.0 (5.81)</td><td valign="top" align="left" rowspan="1" colspan="1">35.5 (10.9)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0003c;.001</td><td valign="top" align="left" rowspan="1" colspan="1">29.0 (14.1)</td><td valign="top" align="left" rowspan="1" colspan="1">26.7 (13.9)</td><td valign="top" align="left" rowspan="1" colspan="1">38.0 (11.4)</td><td valign="top" align="left" rowspan="1" colspan="1">.002</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">SDS score, mean (SD)<xref rid="zoi250402t2n2" ref-type="table-fn"><sup>b</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">68.5 (12.8)</td><td valign="top" align="left" rowspan="1" colspan="1">50.2 (7.09)</td><td valign="top" align="left" rowspan="1" colspan="1">73.9 (8.35)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0003c;.001</td><td valign="top" align="left" rowspan="1" colspan="1">68.8 (12.7)</td><td valign="top" align="left" rowspan="1" colspan="1">62.0 (11.7)</td><td valign="top" align="left" rowspan="1" colspan="1">75.7 (9.64)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0003c;.001</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">BSSI score, mean (SD)<xref rid="zoi250402t2n2" ref-type="table-fn"><sup>b</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">13.2 (9.71)</td><td valign="top" align="left" rowspan="1" colspan="1">5.71 (6.17)</td><td valign="top" align="left" rowspan="1" colspan="1">15.4 (9.45)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0003c;.001</td><td valign="top" align="left" rowspan="1" colspan="1">13.2 (9.71)</td><td valign="top" align="left" rowspan="1" colspan="1">5.43 (4.90)</td><td valign="top" align="left" rowspan="1" colspan="1">22.2 (5.02)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x0003c;.001</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">FSIQ score, mean (SD)<xref rid="zoi250402t2n2" ref-type="table-fn"><sup>b</sup></xref></td><td valign="top" align="left" rowspan="1" colspan="1">95.7 (14.7)</td><td valign="top" align="left" rowspan="1" colspan="1">96.4 (14.7)</td><td valign="top" align="left" rowspan="1" colspan="1">95.5 (14.7)</td><td valign="top" align="left" rowspan="1" colspan="1">.87</td><td valign="top" align="left" rowspan="1" colspan="1">95.9 (14.8)</td><td valign="top" align="left" rowspan="1" colspan="1">96.6 (14.9)</td><td valign="top" align="left" rowspan="1" colspan="1">95.2 (14.8)</td><td valign="top" align="left" rowspan="1" colspan="1">.19</td></tr></tbody></table><table-wrap-foot><p>Abbreviations: BDI-II, Beck Depression Inventory&#x02013;II; BSSI, Beck Scale for Suicidal Ideation; FSIQ, Full-Scale Intelligence Quotient; SDS, Zung Self-Rating Depression Scale.</p><fn id="zoi250402t2n1"><label>
<sup>a</sup>
</label><p>Derived from an independent <italic>t</italic> test for continuous variables and a &#x003c7;<sup>2</sup> test for categorical variables.</p></fn><fn id="zoi250402t2n2"><label>
<sup>b</sup>
</label><p>Available data for each category: education (n&#x02009;=&#x02009;1050 for depression, n&#x02009;=&#x02009;868 for suicide), BDI-II (n&#x02009;=&#x02009;232 for depression, n&#x02009;=&#x02009;93 for suicide), SDS (n&#x02009;=&#x02009;874 for depression and 830 for suicide), BSSI (n&#x02009;=&#x02009;882 for both depression and suicide), FSIQ (n&#x02009;=&#x02009;946 for depression, n&#x02009;=&#x02009;782 for suicide) (see Methods for details).</p></fn></table-wrap-foot></table-wrap></sec><sec id="H2-7-ZOI250402"><title>Overall Evaluations of the Models</title><p>The performance of LLMs and embedding-based ML models in detecting clinically significant depression and high risk of suicide was evaluated based on 4 narratives: self-concept, family, gender perception, and interpersonal relations (<xref rid="zoi250402t3" ref-type="table">Table 3</xref>; <xref rid="zoi250402f2" ref-type="fig">Figure 2</xref>; eTables 2-4 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). Text-embedding 1 consistently outperformed smaller embeddings, although performance varied by narrative types. The analysis suggested that embedding-based ML models, particularly with XGB or NN, provided the best results for both detection tasks. These models outperformed the overall metrics of LLMs in detecting both depression and suicide, although direct statistical comparisons were unavailable. However, LLM1 and LLM2 showed strong AUROC performance, particularly in the few-shot learning. Across LLMs and embedding-based ML models, detections using self-concept narratives achieved the highest performance, with AUROCs of approximately 0.7 to 0.8, a range higher than those achieved with family, gender perception, or interpersonal relations narratives.</p><table-wrap position="float" id="zoi250402t3"><label>Table 3. </label><caption><title>Performance of Zero-Shot and Few-Shot LLMs and Embedding-Based Machine Learning Models Detecting Clinically Significant Depression and High Risk of Suicide Based on SCT Self-Concept Narratives</title></caption><table frame="hsides" rules="groups"><col width="14.07%" span="1"/><col width="14.38%" span="1"/><col width="14.47%" span="1"/><col width="14.49%" span="1"/><col width="14.47%" span="1"/><col width="14.17%" span="1"/><col width="13.95%" span="1"/><thead><tr><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Category and model</th><th colspan="3" valign="top" align="left" scope="colgroup" rowspan="1">Depression</th><th colspan="3" valign="top" align="left" scope="colgroup" rowspan="1">Suicide</th></tr><tr><th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">AUROC (95% CI)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Accuracy (95% CI)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Macro F1-score (95% CI)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">AUROC (95% CI)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Accuracy (95% CI)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Macro F1-score (95% CI)</th></tr></thead><tbody><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Zero-shot</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LLM1</td><td valign="top" align="left" rowspan="1" colspan="1">0.720 (0.689-0.752)</td><td valign="top" align="left" rowspan="1" colspan="1">0.814 (0.789-0.837)</td><td valign="top" align="left" rowspan="1" colspan="1">0.730 (0.697-0.763)</td><td valign="top" align="left" rowspan="1" colspan="1">0.731 (0.704-0.762)</td><td valign="top" align="left" rowspan="1" colspan="1">0.734 (0.706-0.764)</td><td valign="top" align="left" rowspan="1" colspan="1">0.731 (0.702-0.761)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LLM2</td><td valign="top" align="left" rowspan="1" colspan="1">0.714 (0.680-0.747)</td><td valign="top" align="left" rowspan="1" colspan="1">0.814 (0.789-0.836)</td><td valign="top" align="left" rowspan="1" colspan="1">0.727 (0.693-0.757)</td><td valign="top" align="left" rowspan="1" colspan="1">0.721 (0.695-0.750)</td><td valign="top" align="left" rowspan="1" colspan="1">0.715 (0.686-0.743)</td><td valign="top" align="left" rowspan="1" colspan="1">0.715 (0.686-0.743)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LLM3</td><td valign="top" align="left" rowspan="1" colspan="1">0.731 (0.703-0.761)</td><td valign="top" align="left" rowspan="1" colspan="1">0.677 (0.648-0.705)</td><td valign="top" align="left" rowspan="1" colspan="1">0.650 (0.620-0.678)</td><td valign="top" align="left" rowspan="1" colspan="1">0.635 (0.609-0.659)</td><td valign="top" align="left" rowspan="1" colspan="1">0.654 (0.622-0.685)</td><td valign="top" align="left" rowspan="1" colspan="1">0.611 (0.575-0.643)</td></tr><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Few-shot</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LLM1</td><td valign="top" align="left" rowspan="1" colspan="1">0.754 (0.721-0.784)</td><td valign="top" align="left" rowspan="1" colspan="1">0.745 (0.717-0.771)</td><td valign="top" align="left" rowspan="1" colspan="1">0.702 (0.673-0.730)</td><td valign="top" align="left" rowspan="1" colspan="1">0.723 (0.694-0.752)</td><td valign="top" align="left" rowspan="1" colspan="1">0.721 (0.691-0.749)</td><td valign="top" align="left" rowspan="1" colspan="1">0.721 (0.690-0.752)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LLM2</td><td valign="top" align="left" rowspan="1" colspan="1">0.736 (0.704-0.770)</td><td valign="top" align="left" rowspan="1" colspan="1">0.808 (0.784-0.831)</td><td valign="top" align="left" rowspan="1" colspan="1">0.736 (0.706-0.766)</td><td valign="top" align="left" rowspan="1" colspan="1">0.720 (0.691-0.750)</td><td valign="top" align="left" rowspan="1" colspan="1">0.712 (0.683-0.743)</td><td valign="top" align="left" rowspan="1" colspan="1">0.710 (0.679-0.741)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LLM3</td><td valign="top" align="left" rowspan="1" colspan="1">0.700 (0.667-0.734)</td><td valign="top" align="left" rowspan="1" colspan="1">0.776 (0.750-0.801)</td><td valign="top" align="left" rowspan="1" colspan="1">0.697 (0.666-0.728)</td><td valign="top" align="left" rowspan="1" colspan="1">0.704 (0.675-0.735)</td><td valign="top" align="left" rowspan="1" colspan="1">0.700 (0.671-0.731)</td><td valign="top" align="left" rowspan="1" colspan="1">0.700 (0.670-0.731)</td></tr><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Text-embedding 1</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> SVM</td><td valign="top" align="left" rowspan="1" colspan="1">0.736 (0.646-0.818)</td><td valign="top" align="left" rowspan="1" colspan="1">0.770 (0.708-0.822)</td><td valign="top" align="left" rowspan="1" colspan="1">0.686 (0.612-0.754)</td><td valign="top" align="left" rowspan="1" colspan="1">0.711 (0.638-0.784)</td><td valign="top" align="left" rowspan="1" colspan="1">0.678 (0.610-0.746)</td><td valign="top" align="left" rowspan="1" colspan="1">0.675 (0.605-0.745)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LR</td><td valign="top" align="left" rowspan="1" colspan="1">0.758 (0.671-0.842)</td><td valign="top" align="left" rowspan="1" colspan="1">0.793 (0.737-0.840)</td><td valign="top" align="left" rowspan="1" colspan="1">0.727 (0.657, 0787)</td><td valign="top" align="left" rowspan="1" colspan="1">0.715 (0.625-0.787)</td><td valign="top" align="left" rowspan="1" colspan="1">0.650 (0.582-0.723)</td><td valign="top" align="left" rowspan="1" colspan="1">0.647 (0.576-0.717)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> XGB</td><td valign="top" align="left" rowspan="1" colspan="1">0.841 (0.783-0.897)</td><td valign="top" align="left" rowspan="1" colspan="1">0.822 (0.770-0.869)</td><td valign="top" align="left" rowspan="1" colspan="1">0.737 (0.663-0.804)</td><td valign="top" align="left" rowspan="1" colspan="1">0.724 (0.650-0.795)</td><td valign="top" align="left" rowspan="1" colspan="1">0.672 (0.605-0.746)</td><td valign="top" align="left" rowspan="1" colspan="1">0.662 (0.591-0.732)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> NN</td><td valign="top" align="left" rowspan="1" colspan="1">0.802 (0.725-0.878)</td><td valign="top" align="left" rowspan="1" colspan="1">0.817 (0.775-0.864)</td><td valign="top" align="left" rowspan="1" colspan="1">0.736 (0.668-0.806)</td><td valign="top" align="left" rowspan="1" colspan="1">0.739 (0.665-0.807)</td><td valign="top" align="left" rowspan="1" colspan="1">0.661 (0.588-0.723)</td><td valign="top" align="left" rowspan="1" colspan="1">0.656 (0.582-0.720)</td></tr><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Text-embedding 2</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> SVM</td><td valign="top" align="left" rowspan="1" colspan="1">0.626 (0.532-0.719)</td><td valign="top" align="left" rowspan="1" colspan="1">0.685 (0.624-0.746)</td><td valign="top" align="left" rowspan="1" colspan="1">0.592 (0.522-0.660)</td><td valign="top" align="left" rowspan="1" colspan="1">0.633 (0.549-0.713)</td><td valign="top" align="left" rowspan="1" colspan="1">0.548 (0.475-0.621)</td><td valign="top" align="left" rowspan="1" colspan="1">0.546 (0.468-0.621)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LR</td><td valign="top" align="left" rowspan="1" colspan="1">0.642 (0.548-0.733)</td><td valign="top" align="left" rowspan="1" colspan="1">0.704 (0.648-0.761)</td><td valign="top" align="left" rowspan="1" colspan="1">0.621 (0.551-0.689)</td><td valign="top" align="left" rowspan="1" colspan="1">0.637 (0.556-0.716)</td><td valign="top" align="left" rowspan="1" colspan="1">0.571 (0.497-0.644)</td><td valign="top" align="left" rowspan="1" colspan="1">0.569 (0.494-0.644)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> XGB</td><td valign="top" align="left" rowspan="1" colspan="1">0.747 (0.672-0.822)</td><td valign="top" align="left" rowspan="1" colspan="1">0.775 (0.718-0.831)</td><td valign="top" align="left" rowspan="1" colspan="1">0.607 (0.526-0.684)</td><td valign="top" align="left" rowspan="1" colspan="1">0.681 (0.604-0.755)</td><td valign="top" align="left" rowspan="1" colspan="1">0.667 (0.599-0.729)</td><td valign="top" align="left" rowspan="1" colspan="1">0.660 (0.587-0.727)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> NN</td><td valign="top" align="left" rowspan="1" colspan="1">0.699 (0.616-0.779)</td><td valign="top" align="left" rowspan="1" colspan="1">0.728 (0.662-0.779)</td><td valign="top" align="left" rowspan="1" colspan="1">0.631 (0.556-0.698)</td><td valign="top" align="left" rowspan="1" colspan="1">0.695 (0.611-0.766)</td><td valign="top" align="left" rowspan="1" colspan="1">0.616 (0.548-0.684)</td><td valign="top" align="left" rowspan="1" colspan="1">0.600 (0.532-0.669)</td></tr><tr><td valign="top" align="left" scope="col" rowspan="1" colspan="1">Text-embedding 3</td><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> SVM</td><td valign="top" align="left" rowspan="1" colspan="1">0.641 (0.551-0.728)</td><td valign="top" align="left" rowspan="1" colspan="1">0.700 (0.638-0.765)</td><td valign="top" align="left" rowspan="1" colspan="1">0.608 (0.536-0.673)</td><td valign="top" align="left" rowspan="1" colspan="1">0.619 (0.536-0.700)</td><td valign="top" align="left" rowspan="1" colspan="1">0.588 (0.514-0.655)</td><td valign="top" align="left" rowspan="1" colspan="1">0.585 (0.511-0.654)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> LR</td><td valign="top" align="left" rowspan="1" colspan="1">0.657 (0.565-0.745)</td><td valign="top" align="left" rowspan="1" colspan="1">0.723 (0.662-0.779)</td><td valign="top" align="left" rowspan="1" colspan="1">0.636 (0.560-0.702)</td><td valign="top" align="left" rowspan="1" colspan="1">0.636 (0.554-0.717)</td><td valign="top" align="left" rowspan="1" colspan="1">0.588 (0.514-0.655)</td><td valign="top" align="left" rowspan="1" colspan="1">0.585 (0.508-0.654)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> XGB</td><td valign="top" align="left" rowspan="1" colspan="1">0.755 (0.680-0.821)</td><td valign="top" align="left" rowspan="1" colspan="1">0.756 (0.695-0.812)</td><td valign="top" align="left" rowspan="1" colspan="1">0.565 (0.488-0.637)</td><td valign="top" align="left" rowspan="1" colspan="1">0.736 (0.661-0.804)</td><td valign="top" align="left" rowspan="1" colspan="1">0.718 (0.655-0.780)</td><td valign="top" align="left" rowspan="1" colspan="1">0.713 (0.648-0.778)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1"> NN</td><td valign="top" align="left" rowspan="1" colspan="1">0.721 (0.642-0.803)</td><td valign="top" align="left" rowspan="1" colspan="1">0.765 (0.704-0.817)</td><td valign="top" align="left" rowspan="1" colspan="1">0.648 (0.563-0.718)</td><td valign="top" align="left" rowspan="1" colspan="1">0.701 (0.623-0.780)</td><td valign="top" align="left" rowspan="1" colspan="1">0.621 (0.548-0.695)</td><td valign="top" align="left" rowspan="1" colspan="1">0.620 (0.546-0.694)</td></tr></tbody></table><table-wrap-foot><p>Abbreviations: AUROC, area under the receiver operating characteristic curve; LLM1, GPT-4o (May 13, 2024, version; OpenAI); LLM2, gemini-1.0-pro (February 2024 version; Google); LLM3, GPT-3.5-turbo-16k (January 25, 2024, version; OpenAI); LR, logistic regression; NN, neural network; SCT, sentence completion test; SVM, support vector machine; text-embedding 1, text-embedding-3-large (OpenAI), text-embedding 2, text-embedding-3-small (OpenAI), and text-embedding 3, text-embedding-002-ada (OpenAI); XGB, extreme gradient boosting.</p></table-wrap-foot></table-wrap><fig position="float" id="zoi250402f2" fig-type="figure"><label>Figure 2. </label><caption><title>Comparison of Model Performance (Area Under the Receiver Operating Characteristic Curve [AUROC]) With 95% CIs</title><p>A, Large language models (LLMs) for depression detection. B, LLMs for suicide risk detection. C, Embedding-based machine learning (ML) models for depression detection. D, Embedding-based ML models for suicide risk detection. LLM1 indicates GPT-4o (May 13, 2024, version; OpenAI); LLM2, gemini-1.0-pro (February 2024 version; Google); LLM3, GPT-3.5-turbo-16k (January 25, 2024, version; OpenAI); text-embedding 1, text-embedding-3-large (OpenAI), text-embedding 2, text-embedding-3-small (OpenAI), and text-embedding 3, text-embedding-002-ada (OpenAI).</p></caption><graphic xlink:href="jamanetwopen-e2511922-g002" position="float"/></fig></sec><sec id="H2-8-ZOI250402"><title>Depression Detection</title><p>Self-concept narratives consistently showed the most effective results for all LLMs across both zero-shot and few-shot learning (<xref rid="zoi250402t3" ref-type="table">Table 3</xref>; eTables 2-4 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). In zero-shot learning, LLM1 (AUROC, 0.720 [95% CI, 0.689-0.752]), LLM2 (AUROC, 0.714 [95% CI, 0.680-0.747]), and LLM3 (AUROC, 0.731 [95% CI, 0.703-0.761]) showed comparable performance (<xref rid="zoi250402t3" ref-type="table">Table 3</xref>), with minimal mean AUROC differences between models (eTable 5 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). Few-shot learning was significantly associated with improved model performance, with LLM1 showing the best discriminant ability among LLMs, achieving an AUROC of 0.754 (95% CI, 0.721-0.781); LLM2 had an AUROC of 0.736 (95% CI, 0.704-0.770) and LLM 3 had an AUROC of 0.700 (95% CI, 0.667-0.734). Statistical analysis using the Cochran <italic>Q</italic> test (<italic>Q</italic>&#x02009;=&#x02009;159.6; <italic>P</italic>&#x02009;&#x0003c;&#x02009;.001) revealed a significant difference in accuracy among models (eTable 6 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). We found that LLM3 underperformed compared with LLM1 and LLM2 in zero-shot learning, with the McNemar test indicating significant differences (LLM1 vs LLM3: &#x003c7;<sup>2</sup>&#x02009;=&#x02009;64.89; <italic>P</italic>&#x02009;&#x0003c;&#x02009;.001; and LLM2 vs LLM3: &#x003c7;<sup>2</sup>&#x02009;=&#x02009;62.95; <italic>P</italic>&#x02009;&#x0003c;&#x02009;.001) (eTable 7 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>).</p><p>Among embedding-based ML models that were also based on self-concept narratives, text-embedding 1 with XGB achieved the highest AUROC of 0.841 (95% CI, 0.783-0.897), an accuracy of 0.822 (95% CI, 0.770-0.869), and a macro F1-score of 0.737 (95% CI, 0.663-0.804) (<xref rid="zoi250402t3" ref-type="table">Table 3</xref>). NN and LR also performed strongly with text-embedding 1 model, showing AUROCs of 0.802 (95% CI, 0.725-0.878) and 0.758 (95% CI, 0.671-0.842), respectively, with accuracies and macro F1-scores above 0.7. The larger embedding model, text-embedding 1, showed statistically superior performance compared with smaller models. The text-embedding 1 model with XGB outperformed text-embedding 2 with SVM, LR, or NN, achieving an AUROC of 0.841 (95% CI, 0.783-0.897) for depression, as well as text-embedding 3 with SVM or LR (eTable 8 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). Although text-embedding 2 and text-embedding 3 showed lower performance, they maintained notable effectiveness, with XGB achieving AUROCs of 0.747 (95% CI, 0.672-0.822) and 0.755 (95% CI, 0.680-0.821), respectively.</p></sec><sec id="H2-9-ZOI250402"><title>Suicide Risk Detection</title><p>Suicide risk detection was more challenging overall, with lower performance compared with depression detection (<xref rid="zoi250402t3" ref-type="table">Table 3</xref>; eTables 2-4 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). For self-concept narratives, zero-shot LLM1 achieved the highest AUROC of 0.731 (95% CI, 0.704-0.762), and LLM2 performed comparably with an AUROC of 0.721 (95% CI, 0.695-0.750). Zero-shot LLM3 significantly underperformed zero-shot LLM1 and LLM2, with mean AUROC differences of 0.0945 (95% CI, 0.0636-0.1231) and 0.0843 (95% CI, 0.0510-0.1174), respectively (eTable 5 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). LLM1 showed significantly higher accuracy than LLM3 (&#x003c7;<sup>2</sup>&#x02009;=&#x02009;20.35; <italic>P</italic>&#x02009;&#x0003c;&#x02009;.001), while LLM2 did not after Bonferroni correction (&#x003c7;<sup>2</sup>&#x02009;=&#x02009;8.461; <italic>P</italic>&#x02009;=&#x02009;.004; threshold, <italic>P</italic>&#x02009;&#x0003c;&#x02009;.003) (eTable 7 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). Few-shot learning improved performance, particularly for LLM3 (mean AUROC difference of 0.0690 [95% CI, 0.0359-0.1012]) (eTable 5 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). However, zero-shot and few-shot performances were comparable within each model, with mean AUROC differences of 0.0068 (95% CI, &#x02212;0.0183 to 0.0338) for LLM1 and &#x02212;0.001 (95% CI, &#x02212;0.0207 to 0.0187]) for LLM2.</p><p>Based on self-concept narratives, embedding-based ML models maintained reasonable accuracy, although the performance was lower than in depression detection. Text-embedding 1 with NN achieved the highest AUROC of 0.739 (95% CI, 0.665-0.807), an accuracy of 0.661 (95% CI, 0.588-0.723), and a macro F1-score of 0.656 (95% CI, 0.582-0.720), closely followed by XGB (AUROC, 0.724 [95% CI, 0.650-0.795]) (<xref rid="zoi250402t3" ref-type="table">Table 3</xref>). Performance gaps between different embedding sizes were smaller compared with depression detection, with more consistent performance across ML models (AUROC range, 0.711 [95% CI, 0.638-0.784] to 0.739 [0.665-0.807] for text-embedding 1). Text-embedding 3 with XGB showed competitive performance (AUROC, 0.736 [95% CI, 0.661-0.804]), while text-embedding 2 with XGB maintained moderate performance (AUROC, 0.681 [95% CI, 0.604-0.755]).</p></sec><sec id="H2-10-ZOI250402"><title>Qualitative Analysis</title><p>The patient in case 1 was clinically significantly identified as having depression by LLM1 based on self-concept narratives, but not as having depression based on gender perception narratives (eTable 9 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). The self-concept narratives contained negative self-image and pessimistic thoughts about the future, while the gender perception narratives showed no signs of distorted beliefs about gender roles (eResults in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). For cases 2 and 3, in which both patients had clinically significant depression, LLM1 failed to detect depression based on self-concept narratives (eTable 9 in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>). The patient in case 2 had a defensive response style, attempting to present a positive self-image, and the patient in case 3 provided rather superficial responses (eResults in <xref rid="note-ZOI250402-1-s" ref-type="supplementary-material">Supplement 1</xref>).</p></sec></sec><sec id="H1-4-ZOI250402"><title>Discussion</title><p>The purpose of this study was to assess whether LLMs and text-embedding models can identify clinically significant depression and high risk of suicide based on patients&#x02019; narratives collected from the SCT. We found that both LLMs and embedding-based ML models successfully detected depression and suicide, achieving AUROCs of approximately 0.7. This finding suggests that domain-specific pretraining may not be essential, as general-purpose, non&#x02013;domain-specific LLMs can sufficiently interpret the sentiment in patients&#x02019; narratives. Specifically, both zero-shot and few-shot LLM1 and LLM2 showed the highest AUROC among the LLMs, along with ML models trained on embeddings from the text-embedding 1 model. Self-concept narratives yielded the highest performance, probably because they might effectively reflect the cognitive patterns of patients with depression and suicide risk. These findings underline the potential of both advanced generative LLMs and ML models using high-quality embeddings for mental health prediction tasks in clinical settings.</p><p>Our models showed performance comparable to previous studies using social media text data by zero-shot learning to detect stress or depression.<sup><xref rid="zoi250402r12" ref-type="bibr">12</xref>,<xref rid="zoi250402r14" ref-type="bibr">14</xref>,<xref rid="zoi250402r15" ref-type="bibr">15</xref>,<xref rid="zoi250402r17" ref-type="bibr">17</xref>,<xref rid="zoi250402r44" ref-type="bibr">44</xref></sup> Also, compared with the study by Bartal et al,<sup><xref rid="zoi250402r19" ref-type="bibr">19</xref></sup> which showed limited performance of LLM3 in detecting childbirth-related posttraumatic stress disorder, our study showed better results, likely due to the use of the latest generative LLMs and embedding models. This finding is in line with our results that models trained on larger datasets performed better, with LLM1, LLM2, and the text-embedding 1 model showing the greatest performance. Although the exact parameters used for LLM1 were not disclosed, it is estimated that LLM1 was trained on 200 billion parameters, and the text-embedding 1 model might have been similarly trained on an extensive dataset of comparable scale. Embedding-based ML models showed the best performance, likely because they were specifically tailored to participants from our institution.</p><p>However, even LLM3 showed high performance in our zero-shot and few-shot learning, suggesting that either detecting depression-related risk is more suitable for language models or SCT narratives effectively reflect the psychological state of participants at risk. The self-concept narratives, revealing attitudes toward one&#x02019;s abilities, guilt, goals, past, and future,<sup><xref rid="zoi250402r22" ref-type="bibr">22</xref></sup> align with the depression triad of Beck.<sup><xref rid="zoi250402r20" ref-type="bibr">20</xref></sup> These characteristics of narratives may provide more insights into the presence of depression, possibly explaining the higher discriminative power observed in the present study. The importance of narrative content is further supported by lower performance with other types of narratives, especially gender perception narratives, and confirmed by our qualitative analyses. Although standard self-assessment scales are useful, time efficient, and easier to administer at the screening stage, individuals who may otherwise be defensive could reveal their depressive cognitions more openly through projective tests such as the SCT.<sup><xref rid="zoi250402r21" ref-type="bibr">21</xref>,<xref rid="zoi250402r22" ref-type="bibr">22</xref>,<xref rid="zoi250402r26" ref-type="bibr">26</xref></sup> These findings call for a reevaluation of the previously undervalued significance of SCT, particularly by leveraging LLMs to analyze these narratives, potentially improving the effectiveness of screening for mental health risks.</p><p>Through qualitative analyses, we identified factors associated with LLM performance beyond the narrative content. Defensive or superficial responses, often due to psychological conflict or low motivation, may limit detection of mental health risks.<sup><xref rid="zoi250402r45" ref-type="bibr">45</xref></sup> These findings suggest that, like all psychological assessments, SCT narratives alone cannot definitively determine mental health risks. Clinical interviews, comprehensive psychiatric history taking, and clinical observations remain essential.</p><p>To our knowledge, this is the first study to examine the use of LLMs and text-embedding models for detecting depression and suicide risk based on semistructured narratives of psychiatric patients. Our study was based on data from Korean-speaking psychiatric patients. Although LLMs are trained in multiple languages, including Korean, and can translate effectively, our results were comparable with those from studies based on English data.<sup><xref rid="zoi250402r12" ref-type="bibr">12</xref>,<xref rid="zoi250402r17" ref-type="bibr">17</xref>,<xref rid="zoi250402r44" ref-type="bibr">44</xref></sup> This finding suggests that LLMs have advanced to the point where they can make accurate predictions across different languages, contributing to a broader understanding of mental health prediction across diverse linguistic contexts.</p><sec id="H2-11-ZOI250402"><title>Limitations</title><p>This study has several limitations. First, this study was based on narrative data of patients who visited a psychiatric clinic. Even those not classified in the clinically significant depression group or high risk of suicide group might have had other psychiatric symptoms, such as anxiety, mild depression, or psychotic symptoms, limiting generalizability. External validation with data from other psychiatric institutions or a nonpsychiatric population would be necessary. Second, depression and suicide severity were determined using self-report measures rather than clinical diagnoses, so individuals with other psychiatric conditions experiencing significant depressive symptoms or suicidal ideation might have been included. This suggests the model may detect general psychological distress rather than specific conditions, limiting its diagnostic capability. Third, the dataset for depression classification was imbalanced, which could potentially affect model performance. However, we primarily compared AUROCs between models, and the AUROC values were consistent with balanced accuracy for LLM evaluation, indicating that model performance was well balanced despite data imbalances. Fourth, although we performed qualitative analysis to identify factors associated with model prediction, the specific narrative features influencing prediction remain unclear due to the &#x0201c;black-box&#x0201d; nature of AI models, whose internal works are not transparent.<sup><xref rid="zoi250402r46" ref-type="bibr">46</xref></sup> Future studies using explainable AI could clarify which features are most diagnostically significant for detecting mental health risks.<sup><xref rid="zoi250402r46" ref-type="bibr">46</xref></sup> Fifth, although we used deidentified narratives, deploying LLMs in clinical practice raises ethical concerns that must be carefully addressed in the future.</p></sec></sec><sec id="H1-5-ZOI250402"><title>Conclusions</title><p>In this cross-sectional study of SCT narratives from psychiatric patients, LLMs and text-embedding models effectively detected depression and suicide risk, particularly using self-concept narratives. Although these models demonstrate potential for detecting mental health risks, further improvements in performance and safety are essential before clinical application.</p></sec></body><back><ref-list id="REF-ZOI250402"><title>References</title><ref id="zoi250402r1"><label>1</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Kung</surname>
<given-names>TH</given-names></string-name>, <string-name><surname>Cheatham</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Medenilla</surname>
<given-names>A</given-names></string-name>, <etal/></person-group>. <article-title>Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models</article-title>. <source>PLOS Digit Health</source>. <year>2023</year>;<volume>2</volume>(<issue>2</issue>):<elocation-id>e0000198</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pdig.0000198</pub-id>
<pub-id pub-id-type="pmid">36812645</pub-id>
</mixed-citation></ref><ref id="zoi250402r2"><label>2</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Brin</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Sorin</surname>
<given-names>V</given-names></string-name>, <string-name><surname>Vaid</surname>
<given-names>A</given-names></string-name>, <etal/></person-group>. <article-title>Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments</article-title>. <source>Sci Rep</source>. <year>2023</year>;<volume>13</volume>(<issue>1</issue>):<fpage>16492</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-023-43436-9</pub-id>
<pub-id pub-id-type="pmid">37779171</pub-id>
</mixed-citation></ref><ref id="zoi250402r3"><label>3</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Shieh</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Tran</surname>
<given-names>B</given-names></string-name>, <string-name><surname>He</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Kumar</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Freed</surname>
<given-names>JA</given-names></string-name>, <string-name><surname>Majety</surname>
<given-names>P</given-names></string-name></person-group>. <article-title>Assessing ChatGPT 4.0&#x02019;s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports</article-title>. <source>Sci Rep</source>. <year>2024</year>;<volume>14</volume>(<issue>1</issue>):<fpage>9330</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-024-58760-x</pub-id>
<pub-id pub-id-type="pmid">38654011</pub-id>
</mixed-citation></ref><ref id="zoi250402r4"><label>4</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Garg</surname>
<given-names>RK</given-names></string-name>, <string-name><surname>Urs</surname>
<given-names>VL</given-names></string-name>, <string-name><surname>Agarwal</surname>
<given-names>AA</given-names></string-name>, <string-name><surname>Chaudhary</surname>
<given-names>SK</given-names></string-name>, <string-name><surname>Paliwal</surname>
<given-names>V</given-names></string-name>, <string-name><surname>Kar</surname>
<given-names>SK</given-names></string-name></person-group>. <article-title>Exploring the role of ChatGPT in patient care (diagnosis and treatment) and medical research: a systematic review</article-title>. <source>Health Promot Perspect</source>. <year>2023</year>;<volume>13</volume>(<issue>3</issue>):<fpage>183</fpage>-<lpage>191</lpage>. doi:<pub-id pub-id-type="doi">10.34172/hpp.2023.22</pub-id>
<pub-id pub-id-type="pmid">37808939</pub-id>
</mixed-citation></ref><ref id="zoi250402r5"><label>5</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Thirunavukarasu</surname>
<given-names>AJ</given-names></string-name>, <string-name><surname>Ting</surname>
<given-names>DSJ</given-names></string-name>, <string-name><surname>Elangovan</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Gutierrez</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Tan</surname>
<given-names>TF</given-names></string-name>, <string-name><surname>Ting</surname>
<given-names>DSW</given-names></string-name></person-group>. <article-title>Large language models in medicine</article-title>. <source>Nat Med</source>. <year>2023</year>;<volume>29</volume>(<issue>8</issue>):<fpage>1930</fpage>-<lpage>1940</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41591-023-02448-8</pub-id>
<pub-id pub-id-type="pmid">37460753</pub-id>
</mixed-citation></ref><ref id="zoi250402r6"><label>6</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Franco D&#x02019;Souza</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Amanullah</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Mathew</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Surapaneni</surname>
<given-names>KM</given-names></string-name></person-group>. <article-title>Appraising the performance of ChatGPT in psychiatry using 100 clinical case vignettes</article-title>. <source>Asian J Psychiatr</source>. <year>2023</year>;<volume>89</volume>:<elocation-id>103770</elocation-id>. doi:<pub-id pub-id-type="doi">10.1016/j.ajp.2023.103770</pub-id>
<pub-id pub-id-type="pmid">37812998</pub-id>
</mixed-citation></ref><ref id="zoi250402r7"><label>7</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Cabral</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Restrepo</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Kanjee</surname>
<given-names>Z</given-names></string-name>, <etal/></person-group>. <article-title>Clinical reasoning of a generative artificial intelligence model compared with physicians</article-title>. <source>JAMA Intern Med</source>. <year>2024</year>;<volume>184</volume>(<issue>5</issue>):<fpage>581</fpage>-<lpage>583</lpage>. doi:<pub-id pub-id-type="doi">10.1001/jamainternmed.2024.0295</pub-id>
<pub-id pub-id-type="pmid">38557971</pub-id>
</mixed-citation></ref><ref id="zoi250402r8"><label>8</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Longwell</surname>
<given-names>JB</given-names></string-name>, <string-name><surname>Hirsch</surname>
<given-names>I</given-names></string-name>, <string-name><surname>Binder</surname>
<given-names>F</given-names></string-name>, <etal/></person-group>. <article-title>Performance of large language models on medical oncology examination questions</article-title>. <source>JAMA Netw Open</source>. <year>2024</year>;<volume>7</volume>(<issue>6</issue>):<elocation-id>e2417641</elocation-id>. doi:<pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.17641</pub-id>
<pub-id pub-id-type="pmid">38888919</pub-id>
</mixed-citation></ref><ref id="zoi250402r9"><label>9</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Goh</surname>
<given-names>E</given-names></string-name>, <string-name><surname>Gallo</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Hom</surname>
<given-names>J</given-names></string-name>, <etal/></person-group>. <article-title>Large language model influence on diagnostic reasoning: a randomized clinical trial</article-title>. <source>JAMA Netw Open</source>. <year>2024</year>;<volume>7</volume>(<issue>10</issue>):<elocation-id>e2440969</elocation-id>. doi:<pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.40969</pub-id>
<pub-id pub-id-type="pmid">39466245</pub-id>
</mixed-citation></ref><ref id="zoi250402r10"><label>10</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Frances</surname>
<given-names>A</given-names></string-name></person-group>. <article-title>The past, present and future of psychiatric diagnosis</article-title>. <source>World Psychiatry</source>. <year>2013</year>;<volume>12</volume>(<issue>2</issue>):<fpage>111</fpage>-<lpage>112</lpage>. doi:<pub-id pub-id-type="doi">10.1002/wps.20027</pub-id>
<pub-id pub-id-type="pmid">23737411</pub-id>
</mixed-citation></ref><ref id="zoi250402r11"><label>11</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Stein</surname>
<given-names>DJ</given-names></string-name>, <string-name><surname>Shoptaw</surname>
<given-names>SJ</given-names></string-name>, <string-name><surname>Vigo</surname>
<given-names>DV</given-names></string-name>, <etal/></person-group>. <article-title>Psychiatric diagnosis and treatment in the 21st century: paradigm shifts versus incremental integration</article-title>. <source>World Psychiatry</source>. <year>2022</year>;<volume>21</volume>(<issue>3</issue>):<fpage>393</fpage>-<lpage>414</lpage>. doi:<pub-id pub-id-type="doi">10.1002/wps.20998</pub-id>
<pub-id pub-id-type="pmid">36073709</pub-id>
</mixed-citation></ref><ref id="zoi250402r12"><label>12</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Le Glaz</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Haralambous</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Kim-Dufor</surname>
<given-names>DH</given-names></string-name>, <etal/></person-group>. <article-title>Machine learning and natural language processing in mental health: systematic review</article-title>. <source>J Med Internet Res</source>. <year>2021</year>;<volume>23</volume>(<issue>5</issue>):<elocation-id>e15708</elocation-id>. doi:<pub-id pub-id-type="doi">10.2196/15708</pub-id>
<pub-id pub-id-type="pmid">33944788</pub-id>
</mixed-citation></ref><ref id="zoi250402r13"><label>13</label><mixed-citation publication-type="book"><person-group><string-name><surname>Ji</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Zhang</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Ansari</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Fu</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Tiwari</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Cambria</surname>
<given-names>E</given-names></string-name></person-group>. MentalBERT: publicly available pretrained language models for mental healthcare. In: Calzolari N, B&#x000e9;chet F, Blache P, et al, eds. <italic>Proceedings of the Thirteenth Language Resources and Evaluation Conference</italic>. <publisher-name>European Language Resources Association</publisher-name>; <year>2022</year>:<fpage>7184</fpage>-<lpage>7190</lpage>.</mixed-citation></ref><ref id="zoi250402r14"><label>14</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Coppersmith</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Leary</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Crutchley</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Fine</surname>
<given-names>A</given-names></string-name></person-group>. <article-title>Natural language processing of social media as screening for suicide risk</article-title>. <source>Biomed Inform Insights</source>. <year>2018</year>;<volume>10</volume>:<elocation-id>1178222618792860</elocation-id>. doi:<pub-id pub-id-type="doi">10.1177/1178222618792860</pub-id>
<pub-id pub-id-type="pmid">30158822</pub-id>
</mixed-citation></ref><ref id="zoi250402r15"><label>15</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Eichstaedt</surname>
<given-names>JC</given-names></string-name>, <string-name><surname>Smith</surname>
<given-names>RJ</given-names></string-name>, <string-name><surname>Merchant</surname>
<given-names>RM</given-names></string-name>, <etal/></person-group>. <article-title>Facebook language predicts depression in medical records</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2018</year>;<volume>115</volume>(<issue>44</issue>):<fpage>11203</fpage>-<lpage>11208</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1802331115</pub-id>
<pub-id pub-id-type="pmid">30322910</pub-id>
</mixed-citation></ref><ref id="zoi250402r16"><label>16</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Nijhawan</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Attigeri</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Ananthakrishna</surname>
<given-names>T</given-names></string-name></person-group>. <article-title>Stress detection using natural language processing and machine learning over social interactions</article-title>. <source>J Big Data</source>. <year>2022</year>;<volume>9</volume>(<issue>1</issue>):<fpage>33</fpage>. doi:<pub-id pub-id-type="doi">10.1186/s40537-022-00575-6</pub-id>
</mixed-citation></ref><ref id="zoi250402r17"><label>17</label><mixed-citation publication-type="preprint"><person-group><string-name><surname>Lamichhane</surname>
<given-names>B</given-names></string-name></person-group>. <article-title>Evaluation of ChatGPT for NLP-based mental health applications</article-title>. <italic>arXiv</italic>. Preprint posted online March 28, 2023. doi:<pub-id pub-id-type="doi">10.48550/arXiv.2303.15727</pub-id></mixed-citation></ref><ref id="zoi250402r18"><label>18</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Xu</surname>
<given-names>X</given-names></string-name>, <string-name><surname>Yao</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Dong</surname>
<given-names>Y</given-names></string-name>, <etal/></person-group>. <article-title>Mental-LLM: leveraging large language models for mental health prediction via online text data</article-title>. <source>Proc ACM Interact Mob Wearable Ubiquitous Technol</source>. <year>2024</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>-<lpage>32</lpage>. doi:<pub-id pub-id-type="doi">10.1145/3643540</pub-id>
<pub-id pub-id-type="pmid">39925940</pub-id>
</mixed-citation></ref><ref id="zoi250402r19"><label>19</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Bartal</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Jagodnik</surname>
<given-names>KM</given-names></string-name>, <string-name><surname>Chan</surname>
<given-names>SJ</given-names></string-name>, <string-name><surname>Dekel</surname>
<given-names>S</given-names></string-name></person-group>. <article-title>AI and narrative embeddings detect PTSD following childbirth via birth stories</article-title>. <source>Sci Rep</source>. <year>2024</year>;<volume>14</volume>(<issue>1</issue>):<fpage>8336</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-024-54242-2</pub-id>
<pub-id pub-id-type="pmid">38605073</pub-id>
</mixed-citation></ref><ref id="zoi250402r20"><label>20</label><mixed-citation publication-type="book"><person-group><string-name><surname>Beck</surname>
<given-names>AT</given-names></string-name></person-group>. <source>Cognitive Therapy of Depression</source>. <publisher-name>Guilford Press</publisher-name>; <year>1979</year>.</mixed-citation></ref><ref id="zoi250402r21"><label>21</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Holaday</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Smith</surname>
<given-names>DA</given-names></string-name>, <string-name><surname>Sherry</surname>
<given-names>A</given-names></string-name></person-group>. <article-title>Sentence completion tests: a review of the literature and results of a survey of members of the Society for Personality Assessment</article-title>. <source>J Pers Assess</source>. <year>2000</year>;<volume>74</volume>(<issue>3</issue>):<fpage>371</fpage>-<lpage>383</lpage>. doi:<pub-id pub-id-type="doi">10.1207/S15327752JPA7403_3</pub-id>
<pub-id pub-id-type="pmid">10900566</pub-id>
</mixed-citation></ref><ref id="zoi250402r22"><label>22</label><mixed-citation publication-type="book"><person-group><string-name><surname>Sacks</surname>
<given-names>JM</given-names></string-name>, <string-name><surname>Levy</surname>
<given-names>S</given-names></string-name></person-group>. The Sentence Completion Test. In: Abt LE, Bellak L, eds. <italic>Projective Psychology: Clinical Approaches to the Total Personality</italic>. <publisher-name>Alfred A. Knopf</publisher-name>; <year>1950</year>:<fpage>357</fpage>-<lpage>402</lpage>.</mixed-citation></ref><ref id="zoi250402r23"><label>23</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Peterson</surname>
<given-names>CH</given-names></string-name>, <string-name><surname>Lomas</surname>
<given-names>GI</given-names></string-name>, <string-name><surname>Neukrug</surname>
<given-names>ES</given-names></string-name>, <string-name><surname>Bonner</surname>
<given-names>MW</given-names></string-name></person-group>. <article-title>Assessment use by counselors in the United States: implications for policy and practice</article-title>. <source>J Couns Dev</source>. <year>2014</year>;<volume>92</volume>(<issue>1</issue>):<fpage>90</fpage>-<lpage>98</lpage>. doi:<pub-id pub-id-type="doi">10.1002/j.1556-6676.2014.00134.x</pub-id>
</mixed-citation></ref><ref id="zoi250402r24"><label>24</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Ready</surname>
<given-names>RE</given-names></string-name>, <string-name><surname>Veague</surname>
<given-names>HB</given-names></string-name></person-group>. <article-title>Training in psychological assessment: current practices of clinical psychology programs</article-title>. <source>Prof Psychol Res Pr</source>. <year>2014</year>;<volume>45</volume>(<issue>4</issue>):<fpage>278</fpage>-<lpage>282</lpage>. doi:<pub-id pub-id-type="doi">10.1037/a0037439</pub-id>
</mixed-citation></ref><ref id="zoi250402r25"><label>25</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Eom</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Choi</surname>
<given-names>S</given-names></string-name></person-group>. <article-title>A study of clinical psychologist&#x02019;s opinion and practice of comprehensive psychological testing</article-title>. <source>Kor J Clin Psychol</source>. <year>2018</year>;<volume>37</volume>(<issue>1</issue>):<fpage>1</fpage>-<lpage>17</lpage>. doi:<pub-id pub-id-type="doi">10.15842/kjcp.2018.37.1.001</pub-id>
</mixed-citation></ref><ref id="zoi250402r26"><label>26</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Piotrowski</surname>
<given-names>C</given-names></string-name></person-group>. <article-title>Sentence completion methods: a summary review of 70 survey-based studies of training and professional settings</article-title>. <source>SIS J Proj Psychol Ment Health</source>. <year>2018</year>;<volume>25</volume>(<issue>1</issue>):<fpage>60</fpage>-<lpage>75</lpage>. Accessed April 1, 2025. <ext-link xlink:href="https://www.researchgate.net/profile/Chris-Piotrowski/publication/326493982_Sentence_Completion_Methods_A_Summary_Review_of_70_Survey-based_Studies_of_Training_and_Professional_Settings/links/5b512251a6fdcc8dae2f889b/Sentence-Completion-Methods-A-Summary-Review-of-70-Survey-based-Studies-of-Training-and-Professional-Settings.pdf" ext-link-type="uri">https://www.researchgate.net/profile/Chris-Piotrowski/publication/326493982_Sentence_Completion_Methods_A_Summary_Review_of_70_Survey-based_Studies_of_Training_and_Professional_Settings/links/5b512251a6fdcc8dae2f889b/Sentence-Completion-Methods-A-Summary-Review-of-70-Survey-based-Studies-of-Training-and-Professional-Settings.pdf</ext-link></mixed-citation></ref><ref id="zoi250402r27"><label>27</label><mixed-citation publication-type="journal">Chan DW, Lee HB. <article-title>Patterns of psychological test usage in Hong Kong in 1993</article-title>. <source>Prof Psychol Res Pr</source>. <year>1995</year>;<volume>26</volume>(<issue>3</issue>):<fpage>292</fpage>-<lpage>297</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0735-7028.26.3.292</pub-id>
</mixed-citation></ref><ref id="zoi250402r28"><label>28</label><mixed-citation publication-type="book"><person-group><string-name><surname>Beck</surname>
<given-names>AT</given-names></string-name></person-group>. <source>Manual for the Beck Depression Inventory&#x02013;II</source>. <publisher-name>APA PsycTests</publisher-name>; <year>1996</year>.</mixed-citation></ref><ref id="zoi250402r29"><label>29</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Sung</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Kim</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Park</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Bai</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Lee</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Ahn</surname>
<given-names>H</given-names></string-name></person-group>. <article-title>A study on the reliability and the validity of Korean version of the Beck Depression Inventory-II (BDI-II)</article-title>. Article in Korean. <source>J Korean Soc Biol Ther Psychiatry</source>. <year>2008</year>;<volume>14</volume>(<issue>2</issue>):<fpage>201</fpage>-<lpage>212</lpage>. Accessed April 8, 2025. <ext-link xlink:href="https://www.kci.go.kr/kciportal/landing/article.kci?arti_id=ART001308461" ext-link-type="uri">https://www.kci.go.kr/kciportal/landing/article.kci?arti_id=ART001308461</ext-link>
</mixed-citation></ref><ref id="zoi250402r30"><label>30</label><mixed-citation publication-type="book"><person-group><string-name><surname>Zung</surname>
<given-names>WW</given-names></string-name></person-group>. <source>Zung Self-Rating Depression Scale and Depression Status Inventory: Assessment of Depression</source>. <publisher-name>Springer</publisher-name>; <year>1986</year>:<fpage>221</fpage>-<lpage>231</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-3-642-70486-4_21</pub-id></mixed-citation></ref><ref id="zoi250402r31"><label>31</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Lee</surname>
<given-names>JH</given-names></string-name></person-group>. <article-title>Development of the Korean form of Zung&#x02019;s Self-Rating Depression Scale</article-title>. <source>J Yeungnam Med Sci</source>. <year>1995</year>;<volume>12</volume>(<issue>2</issue>):<fpage>292</fpage>-<lpage>305</lpage>. doi:<pub-id pub-id-type="doi">10.12701/yujm.1995.12.2.292</pub-id>
</mixed-citation></ref><ref id="zoi250402r32"><label>32</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Beck</surname>
<given-names>AT</given-names></string-name>, <string-name><surname>Kovacs</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Weissman</surname>
<given-names>A</given-names></string-name></person-group>. <article-title>Assessment of suicidal intention: the Scale for Suicide Ideation</article-title>. <source>J Consult Clin Psychol</source>. <year>1979</year>;<volume>47</volume>(<issue>2</issue>):<fpage>343</fpage>-<lpage>352</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0022-006X.47.2.343</pub-id>
<pub-id pub-id-type="pmid">469082</pub-id>
</mixed-citation></ref><ref id="zoi250402r33"><label>33</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Beck</surname>
<given-names>AT</given-names></string-name>, <string-name><surname>Steer</surname>
<given-names>RA</given-names></string-name>, <string-name><surname>Ranieri</surname>
<given-names>WF</given-names></string-name></person-group>. <article-title>Scale for Suicide Ideation: psychometric properties of a self-report version</article-title>. <source>J Clin Psychol</source>. <year>1988</year>;<volume>44</volume>(<issue>4</issue>):<fpage>499</fpage>-<lpage>505</lpage>. doi:<pub-id pub-id-type="doi">10.1002/1097-4679(198807)44:4&#x0003c;499::AID-JCLP2270440404&#x0003e;3.0.CO;2-6</pub-id>
<pub-id pub-id-type="pmid">3170753</pub-id>
</mixed-citation></ref><ref id="zoi250402r34"><label>34</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Shin</surname>
<given-names>MS</given-names></string-name>, <string-name><surname>Park</surname>
<given-names>KB</given-names></string-name>, <string-name><surname>Oh</surname>
<given-names>KJ</given-names></string-name>, <string-name><surname>Kim</surname>
<given-names>ZS</given-names></string-name></person-group>. <article-title>A study of suicidal ideation among high school students: the structural relation among depression, hopelessness, and suicidal ideation</article-title>. <source>Kor J Clin Psychol.</source>
<year>1990</year>;<volume>9</volume>(<issue>1</issue>):<fpage>1</fpage>-<lpage>19</lpage>. Accessed April 8, 2025. <ext-link xlink:href="https://accesson.kr/kjcp/v.9/1/1/26412" ext-link-type="uri">https://accesson.kr/kjcp/v.9/1/1/26412</ext-link>
</mixed-citation></ref><ref id="zoi250402r35"><label>35</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Cochrane-Brink</surname>
<given-names>KA</given-names></string-name>, <string-name><surname>Lofchy</surname>
<given-names>JS</given-names></string-name>, <string-name><surname>Sakinofsky</surname>
<given-names>I</given-names></string-name></person-group>. <article-title>Clinical rating scales in suicide risk assessment</article-title>. <source>Gen Hosp Psychiatry</source>. <year>2000</year>;<volume>22</volume>(<issue>6</issue>):<fpage>445</fpage>-<lpage>451</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0163-8343(00)00106-7</pub-id>
<pub-id pub-id-type="pmid">11072061</pub-id>
</mixed-citation></ref><ref id="zoi250402r36"><label>36</label><mixed-citation publication-type="journal"><person-group><string-name><surname>McCall</surname>
<given-names>WV</given-names></string-name>, <string-name><surname>Batson</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Webster</surname>
<given-names>M</given-names></string-name>, <etal/></person-group>. <article-title>A psychometric cut-point to separate emergently suicidal depressed patients from stable depressed outpatients</article-title>. <source>Indian J Psychiatry</source>. <year>2013</year>;<volume>55</volume>(<issue>3</issue>):<fpage>283</fpage>-<lpage>286</lpage>. doi:<pub-id pub-id-type="doi">10.4103/0019-5545.117150</pub-id>
<pub-id pub-id-type="pmid">24082251</pub-id>
</mixed-citation></ref><ref id="zoi250402r37"><label>37</label><mixed-citation publication-type="thesis"><person-group><string-name><surname>Shin</surname>
<given-names>MS</given-names></string-name></person-group>. <italic>An Empirical Study of the Mechanism of Suicide: Validation of the Scale for Escape From the Self</italic>. Dissertation. Yonsei University; <year>1992</year>.</mixed-citation></ref><ref id="zoi250402r38"><label>38</label><mixed-citation publication-type="webpage">Hwang ST, Kim J, Park KB, Chey J, Hong SH. Standardization of the K-WAIS-IV. Korean Psychological Association Annual Conference; 2012:140-140. Accessed April 12, 2025. <ext-link xlink:href="https://kiss.kstudy.com/Detail/Ar?key=3097791" ext-link-type="uri">https://kiss.kstudy.com/Detail/Ar?key=3097791</ext-link></mixed-citation></ref><ref id="zoi250402r39"><label>39</label><mixed-citation publication-type="other">Wechsler, D. Wechsler Adult Intelligence Scale&#x02013;Fourth Edition (WAIS-IV). APA PsycTests; 2008. doi:<pub-id pub-id-type="doi">10.1037/t15169-000</pub-id></mixed-citation></ref><ref id="zoi250402r40"><label>40</label><mixed-citation publication-type="webpage">Guidance regarding methods for de-identification of protected health information in accordance with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule. Human Health Services. US Department of Health and Human Services. <year>2012</year>. Accessed September 12, 2024. <ext-link xlink:href="https://www.hhs.gov/hipaa/for-professionals/special-topics/de-identification/index.html" ext-link-type="uri">https://www.hhs.gov/hipaa/for-professionals/special-topics/de-identification/index.html</ext-link></mixed-citation></ref><ref id="zoi250402r41"><label>41</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Pedregosa</surname>
<given-names>F</given-names></string-name>, <string-name><surname>Varoquaux</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Gramfort</surname>
<given-names>A</given-names></string-name>, <etal/></person-group>. <article-title>Scikit-learn: machine learning in Python</article-title>. <source>J Mach Learn Res</source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>-<lpage>2830</lpage>. Accessed April 1, 2025. <ext-link xlink:href="https://dl.acm.org/doi/pdf/10.5555/1953048.2078195" ext-link-type="uri">https://dl.acm.org/doi/pdf/10.5555/1953048.2078195</ext-link></mixed-citation></ref><ref id="zoi250402r42"><label>42</label><mixed-citation publication-type="confproc"><person-group><string-name><surname>Chen</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Guestrin</surname>
<given-names>C</given-names></string-name></person-group>. XGBoost: a scalable tree boosting system. Presented at: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; <year>2016</year>; San Francisco, California. </mixed-citation></ref><ref id="zoi250402r43"><label>43</label><mixed-citation publication-type="confproc"><person-group><string-name><surname>Abadi</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Barham</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Chen</surname>
<given-names>J</given-names></string-name>, <etal/></person-group>. TensorFlow: a system for large-scale machine learning. Presented at: Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation; <year>2016</year>; Savannah, Georgia.</mixed-citation></ref><ref id="zoi250402r44"><label>44</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Ophir</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Tikochinski</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Asterhan</surname>
<given-names>CSC</given-names></string-name>, <string-name><surname>Sisso</surname>
<given-names>I</given-names></string-name>, <string-name><surname>Reichart</surname>
<given-names>R</given-names></string-name></person-group>. <article-title>Deep neural networks detect suicide risk from textual facebook posts</article-title>. <source>Sci Rep</source>. <year>2020</year>;<volume>10</volume>(<issue>1</issue>):<fpage>16685</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-020-73917-0</pub-id>
<pub-id pub-id-type="pmid">33028921</pub-id>
</mixed-citation></ref><ref id="zoi250402r45"><label>45</label><mixed-citation publication-type="book"><person-group><string-name><surname>Groth-Marnat</surname>
<given-names>G</given-names></string-name></person-group>. <italic>Handbook of Psychological Assessment</italic>. 5th ed. John Wiley &#x00026; Sons Inc; <year>2009</year>.</mixed-citation></ref><ref id="zoi250402r46"><label>46</label><mixed-citation publication-type="journal"><person-group><string-name><surname>Amann</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Blasimme</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Vayena</surname>
<given-names>E</given-names></string-name>, <string-name><surname>Frey</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Madai</surname>
<given-names>VI</given-names></string-name>; <collab>Precise4Q Consortium</collab></person-group>. <article-title>Explainability for artificial intelligence in healthcare: a multidisciplinary perspective</article-title>. <source>BMC Med Inform Decis Mak</source>. <year>2020</year>;<volume>20</volume>(<issue>1</issue>):<fpage>310</fpage>. doi:<pub-id pub-id-type="doi">10.1186/s12911-020-01332-6</pub-id>
<pub-id pub-id-type="pmid">33256715</pub-id>
</mixed-citation></ref></ref-list><notes notes-type="supplementary-material" id="note-ZOI250402-1"><supplementary-material id="note-ZOI250402-1-s" position="float" content-type="local-data"><label>Supplement 1.</label><caption><p><bold>eTable 1.</bold> Translated Version of 50 Items of the Korean Sentence Completion Test</p><p><bold>eTable 2.</bold> Performance of Zero-Shot, Few-Shot Large Language Models and Embedding-Based Machine Learning Models Detecting Clinically Significant Depression and High Risk of Suicide Based on SCT Family Narratives</p><p><bold>eTable 3.</bold> Performance of Zero-Shot, Few-Shot Large Language Models and Embedding-Based Machine Learning Models Detecting Clinically Significant Depression and High Risk of Suicide Based on SCT Gender Perception Narratives</p><p><bold>eTable 4.</bold> Performance of Zero-Shot, Few-Shot Large Language Models and Embedding-Based Machine Learning Models Detecting Clinically Significant Depression and High Risk of Suicide Based on SCT Interpersonal Relations</p><p><bold>eTable 5.</bold> Mean AUC Differences and 95% Confidence Intervals Between Model Pairs for Large Language Models Using Self-Concept Narratives</p><p><bold>eTable 6.</bold> Cochran&#x02019;s Test Results for Large Language Models Accuracy Comparisons Using Self-Concept Narratives</p><p><bold>eTable 7.</bold> McNemar Test Results for Pairwise Model Comparisons Using Self-Concept Narratives</p><p><bold>eTable 8.</bold> Statistically Significant Mean AUROC Differences and 95% Confidence Intervals Between Model Pairs for Embedding-Based ML Models Using Self-Concept Narratives</p><p><bold>eMethods.</bold> Procedures for Qualitative Analysis</p><p><bold>eTable 9.</bold> Narratives and GPT-4o Reasoning in Qualitative Analysis</p><p><bold>eResults.</bold> Case Summaries of Qualitative Analysis</p></caption><media xlink:href="jamanetwopen-e2511922-s001.pdf"/></supplementary-material><supplementary-material position="float" content-type="local-data"><label>Supplement 2.</label><caption><p>
Data Sharing Statement
</p></caption><media xlink:href="jamanetwopen-e2511922-s002.pdf"/></supplementary-material></notes></back></article><!--requester-ID pruich-->