<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">JMIR Serious Games</journal-id><journal-id journal-id-type="iso-abbrev">JMIR Serious Games</journal-id><journal-id journal-id-type="publisher-id">JSG</journal-id><journal-title-group><journal-title>JMIR Serious Games</journal-title></journal-title-group><issn pub-type="epub">2291-9279</issn><publisher><publisher-name>JMIR Publications</publisher-name><publisher-loc>Toronto, Canada</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39933172</article-id><article-id pub-id-type="pmc">PMC11862761</article-id><article-id pub-id-type="publisher-id">v13i1e56269</article-id><article-id pub-id-type="doi">10.2196/56269</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group><subj-group subj-group-type="article-type"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>A Serious Game to Study Reduced Field of View in Keyhole Surgery: Development and Experimental Study</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Baranyi</surname><given-names>Ren&#x000e9;</given-names></name></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Xiong</surname><given-names>Shuo</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Hassan</surname><given-names>Ahmed</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Wani</surname><given-names>Imtiaz</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Aksoy</surname><given-names>Mehmet</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Patel</surname><given-names>Dixit</given-names></name></contrib></contrib-group><contrib-group><contrib id="contrib1" contrib-type="author"><name><surname>Whitley</surname><given-names>Phoebe</given-names></name><degrees>MSc</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0009-0008-0729-7720</contrib-id></contrib><contrib id="contrib2" contrib-type="author"><name><surname>Creasey</surname><given-names>Connor</given-names></name><degrees>MSc</degrees><xref rid="aff1" ref-type="aff">1</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0009-0009-3391-9439</contrib-id></contrib><contrib id="contrib3" contrib-type="author"><name><surname>Clarkson</surname><given-names>Matthew J</given-names></name><degrees>PhD</degrees><xref rid="aff2" ref-type="aff">2</xref><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5565-1252</contrib-id></contrib><contrib id="contrib4" contrib-type="author" corresp="yes"><name><surname>Thompson</surname><given-names>Stephen</given-names></name><degrees>PhD</degrees><contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7286-1326</contrib-id><xref rid="aff3" ref-type="aff">3</xref><address><institution>Advanced Research Computing</institution><institution>University College London</institution><addr-line>Gower Street</addr-line><addr-line>London, WC1E 6BT</addr-line><country>United Kingdom</country><phone>44 2076792000</phone><email>s.thompson@ucl.ac.uk</email></address></contrib></contrib-group><aff id="aff1">
<label>1</label>
<institution>Department of Medical Physics and Biomedical Engineering</institution>
<institution>Faculty of Engineering Sciences</institution>
<institution>University College London</institution>
<addr-line>London</addr-line>
<country>United Kingdom</country>
</aff><aff id="aff2">
<label>2</label>
<institution>UCL Hawkes Institute</institution>
<institution>Faculty of Engineering Sciences</institution>
<institution>University College London</institution>
<addr-line>London</addr-line>
<country>United Kingdom</country>
</aff><aff id="aff3">
<label>3</label>
<institution>Advanced Research Computing</institution>
<institution>University College London</institution>
<addr-line>London</addr-line>
<country>United Kingdom</country>
</aff><author-notes><corresp>Corresponding Author: Stephen Thompson <email>s.thompson@ucl.ac.uk</email></corresp></author-notes><pub-date pub-type="collection"><year>2025</year></pub-date><pub-date pub-type="epub"><day>11</day><month>2</month><year>2025</year></pub-date><volume>13</volume><elocation-id>e56269</elocation-id><history><date date-type="received"><day>11</day><month>1</month><year>2024</year></date><date date-type="rev-request"><day>19</day><month>8</month><year>2024</year></date><date date-type="rev-recd"><day>30</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>17</day><month>1</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9;Phoebe Whitley, Connor Creasey, Matthew J Clarkson, Stephen Thompson. Originally published in JMIR Serious Games (https://games.jmir.org), 11.02.2025.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link xlink:href="https://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Serious Games, is properly cited. The complete bibliographic information, a link to the original publication on <ext-link xlink:href="https://games.jmir.org" ext-link-type="uri">https://games.jmir.org</ext-link>, as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:href="https://games.jmir.org/2025/1/e56269"/><abstract><sec sec-type="background"><title>Background</title><p>During keyhole surgery, the surgeon is required to perform highly demanding tasks while only being able to see part of the patient&#x02019;s anatomy. This limited field of view is widely cited as a key limitation of the procedure, and many computational methods have been proposed to overcome it. However, the precise effects of a limited field of view on task performance remain unknown due to the lack of tools to study these effects effectively.</p></sec><sec sec-type="objective"><title>Objective</title><p>This paper describes our work on developing a serious game with 2 objectives: (1) to create an engaging game that communicates some of the challenges of keyhole surgery, and (2) to test the effect of a limited field of view on task performance. The development of a serious game that can be played by a wide range of participants will enable us to gather quantitative data on the effects of the reduced field of view on task performance. These data can inform the future development of technologies to help surgeons reduce the impact of a limited field of view on clinical outcomes for patients. The game is open source and may be adapted and used by other researchers to study related problems.</p></sec><sec sec-type="methods"><title>Methods</title><p>We implemented an open-source serious game in JavaScript, inspired by the surgical task of selectively cauterizing blood vessels during twin-to-twin transfusion surgery. During the game, the player is required to identify and cut the correct blood vessel under different fields of view and varying levels of vascular complexity. We conducted a quantitative analysis of task performance time under different conditions and a formative analysis of the game using participant questionnaires.</p></sec><sec sec-type="results"><title>Results</title><p>We recruited 25 players to test the game and recorded their task performance time, accuracy, and qualitative metrics. Reducing the field of view resulted in participants taking significantly longer (P&#x0003c;.001) to perform otherwise identical tasks (mean 6.4 seconds, 95% CI 5.0-7.8 seconds vs mean 13.6 seconds, 95% CI 10.3-16.9 seconds). Participants found the game engaging and agreed that it enhanced their understanding of the limited field of view during keyhole surgery.</p></sec><sec sec-type="conclusions"><title>Conclusions</title><p>We recruited 25 players to test the game and recorded their task performance time, accuracy, and qualitative metrics. Reducing the field of view resulted in participants taking statistically significantly longer (16.4 vs 9.8 seconds; P=.05) to perform otherwise identical tasks. Participants found the game engaging and agreed that it enhanced their understanding of the limited field of view during keyhole surgery.</p></sec></abstract><kwd-group><kwd>keyhole surgery</kwd><kwd>laparoscopic surgery</kwd><kwd>serious games</kwd><kwd>image mosaicking</kwd><kwd>field of view</kwd><kwd>javascript</kwd><kwd>html</kwd><kwd>opensource</kwd></kwd-group></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><sec><title>Background</title><p>Keyhole surgery presents various advantages when compared with open surgery. The primary reason is that manipulation of abdominal tissue is reduced, resulting in less scarring, trauma, and hemorrhaging. This reduces the demand on health care services as patients require shorter hospital stays due to less postoperative pain [<xref rid="ref1" ref-type="bibr">1</xref>-<xref rid="ref3" ref-type="bibr">3</xref>]. Although keyhole surgery offers advantages, there are also limitations, such as a limited field of view, reduced depth perception, and increased procedure times.</p><p>Keyhole surgery is performed using endoscopes (and laparoscopes, a rigid endoscope used in abdominal procedures). Endoscopes consist of a long thin tube, with a camera and light source attached at the end. The surgeon is unable to see the anatomy directly but instead relies on video relayed from the endoscope camera [<xref rid="ref4" ref-type="bibr">4</xref>]. This video presents a significantly reduced field of view in comparison to open surgery [<xref rid="ref5" ref-type="bibr">5</xref>].</p><p>The monitor reduces depth perception of the operating scene as surgeons must map between the 2D image on the monitor and the 3D anatomical structure of the patient [<xref rid="ref6" ref-type="bibr">6</xref>]. Visual misperceptions can occur from the loss of binocular vision due to a decrease in depth perception [<xref rid="ref7" ref-type="bibr">7</xref>]. This can also be caused by surgeon fatigue as the laparoscopic setup is cerebrally intensive and increases the cognitive load of surgeons [<xref rid="ref8" ref-type="bibr">8</xref>].</p><p>Modern endoscopes provide high spatial resolution, but at the expense of a limited field of view [<xref rid="ref9" ref-type="bibr">9</xref>]. The surgeon&#x02019;s ability to view the surgical scene is limited by the narrow monocular field of view of the endoscopic camera [<xref rid="ref10" ref-type="bibr">10</xref>]. In contrast to the panoramic view during open surgery, the endoscope only images small areas of the surgical scene at once [<xref rid="ref11" ref-type="bibr">11</xref>]. The camera has a fixed field of view, requiring the surgeon to maneuver the laparoscope to the target region [<xref rid="ref12" ref-type="bibr">12</xref>]. The limited field of view during endoscope surgery has been widely cited as a limitation, and this will be the focus of this research project.</p></sec><sec><title>Image Mosaicking</title><p>Image mosaicking is an established technique to construct a single image of the increased field of view by aligning various partially overlapped images of the same scene. Computational mosaicking can increase the field of view without compromising spatial resolution. Recently, this technique has been heavily researched, and its application is used in numerous industries, such as surveillance, satellite mapping, and agriculture. Mosaicking has also been used in endoscopic surgery to overcome the limited field of view and assists surgeons in manipulating the surgical scene and planning surgeries [<xref rid="ref13" ref-type="bibr">13</xref>]. Daga et al [<xref rid="ref14" ref-type="bibr">14</xref>] demonstrated the use of computational mosaicking for spatial orientation and anastomoses localization during endoscopic procedures. Computational mosaicking in endoscopic surgery remains challenging due to inhomogeneous lighting [<xref rid="ref15" ref-type="bibr">15</xref>] and uncontrolled movement of the endoscope combined with geometric image distortion from the endoscope camera [<xref rid="ref16" ref-type="bibr">16</xref>]. Because of these challenges, research to develop enhanced mosaicking algorithms is ongoing; however, there remains little understanding of the likely benefits of computational mosaicking in this field. A recent study has shown that experienced laparoscopic surgeons are proficient at &#x0201c;mentally mosaicking,&#x0201d; which is the ability to effectively translate the 2D visual information into the 3D anatomical context [<xref rid="ref17" ref-type="bibr">17</xref>]. Our research is inspired by the question of how to best deploy computational mosaicking taking into account the user&#x02019;s ability to do the same task mentally.</p><p>A key question that remains difficult to answer is &#x0201c;What precisely are the benefits of mosaicking or otherwise enlarging the field of view?.&#x0201d; To put it in statistical terms, what is the expected effect size for a given change in the field of view? Estimating the effect size is essential for any power calculation required in a study on a proposed technology to enlarge the field of view. As the study becomes more realistic and onerous (eg, an in vivo study requiring human volunteers and expert surgeons), it becomes essential that a realistic required sample size can be calculated before gaining ethical approval. One way to estimate the effect size would be to perform a study measuring task performance versus field of view; however, such a study would require a large number of participants. Recruiting sufficient surgeons to perform such a study would be difficult and time-consuming.</p></sec><sec><title>User Studies With Nonexpert Users</title><p>Our work builds on the recent work of Yoo et al [<xref rid="ref18" ref-type="bibr">18</xref>] who asked whether nonsurgical participants could stand in for surgical participants in user studies. They compared performance between participants with different levels of surgical training when interacting with a surgical augmented reality system (also see [<xref rid="ref19" ref-type="bibr">19</xref>]). Comparing surgeons with different levels of experience with nonsurgeons, they found important differences in the performance of surgeons and nonsurgeons, but also similarities that can be used to inform system design, concluding that nonsurgical users could act as useful stand ins for surgical users, particularly in the early stages of device development. We wanted to see whether, by creating an abstract and fun representation of the mosaicking problem, we could lower the bar to recruitment, thus making a prerecruitment power study less important (ie, we can easily recruit many people, and there is no risk to the participants), so we can keep recruiting until we have enough data to show the statistical significance and calculate an effect size to inform future work. One way to achieve this may be through a serious game, which creates a simplified representation of the clinical problem, allowing us to recruit nonexpert users.</p></sec><sec><title>Serious Games</title><p>Serious games have become increasingly prevalent for educational purposes, partly due to advancements in technology [<xref rid="ref20" ref-type="bibr">20</xref>]. Serious games fulfill an additional role beyond pure entertainment [<xref rid="ref21" ref-type="bibr">21</xref>,<xref rid="ref22" ref-type="bibr">22</xref>]. Research has shown that incorporating intrinsic motivation into games, such as challenges and curiosity, substantially increases user motivation [<xref rid="ref5" ref-type="bibr">5</xref>]. Creating immersive game environments can generate a deeper understanding by allowing users to test their problem-solving and decision-making skills within a safe environment [<xref rid="ref23" ref-type="bibr">23</xref>]. Serious games can be personalized and designed to support the acquisition of knowledge and skill development, showing the need for these games to evaluate learning progress through player feedback [<xref rid="ref24" ref-type="bibr">24</xref>]. Providing an interactive learning environment with instant visual feedback, such as a score, encourages more involvement and leads to a greater desire to complete the task at hand [<xref rid="ref25" ref-type="bibr">25</xref>].</p><p>Serious games have previously been applied in the field of surgical training; for example, Underground is a serious game for the Nintendo Wii U platform, and the psychomotor skills required by users to complete the game objectives are closely related to the laparoscopic motor skills required by surgeons. Jalink et al [<xref rid="ref26" ref-type="bibr">26</xref>] concluded that playing Underground increased laparoscopic skill development. A very important point when considering the use of games to represent a complex real-world procedure such as surgery is construct validity, that is, can it be shown that the skills used during the game correlate with performance during surgery. Construct validity for Underground was demonstrated by IJgosse et al [<xref rid="ref27" ref-type="bibr">27</xref>], proving a link between in-game performance and surgical skills. Perhaps more interestingly, links between in-game performance and suturing skills have been shown for games with no apparent link to surgery [<xref rid="ref28" ref-type="bibr">28</xref>].</p><p>Similarly, Ou et al [<xref rid="ref29" ref-type="bibr">29</xref>] demonstrated that surgical trainees with previous gaming experience performed better in terms of laparoscopic simulation performance, compared with their nongaming counterparts. Surgical serious games must measure specific game metrics to quantify user performance [<xref rid="ref30" ref-type="bibr">30</xref>]. The Kheiron Training System is a serious game designed to test basic psycho-motor skills required during laparoscopic surgery by utilizing real laparoscopic instruments. However, no studies have provided validation of this game as a training platform or obtained data to quantify the effect of the limited field of view in this game [<xref rid="ref23" ref-type="bibr">23</xref>]. Although these studies show that serious games can be applied to skill development for surgical tasks, none of them attempt to answer questions on whether surgical technology development can be informed by users&#x02019; task performance when playing serious games. In this paper, we demonstrate the use of a serious game to generate quantitative data to inform the ongoing development of computational mosaicking.</p><p>The remaining sections of this paper describe the development and testing of the serious game we are developing. The game is designed to enable gathering quantitative data on the effect of reduced field of view that will be applicable to keyhole surgery. These data will be useful for estimating effect sizes (and hence statistical power) for follow-up studies requiring more clinically representative participants and equipment. Alongside this, we also aimed to make the game engaging and fun to play, accessible to users of different abilities, and able to test the skills (hand-eye coordination and mental mosaicking) of different users.</p></sec><sec><title>Game Design and Implementation</title><p>The game has 2 aims: first, to study the effect of a reduced field of view on task performance, and second, to create a game for public engagement that communicates the challenges of keyhole surgery to a nontechnical audience and explores how image mosaicking may help address these challenges. These 2 aims are somewhat contradictory. For a strict study of a reduced field of view, a randomized-level structure coupled with a strictly defined training protocol would be ideal, to avoid comparison results being confounded with learning effects [<xref rid="ref31" ref-type="bibr">31</xref>]. For a game aimed at public engagement, however, we want something that is easy to play from level 1 and engages the player with increased challenges at each level.</p><p>For this study, we decided to focus on the latter aim, so we use a set-level structure with increasing challenge at each level. This was to ensure the user was in a flow state by increasing the skill level required to successfully complete each game level [<xref rid="ref32" ref-type="bibr">32</xref>]. To reduce the impact of learning effects, the levels used for comparison were placed at the end of the sequential-level structure. <xref rid="table1" ref-type="table">Table 1</xref> summarizes the level structure, the objectives for each level, and the skills developed for each level.</p><table-wrap position="float" id="table1"><label>Table 1</label><caption><p>Level structure showing the game features and skills required in each level. The game gets more difficult with each level, while incrementally introducing 1 of 3 challenges (more vessels, more complex shapes, and limiting the field of view).</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="100" span="1"/><col width="100" span="1"/><col width="150" span="1"/><col width="150" span="1"/><col width="500" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Level</td><td rowspan="1" colspan="1">Vessels</td><td rowspan="1" colspan="1">Vessels intertwined</td><td rowspan="1" colspan="1">Field of view</td><td rowspan="1" colspan="1">Skills tested</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">No</td><td rowspan="1" colspan="1">Full</td><td rowspan="1" colspan="1">Hand-eye coordination</td></tr><tr valign="top"><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">No</td><td rowspan="1" colspan="1">Full</td><td rowspan="1" colspan="1">Hand-eye coordination and decision-making</td></tr><tr valign="top"><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">No</td><td rowspan="1" colspan="1">Limited</td><td rowspan="1" colspan="1">Hand-eye coordination and image mosaicking</td></tr><tr valign="top"><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">Intertwined</td><td rowspan="1" colspan="1">Full</td><td rowspan="1" colspan="1">Hand-eye coordination, visual perception, and decision-making</td></tr><tr valign="top"><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">Intertwined</td><td rowspan="1" colspan="1">Limited</td><td rowspan="1" colspan="1">Hand-eye coordination, visual perception, decision-making, and image mosaicking</td></tr><tr valign="top"><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">Intertwined</td><td rowspan="1" colspan="1">Full</td><td rowspan="1" colspan="1">Hand-eye coordination, visual perception, and decision-making</td></tr><tr valign="top"><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">Intertwined</td><td rowspan="1" colspan="1">Limited</td><td rowspan="1" colspan="1">Hand-eye coordination, visual perception, decision-making, and image mosaicking</td></tr></tbody></table></table-wrap><p>We identified 4 key skills that we wanted to address in the game. The first skill is hand-eye coordination, which is needed for all surgeries. Successful surgery requires that the surgeon is able to accurately cut in the intended location. In actual surgery, this is complicated by the need to use specialized tools. This is particularly difficult for keyhole surgery where the action of the tools is reversed. In a previous study [<xref rid="ref33" ref-type="bibr">33</xref>] with nonexpert recruits, we observed that the mental load required to use laparoscopic tools can overwhelm any effect observed from changing the control variables. If the cutting mechanism is made too realistic, it is likely that we would not observe a change in performance with the field of view, as nonexpert users might find the game too difficult. Therefore, we decided that the hand-eye coordination skill would just require the use of a mouse to position the cursor over the vessel and press the mouse button to commence a cut. This element of the game remains the same across all levels.</p><p>The second skill is decision-making in the form of curve tracing [<xref rid="ref34" ref-type="bibr">34</xref>] (ie, given the choice of 2 vessels, which one should be cut?). The user is required to visually inspect each path and work out which one connects the 2 black dots. Our game was inspired by surgery to treat twin-to-twin transfusion, as this is an area where image mosaicking has been proposed to improve performance [<xref rid="ref14" ref-type="bibr">14</xref>] in keyhole surgery. The surgeon selectively cauterizes placental blood vessels to separate the blood supply to each twin. This requires careful identification of each vessel and its path. We created a simplified representation of this to create a curve-tracing game. Our representation of this is abstract to enable nonexpert users to play, but elements such as multiple vessels and intertwining are introduced during the game. All levels apart from 1 and 3 have multiple vessels and the player must decide which is the correct vessel to cut.</p><p>The third skill is visual perception. In most keyhole procedures, differentiating one structure from another can be challenging, as human anatomy does not consist of regular shapes in high-contrast colors. Therefore, we designed the game with a low-color contrast between the vessels and the background. In levels 4-7, we introduced multiple intertwined vessels without color contrast to make it more difficult to distinguish between them.</p><p>The final skill is image mosaicking. During keyhole surgery, it is not possible to see the whole surgical scene, a situation referred to as the limited field of view. A skilled keyhole surgeon must be able to mentally reconstruct the whole anatomical scene from a series of partial views created as they move the endoscope around. We introduce this skill at level 3 using a spotlight effect, so the player can only see part of the scene at once and must move the spotlight around with the mouse to mentally reconstruct the scene and identify the correct vessel.</p><p>The 4 skills are combined in different ways as the game progresses. To study the potential effects of a limited field of view, we created 2 pairs of levels (4&#x0003c;&#x0003e;5 and 6&#x0003c;&#x0003e;7) that are identical except for the field of view, allowing for a comparison of results between these levels.</p></sec><sec><title>Game Implementation</title><p><xref rid="figure1" ref-type="fig">Figure 1</xref> (also see [<xref rid="ref35" ref-type="bibr">35</xref>,<xref rid="ref36" ref-type="bibr">36</xref>]) shows screenshots of 6 game levels, illustrating the main game mechanics. <xref rid="figure1" ref-type="fig">Figure 1</xref>A shows the game at its most basic level with a single vessel on the screen. The user has identified the vessel and drawn a black line across the vessel to cut it. The time (in seconds) it took them to do this is displayed at the top left along with the number of attempts. A reduced field of view is introduced at level 4 (<xref rid="figure1" ref-type="fig">Figure 1</xref>C), with levels getting progressively harder until level 7 (<xref rid="figure1" ref-type="fig">Figure 1</xref>F), which has 3 intertwined blood vessels with a reduced field of view. Finally, level 7 has 3 intertwined blood vessels combined with a limited field of view.</p><p>The game was implemented in HTML and JavaScript and can be run in most modern web browsers. It is hosted as a static web page on GitHub. Allowing users to run the game directly from their browsers provides instant feedback, enhancing user interaction and engagement by displaying results immediately [<xref rid="ref33" ref-type="bibr">33</xref>]. Game elements were created using the Phaser (version 3.60.0) [<xref rid="ref37" ref-type="bibr">37</xref>] game framework. Phaser offers a configurable, open-source development library that supports small build sizes and fast loading times [<xref rid="ref38" ref-type="bibr">38</xref>]. Additionally, it provides a wide range of tutorials and community support to facilitate development.</p><p>The game includes a timer to measure the time taken to complete each level but does not record results. Therefore, for the experiments, the results were recorded manually by the authors. For full technical details, the version of the game used in this paper, along with the data supporting the results, is archived on Zenodo [<xref rid="ref35" ref-type="bibr">35</xref>].</p><fig position="float" id="figure1"><label>Figure 1</label><caption><p>Examples of 6 game levels illustrating the incremental change in difficulty throughout the game. The full implementation of the game can be found at [<xref rid="ref35" ref-type="bibr">35</xref>] or played directly at [<xref rid="ref36" ref-type="bibr">36</xref>].</p></caption><graphic xlink:href="games_v13i1e56269_fig1" position="float"/></fig></sec><sec><title>Vessel Creation and Cutting Logic</title><p>Vessels were represented as polygons, colored red, and stretched to fit the window width. Users navigated a pointer around the scene using their mouse. On levels with a reduced field of view, the mouse also moved the viewport (implemented using a circular bitmap mask), ensuring that the mouse pointer remained at the center of the viewport. Pressing and holding the mouse button started drawing a black line across the scene, while releasing the button ended the line drawing and incremented the attempt counter by 1. Upon completing the line drawing, a check determined whether the drawn line completely intersected the target vessel. If successful, a level completion message was displayed, and the level timer stopped. To prevent users from drawing a line across the entire scene&#x02014;inevitably intersecting both sides of the polygon&#x02014;a maximum line length of 45 units was enforced.</p><p>For levels with multiple blood vessels, circles were added to the end of each path, and users were required to cut only the blood vessel labeled with 2 black circles (see <xref rid="figure1" ref-type="fig">Figure 1</xref>C for an illustration).</p><p><xref rid="figure1" ref-type="fig">Figure 1</xref>D demonstrates how the limited field of view was incorporated. Users could only view the game scene within the mask by moving their mouse across the screen. They had to navigate around the screen to locate the blood vessel marked with 2 black circles and use their mouse to cut it. The timer, displayed at the top of the game interface, stopped only after both sides of the correct blood vessel were fully intersected. If the user failed to completely intersect both sides of the blood vessel, the accuracy counter was incremented, and the timer continued. Users then had to try again by drawing a new line to cut the blood vessel.</p><p>The complete implementation of the game used in this publication is archived online [<xref rid="ref35" ref-type="bibr">35</xref>]. The archive also includes links to newer development versions of the game and the URL provided to participants for accessing the game. This participant access URL leads to an index screen that contains links to the consent form, game instructions, and individual levels.</p></sec></sec><sec sec-type="methods"><title>Methods</title><sec><title>Study Design</title><p>We used the game to perform a single-arm user study with all users playing all levels of the game in the same order.</p></sec><sec><title>Participant Recruitment</title><p>As discussed in the &#x0201c;Introduction&#x0201d; section, a key aim of the game design was to ensure that clinical experience was not required to play. Therefore, we deliberately avoided recruiting surgeons at this stage, although they were not excluded. The only inclusion criteria were age (participants had to be between 18 and 65 years old) and residency in the United Kingdom. Participants were recruited through the departmental email list (Medical Physics and Biomedical Engineering) or via a direct approach among the first author&#x02019;s acquaintances.</p><p>Participant experiments were conducted either in person or via video calls and lasted approximately 15 minutes. Participants accessed the game through a URL [<xref rid="ref35" ref-type="bibr">35</xref>].</p><p>Before playing the game, participants were asked, &#x0201c;What do you know about laparoscopic surgery?&#x0201d; and &#x0201c;Do you know the potential effects of a limited field of view in laparoscopic surgery?&#x0201d; to assess their prior knowledge of the domain. After completing a consent form, participants were provided with instructions on how to play the game.</p><p>Participants were instructed to play the game and complete each level in sequence, accessing each level through the game&#x02019;s home page.</p></sec><sec><title>Time to Complete Level</title><p>The in-game timer started automatically when participants clicked on a game level and stopped once they successfully cut the correct blood vessel. These data were recorded by the researcher for both in-person and remote experiments.</p></sec><sec><title>Accuracy</title><p>A counter variable recorded the number of attempts each participant needed to successfully complete each level, increasing with each mouse click used to draw a new line.</p></sec><sec><title>Participant Questionnaires</title><p>In addition to the pregame questionnaires, participants completed a postgame questionnaire, a NASA (National Aeronautics and Space Administration) Task Load Index [<xref rid="ref39" ref-type="bibr">39</xref>] questionnaire, and a System Usability Scale [<xref rid="ref40" ref-type="bibr">40</xref>] questionnaire after finishing all 7 levels. Full details of the questions can be found in the &#x0201c;Results&#x0201d; section.</p></sec><sec><title>Ethical Approval</title><p>This study was approved by University College London&#x02019;s Research Ethics Committee (reference number 24249_001). Informed consent was obtained from all individual participants included in the study.</p></sec></sec><sec sec-type="results"><title>Results</title><sec><title>Participant Recruitment</title><p>We recruited 25 participants from a range of backgrounds, experiences, and ages for this study. The recruitment approach led to a high number of master&#x02019;s students with advanced knowledge of laparoscopic surgery and computer science, as well as students specializing in other sciences. Additionally, working professionals from various industries were recruited, some with little to no understanding of laparoscopic surgery. One participant had medical experience and reported knowledge of keyhole surgery. This diverse participant pool was selected to gather a broad range of responses and perspectives.</p><p>We did not record details of participants&#x02019; prior gaming experience or their computer usage. However, as some participants were known to the authors, we can anecdotally state that those who used computers less tended to complete tasks more slowly and found the user interface harder to navigate. The participants with medical experience did not appear to perform differently from the main population.</p></sec><sec><title>Time to Complete Level</title><p>The mean and SD of the time to complete each level are shown on the left-hand side of <xref rid="table2" ref-type="table">Table 2</xref>, along with 95% CIs for the mean.</p><table-wrap position="float" id="table2"><label>Table 2</label><caption><p>Mean (SD) and 95% CI for time and number of attempts to complete each level.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="200" span="1"/><col width="200" span="1"/><col width="200" span="1"/><col width="0" span="1"/><col width="200" span="1"/><col width="200" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Level</td><td colspan="3" rowspan="1">Participant time results (seconds)</td><td colspan="2" rowspan="1">Participant accuracy (attempts)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Mean (SD)</td><td rowspan="1" colspan="1">95% CI</td><td colspan="2" rowspan="1">Mean (SD)</td><td rowspan="1" colspan="1">95% CI</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">5.7 (3.6)</td><td rowspan="1" colspan="1">4.2-6.9</td><td colspan="2" rowspan="1">1.3 (2.0)</td><td rowspan="1" colspan="1">0.5-2.1</td></tr><tr valign="top"><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">3.3 (2.6)</td><td rowspan="1" colspan="1">2.2-4.4</td><td colspan="2" rowspan="1">1.2 (0.7)</td><td rowspan="1" colspan="1">0.9-1.5</td></tr><tr valign="top"><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">7.2 (2.8)</td><td rowspan="1" colspan="1">6.0-8.4</td><td colspan="2" rowspan="1">1.4 (1.1)</td><td rowspan="1" colspan="1">0.9-1.9</td></tr><tr valign="top"><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">6.4 (3.3)</td><td rowspan="1" colspan="1">5.0-7.8</td><td colspan="2" rowspan="1">1.6 (1.1)</td><td rowspan="1" colspan="1">1.2-2.0</td></tr><tr valign="top"><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">12.5 (5.7)</td><td rowspan="1" colspan="1">10.2-14.8</td><td colspan="2" rowspan="1">1.4 (0.7)</td><td rowspan="1" colspan="1">1.1-1.7</td></tr><tr valign="top"><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">9.8 (4.8)</td><td rowspan="1" colspan="1">7.8-11.8</td><td colspan="2" rowspan="1">1.8 (0.9)</td><td rowspan="1" colspan="1">1.4-2.2</td></tr><tr valign="top"><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">16.4 (11.0)</td><td rowspan="1" colspan="1">11.9-20.9</td><td colspan="2" rowspan="1">1.6 (1.2)</td><td rowspan="1" colspan="1">1.1-2.1</td></tr></tbody></table></table-wrap><p><xref rid="figure2" ref-type="fig">Figure 2</xref> presents a boxplot of level completion times alongside a brief description of each level&#x02019;s features. The figure shows a general trend of increasing completion time from left to right, corresponding with an increasing level of complexity. On average, level 2 was completed the fastest (in 3.3 seconds). This level featured 2 blood vessels displayed on the game interface without a restricted field of view. By contrast, level 7&#x02014;the most challenging level&#x02014;took the longest time to complete, with an average time of 16.4 seconds. This level featured 3 intertwined blood vessels following a complex path and was constrained by a limited field of view.</p><fig position="float" id="figure2"><label>Figure 2</label><caption><p>Box plot displaying the average time to complete each level. F.O.V.: field of view.</p></caption><graphic xlink:href="games_v13i1e56269_fig2" position="float"/></fig><p>While the general trend in <xref rid="figure2" ref-type="fig">Figure 2</xref> shows increasing completion times as level complexity increases, there are 2 exceptions when the field of view is restricted. Level 4 (with 2 blood vessels) had a shorter completion time than level 3 (which featured a single blood vessel and a limited field of view). Similarly, level 6 (with 3 intertwined blood vessels) was completed faster than level 5 (which had 2 intertwined blood vessels and a limited field of view). This suggests that a restricted field of view has a greater impact on performance than on other factors examined in this study. The effect of limiting the field of view can be estimated by comparing results from levels that were identical except for this restriction (ie, comparing level 4 with level 5 and level 6 with level 7).</p><p>We compared the completion times for levels 4 and 5 using a Welch 2-sample <italic>t</italic> test, which yielded a <italic>P</italic> value of &#x0003c;.001 indicating a statistically significant impact of limiting the field of view. The Cohen <italic>d</italic> effect size was 1.19, suggesting a large effect. A similar comparison between levels 6 and 7 produced a <italic>P</italic> value of .009 and an effect size of 0.79, further supporting the significant impact of a restricted field of view.</p></sec><sec><title>Accuracy</title><p>The number of attempts is displayed on the right-hand side of <xref rid="table2" ref-type="table">Table 2</xref>. A Welch 2-sample <italic>t</italic> test confirmed no significant differences in the number of attempts across levels (the minimum <italic>P</italic> value was .23 between levels 5 and 6). The numerical results and analysis scripts referenced above are archived along with the game code in [<xref rid="ref35" ref-type="bibr">35</xref>].</p></sec><sec><title>Participant Questionnaires</title><p>To assess participants&#x02019; prior knowledge, all participants were asked, &#x0201c;What do you know about laparoscopic surgery?&#x0201d; and &#x0201c;Do you know the potential effects of a limited field of view in laparoscopic surgery?&#x0201d; before playing the game. All 25 participants recognized that laparoscopy is a type of surgical procedure; however, their level of understanding varied significantly depending on their occupation and personal experiences. Participants from the researcher&#x02019;s student cohort were highly knowledgeable about this topic and understood both the advantages and limitations of this minimally invasive procedure. By contrast, participants from a nonmedical background had limited awareness of the benefits of laparoscopic surgery and the potential impact of a restricted field of view.</p><p>The results of the postgame questionnaire are shown in <xref rid="table3" ref-type="table">Table 3</xref>. The questionnaire was completed by 22 participants. Three participants commented on the game&#x02019;s background color, suggesting that a greater contrast between the background and blood vessels would improve visibility. Four participants stated that they enjoyed the game timer, as it heightened their competitiveness under time pressure. Two participants mentioned feeling frustrated due to their limited experience with a Mac laptop and its built-in mouse, which hindered their ability to complete levels quickly.</p><table-wrap position="float" id="table3"><label>Table 3</label><caption><p>Participant questionnaire results: percentage and absolute number of participants who answered yes when answering the questionnaire after completing the game.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="750" span="1"/><col width="250" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">Question</td><td rowspan="1" colspan="1">Yes, n/N (%)</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">Did playing this game enhance your understanding of the limited field of view in laparoscopic surgery?</td><td rowspan="1" colspan="1">20/22 (91)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Do you think this game is clinically relevant?</td><td rowspan="1" colspan="1">19/22 (86)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Do you think the difficulty increased with each level?</td><td rowspan="1" colspan="1">20/22 (91)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Did you find the game engaging?</td><td rowspan="1" colspan="1">22/22 (100)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Did you find the game layout visually pleasing?</td><td rowspan="1" colspan="1">22/22 (100)</td></tr></tbody></table></table-wrap><p>Participants also completed a NASA Task Load Index [<xref rid="ref39" ref-type="bibr">39</xref>] questionnaire, rating each workload demand on a scale of 1-10. For the questions related to demand (1-3, 5-6) a score of 1 is described as &#x0201c;very low&#x0201d; and a score of 10 as &#x0201c;very high.&#x0201d; For question 4, a score of 1 is &#x0201c;perfect&#x0201d; and 10 is &#x0201c;failure.&#x0201d; <xref rid="table4" ref-type="table">Table 4</xref> presents the average scores for the 6 workload demands. The results indicate that participants felt neutral about the mental demands required to complete the tasks in this serious game. Physical demand received the lowest rating, with an average score of 1.6, while performance workload was rated the highest. Effort workload scores varied significantly, with widely dispersed data resulting in a neutral average of 5.3. Participants rated their frustration levels relatively low, with an average score of 2.8.</p><p>Additionally, participants completed a System Usability Scale questionnaire [<xref rid="ref40" ref-type="bibr">40</xref>], the results of which are shown in <xref rid="table5" ref-type="table">Table 5</xref>.</p><table-wrap position="float" id="table4"><label>Table 4</label><caption><p>NASAa Task Load Index results: the average score out of 10 for each demand.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="750" span="1"/><col width="250" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">NASA Task Load Index</td><td rowspan="1" colspan="1">Mean score</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">Mental: How mentally demanding was the task?</td><td rowspan="1" colspan="1">4.9</td></tr><tr valign="top"><td rowspan="1" colspan="1">Physical: How physically demanding was the task?</td><td rowspan="1" colspan="1">1.6</td></tr><tr valign="top"><td rowspan="1" colspan="1">Temporal: How hurried or rushed was the pace of the task?</td><td rowspan="1" colspan="1">5.6</td></tr><tr valign="top"><td rowspan="1" colspan="1">Performance: How successful were you in accomplishing what you were asked to do?</td><td rowspan="1" colspan="1">7.7</td></tr><tr valign="top"><td rowspan="1" colspan="1">Effort: How hard did you have to work to accomplish your level of performance?</td><td rowspan="1" colspan="1">5.3</td></tr><tr valign="top"><td rowspan="1" colspan="1">Frustration: How insecure, discouraged, irritated, stressed, and annoyed were you?</td><td rowspan="1" colspan="1">2.8</td></tr></tbody></table><table-wrap-foot><fn id="table4fn1"><p><sup>a</sup>NASA: National Aeronautics and Space Administration.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="table5"><label>Table 5</label><caption><p>System Usability results: the average score out of 5 for each demand in the System Usability Scale.</p></caption><table frame="hsides" rules="groups" width="1000" cellpadding="5" cellspacing="0" border="1"><col width="750" span="1"/><col width="250" span="1"/><thead><tr valign="top"><td rowspan="1" colspan="1">System Usability Scale</td><td rowspan="1" colspan="1">Mean score</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">I think that I would like to use this system frequently</td><td rowspan="1" colspan="1">3.2</td></tr><tr valign="top"><td rowspan="1" colspan="1">I found the system unnecessarily complex</td><td rowspan="1" colspan="1">1.3</td></tr><tr valign="top"><td rowspan="1" colspan="1">I thought the system was easy to use</td><td rowspan="1" colspan="1">4.3</td></tr><tr valign="top"><td rowspan="1" colspan="1">I think that I would need the support of a technical person to be able to use this system</td><td rowspan="1" colspan="1">1.5</td></tr><tr valign="top"><td rowspan="1" colspan="1">I found that the various functions in this system were well integrated</td><td rowspan="1" colspan="1">3.8</td></tr><tr valign="top"><td rowspan="1" colspan="1">I thought there was too much inconsistency in this system</td><td rowspan="1" colspan="1">1.7</td></tr><tr valign="top"><td rowspan="1" colspan="1">I would imagine that most people would learn to use this system very quickly</td><td rowspan="1" colspan="1">4.6</td></tr><tr valign="top"><td rowspan="1" colspan="1">I found the system very cumbersome to use</td><td rowspan="1" colspan="1">1.6</td></tr><tr valign="top"><td rowspan="1" colspan="1">I felt very confident using the system</td><td rowspan="1" colspan="1">4.3</td></tr><tr valign="top"><td rowspan="1" colspan="1">I needed to learn a lot of things before I could get going with this system</td><td rowspan="1" colspan="1">1.2</td></tr></tbody></table></table-wrap></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Principal Findings</title><p>The qualitative results from participant questionnaires suggest that we have successfully created an engaging game that can facilitate discussions about the challenges of keyhole surgery with nontechnical audiences. The quantitative results, based on comparisons of level completion times, indicate that our game can provide valuable insights into the effects of a limited field of view on task performance.</p></sec><sec><title>Game Design</title><p>Our game design was a balance between creating an engaging experience by gradually increasing the difficulty of each level and enabling a paired comparison between different conditions. Our results indicate that we largely succeeded in both objectives. As shown in <xref rid="table3" ref-type="table">Table 3</xref>, all participants found the game engaging, and we observed a statistically significant difference in performance when the field of view was reduced (see <xref rid="figure2" ref-type="fig">Figure 2</xref>).</p><p>Randomizing the level structure might have resulted in a more robust test of our hypotheses but would likely have come at the expense of participant engagement. Maintaining a continuous flow state throughout the game was crucial, as the flow has a positive impact on learning and is strongly linked to user attention and focus. Research suggests that when a user&#x02019;s attention is directed toward a limited set of stimuli, irrelevant perceptions and distractions are minimized [<xref rid="ref41" ref-type="bibr">41</xref>]. Additionally, studies have demonstrated that sensory and cognitive curiosity increases when users find a game intrinsically interesting, thereby enhancing engagement [<xref rid="ref42" ref-type="bibr">42</xref>,<xref rid="ref43" ref-type="bibr">43</xref>]. Notably, all 22 participants who completed the questionnaire agreed that this serious game was engaging.</p><p>Three participants commented on the color contrast between the game background and blood vessels, suggesting that a greater difference in color would have helped them distinguish between the 2, especially in the harder levels. The low contrast between the background and blood vessels was an intentional design choice, as the illumination of the surgical scene is limited during laparoscopic surgery [<xref rid="ref15" ref-type="bibr">15</xref>].</p><p>Additionally, bodily fluids, such as blood, can further obscure the surgeon&#x02019;s view of the anatomical context. The game design aimed to replicate these challenges by maintaining low contrast, requiring players to focus and use precision to identify and cut the correct blood vessels. Future work could explore fine-tuning the display for different applications of the game.</p></sec><sec><title>Learning the Anatomy</title><p>There is evidence of a learning effect between levels 1 and 2, as level 2 was completed faster on average and with fewer attempts than level 1 (see <xref rid="table2" ref-type="table">Table 2</xref>). Observations of participants attempting level 1 indicated that they were initially unaware of the maximum line length they could draw with their mouse. It is likely that the lower average number of attempts in level 2 resulted from participants becoming aware of this game mechanic.</p><p>Levels with a more complex vessel pattern (levels 4 and 6) required more attempts than those where the pattern remained the same or had no intertwining (levels 2, 3, 5, and 7); however, these differences were not statistically significant. The finding that levels with a reduced field of view took longer to complete but did not require more attempts suggests that the mechanisms for mental mosaicking and learning the anatomy may be distinct processes.</p></sec><sec><title>Accessibility</title><p>This game was designed to be accessible to users of all abilities. The participant pool was diverse, with varying levels of knowledge and experience in laparoscopic surgery and web-based games. Participants ranged in age from 18 to 57 years, with 2 reporting dyslexia and 1 reporting dyspraxia. All 25 participants successfully completed all levels, suggesting that the game was accessible to them. However, no participants had color blindness or vision deficiencies. Given the low contrast between the game background and blood vessels and the fact that the correct blood vessels were identifiable only by black circles, it cannot be concluded that the game is accessible to users with visual impairments. Results from the NASA Task Load Index indicated varied effort workload scores, suggesting that some participants had limited experience using a laptop. As a result, the game may be less accessible to players with no prior laptop or gaming experience.</p></sec><sec><title>Limitations and Future Work</title><p>At present, the game presents a very simplified representation of the surgical environment. This simplification limits the game&#x02019;s direct relevance to surgery. The simplification was a deliberate decision to keep the game accessible to the widest possible user base; however, future work may require a more clinically realistic environment. Repeating the experiment with a sample of surgeons, controlling for specialty and expertise, will help validate our methodology of recruiting nonexpert participants. Bearing in mind the results of Yoo et al [<xref rid="ref18" ref-type="bibr">18</xref>], we still expect to see a correlation between the field of view and task completion time; however, we would not expect the results to be identical. Furthermore, the results would vary between levels of surgical experience and specialty. Surgeons would bring differing levels of prior knowledge that would alter game performance. Comparing the results between different user groups might yield useful information about the differences between trained surgeons and the general population.</p><p>The game&#x02019;s simplicity makes it impossible at present to fully understand the impact of learning effect on the results. The fact that the level pairs we used to compare between different field of view settings (4&#x0003c;&#x0003e;5 and 6&#x0003c;&#x0003e;7) were otherwise identical means that our results may underestimate the impact of reducing the field of view due to the participants learning from the preceding level. Future work could look at introducing more complex level progression to control for this.</p><p>To increase the clinical relevance of the game, the graphics and design could be changed to represent a more clinical environment. For example, it would be relatively easy to change the backdrop to a screenshot taken from a clinical procedure with vessels overlaid in more clinically realistic colors. Artifacts such as smoke and bleeding often seen in keyhole surgery could also be added, but would require significantly more programming work. It would then make interesting future work to compare the performance on this more realistic game between surgeons and nonsurgeons. We are also exploring ways to incorporate a negative scoring system to penalize mistakes, such as cutting the wrong blood vessel, and enable better analysis of how the field of view affects the errors made.</p><p>To investigate the impact of computational image mosaicking on task performance, additional levels will be required. At a basic level, users could use their mouse to &#x0201c;paint&#x0201d; on the scene, revealing the blood vessels underneath. This would create a larger field of view, simulating computational image mosaicking. As the game becomes more complicated, it is likely that the effect sizes will decrease, requiring a larger sample size to demonstrate statistical significance. A key advantage of our approach is its ability to support the recruitment of large numbers of participants.</p><p>Work is ongoing to improve scene management, making it easier for the user to move from one level to the next. Efforts are also underway to gather results using an automated database backend.</p></sec><sec><title>Conclusions</title><p>Our serious Blood Vessel Game was used to demonstrate a quantifiable effect of a limited field of view on task performance time, with the same task taking between 60% and 100% longer when the view was restricted. No effect on task accuracy was detected. Our results represent the first time this effect has been quantified in this way. The game also serves as an engaging educational tool for discussing the impact of a limited field of view on task performance, with 20 out of 22 (91%) participants agreeing that the game was educational and all (22/22, 100%) agreeing that it was engaging. The game is entirely open source, and we welcome contributions to enhance its usefulness.</p></sec></sec></body><back><ack><p>This work is supported by the Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS) (grant 203145Z/16/Z). No artificial intelligence tools were used in the preparation of this work.</p></ack><fn-group><fn fn-type="con"><p>Authors' Contributions: PW contributed to the conceptualization, formal analysis, investigation, software, visualization, and writing the original draft. CC contributed to writing reviews and editing. MJC contributed to conceptualization, funding acquisition, project administration, and supervision. ST contributed to conceptualization, investigation, project administration, software, supervision, and writing reviews and editing.</p></fn><fn fn-type="COI-statement"><p>Conflicts of Interest: None declared.</p></fn></fn-group><glossary><title>Abbreviations</title><def-list><def-item><term id="abb1">NASA</term><def><p>National Aeronautics and Space Administration</p></def></def-item></def-list></glossary><notes><sec sec-type="data-availability"><title>Data Availability</title><p>The game implementation and data used in this paper are freely available at [<xref rid="ref35" ref-type="bibr">35</xref>].</p></sec></notes><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayden</surname><given-names>P</given-names></name><name><surname>Cowman</surname><given-names>S</given-names></name></person-group><article-title>Anaesthesia for laparoscopic surgery</article-title><source>Continuing Education in Anaesthesia Critical Care &#x00026; Pain</source><year>2011</year><month>10</month><volume>11</volume><issue>5</issue><fpage>177</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1093/bjaceaccp/mkr027</pub-id></element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuoppala</surname><given-names>T</given-names></name><name><surname>Tom&#x000e1;s</surname><given-names>Eija</given-names></name><name><surname>Heinonen</surname><given-names>P</given-names></name></person-group><article-title>Clinical outcome and complications of laparoscopic surgery compared with traditional surgery in women with endometrial cancer</article-title><source>Arch Gynecol Obstet</source><year>2004</year><month>07</month><day>1</day><volume>270</volume><issue>1</issue><fpage>25</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1007/s00404-003-0488-7</pub-id><pub-id pub-id-type="medline">12728326</pub-id><pub-id pub-id-type="pmid">12728326</pub-id>
</element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rege</surname><given-names>RV</given-names></name><name><surname>Merriam</surname><given-names>LT</given-names></name><name><surname>Joehl</surname><given-names>RJ</given-names></name></person-group><article-title>LAPAROSCOPIC SPLENECTOMY</article-title><source>Surgical Clinics of North America</source><year>1996</year><month>6</month><volume>76</volume><issue>3</issue><fpage>459</fpage><lpage>468</lpage><pub-id pub-id-type="doi">10.1016/s0039-6109(05)70453-9</pub-id><pub-id pub-id-type="pmid">8669006</pub-id>
</element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walczak</surname><given-names>DA</given-names></name><name><surname>Pawe&#x00142;czak</surname><given-names>D</given-names></name><name><surname>Piotrowski</surname><given-names>P</given-names></name><name><surname>Trzeciak</surname><given-names>PW</given-names></name><name><surname>J&#x00119;drzejczyk</surname><given-names>A</given-names></name><name><surname>Pasieka</surname><given-names>Z</given-names></name></person-group><article-title>Video display during laparoscopy - where should it be placed?</article-title><source>Wideochir Inne Tech Maloinwazyjne</source><year>2015</year><month>04</month><volume>10</volume><issue>1</issue><fpage>87</fpage><lpage>91</lpage><comment>
<ext-link xlink:href="https://doi.org/10.5114/wiitm.2014.47434" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.5114/wiitm.2014.47434</pub-id><pub-id pub-id-type="medline">25960798</pub-id><pub-id pub-id-type="pii">24094</pub-id><!--<pub-id pub-id-type="pmcid">PMC4414093</pub-id>--><pub-id pub-id-type="pmid">25960798</pub-id>
</element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Watras</surname><given-names>A</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Zeng</surname><given-names>Z</given-names></name><name><surname>Greenberg</surname><given-names>J</given-names></name><name><surname>Heise</surname><given-names>C</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name></person-group><article-title>Large-field-of-view visualization utilizing multiple miniaturized cameras for laparoscopic surgery</article-title><source>Micromachines (Basel)</source><year>2018</year><month>08</month><day>25</day><volume>9</volume><issue>9</issue><fpage>431</fpage><pub-id pub-id-type="doi">10.3390/mi9090431</pub-id><pub-id pub-id-type="medline">30424364</pub-id><pub-id pub-id-type="pii">mi9090431</pub-id><!--<pub-id pub-id-type="pmcid">PMC6187494</pub-id>--><pub-id pub-id-type="pmid">30424364</pub-id>
</element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogdanova</surname><given-names>R</given-names></name><name><surname>Boulanger</surname><given-names>P</given-names></name><name><surname>Zheng</surname><given-names>B</given-names></name></person-group><article-title>Depth perception of surgeons in minimally invasive surgery</article-title><source>Surg Innov</source><year>2016</year><month>10</month><day>09</day><volume>23</volume><issue>5</issue><fpage>515</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1177/1553350616639141</pub-id><pub-id pub-id-type="medline">27009686</pub-id><pub-id pub-id-type="pii">1553350616639141</pub-id><pub-id pub-id-type="pmid">27009686</pub-id>
</element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sinha</surname><given-names>R</given-names></name><name><surname>Raje</surname><given-names>S</given-names></name><name><surname>Rao</surname><given-names>G</given-names></name></person-group><article-title>Three-dimensional laparoscopy: Principles and practice</article-title><source>J Min Access Surg</source><year>2017</year><volume>13</volume><issue>3</issue><fpage>165</fpage><pub-id pub-id-type="doi">10.4103/0972-9941.181761</pub-id></element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Xin</surname><given-names>H</given-names></name><name><surname>Zelek</surname><given-names>J. S.</given-names></name><name><surname>Carnahan</surname><given-names>H</given-names></name></person-group><article-title>Laparoscopic surgery, perceptual limitations and force: a review</article-title><source>First Canadian Student Conference on Biomedical Computing</source><year>2006</year><conf-name>Queen&#x02019;s University Kingston</conf-name><conf-date>September 28, 2006</conf-date><conf-loc>Kingston, ON, Canada</conf-loc></element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname><given-names>Y</given-names></name><name><surname>Hua</surname><given-names>H</given-names></name></person-group><article-title>Optical design and system engineering of a multiresolution foveated laparoscope</article-title><source>Appl Opt</source><year>2016</year><month>04</month><day>08</day><volume>55</volume><issue>11</issue><fpage>3058</fpage><pub-id pub-id-type="doi">10.1364/ao.55.003058</pub-id><pub-id pub-id-type="pmid">27139875</pub-id>
</element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tendick</surname><given-names>F</given-names></name><name><surname>Jennings</surname><given-names>RW</given-names></name><name><surname>Tharp</surname><given-names>G</given-names></name><name><surname>Stark</surname><given-names>L</given-names></name></person-group><article-title>Sensing and Manipulation Problems in Endoscopic Surgery: Experiment, Analysis, and Observation</article-title><source>Presence: Teleoperators &#x00026; Virtual Environments</source><year>1993</year><month>01</month><volume>2</volume><issue>1</issue><fpage>66</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1162/pres.1993.2.1.66</pub-id></element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>B</given-names></name><name><surname>Mobasheri</surname><given-names>M</given-names></name></person-group><article-title>Principles of safe laparoscopic surgery</article-title><source>Surgery (Oxford)</source><year>2017</year><month>04</month><volume>35</volume><issue>4</issue><fpage>216</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.mpsur.2017.01.010</pub-id></element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watras</surname><given-names>AJ</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Ke</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Greenberg</surname><given-names>JA</given-names></name><name><surname>Heise</surname><given-names>CP</given-names></name><name><surname>Hu</surname><given-names>YH</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name></person-group><article-title>Large-Field-of-View Visualization with Small Blind Spots Utilizing Tilted Micro-Camera Array for Laparoscopic Surgery</article-title><source>Micromachines</source><year>2020</year><month>05</month><day>10</day><volume>11</volume><issue>5</issue><fpage>488</fpage><pub-id pub-id-type="doi">10.3390/mi11050488</pub-id><pub-id pub-id-type="pmid">32397580</pub-id>
</element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Mazomenos</surname><given-names>E</given-names></name><name><surname>Chandler</surname><given-names>JH</given-names></name><name><surname>Obstein</surname><given-names>KL</given-names></name><name><surname>Valdastri</surname><given-names>P</given-names></name><name><surname>Stoyanov</surname><given-names>D</given-names></name><name><surname>Vasconcelos</surname><given-names>F</given-names></name></person-group><article-title>Robust endoscopic image mosaicking via fusion of multimodal estimation</article-title><source>Med Image Anal</source><year>2023</year><month>02</month><volume>84</volume><fpage>102709</fpage><comment>
<ext-link xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(22)00337-1" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1016/j.media.2022.102709</pub-id><pub-id pub-id-type="medline">36549045</pub-id><pub-id pub-id-type="pii">S1361-8415(22)00337-1</pub-id><!--<pub-id pub-id-type="pmcid">PMC10636739</pub-id>--><pub-id pub-id-type="pmid">36549045</pub-id>
</element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Daga</surname><given-names>P</given-names></name><name><surname>Chadebecq</surname><given-names>F</given-names></name><name><surname>Shakir</surname><given-names>D. I.</given-names></name><name><surname>Herrera</surname><given-names>L.C.G.P.</given-names></name><name><surname>Tella</surname><given-names>M</given-names></name><name><surname>Dwyer</surname><given-names>G</given-names></name><name><surname>David</surname><given-names>A.L.</given-names></name><name><surname>Deprest,</surname><given-names>J.</given-names></name><name><surname>Stoyanov</surname><given-names>D.</given-names></name><name><surname>Vercauteren</surname><given-names>T</given-names></name></person-group><article-title>Real-time mosaicing of fetoscopic videos using sift</article-title><year>2016</year><month>3</month><day>18</day><conf-name>SPIE Medical Imaging</conf-name><conf-date>March 18, 2016</conf-date><conf-loc>San Diego, CA</conf-loc><fpage>533</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1117/12.2217172</pub-id></element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pandey</surname><given-names>A</given-names></name><name><surname>Pati</surname><given-names>UC</given-names></name></person-group><article-title>Image mosaicing: a deeper insight</article-title><source>Image and Vision Computing</source><year>2019</year><month>09</month><volume>89</volume><fpage>236</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1016/j.imavis.2019.07.002</pub-id></element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergen</surname><given-names>T</given-names></name><name><surname>Wittenberg</surname><given-names>T</given-names></name></person-group><article-title>Stitching and surface reconstruction from endoscopic image sequences: a review of applications and methods</article-title><source>IEEE J Biomed Health Inform</source><year>2016</year><month>1</month><volume>20</volume><issue>1</issue><fpage>304</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1109/jbhi.2014.2384134</pub-id><pub-id pub-id-type="pmid">25532214</pub-id>
</element-citation></ref><ref id="ref17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ten Dam</surname><given-names>Ellen</given-names></name><name><surname>Helder</surname><given-names>HM</given-names></name><name><surname>van der Laan</surname><given-names>BFAM</given-names></name><name><surname>Feijen</surname><given-names>RA</given-names></name><name><surname>Korsten-Meijer</surname><given-names>Astrid G W</given-names></name></person-group><article-title>The effect of three-dimensional visualisation on performance in endoscopic sinus&#x000a0;surgery: a clinical training study using surgical navigation for movement analysis in a randomised crossover design</article-title><source>Clin Otolaryngol</source><year>2020</year><month>03</month><day>27</day><volume>45</volume><issue>2</issue><fpage>211</fpage><lpage>220</lpage><comment>
<ext-link xlink:href="https://europepmc.org/abstract/MED/31846558" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1111/coa.13494</pub-id><pub-id pub-id-type="medline">31846558</pub-id><!--<pub-id pub-id-type="pmcid">PMC7027512</pub-id>--><pub-id pub-id-type="pmid">31846558</pub-id>
</element-citation></ref><ref id="ref18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname><given-names>S</given-names></name><name><surname>Ramalhinho</surname><given-names>J</given-names></name><name><surname>Dowrick</surname><given-names>T</given-names></name><name><surname>Somasundaram</surname><given-names>M</given-names></name><name><surname>Gurusamy</surname><given-names>K</given-names></name><name><surname>Davidson</surname><given-names>B</given-names></name><name><surname>Clarkson</surname><given-names>MJ</given-names></name><name><surname>Blandford</surname><given-names>A</given-names></name></person-group><article-title>Can engineers represent surgeons in usability studies? Comparison of results from evaluating augmented reality guidance for laparoscopic surgery</article-title><source>Computers &#x00026; Graphics</source><year>2024</year><month>04</month><volume>119</volume><fpage>103881</fpage><pub-id pub-id-type="doi">10.1016/j.cag.2024.01.008</pub-id></element-citation></ref><ref id="ref19"><label>19</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Christoph</surname><given-names>D</given-names></name><name><surname>Soojeong</surname><given-names>Y</given-names></name><name><surname>Matthew</surname><given-names>M.J.</given-names></name><name><surname>Thompson</surname><given-names>S</given-names></name></person-group><article-title>Enhanced surgeons: understanding the design of augmented reality instructions for keyhole surgery</article-title><year>2023</year><conf-name>IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</conf-name><conf-date>March 25-29, 2023</conf-date><conf-loc>Shanghai, China</conf-loc><fpage>123</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1109/vrw58643.2023.00031</pub-id></element-citation></ref><ref id="ref20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khouna</surname><given-names>J</given-names></name><name><surname>Ajana</surname><given-names>L</given-names></name><name><surname>Rhazal</surname><given-names>A</given-names></name><name><surname>El Mokri</surname><given-names>A</given-names></name></person-group><article-title>The use of educational software in teaching physics in the Moroccan context</article-title><source>Int J Emerg Technol Learn</source><year>2020</year><month>09</month><day>25</day><volume>15</volume><issue>18</issue><fpage>270</fpage><pub-id pub-id-type="doi">10.3991/ijet.v15i18.15455</pub-id></element-citation></ref><ref id="ref21"><label>21</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>J</given-names></name></person-group><article-title>Designing immersive serious games</article-title><source>PhD thesis, University of Southampton</source><year>2017</year><month>06</month><day>01</day><date-in-citation content-type="access-date">2025-02-03</date-in-citation><comment>
<ext-link xlink:href="https://eprints.soton.ac.uk/419472/1/JB_ThesisFinal.pdf" ext-link-type="uri">https://eprints.soton.ac.uk/419472/1/JB_ThesisFinal.pdf</ext-link>
</comment></element-citation></ref><ref id="ref22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorbanev</surname><given-names>I</given-names></name><name><surname>Agudelo-Londo&#x000f1;o</surname><given-names>Sandra</given-names></name><name><surname>Gonz&#x000e1;lez</surname><given-names>Rafael A</given-names></name><name><surname>Cortes</surname><given-names>A</given-names></name><name><surname>Pomares</surname><given-names>A</given-names></name><name><surname>Delgadillo</surname><given-names>V</given-names></name><name><surname>Yepes</surname><given-names>FJ</given-names></name><name><surname>Mu&#x000f1;oz</surname><given-names>&#x000d3;scar</given-names></name></person-group><article-title>A systematic review of serious games in medical education: quality of evidence and pedagogical strategy</article-title><source>Med Educ Online</source><year>2018</year><month>12</month><day>19</day><volume>23</volume><issue>1</issue><fpage>1438718</fpage><comment>
<ext-link xlink:href="https://www.tandfonline.com/doi/10.1080/10872981.2018.1438718?url_ver=Z39.88-2003&#x00026;rfr_id=ori:rid:crossref.org&#x00026;rfr_dat=cr_pub0pubmed" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1080/10872981.2018.1438718</pub-id><pub-id pub-id-type="medline">29457760</pub-id><!--<pub-id pub-id-type="pmcid">PMC5827764</pub-id>--><pub-id pub-id-type="pmid">29457760</pub-id>
</element-citation></ref><ref id="ref23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olgers</surname><given-names>TJ</given-names></name><name><surname>Bij de Weg</surname><given-names>AA</given-names></name><name><surname>Ter Maaten</surname><given-names>JC</given-names></name></person-group><article-title>Serious games for improving technical skills in medicine: scoping review</article-title><source>JMIR Serious Games</source><year>2021</year><month>01</month><day>25</day><volume>9</volume><issue>1</issue><fpage>e24093</fpage><comment>
<ext-link xlink:href="https://games.jmir.org/2021/1/e24093/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/24093</pub-id><pub-id pub-id-type="medline">33492234</pub-id><pub-id pub-id-type="pii">v9i1e24093</pub-id><!--<pub-id pub-id-type="pmcid">PMC7870348</pub-id>--><pub-id pub-id-type="pmid">33492234</pub-id>
</element-citation></ref><ref id="ref24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellotti</surname><given-names>F</given-names></name><name><surname>Kapralos</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Moreno-Ger</surname><given-names>P</given-names></name><name><surname>Berta</surname><given-names>R</given-names></name></person-group><article-title>Assessment in and of serious games: an overview</article-title><source>Advances in Human-Computer Interaction</source><year>2013</year><volume>2013</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1155/2013/136864</pub-id></element-citation></ref><ref id="ref25"><label>25</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Martins</surname><given-names>T</given-names></name><name><surname>Carvalho</surname><given-names>V</given-names></name><name><surname>Soares</surname><given-names>F</given-names></name><name><surname>Moreira</surname><given-names>MF</given-names></name></person-group><article-title>Serious game as a tool to intellectual disabilities therapy: total challenge</article-title><year>2011</year><conf-name>IEEE 1st International Conference on Serious Games and Applications for Health (SeGAH)</conf-name><conf-date>November 16-18, 2011</conf-date><conf-loc>Braga, Portugal</conf-loc><publisher-loc>New York, NY</publisher-loc><publisher-name>IEEE</publisher-name><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1109/segah.2011.6165444</pub-id></element-citation></ref><ref id="ref26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jalink</surname><given-names>MB</given-names></name><name><surname>Heineman</surname><given-names>E</given-names></name><name><surname>Pierie</surname><given-names>JPEN</given-names></name><name><surname>ten Cate Hoedemaker</surname><given-names>H O</given-names></name></person-group><article-title>The effect of a preoperative warm-up with a custom-made Nintendo video game on the performance of laparoscopic surgeons</article-title><source>Surg Endosc</source><year>2015</year><month>08</month><volume>29</volume><issue>8</issue><fpage>2284</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1007/s00464-014-3943-6</pub-id><pub-id pub-id-type="medline">25361658</pub-id><pub-id pub-id-type="pmid">25361658</pub-id>
</element-citation></ref><ref id="ref27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>IJgosse</surname><given-names>W</given-names></name><name><surname>van Goor</surname><given-names>H</given-names></name><name><surname>Rosman</surname><given-names>C</given-names></name><name><surname>Luursema</surname><given-names>J</given-names></name></person-group><article-title>Construct validity of a serious game for laparoscopic skills training: validation study</article-title><source>JMIR Serious Games</source><year>2020</year><month>05</month><day>07</day><volume>8</volume><issue>2</issue><fpage>e17222</fpage><comment>
<ext-link xlink:href="https://games.jmir.org/2020/2/e17222/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/17222</pub-id><pub-id pub-id-type="medline">32379051</pub-id><pub-id pub-id-type="pii">v8i2e17222</pub-id><!--<pub-id pub-id-type="pmcid">PMC7243133</pub-id>--><pub-id pub-id-type="pmid">32379051</pub-id>
</element-citation></ref><ref id="ref28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosser</surname><given-names>JC</given-names></name><name><surname>Lynch</surname><given-names>Paul J</given-names></name><name><surname>Cuddihy</surname><given-names>Laurie</given-names></name><name><surname>Gentile</surname><given-names>Douglas A</given-names></name><name><surname>Klonsky</surname><given-names>Jonathan</given-names></name><name><surname>Merrell</surname><given-names>Ronald</given-names></name></person-group><article-title>The impact of video games on training surgeons in the 21st century</article-title><source>Arch Surg</source><year>2007</year><month>02</month><day>01</day><volume>142</volume><issue>2</issue><fpage>181</fpage><lpage>6; discusssion 186</lpage><pub-id pub-id-type="doi">10.1001/archsurg.142.2.181</pub-id><pub-id pub-id-type="medline">17309970</pub-id><pub-id pub-id-type="pii">142/2/181</pub-id><pub-id pub-id-type="pmid">17309970</pub-id>
</element-citation></ref><ref id="ref29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ou</surname><given-names>Y</given-names></name><name><surname>McGlone</surname><given-names>ER</given-names></name><name><surname>Camm</surname><given-names>CF</given-names></name><name><surname>Khan</surname><given-names>OA</given-names></name></person-group><article-title>Does playing video games improve laparoscopic skills?</article-title><source>International Journal of Surgery</source><year>2013</year><month>06</month><volume>11</volume><issue>5</issue><fpage>365</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1016/j.ijsu.2013.02.020</pub-id><pub-id pub-id-type="pmid">23467109</pub-id>
</element-citation></ref><ref id="ref30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graafland</surname><given-names>M</given-names></name><name><surname>Schraagen</surname><given-names>JM</given-names></name><name><surname>Schijven</surname><given-names>MP</given-names></name></person-group><article-title>Systematic review of serious games for medical education and surgical skills training</article-title><source>Br J Surg</source><year>2012</year><month>10</month><volume>99</volume><issue>10</issue><fpage>1322</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1002/bjs.8819</pub-id><pub-id pub-id-type="medline">22961509</pub-id><pub-id pub-id-type="pmid">22961509</pub-id>
</element-citation></ref><ref id="ref31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackburne</surname><given-names>T</given-names></name><name><surname>Rodriguez</surname><given-names>A</given-names></name><name><surname>Johnstone</surname><given-names>SJ</given-names></name></person-group><article-title>A serious game to increase healthy food consumption in overweight or obese adults: randomized controlled trial</article-title><source>JMIR Serious Games</source><year>2016</year><month>07</month><day>13</day><volume>4</volume><issue>2</issue><fpage>e10</fpage><comment>
<ext-link xlink:href="https://games.jmir.org/2016/2/e10/" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.2196/games.5708</pub-id><pub-id pub-id-type="medline">27417192</pub-id><pub-id pub-id-type="pii">v4i2e10</pub-id><!--<pub-id pub-id-type="pmcid">PMC4963607</pub-id>--><pub-id pub-id-type="pmid">27417192</pub-id>
</element-citation></ref><ref id="ref32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiili</surname><given-names>K</given-names></name></person-group><article-title>Digital game-based learning: Towards an experiential gaming model</article-title><source>The Internet and Higher Education</source><year>2005</year><month>1</month><volume>8</volume><issue>1</issue><fpage>13</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.iheduc.2004.12.001</pub-id></element-citation></ref><ref id="ref33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fairclough</surname><given-names>SH</given-names></name><name><surname>Gilleade</surname><given-names>K</given-names></name><name><surname>Ewing</surname><given-names>KC</given-names></name><name><surname>Roberts</surname><given-names>J</given-names></name></person-group><article-title>Capturing user engagement via psychophysiology: measures and mechanisms for biocybernetic adaptation</article-title><source>IJAACS</source><year>2013</year><volume>6</volume><issue>1</issue><fpage>63</fpage><pub-id pub-id-type="doi">10.1504/ijaacs.2013.050694</pub-id></element-citation></ref><ref id="ref34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jolicoeur</surname><given-names>P</given-names></name><name><surname>Ullman</surname><given-names>S</given-names></name><name><surname>Mackay</surname><given-names>M</given-names></name></person-group><article-title>Curve tracing: a possible basic operation in the perception of spatial relations</article-title><source>Mem Cognit</source><year>1986</year><month>03</month><volume>14</volume><issue>2</issue><fpage>129</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.3758/bf03198373</pub-id><pub-id pub-id-type="medline">3724444</pub-id></element-citation></ref><ref id="ref35"><label>35</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Whitley</surname><given-names>P</given-names></name><name><surname>Clarkson</surname><given-names>MJ</given-names></name><name><surname>Thompson</surname><given-names>S</given-names></name></person-group><article-title>Blood vessel game</article-title><source>Zenodo</source><date-in-citation content-type="access-date">2025-02-03</date-in-citation><comment>
<ext-link xlink:href="https://zenodo.org/records/10489683" ext-link-type="uri">https://zenodo.org/records/10489683</ext-link>
</comment></element-citation></ref><ref id="ref36"><label>36</label><element-citation publication-type="webpage"><article-title>Blood vessel game</article-title><source>GitHub</source><date-in-citation content-type="access-date">2025-02-05</date-in-citation><comment>
<ext-link xlink:href="https://scikit-surgery.github.io/Blood-Vessel-Game/" ext-link-type="uri">https://scikit-surgery.github.io/Blood-Vessel-Game/</ext-link>
</comment></element-citation></ref><ref id="ref37"><label>37</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>Phaser Developers</collab></person-group><article-title>Phaser Computer software</article-title><source>https://github.com/phaserjs/phaser</source><date-in-citation content-type="access-date">2025-02-03</date-in-citation><comment>
<ext-link xlink:href="https://github.com/phaserjs/phaser" ext-link-type="uri">https://github.com/phaserjs/phaser</ext-link>
</comment></element-citation></ref><ref id="ref38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreira</surname><given-names>RAF</given-names></name><name><surname>Assun&#x000e7;&#x000e3;o</surname><given-names>WKG</given-names></name><name><surname>Martinez</surname><given-names>J</given-names></name><name><surname>Figueiredo</surname><given-names>E</given-names></name></person-group><article-title>Open-source software product line extraction processes: the ArgoUML-SPL and Phaser cases</article-title><source>Empir Software Eng</source><year>2022</year><month>04</month><day>08</day><volume>27</volume><issue>4</issue><fpage>1</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1007/s10664-021-10104-3</pub-id></element-citation></ref><ref id="ref39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hart</surname><given-names>SG</given-names></name></person-group><article-title>Nasa-Task Load Index (NASA-TLX); 20 years later</article-title><source>Proceedings of the Human Factors and Ergonomics Society Annual Meeting</source><year>2006</year><month>10</month><day>01</day><volume>50</volume><issue>9</issue><fpage>904</fpage><lpage>908</lpage><comment>
<ext-link xlink:href="http://pro.sagepub.com/content/50/9/904.full.pdf+html" ext-link-type="uri"/>
</comment><pub-id pub-id-type="doi">10.1177/154193120605000909</pub-id></element-citation></ref><ref id="ref40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>JR</given-names></name></person-group><article-title>The System Usability Scale: past, present, and future</article-title><source>International Journal of Human&#x02013;Computer Interaction</source><year>2018</year><month>03</month><day>30</day><volume>34</volume><issue>7</issue><fpage>577</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1080/10447318.2018.1455307</pub-id></element-citation></ref><ref id="ref41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Webster</surname><given-names>J</given-names></name><name><surname>Trevino</surname><given-names>LK</given-names></name><name><surname>Ryan</surname><given-names>L</given-names></name></person-group><article-title>The dimensionality and correlates of flow in human-computer interactions</article-title><source>Computers in Human Behavior</source><year>1993</year><month>12</month><volume>9</volume><issue>4</issue><fpage>411</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1016/0747-5632(93)90032-N</pub-id></element-citation></ref><ref id="ref42"><label>42</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Csikszentmihalyi</surname><given-names>M</given-names></name></person-group><source>Beyond Boredom and Anxiety</source><year>2000</year><publisher-loc>Hoboken, NJ</publisher-loc><publisher-name>Jossey-Bass</publisher-name></element-citation></ref><ref id="ref43"><label>43</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Mazomenos</surname><given-names>E</given-names></name><name><surname>Chandler</surname><given-names>JH</given-names></name><name><surname>Obstein</surname><given-names>KL</given-names></name><name><surname>Valdastri</surname><given-names>P</given-names></name><name><surname>Stoyanov</surname><given-names>D</given-names></name><name><surname>Vasconcelos</surname><given-names>F</given-names></name></person-group><article-title>Robust endoscopic image mosaicking via fusion of multimodal estimation</article-title><source>Med Image Anal</source><year>2023</year><month>02</month><volume>84</volume><fpage>102709</fpage><pub-id pub-id-type="doi">10.1016/j.media.2022.102709</pub-id><pub-id pub-id-type="medline">36549045</pub-id><pub-id pub-id-type="pii">S1361-8415(22)00337-1</pub-id><!--<pub-id pub-id-type="pmcid">PMC10636739</pub-id>--><pub-id pub-id-type="pmid">36549045</pub-id>
</element-citation></ref></ref-list></back></article>