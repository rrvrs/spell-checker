<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Oral Health</journal-id><journal-id journal-id-type="iso-abbrev">Front Oral Health</journal-id><journal-id journal-id-type="publisher-id">Front. Oral. Health</journal-id><journal-title-group><journal-title>Frontiers in Oral Health</journal-title></journal-title-group><issn pub-type="epub">2673-4842</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40013098</article-id><article-id pub-id-type="pmc">PMC11860867</article-id><article-id pub-id-type="doi">10.3389/froh.2025.1541976</article-id><article-categories><subj-group subj-group-type="heading"><subject>Oral Health</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Evaluating ChatGPT-4's performance on oral and maxillofacial queries: Chain of Thought and standard method</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Ji</surname><given-names>Kaiyuan</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="an1" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2916944/overview"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Wu</surname><given-names>Zhihan</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="an1" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2954037/overview"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Han</surname><given-names>Jing</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2966194/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Zhai</surname><given-names>Guangtao</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref><xref rid="cor1" ref-type="corresp">*</xref><uri xlink:href="https://loop.frontiersin.org/people/843249/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Liu</surname><given-names>Jiannan</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="cor1" ref-type="corresp">*</xref><uri xlink:href="https://loop.frontiersin.org/people/2081482/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff id="aff1"><label><sup>1</sup></label><institution>School of Communication and Electronic Engineering, East China Normal University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff><aff id="aff2"><label><sup>2</sup></label><institution>Department of Oral and Maxillofacial Head and Neck Oncology, Shanghai Ninth People&#x02019;s Hospital, Shanghai Jiao Tong University School of Medicine</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff><aff id="aff3"><label><sup>3</sup></label><institution>School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University</institution>, <addr-line>Shanghai</addr-line>, <country>China</country></aff><author-notes><fn fn-type="edited-by"><p><bold>Edited by:</bold> Leandro Napier Souza, Federal University of Minas Gerais, Brazil</p></fn><fn fn-type="edited-by"><p><bold>Reviewed by:</bold> Khalid Almas, Imam Abdulrahman Bin Faisal University, Saudi Arabia</p><p>Zhi-Cheng Li, Chinese Academy of Sciences (CAS), China</p><p>Fa-yu Liu, China Medical University, China</p></fn><corresp id="cor1"><label>*</label><bold>Correspondence:</bold> Guangtao Zhai <email>zhaiguangtao@sjtu.edu.cn</email> Jiannan Liu <email>laurence_ljn@163.com</email></corresp><fn fn-type="equal" id="an1"><label>
<sup>&#x02020;</sup>
</label><p>These authors have contributed equally to this work</p></fn></author-notes><pub-date pub-type="epub"><day>12</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>6</volume><elocation-id>1541976</elocation-id><history><date date-type="received"><day>09</day><month>12</month><year>2024</year></date><date date-type="accepted"><day>28</day><month>1</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 Ji, Wu, Han, Zhai and Liu.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Ji, Wu, Han, Zhai and Liu</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License (CC BY)</ext-link>. The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><sec><title>Objectives</title><p>Oral and maxillofacial diseases affect approximately 3.5 billion people worldwide. With the continuous advancement of Artificial Intelligence technologies, particularly the application of generative pre-trained transformers like ChatGPT-4, there is potential to enhance public awareness of the prevention and early detection of these diseases. This study evaluated the performance of ChatGPT-4 in addressing oral and maxillofacial disease questions using standard approaches and the Chain of Thought (CoT) method, aiming to gain a deeper understanding of its capabilities, potential, and limitations.</p></sec><sec><title>Materials and methods</title><p>Three experts, drawing from their extensive experience and the most common questions in clinical settings, selected 130 open-ended questions and 1,805 multiple-choice questions from the national dental licensing examination. These questions encompass 12 areas of oral and maxillofacial surgery, including Prosthodontics, Pediatric Dentistry, Maxillofacial Tumors and Salivary Gland Diseases, and maxillofacial Infections.</p></sec><sec><title>Results</title><p>Using CoT approach, ChatGPT-4 exhibited marked enhancements in accuracy, structure, completeness, professionalism, and overall impression for open-ended questions, revealing statistically significant differences compared to its performance on general oral and maxillofacial inquiries. In the realm of multiple-choice questions, the application of CoT method boosted ChatGPT-4's accuracy across all major subjects, achieving an overall accuracy increase of 3.1%.</p></sec><sec><title>Conclusions</title><p>When employing ChatGPT-4 to address questions in oral and maxillofacial surgery, incorporating CoT as a querying method can enhance its performance and help the public improve their understanding and awareness of such issues. However, it is not advisable to consider it a substitute for doctors.</p></sec></abstract><kwd-group><kwd>Artificial Intelligence</kwd><kwd>Chain of Thought</kwd><kwd>education tool</kwd><kwd>ChatGPT-4</kwd><kwd>oral and maxillofacial</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">National Natural Science Foundation of China</funding-source><award-id award-type="contract" rid="cn001">62322114</award-id></award-group><award-group><funding-source id="cn002">Fundamental Research Funds for the Central Universities, China</funding-source><award-id award-type="contract" rid="cn002">YG2023LC06</award-id></award-group></funding-group><funding-group><funding-statement>The author(s) declare financial support was received for the research, authorship, and/or publication of this article. This research was supported by the National Natural Science Foundation of China (NSFC, grant No. 62322114); and the Fundamental Research Funds for the Central Universities, China (No. YG2023LC06). The funders participated in the study design, data collection, data analysis, data interpretation, manuscript preparation, and the decision to submit the article for publication.</funding-statement></funding-group><counts><fig-count count="4"/><table-count count="2"/><equation-count count="0"/><ref-count count="32"/><page-count count="10"/><word-count count="0"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Oral and Maxillofacial Surgery</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="s1"><label>1</label><title>Introduction</title><p>Oral and maxillofacial diseases are the most widespread health conditions, according to the World Health Organization's 2022 Global Oral Health Status report, oral and maxillofacial diseases have impacted approximately 3.5 billion&#x02014;almost half of the world's population (45%) people in the world (<xref rid="B1" ref-type="bibr">1</xref>&#x02013;<xref rid="B4" ref-type="bibr">4</xref>). Oral and maxillofacial diseases can also lead to pain, discomfort, mental problems, respiratory health problems and even death in extreme consequences (<xref rid="B5" ref-type="bibr">5</xref>, <xref rid="B6" ref-type="bibr">6</xref>). The &#x0201c;three early&#x0201d; principle&#x02014;early prevention, early diagnosis, and early treatment is the key to reduce the incidence and improve the possibility of curing oral and maxillofacial diseases.</p><p>Traditionally, the prevention and diagnosis of oral and maxillofacial diseases all rely on the judgment and expertise of dentists. However, due to the complex progress of oral and maxillofacial diseases, detecting and diagnosing diseases quickly and accurately is challenging for the dentists (<xref rid="B7" ref-type="bibr">7</xref>). In recent years, the substantial development in Artificial Intelligence (AI) are expected to bring a turning point in the field of oral and maxillofacial surgery (<xref rid="B8" ref-type="bibr">8</xref>, <xref rid="B9" ref-type="bibr">9</xref>). Significant progress has been made in Generative Artificial Intelligence (GenAI) and large language models (LLMs) (<xref rid="B10" ref-type="bibr">10</xref>, <xref rid="B11" ref-type="bibr">11</xref>). With the rapid development of GenAI and LLMs, it is increasingly utilized in oral and maxillofacial surgery for various applications, such as improving workflow, detecting diseases, predicting treatment outcomes, and creating personalized patient-centered plans (<xref rid="B12" ref-type="bibr">12</xref>, <xref rid="B13" ref-type="bibr">13</xref>). AI helps dentists by providing more predictable diagnosis and treatment outcomes. Recent studies have assessed the performance of conversational AI models such as ChatGPT in addressing queries related to oral and maxillofacial surgery (<xref rid="B14" ref-type="bibr">14</xref>&#x02013;<xref rid="B18" ref-type="bibr">18</xref>).</p><p>As LLMs continue to evolve, research focused on enhancing their performance with minimal cost has gained popularity. Methods such as prompts, which avoid the need for retraining, have emerged as effective solutions. One such method, the Chain of Thought (CoT), acts as a form of prompting by guiding LLMs to analyze problems methodically and deliver well-reasoned answers, thereby elevating the quality of responses. This approach not only enhances the consistency of LLM responses to the same query but also streamlines their thought process.</p><p>Developed by OpenAI in San Francisco, CA, United States, ChatGPT exemplifies an LLM that harnesses both supervised learning and reinforcement learning to generate responses that mimic human conversation (<xref rid="B19" ref-type="bibr">19</xref>). Utilizing CoT with ChatGPT can significantly refine its response and reasoning capabilities (<xref rid="B20" ref-type="bibr">20</xref>). This implies that integrating CoT with LLMs could enhance their potential to address certain medical issues and clinical diagnoses more effectively. As an accessible tool, it also has the potential to enhance public awareness and prevention of such diseases. However, the effectiveness of CoT in improving responses to oral and maxillofacial queries has yet to be evaluated.</p><p>In this article, we conducted a study aimed at evaluating the differences in the quality of information provided by ChatGPT-4 when responding to oral and maxillofacial inquiries using the CoT method compared to the standard response mode. By contrasting these two approaches, we explored the performance, limitations, and potential educational value of ChatGPT-4 in the field of oral and maxillofacial surgery.</p></sec><sec sec-type="methods" id="s2"><label>2</label><title>Materials and methods</title><sec id="s2a"><label>2.1</label><title>Research design</title><p>Globally, interest in oral and maxillofacial education has progressively garnered more attention from the academic community over time (<xref rid="B21" ref-type="bibr">21</xref>). Research has shown that studies from both China and the United States exert substantial influence in the field of stomatology, confirming that their research adheres to international standards (<xref rid="B22" ref-type="bibr">22</xref>). Responses from ChatGPT-4 to oral and maxillofacial issues prevalent in China could establish benchmarks for evaluating its proficiency within the oral and maxillofacial domain. The questions for this study were selected by three experienced experts from the national dental licensing examination and common clinical inquiries from patients concerning oral and maxillofacial diseases. The inquiries were divided into multiple-choice and open-ended formats, comprehensively addressing various facets of the oral and maxillofacial domain, including Prosthodontics, Endodontics, Periodontology, Oral mucosal diseases, Pediatric Dentistry, Preventive Oral Medicine, Maxillofacial Surgery and Anesthesia, Maxillofacial Infections and Trauma, Maxillofacial Tumors and Salivary Gland Diseases, Temporomandibular and Maxillofacial Nerve Disorders, Congenital and Acquired Maxillofacial Deformities, and Dental and Alveolar Surgery. We collected a dataset from January to February 2024, comprising 130 open-ended questions and 1805 multiple-choice questions. Each of the multiple-choice questions has one correct reference answer, while the open-ended questions do not. These questions were administered to ChatGPT-4 over the period from March 1 to March 27, 2024.</p><p>The research was structured into two distinct phases, focusing on the evaluation of open-ended and multiple-choice questions. Each type of question was addressed through two methodologies: direct submission of the question in Chinese for ChatGPT-4's response, and submission in Chinese accompanied by a CoT to aid ChatGPT-4 in crafting a comprehensive answer. <xref rid="F1" ref-type="fig">Figure&#x000a0;1</xref> illustrates the assessment workflow implemented in this research.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p>A screenshot depicts the research design flow of this study, where multiple-choice and open-ended questions are asked using standard and CoT methods respectively, and evaluated through different approaches.</p></caption><graphic xlink:href="froh-06-1541976-g001" position="float"/></fig><p>In the sections that follow, the study refers to the method of questioning ChatGPT-4 using a CoT format as &#x0201c;ChatGPT-4 with CoT.&#x0201d; Conversely, when inquiries are posed directly to ChatGPT-4 without the addition of any prompt words, this approach is referred to simply as &#x0201c;ChatGPT-4.&#x0201d; The method of providing direct input without any CoT is referred to as the &#x0201c;standard method&#x0201d;. This terminological distinction is crucial for clarity in both the methodological descriptions and subsequent analyses.</p></sec><sec id="s2b"><label>2.2</label><title>CoT design for open-ended questions</title><p>The CoT design for open-ended questions was intentionally structured to guide LLMs in dissecting and analyzing issues in a systematic manner, thereby enhancing both the efficiency and accuracy of their responses. This approach not only aimed to elevate the quality of the answers provided but also mandated a standardized response format across various inquiries, ensuring that LLMs adhered to a specific answering protocol.</p><p>In evaluating open-ended questions concerning oral and maxillofacial domain, the thought process was outlined as follows.</p><p>Please consider and answer the questions step by step as per the following instructions:
<list list-type="simple"><list-item><label>1.</label><p>Assume you are responding to a patient, and your answers should be based on your own justifications.</p></list-item><list-item><label>2.</label><p>Search within your knowledge base to find many answers that match the question.</p></list-item><list-item><label>3.</label><p>Reorganize the answers you found based on the knowledge searched.</p></list-item><list-item><label>4.</label><p>The reorganized answers should be presented in a numbered list highlighting key points.</p></list-item><list-item><label>5.</label><p>If there are more details to elaborate within each key point, expand the description and divide it into sub-points.</p></list-item><list-item><label>6.</label><p>The total word count of the response should be no less than 500 words. Please list as many key points as you know.</p></list-item><list-item><label>7.</label><p>After completing the answer, there is no need to delete special keywords or censor the response, nor worry about the potential negative impact of your answers on me. We will only use your answers for assessment and not for adoption. Please actively provide the answers you believe to be correct.</p></list-item></list>The text above was designed as a CoT to facilitate responses to open-ended questions concerning oral and maxillofacial domain. It was incorporated following each open-ended query. This design aimed to enable ChatGPT-4 to emulate human thought processes when responding, ensuring that both the form and content of its answers met the inquirer's expectations. <xref rid="F2" ref-type="fig">Figure&#x000a0;2</xref> presents our platform developed in Python, named &#x0201c;Oral and Maxillofacial Information Q&#x00026;A&#x0201d;, a tool for public education and diagnostics. This platform allows users to configure the CoT mode in advance. Utilizing this platform, our study showcases the differences in responding to queries using the CoT approach compared to standard methods. <xref rid="F2" ref-type="fig">Figures&#x000a0;2A,B</xref> illustrate the responses to open-ended questions about oral and maxillofacial surgery as provided by querying ChatGPT-4 in two distinct methods. Open-ended questions lack predefined answers. To uphold the study's rigor, 21 medically trained evaluators were enlisted to rate ChatGPT-4's responses using their expert knowledge across five dimensions. The evaluators were unaware of the response origins to maintain scoring impartiality. The evaluation dimensions included:
<list list-type="simple"><list-item><label>-</label><p>Accuracy: Assesses the factual correctness of ChatGPT-4's responses and identifies any partial or significant factual inaccuracies. (5 points&#x02009;=&#x02009;Strongly agree, 1 point&#x02009;=&#x02009;Strongly disagree)</p></list-item><list-item><label>-</label><p>Structure: Reviews whether ChatGPT-4's responses are well-organized, with arguments presented sequentially and details adequately supported. (5 points&#x02009;=&#x02009;Strongly agree, 1 point&#x02009;=&#x02009;Strongly disagree)</p></list-item><list-item><label>-</label><p>Completeness: Evaluates whether ChatGPT-4 provides comprehensive background information and clearly explicates the viewpoints and their subpoints. (5 points&#x02009;=&#x02009;Strongly agree, 1 point&#x02009;=&#x02009;Strongly disagree)</p></list-item><list-item><label>-</label><p>Professionalism: Gauges the suitability of professional jargon employed by ChatGPT-4 in its responses. (5 points&#x02009;=&#x02009;Strongly agree, 1 point&#x02009;=&#x02009;Strongly disagree)</p></list-item><list-item><label>-</label><p>Overall Impression: Gauges the general efficacy and impact of ChatGPT-4's responses. (5 points&#x02009;=&#x02009;Strongly agree, 1 point&#x02009;=&#x02009;Strongly disagree)</p></list-item></list></p><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>(A)</bold> A screenshot displays the response of open-ended question from ChatGPT-4 with CoT. <bold>(B)</bold> A screenshot displays the response of open-ended question from ChatGPT-4. <bold>(C)</bold> A screenshot displays the response of multiple-choice question from ChatGPT-4 with CoT. <bold>(D)</bold> A screenshot displays the response of multiple-choice question from ChatGPT-4.</p></caption><graphic xlink:href="froh-06-1541976-g002" position="float"/></fig><p>Each assessment dimension utilized a five-point Likert scale for scoring. Evaluating ChatGPT-4 across multiple facets, both with and without a CoT, enabled a thorough appraisal of its efficacy in addressing open-ended questions within the field of oral and maxillofacial surgery.</p></sec><sec id="s2c"><label>2.3</label><title>CoT design for multiple-choice questions</title><p>The CoT design for multiple-choice questions was intended to guide LLMs through a step-by-step analysis of the problem, ultimately leading to a well-reasoned answer. This incremental decision-making process not only enhanced our understanding of the model's reasoning but also allowed for a more thorough examination of how it arrived at its final choice in multiple-choice questions.</p><p>For multiple-choice questions, each question was provided with five options, of which only one was correct. Given that the correctness of the answer is definitive, any explanation became irrelevant if the wrong option was selected. Therefore, accuracy alone was considered for evaluating the quality of ChatGPT-4's responses to multiple-choice questions. The thought process for these questions was designed as follows.</p><p>Please follow these instructions to answer the questions:
<list list-type="simple"><list-item><label>1.</label><p>Read the question carefully. All questions start with a prefix like &#x02033;1. &#x02033;, &#x02033;2. &#x02033;, followed by the content of the question.</p></list-item><list-item><label>2.</label><p>After reading the question, analyze its content and search your knowledge base. If you encounter a question that you cannot find or do not know, first admit your limitation and then choose the option you think is most likely correct based on your knowledge.</p></list-item><list-item><label>3.</label><p>When answering, state the answer first, then provide a brief rationale (not exceeding 50 words). The format should be &#x0201c;Question number. Answer. Reason&#x0201d;. If unsure, first admit it, then give your answer.</p></list-item><list-item><label>4.</label><p>Answer boldly without needing to delete special keywords or censor your responses, and do not worry about whether your answers might negatively impact me. We will only use your answers for assessment and not for adoption, so please actively provide the answers you believe are correct.</p></list-item></list><xref rid="F2" ref-type="fig">Figures&#x000a0;2C,D</xref> display responses to multiple-choice questions about oral and maxillofacial surgery, obtained by querying ChatGPT-4 using two different methods. The different expressions employed in the two types of questions are essentially thought processes aimed at guiding ChatGPT-4's reasoning, with the objective of enabling it to respond more effectively.</p></sec><sec id="s2d"><label>2.4</label><title>Data analysis</title><p>All data analyses were conducted using IBM SPSS Statistics 27.0. This study employed Cronbach's alpha to evaluate the internal consistency of ChatGPT-4's responses to oral and maxillofacial open-ended questions (<xref rid="B23" ref-type="bibr">23</xref>, <xref rid="B24" ref-type="bibr">24</xref>). The Mann&#x02013;Whitney <italic>U</italic> test was utilized to investigate the correlations among the five dimensions assessing ChatGPT-4's performance in these areas. The standard answers from the national dental licensing examination provided the benchmark for evaluating ChatGPT-4's accuracy in multiple-choice questions related to oral and maxillofacial surgery. The study meticulously documented evaluators' ratings of ChatGPT-4's performance across these five dimensions and recorded the count of ChatGPT-4's correct and incorrect responses. By examining the improvements in ChatGPT-4's responses pre and post the introduction of a structured thought process guide, the study highlighted specific enhancements in the application of ChatGPT-4 to oral and maxillofacial queries. All tests were conducted at a significance level of 0.05, with values below this threshold indicating statistically significant differences.</p></sec></sec><sec sec-type="results" id="s3"><label>3</label><title>Results</title><sec id="s3a"><label>3.1</label><title>Internal consistency of evaluation results</title><p>In the results section, this paper presents a comparative analysis of ChatGPT-4's performance with and without the integration of CoT in addressing oral and maxillofacial questions. Initially, we assessed the internal consistency of responses from 21 researchers using both configurations. We employed a detailed methodological framework where ChatGPT-4 was augmented with CoT by prompting it to explicitly delineate its reasoning process before delivering the final answer. This approach aimed to enhance the model's problem-solving capabilities. To evaluate the performance, we devised a set of five criteria: accuracy, completeness, structure, professionalism, and overall impression in the responses. As indicated in <xref rid="T1" ref-type="table">Table&#x000a0;1</xref>, all Cronbach's alpha coefficients for these criteria exceeded 0.7, suggesting robust internal consistency across different evaluative dimensions (<xref rid="B20" ref-type="bibr">23</xref>&#x02013;<xref rid="B22" ref-type="bibr">25</xref>). The chatbot's responses to oral and maxillofacial issues are detailed in the <xref rid="s10" ref-type="sec">Supplementary Materials</xref> provided.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Evaluation of the Cronbach's alpha for all groups.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="center" span="1"/></colgroup><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Answer source</th><th valign="top" align="left" rowspan="1" colspan="1">Evaluation group</th><th valign="top" align="center" rowspan="1" colspan="1">Cronbach's alpha</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="left" rowspan="1" colspan="1">Accuracy</td><td valign="top" align="center" rowspan="1" colspan="1">0.939</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="left" rowspan="1" colspan="1">Completeness</td><td valign="top" align="center" rowspan="1" colspan="1">0.979</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="left" rowspan="1" colspan="1">Structure</td><td valign="top" align="center" rowspan="1" colspan="1">0.966</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="left" rowspan="1" colspan="1">Professionalism</td><td valign="top" align="center" rowspan="1" colspan="1">0.982</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="left" rowspan="1" colspan="1">Overall impression</td><td valign="top" align="center" rowspan="1" colspan="1">0.888</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="left" rowspan="1" colspan="1">Accuracy</td><td valign="top" align="center" rowspan="1" colspan="1">0.988</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="left" rowspan="1" colspan="1">Completeness</td><td valign="top" align="center" rowspan="1" colspan="1">0.992</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="left" rowspan="1" colspan="1">Structure</td><td valign="top" align="center" rowspan="1" colspan="1">0.991</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="left" rowspan="1" colspan="1">Professionalism</td><td valign="top" align="center" rowspan="1" colspan="1">0.991</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="left" rowspan="1" colspan="1">Overall impression</td><td valign="top" align="center" rowspan="1" colspan="1">0.901</td></tr></tbody></table><table-wrap-foot><fn id="table-fn1"><p>ChatGPT-4 with CoT, provide input to ChatGPT-4 utilizing the CoT methodology; ChatGPT-4, provide direct input to ChatGPT-4.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3b"><label>3.2</label><title>Open-ended questions</title><p>This study assessed the performance differences between ChatGPT-4 with CoT and ChatGPT-4 without CoT using open-ended oral and maxillofacial questions across various response quality dimensions. The evaluation metrics included Interquartile Range (IQR), median, and the 75th percentile, along with accuracy on multiple-choice questions. These results detailed in <xref rid="T2" ref-type="table">Table&#x000a0;2</xref>.</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Performance evaluation of ChatGPT-4 and ChatGPT-4 with CoT.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Evaluation criteria</th><th valign="top" align="left" rowspan="1" colspan="1">Approach</th><th valign="top" align="center" rowspan="1" colspan="1">Q1</th><th valign="top" align="center" rowspan="1" colspan="1">Q2</th><th valign="top" align="center" rowspan="1" colspan="1">Q3</th><th valign="top" align="center" rowspan="1" colspan="1">IQR</th><th valign="top" align="center" rowspan="1" colspan="1"><italic>P</italic> value</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="2" colspan="1">Accuracy</td><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="2" colspan="1">&#x0003c;0.001<xref rid="table-fn3" ref-type="table-fn">*</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">2</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Completeness</td><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="2" colspan="1">&#x0003c;0.001<xref rid="table-fn3" ref-type="table-fn">*</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">1</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Structure</td><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="2" colspan="1">&#x0003c;0.001<xref rid="table-fn3" ref-type="table-fn">*</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">2</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Professionalism</td><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="2" colspan="1">&#x0003c;0.001<xref rid="table-fn3" ref-type="table-fn">*</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">2</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Overall Impression</td><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4 with CoT</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">1</td><td valign="top" align="center" rowspan="2" colspan="1">&#x0003c;0.001<xref rid="table-fn3" ref-type="table-fn">*</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">ChatGPT-4</td><td valign="top" align="center" rowspan="1" colspan="1">3</td><td valign="top" align="center" rowspan="1" colspan="1">4</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">2</td></tr></tbody></table><table-wrap-foot><fn id="table-fn2"><p>ChatGPT-4 with CoT, provide input to ChatGPT-4 utilizing the CoT methodology; ChatGPT-4, provide direct input to ChatGPT-4.</p></fn><fn id="table-fn3"><label>*</label><p>Statistical significance by Mann&#x02013;Whitney <italic>U</italic> test (<italic>P</italic>&#x02009;<italic>&#x0003c;</italic>&#x02009;0.001).</p></fn></table-wrap-foot></table-wrap><p>In terms of accuracy, ChatGPT-4 with CoT showed a 25th percentile score of 4, advancing to 5 in the 75th percentile, indicating superior performance with an IQR of 1. In contrast, ChatGPT-4 without CoT reached a 25th percentile score of 3 and with an IQR of 2, suggesting greater score fluctuation and somewhat inferior accuracy in answering open-ended questions. The statistical significance of this improvement was confirmed with a <italic>p</italic>-value of less than 0.001 (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p><p>While both approaches exhibit identical IQR for response completeness, the median score for ChatGPT-4 with CoT is 5, indicating that the completeness of responses for maxillofacial surgery questions by ChatGPT-4 with CoT is more highly recognized by evaluators. In contrast, ChatGPT-4 demonstrates lower completeness, with a statistically significant difference observed between the two conditions (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). These findings suggest that incorporating CoT could enhance the performance of ChatGPT-4 to a notable degree.</p><p>Focusing on structural dimensions, analysis of the two methods reveals consistent median values. Nevertheless, a greater variance is observed in ChatGPT-4's performance, coupled with a statistically significant difference (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). This variance underscores the efficacy of a well-implemented CoT in facilitating more structured and coherent outputs from ChatGPT-4. In contrast, while responses from ChatGPT-4 without CoT maintain a basic level of structural integrity, the randomness and inconsistencies in response structure may impede the reader's ability to discern critical information.</p><p>In the dimension of professionalism, ChatGPT-4 with CoT showed higher consistency with an IQR of 1, scoring from 4 to 5. ChatGPT-4 without CoT, while achieving the same peak, exhibited greater variability with an IQR of 2. The Mann&#x02013;Whitney <italic>U</italic> test indicated a statistically significant difference between the two methods. Responses from ChatGPT-4 with CoT appeared relatively more professional and, to some extent, closer to medical knowledge.</p><p>The overall impression metrics corroborate these findings. ChatGPT-4 with CoT maintains higher consistency and peak scores, as evidenced by a uniform IQR of 1 and a <italic>p</italic> value of less than 0.001 (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) across all dimensions. This is in stark contrast to ChatGPT-4.</p><p>As illustrated in <xref rid="F3" ref-type="fig">Figure&#x000a0;3A</xref>, ChatGPT-4 with CoT demonstrates superior performance across all evaluated aspects compared to ChatGPT-4 without CoT. Furthermore, <xref rid="F3" ref-type="fig">Figure&#x000a0;3B</xref> reveals that ChatGPT-4 with CoT achieves a higher frequency of scores of 5 in all five evaluation dimensions.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>(A)</bold> Radar chart displaying average scores across evaluation metrics for ChatChatGPT-4 and ChatChatGPT-4 with CoT. <bold>(B)</bold> Frequency distribution of scores for ChatGPT-4with CoT and ChatGPT-4 across five metrics.</p></caption><graphic xlink:href="froh-06-1541976-g003" position="float"/></fig><p>These results underscore the enhanced performance of ChatGPT-4 with CoT, particularly in terms of consistency and superior outcomes across all assessed metrics.</p></sec><sec id="s3c"><label>3.3</label><title>Multiple-choice questions</title><p>This study comprised 1,805 multiple-choice questions, each with five options. To evaluate ChatGPT-4's performance in the field of oral and maxillofacial surgery, the questions were initially categorized into 12 major topics. <xref rid="F4" ref-type="fig">Figure&#x000a0;4</xref> illustrates the comparative accuracy performance of ChatGPT-4 and ChatGPT-4 with CoT in multiple-choice questions related to oral and maxillofacial topics.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p>Comparative accuracy performance of ChatGPT-4 and ChatGPT-4 with CoT in oral and maxillofacial multiple-choice questions. &#x0201c;<italic>N</italic>&#x0201d; represents the number of questions.</p></caption><graphic xlink:href="froh-06-1541976-g004" position="float"/></fig><p>The figure demonstrates that ChatGPT-4 with CoT consistently achieved higher accuracy across all topics compared to ChatGPT-4. This suggests that a well-structured CoT design enhanced the ChatGPT-4's accuracy in addressing questions related to oral and maxillofacial surgery.</p><p>By emulating the reasoning process inherent in problem-solving, this technique assists in structuring and elucidating the model's responses more efficaciously. Additionally, this approach provides insights into the cognitive processes of large language models, illustrating how they mimic human reasoning to formulate specific responses. Such insights are critical for augmenting the interpretability and dependability of these models.</p></sec></sec><sec sec-type="discussion" id="s4"><label>4</label><title>Discussion</title><p>As the development of large multimodal AI models progresses, an increasing number of researchers are focusing on the evolution of these large models and their applications in real life (<xref rid="B26" ref-type="bibr">26</xref>, <xref rid="B27" ref-type="bibr">27</xref>). They are highly likely to have a significant effect on several different aspects of the medical and dental fields (<xref rid="B28" ref-type="bibr">28</xref>&#x02013;<xref rid="B30" ref-type="bibr">30</xref>). Consequently, the question of how to employ large models in the medical field and enhance their performance through various methods has gradually become a popular research topic (<xref rid="B13" ref-type="bibr">13</xref>, <xref rid="B31" ref-type="bibr">31</xref>, <xref rid="B32" ref-type="bibr">32</xref>).</p><p>In this study, we investigated the performance of ChatGPT-4 in answering different types of questions by incorporating the CoT questioning method. Our study aimed to explore how CoT affected the quality of responses generated by ChatGPT-4. To evaluate the impact of CoT, we compared ChatGPT-4's responses to these questions using standard questioning and CoT questioning methods.</p><p>The results from the Mann&#x02013;Whitney <italic>U</italic> test, as delineated in <xref rid="T2" ref-type="table">Table&#x000a0;2</xref>, reveal significant differences between ChatGPT-4 employing CoT processing and the standard version of ChatGPT-4, across multiple evaluative dimensions including accuracy, completeness, structure, professionalism, and overall impression in response to open-ended oral and maxillofacial questions. Furthermore, <xref rid="F3" ref-type="fig">Figure&#x000a0;3B</xref> illustrates a higher frequency of maximum scores (score of 5) achieved by ChatGPT-4 with CoT across these dimensions compared to its standard counterpart. These findings underscore the enhancement in performance conferred by CoT, facilitating superior response quality and aligning more closely with user expectations in this specialized domain.</p><p>In the case of multiple-choice questions, ChatGPT-4 scored 60.78% with standard questioning, while CoT questioning resulted in an accuracy of 63.88%, marking an improvement of 3.1%.The national dental licensing examination in China requires an accuracy rate of over 60%, positioning ChatGPT-4 at the passing threshold. Incorporating CoT helps ChatGPT-4 meet this requirement more smoothly. This suggests that different CoT strategies can guide ChatGPT-4 to think more actively, particularly in the context of dental health-related multiple-choice questions, thus improving response accuracy. Future research can further refine these strategies to enhance ChatGPT-4's performance across various domains (<xref rid="B33" ref-type="bibr">33</xref>, <xref rid="B34" ref-type="bibr">34</xref>).</p><p>As seen from <xref rid="F3" ref-type="fig">Figure&#x000a0;3B</xref>, although the introduction of the CoT mechanism in ChatGPT-4 shows higher performance in terms of the frequency of scores of five across all dimensions compared to the standard method, the frequency of scores of four remains not less than 40%, and the accuracy in multiple-choice questions is only slightly above the passing mark (3.88%).This indicates that, while CoT enhances the model's capability in responding to open-ended questions, it still exhibits limitations, particularly in handling multiple-choice questions where its performance reaches just a basic level. Therefore, utilizing CoT-enhanced ChatGPT-4 for science communication and education holds significant potential, especially in the field of oral and maxillofacial medicine. This approach not only increases public awareness of preventative knowledge in oral and maxillofacial medicine but also serves as a convenient tool for disseminating knowledge in this area. However, due to the nature and limitations of its responses, this chatbot cannot replace clinical doctors and should be regarded as a supplement to professional medical advice.</p><p>This study has several limitations. Firstly, it focuses exclusively on ChatGPT-4's performance on open-ended and multiple-choice questions, without evaluating its capabilities on other types of questions. Secondly, the study examines ChatGPT-4's performance solely on common oral and maxillofacial issues in China, without testing its performance in other countries (<xref rid="B35" ref-type="bibr">35</xref>, <xref rid="B36" ref-type="bibr">36</xref>).</p></sec><sec sec-type="conclusions" id="s5"><label>5</label><title>Conclusion</title><p>This study explores the application of the CoT methodology in enhancing the ability of ChatGPT-4 to answer open-ended and multiple-choice questions. In the realm of open-ended queries, the introduction of CoT to ChatGPT-4 demonstrated statistically significant differences across five dimensions when compared to the original version of ChatGPT-4, with superior composite performance in these dimensions. Additionally, for multiple-choice questions, the overall accuracy of ChatGPT-4 employing CoT improved by 3.1%. These enhancements indicate that CoT facilitates a deeper thought process, enabling ChatGPT-4 to handle inquiries more effectively and provide more satisfactory recommendations. By integrating CoT with ChatGPT-4, not only is the model's performance enhanced, but its responses can also serve as educational resources to improve the public's understanding and awareness of oral and maxillofacial diseases, thus holding significant educational value. Furthermore, CoT helps demystify the &#x0201c;black box&#x0201d; nature of large language models to an extent. However, it must be emphasized that while AI can support oral and maxillofacial education, it does not replace the expertise and judgment of healthcare professionals. Therefore, integrating AI should complement, rather than substitute, the profound knowledge of medical experts.</p></sec></body><back><ack><title>Acknowledgments</title><p>During the completion of this research, we would like to express our gratitude to Shanghai Jiao Tong University and Shanghai Ninth People's Hospital for providing the materials and support.</p></ack><sec sec-type="data-availability" id="s6"><title>Data availability statement</title><p>The original contributions presented in the study are included in the article/<xref rid="s10" ref-type="sec">Supplementary Material</xref>, further inquiries can be directed to the corresponding authors.</p></sec><sec sec-type="ethics-statement" id="s14"><title>Ethics statement</title><p>This study was conducted in accordance with the Declaration of Helsinki and did not require approval from an ethics committee. The privacy of participants' data was upheld throughout the study. As the study did not utilize patient data and clinicians voluntarily participated, the institutional review board exempted it from the need for ethical review and approval.</p></sec><sec sec-type="author-contributions" id="s7"><title>Author contributions</title><p>KJ: Data curation, Investigation, Methodology, Visualization, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. ZW: Data curation, Investigation, Methodology, Visualization, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. JH: Conceptualization, Data curation, Formal Analysis, Methodology, Resources, Writing &#x02013; review &#x00026; editing. GZ: Conceptualization, Methodology, Project administration, Writing &#x02013; review &#x00026; editing. JL: Conceptualization, Funding acquisition, Investigation, Project administration, Writing &#x02013; review &#x00026; editing.</p></sec><sec sec-type="COI-statement" id="s9"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type="ai-statement" id="s12"><title>Generative AI statement</title><p>The author(s) declare that no Generative AI was used in the creation of this manuscript.</p></sec><sec sec-type="disclaimer" id="s11"><title>Publisher's note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><sec sec-type="supplementary-material" id="s10"><title>Supplementary material</title><p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/froh.2025.1541976/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/froh.2025.1541976/full#supplementary-material</ext-link></p><supplementary-material id="SD1" position="float" content-type="local-data"><media xlink:href="Table1.docx" id="d100e878" position="anchor"/></supplementary-material></sec><ref-list><title>References</title><ref id="B1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ali</surname><given-names>K</given-names></name><name><surname>Barhom</surname><given-names>N</given-names></name><name><surname>Tamimi</surname><given-names>F</given-names></name><name><surname>Duggal</surname><given-names>M</given-names></name></person-group>. <article-title>ChatGPT&#x02014;a double-edged sword for healthcare education? Implications for assessments of dental students</article-title>. <source>Eur J Dent Educ</source>. (<year>2024</year>) <volume>28</volume>(<issue>1</issue>):<fpage>206</fpage>&#x02013;<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1111/eje.12937</pub-id><pub-id pub-id-type="pmid">37550893</pub-id>
</mixed-citation></ref><ref id="B2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balel</surname><given-names>Y</given-names></name></person-group>. <article-title>Can ChatGPT be used in oral and maxillofacial surgery?</article-title>
<source>J Stomatol Oral Maxillofac Surg</source>. (<year>2023</year>) <volume>124</volume>(<issue>5</issue>):<fpage>101471</fpage>. <pub-id pub-id-type="doi">10.1016/j.jormas.2023.101471</pub-id><pub-id pub-id-type="pmid">37061037</pub-id>
</mixed-citation></ref><ref id="B3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benzian</surname><given-names>H</given-names></name><name><surname>Watt</surname><given-names>R</given-names></name><name><surname>Makino</surname><given-names>Y</given-names></name><name><surname>Stauf</surname><given-names>N</given-names></name><name><surname>Varenne</surname><given-names>B</given-names></name></person-group>. <article-title>WHO calls to end the global crisis of oral health</article-title>. <source>Lancet</source>. (<year>2022</year>) <volume>400</volume>(<issue>10367</issue>):<fpage>1909</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1016/S0140-6736(22)02322-4</pub-id><pub-id pub-id-type="pmid">36410360</pub-id>
</mixed-citation></ref><ref id="B4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>CM</given-names></name><name><surname>Chu</surname><given-names>CH</given-names></name><name><surname>Duangthip</surname><given-names>D</given-names></name><name><surname>Ettinger</surname><given-names>RL</given-names></name><name><surname>Hugo</surname><given-names>FN</given-names></name><name><surname>Kettratad-Pruksapong</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>Global perspectives of oral health policies and oral healthcare schemes for older adult populations</article-title>. <source>Front Oral Health</source>. (<year>2021</year>) <volume>2</volume>:<fpage>703526</fpage>. <pub-id pub-id-type="doi">10.3389/froh.2021.703526</pub-id><pub-id pub-id-type="pmid">35048040</pub-id>
</mixed-citation></ref><ref id="B5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bland</surname><given-names>JM</given-names></name></person-group>. <article-title>Statistics notes: Cronbach&#x02019;s alpha</article-title>. <source>Br Med J</source>. (<year>1997</year>) <volume>314</volume>:<fpage>572</fpage>. <pub-id pub-id-type="doi">10.1136/bmj.314.7080.572</pub-id><pub-id pub-id-type="pmid">9055718</pub-id>
</mixed-citation></ref><ref id="B6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cascella</surname><given-names>M</given-names></name><name><surname>Montomoli</surname><given-names>J</given-names></name><name><surname>Bellini</surname><given-names>V</given-names></name><name><surname>Bignami</surname><given-names>E</given-names></name></person-group>. <article-title>Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios</article-title>. <source>J Med Syst</source>. (<year>2023</year>) <volume>47</volume>(<issue>1</issue>):<fpage>33</fpage>. <pub-id pub-id-type="doi">10.1007/s10916-023-01925-4</pub-id><pub-id pub-id-type="pmid">36869927</pub-id>
</mixed-citation></ref><ref id="B7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chau</surname><given-names>RCW</given-names></name><name><surname>Thu</surname><given-names>KM</given-names></name><name><surname>Yu</surname><given-names>OY</given-names></name><name><surname>Hsung</surname><given-names>RT-C</given-names></name><name><surname>Lo</surname><given-names>ECM</given-names></name><name><surname>Lam</surname><given-names>WYH</given-names></name></person-group>. <article-title>Performance of generative artificial intelligence in dental licensing examinations</article-title>. <source>Int Dent J</source>. (<year>2024</year>) <volume>74</volume>(<issue>3</issue>):<fpage>616</fpage>&#x02013;<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1016/j.identj.2023.12.007</pub-id><pub-id pub-id-type="pmid">38242810</pub-id>
</mixed-citation></ref><ref id="B8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>W</given-names></name></person-group>. <article-title>Assessment of the capacity of ChatGPT as a self-learning tool in medical pharmacology: a study using MCQs</article-title>. <source>BMC Med Educ</source>. (<year>2023</year>) <volume>23</volume>(<issue>1</issue>):<fpage>864</fpage>. <pub-id pub-id-type="doi">10.1186/s12909-023-04832-x</pub-id><pub-id pub-id-type="pmid">37957666</pub-id>
</mixed-citation></ref><ref id="B9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajinikanth</surname><given-names>SB</given-names></name><name><surname>Rajkumar</surname><given-names>DSR</given-names></name><name><surname>Rajinikanth</surname><given-names>A</given-names></name><name><surname>Anandhapandian</surname><given-names>PA</given-names></name></person-group>. <article-title>An overview of artificial intelligence based automated diagnosis in paediatric dentistry</article-title>. <source>Front Oral Health</source>. (<year>2024</year>) <volume>5</volume>:<fpage>1482334</fpage>. <pub-id pub-id-type="doi">10.3389/froh.2024.1482334</pub-id><pub-id pub-id-type="pmid">39777218</pub-id>
</mixed-citation></ref><ref id="B10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cronbach</surname><given-names>LJ</given-names></name></person-group>. <article-title>Coefficient alpha and the internal structure of tests</article-title>. <source>Psychometrika</source>. (<year>1951</year>) <volume>16</volume>(<issue>3</issue>):<fpage>297</fpage>&#x02013;<lpage>334</lpage>. <pub-id pub-id-type="doi">10.1007/BF02310555</pub-id></mixed-citation></ref><ref id="B11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guarnizo-Herre&#x000f1;o</surname><given-names>CC</given-names></name><name><surname>Celeste</surname><given-names>RK</given-names></name><name><surname>Peres</surname><given-names>MA</given-names></name></person-group>. <article-title>The ongoing fight for population oral health</article-title>. <source>Lancet</source>. (<year>2024</year>) <volume>404</volume>(<issue>10453</issue>):<fpage>635</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/S0140-6736(24)00536-1</pub-id><pub-id pub-id-type="pmid">38518794</pub-id>
</mixed-citation></ref><ref id="B12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>A</given-names></name><name><surname>Saleena</surname><given-names>LM</given-names></name><name><surname>Kannan</surname><given-names>P</given-names></name><name><surname>Shivachandran</surname><given-names>A</given-names></name></person-group>. <article-title>The impact of oral diseases on respiratory health and the influence of respiratory infections on the oral microbiome</article-title>. <source>J Dent</source>. (<year>2024</year>) <volume>148</volume>:<fpage>105213</fpage>. <pub-id pub-id-type="doi">10.1016/j.jdent.2024.105213</pub-id><pub-id pub-id-type="pmid">38936454</pub-id>
</mixed-citation></ref><ref id="B13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>M</given-names></name><name><surname>Ribeiro</surname><given-names>AP</given-names></name><name><surname>Drew</surname><given-names>TM</given-names></name><name><surname>Pereira</surname><given-names>PN</given-names></name></person-group>. <article-title>Generative AI use in dental education: efficient exam item writing</article-title>. <source>J Dent Educ</source>. (<year>2023</year>) <volume>87</volume>:<fpage>1865</fpage>&#x02013;<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1002/jdd.13294</pub-id><pub-id pub-id-type="pmid">37354022</pub-id>
</mixed-citation></ref><ref id="B14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name></person-group>. <article-title>The rise of ChatGPT: exploring its potential in medical education</article-title>. <source>Anat Sci Educ</source>. (<year>2024</year>) <volume>17</volume>(<issue>5</issue>):<fpage>926</fpage>&#x02013;<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1002/ase.2270</pub-id><pub-id pub-id-type="pmid">36916887</pub-id>
</mixed-citation></ref><ref id="B15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Tang</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Liao</surname><given-names>G</given-names></name><name><surname>Zheng</surname><given-names>L</given-names></name></person-group>. <article-title>Global bibliometric mapping of dental development research for the period 2012&#x02013;2021</article-title>. <source>Int J Paediatr Dent</source>. (<year>2024</year>) <volume>34</volume>(<issue>1</issue>):<fpage>66</fpage>&#x02013;<lpage>76</lpage>. <pub-id pub-id-type="doi">10.1111/ipd.13098</pub-id><pub-id pub-id-type="pmid">37330969</pub-id>
</mixed-citation></ref><ref id="B16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mago</surname><given-names>J</given-names></name><name><surname>Kanekar</surname><given-names>A</given-names></name><name><surname>Sharma</surname><given-names>M</given-names></name></person-group>. <article-title>Applications of ChatGPT in oral healthcare: a current and brief overview</article-title>. <source>Glob J Res Anal</source>. (<year>2023</year>) <volume>12</volume>(<issue>6</issue>):<fpage>159</fpage>&#x02013;<lpage>60</lpage>. <pub-id pub-id-type="doi">10.36106/gjra/7112189</pub-id></mixed-citation></ref><ref id="B17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ossowska</surname><given-names>A</given-names></name><name><surname>Kusiak</surname><given-names>A</given-names></name><name><surname>&#x0015a;wietlik</surname><given-names>D</given-names></name></person-group>. <article-title>Artificial intelligence in dentistry&#x02014;narrative review</article-title>. <source>Int J Environ Res Public Health</source>. (<year>2022</year>) <volume>19</volume>(<issue>6</issue>):<fpage>3449</fpage>. <pub-id pub-id-type="doi">10.3390/ijerph19063449</pub-id><pub-id pub-id-type="pmid">35329136</pub-id>
</mixed-citation></ref><ref id="B18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peres</surname><given-names>MA</given-names></name><name><surname>Macpherson</surname><given-names>LM</given-names></name><name><surname>Weyant</surname><given-names>RJ</given-names></name><name><surname>Daly</surname><given-names>B</given-names></name><name><surname>Venturelli</surname><given-names>R</given-names></name><name><surname>Mathur</surname><given-names>MR</given-names></name><etal/></person-group>
<article-title>Oral diseases: a global public health challenge</article-title>. <source>Lancet</source>. (<year>2019</year>) <volume>394</volume>(<issue>10194</issue>):<fpage>249</fpage>&#x02013;<lpage>60</lpage>. <pub-id pub-id-type="doi">10.1016/S0140-6736(19)31146-8</pub-id><pub-id pub-id-type="pmid">31327369</pub-id>
</mixed-citation></ref><ref id="B19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rokhshad</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>P</given-names></name><name><surname>Mohammad-Rahimi</surname><given-names>H</given-names></name><name><surname>Pitchika</surname><given-names>V</given-names></name><name><surname>Entezari</surname><given-names>N</given-names></name><name><surname>Schwendicke</surname><given-names>F</given-names></name></person-group>. <article-title>Accuracy and consistency of chatbots versus clinicians for answering pediatric dentistry questions: a pilot study</article-title>. <source>J Dent</source>. (<year>2024</year>) <volume>144</volume>:<fpage>104938</fpage>. <pub-id pub-id-type="doi">10.1016/j.jdent.2024.104938</pub-id><pub-id pub-id-type="pmid">38499280</pub-id>
</mixed-citation></ref><ref id="B20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwendicke</surname><given-names>FA</given-names></name><name><surname>Samek</surname><given-names>W</given-names></name><name><surname>Krois</surname><given-names>J</given-names></name></person-group>. <article-title>Artificial intelligence in dentistry: chances and challenges</article-title>. <source>J Dent Res</source>. (<year>2020</year>) <volume>99</volume>(<issue>7</issue>):<fpage>769</fpage>&#x02013;<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1177/0022034520915714</pub-id><pub-id pub-id-type="pmid">32315260</pub-id>
</mixed-citation></ref><ref id="B21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Javed</surname><given-names>F</given-names></name><name><surname>Coletta</surname><given-names>RD</given-names></name></person-group>. <article-title>Education in oral health</article-title>. <source>Front Oral Health</source>. (<year>2023</year>) <volume>4</volume>:<fpage>1315663</fpage>. <pub-id pub-id-type="doi">10.3389/froh.2023.1315663</pub-id><pub-id pub-id-type="pmid">38024147</pub-id>
</mixed-citation></ref><ref id="B22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taber</surname><given-names>KS</given-names></name></person-group>. <article-title>The use of Cronbach&#x02019;s alpha when developing and reporting research instruments in science education</article-title>. <source>Res Sci Educ</source><italic>.</italic> (<year>2018</year>) <volume>48</volume>:<fpage>1273</fpage>&#x02013;<lpage>96</lpage>. <pub-id pub-id-type="doi">10.1007/s11165-016-9602-2</pub-id></mixed-citation></ref><ref id="B23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thurzo</surname><given-names>A</given-names></name><name><surname>Urbanov&#x000e1;</surname><given-names>W</given-names></name><name><surname>Nov&#x000e1;k</surname><given-names>B</given-names></name><name><surname>Czako</surname><given-names>L</given-names></name><name><surname>Siebert</surname><given-names>T</given-names></name><name><surname>Stano</surname><given-names>P</given-names></name><etal/></person-group>
<article-title>Where is the artificial intelligence applied in dentistry? Systematic review and literature analysis</article-title>. <source>Healthcare</source>. (<year>2022</year>) <volume>10</volume>(<issue>7</issue>):<fpage>1269</fpage>. <pub-id pub-id-type="doi">10.3390/healthcare10071269</pub-id><pub-id pub-id-type="pmid">35885796</pub-id>
</mixed-citation></ref><ref id="B24"><label>24.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tuzova</surname><given-names>L</given-names></name><name><surname>Tuzoff</surname><given-names>D</given-names></name><name><surname>Pulver</surname><given-names>LE</given-names></name></person-group>. <article-title>AI In dentistry</article-title>. In: <person-group person-group-type="author"><name><surname>Byrne</surname><given-names>MF</given-names></name><name><surname>Parsa</surname><given-names>N</given-names></name><name><surname>Greenhill</surname><given-names>AT</given-names></name><name><surname>Chahal</surname><given-names>D</given-names></name><name><surname>Ahmad</surname><given-names>O</given-names></name><name><surname>Bagci</surname><given-names>U</given-names></name></person-group>, editors. <source>AI in Clinical Medicine: A Practical Guide for Healthcare Professionals</source>. <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Wiley</publisher-name> (<year>2023</year>). p. <fpage>104</fpage>&#x02013;<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1002/9781119790686.ch11</pub-id></mixed-citation></ref><ref id="B25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Traverso</surname><given-names>A</given-names></name><name><surname>Dekker</surname><given-names>A</given-names></name><name><surname>Qian</surname><given-names>L</given-names></name><name><surname>Sun</surname><given-names>P</given-names></name></person-group>. <article-title>Assessing the role of GPT-4 in thyroid ultrasound diagnosis and treatment recommendations: enhancing interpretability with a chain of thought approach</article-title>. <source>Quant Imaging Med Surg</source>. (<year>2024</year>) <volume>14</volume>(<issue>2</issue>):<fpage>1602</fpage>. <pub-id pub-id-type="doi">10.21037/qims-23-1180</pub-id><pub-id pub-id-type="pmid">38415150</pub-id>
</mixed-citation></ref><ref id="B26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Lv</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>G</given-names></name><etal/></person-group>
<article-title>Advancements in oral and maxillofacial surgery medical image segmentation techniques: an overview</article-title>. <source>J Dent</source>. (<year>2023</year>) <volume>138</volume>:<fpage>104727</fpage>. <pub-id pub-id-type="doi">10.1016/j.jdent.2023.104727</pub-id><pub-id pub-id-type="pmid">37769934</pub-id>
</mixed-citation></ref><ref id="B27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Shi</surname><given-names>K</given-names></name><etal/></person-group>
<article-title>Artificial intelligence in the diagnosis of dental diseases on panoramic radiographs: a preliminary study</article-title>. <source>BMC Oral Health</source>. (<year>2023</year>) <volume>23</volume>(<issue>1</issue>):<fpage>358</fpage>. <pub-id pub-id-type="doi">10.1186/s12903-023-03027-6</pub-id><pub-id pub-id-type="pmid">37270488</pub-id>
</mixed-citation></ref><ref id="B28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abd-Alrazaq</surname><given-names>A</given-names></name><name><surname>AlSaad</surname><given-names>R</given-names></name><name><surname>Alhuwail</surname><given-names>D</given-names></name><name><surname>Ahmed</surname><given-names>A</given-names></name><name><surname>Healy</surname><given-names>PM</given-names></name><name><surname>Latifi</surname><given-names>S</given-names></name><etal/></person-group>
<article-title>Large language models in medical education: opportunities, challenges, and future directions</article-title>. <source>JMIR Med Educ</source>. (<year>2023</year>) <volume>9</volume>(<issue>1</issue>):<fpage>e48291</fpage>. <pub-id pub-id-type="doi">10.2196/48291</pub-id><pub-id pub-id-type="pmid">37261894</pub-id>
</mixed-citation></ref><ref id="B29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alhaidry</surname><given-names>HM</given-names></name><name><surname>Fatani</surname><given-names>B</given-names></name><name><surname>Alrayes</surname><given-names>JO</given-names></name><name><surname>Almana</surname><given-names>AM</given-names></name><name><surname>Alfhaed</surname><given-names>NK</given-names></name></person-group>. <article-title>ChatGPT in dentistry: a comprehensive review</article-title>. <source>Cureus</source>. (<year>2023</year>) <volume>15</volume>(<issue>4</issue>). <pub-id pub-id-type="doi">10.7759/cureus.38317</pub-id><pub-id pub-id-type="pmid">37266053</pub-id>
</mixed-citation></ref><ref id="B30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spielman</surname><given-names>AI</given-names></name></person-group>. <article-title>Dental education and practice: past, present, and future trends</article-title>. <source>Front Oral Health</source>. (<year>2024</year>) <volume>5</volume>:<fpage>1368121</fpage>. <pub-id pub-id-type="doi">10.3389/froh.2024.1368121</pub-id><pub-id pub-id-type="pmid">38694791</pub-id>
</mixed-citation></ref><ref id="B31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaulieu-Jones</surname><given-names>BR</given-names></name><name><surname>Berrigan</surname><given-names>MT</given-names></name><name><surname>Shah</surname><given-names>S</given-names></name><name><surname>Marwaha</surname><given-names>JS</given-names></name><name><surname>Lai</surname><given-names>S-L</given-names></name><name><surname>Brat</surname><given-names>GA</given-names></name></person-group>. <article-title>Evaluating capabilities of large language models: performance of GPT-4 on surgical knowledge assessments</article-title>. <source>Surgery</source>. (<year>2024</year>) <volume>175</volume>(<issue>4</issue>):<fpage>936</fpage>&#x02013;<lpage>42</lpage>. <pub-id pub-id-type="doi">10.1016/j.surg.2023.12.014</pub-id><pub-id pub-id-type="pmid">38246839</pub-id>
</mixed-citation></ref><ref id="B32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eggmann</surname><given-names>F</given-names></name><name><surname>Weiger</surname><given-names>R</given-names></name><name><surname>Zitzmann</surname><given-names>NU</given-names></name><name><surname>Blatz</surname><given-names>MB</given-names></name></person-group>. <article-title>Implications of large language models such as ChatGPT for dental medicine</article-title>. <source>J Esthet Restor Dent</source>. (<year>2023</year>) <volume>35</volume>(<issue>7</issue>):<fpage>1098</fpage>&#x02013;<lpage>102</lpage>. <pub-id pub-id-type="doi">10.1111/jerd.13046</pub-id><pub-id pub-id-type="pmid">37017291</pub-id>
</mixed-citation></ref><ref id="B33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kung</surname><given-names>TH</given-names></name><name><surname>Cheatham</surname><given-names>M</given-names></name><name><surname>Medenilla</surname><given-names>A</given-names></name><name><surname>Sillos</surname><given-names>C</given-names></name><name><surname>De Leon</surname><given-names>L</given-names></name><name><surname>Elepa&#x000f1;o</surname><given-names>C</given-names></name><etal/></person-group>
<article-title>Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models</article-title>. <source>PLoS Digital Health</source>. (<year>2023</year>) <volume>2</volume>(<issue>2</issue>):<fpage>e0000198</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pdig.0000198</pub-id><pub-id pub-id-type="pmid">36812645</pub-id>
</mixed-citation></ref><ref id="B34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohta</surname><given-names>K</given-names></name><name><surname>Ohta</surname><given-names>S</given-names></name></person-group>. <article-title>The performance of GPT-3.5, GPT-4, and bard on the Japanese national dentist examination: a comparison study</article-title>. <source>Cureus</source>. (<year>2023</year>) <volume>15</volume>(<issue>12</issue>). <pub-id pub-id-type="doi">10.7759/cureus.50369</pub-id></mixed-citation></ref><ref id="B35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singhal</surname><given-names>K</given-names></name><name><surname>Azizi</surname><given-names>S</given-names></name><name><surname>Tu</surname><given-names>T</given-names></name><name><surname>Mahdavi</surname><given-names>SS</given-names></name><name><surname>Wei</surname><given-names>J</given-names></name><name><surname>Chung</surname><given-names>HW</given-names></name><etal/></person-group>
<article-title>Large language models encode clinical knowledge</article-title>. <source>Nature</source>. (<year>2023</year>) <volume>620</volume>(<issue>7972</issue>):<fpage>172</fpage>&#x02013;<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-023-06291-2</pub-id><pub-id pub-id-type="pmid">37438534</pub-id>
</mixed-citation></ref><ref id="B36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su&#x000e1;rez</surname><given-names>A</given-names></name><name><surname>D&#x000ed;az-Flores Garc&#x000ed;a</surname><given-names>V</given-names></name><name><surname>Algar</surname><given-names>J</given-names></name><name><surname>G&#x000f3;mez S&#x000e1;nchez</surname><given-names>M</given-names></name><name><surname>Llorente de Pedro</surname><given-names>M</given-names></name><name><surname>Freire</surname><given-names>Y</given-names></name></person-group>. <article-title>Unveiling the ChatGPT phenomenon: evaluating the consistency and accuracy of endodontic question answers</article-title>. <source>Int Endod J</source>. (<year>2024</year>) <volume>57</volume>(<issue>1</issue>):<fpage>108</fpage>&#x02013;<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1111/iej.13985</pub-id><pub-id pub-id-type="pmid">37814369</pub-id>
</mixed-citation></ref></ref-list></back></article>