<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006490</article-id><article-id pub-id-type="pmc">PMC11860784</article-id><article-id pub-id-type="doi">10.3390/s25041261</article-id><article-id pub-id-type="publisher-id">sensors-25-01261</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Physical Activity in Pre-Ambulatory Children with Cerebral Palsy: An Exploratory Validation Study to Distinguish Active vs. Sedentary Time Using Wearable Sensors</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-7811-8429</contrib-id><name><surname>Orlando</surname><given-names>Julie M.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af1-sensors-25-01261" ref-type="aff">1</xref><xref rid="c1-sensors-25-01261" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2531-5394</contrib-id><name><surname>Smith</surname><given-names>Beth A.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af2-sensors-25-01261" ref-type="aff">2</xref><xref rid="af3-sensors-25-01261" ref-type="aff">3</xref><xref rid="af4-sensors-25-01261" ref-type="aff">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-4178-8872</contrib-id><name><surname>Hafer</surname><given-names>Jocelyn F.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af5-sensors-25-01261" ref-type="aff">5</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0003-1298-0050</contrib-id><name><surname>Paremski</surname><given-names>Athylia</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af1-sensors-25-01261" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-2790-6787</contrib-id><name><surname>Amodeo</surname><given-names>Matthew</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="af6-sensors-25-01261" ref-type="aff">6</xref><xref rid="af7-sensors-25-01261" ref-type="aff">7</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2892-7687</contrib-id><name><surname>Lobo</surname><given-names>Michele A.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af8-sensors-25-01261" ref-type="aff">8</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8427-3051</contrib-id><name><surname>Prosser</surname><given-names>Laura A.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af1-sensors-25-01261" ref-type="aff">1</xref><xref rid="af9-sensors-25-01261" ref-type="aff">9</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Boissy</surname><given-names>Patrick</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01261"><label>1</label>Division of Rehabilitation Medicine, Children&#x02019;s Hospital of Philadelphia, Philadelphia, PA 19104, USA; <email>paremskia@chop.edu</email> (A.P.); <email>prosserl@chop.edu</email> (L.A.P.)</aff><aff id="af2-sensors-25-01261"><label>2</label>Developmental Neuroscience and Neurogenetics Program, The Saban Research Institute, Children&#x02019;s Hospital Los Angeles, Los Angeles, CA 90027, USA; <email>bsmith@chla.usc.edu</email></aff><aff id="af3-sensors-25-01261"><label>3</label>Division of Developmental-Behavioral Pediatrics, Children&#x02019;s Hospital Los Angeles, Los Angeles, CA 90027, USA</aff><aff id="af4-sensors-25-01261"><label>4</label>Department of Pediatrics, Keck School of Medicine, University of Southern California, Los Angeles, CA 90089, USA</aff><aff id="af5-sensors-25-01261"><label>5</label>Kinesiology and Applied Physiology, University of Delaware, Newark, DE 19713, USA; <email>jfhafer@udel.edu</email></aff><aff id="af6-sensors-25-01261"><label>6</label>Department of Physical Medicine and Rehabilitation, Hospital of the University of Pennsylvania, Philadelphia, PA 19146, USA; <email>matthew.amodeo@ochsner.org</email></aff><aff id="af7-sensors-25-01261"><label>7</label>Department of Pediatric Neurosciences, Ochsner Health System, New Orleans, LA 70121, USA</aff><aff id="af8-sensors-25-01261"><label>8</label>Physical Therapy Department, Biomechanics &#x00026; Movement Science Program, University of Delaware, Newark, DE 19713, USA; <email>malobo@udel.edu</email></aff><aff id="af9-sensors-25-01261"><label>9</label>Department of Pediatrics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA</aff><author-notes><corresp id="c1-sensors-25-01261"><label>*</label>Correspondence: <email>orlandoj1@chop.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>19</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1261</elocation-id><history><date date-type="received"><day>13</day><month>1</month><year>2025</year></date><date date-type="rev-recd"><day>11</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>17</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Wearable inertial sensor technology affords opportunities to record the physical activity of young children in their natural environments. The interpretation of these data, however, requires validation. The purpose of this study was to develop and establish the criterion validity of a method of quantifying active and sedentary physical activity using an inertial sensor for pre-ambulatory children with cerebral palsy. Ten participants were video recorded during 30 min physical therapy sessions that encouraged gross motor play activities, and the video recording was behaviorally coded to identify active and sedentary time. A receiver operating characteristic curve identified the optimal threshold to maximize true positive and minimize false positive active time for eight participants in the development dataset. The threshold was 0.417 m/s<sup>2</sup> and was then validated with the remaining two participants; the percent of true positives and true negatives was 92.2 and 89.7%, respectively. We conclude that there is potential for raw sensor data to be used to quantify active and sedentary time in pre-ambulatory children with physical disability, and raw acceleration data may be more generalizable than the sensor-specific activity counts commonly reported in the literature.</p></abstract><kwd-group><kwd>wearable sensors</kwd><kwd>activity cut-points</kwd><kwd>activity monitoring</kwd><kwd>motion sensors</kwd><kwd>accelerometry</kwd><kwd>actigraphy</kwd><kwd>sedentary</kwd><kwd>active</kwd><kwd>cerebral palsy</kwd></kwd-group><funding-group><award-group><funding-source>National Institute on Disability, Independent Living, and Rehabilitation Research</funding-source><award-id>H133G140166</award-id></award-group><award-group><funding-source>National Institute of Child Health and Human Development</funding-source><award-id>1R01HD098364</award-id></award-group><award-group><funding-source>UNIDEL Distinguished Graduate Fellowship (Orlando)</funding-source></award-group><funding-statement>This research was funded by the National Institute on Disability, Independent Living, and Rehabilitation Research, Field-Initiated Research Grant H133G140166 (Prosser), National Institute of Child Health and Human Development award 1R01HD098364 (Prosser (contact), Kolobe, Smith), and the UNIDEL Distinguished Graduate Fellowship (Orlando).</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01261"><title>1. Introduction</title><p>Time spent playing on the floor, or playing in an unconstrained environment, has important implications for child development [<xref rid="B1-sensors-25-01261" ref-type="bibr">1</xref>,<xref rid="B2-sensors-25-01261" ref-type="bibr">2</xref>,<xref rid="B3-sensors-25-01261" ref-type="bibr">3</xref>,<xref rid="B4-sensors-25-01261" ref-type="bibr">4</xref>]. For young children under three years of age, floor play time allows for self-initiated movement, exploratory behavior with objects, and face-to-face interactions with parents [<xref rid="B1-sensors-25-01261" ref-type="bibr">1</xref>,<xref rid="B5-sensors-25-01261" ref-type="bibr">5</xref>]. These early exploratory behaviors, including exploration of self and objects are predictive of motor, cognitive, and language development, and early exploratory behaviors are also related to more advanced play skills [<xref rid="B3-sensors-25-01261" ref-type="bibr">3</xref>,<xref rid="B4-sensors-25-01261" ref-type="bibr">4</xref>]. Young children tend to vary exploratory actions with toys and face-to-face interactions with their parents based on their position. Thus, encouraging unconstrained floor play time may provide opportunities for children to experience different positions and have varied, rich interactions with the objects and people within their environment [<xref rid="B1-sensors-25-01261" ref-type="bibr">1</xref>,<xref rid="B6-sensors-25-01261" ref-type="bibr">6</xref>]. Therefore, there is a need to develop novel ways to measure physical activity during floor play activities, which contribute to opportunities for developmental advancement for pre-walking children.</p><p>For children with cerebral palsy (CP) or who are at high risk for CP, floor play time may have even greater implications for development. Children with CP display more sedentary behaviors than typically developing peers [<xref rid="B7-sensors-25-01261" ref-type="bibr">7</xref>]. Sedentary time appears to increase for children with CP over early childhood (i.e., 2&#x02013;5 years of age) regardless of severity level, indicated by the gross motor function classification system (GMFCS) level [<xref rid="B8-sensors-25-01261" ref-type="bibr">8</xref>], with level 1 indicating the lowest severity and level 5 indicating the highest severity. Additionally, 2-year-old children with CP (GMFCS levels 3, 4, and 5) were less likely to meet physical activity guidelines than their typically developing peers over a 3-day period [<xref rid="B9-sensors-25-01261" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-01261" ref-type="bibr">10</xref>]. Measuring activity during floor play time in pre-walking children will support our ability to identify children who have inadequate active time and implement interventions early in life.</p><p>While measuring activity for young children can provide valuable information, there are limitations with current measurement approaches. The gold standard for measuring and categorizing variable activities is the behavioral coding of video recordings; however, this method is time and resource intensive, and not always feasible in natural environments, such as home and childcare settings [<xref rid="B11-sensors-25-01261" ref-type="bibr">11</xref>,<xref rid="B12-sensors-25-01261" ref-type="bibr">12</xref>]. Some research groups have explored using machine learning to classify activities; however, there remain challenges with misclassifying activities, particularly during adult interactions [<xref rid="B13-sensors-25-01261" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-01261" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-01261" ref-type="bibr">15</xref>,<xref rid="B16-sensors-25-01261" ref-type="bibr">16</xref>,<xref rid="B17-sensors-25-01261" ref-type="bibr">17</xref>,<xref rid="B18-sensors-25-01261" ref-type="bibr">18</xref>]. Fully personalized machine learning classifiers were the most accurate in classifying activities for youth with CP, GMFCS level I&#x02013;III, in a laboratory setting; however, they were found to have poor accuracy in a natural setting and require the presence of a researcher to identify activities during the training period [<xref rid="B13-sensors-25-01261" ref-type="bibr">13</xref>]. The presence of the researcher may change participant behavior. For example, in a qualitative in-depth interview, mothers of 2-year-old children reported that their behavior and their child&#x02019;s behaviors changed during parent&#x02013;child observations, which they felt was related to the researcher&#x02019;s presence [<xref rid="B18-sensors-25-01261" ref-type="bibr">18</xref>,<xref rid="B19-sensors-25-01261" ref-type="bibr">19</xref>]. The concept of &#x0201c;knowing you are being recorded&#x0201d; whether a researcher is present or not may also change behavior, and this limitation applies to multiple measurement systems, including wearable sensors.</p><p>Interpreting data recorded from wearable sensors is another significant area of challenge. The amount and type of activity (frequently reported as sedentary, light, or moderate-to-vigorous physical activity) is often reported in proprietary &#x0201c;activity counts&#x0201d;, which poses challenges for interpreting data recorded with different sensors and lacks methodological transparency for understanding the cut-points for activity level classifications [<xref rid="B20-sensors-25-01261" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-01261" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-01261" ref-type="bibr">22</xref>,<xref rid="B23-sensors-25-01261" ref-type="bibr">23</xref>,<xref rid="B24-sensors-25-01261" ref-type="bibr">24</xref>,<xref rid="B25-sensors-25-01261" ref-type="bibr">25</xref>]. For example, a higher activity count, suggesting a higher intensity of movement, can reflect a higher frequency of movement or larger acceleration of the movements produced and does not distinguish between those patterns. Further, the accurate measurement of activity requires validation in unique research cohorts, which has often not been performed when using existing &#x0201c;activity count&#x0201d; methods. In 2-month-old infants, for example, it is possible that many of their movements are &#x0201c;below threshold&#x0201d; and do not generate activity counts, thus providing an inaccurate output. Young infants can demonstrate a muscle strength gain to body growth/mass gain imbalance, which would likely result in slow acceleration movements [<xref rid="B26-sensors-25-01261" ref-type="bibr">26</xref>]. As such, current acceleration thresholds for counting &#x0201c;activity counts&#x0201d; may be too high to adequately capture many of their movements [<xref rid="B26-sensors-25-01261" ref-type="bibr">26</xref>]. In a scoping review examining physical activity measurements in children under 2 years old, Prioreschi and Micklesfield concluded that cut-points specific to this population are needed, and reporting &#x0201c;raw counts&#x0201d; should be prioritized to allow for comparisons across studies, particularly due to the variability in movements among infants and toddlers [<xref rid="B27-sensors-25-01261" ref-type="bibr">27</xref>]. However, often &#x0201c;raw counts&#x0201d; have not been validated in the population being measured [<xref rid="B28-sensors-25-01261" ref-type="bibr">28</xref>]. This study will use raw acceleration data from an inertial measurement unit to develop a threshold to determine active vs. sedentary time in pre-ambulatory children with CP.</p><p>There are a greater number of validation studies for ambulatory children. Hurter et al. established device-specific thresholds using raw accelerometry signals to classify sedentary and stationary activities in 9&#x02013;10-year-old children [<xref rid="B29-sensors-25-01261" ref-type="bibr">29</xref>]. Trost et al. validated cut-points for sedentary, light, and moderate&#x02013;vigorous physical activity in ambulatory toddlers using triaxial accelerometers worn at the right hip [<xref rid="B30-sensors-25-01261" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-01261" ref-type="bibr">31</xref>]. As noted in a systematic review and meta-analysis conducted by Bruijns et al., these cut-points have been widely used in studies including toddlers [<xref rid="B32-sensors-25-01261" ref-type="bibr">32</xref>]. In addition to the Trost et al. cut-points, often studies have applied cut-points that had not been validated for the toddler age range [<xref rid="B31-sensors-25-01261" ref-type="bibr">31</xref>,<xref rid="B32-sensors-25-01261" ref-type="bibr">32</xref>]. The validity of such results are questionable.</p><p>For young children, sensors have been validated to identify positions and to classify specific movement patterns. The Get Around Garment is a validated smart garment with an integrated triaxial accelerometer to classify infant positions in a natural environment [<xref rid="B33-sensors-25-01261" ref-type="bibr">33</xref>]. Airaksinen et al. have also developed and validated a smart jumpsuit for infants incorporating multiple triaxial accelerometers and gyroscopes to classify specific movements and positions and gross motor skills using machine learning algorithms [<xref rid="B34-sensors-25-01261" ref-type="bibr">34</xref>,<xref rid="B35-sensors-25-01261" ref-type="bibr">35</xref>]. To identify specific movement patterns, infant leg movement quantity and kinematic characteristics have been validated, as well as the detection of infant arm movement bouts [<xref rid="B36-sensors-25-01261" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-01261" ref-type="bibr">37</xref>]. While validation studies have been growing with this young population, there remains a need to validate the use of sensors to quantify activity for young children. Ghazi et al. developed and validated physical activity thresholds for pre-walking infants based on the area under the acceleration&#x02013;time curve and area under the jerk&#x02013;time curve using synchronized behaviorally coded video recordings and ankle sensor recordings. However, the amount of data per participant was limited to 2&#x02013;8 min [<xref rid="B38-sensors-25-01261" ref-type="bibr">38</xref>]. Therefore, additional validation studies are needed with longer durations of data and samples across different age and motor skill ranges.</p><p>In order to better prescribe early activity interventions for pre-walking children with CP, objective methods to evaluate physical activity levels are needed. Using methods that can be applied to raw sensor data would make a physical activity monitoring tool accessible to and comparable across patient populations. Therefore, the purpose of this study was to develop and establish the criterion validity of a method of quantifying active and sedentary activity using triaxial accelerometer data from an inertial sensor worn on the lateral thigh for pre-walking children with cerebral palsy during floor play time.</p></sec><sec id="sec2-sensors-25-01261"><title>2. Materials and Methods</title><sec sec-type="subjects" id="sec2dot1-sensors-25-01261"><title>2.1. Participants</title><p>Participants were pre-ambulatory children with CP recruited as part of two rehabilitation clinical trials: the first investigating the influence of two rehabilitation approaches on motor development in children with CP (ClinicalTrials.gov Identifier: NCT02340026) and the second characterizing the development of locomotor learning over the first 18 months of life in infants at high risk for CP (ClinicalTrials.gov Identifier: NCT04561232) [<xref rid="B39-sensors-25-01261" ref-type="bibr">39</xref>,<xref rid="B40-sensors-25-01261" ref-type="bibr">40</xref>]. See <xref rid="sensors-25-01261-t001" ref-type="table">Table 1</xref> for participant information. All procedures were approved by the Institutional Review Board at The Children&#x02019;s Hospital of Philadelphia.</p></sec><sec id="sec2dot2-sensors-25-01261"><title>2.2. Data Collection</title><p>Participants were video recorded during a 30 min (mean: 30.6 min, range: 30.2&#x02013;30.9 min) physical therapy session in an outpatient physical therapy environment between November of 2018 and June of 2023. The space included developmentally appropriate toys and surfaces to encourage movement and pulling-to-stand. The participants wore an inertial sensor (Opal sensor, APDM, Inc., Portland, OR, USA) on their dominant leg, placed at the lateral aspect of the child&#x02019;s thigh and secured with a hook and loop fastening strap (<xref rid="sensors-25-01261-f001" ref-type="fig">Figure 1</xref>). The placement was chosen to capture a majority of gross motor movements. The sensor recorded data at 128 Hz. The sessions were video recorded at 30 Hz with a VIXIA HF R70 camcorder (Canon U.S.A Inc., Melville, NY, USA).</p></sec><sec id="sec2dot3-sensors-25-01261"><title>2.3. Data Processing</title><p>Behavioral coding was conducted using Datavyu, an open source software package that is designed for behavioral coding from video observations [<xref rid="B41-sensors-25-01261" ref-type="bibr">41</xref>]. Our guidelines for coding active and sedentary time are described in <xref rid="app1-sensors-25-01261" ref-type="app">Supplementary Material S1</xref>, including specific examples. Movement classified as &#x0201c;active&#x0201d; time included walking with a push-toy or with upper limb support, dynamic movement or transitions, and limb movement that included at least 30 degrees of trunk movement, while &#x0201c;sedentary&#x0201d; time was coded for static positions. Adult handling, or time when the participant was picked up or moved by an adult, was also identified and excluded during the threshold development, and then included as &#x0201c;sedentary&#x0201d; time during validation. Behavioral coding was conducted by researchers trained in video observation (AP, JO). Inter-rater frame by frame reliability was completed for 30 percent of the data and calculated as [the number of agreements/ (the number of disagreements + agreements)] &#x000d7; 100 within a tolerance of 500 milliseconds using Datavyu software (version 1.3.8).</p><p>The start time and stop times of the session recorded by the video and sensor data were synchronized. When possible, a button press on the sensor was used to synchronize the video and sensor data. In one case, the button press was not possible due to the version of the sensor, and instead, the video and sensor data were synchronized using a windmill action (i.e., moving the sensors in a large circle for 5 cycles) performed by the researcher prior to donning and again after removing the sensor from the child. These movements were easily identified in a graph of the raw (unfiltered) resultant acceleration magnitude data.</p><p>Raw triaxial accelerometer data were visually inspected in Motion Studio (APDM, Inc., Portland, OR, USA) to ensure the expected amount of data were present. Raw data were then processed using a fully automated, custom MATLAB (Version 2023b; The Math Works Inc., Natick, MA, USA) program. This program is openly available at [<uri xlink:href="https://github.com/jorlandoDPT/Sensors-Paper">https://github.com/jorlandoDPT/Sensors-Paper</uri>]. <xref rid="sensors-25-01261-f002" ref-type="fig">Figure 2</xref> provides a visual representation of the data processing steps. The data were divided into a development and a validation dataset. The development dataset included the first 8 participants, and then the validation dataset included the remaining 2 participants. Raw acceleration components were concatenated for the 8 participants in the development dataset. <xref rid="sensors-25-01261-f002" ref-type="fig">Figure 2</xref> displays the data processing steps applied to the development dataset. The raw acceleration data were transformed to a world frame of reference using sensor accelerometer, gyroscope, and magnetometer data in a sensor fusion algorithm created and openly shared by APDM [<xref rid="B42-sensors-25-01261" ref-type="bibr">42</xref>]. The gravity vector was subtracted from the &#x0201c;up&#x0201d; portion of the world frame data, and then the resultant was calculated to obtain the signal of interest, with acceleration due to gravity removed. To determine appropriate filtering procedures, we then conducted a power spectral density analysis on the resultant acceleration signal and determined the frequency threshold that contained 95% of the signal&#x02019;s power. We then filtered the acceleration data with a 4th-order lowpass Butterworth filter with a cutoff frequency of 19.9 m/s<sup>2</sup>. The absolute value of the filtered acceleration signal was then downsampled by a factor of 4 (i.e., 128 to 32 Hz) to better correspond to the frame rate of the video data [<xref rid="B43-sensors-25-01261" ref-type="bibr">43</xref>].</p><p><xref rid="sensors-25-01261-f003" ref-type="fig">Figure 3</xref> displays the steps to determine the threshold to distinguish active from sedentary time from the concatenated 8 participants in the development dataset. A receiver operating characteristic (ROC) curve was plotted for the development dataset using the perfcurve function in MATLAB. The perfcurve function computed the optimal operating point to identify the optimal threshold that maximized true positives and minimized false positives. This threshold is consistent with a visual inspection of the histogram in <xref rid="sensors-25-01261-f003" ref-type="fig">Figure 3</xref>A.</p><p>We validated the threshold with the remaining 2 participants (validation dataset). The validation data were processed using the same steps described above. The raw acceleration components were transformed to a world frame of reference, the gravity vector was subtracted from the &#x0201c;up&#x0201d; portion of the world frame data, and then the resultant acceleration magnitude was calculated. The data were filtered using the procedures determined by the development dataset, and then the absolute value of the filtered acceleration signal was downsampled by a factor of 4.</p><p>After applying the threshold to each of the participants within the validation dataset, we evaluated the agreement between sedentary and active time identified through the threshold compared to the gold-standard behavioral coding with a tolerance of 0.125 s to correct for any between-frame misalignment between the behavioral coding and sensor data. We calculated the sensitivity (i.e., true positives frames/total positive frames) and specificity (i.e., true negatives frames/total negative frames). A sensitivity and specificity of 0.7&#x02013;0.79 was considered &#x0201c;acceptable&#x0201d;, and greater than 0.8 was considered &#x0201c;good&#x0201d;.</p></sec></sec><sec sec-type="results" id="sec3-sensors-25-01261"><title>3. Results</title><p>The inter-rater agreement was 84.8% between coders. Within the development dataset, 46.7% of the sessions were active time and 53.7% of the sessions were sedentary time, and 0.2% of the data were excluded due to adult handling (which represents time when the sensor was likely moving but perhaps not due to the physical activity of the child), identified through behavioral coding. The optimal threshold for the development dataset was 0.417 m/s<sup>2</sup>, and the area under the curve was from 0.60 (<xref rid="sensors-25-01261-t002" ref-type="table">Table 2</xref>). The optimal threshold identified a total of 36.5% active time and 63.5% sedentary time.</p><p>The percent of true positives and true negatives (i.e., agreement) combined for the validation dataset using the threshold compared to the gold-standard behavioral coding was 92.2% and 89.7%, respectively (<xref rid="sensors-25-01261-f004" ref-type="fig">Figure 4</xref>). The sensitivity and specificity were greater than 85% for both participants (<xref rid="sensors-25-01261-t003" ref-type="table">Table 3</xref>). Video coding identified 60.0% and 81.0% active time compared to 58.9% and 77.2% active time identified using the threshold for both participants 9 and 10, respectively. Therefore, using video validation with children in the target population, we were able to achieve good agreement with manual behavior coding using an acceleration threshold of 0.417 m/s<sup>2</sup>, above which represented active time and below which represented sedentary time.</p></sec><sec sec-type="discussion" id="sec4-sensors-25-01261"><title>4. Discussion</title><p>This study established the criterion validity of a method of quantifying active and sedentary activity using triaxial accelerometer data from an inertial sensor worn on the lateral thigh for pre-ambulatory children with CP during floor play time. Our approach to distinguish between active and sedentary time suggests potential for good sensitivity and specificity. Importantly, analysis was performed on the raw triaxial accelerometer data, making it applicable to data collected with any inertial sensor as opposed to limited to specific sensors.</p><p>In the present study, our primary aim was to distinguish active time; however, previous studies have established sedentary thresholds using activity counts. Oftedal et al. validated cut-points using activity counts to measure sedentary time (i.e., sitting or lying) in non-ambulatory toddlers with CP, and their work may provide a model for continued work validating wearable sensors with young children [<xref rid="B23-sensors-25-01261" ref-type="bibr">23</xref>]. However, because their work uses activity counts, there is limited generalizability beyond a specific type of sensor. While measuring the amount of sedentary time is important for health and wellness, identifying active time may be more impactful for early therapeutic interventions.</p><p>A known problem with the use of sensors to objectively measure activity with young children is that caregivers may interact with and handle the child through picking up the child, moving the child, or completing usual care, such as diaper changes [<xref rid="B44-sensors-25-01261" ref-type="bibr">44</xref>,<xref rid="B45-sensors-25-01261" ref-type="bibr">45</xref>,<xref rid="B46-sensors-25-01261" ref-type="bibr">46</xref>]. Because we chose to evaluate specific play time sessions, this problem was minimal in our dataset (&#x0003c;1%). We excluded picked-up time from the development dataset and classified this as sedentary time for the validation dataset. Oftedal et al.&#x02019;s study also identified periods of adult interactions in their validation of cut-points for toddlers with CP using activity counts; however, they excluded time with adult interactions from their analysis [<xref rid="B23-sensors-25-01261" ref-type="bibr">23</xref>]. While removing adult interactions does improve the accuracy of sensor-identified activity levels, this does not reflect the naturalistic environment of the child, especially the pre-ambulatory child. Additionally, if research groups plan to capture full-day recordings of child activity, excluding all periods of adult interactions is not feasible as it would be almost impossible to identify all occurrences. We sought to minimize the challenge of adult interactions by focusing on floor play time instead of full-day recordings. Further work examining the differences between full-day recordings and targeted floor play time is needed, and adult interference remains a limitation of sensor-identified activity levels.</p><p>While considered the gold standard, behavioral coding is resource intensive and requires the researcher to be present, which can interfere with natural behaviors [<xref rid="B19-sensors-25-01261" ref-type="bibr">19</xref>]. Other methods have been employed to evaluate activity in natural environments [<xref rid="B47-sensors-25-01261" ref-type="bibr">47</xref>,<xref rid="B48-sensors-25-01261" ref-type="bibr">48</xref>]. One such method is ecological momentary assessment (EMA) to measure information about infant positioning at home; however, EMA requires families to use a smart phone to log information or reply to a text message about their infants&#x02019; position [<xref rid="B49-sensors-25-01261" ref-type="bibr">49</xref>,<xref rid="B50-sensors-25-01261" ref-type="bibr">50</xref>]. While this method is considered feasible, these studies still require significant parent engagement, require knowledge of the typical frequency and duration of the occurrence of the behavior being studied, and are open to user interpretation based on the questions or prompts [<xref rid="B49-sensors-25-01261" ref-type="bibr">49</xref>]. Similar to EMA, sensors also allow researchers to identify infant behavior in a natural environment and require less effort for families [<xref rid="B33-sensors-25-01261" ref-type="bibr">33</xref>].</p><p>Another consideration for identifying activity in young children is the location and number of sensors. For the current study, a single sensor placed on the lateral thigh of the child&#x02019;s dominant leg was chosen to capture transitions and movement consistent with our definition of active time. Many studies involving preschool children have used a hip or low back placement [<xref rid="B10-sensors-25-01261" ref-type="bibr">10</xref>,<xref rid="B30-sensors-25-01261" ref-type="bibr">30</xref>,<xref rid="B51-sensors-25-01261" ref-type="bibr">51</xref>,<xref rid="B52-sensors-25-01261" ref-type="bibr">52</xref>,<xref rid="B53-sensors-25-01261" ref-type="bibr">53</xref>,<xref rid="B54-sensors-25-01261" ref-type="bibr">54</xref>]. Trost et al. compared hip and wrist placement to identify activity in preschoolers and found that either location resulted in an acceptable accuracy of activity recognition with optimal cut-points, with a sensitivity ranging between 88.4 and 89.4 and specificity ranging from 85.1 to 85.8 for recordings at the hip and a sensitivity ranging between 61.3 and 80.2 and specificity ranging from 90.1 to 93.9 for recordings at the wrist [<xref rid="B30-sensors-25-01261" ref-type="bibr">30</xref>]. The sensitivity and specificity reported at both locations were similar to the current study. Trost et al. also reported that combining wrist and hip placement had the greatest accuracy; however, using multiple sensors adds expense, processing time, data storage requirements, and additional steps for parents when donning devices [<xref rid="B30-sensors-25-01261" ref-type="bibr">30</xref>]. Wrist placement is often selected when evaluating arm use after constraint-induced therapy or detecting infant arm movement [<xref rid="B55-sensors-25-01261" ref-type="bibr">55</xref>,<xref rid="B56-sensors-25-01261" ref-type="bibr">56</xref>]. In our previous work with preschool children, we found that a few children were interested in the device and attempted to remove it, thus having the device on the wrist may be more accessible than the hip and pose additional challenges within this young population [<xref rid="B57-sensors-25-01261" ref-type="bibr">57</xref>].</p><p>The accuracy of identifying active and sedentary time is dependent on the definition of active and sedentary time used during behavioral coding. As shown in <xref rid="app1-sensors-25-01261" ref-type="app">Supplementary Material S1</xref>, our definition of active time focuses on gross movements of the trunk, including movement at the upper or lower extremities that induces trunk movement. We defined sedentary time as any time that was not active, including time with adult interference. In the literature, including studies with children with CP, sedentary time is often indicated by sitting or lying positions [<xref rid="B28-sensors-25-01261" ref-type="bibr">28</xref>]. However, sitting is a position where object exploration often occurs, and therefore sitting may be active time if exploratory upper extremity movements also induce trunk movements, such as leaning forward or rotating the trunk to reach objects [<xref rid="B6-sensors-25-01261" ref-type="bibr">6</xref>,<xref rid="B58-sensors-25-01261" ref-type="bibr">58</xref>]. Clear, consistent descriptions of what constitutes active time are necessary and will enhance the reproducibility of the sensor threshold application in identifying active and sedentary periods during floor play.</p></sec><sec id="sec5-sensors-25-01261"><title>5. Limitations</title><p>This paper has several limitations. The threshold was developed using data from eight participants, and criterion validity was established with two participants, and therefore there is potential for overfitting. The ratio of 80% development and 20% validation data was selected to have enough training data to achieve a threshold that fits the population. The participants in the validation dataset were both GMFCS level I, which may limit the generalizability of the threshold. Importantly, despite their similar general motor ability, these two participants had different amounts of active time, which was reflected in both the behavioral coding and the wearable sensor method. Additionally, while we attempted to provide toys and surfaces to replicate a natural play setting, this analysis did not take place in a natural setting, and therefore the validity of this threshold in a natural setting is not known [<xref rid="B28-sensors-25-01261" ref-type="bibr">28</xref>]. Another limitation is the use of a single sensor to identify movement (although this is also a strength in regard to participant burden and resource use). The use of a single sensor could lead to misidentifying active time; to mitigate this limitation, the sensor placement fit our definition of active and sedentary time for this study. Additional limitations include potentially misidentifying active time as sedentary time if the activity involved trunk movement that was below the determined threshold, or misidentifying sedentary time as active time if the child was picked up or moved by an adult in the validation dataset. Importantly, this work established the criterion validity of sensor data from a single thigh sensor during 30 min play intervals for pre-ambulatory children with cerebral palsy; we did not evaluate the validity of this threshold in all circumstances. Future work is needed to assess the validity of this threshold in larger datasets, including children across GMFCS levels, and in natural settings.</p></sec><sec sec-type="conclusions" id="sec6-sensors-25-01261"><title>6. Conclusions</title><p>A method of quantifying active and sedentary activity using an inertial sensor for pre-ambulatory children with CP was developed and the criterion validity was established with good sensitivity and specificity. We report the development and validation approach that may serve as a model for validating raw accelerometry data in other populations.</p></sec></body><back><ack><title>Acknowledgments</title><p>We acknowledge Mayumi Mohan for their initial work on the MATLAB program, Julie Skorup PT DPT and Samuel Pierce PT PhD for their assistance with data collection, Duncan Tulimieri for his assistance testing and revising the open source MATLAB program, and Mustafa Ghazi for his guidance.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><app-group><app id="app1-sensors-25-01261"><title>Supplementary Materials</title><p>The following supporting information can be downloaded at: <uri xlink:href="https://www.mdpi.com/article/10.3390/s25041261/s1">https://www.mdpi.com/article/10.3390/s25041261/s1</uri>.</p><supplementary-material id="sensors-25-01261-s001" position="float" content-type="local-data"><media xlink:href="sensors-25-01261-s001.zip"/></supplementary-material></app></app-group><notes><title>Author Contributions</title><p>Conceptualization, L.A.P., B.A.S., J.M.O., J.F.H., A.P., M.A. and M.A.L.; methodology, L.A.P., B.A.S., J.M.O., J.F.H., A.P., M.A. and M.A.L.; software, J.M.O., J.F.H. and B.A.S.; formal analysis, L.A.P., B.A.S., J.M.O. and J.F.H.; writing&#x02014;original draft preparation, J.M.O.; writing&#x02014;review and editing, L.A.P., B.A.S., J.M.O., J.F.H., A.P., M.A. and M.A.L.; supervision, L.A.P. and B.A.S.; project administration, L.A.P. and B.A.S.; funding acquisition, L.A.P. and J.M.O. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>This study was conducted according to the guidelines of the Declaration of Helsinki and approved by the Institutional Review Board at The Children&#x02019;s Hospital of Philadelphia (protocol code IRB 14-011172 and date of approval 11 May 2014).</p></notes><notes><title>Informed Consent Statement</title><p>Informed consent was obtained from one parent or legal guardian for each child involved in this study.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data presented in this study are available on request from the corresponding author. The data are not publicly available due to human subject privacy regulations. De-identified data may be shared on request with successful execution of the data use agreement.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results.</p></notes><glossary><title>Abbreviations</title><p>The following abbreviations are used in this manuscript:
<array><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">CP</td><td align="left" valign="middle" rowspan="1" colspan="1">Cerebral palsy</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GMFCS</td><td align="left" valign="middle" rowspan="1" colspan="1">Gross Motor Function Classification System</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">ROC</td><td align="left" valign="middle" rowspan="1" colspan="1">Receiver operating characteristic</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">EMA</td><td align="left" valign="middle" rowspan="1" colspan="1">Ecological momentary assessment</td></tr></tbody></array></p></glossary><ref-list><title>References</title><ref id="B1-sensors-25-01261"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Franchak</surname><given-names>J.M.</given-names></name>
<name><surname>Kretch</surname><given-names>K.S.</given-names></name>
<name><surname>Adolph</surname><given-names>K.E.</given-names></name>
</person-group><article-title>See and be seen: Infant-caregiver social looking during locomotor free play</article-title><source>Dev. Sci.</source><year>2018</year><volume>21</volume><fpage>e12626</fpage><pub-id pub-id-type="doi">10.1111/desc.12626</pub-id><pub-id pub-id-type="pmid">29071760</pub-id>
</element-citation></ref><ref id="B2-sensors-25-01261"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Gibson</surname><given-names>E.J.</given-names></name>
</person-group><article-title>Exploratory-Behavior In The Development Of Perceiving, Acting, And The Acquiring Of Knowledge</article-title><source>Annu. Rev. Psychol.</source><year>1988</year><volume>39</volume><fpage>1</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1146/annurev.ps.39.020188.000245</pub-id></element-citation></ref><ref id="B3-sensors-25-01261"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Belsky</surname><given-names>J.</given-names></name>
<name><surname>Most</surname><given-names>R.K.</given-names></name>
</person-group><article-title>From Exploration to Play&#x02014;A Cross-Sectional Study of Infant Free Play-Behavior</article-title><source>Dev. Psychol.</source><year>1981</year><volume>17</volume><fpage>630</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.17.5.630</pub-id></element-citation></ref><ref id="B4-sensors-25-01261"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Babik</surname><given-names>I.</given-names></name>
<name><surname>Galloway</surname><given-names>J.C.</given-names></name>
<name><surname>Lobo</surname><given-names>M.A.</given-names></name>
</person-group><article-title>Early Exploration of One&#x02019;s Own Body, Exploration of Objects, and Motor, Language, and Cognitive Development Relate Dynamically Across the First Two Years of Life</article-title><source>Dev. Psychol.</source><year>2022</year><volume>58</volume><fpage>222</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1037/dev0001289</pub-id><pub-id pub-id-type="pmid">34990201</pub-id>
</element-citation></ref><ref id="B5-sensors-25-01261"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>James</surname><given-names>K.H.</given-names></name>
<name><surname>Swain</surname><given-names>S.N.</given-names></name>
</person-group><article-title>Only self-generated actions create sensori-motor systems in the developing brain</article-title><source>Dev. Sci.</source><year>2011</year><volume>14</volume><fpage>673</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2010.01011.x</pub-id><pub-id pub-id-type="pmid">21676088</pub-id>
</element-citation></ref><ref id="B6-sensors-25-01261"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Soska</surname><given-names>K.C.</given-names></name>
<name><surname>Adolph</surname><given-names>K.E.</given-names></name>
</person-group><article-title>Postural Position Constrains Multimodal Object Exploration in Infants</article-title><source>Infancy</source><year>2014</year><volume>19</volume><fpage>138</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1111/infa.12039</pub-id><pub-id pub-id-type="pmid">24639621</pub-id>
</element-citation></ref><ref id="B7-sensors-25-01261"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Alamoudi</surname><given-names>N.A.</given-names></name>
<name><surname>Algabbani</surname><given-names>M.F.</given-names></name>
<name><surname>Al-Heizan</surname><given-names>M.O.</given-names></name>
<name><surname>Alhusaini</surname><given-names>A.A.</given-names></name>
</person-group><article-title>Physical activity and sedentary behavior among ambulatory children with cerebral palsy using accelerometer: A cross-sectional study</article-title><source>Front. Pediatr.</source><year>2024</year><volume>12</volume><elocation-id>1463288</elocation-id><pub-id pub-id-type="doi">10.3389/fped.2024.1463288</pub-id><pub-id pub-id-type="pmid">39363968</pub-id>
</element-citation></ref><ref id="B8-sensors-25-01261"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Palisano</surname><given-names>R.</given-names></name>
<name><surname>Rosenbaum</surname><given-names>P.</given-names></name>
<name><surname>Walter</surname><given-names>S.</given-names></name>
<name><surname>Russell</surname><given-names>D.</given-names></name>
<name><surname>Wood</surname><given-names>E.</given-names></name>
<name><surname>Galuppi</surname><given-names>B.</given-names></name>
</person-group><article-title>Development and reliability of a system to classify gross motor function in children with cerebral palsy</article-title><source>Dev. Med. Child. Neurol.</source><year>1997</year><volume>39</volume><fpage>214</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8749.1997.tb07414.x</pub-id><pub-id pub-id-type="pmid">9183258</pub-id>
</element-citation></ref><ref id="B9-sensors-25-01261"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Keawutan</surname><given-names>P.</given-names></name>
<name><surname>Bell</surname><given-names>K.L.</given-names></name>
<name><surname>Oftedal</surname><given-names>S.</given-names></name>
<name><surname>Ware</surname><given-names>R.S.</given-names></name>
<name><surname>Stevenson</surname><given-names>R.D.</given-names></name>
<name><surname>Davies</surname><given-names>P.S.W.</given-names></name>
<name><surname>Boyd</surname><given-names>R.N.</given-names></name>
</person-group><article-title>Longitudinal physical activity and sedentary behaviour in preschool-aged children with cerebral palsy across all functional levels</article-title><source>Dev. Med. Child. Neurol.</source><year>2017</year><volume>59</volume><fpage>852</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1111/dmcn.13439</pub-id><pub-id pub-id-type="pmid">28432680</pub-id>
</element-citation></ref><ref id="B10-sensors-25-01261"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Oftedal</surname><given-names>S.</given-names></name>
<name><surname>Bell</surname><given-names>K.L.</given-names></name>
<name><surname>Davies</surname><given-names>P.S.W.</given-names></name>
<name><surname>Ware</surname><given-names>R.S.</given-names></name>
<name><surname>Boyd</surname><given-names>R.N.</given-names></name>
</person-group><article-title>Sedentary and Active Time in Toddlers with and without Cerebral Palsy</article-title><source>Med. Sci. Sports Exerc.</source><year>2015</year><volume>47</volume><fpage>2076</fpage><lpage>2083</lpage><pub-id pub-id-type="doi">10.1249/MSS.0000000000000653</pub-id><pub-id pub-id-type="pmid">26378944</pub-id>
</element-citation></ref><ref id="B11-sensors-25-01261"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Abbruzzese</surname><given-names>L.D.</given-names></name>
<name><surname>Yamane</surname><given-names>N.</given-names></name>
<name><surname>Fein</surname><given-names>D.</given-names></name>
<name><surname>Naigles</surname><given-names>L.</given-names></name>
<name><surname>Goldman</surname><given-names>S.</given-names></name>
</person-group><article-title>Assessing Child Postural Variability: Development, Feasibility, and Reliability of a Video Coding System</article-title><source>Phys. Occup. Ther. Pediatr.</source><year>2020</year><volume>41</volume><fpage>314</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1080/01942638.2020.1833272</pub-id><pub-id pub-id-type="pmid">33063576</pub-id>
</element-citation></ref><ref id="B12-sensors-25-01261"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bril</surname><given-names>B.</given-names></name>
<name><surname>Sabatier</surname><given-names>C.</given-names></name>
</person-group><article-title>The Cultural-Context of Motor Development&#x02014;Postural Manipulations in the Daily Life of Bambara Babies (MALI)</article-title><source>Int. J. Behav. Dev.</source><year>1986</year><volume>9</volume><fpage>439</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1177/016502548600900403</pub-id></element-citation></ref><ref id="B13-sensors-25-01261"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ahmadi</surname><given-names>M.N.</given-names></name>
<name><surname>O&#x02019;Neil</surname><given-names>M.E.</given-names></name>
<name><surname>Baque</surname><given-names>E.</given-names></name>
<name><surname>Boyd</surname><given-names>R.N.</given-names></name>
<name><surname>Trost</surname><given-names>S.G.</given-names></name>
</person-group><article-title>Machine Learning to Quantify Physical Activity in Children with Cerebral Palsy: Comparison of Group, Group-Personalized, and Fully-Personalized Activity Classification Models</article-title><source>Sensors</source><year>2020</year><volume>20</volume><elocation-id>3976</elocation-id><pub-id pub-id-type="doi">10.3390/s20143976</pub-id><pub-id pub-id-type="pmid">32708963</pub-id>
</element-citation></ref><ref id="B14-sensors-25-01261"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Albert</surname><given-names>M.V.</given-names></name>
<name><surname>Sugianto</surname><given-names>A.</given-names></name>
<name><surname>Nickele</surname><given-names>K.</given-names></name>
<name><surname>Zavos</surname><given-names>P.</given-names></name>
<name><surname>Sindu</surname><given-names>P.</given-names></name>
<name><surname>Ali</surname><given-names>M.</given-names></name>
<name><surname>Kwon</surname><given-names>S.</given-names></name>
</person-group><article-title>Hidden Markov model-based activity recognition for toddlers</article-title><source>Physiol. Meas.</source><year>2020</year><volume>41</volume><fpage>025003</fpage><pub-id pub-id-type="doi">10.1088/1361-6579/ab6ebb</pub-id><pub-id pub-id-type="pmid">32142480</pub-id>
</element-citation></ref><ref id="B15-sensors-25-01261"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kwon</surname><given-names>S.</given-names></name>
<name><surname>Sindu</surname><given-names>P.</given-names></name>
<name><surname>Nickele</surname><given-names>K.</given-names></name>
<name><surname>Zavos</surname><given-names>P.</given-names></name>
<name><surname>Sugianto</surname><given-names>A.</given-names></name>
<name><surname>Albert</surname><given-names>M.V.</given-names></name>
</person-group><article-title>Accelerometer-Based Activity Classification Algorithm for Toddlers: Machine Learning Approach</article-title><source>Med. Sci. Sports Exerc.</source><year>2019</year><volume>51</volume><fpage>363</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.1249/01.mss.0000561596.79242.c7</pub-id></element-citation></ref><ref id="B16-sensors-25-01261"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kwon</surname><given-names>S.</given-names></name>
<name><surname>Zavos</surname><given-names>P.</given-names></name>
<name><surname>Nickele</surname><given-names>K.</given-names></name>
<name><surname>Sugianto</surname><given-names>A.</given-names></name>
<name><surname>Albert</surname><given-names>M.V.</given-names></name>
</person-group><article-title>Hip and Wrist-Worn Accelerometer Data Analysis for Toddler Activities</article-title><source>Int. J. Environ. Res. Public Health</source><year>2019</year><volume>16</volume><elocation-id>2598</elocation-id><pub-id pub-id-type="doi">10.3390/ijerph16142598</pub-id><pub-id pub-id-type="pmid">31330889</pub-id>
</element-citation></ref><ref id="B17-sensors-25-01261"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Welch</surname><given-names>S.B.</given-names></name>
<name><surname>Honegger</surname><given-names>K.</given-names></name>
<name><surname>O&#x02019;Brien</surname><given-names>M.</given-names></name>
<name><surname>Capan</surname><given-names>S.</given-names></name>
<name><surname>Kwon</surname><given-names>S.</given-names></name>
<name><surname>Welch</surname><given-names>S.B.</given-names></name>
<name><surname>Honegger</surname><given-names>K.</given-names></name>
<name><surname>O&#x02019;Brien</surname><given-names>M.</given-names></name>
<name><surname>Capan</surname><given-names>S.</given-names></name>
<name><surname>Kwon</surname><given-names>S.</given-names></name>
</person-group><article-title>Examination of physical activity development in early childhood: Protocol for a longitudinal cohort study of mother-toddler dyads</article-title><source>BMC Pediatrics</source><year>2023</year><volume>23</volume><elocation-id>129</elocation-id><pub-id pub-id-type="doi">10.1186/s12887-023-03910-9</pub-id><pub-id pub-id-type="pmid">36941567</pub-id>
</element-citation></ref><ref id="B18-sensors-25-01261"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bennetts</surname><given-names>S.K.</given-names></name>
<name><surname>Mensah</surname><given-names>F.K.</given-names></name>
<name><surname>Green</surname><given-names>J.</given-names></name>
<name><surname>Hackworth</surname><given-names>N.J.</given-names></name>
<name><surname>Westrupp</surname><given-names>E.M.</given-names></name>
<name><surname>Reilly</surname><given-names>S.</given-names></name>
</person-group><article-title>Mothers&#x02019; Experiences of Parent-Reported and Video-Recorded Observational Assessments</article-title><source>J. Child. Fam. Stud.</source><year>2017</year><volume>26</volume><fpage>3312</fpage><lpage>3326</lpage><pub-id pub-id-type="doi">10.1007/s10826-017-0826-1</pub-id></element-citation></ref><ref id="B19-sensors-25-01261"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Friesen</surname><given-names>K.B.</given-names></name>
<name><surname>Zhang</surname><given-names>Z.T.</given-names></name>
<name><surname>Monaghan</surname><given-names>P.G.</given-names></name>
<name><surname>Oliver</surname><given-names>G.D.</given-names></name>
<name><surname>Roper</surname><given-names>J.A.</given-names></name>
</person-group><article-title>All eyes on you: How researcher presence changes the way you walk</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><elocation-id>17159</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-73734-5</pub-id><pub-id pub-id-type="pmid">33051502</pub-id>
</element-citation></ref><ref id="B20-sensors-25-01261"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hager</surname><given-names>E.R.</given-names></name>
<name><surname>Gormley</surname><given-names>C.E.</given-names></name>
<name><surname>Latta</surname><given-names>L.W.</given-names></name>
<name><surname>Treuth</surname><given-names>M.S.</given-names></name>
<name><surname>Caulfield</surname><given-names>L.E.</given-names></name>
<name><surname>Black</surname><given-names>M.M.</given-names></name>
</person-group><article-title>Toddler physical activity study: Laboratory and community studies to evaluate accelerometer validity and correlates</article-title><source>BMC Public Health</source><year>2016</year><volume>16</volume><fpage>936</fpage><pub-id pub-id-type="doi">10.1186/s12889-016-3569-9</pub-id><pub-id pub-id-type="pmid">27600404</pub-id>
</element-citation></ref><ref id="B21-sensors-25-01261"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>O&#x02019;Neil</surname><given-names>M.E.</given-names></name>
<name><surname>Fragala-Pinkham</surname><given-names>M.A.</given-names></name>
<name><surname>Forman</surname><given-names>J.L.</given-names></name>
<name><surname>Trost</surname><given-names>S.G.</given-names></name>
</person-group><article-title>Measuring reliability and validity of the ActiGraph GT3X accelerometer for children with cerebral palsy: A feasibility study</article-title><source>J. Pediatr. Rehabil. Med.</source><year>2014</year><volume>7</volume><fpage>233</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.3233/PRM-140292</pub-id><pub-id pub-id-type="pmid">25260506</pub-id>
</element-citation></ref><ref id="B22-sensors-25-01261"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cauwenberghe</surname><given-names>E.</given-names></name>
<name><surname>Gubbels</surname><given-names>J.</given-names></name>
<name><surname>De Bourdeaudhuij</surname><given-names>I.</given-names></name>
<name><surname>Cardon</surname><given-names>G.</given-names></name>
</person-group><article-title>Feasibility and validity of accelerometer measurements to assess physical activity in toddlers</article-title><source>Int. J. Behav. Nutr. Phys. Act.</source><year>2011</year><volume>8</volume><fpage>67</fpage><pub-id pub-id-type="doi">10.1186/1479-5868-8-67</pub-id><pub-id pub-id-type="pmid">21703004</pub-id>
</element-citation></ref><ref id="B23-sensors-25-01261"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Oftedal</surname><given-names>S.</given-names></name>
<name><surname>Bell</surname><given-names>K.L.</given-names></name>
<name><surname>Davies</surname><given-names>P.S.W.</given-names></name>
<name><surname>Ware</surname><given-names>R.S.</given-names></name>
<name><surname>Boyd</surname><given-names>R.N.</given-names></name>
</person-group><article-title>Validation of Accelerometer Cut Points in Toddlers with and without Cerebral Palsy</article-title><source>Med. Sci. Sports Exerc.</source><year>2014</year><volume>46</volume><fpage>1808</fpage><lpage>1815</lpage><pub-id pub-id-type="doi">10.1249/MSS.0000000000000299</pub-id><pub-id pub-id-type="pmid">25134003</pub-id>
</element-citation></ref><ref id="B24-sensors-25-01261"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Alhassan</surname><given-names>S.</given-names></name>
<name><surname>Sirard</surname><given-names>J.R.</given-names></name>
<name><surname>Kurdziel</surname><given-names>L.B.F.</given-names></name>
<name><surname>Merrigan</surname><given-names>S.</given-names></name>
<name><surname>Greever</surname><given-names>C.</given-names></name>
<name><surname>Spencer</surname><given-names>R.M.C.</given-names></name>
</person-group><article-title>Cross-Validation of Two Accelerometers for Assessment of Physical Activity and Sedentary Time in Preschool Children</article-title><source>Pediatr. Exerc. Sci.</source><year>2017</year><volume>29</volume><fpage>268</fpage><lpage>277</lpage><pub-id pub-id-type="doi">10.1123/pes.2016-0074</pub-id><pub-id pub-id-type="pmid">28290759</pub-id>
</element-citation></ref><ref id="B25-sensors-25-01261"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Greever</surname><given-names>C.J.</given-names></name>
<name><surname>Sirard</surname><given-names>J.</given-names></name>
<name><surname>Alhassan</surname><given-names>S.</given-names></name>
</person-group><article-title>Objective Analysis of Preschoolers&#x02019; Physical Activity Patterns During Free Playtime</article-title><source>J. Phys. Act. Health</source><year>2015</year><volume>12</volume><fpage>1253</fpage><lpage>1258</lpage><pub-id pub-id-type="doi">10.1123/jpah.2014-0307</pub-id><pub-id pub-id-type="pmid">25966497</pub-id>
</element-citation></ref><ref id="B26-sensors-25-01261"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Thelen</surname><given-names>E.</given-names></name>
<name><surname>Fisher</surname><given-names>D.M.</given-names></name>
</person-group><article-title>Newborn stepping: An explanation for a &#x0201c;disappearing&#x0201d; reflex</article-title><source>Dev. Psychol.</source><year>1982</year><volume>18</volume><fpage>760</fpage><lpage>775</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.18.5.760</pub-id></element-citation></ref><ref id="B27-sensors-25-01261"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Prioreschi</surname><given-names>A.</given-names></name>
<name><surname>Micklesfield</surname><given-names>L.K.</given-names></name>
</person-group><article-title>A scoping review examining physical activity measurement and levels in the first 2 years of life</article-title><source>Child. Care Health Dev.</source><year>2016</year><volume>42</volume><fpage>775</fpage><lpage>783</lpage><pub-id pub-id-type="doi">10.1111/cch.12382</pub-id><pub-id pub-id-type="pmid">27491934</pub-id>
</element-citation></ref><ref id="B28-sensors-25-01261"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xiong</surname><given-names>J.</given-names></name>
<name><surname>Reedman</surname><given-names>S.E.</given-names></name>
<name><surname>Kho</surname><given-names>M.E.</given-names></name>
<name><surname>Timmons</surname><given-names>B.W.</given-names></name>
<name><surname>Verschuren</surname><given-names>O.</given-names></name>
<name><surname>Gorter</surname><given-names>J.W.</given-names></name>
</person-group><article-title>Operationalization, measurement, and health indicators of sedentary behavior in individuals with cerebral palsy: A scoping review</article-title><source>Disabil. Rehabil.</source><year>2021</year><volume>44</volume><fpage>6070</fpage><lpage>6081</lpage><pub-id pub-id-type="doi">10.1080/09638288.2021.1949050</pub-id><pub-id pub-id-type="pmid">34334077</pub-id>
</element-citation></ref><ref id="B29-sensors-25-01261"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hurter</surname><given-names>L.</given-names></name>
<name><surname>Fairclough</surname><given-names>S.J.</given-names></name>
<name><surname>Knowles</surname><given-names>Z.R.</given-names></name>
<name><surname>Porcellato</surname><given-names>L.A.</given-names></name>
<name><surname>Cooper-Ryan</surname><given-names>A.M.</given-names></name>
<name><surname>Boddy</surname><given-names>L.M.</given-names></name>
</person-group><article-title>Establishing Raw Acceleration Thresholds to Classify Sedentary and Stationary Behaviour in Children</article-title><source>Children</source><year>2018</year><volume>5</volume><elocation-id>172</elocation-id><pub-id pub-id-type="doi">10.3390/children5120172</pub-id><pub-id pub-id-type="pmid">30572683</pub-id>
</element-citation></ref><ref id="B30-sensors-25-01261"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Trost</surname><given-names>S.G.</given-names></name>
<name><surname>Cliff</surname><given-names>D.P.</given-names></name>
<name><surname>Ahmadi</surname><given-names>M.N.</given-names></name>
<name><surname>Tuc</surname><given-names>N.V.</given-names></name>
<name><surname>Hagenbuchner</surname><given-names>M.</given-names></name>
</person-group><article-title>Sensor-enabled Activity Class Recognition in Preschoolers: Hip versus Wrist Data</article-title><source>Med. Sci. Sports Exerc.</source><year>2018</year><volume>50</volume><fpage>634</fpage><lpage>641</lpage><pub-id pub-id-type="doi">10.1249/MSS.0000000000001460</pub-id><pub-id pub-id-type="pmid">29059107</pub-id>
</element-citation></ref><ref id="B31-sensors-25-01261"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Trost</surname><given-names>S.G.</given-names></name>
<name><surname>Fees</surname><given-names>B.S.</given-names></name>
<name><surname>Haar</surname><given-names>S.J.</given-names></name>
<name><surname>Murray</surname><given-names>A.D.</given-names></name>
<name><surname>Crowe</surname><given-names>L.K.</given-names></name>
</person-group><article-title>Identification and Validity of Accelerometer Cut-Points for Toddlers</article-title><source>Obesity</source><year>2012</year><volume>20</volume><fpage>2317</fpage><lpage>2319</lpage><pub-id pub-id-type="doi">10.1038/oby.2011.364</pub-id><pub-id pub-id-type="pmid">22173573</pub-id>
</element-citation></ref><ref id="B32-sensors-25-01261"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bruijns</surname><given-names>B.A.</given-names></name>
<name><surname>Truelove</surname><given-names>S.</given-names></name>
<name><surname>Johnson</surname><given-names>A.M.</given-names></name>
<name><surname>Gilliland</surname><given-names>J.</given-names></name>
<name><surname>Tucker</surname><given-names>P.</given-names></name>
</person-group><article-title>Infants&#x02019; and toddlers&#x02019; physical activity and sedentary time as measured by accelerometry: A systematic review and meta-analysis</article-title><source>Int. J. Behav. Nutr. Phys. Act.</source><year>2020</year><volume>17</volume><fpage>14</fpage><pub-id pub-id-type="doi">10.1186/s12966-020-0912-4</pub-id><pub-id pub-id-type="pmid">32028975</pub-id>
</element-citation></ref><ref id="B33-sensors-25-01261"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Greenspan</surname><given-names>B.</given-names></name>
<name><surname>Cunha</surname><given-names>A.B.</given-names></name>
<name><surname>Lobo</surname><given-names>M.A.</given-names></name>
</person-group><article-title>Design and validation of a smart garment to measure positioning practices of parents with young infants</article-title><source>Infant. Behav. Dev.</source><year>2021</year><volume>62</volume><fpage>101530</fpage><pub-id pub-id-type="doi">10.1016/j.infbeh.2021.101530</pub-id><pub-id pub-id-type="pmid">33548894</pub-id>
</element-citation></ref><ref id="B34-sensors-25-01261"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Airaksinen</surname><given-names>M.</given-names></name>
<name><surname>Rasanen</surname><given-names>O.</given-names></name>
<name><surname>Ilen</surname><given-names>E.</given-names></name>
<name><surname>Hayrinen</surname><given-names>T.</given-names></name>
<name><surname>Kivi</surname><given-names>A.</given-names></name>
<name><surname>Marchi</surname><given-names>V.</given-names></name>
<name><surname>Gallen</surname><given-names>A.</given-names></name>
<name><surname>Blom</surname><given-names>S.</given-names></name>
<name><surname>Varhe</surname><given-names>A.</given-names></name>
<name><surname>Kaartinen</surname><given-names>N.</given-names></name>
<etal/>
</person-group><article-title>Automatic Posture and Movement Tracking of Infants with Wearable Movement Sensors</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><fpage>169</fpage><pub-id pub-id-type="doi">10.1038/s41598-019-56862-5</pub-id><pub-id pub-id-type="pmid">31932616</pub-id>
</element-citation></ref><ref id="B35-sensors-25-01261"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Airaksinen</surname><given-names>M.</given-names></name>
<name><surname>Taylor</surname><given-names>E.</given-names></name>
<name><surname>Gallen</surname><given-names>A.</given-names></name>
<name><surname>Il&#x000e9;n</surname><given-names>E.</given-names></name>
<name><surname>Saari</surname><given-names>A.</given-names></name>
<name><surname>Sankilampi</surname><given-names>U.</given-names></name>
<name><surname>R&#x000e4;s&#x000e4;nen</surname><given-names>O.</given-names></name>
<name><surname>Haataja</surname><given-names>L.M.</given-names></name>
<name><surname>Vanhatalo</surname><given-names>S.</given-names></name>
</person-group><article-title>Charting infants&#x02019; motor development at home using a wearable system: Validation and comparison to physical growth charts</article-title><source>eBioMedicine</source><year>2023</year><volume>92</volume><elocation-id>104591</elocation-id><pub-id pub-id-type="doi">10.1016/j.ebiom.2023.104591</pub-id><pub-id pub-id-type="pmid">37137181</pub-id>
</element-citation></ref><ref id="B36-sensors-25-01261"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Trujillo-Priego</surname><given-names>I.A.</given-names></name>
<name><surname>Smith</surname><given-names>B.A.</given-names></name>
</person-group><article-title>Kinematic characteristics of infant leg movements produced across a full day</article-title><source>J. Rehabil. Assist. Technol. Eng.</source><year>2017</year><volume>4</volume><fpage>2055668317717461</fpage><pub-id pub-id-type="doi">10.1177/2055668317717461</pub-id><pub-id pub-id-type="pmid">28845239</pub-id>
</element-citation></ref><ref id="B37-sensors-25-01261"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Smith</surname><given-names>B.A.</given-names></name>
<name><surname>Trujillo-Priego</surname><given-names>I.A.</given-names></name>
<name><surname>Lane</surname><given-names>C.J.</given-names></name>
<name><surname>Finley</surname><given-names>J.M.</given-names></name>
<name><surname>Horak</surname><given-names>F.B.</given-names></name>
</person-group><article-title>Daily Quantity of Infant Leg Movement: Wearable Sensor Algorithm and Relationship to Walking Onset</article-title><source>Sensors</source><year>2015</year><volume>15</volume><fpage>19006</fpage><lpage>19020</lpage><pub-id pub-id-type="doi">10.3390/s150819006</pub-id><pub-id pub-id-type="pmid">26247951</pub-id>
</element-citation></ref><ref id="B38-sensors-25-01261"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ghazi</surname><given-names>M.A.</given-names></name>
<name><surname>Zhou</surname><given-names>J.</given-names></name>
<name><surname>Havens</surname><given-names>K.L.</given-names></name>
<name><surname>Smith</surname><given-names>B.A.</given-names></name>
</person-group><article-title>Accelerometer Thresholds for Estimating Physical Activity Intensity Levels in Infants: A Preliminary Study</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>4436</elocation-id><pub-id pub-id-type="doi">10.3390/s24144436</pub-id><pub-id pub-id-type="pmid">39065833</pub-id>
</element-citation></ref><ref id="B39-sensors-25-01261"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Prosser</surname><given-names>L.A.</given-names></name>
<name><surname>Skorup</surname><given-names>J.</given-names></name>
<name><surname>Pierce</surname><given-names>S.R.</given-names></name>
<name><surname>Jawad</surname><given-names>A.F.</given-names></name>
<name><surname>Fagg</surname><given-names>A.H.</given-names></name>
<name><surname>Kolobe</surname><given-names>T.H.A.</given-names></name>
<name><surname>Smith</surname><given-names>B.A.</given-names></name>
</person-group><article-title>Locomotor learning in infants at high risk for cerebral palsy: A study protocol</article-title><source>Front. Pediatr.</source><year>2023</year><volume>11</volume><elocation-id>891633</elocation-id><pub-id pub-id-type="doi">10.3389/fped.2023.891633</pub-id><pub-id pub-id-type="pmid">36911033</pub-id>
</element-citation></ref><ref id="B40-sensors-25-01261"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Prosser</surname><given-names>L.A.</given-names></name>
<name><surname>Pierce</surname><given-names>S.R.</given-names></name>
<name><surname>Dillingham</surname><given-names>T.R.</given-names></name>
<name><surname>Bernbaum</surname><given-names>J.C.</given-names></name>
<name><surname>Jawad</surname><given-names>A.F.</given-names></name>
</person-group><article-title>iMOVE: Intensive Mobility training with Variability and Error compared to conventional rehabilitation for young children with cerebral palsy: The protocol for a single blind randomized controlled trial</article-title><source>BMC Pediatr.</source><year>2018</year><volume>18</volume><elocation-id>329</elocation-id><pub-id pub-id-type="doi">10.1186/s12887-018-1303-8</pub-id><pub-id pub-id-type="pmid">30326883</pub-id>
</element-citation></ref><ref id="B41-sensors-25-01261"><label>41.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<collab>Datavyu Team</collab>
</person-group><article-title>Datavyu: A Video Coding Tool</article-title><year>2014</year><comment>Available online: <ext-link xlink:href="http://datavyu.org" ext-link-type="uri">http://datavyu.org</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-16">(accessed on 16 February 2025)</date-in-citation></element-citation></ref><ref id="B42-sensors-25-01261"><label>42.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Holmstrom</surname><given-names>L.</given-names></name>
</person-group><article-title>Using Orientation Estimates to Convert from Sensor Frame to Earth Frame of Reference</article-title><comment>Available online: <ext-link xlink:href="https://support.apdm.com/hc/en-us/articles/214504186-Using-orientation-estimates-to-convert-from-sensor-frame-to-Earth-frame-of-refernce" ext-link-type="uri">https://support.apdm.com/hc/en-us/articles/214504186-Using-orientation-estimates-to-convert-from-sensor-frame-to-Earth-frame-of-refernce</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2021-09-30">(accessed on 30 September 2021)</date-in-citation></element-citation></ref><ref id="B43-sensors-25-01261"><label>43.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Winter</surname><given-names>D.A.</given-names></name>
</person-group><source>Biomechanics and Motor Control of Human Movement</source><publisher-name>John Wiley &#x00026; Sons</publisher-name><publisher-loc>Hoboken, NJ, USA</publisher-loc><year>2009</year></element-citation></ref><ref id="B44-sensors-25-01261"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhou</surname><given-names>J.D.</given-names></name>
<name><surname>Schaefer</surname><given-names>S.Y.</given-names></name>
<name><surname>Smith</surname><given-names>B.A.</given-names></name>
</person-group><article-title>Quantifying Caregiver Movement when Measuring Infant Movement across a Full Day: A Case Report</article-title><source>Sensors</source><year>2019</year><volume>19</volume><elocation-id>2886</elocation-id><pub-id pub-id-type="doi">10.3390/s19132886</pub-id><pub-id pub-id-type="pmid">31261884</pub-id>
</element-citation></ref><ref id="B45-sensors-25-01261"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Worobey</surname><given-names>J.</given-names></name>
<name><surname>Vetrini</surname><given-names>N.R.</given-names></name>
<name><surname>Rozo</surname><given-names>E.M.</given-names></name>
</person-group><article-title>Mechanical measurement of infant activity: A cautionary note</article-title><source>Infant. Behav. Dev.</source><year>2009</year><volume>32</volume><fpage>167</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1016/j.infbeh.2008.12.003</pub-id><pub-id pub-id-type="pmid">19178947</pub-id>
</element-citation></ref><ref id="B46-sensors-25-01261"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Airaksinen</surname><given-names>M.</given-names></name>
<name><surname>Vaaras</surname><given-names>E.</given-names></name>
<name><surname>Haataja</surname><given-names>L.</given-names></name>
<name><surname>R&#x000e4;s&#x000e4;nen</surname><given-names>O.</given-names></name>
<name><surname>Vanhatalo</surname><given-names>S.</given-names></name>
</person-group><article-title>Automatic assessment of infant carrying and holding using at-home wearable recordings</article-title><source>Sci. Rep.</source><year>2024</year><volume>14</volume><fpage>4852</fpage><pub-id pub-id-type="doi">10.1038/s41598-024-54536-5</pub-id><pub-id pub-id-type="pmid">38418850</pub-id>
</element-citation></ref><ref id="B47-sensors-25-01261"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lee</surname><given-names>I.M.</given-names></name>
<name><surname>Shiroma</surname><given-names>E.J.</given-names></name>
</person-group><article-title>Using accelerometers to measure physical activity in large-scale epidemiological studies: Issues and challenges</article-title><source>Br. J. Sports Med.</source><year>2014</year><volume>48</volume><fpage>197</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1136/bjsports-2013-093154</pub-id><pub-id pub-id-type="pmid">24297837</pub-id>
</element-citation></ref><ref id="B48-sensors-25-01261"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Franchak</surname><given-names>J.M.</given-names></name>
<name><surname>Scott</surname><given-names>V.</given-names></name>
<name><surname>Luo</surname><given-names>C.</given-names></name>
</person-group><article-title>A Contactless Method for Measuring Full-Day, Naturalistic Motor Behavior Using Wearable Inertial Sensors</article-title><source>Front. Psychol.</source><year>2021</year><volume>12</volume><elocation-id>701343</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2021.701343</pub-id><pub-id pub-id-type="pmid">34744865</pub-id>
</element-citation></ref><ref id="B49-sensors-25-01261"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Franchak</surname><given-names>J.M.</given-names></name>
</person-group><article-title>Changing Opportunities for Learning in Everyday Life: Infant Body Position Over the First Year</article-title><source>Infancy</source><year>2019</year><volume>24</volume><fpage>187</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1111/infa.12272</pub-id><pub-id pub-id-type="pmid">32677202</pub-id>
</element-citation></ref><ref id="B50-sensors-25-01261"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Rosales</surname><given-names>M.R.</given-names></name>
<name><surname>Rohloff</surname><given-names>P.</given-names></name>
<name><surname>Vanderbilt</surname><given-names>D.L.</given-names></name>
<name><surname>Tripathi</surname><given-names>T.</given-names></name>
<name><surname>Valentini</surname><given-names>N.C.</given-names></name>
<name><surname>Dusing</surname><given-names>S.</given-names></name>
<name><surname>Smith</surname><given-names>B.A.</given-names></name>
</person-group><article-title>Collecting Infant Environmental and Experiential Data Using Smartphone Surveys</article-title><source>Pediatr. Phys. Ther.</source><year>2021</year><volume>33</volume><fpage>47</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1097/PEP.0000000000000766</pub-id><pub-id pub-id-type="pmid">33337776</pub-id>
</element-citation></ref><ref id="B51-sensors-25-01261"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Nam</surname><given-names>Y.</given-names></name>
<name><surname>Park</surname><given-names>J.W.</given-names></name>
</person-group><article-title>Child Activity Recognition Based on Cooperative Fusion Model of a Triaxial Accelerometer and a Barometric Pressure Sensor</article-title><source>IEEE J. Biomed. Health Inform.</source><year>2013</year><volume>17</volume><fpage>420</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1109/jbhi.2012.2235075</pub-id><pub-id pub-id-type="pmid">24235114</pub-id>
</element-citation></ref><ref id="B52-sensors-25-01261"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hagenbuchner</surname><given-names>M.</given-names></name>
<name><surname>Cliff</surname><given-names>D.P.</given-names></name>
<name><surname>Trost</surname><given-names>S.G.</given-names></name>
<name><surname>Tuc</surname><given-names>N.V.</given-names></name>
<name><surname>Peoples</surname><given-names>G.E.</given-names></name>
</person-group><article-title>Prediction of activity type in preschool children using machine learning techniques</article-title><source>J. Sci. Med. Sport.</source><year>2015</year><volume>18</volume><fpage>426</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/j.jsams.2014.06.003</pub-id><pub-id pub-id-type="pmid">25088983</pub-id>
</element-citation></ref><ref id="B53-sensors-25-01261"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>W.</given-names></name>
<name><surname>Adolph</surname><given-names>A.L.</given-names></name>
<name><surname>Puyau</surname><given-names>M.R.</given-names></name>
<name><surname>Vohra</surname><given-names>F.A.</given-names></name>
<name><surname>Butte</surname><given-names>N.F.</given-names></name>
<name><surname>Zakeri</surname><given-names>I.F.</given-names></name>
</person-group><article-title>Support vector machines classifiers of physical activities in preschoolers</article-title><source>Physiol. Rep.</source><year>2013</year><volume>1</volume><fpage>e00006</fpage><pub-id pub-id-type="doi">10.1002/phy2.6</pub-id><pub-id pub-id-type="pmid">24303099</pub-id>
</element-citation></ref><ref id="B54-sensors-25-01261"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kang</surname><given-names>L.J.</given-names></name>
<name><surname>Hsieh</surname><given-names>M.C.</given-names></name>
<name><surname>Liao</surname><given-names>H.F.</given-names></name>
<name><surname>Hwang</surname><given-names>A.W.</given-names></name>
</person-group><article-title>Environmental Barriers to Participation of Preschool Children with and without Physical Disabilities</article-title><source>Int. J. Environ. Res. Public. Health</source><year>2017</year><volume>14</volume><elocation-id>518</elocation-id><pub-id pub-id-type="doi">10.3390/ijerph14050518</pub-id><pub-id pub-id-type="pmid">28492518</pub-id>
</element-citation></ref><ref id="B55-sensors-25-01261"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hwang</surname><given-names>Y.S.</given-names></name>
<name><surname>Kwon</surname><given-names>J.Y.</given-names></name>
</person-group><article-title>Effects of Modified Constraint-Induced Movement Therapy in Real-World Arm Use in Young Children with Unilateral Cerebral Palsy: A Single-Blind Randomized Trial</article-title><source>Neuropediatrics</source><year>2020</year><volume>51</volume><fpage>259</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1055/s-0040-1702220</pub-id><pub-id pub-id-type="pmid">32143221</pub-id>
</element-citation></ref><ref id="B56-sensors-25-01261"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Trujillo-Priego</surname><given-names>I.A.</given-names></name>
<name><surname>Lane</surname><given-names>C.J.</given-names></name>
<name><surname>Vanderbilt</surname><given-names>D.L.</given-names></name>
<name><surname>Deng</surname><given-names>W.Y.</given-names></name>
<name><surname>Loeb</surname><given-names>G.E.</given-names></name>
<name><surname>Shida</surname><given-names>J.</given-names></name>
<name><surname>Smith</surname><given-names>B.A.</given-names></name>
</person-group><article-title>Development of a Wearable Sensor Algorithm to Detect the Quantity and Kinematic Characteristics of Infant Arm Movement Bouts Produced across a Full Day in the Natural Environment</article-title><source>Technologies</source><year>2017</year><volume>5</volume><elocation-id>39</elocation-id><pub-id pub-id-type="doi">10.3390/technologies5030039</pub-id><pub-id pub-id-type="pmid">28824853</pub-id>
</element-citation></ref><ref id="B57-sensors-25-01261"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Orlando</surname><given-names>J.M.</given-names></name>
<name><surname>Pierce</surname><given-names>S.</given-names></name>
<name><surname>Mohan</surname><given-names>M.</given-names></name>
<name><surname>Skorup</surname><given-names>J.</given-names></name>
<name><surname>Paremski</surname><given-names>A.</given-names></name>
<name><surname>Bochnak</surname><given-names>M.</given-names></name>
<name><surname>Prosser</surname><given-names>L.A.</given-names></name>
</person-group><article-title>Physical activity in non-ambulatory toddlers with cerebral palsy</article-title><source>Res. Dev. Disabil.</source><year>2019</year><volume>90</volume><fpage>51</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/j.ridd.2019.04.002</pub-id><pub-id pub-id-type="pmid">31063871</pub-id>
</element-citation></ref><ref id="B58-sensors-25-01261"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Rachwani</surname><given-names>J.</given-names></name>
<name><surname>Santamaria</surname><given-names>V.</given-names></name>
<name><surname>Saavedra</surname><given-names>S.L.</given-names></name>
<name><surname>Woollacott</surname><given-names>M.H.</given-names></name>
</person-group><article-title>The development of trunk control and its relation to reaching in infancy: A longitudinal study</article-title><source>Front. Hum. Neurosci.</source><year>2015</year><volume>9</volume><elocation-id>94</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2015.00094</pub-id><pub-id pub-id-type="pmid">25759646</pub-id>
</element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01261-f001"><label>Figure 1</label><caption><p>Schematic of sensor placement. Sensors were placed on the lateral aspect of the child&#x02019;s dominant thigh. Created in BioRender. Orlando, J. (2024) <uri xlink:href="https://BioRender.com/l01b058">https://BioRender.com/l01b058</uri>.</p></caption><graphic xlink:href="sensors-25-01261-g001" position="float"/></fig><fig position="float" id="sensors-25-01261-f002"><label>Figure 2</label><caption><p>Data processing steps: (<bold>A</bold>) raw acceleration components with the x-axis in red, y-axis in green, and z-axis in blue; (<bold>B</bold>) raw acceleration transformed into the world frame of reference with gravity removed with the x-axis in red, y-axis in green, and z-axis in blue; (<bold>C</bold>) power spectral density results with the vertical blue line at 95% of the data; (<bold>D</bold>) filtered resultant acceleration magnitude.</p></caption><graphic xlink:href="sensors-25-01261-g002" position="float"/></fig><fig position="float" id="sensors-25-01261-f003"><label>Figure 3</label><caption><p>(<bold>A</bold>) Histogram showing the filtered resultant acceleration magnitude of the sensor data during active and sedentary time identified through the gold-standard behavioral coding of the development dataset with the x-axis limit set to 5, excluding higher accelerations with low counts. (<bold>B</bold>) Receiver operating characteristic curve in blue with the optimal threshold in red identified for the development dataset. The threshold was then tested with the validation dataset. (<bold>C</bold>) Histogram showing the filtered resultant acceleration magnitude of the sensor data for the development dataset during active and sedentary time identified by the threshold with the x-axis limit set to 5, excluding higher accelerations with low counts.</p></caption><graphic xlink:href="sensors-25-01261-g003" position="float"/></fig><fig position="float" id="sensors-25-01261-f004"><label>Figure 4</label><caption><p>(<bold>A</bold>) Time-series plot displaying the active time epochs identified by the gold-standard behavioral coding (purple) and sensor (green) methodologies for a participant in the validation dataset. (<bold>B</bold>) A subsection of the same time-series displaying examples of true positives [(the sum of the number of frames when the sensor method and the video coding method &#x000b1; four frames (i.e., 0.125 s) were both classified as active time/total number of frames) &#x000d7; 100], true negatives [(the sum of the number of frames when the sensor method and the video coding method &#x000b1; four frames (i.e., 0.125 s) were both classified as sedentary time/total number of frames) &#x000d7; 100], false positives [(the sum of the number of frames when the sensor method was classified as active and was not a true positive/total number of frames) &#x000d7; 100], and false negatives [(the sum of the number of frames when the sensor method was classified as sedentary and was not a true negative/total number of frames) &#x000d7; 100].</p></caption><graphic xlink:href="sensors-25-01261-g004" position="float"/></fig><table-wrap position="float" id="sensors-25-01261-t001"><object-id pub-id-type="pii">sensors-25-01261-t001_Table 1</object-id><label>Table 1</label><caption><p>Participant characteristics.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Participant</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sex</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Age (Months)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">GMFCS <sup>^</sup></th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21.9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">III</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">M</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">I</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">III</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">I</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">M</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9.4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">V</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">M</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">IV</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">II</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">F</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13.8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">I</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">M</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">I</td></tr></tbody></table><table-wrap-foot><fn><p><sup>^</sup> GMFCS = Gross Motor Function Classification System [<xref rid="B8-sensors-25-01261" ref-type="bibr">8</xref>].</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-01261-t002"><object-id pub-id-type="pii">sensors-25-01261-t002_Table 2</object-id><label>Table 2</label><caption><p>The optimal threshold and area under the curve for the development dataset and the confusion matrices using the optimal threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Study ID</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Optimal Threshold (m/s/s)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Area Under the Curve</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sum of True Positives and True Negatives <sup>+</sup></th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">True Positives <sup>+</sup> (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">True Negatives <sup>+</sup> (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">False Positives <sup>+</sup> (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">False Negatives <sup>+</sup> (%)</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1&#x02013;8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.417</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.60</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>75.1</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">27.9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">47.2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6.9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">17.9</td></tr></tbody></table><table-wrap-foot><fn><p><sup>+</sup> Tolerance of 0.125 s; bold font denotes a summary measure.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-01261-t003"><object-id pub-id-type="pii">sensors-25-01261-t003_Table 3</object-id><label>Table 3</label><caption><p>Confusion matrices for each participant in the validation dataset using the average threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Study ID</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sum of True Positives and True Negatives <sup>+</sup></th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">True Positives <sup>+</sup> (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">True Negatives <sup>+</sup> (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">False Positives <sup>+</sup> (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">False Negatives <sup>+</sup> (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sensitivity</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Specificity</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>92.2</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">17.0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.93</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.90</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>89.7</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">53.8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">35.9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6.1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.90</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.89</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mean</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>90.9</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">64.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">26.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.91</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.89</td></tr></tbody></table><table-wrap-foot><fn><p><sup>+</sup> Tolerance of 0.125 s; bold font denotes a summary measure.</p></fn></table-wrap-foot></table-wrap></floats-group></article>