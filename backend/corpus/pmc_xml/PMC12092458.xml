<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="systematic-review"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Med (Lausanne)</journal-id><journal-id journal-id-type="iso-abbrev">Front Med (Lausanne)</journal-id><journal-id journal-id-type="publisher-id">Front. Med.</journal-id><journal-title-group><journal-title>Frontiers in Medicine</journal-title></journal-title-group><issn pub-type="epub">2296-858X</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40400628</article-id><article-id pub-id-type="pmc">PMC12092458</article-id><article-id pub-id-type="doi">10.3389/fmed.2025.1519768</article-id><article-categories><subj-group subj-group-type="heading"><subject>Medicine</subject><subj-group><subject>Systematic Review</subject></subj-group></subj-group></article-categories><title-group><article-title>Artificial intelligence versus manual screening for the detection of diabetic retinopathy: a comparative systematic review and meta-analysis</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Tahir</surname><given-names>Hasan Nawaz</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Ullah</surname><given-names>Naseer</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="c002" ref-type="corresp">
<sup>*</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2882473/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author"><name><surname>Tahir</surname><given-names>Mursala</given-names></name><xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Domnic</surname><given-names>Inbaraj Susai</given-names></name><xref rid="aff4" ref-type="aff">
<sup>4</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Prabhakar</surname><given-names>Ramaprabha</given-names></name><xref rid="aff5" ref-type="aff">
<sup>5</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/validation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Meerasa</surname><given-names>Semmal Syed</given-names></name><xref rid="aff5" ref-type="aff">
<sup>5</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>AbdElneam</surname><given-names>Ahmed Ibrahim</given-names></name><xref rid="aff6" ref-type="aff">
<sup>6</sup>
</xref><xref rid="aff7" ref-type="aff">
<sup>7</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Tahir</surname><given-names>Shahnawaz</given-names></name><xref rid="aff8" ref-type="aff">
<sup>8</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Ali</surname><given-names>Yousaf</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><uri xlink:href="https://loop.frontiersin.org/people/2991842/overview"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Community Medicine, College of Medicine, Dwadimi, Shaqra University</institution>, <addr-line>Shaqra</addr-line>, <country>Saudi Arabia</country></aff><aff id="aff2"><sup>2</sup><institution>Department of Community Medicine, Khyber Medical College Peshawar</institution>, <addr-line>Peshawar</addr-line>, <country>Pakistan</country></aff><aff id="aff3"><sup>3</sup><institution>Department of Community Medicine, Liaquat National Hospital and Medical College, Jinnah Sindh Medical University</institution>, <addr-line>Karachi</addr-line>, <country>Pakistan</country></aff><aff id="aff4"><sup>4</sup><institution>Department of Pharmacology, College of Medicine, Dwadimi, Shaqra University</institution>, <addr-line>Shaqra</addr-line>, <country>Saudi Arabia</country></aff><aff id="aff5"><sup>5</sup><institution>Department of Physiology, College of Medicine, Shaqra University</institution>, <addr-line>Shaqra</addr-line>, <country>Saudi Arabia</country></aff><aff id="aff6"><sup>6</sup><institution>Departments of Clinical Biochemistry and Basic Medical Sciences, College of Medicine, Dwadimi, Shaqra University</institution>, <addr-line>Shaqra</addr-line>, <country>Saudi Arabia</country></aff><aff id="aff7"><sup>7</sup><institution>Molecular Genetics and Enzymology Department, Human Genetics and Genome Research Institute, National Research Center, Dokki</institution>, <addr-line>Cairo</addr-line>, <country>Egypt</country></aff><aff id="aff8"><sup>8</sup><institution>Department of Gastroenterology, Dow University of Health Sciences</institution>, <addr-line>Karachi</addr-line>, <country>Pakistan</country></aff><author-notes><fn fn-type="edited-by" id="fn0001"><p>Edited by: Yanwu Xu, Baidu, China</p></fn><fn fn-type="edited-by" id="fn0002"><p>Reviewed by: Xiuju Chen, Xiamen University, China</p><p>Rajalakshmi R., Madras Diabetes Research Foundation, India</p></fn><corresp id="c001">*Correspondence: Hasan Nawaz Tahir, <email>hasan.nawaz@su.edu.sa</email></corresp><corresp id="c002">Naseer Ullah, <email>khannasir965@gmail.com</email></corresp></author-notes><pub-date pub-type="epub"><day>07</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>12</volume><elocation-id>1519768</elocation-id><history>
<date date-type="received"><day>07</day><month>11</month><year>2024</year></date>
<date date-type="accepted"><day>14</day><month>4</month><year>2025</year></date>
</history><permissions><copyright-statement>Copyright &#x000a9; 2025 Tahir, Ullah, Tahir, Domnic, Prabhakar, Meerasa, AbdElneam, Tahir and Ali.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Tahir, Ullah, Tahir, Domnic, Prabhakar, Meerasa, AbdElneam, Tahir and Ali</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><sec id="sec1"><title>Background</title><p>Diabetic retinopathy is one of the leading causes of blindness globally, among individuals with diabetes mellitus. Early detection through screening can help in preventing disease progression. In recent advancements artificial Intelligence assisted screening has emerged as an alternative to traditional manual screening methods. This diagnostic test accuracy (DTA) review aims to compare the sensitivity and specificity of AI versus manual screening for detecting diabetic retinopathy, focusing on both dilated and un-dilated eyes.</p></sec><sec id="sec2"><title>Methods</title><p>A systematic review and meta-analysis were conducted for comparison of AI vs. manual screening of diabetic retinopathy using 25 observational (cross sectional, validation and cohort) studies with total images of 613,690 used for screening published between January 2015 and December 2024. Outcomes of the study was sensitivity, and specificity. Risk of bias was assessed using the QUADAS-2 tool for validation studies, the AXIS tool for cross-sectional studies, and the Newcastle-Ottawa Scale for cohort studies.</p></sec><sec id="sec3"><title>Results</title><p>The results of this meta-analysis showed that for un-dilated eyes, AI screening showed pooled sensitivity of 0.90 [95% CI: 0.85&#x02013;0.94] and pooled specificity of 0.94 [95% CI: 0.91&#x02013;0.96] while manual screening shows pooled sensitivity of 0.79 [95% CI: 0.60&#x02013;0.91] and pooled specificity of 0.99 [95% CI: 0.98&#x02013;0.99]. For dilated eyes the pooled sensitivity of AI screening is 0.95 [95% CI: 0.91&#x02013;0.97] and pooled specificity is 0.87 [95% CI: 0.79&#x02013;0.92], while manual screening sensitivity is 0.90 [95% CI: 0.87&#x02013;0.92] and specificity is 0.99 [95% CI: 0.99&#x02013;1.00]. These data show comparable sensitivities and specificities of AI and manual screening, with AI performing better in sensitivity.</p></sec><sec id="sec4"><title>Conclusion</title><p>AI-assisted screening for diabetic retinopathy shows comparable sensitivity and specificity compared to manual screening. These results suggest that AI can be a reliable alternative in clinical settings, with increased early detection rates and reducing the burden on ophthalmologists. Further research is needed to validate these findings.</p></sec><sec><title>Systematic review registration</title><p><uri xlink:href="https://www.crd.york.ac.uk/PROSPERO/home">https://www.crd.york.ac.uk/PROSPERO/home</uri>, CRD42024596611.</p></sec></abstract><kwd-group><kwd>diabetic retinopathy</kwd><kwd>screening</kwd><kwd>artificial intelligence</kwd><kwd>deep learning</kwd><kwd>manual screening</kwd><kwd>automated detection</kwd></kwd-group><funding-group><funding-statement>The author(s) declare that no financial support was received for the research and/or publication of this article.</funding-statement></funding-group><counts><fig-count count="9"/><table-count count="4"/><equation-count count="0"/><ref-count count="34"/><page-count count="14"/><word-count count="6236"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Ophthalmology</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec5"><title>Introduction</title><p>Diabetic Retinopathy (DR) is one of the most prevalent microvascular complications of diabetes, characterized by damage to the retina due to prolonged hyperglycemia. It remains a leading cause of blindness globally, particularly among working-age adults. The World Health Organization (WHO) estimates that over 422 million people worldwide have diabetes (<xref rid="ref1" ref-type="bibr">1</xref>), with approximately 103.12 million adult individuals affected by diabetic retinopathy and 160.50 million by 2045 (<xref rid="ref2" ref-type="bibr">2</xref>). In advanced stages, untreated DR can lead to severe vision impairment and blindness. According to a 2023 global report on vision by the WHO report globally distance vision impairment or blindness from diabetic retinopathy are 3.9 million (<xref rid="ref3" ref-type="bibr">3</xref>). Early detection and timely treatment can significantly reduce the risk of vision loss, but widespread screening remains a challenge, particularly in low-resource settings.</p><p>Screening for diabetic retinopathy has traditionally been performed through manual methods, including fundus photography, direct ophthalmoscopy, mydriatic and non mydriatic retinal photography, slit lamp microscopy, and retinal video recording conducted by trained ophthalmologists. However, these methods are often time-consuming and require specialized equipment and personnel, limiting their availability in certain regions (<xref rid="ref4" ref-type="bibr">4</xref>). Recent technological advancements have led to the development of automated screening methods using artificial intelligence (AI). AI-based algorithms, particularly deep learning models, can analyze retinal images and detect signs of DR with comparable sensitivity and specificity to human graders. These systems have the potential to increase screening efficiency, reduce costs, and provide access to screening in underserved populations. AI has been recognized for its ability to identify DR and classify the severity of the condition, making it a valuable tool in large-scale screening programs.</p><p>There are few systematic reviews and meta-analyses which have evaluated the performance of AI-based systems for DR screening. Meta-analysis reported high sensitivity and specificity for AI algorithms (<xref rid="ref5" ref-type="bibr">5&#x02013;8</xref>). Another review (<xref rid="ref9" ref-type="bibr">9</xref>) supported these findings but highlighted the variability in performance. However there is no review on comparison of AI vs. manual method to clarify the role of AI in different screening contexts, particularly in comparison to manual methods.</p><p>This Review aims to evaluate the performance of AI versus manual screening in DR detection. We systematically review the sensitivity and specificity of AI and manual methods, with a focus on both dilated and un-dilated eye conditions.</p></sec><sec sec-type="methods" id="sec6"><title>Methods</title><sec id="sec7"><title>Search strategy</title><p>We conducted a literature search for AI and manual screening methods of diabetic retinopathy using PubMed and Google Scholar to identify relevant studies published between January 2015 to September 2024 and a second search was done in Feb 2025 which added 13 studies to included studies which become 25 included studies. Search strategy contain mesh terms and keywords which included &#x0201c;diabetic retinopathy,&#x0201d; &#x0201c;artificial intelligence,&#x0201d; &#x0201c;deep learning,&#x0201d; &#x0201c;manual screening,&#x0201d; and &#x0201c;automated detection.&#x0201d; Only English language articles were included if they show AI-based or manual-based screening methods for DR detection and reported sensitivity and specificity outcomes.</p></sec><sec id="sec8"><title>Inclusion criteria</title><p>Studies were included if they were observational or validation and evaluated AI algorithms or manual screening for DR with patients aged 15 to 90&#x0202f;years diagnosed with DR and reported sensitivity and specificity outcomes for either dilated or un-dilated eye conditions. Studies were excluded if they did not report the outcomes of interest (specificity and sensitivity), the author of the studies did not respond or if the full text were not available.</p></sec><sec id="sec9"><title>Study selection</title><p>Initially two independent reviewers screened the articles by titles and abstracts. Once the articles met the inclusion criteria or were uncertain than full texts were obtained for those. The same reviewers then independently assessed the full texts. Discrepancies were resolved through discussion or, if needed, consultation with a third reviewer. PRISMA flow diagram was used for documentation of selection process <xref rid="fig1" ref-type="fig">Figure 1</xref>.</p><fig position="float" id="fig1"><label>Figure 1</label><caption><p>PRISMA flow diagram for included studies.</p></caption><graphic xlink:href="fmed-12-1519768-g001" position="float"/></fig></sec><sec id="sec10"><title>Quality assessment</title><p>Each study was assessed for quality by two independent reviewers to evaluate selection bias, outcome/exposure assessment bias, follow-up bias, measurement bias, sample representativeness, reporting bias, index test bias, reference standard bias, flow and timing bias, and ethical considerations bias was evaluated. Three different tools QUADAS-2, AXIS tool, and Newcastle-Ottawa scale was used according to type of studies (validation study, cross-sectional and cohort respectively) to evaluate risk of bias, which were used for strength of evidence of meta-analysis results.</p></sec><sec id="sec11"><title>Data extraction</title><p>Sensitivity and specificity data for AI and manual screening methods were extracted using a standardized data collection form for dilated or un-dilated eyes. Extracted information included study characteristics such as first author, country, number of participants, number of images, age of participants, comparison to human grader, photographic protocol, reference standard and outcomes of interest like sensitivity, and specificity. Two reviewers independently extracted data to minimize bias, by consensus or consulting a third reviewer disagreements were resolved. The information was initially entered into Excel tables and then transferred to Review Manager 5.4 and R-software for analysis. The risk of bias was assessed using the Newcastle-Ottawa scale for cohort studies, the AXIS tool for cross-sectional studies, and the QUADAS-2 tool for validation studies.</p></sec></sec><sec sec-type="results" id="sec12"><title>Results</title><sec id="sec13"><title>Study characteristics</title><p>A total of 25 studies met the inclusion criteria of this review which evaluated Artificial intelligence based screening and manual screening for diabetic retinopathy. Twelve studies reported images of un-dilated eyes screened by AI-based or manual methods, while 14 studies show dilated eyes images screened by AI-based and manual methods. Twelve out of 25 studies were prospective (<xref rid="ref10" ref-type="bibr">10&#x02013;21</xref>), and 13 were retrospective design (<xref rid="ref22" ref-type="bibr">22&#x02013;34</xref>).</p><p>The range of sample size is from 54 to 5,738 in 19 studies with total participants of 29,358 while six studies did not mentioned number of participants but only images, 613,690 images in 25 studies were used for screening process, in a broad geographic range of settings (out patients, hospital, community based and nationwide survey) and populations. The details are given in <xref rid="tab1" ref-type="table">Table 1</xref>.</p><table-wrap position="float" id="tab1"><label>Table 1</label><caption><p>Characteristics of included studies.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Study</th><th align="left" valign="top" rowspan="1" colspan="1">Country</th><th align="left" valign="top" rowspan="1" colspan="1">Study setting</th><th align="center" valign="top" rowspan="1" colspan="1">No. of images</th><th align="center" valign="top" rowspan="1" colspan="1">No. of participants</th><th align="left" valign="top" rowspan="1" colspan="1">Prospective</th><th align="left" valign="top" rowspan="1" colspan="1">Compared to human graders</th><th align="left" valign="top" rowspan="1" colspan="1">Photographic protocol</th><th align="left" valign="top" rowspan="1" colspan="1">Reference standard</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Ting et al. 2017 (<xref rid="ref25" ref-type="bibr">25</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Singapore</td><td align="left" valign="top" rowspan="1" colspan="1">Community-based and clinic-based populations</td><td align="center" valign="top" rowspan="1" colspan="1">225,302</td><td align="center" valign="top" rowspan="1" colspan="1">Not mentioned</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">2 fields images, Mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Grading by a retinal specialist (&#x0003e;5&#x0202f;years&#x02019; experience in conducting diabetic retinopathy assessment)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Sosale et al. 2020 (<xref rid="ref15" ref-type="bibr">15</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">India</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">618</td><td align="center" valign="top" rowspan="1" colspan="1">297</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">3-fields dilated retinal imaging, Mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Adjudicated diagnosis of the two fellowship-trained vitreoretinal specialists</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Surya et al. 2023 (<xref rid="ref16" ref-type="bibr">16</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">India</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">1,234</td><td align="center" valign="top" rowspan="1" colspan="1">1,085</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">5 fields imaging, No Mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Diagnosis made by the specialist ophthalmologists</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Piatti et al. 2024 (<xref rid="ref13" ref-type="bibr">13</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Italy</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">602</td><td align="center" valign="top" rowspan="1" colspan="1">598</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">2 field imaging, Mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Classification of the retinal images by the human ophthalmologist grader</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Sedova et al. 2022 (<xref rid="ref14" ref-type="bibr">14</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Austria</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">113</td><td align="center" valign="top" rowspan="1" colspan="1">54</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree, 2 fields imaging, No Mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Manual grading of images by retina specialists</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ipp 2021 (<xref rid="ref10" ref-type="bibr">10</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">United states</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">4,004</td><td align="center" valign="top" rowspan="1" colspan="1">893</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">4-wide field imaging for no Mydriasis and 2 fields imaging No Mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Grading of 4-wide-field stereoscopic dilated fundus photographs by the WFPRC</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Tokuda et al. 2022 (<xref rid="ref17" ref-type="bibr">17</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Japan</td><td align="left" valign="top" rowspan="1" colspan="1">Inpatient</td><td align="center" valign="top" rowspan="1" colspan="1">69</td><td align="center" valign="top" rowspan="1" colspan="1">70</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree, no mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Grading of the fundus images by three retinal experts according to the ICDRS scale</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Acharyya et al. 2024 (<xref rid="ref22" ref-type="bibr">22</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">India</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">1,783</td><td align="center" valign="top" rowspan="1" colspan="1">Not mentioned</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree, no mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Consensus of three blinded vitreoretinal specialists, with an arbitrator resolving any disagreements.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Arenas-Cavalli et al. 2022 (<xref rid="ref23" ref-type="bibr">23</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Chile</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">1,142</td><td align="center" valign="top" rowspan="1" colspan="1">1,123</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree, 2 fields, variable for case to case</td><td align="left" valign="top" rowspan="1" colspan="1">assessment performed remotely by a clinical ophthalmologist.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Li et al. 2022 (<xref rid="ref11" ref-type="bibr">11</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">China</td><td align="left" valign="top" rowspan="1" colspan="1">Hospital-based study</td><td align="center" valign="top" rowspan="1" colspan="1">1,464</td><td align="center" valign="top" rowspan="1" colspan="1">1,147</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree, no mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Grading of the retinal fundus images by a certified retinal specialist with more than 12&#x0202f;years of experience, who used the 5-point (ICDRS) scale to assign grades</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Limwattanayingyong et al. 2020 (<xref rid="ref24" ref-type="bibr">24</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Thailand</td><td align="left" valign="top" rowspan="1" colspan="1">Nationwide screening program</td><td align="center" valign="top" rowspan="1" colspan="1">11,148</td><td align="center" valign="top" rowspan="1" colspan="1">5,738</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree, 1 field, no mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Grading of the retinal photographs by a panel of three IRS</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Lupidi et al. 2023 (<xref rid="ref12" ref-type="bibr">12</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Italy</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">831</td><td align="center" valign="top" rowspan="1" colspan="1">251</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">50-degree, 1 field, no mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Fundus biomicroscopic examination by an experienced retina specialist</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Gonz&#x000e1;lez-Gonzalo et al. 2020 (<xref rid="ref26" ref-type="bibr">26</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Sweden</td><td align="left" valign="top" rowspan="1" colspan="1">Dataset</td><td align="center" valign="top" rowspan="1" colspan="1">600</td><td align="center" valign="top" rowspan="1" colspan="1">288</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree field, no mdriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Certified ophthalmologist with over 12&#x0202f;years of experience</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Lin et al. 2018 (<xref rid="ref27" ref-type="bibr">27</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">United states</td><td align="left" valign="top" rowspan="1" colspan="1">Dataset</td><td align="center" valign="top" rowspan="1" colspan="1">33,000</td><td rowspan="1" colspan="1"/><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">no</td><td align="left" valign="top" rowspan="1" colspan="1">not mentioned</td><td align="left" valign="top" rowspan="1" colspan="1">Well-trained clinicians according to the International Clinical Diabetic Retinopathy scale</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Li et al. 2019 (<xref rid="ref28" ref-type="bibr">28</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">China</td><td align="left" valign="top" rowspan="1" colspan="1">Hospital-based study</td><td align="center" valign="top" rowspan="1" colspan="1">19,233</td><td align="center" valign="top" rowspan="1" colspan="1">5,278</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Inner circle of retina</td><td align="left" valign="top" rowspan="1" colspan="1">Expert committee of three senior ophthalmologists</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Soto-Pedre et al. 2015 (<xref rid="ref18" ref-type="bibr">18</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Spain</td><td align="left" valign="top" rowspan="1" colspan="1">Dataset</td><td align="center" valign="top" rowspan="1" colspan="1">10,556</td><td align="center" valign="top" rowspan="1" colspan="1">5,278</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree field, mdriasis</td><td align="left" valign="top" rowspan="1" colspan="1">One retinal specialist</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Hansen et al. 2015 (<xref rid="ref29" ref-type="bibr">29</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Kenya</td><td align="left" valign="top" rowspan="1" colspan="1">Community-based</td><td align="center" valign="top" rowspan="1" colspan="1">6,788</td><td align="center" valign="top" rowspan="1" colspan="1">3,460</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">2 field, mydraisis</td><td align="left" valign="top" rowspan="1" colspan="1">Moorfields Eye Hospitals Reading Centre in the UK</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Rajalakshmi et al. 2018 (<xref rid="ref19" ref-type="bibr">19</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">India</td><td align="left" valign="top" rowspan="1" colspan="1">Hospital-based study</td><td align="center" valign="top" rowspan="1" colspan="1">2,408</td><td align="center" valign="top" rowspan="1" colspan="1">301</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree field, mdriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Ophthalmologists (retina specialists)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Gargeya and Leng 2017 (<xref rid="ref30" ref-type="bibr">30</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">United states</td><td align="left" valign="top" rowspan="1" colspan="1">Dataset</td><td align="center" valign="top" rowspan="1" colspan="1">75,137</td><td align="center" valign="top" rowspan="1" colspan="1">Not mentioned</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">inner retinal circle</td><td align="left" valign="top" rowspan="1" colspan="1">Panel of human retinal specialists</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Wang et al. 2018 (<xref rid="ref20" ref-type="bibr">20</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">India</td><td align="left" valign="top" rowspan="1" colspan="1">Outpatient</td><td align="center" valign="top" rowspan="1" colspan="1">1,661</td><td align="center" valign="top" rowspan="1" colspan="1">383</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">non-steered central image, mydriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Certified diabetic retinopathy (DR) graders at the Doheny Image Reading Center (DIRC)</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Abr&#x000e0;moff et al. 2016 (<xref rid="ref31" ref-type="bibr">31</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">United states</td><td align="left" valign="top" rowspan="1" colspan="1">Dataset</td><td align="center" valign="top" rowspan="1" colspan="1">1,748</td><td align="center" valign="top" rowspan="1" colspan="1">874</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree field, mdriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Three US Board certified retinal specialists</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Zhang et al. 2019 (<xref rid="ref32" ref-type="bibr">32</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">China</td><td align="left" valign="top" rowspan="1" colspan="1">Hospital-based study</td><td align="center" valign="top" rowspan="1" colspan="1">13,767</td><td align="center" valign="top" rowspan="1" colspan="1">1,872</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree field, mdriasis</td><td align="left" valign="top" rowspan="1" colspan="1">One retinal specialist with over 27&#x0202f;years of experience and two ophthalmologists with over 5&#x0202f;years of experience</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Li et al. 2018 (<xref rid="ref21" ref-type="bibr">21</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">China and Australia</td><td align="left" valign="top" rowspan="1" colspan="1">Hospital-based study</td><td align="center" valign="top" rowspan="1" colspan="1">106,244</td><td align="center" valign="top" rowspan="1" colspan="1">Not mentioned</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">45-degree field, mdriasis and non mydraisis</td><td align="left" valign="top" rowspan="1" colspan="1">Panel of ophthalmologists</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Zhang et al. 2022 (<xref rid="ref33" ref-type="bibr">33</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">China</td><td align="left" valign="top" rowspan="1" colspan="1">Dataset</td><td align="center" valign="top" rowspan="1" colspan="1">92,894</td><td align="center" valign="top" rowspan="1" colspan="1">Not mentioned</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">Fundus images</td><td align="left" valign="top" rowspan="1" colspan="1">Ophthalmologist used international grading system for diabetic retinopathy</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Kumar et al. 2016 (<xref rid="ref34" ref-type="bibr">34</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">India</td><td align="left" valign="top" rowspan="1" colspan="1">Hospital-based study</td><td align="center" valign="top" rowspan="1" colspan="1">1,344</td><td align="center" valign="top" rowspan="1" colspan="1">368</td><td align="left" valign="top" rowspan="1" colspan="1">No</td><td align="left" valign="top" rowspan="1" colspan="1">Yes</td><td align="left" valign="top" rowspan="1" colspan="1">50-degree field, mdriasis</td><td align="left" valign="top" rowspan="1" colspan="1">Panel of expert ophthalmologists at the Regional Institute of Ophthalmology</td></tr></tbody></table><table-wrap-foot><p>WFPRC, Wisconsin Fundus Photograph Reading Center; IRS, international retina specialists; ICDRS, International Clinical Diabetic Retinopathy Severity scale. <sup>a</sup>These are the external datasets for which accuracy estimates were included in the meta-analysis; datasets used for training and internal validation were not included. b. &#x0201c;Compared to human graders&#x0201d; refers to whether retinal images were graded and compared with the results provided by AI with human graders. c. Where specified the mydriatic or non-mydriatic imaging protocols were followed depending on the study setting, with multiple fields captured. d. For certain studies, the primary reference standard was provided by expert ophthalmologists or retinal specialists with a minimum of 5&#x0202f;years&#x02019; experience in diabetic retinopathy assessment, though in some cases, decisions were made through consensus from multiple specialists or reading centers. e. External validation of these studies was conducted in clinical settings such as hospital-based, outpatient, or community-based screening programs, as specified.</p></table-wrap-foot></table-wrap></sec><sec id="sec14"><title>Test accuracy</title><p>The diagnostic accuracy of AI-based diabetic retinopathy (DR) screening compared to manual methods shows that, in dilated eyes, the SROC curves shows wider confidence intervals of specificities across the included studies, indicating variability in diagnostic performance.</p><p>Un-dilated eye screening tends to achieve high sensitivity and specificity values with most of the studies reporting sensitivity and specificity of more than 0.90. This suggests a reliable ability of AI algorithms to correctly identify DR in un-dilated eye examinations. The studies generally cluster around the upper-left corner of the plot, indicating strong diagnostic performance with low rates of false positives and false negatives.</p><p>Overall, these SROC plots highlight that AI models demonstrate robust diagnostic accuracy for detecting diabetic retinopathy in both dilated and un-dilated settings, with higher sensitivity and closer specificity compared to manual screening methods in most of the studies as can be seen in the <xref rid="fig2" ref-type="fig">Figures 2</xref>, <xref rid="fig3" ref-type="fig">3</xref>.</p><fig position="float" id="fig2"><label>Figure 2</label><caption><p>SROC plot for un-dilated eyes screening.</p></caption><graphic xlink:href="fmed-12-1519768-g002" position="float"/></fig><fig position="float" id="fig3"><label>Figure 3</label><caption><p>SROC plot for dilated eyes screening.</p></caption><graphic xlink:href="fmed-12-1519768-g003" position="float"/></fig></sec><sec id="sec15"><title>Sensitivity</title><p>The sensitivity of AI-based screening for dilated eyes show consistent results across the studies with a pooled sensitivity of 0.95 (95% CI: 0.91, 0.97). For manual screening in dilated eyes, the pooled sensitivity reported was 0.90 (95% CI: 0.87, 0.92), showing lower performance than AI as given in <xref rid="tab2" ref-type="table">Table 2</xref> and <xref rid="fig4" ref-type="fig">Figure 4</xref>. For un-dilated eyes, AI screening achieved a pooled sensitivity of 0.92 (95% CI: 0.87, 0.95). In the manual screening of un-dilated eyes images pooled sensitivities of 0.79 (95% CI: 0.60, 0.91) is reported given in <xref rid="tab2" ref-type="table">Table 2</xref> and <xref rid="fig5" ref-type="fig">Figure 5</xref>. AI-based screening shows higher performance than manual screening.</p><table-wrap position="float" id="tab2"><label>Table 2</label><caption><p>Results for outcomes.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Study</th><th align="left" valign="top" rowspan="1" colspan="1">Outcome</th><th rowspan="1" colspan="1">Dilated/Un-dilated eye</th><th align="center" valign="top" rowspan="1" colspan="1">TP</th><th align="center" valign="top" rowspan="1" colspan="1">FP</th><th align="center" valign="top" rowspan="1" colspan="1">FP</th><th align="center" valign="top" rowspan="1" colspan="1">TN</th><th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (CI at 95%)</th><th align="center" valign="top" rowspan="1" colspan="1">Specificity (CI at 95%)</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Piatti et al. 2024 (<xref rid="ref13" ref-type="bibr">13</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Mild DR with AI</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">70</td><td align="center" valign="top" rowspan="1" colspan="1">102</td><td align="center" valign="top" rowspan="1" colspan="1">102</td><td align="center" valign="top" rowspan="1" colspan="1">399</td><td align="center" valign="top" rowspan="1" colspan="1">0.41 [0.33, 0.48]</td><td align="center" valign="top" rowspan="1" colspan="1">0.93 [0.90, 0.95]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Piatti et al. 2024 (<xref rid="ref13" ref-type="bibr">13</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Moderate and beyond with AI</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">35</td><td align="center" valign="top" rowspan="1" colspan="1">0</td><td align="center" valign="top" rowspan="1" colspan="1">0</td><td align="center" valign="top" rowspan="1" colspan="1">0</td><td align="center" valign="top" rowspan="1" colspan="1">1.00 [0.90, 1.00]</td><td align="center" valign="top" rowspan="1" colspan="1">Not estimable</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Sosale et al. 2020 (<xref rid="ref15" ref-type="bibr">15</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI for referable DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">120</td><td align="center" valign="top" rowspan="1" colspan="1">23</td><td align="center" valign="top" rowspan="1" colspan="1">23</td><td align="center" valign="top" rowspan="1" colspan="1">153</td><td align="center" valign="top" rowspan="1" colspan="1">0.84 [0.77, 0.90]</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.96, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Sosale et al. 2020 (<xref rid="ref15" ref-type="bibr">15</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI for any DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">105</td><td align="center" valign="top" rowspan="1" colspan="1">8</td><td align="center" valign="top" rowspan="1" colspan="1">8</td><td align="center" valign="top" rowspan="1" colspan="1">168</td><td align="center" valign="top" rowspan="1" colspan="1">0.93 [0.87, 0.97]</td><td align="center" valign="top" rowspan="1" colspan="1">0.91 [0.86, 0.95]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ting et al. 2017 (<xref rid="ref25" ref-type="bibr">25</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI for referable DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">3,057</td><td align="center" valign="top" rowspan="1" colspan="1">9,172</td><td align="center" valign="top" rowspan="1" colspan="1">9,172</td><td align="center" valign="top" rowspan="1" colspan="1">100,097</td><td align="center" valign="top" rowspan="1" colspan="1">0.25 [0.24, 0.26]</td><td align="center" valign="top" rowspan="1" colspan="1">1.00 [1.00, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ting et al. 2017 (<xref rid="ref25" ref-type="bibr">25</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Moderate and beyond with AI</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">676</td><td align="center" valign="top" rowspan="1" colspan="1">9,969</td><td align="center" valign="top" rowspan="1" colspan="1">9,969</td><td align="center" valign="top" rowspan="1" colspan="1">102,003</td><td align="center" valign="top" rowspan="1" colspan="1">0.06 [0.06, 0.07]</td><td align="center" valign="top" rowspan="1" colspan="1">1.00 [1.00, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ipp 2021 (<xref rid="ref10" ref-type="bibr">10</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI for Mod and beyond</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">356</td><td align="center" valign="top" rowspan="1" colspan="1">375</td><td align="center" valign="top" rowspan="1" colspan="1">375</td><td align="center" valign="top" rowspan="1" colspan="1">2,630</td><td align="center" valign="top" rowspan="1" colspan="1">0.49 [0.45, 0.52]</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.99, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Soto-Pedre et al. 2015 (<xref rid="ref18" ref-type="bibr">18</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">535</td><td align="center" valign="top" rowspan="1" colspan="1">1,034</td><td align="center" valign="top" rowspan="1" colspan="1">1,034</td><td align="center" valign="top" rowspan="1" colspan="1">2,277</td><td align="center" valign="top" rowspan="1" colspan="1">0.34 [0.32, 0.37]</td><td align="center" valign="top" rowspan="1" colspan="1">0.69 [0.67, 0.70]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Wang et al. 2018 (<xref rid="ref20" ref-type="bibr">20</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">213</td><td align="center" valign="top" rowspan="1" colspan="1">205</td><td align="center" valign="top" rowspan="1" colspan="1">205</td><td align="center" valign="top" rowspan="1" colspan="1">206</td><td align="center" valign="top" rowspan="1" colspan="1">0.51 [0.46, 0.56]</td><td align="center" valign="top" rowspan="1" colspan="1">0.50 [0.45, 0.55]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Abr&#x000e0;moff et al. 2016 (<xref rid="ref31" ref-type="bibr">31</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">182</td><td align="center" valign="top" rowspan="1" colspan="1">88</td><td align="center" valign="top" rowspan="1" colspan="1">88</td><td align="center" valign="top" rowspan="1" colspan="1">598</td><td align="center" valign="top" rowspan="1" colspan="1">0.67 [0.61, 0.73]</td><td align="center" valign="top" rowspan="1" colspan="1">0.87 [0.84, 0.90]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Hansen et al. 2015 (<xref rid="ref29" ref-type="bibr">29</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">91</td><td align="center" valign="top" rowspan="1" colspan="1">900</td><td align="center" valign="top" rowspan="1" colspan="1">900</td><td align="center" valign="top" rowspan="1" colspan="1">2,093</td><td align="center" valign="top" rowspan="1" colspan="1">0.09 [0.07, 0.11]</td><td align="center" valign="top" rowspan="1" colspan="1">0.70 [0.68, 0.72]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Rajalakshmi et al. 2018 (<xref rid="ref19" ref-type="bibr">19</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">184</td><td align="center" valign="top" rowspan="1" colspan="1">21</td><td align="center" valign="top" rowspan="1" colspan="1">21</td><td align="center" valign="top" rowspan="1" colspan="1">84</td><td align="center" valign="top" rowspan="1" colspan="1">0.90 [0.85, 0.94]</td><td align="center" valign="top" rowspan="1" colspan="1">0.80 [0.71, 0.87]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Kumar et al. 2016 (<xref rid="ref34" ref-type="bibr">34</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">722</td><td align="center" valign="top" rowspan="1" colspan="1">176</td><td align="center" valign="top" rowspan="1" colspan="1">176</td><td align="center" valign="top" rowspan="1" colspan="1">176</td><td align="center" valign="top" rowspan="1" colspan="1">0.80 [0.78, 0.83]</td><td align="center" valign="top" rowspan="1" colspan="1">0.50 [0.45, 0.55]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Zhang et al. 2019 (<xref rid="ref32" ref-type="bibr">32</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR (Grading system)</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">414</td><td align="center" valign="top" rowspan="1" colspan="1">4</td><td align="center" valign="top" rowspan="1" colspan="1">4</td><td align="center" valign="top" rowspan="1" colspan="1">344</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.98, 1.00]</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.97, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Zhang et al. 2019 (<xref rid="ref32" ref-type="bibr">32</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR (identification system)</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">412</td><td align="center" valign="top" rowspan="1" colspan="1">8</td><td align="center" valign="top" rowspan="1" colspan="1">8</td><td align="center" valign="top" rowspan="1" colspan="1">340</td><td align="center" valign="top" rowspan="1" colspan="1">0.98 [0.96, 0.99]</td><td align="center" valign="top" rowspan="1" colspan="1">0.98 [0.96, 0.99]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Zhang et al. 2022 (<xref rid="ref33" ref-type="bibr">33</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR (InceptionV3_299)</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">12,440</td><td align="center" valign="top" rowspan="1" colspan="1">3,580</td><td align="center" valign="top" rowspan="1" colspan="1">3,580</td><td align="center" valign="top" rowspan="1" colspan="1">35,953</td><td align="center" valign="top" rowspan="1" colspan="1">0.78 [0.77, 0.78]</td><td align="center" valign="top" rowspan="1" colspan="1">0.91 [0.91, 0.91]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Zhang et al. 2022 (<xref rid="ref33" ref-type="bibr">33</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR (InceptionV3_896)</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">12,984</td><td align="center" valign="top" rowspan="1" colspan="1">3,676</td><td align="center" valign="top" rowspan="1" colspan="1">3,676</td><td align="center" valign="top" rowspan="1" colspan="1">35,857</td><td align="center" valign="top" rowspan="1" colspan="1">0.78 [0.77, 0.79]</td><td align="center" valign="top" rowspan="1" colspan="1">0.91 [0.90, 0.91]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Sedova et al. 2022 (<xref rid="ref14" ref-type="bibr">14</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">27</td><td align="center" valign="top" rowspan="1" colspan="1">1</td><td align="center" valign="top" rowspan="1" colspan="1">1</td><td align="center" valign="top" rowspan="1" colspan="1">16</td><td align="center" valign="top" rowspan="1" colspan="1">0.96 [0.82, 1.00]</td><td align="center" valign="top" rowspan="1" colspan="1">0.80 [0.56, 0.94]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ipp 2021 (<xref rid="ref10" ref-type="bibr">10</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI for Mod to Severe</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">331</td><td align="center" valign="top" rowspan="1" colspan="1">345</td><td align="center" valign="top" rowspan="1" colspan="1">345</td><td align="center" valign="top" rowspan="1" colspan="1">2,342</td><td align="center" valign="top" rowspan="1" colspan="1">0.49 [0.45, 0.53]</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.99, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Surya et al. 2023 (<xref rid="ref16" ref-type="bibr">16</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">42</td><td align="center" valign="top" rowspan="1" colspan="1">10</td><td align="center" valign="top" rowspan="1" colspan="1">10</td><td align="center" valign="top" rowspan="1" colspan="1">283</td><td align="center" valign="top" rowspan="1" colspan="1">0.81 [0.67, 0.90]</td><td align="center" valign="top" rowspan="1" colspan="1">0.91 [0.88, 0.94]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Limwattanayingyong et al. 2020 (<xref rid="ref24" ref-type="bibr">24</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">1st screening DL for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">669</td><td align="center" valign="top" rowspan="1" colspan="1">102</td><td align="center" valign="top" rowspan="1" colspan="1">102</td><td align="center" valign="top" rowspan="1" colspan="1">4,932</td><td align="center" valign="top" rowspan="1" colspan="1">0.87 [0.84, 0.89]</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.99, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Limwattanayingyong et al. 2020 (<xref rid="ref24" ref-type="bibr">24</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">2nd screening DL for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">190</td><td align="center" valign="top" rowspan="1" colspan="1">84</td><td align="center" valign="top" rowspan="1" colspan="1">84</td><td align="center" valign="top" rowspan="1" colspan="1">3,853</td><td align="center" valign="top" rowspan="1" colspan="1">0.69 [0.64, 0.75]</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.99, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Arenas-Cavalli et al. 2022 (<xref rid="ref23" ref-type="bibr">23</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">226</td><td align="center" valign="top" rowspan="1" colspan="1">227</td><td align="center" valign="top" rowspan="1" colspan="1">227</td><td align="center" valign="top" rowspan="1" colspan="1">657</td><td align="center" valign="top" rowspan="1" colspan="1">0.50 [0.45, 0.55]</td><td align="center" valign="top" rowspan="1" colspan="1">0.98 [0.97, 0.99]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Lupidi et al. 2023 (<xref rid="ref12" ref-type="bibr">12</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR (Selena +)</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">121</td><td align="center" valign="top" rowspan="1" colspan="1">4</td><td align="center" valign="top" rowspan="1" colspan="1">4</td><td align="center" valign="top" rowspan="1" colspan="1">122</td><td align="center" valign="top" rowspan="1" colspan="1">0.97 [0.92, 0.99]</td><td align="center" valign="top" rowspan="1" colspan="1">0.97 [0.92, 0.99]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Acharyya et al. 2024 (<xref rid="ref22" ref-type="bibr">22</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">848</td><td align="center" valign="top" rowspan="1" colspan="1">128</td><td align="center" valign="top" rowspan="1" colspan="1">128</td><td align="center" valign="top" rowspan="1" colspan="1">732</td><td align="center" valign="top" rowspan="1" colspan="1">0.87 [0.85, 0.89]</td><td align="center" valign="top" rowspan="1" colspan="1">0.91 [0.88, 0.93]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Li et al. 2022 (<xref rid="ref11" ref-type="bibr">11</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">86</td><td align="center" valign="top" rowspan="1" colspan="1">25</td><td align="center" valign="top" rowspan="1" colspan="1">25</td><td align="center" valign="top" rowspan="1" colspan="1">1,323</td><td align="center" valign="top" rowspan="1" colspan="1">0.77 [0.69, 0.85]</td><td align="center" valign="top" rowspan="1" colspan="1">0.99 [0.99, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Tokuda et al. 2022 (<xref rid="ref17" ref-type="bibr">17</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">13</td><td align="center" valign="top" rowspan="1" colspan="1">5</td><td align="center" valign="top" rowspan="1" colspan="1">5</td><td align="center" valign="top" rowspan="1" colspan="1">49</td><td align="center" valign="top" rowspan="1" colspan="1">0.72 [0.47, 0.90]</td><td align="center" valign="top" rowspan="1" colspan="1">0.96 [0.87, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Li et al. 2019 (<xref rid="ref28" ref-type="bibr">28</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">519</td><td align="center" valign="top" rowspan="1" colspan="1">16</td><td align="center" valign="top" rowspan="1" colspan="1">16</td><td align="center" valign="top" rowspan="1" colspan="1">256</td><td align="center" valign="top" rowspan="1" colspan="1">0.98 [0.97, 0.99]</td><td align="center" valign="top" rowspan="1" colspan="1">0.94 [0.91, 0.97]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Lin et al. 2018 (<xref rid="ref27" ref-type="bibr">27</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">10,254</td><td align="center" valign="top" rowspan="1" colspan="1">1,519</td><td align="center" valign="top" rowspan="1" colspan="1">1,519</td><td align="center" valign="top" rowspan="1" colspan="1">13,481</td><td align="center" valign="top" rowspan="1" colspan="1">0.68 [0.68, 0.69]</td><td align="center" valign="top" rowspan="1" colspan="1">0.90 [0.89, 0.90]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Gonz&#x000e1;lez-Gonzalo et al. 2020 (<xref rid="ref26" ref-type="bibr">26</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">132</td><td align="center" valign="top" rowspan="1" colspan="1">30</td><td align="center" valign="top" rowspan="1" colspan="1">30</td><td align="center" valign="top" rowspan="1" colspan="1">295</td><td align="center" valign="top" rowspan="1" colspan="1">0.92 [0.86, 0.96]</td><td align="center" valign="top" rowspan="1" colspan="1">0.91 [0.87, 0.94]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Gargeya and Leng 2017 (<xref rid="ref30" ref-type="bibr">30</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">813</td><td align="center" valign="top" rowspan="1" colspan="1">113</td><td align="center" valign="top" rowspan="1" colspan="1">113</td><td align="center" valign="top" rowspan="1" colspan="1">761</td><td align="center" valign="top" rowspan="1" colspan="1">0.93 [0.91, 0.95]</td><td align="center" valign="top" rowspan="1" colspan="1">0.87 [0.85, 0.89]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Li et al. 2018 (<xref rid="ref21" ref-type="bibr">21</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">AI screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">371</td><td align="center" valign="top" rowspan="1" colspan="1">199</td><td align="center" valign="top" rowspan="1" colspan="1">199</td><td align="center" valign="top" rowspan="1" colspan="1">13,057</td><td align="center" valign="top" rowspan="1" colspan="1">0.93 [0.89, 0.95]</td><td align="center" valign="top" rowspan="1" colspan="1">0.98 [0.98, 0.99]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Limwattanayingyong et al. 2020 (<xref rid="ref24" ref-type="bibr">24</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">!st screening Manual for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">165</td><td align="center" valign="top" rowspan="1" colspan="1">124</td><td align="center" valign="top" rowspan="1" colspan="1">59</td><td align="center" valign="top" rowspan="1" colspan="1">3,915</td><td align="center" valign="top" rowspan="1" colspan="1">0.74 [0.67, 0.79]</td><td align="center" valign="top" rowspan="1" colspan="1">0.97 [0.96, 0.97]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Limwattanayingyong et al. 2020 (<xref rid="ref24" ref-type="bibr">24</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">2nd screening Manual for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">519</td><td align="center" valign="top" rowspan="1" colspan="1">185</td><td align="center" valign="top" rowspan="1" colspan="1">71</td><td align="center" valign="top" rowspan="1" colspan="1">4,963</td><td align="center" valign="top" rowspan="1" colspan="1">0.88 [0.85, 0.90]</td><td align="center" valign="top" rowspan="1" colspan="1">0.96 [0.96, 0.97]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Sedova et al. 2022 (<xref rid="ref14" ref-type="bibr">14</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Manual screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">21</td><td align="center" valign="top" rowspan="1" colspan="1">2</td><td align="center" valign="top" rowspan="1" colspan="1">1</td><td align="center" valign="top" rowspan="1" colspan="1">32</td><td align="center" valign="top" rowspan="1" colspan="1">0.95 [0.77, 1.00]</td><td align="center" valign="top" rowspan="1" colspan="1">0.94 [0.80, 0.99]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Sedova et al. 2022 (<xref rid="ref14" ref-type="bibr">14</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Manual screening for DR</td><td align="left" valign="top" rowspan="1" colspan="1">Undilated</td><td align="center" valign="top" rowspan="1" colspan="1">22</td><td align="center" valign="top" rowspan="1" colspan="1">2</td><td align="center" valign="top" rowspan="1" colspan="1">1</td><td align="center" valign="top" rowspan="1" colspan="1">32</td><td align="center" valign="top" rowspan="1" colspan="1">0.96 [0.78, 1.00]</td><td align="center" valign="top" rowspan="1" colspan="1">0.94 [0.80, 0.99]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ting et al. 2017 (<xref rid="ref25" ref-type="bibr">25</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Manual for referable DR</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">3,077</td><td align="center" valign="top" rowspan="1" colspan="1">302</td><td align="center" valign="top" rowspan="1" colspan="1">768</td><td align="center" valign="top" rowspan="1" colspan="1">108,501</td><td align="center" valign="top" rowspan="1" colspan="1">0.80 [0.79, 0.81]</td><td align="center" valign="top" rowspan="1" colspan="1">1.00 [1.00, 1.00]</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Ting et al. 2017 (<xref rid="ref25" ref-type="bibr">25</xref>)</td><td align="left" valign="top" rowspan="1" colspan="1">Moderate and beyond with Manual</td><td align="left" valign="top" rowspan="1" colspan="1">Dilated</td><td align="center" valign="top" rowspan="1" colspan="1">558</td><td align="center" valign="top" rowspan="1" colspan="1">78</td><td align="center" valign="top" rowspan="1" colspan="1">447</td><td align="center" valign="top" rowspan="1" colspan="1">111,525</td><td align="center" valign="top" rowspan="1" colspan="1">0.56 [0.52, 0.59]</td><td align="center" valign="top" rowspan="1" colspan="1">1.00 [1.00, 1.00]</td></tr></tbody></table><table-wrap-foot><p>CI, Confidence Interval; DR, Diabetic Retinopathy; Referable DR, severity grade 2 and above; DL, Deep Learning; DLA, Deep Learning Algorithm; FN, False Negative; FP, False Positive; Mod, Moderate; RDR, Referable Diabetic Retinopathy; SVM, Support Vector Machine; TP, True Positive; TN, True Negative; UWF, Ultra-Wide Field Grading.</p></table-wrap-foot></table-wrap><fig position="float" id="fig4"><label>Figure 4</label><caption><p>Specificity forest plot for un-dilated eyes.</p></caption><graphic xlink:href="fmed-12-1519768-g004" position="float"/></fig><fig position="float" id="fig5"><label>Figure 5</label><caption><p>Sensitivity forest plot for un-dilated eyes.</p></caption><graphic xlink:href="fmed-12-1519768-g005" position="float"/></fig></sec><sec id="sec16"><title>Specificity</title><p>Pooled specificity of AI screening for dilated eyes was reported at 0.87 (95% CI: 0.79, 0.92) showing a good performance and manual screening for dilated eyes also showed a high pooled specificity value of 0.99 (95% CI: 0.99, 1.00). Showing a good performance of both AI-based and manual screening methods as shown in the <xref rid="fig6" ref-type="fig">Figure 6</xref>. For un-dilated eyes, AI screening demonstrated pooled specificity of 0.94 (95% CI: 0.91, 0.96). Manual screening similarly showed robust specificity 0.99 (95% CI: 0.98, 0.99) as given in the <xref rid="fig7" ref-type="fig">Figure 7</xref>. Showing that AI a comparable alternative to manual screening.</p><fig position="float" id="fig6"><label>Figure 6</label><caption><p>Specificity forest plot for dilated eyes.</p></caption><graphic xlink:href="fmed-12-1519768-g006" position="float"/></fig><fig position="float" id="fig7"><label>Figure 7</label><caption><p>Sensitivity forest plot for dilated eyes.</p></caption><graphic xlink:href="fmed-12-1519768-g007" position="float"/></fig></sec><sec id="sec17"><title>Multi-test analysis</title><p>The combined pooled sensitivity and specificity of dilated eye is 0.94 [95% CI: 0.90; 0.97] and 0.91 [0.83; 0.95] with heterogeneity of 95.2 and 99.9% and <italic>p</italic> value of 0.0386 and 0.0001, respectively, showing comparable results in the outcomes with high variability among studies as shown in <xref rid="fig4" ref-type="fig">Figures 4</xref>, <xref rid="fig6" ref-type="fig">6</xref>. Un-dilated eye report combined pooled sensitivity and specificity of 0.90 [95% CI: 0.85; 0.94] and 0.95 [0.93; 0.97] with heterogeneity of 98.1 and 99.1% and <italic>p</italic> value of 0.0437 and 0.0001, respectively, showing results with no statistically significant difference as shown in <xref rid="fig5" ref-type="fig">Figures 5</xref>, <xref rid="fig7" ref-type="fig">7</xref>.</p></sec><sec id="sec18"><title>Risk of bias</title><p>Risk of bias was systematically assessed using appropriate tools for the study designs. For the 16 validation studies (<xref rid="ref13" ref-type="bibr">13</xref>, <xref rid="ref16" ref-type="bibr">16</xref>, <xref rid="ref18" ref-type="bibr">18&#x02013;21</xref>, <xref rid="ref23" ref-type="bibr">23</xref>, <xref rid="ref26" ref-type="bibr">26&#x02013;34</xref>), the QUADAS-2 tool was used. Thirteen of these studies demonstrated a low risk of bias, while three study shows some concerns particularly in the domain 3 and 4, as shown in the accompanying <xref rid="fig8" ref-type="fig">Figures 8</xref>, <xref rid="fig9" ref-type="fig">9</xref>.</p><fig position="float" id="fig8"><label>Figure 8</label><caption><p>Risk of bias assessment traffic light plot for QUADAS-2 tool.</p></caption><graphic xlink:href="fmed-12-1519768-g008" position="float"/></fig><fig position="float" id="fig9"><label>Figure 9</label><caption><p>Risk of bias assessment summary plot for QUADAS-2 tool.</p></caption><graphic xlink:href="fmed-12-1519768-g009" position="float"/></fig><p>For the five cross-sectional studies, the AXIS tool was used to assess the risk of bias (<xref rid="ref10" ref-type="bibr">10</xref>, <xref rid="ref12" ref-type="bibr">12</xref>, <xref rid="ref15" ref-type="bibr">15</xref>, <xref rid="ref22" ref-type="bibr">22</xref>, <xref rid="ref25" ref-type="bibr">25</xref>). The results reported a moderate risk of bias across the studies, with bias related to results and conclusion. These findings are summarized in <xref rid="tab3" ref-type="table">Table 3</xref>.</p><table-wrap position="float" id="tab3"><label>Table 3</label><caption><p>AXIS risk of bias assessment summary-percentages of items satisfied.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="1" colspan="1">Author</th><th align="center" valign="top" rowspan="1" colspan="1">Intro</th><th align="center" valign="top" rowspan="1" colspan="1">Methods</th><th align="center" valign="top" rowspan="1" colspan="1">Results</th><th align="center" valign="top" rowspan="1" colspan="1">Conclusions</th><th align="center" valign="top" rowspan="1" colspan="1">Other</th><th align="left" valign="top" rowspan="1" colspan="1">Risk</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">Ting et al. 2017 (<xref rid="ref25" ref-type="bibr">25</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" rowspan="1" colspan="1">75%</td><td align="center" valign="middle" rowspan="1" colspan="1">50%</td><td align="left" valign="middle" rowspan="1" colspan="1">Moderate</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Sosale et al. 2020 (<xref rid="ref15" ref-type="bibr">15</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" rowspan="1" colspan="1">75%</td><td align="center" valign="middle" rowspan="1" colspan="1">0%</td><td align="left" valign="middle" rowspan="1" colspan="1">Moderate</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Ipp 2021 (<xref rid="ref10" ref-type="bibr">10</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="left" valign="middle" rowspan="1" colspan="1">Moderate</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Acharyya et al. 2024 (<xref rid="ref22" ref-type="bibr">22</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">90%</td><td align="center" valign="middle" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" rowspan="1" colspan="1">75%</td><td align="center" valign="middle" rowspan="1" colspan="1">0%</td><td align="left" valign="middle" rowspan="1" colspan="1">Moderate</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Lupidi et al. 2023 (<xref rid="ref12" ref-type="bibr">12</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">100%</td><td align="center" valign="middle" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" rowspan="1" colspan="1">75%</td><td align="center" valign="middle" rowspan="1" colspan="1">0%</td><td align="left" valign="middle" rowspan="1" colspan="1">Moderate</td></tr></tbody></table><table-wrap-foot><p>AXIS, Appraisal tool for Cross-Sectional Studies; %, percentage of the bias.</p></table-wrap-foot></table-wrap><p>In the risk of bias assessment of four cohort studies, the Newcastle-Ottawa Scale was applied. All four studies demonstrated a low risk of bias, in all domains such as selection, comparability, and outcome assessment (<xref rid="ref11" ref-type="bibr">11</xref>, <xref rid="ref14" ref-type="bibr">14</xref>, <xref rid="ref17" ref-type="bibr">17</xref>, <xref rid="ref24" ref-type="bibr">24</xref>). These results are detailed in <xref rid="tab4" ref-type="table">Table 4</xref>, supporting the reliability of the included cohort studies.</p><table-wrap position="float" id="tab4"><label>Table 4</label><caption><p>Asterisk rating in observational studies according Newcastle-Ottawa scale (NOS) tool.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top" rowspan="2" colspan="1">Study</th><th align="center" valign="top" colspan="4" rowspan="1">Adequacy of selection</th><th align="center" valign="top" rowspan="2" colspan="1">Comparability</th><th align="center" valign="top" colspan="3" rowspan="1">Outcome assessment</th><th align="center" valign="top" rowspan="2" colspan="1">Asterisk rating</th><th align="left" valign="top" rowspan="2" colspan="1">Overall</th></tr><tr><th align="center" valign="top" rowspan="1" colspan="1">Representative of the exposed cohorts</th><th align="center" valign="top" rowspan="1" colspan="1">Selection of the exposed cohorts</th><th align="center" valign="top" rowspan="1" colspan="1">ascertainment of exposure</th><th align="center" valign="top" rowspan="1" colspan="1">Demonstration that Outcome of Interest was Not Present at Start of Study</th><th align="center" valign="top" rowspan="1" colspan="1">Assessment of outcomes</th><th align="center" valign="top" rowspan="1" colspan="1">Follow-up period long enough for outcome to occur</th><th align="center" valign="top" rowspan="1" colspan="1">Adequacy of follow-up period among cohorts</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">Sedova et al. 2022 (<xref rid="ref14" ref-type="bibr">14</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td rowspan="1" colspan="1"/><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">**</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">8.0/9.0</td><td align="left" valign="middle" rowspan="1" colspan="1">Low</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Tokuda et al. 2022 (<xref rid="ref17" ref-type="bibr">17</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td rowspan="1" colspan="1"/><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">**</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td rowspan="1" colspan="1"/><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">7.0/9.0</td><td align="left" valign="middle" rowspan="1" colspan="1">Low</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Li et al. 2022 (<xref rid="ref11" ref-type="bibr">11</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td rowspan="1" colspan="1"/><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">**</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td rowspan="1" colspan="1"/><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">7.0/9.0</td><td align="left" valign="middle" rowspan="1" colspan="1">Low</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Limwattanayingyong et al. 2020 (<xref rid="ref24" ref-type="bibr">24</xref>)</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td rowspan="1" colspan="1"/><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td rowspan="1" colspan="1"/><td align="center" valign="middle" rowspan="1" colspan="1">**</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">*</td><td align="center" valign="middle" rowspan="1" colspan="1">7.0/9.0</td><td align="left" valign="middle" rowspan="1" colspan="1">Low</td></tr></tbody></table><table-wrap-foot><p>NOS, Newcastle-Ottawa Scale; **Indicates two stars in NOS for comparability domain; *Indicates one star for selection, comparability, or outcome assessment based on NOS guidelines for cohort studies; Adequacy of follow-up period: evaluated based on sufficient follow-up time.</p></table-wrap-foot></table-wrap></sec></sec><sec sec-type="discussion" id="sec19"><title>Discussion</title><p>The development of artificial intelligence based screening systems has led to potential use as a diagnostic tool in health care system. Evaluating the accuracy of AI in clinical settings is essential to ensure its implementation in clinical settings. Diabetic retinopathy screening is important in preventing vision loss. In this meta-analysis, we assessed the diagnostic accuracy of AI-based systems versus manual screening methods for both dilated and un-dilated eyes, for detecting DR. The aim was to determine whether AI systems could offer a comparable or superior alternative to manual methods in clinical practice.</p><p>Our results showed that AI systems demonstrated a high sensitivity across most studies. In comparison sensitivity for both dilated and un-dilated eyes using AI screening shows a good performance and specificity for AI screening and manual screening was generally comparable, with dilated eyes as well as un-dilated eyes.</p><p>These results highlight that AI systems, especially in un-dilated eye conditions, show promise for clinical use with reliable sensitivity and specificity, but variations exist depending on the system and clinical setting.</p><p>Most of the studies exhibit low risk of bias showing which shows robust methodologies and reliable findings but some validation studies have shown moderate risk of bias especially in index test and reference standards suggesting possible inconsistencies in diagnostic criteria or lack of blinding. Also the studies assessed with axis tool shows moderate risk of bias in all studies especially in the results and conclusion domain indicates potential selective reporting, which could introduce bias in outcome interpretation.</p><sec id="sec20"><title>Limitations and implications</title><p>Despite the promising outcomes, several limitations must be acknowledged. First, there is considerable heterogeneity across the included studies in terms of study settings, photographic protocols, and reference standards. The studies vary from community-based to outpatient settings, and the imaging techniques range from two-field to five-field photography with or without mydriasis. These differences may have influenced the diagnostic performance of AI based screening, limiting the generalizability of the findings. Additionally, the reference standards used for manual grading differ across studies, with some having single specialists and others using diagnoses by multiple experts, potentially affecting the accuracy of comparisons. Second, not all studies report the number of participants, making it difficult to assess the true sample size, which could impact diagnostic validity. Third, there is a significant variability among the studies in AI based screening, Variability in AI performance can arise from differences in study methodologies, dataset quality, and model training conditions. The findings highlight the need for standardized evaluation metrics and more transparent reporting to solve inconsistencies. Addressing these issues will enhance the reliability of AI applications in clinical settings and ensure robust decision-making.</p><p>Moreover, some of the studies had a moderate risk of bias which could lead to over-estimation or down-estimation of accuracy. To ensure that AI systems are safe and effective for real-world use, evaluations need to be conducted in representative clinical settings. Systems should be tested on a wide range of image qualities, and medical settings.</p></sec></sec><sec sec-type="conclusions" id="sec21"><title>Conclusion</title><p>The findings from this meta-analysis suggest that AI systems are promising for DR screening, especially in settings where high sensitivity is critical. However, further independent studies, particularly those assessing the dilated eyes screening, are required to establish the efficacy of AI in broader clinical practice. Factors such as system technical failures, and operational settings should also be considered before full implementation. In conclusion, while AI-based systems offer a valuable tool for reducing the workload on human graders, their clinical utility depends on continued rigorous evaluation and refinement.</p><sec id="sec22"><title>Future research</title><p>Future work should focus on refining AI algorithms for dilated eye conditions and exploring the integration of AI screening into routine ophthalmic practice. Large-scale, prospective validation studies will be essential to confirm these findings and guide the adoption of AI in DR screening protocols.</p></sec></sec></body><back><ack><p>The authors would like to thank the Deanship of Scientific Research at Shaqra University for supporting this work. This research is supported by the author, there are no sponsors or funds for the research.</p></ack><sec sec-type="data-availability" id="sec23"><title>Data availability statement</title><p>The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.</p></sec><sec sec-type="author-contributions" id="sec24"><title>Author contributions</title><p>HT: Conceptualization, Methodology, Project administration, Supervision, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. NU: Conceptualization, Data curation, Formal analysis, Investigation, Writing &#x02013; review &#x00026; editing, Writing &#x02013; original draft. MT: Formal analysis, Validation, Writing &#x02013; review &#x00026; editing. ID: Data curation, Formal analysis, Writing &#x02013; review &#x00026; editing. RP: Data curation, Validation, Writing &#x02013; review &#x00026; editing. SM: Formal analysis, Writing &#x02013; review &#x00026; editing. AA: Methodology, Writing &#x02013; review &#x00026; editing. ST: Formal analysis, Writing &#x02013; review &#x00026; editing. YA: Methodology, Writing &#x02013; review &#x00026; editing.</p></sec><sec sec-type="COI-statement" id="sec26"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type="ai-statement" id="sec27"><title>Generative AI statement</title><p>The authors declare that no Gen AI was used in the creation of this manuscript.</p></sec><sec sec-type="disclaimer" id="sec28"><title>Publisher&#x02019;s note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><ref-list><title>References</title><ref id="ref1"><label>1.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><collab id="coll1">World Health Organization</collab></person-group>. <source>Global report on diabetes</source>. <publisher-loc>Geneva</publisher-loc>: <publisher-name>World Health Organization</publisher-name> (<year>2016</year>).</mixed-citation></ref><ref id="ref2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teo</surname><given-names>ZL</given-names></name>
<name><surname>Tham</surname><given-names>YC</given-names></name>
<name><surname>Yu</surname><given-names>M</given-names></name>
<name><surname>Chee</surname><given-names>ML</given-names></name>
<name><surname>Rim</surname><given-names>TH</given-names></name>
<name><surname>Cheung</surname><given-names>N</given-names></name>
<etal/></person-group>. <article-title>Global prevalence of diabetic retinopathy and projection of burden through 2045: systematic review and meta-analysis</article-title>. <source>Ophthalmology</source>. (<year>2021</year>) <volume>128</volume>:<fpage>1580</fpage>&#x02013;<lpage>91</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ophtha.2021.04.027</pub-id>, PMID: <pub-id pub-id-type="pmid">33940045</pub-id>
</mixed-citation></ref><ref id="ref3"><label>3.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><collab id="coll2">World Health Organization</collab></person-group>. (<year>2023</year>) Blindness and visual impairment fact sheet. Available online at: <ext-link xlink:href="https://www.who.int/news-room/fact-sheets/detail/blindness-and-visual-impairment" ext-link-type="uri">https://www.who.int/news-room/fact-sheets/detail/blindness-and-visual-impairment</ext-link></mixed-citation></ref><ref id="ref4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piyasena</surname><given-names>M</given-names></name>
<name><surname>Murthy</surname><given-names>GVS</given-names></name>
<name><surname>Yip</surname><given-names>JLY</given-names></name>
<name><surname>Gilbert</surname><given-names>C</given-names></name>
<name><surname>Zuurmond</surname><given-names>M</given-names></name>
<name><surname>Peto</surname><given-names>T</given-names></name>
<etal/></person-group>. <article-title>Systematic review on barriers and enablers for access to diabetic retinopathy screening services in different income settings</article-title>. <source>PLoS One</source>. (<year>2019</year>) <volume>14</volume>:<fpage>e0198979</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0198979</pub-id>, PMID: <pub-id pub-id-type="pmid">31013274</pub-id>
</mixed-citation></ref><ref id="ref5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasan</surname><given-names>SU</given-names></name>
<name><surname>Siddiqui</surname><given-names>MAR</given-names></name></person-group>. <article-title>Diagnostic accuracy of smartphone-based artificial intelligence systems for detecting diabetic retinopathy: a systematic review and meta-analysis</article-title>. <source>Diabetes Res Clin Pract</source>. (<year>2023</year>) <volume>205</volume>:<fpage>110943</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.diabres.2023.110943</pub-id>, PMID: <pub-id pub-id-type="pmid">37805002</pub-id>
</mixed-citation></ref><ref id="ref6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uy</surname><given-names>H</given-names></name>
<name><surname>Fielding</surname><given-names>C</given-names></name>
<name><surname>Hohlfeld</surname><given-names>A</given-names></name>
<name><surname>Ochodo</surname><given-names>E</given-names></name>
<name><surname>Opare</surname><given-names>A</given-names></name>
<name><surname>Mukonda</surname><given-names>E</given-names></name>
<etal/></person-group>. <article-title>Diagnostic test accuracy of artificial intelligence in screening for referable diabetic retinopathy in real-world settings: a systematic review and meta-analysis</article-title>. <source>PLOS Glob Public Health</source>. (<year>2023</year>) <volume>3</volume>:<fpage>e0002160</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pgph.0002160</pub-id>, PMID: <pub-id pub-id-type="pmid">37729122</pub-id>
</mixed-citation></ref><ref id="ref7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S</given-names></name>
<name><surname>Zhang</surname><given-names>Y</given-names></name>
<name><surname>Lei</surname><given-names>S</given-names></name>
<name><surname>Zhu</surname><given-names>H</given-names></name>
<name><surname>Li</surname><given-names>J</given-names></name>
<name><surname>Wang</surname><given-names>Q</given-names></name>
<etal/></person-group>. <article-title>Performance of deep neural network-based artificial intelligence method in diabetic retinopathy screening: a systematic review and meta-analysis of diagnostic test accuracy</article-title>. <source>Eur J Endocrinol</source>. (<year>2020</year>) <volume>183</volume>:<fpage>41</fpage>&#x02013;<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1530/EJE-19-0968</pub-id>, PMID: <pub-id pub-id-type="pmid">32504495</pub-id>
</mixed-citation></ref><ref id="ref8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhelev</surname><given-names>Z</given-names></name>
<name><surname>Peters</surname><given-names>J</given-names></name>
<name><surname>Rogers</surname><given-names>M</given-names></name>
<name><surname>Allen</surname><given-names>M</given-names></name>
<name><surname>Kijauskaite</surname><given-names>G</given-names></name>
<name><surname>Seedat</surname><given-names>F</given-names></name>
<etal/></person-group>. <article-title>Test accuracy of artificial intelligence-based grading of fundus images in diabetic retinopathy screening: a systematic review</article-title>. <source>J Med Screen</source>. (<year>2023</year>) <volume>30</volume>:<fpage>97</fpage>&#x02013;<lpage>112</lpage>. doi: <pub-id pub-id-type="doi">10.1177/09691413221144382</pub-id>, PMID: <pub-id pub-id-type="pmid">36617971</pub-id>
</mixed-citation></ref><ref id="ref9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>CH</given-names></name>
<name><surname>Kyaw</surname><given-names>BM</given-names></name>
<name><surname>Smith</surname><given-names>H</given-names></name>
<name><surname>Tan</surname><given-names>CS</given-names></name>
<name><surname>Tudor Car</surname><given-names>L</given-names></name></person-group>. <article-title>Use of smartphones to detect diabetic retinopathy: scoping review and Meta-analysis of diagnostic test accuracy studies</article-title>. <source>J Med Internet Res</source>. (<year>2020</year>) <volume>22</volume>:<fpage>e16658</fpage>. doi: <pub-id pub-id-type="doi">10.2196/16658</pub-id>, PMID: <pub-id pub-id-type="pmid">32347810</pub-id>
</mixed-citation></ref><ref id="ref10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ipp</surname><given-names>E</given-names></name>
<name><surname>Liljenquist</surname><given-names>D</given-names></name>
<name><surname>Bode</surname><given-names>B</given-names></name>
<name><surname>Shah</surname><given-names>VN</given-names></name>
<name><surname>Silverstein</surname><given-names>S</given-names></name>
<name><surname>Regillo</surname><given-names>CD</given-names></name>
<etal/></person-group>. <article-title>Pivotal evaluation of an artificial intelligence system for autonomous detection of referrable and vision-threatening diabetic retinopathy</article-title>. <source>JAMA Netw Open</source>. (<year>2021</year>) <volume>4</volume>:<fpage>e2134254</fpage>. doi: <pub-id pub-id-type="doi">10.1001/jamanetworkopen.2021.34254</pub-id>, PMID: <pub-id pub-id-type="pmid">34779843</pub-id>
</mixed-citation></ref><ref id="ref11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name>
<name><surname>Ma</surname><given-names>M</given-names></name>
<name><surname>Lai</surname><given-names>M</given-names></name>
<name><surname>Gu</surname><given-names>L</given-names></name>
<name><surname>Kang</surname><given-names>M</given-names></name>
<name><surname>Wang</surname><given-names>Z</given-names></name>
<etal/></person-group>. <article-title>A stratified analysis of a deep learning algorithm in the diagnosis of diabetic retinopathy in a real-world study</article-title>. <source>J Diabetes</source>. (<year>2022</year>) <volume>14</volume>:<fpage>111</fpage>&#x02013;<lpage>20</lpage>. doi: <pub-id pub-id-type="doi">10.1111/1753-0407.13241</pub-id>, PMID: <pub-id pub-id-type="pmid">34889059</pub-id>
</mixed-citation></ref><ref id="ref12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lupidi</surname><given-names>M</given-names></name>
<name><surname>Danieli</surname><given-names>L</given-names></name>
<name><surname>Fruttini</surname><given-names>D</given-names></name>
<name><surname>Nicolai</surname><given-names>M</given-names></name>
<name><surname>Lassandro</surname><given-names>N</given-names></name>
<name><surname>Chhablani</surname><given-names>J</given-names></name>
<etal/></person-group>. <article-title>Artificial intelligence in diabetic retinopathy screening: clinical assessment using handheld fundus camera in a real-life setting</article-title>. <source>Acta Diabetol</source>. (<year>2023</year>) <volume>60</volume>:<fpage>1083</fpage>&#x02013;<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00592-023-02104-0</pub-id>, PMID: <pub-id pub-id-type="pmid">37154944</pub-id>
</mixed-citation></ref><ref id="ref13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piatti</surname><given-names>A</given-names></name>
<name><surname>Romeo</surname><given-names>F</given-names></name>
<name><surname>Manti</surname><given-names>R</given-names></name>
<name><surname>Doglio</surname><given-names>M</given-names></name>
<name><surname>Tartaglino</surname><given-names>B</given-names></name>
<name><surname>Nada</surname><given-names>E</given-names></name>
<etal/></person-group>. <article-title>Feasibility and accuracy of the screening for diabetic retinopathy using a fundus camera and an artificial intelligence pre-evaluation application</article-title>. <source>Acta Diabetol</source>. (<year>2024</year>) <volume>61</volume>:<fpage>63</fpage>&#x02013;<lpage>8</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00592-023-02172-2</pub-id>, PMID: <pub-id pub-id-type="pmid">37676288</pub-id>
</mixed-citation></ref><ref id="ref14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sedova</surname><given-names>A</given-names></name>
<name><surname>Hajdu</surname><given-names>D</given-names></name>
<name><surname>Datlinger</surname><given-names>F</given-names></name>
<name><surname>Steiner</surname><given-names>I</given-names></name>
<name><surname>Neschi</surname><given-names>M</given-names></name>
<name><surname>Aschauer</surname><given-names>J</given-names></name>
<etal/></person-group>. <article-title>Comparison of early diabetic retinopathy staging in asymptomatic patients between autonomous AI-based screening and human-graded ultra-widefield colour fundus images</article-title>. <source>Eye</source>. (<year>2022</year>) <volume>36</volume>:<fpage>510</fpage>&#x02013;<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41433-021-01912-4</pub-id>, PMID: <pub-id pub-id-type="pmid">35132211</pub-id>
</mixed-citation></ref><ref id="ref15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sosale</surname><given-names>B</given-names></name>
<name><surname>Sosale</surname><given-names>AR</given-names></name>
<name><surname>Murthy</surname><given-names>H</given-names></name>
<name><surname>Sengupta</surname><given-names>S</given-names></name>
<name><surname>Naveenam</surname><given-names>M</given-names></name></person-group>. <article-title>Medios-an offline, smartphone-based artificial intelligence algorithm for the diagnosis of diabetic retinopathy</article-title>. <source>Indian J Ophthalmol</source>. (<year>2020</year>) <volume>68</volume>:<fpage>391</fpage>&#x02013;<lpage>5</lpage>. doi: <pub-id pub-id-type="doi">10.4103/ijo.IJO_1203_19</pub-id>, PMID: <pub-id pub-id-type="pmid">31957735</pub-id>
</mixed-citation></ref><ref id="ref16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Surya</surname><given-names>J</given-names></name>
<name><surname>Garima</surname></name>
<name><surname>Pandy</surname><given-names>N</given-names></name>
<name><surname>Hyungtaek Rim</surname><given-names>T</given-names></name>
<name><surname>Lee</surname><given-names>G</given-names></name>
<name><surname>Priya</surname><given-names>MNS</given-names></name>
<etal/></person-group>. <article-title>Efficacy of deep learning-based artificial intelligence models in screening and referring patients with diabetic retinopathy and glaucoma</article-title>. <source>Indian J Ophthalmol</source>. (<year>2023</year>) <volume>71</volume>:<fpage>3039</fpage>&#x02013;<lpage>45</lpage>. doi: <pub-id pub-id-type="doi">10.4103/IJO.IJO_11_23</pub-id>, PMID: <pub-id pub-id-type="pmid">37530278</pub-id>
</mixed-citation></ref><ref id="ref17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tokuda</surname><given-names>Y</given-names></name>
<name><surname>Tabuchi</surname><given-names>H</given-names></name>
<name><surname>Nagasawa</surname><given-names>T</given-names></name>
<name><surname>Tanabe</surname><given-names>M</given-names></name>
<name><surname>Deguchi</surname><given-names>H</given-names></name>
<name><surname>Yoshizumi</surname><given-names>Y</given-names></name>
<etal/></person-group>. <article-title>Automatic diagnosis of diabetic retinopathy stage focusing exclusively on retinal hemorrhage</article-title>. <source>Medicina</source>. (<year>2022</year>) <volume>58</volume>:<fpage>1681</fpage>. doi: <pub-id pub-id-type="doi">10.3390/medicina58111681</pub-id><pub-id pub-id-type="pmid">36422220</pub-id>
</mixed-citation></ref><ref id="ref18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soto-Pedre</surname><given-names>E</given-names></name>
<name><surname>Navea</surname><given-names>A</given-names></name>
<name><surname>Millan</surname><given-names>S</given-names></name>
<name><surname>Hernaez-Ortega</surname><given-names>MC</given-names></name>
<name><surname>Morales</surname><given-names>J</given-names></name>
<name><surname>Desco</surname><given-names>MC</given-names></name>
<etal/></person-group>. <article-title>Evaluation of automated image analysis software for the detection of diabetic retinopathy to reduce the ophthalmologists' workload</article-title>. <source>Acta Ophthalmol</source>. (<year>2015</year>) <volume>93</volume>:<fpage>e52</fpage>&#x02013;<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1111/aos.12481</pub-id>, PMID: <pub-id pub-id-type="pmid">24975456</pub-id>
</mixed-citation></ref><ref id="ref19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajalakshmi</surname><given-names>R</given-names></name>
<name><surname>Subashini</surname><given-names>R</given-names></name>
<name><surname>Anjana</surname><given-names>RM</given-names></name>
<name><surname>Mohan</surname><given-names>V</given-names></name></person-group>. <article-title>Automated diabetic retinopathy detection in smartphone-based fundus photography using artificial intelligence</article-title>. <source>Eye (Lond)</source>. (<year>2018</year>) <volume>32</volume>:<fpage>1138</fpage>&#x02013;<lpage>44</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41433-018-0064-9</pub-id>, PMID: <pub-id pub-id-type="pmid">29520050</pub-id>
</mixed-citation></ref><ref id="ref20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>K</given-names></name>
<name><surname>Jayadev</surname><given-names>C</given-names></name>
<name><surname>Nittala</surname><given-names>MG</given-names></name>
<name><surname>Velaga</surname><given-names>SB</given-names></name>
<name><surname>Ramachandra</surname><given-names>CA</given-names></name>
<name><surname>Bhaskaranand</surname><given-names>M</given-names></name>
<etal/></person-group>. <article-title>Automated detection of diabetic retinopathy lesions on ultrawidefield pseudocolour images</article-title>. <source>Acta Ophthalmol</source>. (<year>2018</year>) <volume>96</volume>:<fpage>e168</fpage>&#x02013;<lpage>73</lpage>. doi: <pub-id pub-id-type="doi">10.1111/aos.13528</pub-id>, PMID: <pub-id pub-id-type="pmid">28926199</pub-id>
</mixed-citation></ref><ref id="ref21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Z</given-names></name>
<name><surname>Keel</surname><given-names>S</given-names></name>
<name><surname>Liu</surname><given-names>C</given-names></name>
<name><surname>He</surname><given-names>Y</given-names></name>
<name><surname>Meng</surname><given-names>W</given-names></name>
<name><surname>Scheetz</surname><given-names>J</given-names></name>
<etal/></person-group>. <article-title>An automated grading system for detection of vision-threatening referable diabetic retinopathy on the basis of color fundus photographs</article-title>. <source>Diabetes Care</source>. (<year>2018</year>) <volume>41</volume>:<fpage>2509</fpage>&#x02013;<lpage>16</lpage>. doi: <pub-id pub-id-type="doi">10.2337/dc18-0147</pub-id>, PMID: <pub-id pub-id-type="pmid">30275284</pub-id>
</mixed-citation></ref><ref id="ref22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acharyya</surname><given-names>M</given-names></name>
<name><surname>Moharana</surname><given-names>B</given-names></name>
<name><surname>Jain</surname><given-names>S</given-names></name>
<name><surname>Tandon</surname><given-names>M</given-names></name></person-group>. <article-title>A double-blinded study for quantifiable assessment of the diagnostic accuracy of AI tool "ADVEN-i" in identifying diseased fundus images including diabetic retinopathy on a retrospective data</article-title>. <source>Indian J Ophthalmol</source>. (<year>2024</year>) <volume>72</volume>:<fpage>S46</fpage>&#x02013;<lpage>s52</lpage>. doi: <pub-id pub-id-type="doi">10.4103/IJO.IJO_3342_22</pub-id>, PMID: <pub-id pub-id-type="pmid">38131542</pub-id>
</mixed-citation></ref><ref id="ref23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arenas-Cavalli</surname><given-names>JT</given-names></name>
<name><surname>Abarca</surname><given-names>I</given-names></name>
<name><surname>Rojas-Contreras</surname><given-names>M</given-names></name>
<name><surname>Bernuy</surname><given-names>F</given-names></name>
<name><surname>Donoso</surname><given-names>R</given-names></name></person-group>. <article-title>Clinical validation of an artificial intelligence-based diabetic retinopathy screening tool for a national health system</article-title>. <source>Eye (Lond)</source>. (<year>2022</year>) <volume>36</volume>:<fpage>78</fpage>&#x02013;<lpage>85</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41433-020-01366-0</pub-id>, PMID: <pub-id pub-id-type="pmid">33432168</pub-id>
</mixed-citation></ref><ref id="ref24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Limwattanayingyong</surname><given-names>J</given-names></name>
<name><surname>Nganthavee</surname><given-names>V</given-names></name>
<name><surname>Seresirikachorn</surname><given-names>K</given-names></name>
<name><surname>Singalavanija</surname><given-names>T</given-names></name>
<name><surname>Soonthornworasiri</surname><given-names>N</given-names></name>
<name><surname>Ruamviboonsuk</surname><given-names>V</given-names></name>
<etal/></person-group>. <article-title>Longitudinal screening for diabetic retinopathy in a Nationwide screening program: comparing deep learning and human graders</article-title>. <source>J Diabetes Res</source>. (<year>2020</year>) <volume>2020</volume>:<fpage>8839376</fpage>. doi: <pub-id pub-id-type="doi">10.1155/2020/8839376</pub-id><pub-id pub-id-type="pmid">33381600</pub-id>
</mixed-citation></ref><ref id="ref25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ting</surname><given-names>DSW</given-names></name>
<name><surname>Cheung</surname><given-names>CYL</given-names></name>
<name><surname>Lim</surname><given-names>G</given-names></name>
<name><surname>Tan</surname><given-names>GSW</given-names></name>
<name><surname>Quang</surname><given-names>ND</given-names></name>
<name><surname>Gan</surname><given-names>A</given-names></name>
<etal/></person-group>. <article-title>Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes</article-title>. <source>JAMA</source>. (<year>2017</year>) <volume>318</volume>:<fpage>2211</fpage>&#x02013;<lpage>23</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jama.2017.18152</pub-id>, PMID: <pub-id pub-id-type="pmid">29234807</pub-id>
</mixed-citation></ref><ref id="ref26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonz&#x000e1;lez-Gonzalo</surname><given-names>C</given-names></name>
<name><surname>S&#x000e1;nchez-Guti&#x000e9;rrez</surname><given-names>V</given-names></name>
<name><surname>Hern&#x000e1;ndez-Mart&#x000ed;nez</surname><given-names>P</given-names></name>
<name><surname>Contreras</surname><given-names>I</given-names></name>
<name><surname>Lechanteur</surname><given-names>YT</given-names></name>
<name><surname>Domanian</surname><given-names>A</given-names></name>
<etal/></person-group>. <article-title>Evaluation of a deep learning system for the joint automated detection of diabetic retinopathy and age-related macular degeneration</article-title>. <source>Acta Ophthalmol</source>. (<year>2020</year>) <volume>98</volume>:<fpage>368</fpage>&#x02013;<lpage>77</lpage>. doi: <pub-id pub-id-type="doi">10.1111/aos.14306</pub-id>, PMID: <pub-id pub-id-type="pmid">31773912</pub-id>
</mixed-citation></ref><ref id="ref27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>GM</given-names></name>
<name><surname>Chen</surname><given-names>M-J</given-names></name>
<name><surname>Yeh</surname><given-names>C-H</given-names></name>
<name><surname>Lin</surname><given-names>Y-Y</given-names></name>
<name><surname>Kuo</surname><given-names>H-Y</given-names></name>
<name><surname>Lin</surname><given-names>M-H</given-names></name>
<etal/></person-group>. <article-title>Transforming retinal photographs to entropy images in deep learning to improve automated detection for diabetic retinopathy</article-title>. <source>J Ophthalmol</source>. (<year>2018</year>) <volume>2018</volume>:<fpage>2159702</fpage>. doi: <pub-id pub-id-type="doi">10.1155/2018/2159702</pub-id><pub-id pub-id-type="pmid">30275989</pub-id>
</mixed-citation></ref><ref id="ref28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>F</given-names></name>
<name><surname>Liu</surname><given-names>Z</given-names></name>
<name><surname>Chen</surname><given-names>H</given-names></name>
<name><surname>Jiang</surname><given-names>M</given-names></name>
<name><surname>Zhang</surname><given-names>X</given-names></name>
<name><surname>Wu</surname><given-names>Z</given-names></name></person-group>. <article-title>Automatic detection of diabetic retinopathy in retinal fundus photographs based on deep learning algorithm</article-title>. <source>Transl Vis Sci Technol</source>. (<year>2019</year>) <volume>8</volume>:<fpage>4</fpage>. doi: <pub-id pub-id-type="doi">10.1167/tvst.8.6.4</pub-id>, PMID: <pub-id pub-id-type="pmid">31737428</pub-id>
</mixed-citation></ref><ref id="ref29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>MB</given-names></name>
<name><surname>Abr&#x000e0;moff</surname><given-names>MD</given-names></name>
<name><surname>Folk</surname><given-names>JC</given-names></name>
<name><surname>Mathenge</surname><given-names>W</given-names></name>
<name><surname>Bastawrous</surname><given-names>A</given-names></name>
<name><surname>Peto</surname><given-names>T</given-names></name></person-group>. <article-title>Results of automated retinal image analysis for detection of diabetic retinopathy from the Nakuru study, Kenya</article-title>. <source>PLoS One</source>. (<year>2015</year>) <volume>10</volume>:<fpage>e0139148</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0139148</pub-id>, PMID: <pub-id pub-id-type="pmid">26425849</pub-id>
</mixed-citation></ref><ref id="ref30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gargeya</surname><given-names>R</given-names></name>
<name><surname>Leng</surname><given-names>T</given-names></name></person-group>. <article-title>Automated identification of diabetic retinopathy using deep learning</article-title>. <source>Ophthalmology</source>. (<year>2017</year>) <volume>124</volume>:<fpage>962</fpage>&#x02013;<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ophtha.2017.02.008</pub-id>, PMID: <pub-id pub-id-type="pmid">28359545</pub-id>
</mixed-citation></ref><ref id="ref31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abr&#x000e0;moff</surname><given-names>MD</given-names></name>
<name><surname>Lou</surname><given-names>Y</given-names></name>
<name><surname>Erginay</surname><given-names>A</given-names></name>
<name><surname>Clarida</surname><given-names>W</given-names></name>
<name><surname>Amelon</surname><given-names>R</given-names></name>
<name><surname>Folk</surname><given-names>JC</given-names></name>
<etal/></person-group>. <article-title>Improved automated detection of diabetic retinopathy on a publicly available dataset through integration of deep learning</article-title>. <source>Invest Ophthalmol Vis Sci</source>. (<year>2016</year>) <volume>57</volume>:<fpage>5200</fpage>&#x02013;<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1167/iovs.16-19964</pub-id>, PMID: <pub-id pub-id-type="pmid">27701631</pub-id>
</mixed-citation></ref><ref id="ref32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>W</given-names></name>
<name><surname>Zhong</surname><given-names>J</given-names></name>
<name><surname>Yang</surname><given-names>S</given-names></name>
<name><surname>Gao</surname><given-names>Z</given-names></name>
<name><surname>Hu</surname><given-names>J</given-names></name>
<name><surname>Chen</surname><given-names>Y</given-names></name>
<etal/></person-group>. <article-title>Automated identification and grading system of diabetic retinopathy using deep neural networks</article-title>. <source>Knowl-Based Syst</source>. (<year>2019</year>) <volume>175</volume>:<fpage>12</fpage>&#x02013;<lpage>25</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.knosys.2019.03.016</pub-id></mixed-citation></ref><ref id="ref33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X</given-names></name>
<name><surname>Li</surname><given-names>F</given-names></name>
<name><surname>Li</surname><given-names>D</given-names></name>
<name><surname>Wei</surname><given-names>Q</given-names></name>
<name><surname>Han</surname><given-names>X</given-names></name>
<name><surname>Zhang</surname><given-names>B</given-names></name>
<etal/></person-group>. <article-title>Automated detection of severe diabetic retinopathy using deep learning method</article-title>. <source>Graefes Arch Clin Exp Ophthalmol</source>. (<year>2022</year>) 260:<fpage>849</fpage>&#x02013;<lpage>856</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00417-021-05402-x</pub-id></mixed-citation></ref><ref id="ref34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>PS</given-names></name>
<name><surname>Deepak</surname><given-names>RU</given-names></name>
<name><surname>Sathar</surname><given-names>A</given-names></name>
<name><surname>Sahasranamam</surname><given-names>V</given-names></name>
<name><surname>Rajesh Kumar</surname><given-names>R</given-names></name></person-group>. <article-title>Automated detection system for diabetic retinopathy using two field fundus photography</article-title>. <source>Procedia Comput Sci</source>. (<year>2016</year>) <volume>93</volume>:<fpage>486</fpage>&#x02013;<lpage>94</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.procs.2016.07.237</pub-id></mixed-citation></ref></ref-list></back></article>