<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" id="tops12679" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Top Cogn Sci</journal-id><journal-id journal-id-type="iso-abbrev">Top Cogn Sci</journal-id><journal-id journal-id-type="doi">10.1111/(ISSN)1756-8765</journal-id><journal-id journal-id-type="publisher-id">TOPS</journal-id><journal-title-group><journal-title>Topics in Cognitive Science</journal-title></journal-title-group><issn pub-type="ppub">1756-8757</issn><issn pub-type="epub">1756-8765</issn><publisher><publisher-name>John Wiley and Sons Inc.</publisher-name><publisher-loc>Hoboken</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">37384870</article-id><article-id pub-id-type="pmc">PMC12093911</article-id>
<article-id pub-id-type="doi">10.1111/tops.12679</article-id><article-id pub-id-type="publisher-id">TOPS12679</article-id><article-categories><subj-group subj-group-type="overline"><subject>Original Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Fostering Collective Intelligence in Human&#x02013;AI Collaboration: Laying the Groundwork for COHUMAIN</article-title><alt-title alt-title-type="left-running-head">P. Gupta et al.</alt-title></title-group><contrib-group><contrib id="tops12679-cr-0001" contrib-type="author" corresp="yes"><name><surname>Gupta</surname><given-names>Pranav</given-names></name><xref rid="tops12679-aff-0001" ref-type="aff">
<sup>1</sup>
</xref><address><email>pranavgu@illinois.edu</email></address></contrib><contrib id="tops12679-cr-0002" contrib-type="author"><name><surname>Nguyen</surname><given-names>Thuy Ngoc</given-names></name><xref rid="tops12679-aff-0002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib id="tops12679-cr-0003" contrib-type="author"><name><surname>Gonzalez</surname><given-names>Cleotilde</given-names></name><xref rid="tops12679-aff-0002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib id="tops12679-cr-0004" contrib-type="author"><name><surname>Woolley</surname><given-names>Anita Williams</given-names></name><xref rid="tops12679-aff-0003" ref-type="aff">
<sup>3</sup>
</xref></contrib></contrib-group><aff id="tops12679-aff-0001">
<label>
<sup>1</sup>
</label>
<named-content content-type="organisation-division">Gies College of Business</named-content>
<institution>University of Illinois, Urbana&#x02010;Champaign</institution>
</aff><aff id="tops12679-aff-0002">
<label>
<sup>2</sup>
</label>
<named-content content-type="organisation-division">Department of Social &#x00026; Decision Sciences</named-content>
<institution>Carnegie Mellon University</institution>
</aff><aff id="tops12679-aff-0003">
<label>
<sup>3</sup>
</label>
<named-content content-type="organisation-division">Tepper School of Business</named-content>
<institution>Carnegie Mellon University</institution>
</aff><author-notes><corresp id="correspondenceTo">
<label>*</label>Correspondence should be sent to Pranav Gupta, Gies College of Business, University of Illinois, Urbana&#x02010;Champaign, 6 Wohlers Hall, 1206 S. Sixth St., Champaign, IL 61820, USA. Email: <email>pranavgu@illinois.edu</email>
<break/>
</corresp></author-notes><pub-date pub-type="epub"><day>29</day><month>6</month><year>2023</year></pub-date><pub-date pub-type="ppub"><month>4</month><year>2025</year></pub-date><volume>17</volume><issue seq="50">2</issue><issue-id pub-id-type="doi">10.1111/tops.v17.2</issue-id><issue-title content-type="special-issue-title">Topic: Fellows of the Cognitive Science Society; Editor: Andrea Bender &#x02014; Topic: Building the Socio&#x02010;Cognitive Architecture of COHUMAIN: Collective Human&#x02013;Machine Intelligence; Editors: Cleotilde Gonzalez, Henny Admoni, Scott Brown and Anita Williams Woolley</issue-title><fpage>189</fpage><lpage>216</lpage><history>
<date date-type="rev-recd"><day>12</day><month>6</month><year>2023</year></date>
<date date-type="received"><day>30</day><month>6</month><year>2022</year></date>
<date date-type="accepted"><day>12</day><month>6</month><year>2023</year></date>
</history><permissions><!--&#x000a9; 2025 Cognitive Science Society LLC.--><copyright-statement content-type="article-copyright">&#x000a9; 2023 The Authors. <italic toggle="yes">Topics in Cognitive Science</italic> published by Wiley Periodicals LLC on behalf of Cognitive Science Society.</copyright-statement><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="file:TOPS-17-189.pdf"/><abstract><title>Abstract</title><p>Artificial Intelligence (AI) powered machines are increasingly mediating our work and many of our managerial, economic, and cultural interactions. While technology enhances individual capability in many ways, how do we know that the sociotechnical system as a whole, consisting of a complex web of hundreds of human&#x02013;machine interactions, is exhibiting collective intelligence? Research on human&#x02013;machine interactions has been conducted within different disciplinary silos, resulting in social science models that underestimate technology and vice versa. Bringing together these different perspectives and methods at this juncture is critical. To truly advance our understanding of this important and quickly evolving area, we need vehicles to help research connect across disciplinary boundaries.</p><p>This paper advocates for establishing an interdisciplinary research domain&#x02014;Collective Human&#x02010;Machine Intelligence (COHUMAIN). It outlines a research agenda for a holistic approach to designing and developing the dynamics of sociotechnical systems. In illustrating the kind of approach, we envision in this domain, we describe recent work on a sociocognitive architecture, the transactive systems model of collective intelligence, that articulates the critical processes underlying the emergence and maintenance of collective intelligence and extend it to human&#x02013;AI systems. We connect this with synergistic work on a compatible cognitive architecture, instance&#x02010;based learning theory and apply it to the design of AI agents that collaborate with humans. We present this work as a call to researchers working on related questions to not only engage with our proposal but also develop their own sociocognitive architectures and unlock the real potential of human&#x02013;machine intelligence.</p></abstract><abstract id="tops12679-abs-1001" abstract-type="short"><p>How do we know that a sociotechnical system, as a whole, is exhibiting collective intelligence? We outline a research agenda for COHUMAIN by proposing sociocognitive architectures as a vehicle for designing and developing the dynamics of sociotechnical systems and illustrate this holistic approach by discussing the transactive systems model of collective intelligence and instance&#x02010;based learning.</p></abstract><kwd-group kwd-group-type="author-generated"><kwd id="tops12679-kwd-0001">Human&#x02013;AI collaboration</kwd><kwd id="tops12679-kwd-0002">Collective intelligence</kwd><kwd id="tops12679-kwd-0003">Sociocognitive architectures</kwd><kwd id="tops12679-kwd-0004">Cognitive architectures</kwd><kwd id="tops12679-kwd-0005">Artificial social intelligence</kwd><kwd id="tops12679-kwd-0006">Instance&#x02010;based learning</kwd></kwd-group><funding-group><award-group id="funding-0001"><funding-source>&#x000a0;&#x000a0;Defense Advanced Research Projects Agency</funding-source><award-id>W911NF&#x02010;20&#x02010;1&#x02010;0006</award-id></award-group></funding-group><counts><fig-count count="2"/><table-count count="1"/><page-count count="28"/><word-count count="13916"/></counts><custom-meta-group><custom-meta><meta-name>source-schema-version-number</meta-name><meta-value>2.0</meta-value></custom-meta><custom-meta><meta-name>cover-date</meta-name><meta-value>April 2025</meta-value></custom-meta><custom-meta><meta-name>details-of-publishers-convertor</meta-name><meta-value>Converter:WILEY_ML3GV2_TO_JATSPMC version:6.5.6 mode:remove_FC converted:21.05.2025</meta-value></custom-meta></custom-meta-group></article-meta><notes><fn-group><fn id="tops12679-note-0002"><p>This article is part of the topic &#x0201c;Building the Socio&#x02010;Cognitive Architecture of COHUMAIN: Collective Human&#x02010;Machine Intelligence,&#x0201d; Cleotilde Gonzalez, Henny Admoni, Scott Brown and Anita Williams Woolley (Topic Editors).</p></fn></fn-group></notes></front><body><sec id="tops12679-sec-0010"><label>1</label><title>Introduction</title><p>Work on artificial intelligence (AI) has grown at an exponential pace. From feedback&#x02010;loop cybernetics and generalized cognitive architectures to reinforcement learning models that organize knowledge and iteratively improve themselves, we now have large&#x02010;language models capable of leveraging the deep patterns in our collective knowledge to generate new insights. As the scope and penetration of AI&#x02010;powered machines explode, the volume of information and pace of change is outstripping our bounded cognitive capacity. Hence, we have come to rely on physical and digital machines to mediate our collective actions&#x02014;augment our memory, manage our attention, and help us coordinate our collective decisions. In adjacent fields, social scientists are refining their understanding of collective intelligence (CI) in human systems, broadly defined as a group's ability to solve various problems across different environments (Riedl, Kim, Gupta, Malone, &#x00026; Woolley, <xref rid="tops12679-bib-0104" ref-type="bibr">2021</xref>; Woolley, Chabris, Pentland, Hashmi, &#x00026; Malone, <xref rid="tops12679-bib-0131" ref-type="bibr">2010</xref>). We have moved from simply harnessing the wisdom of crowds for solving prediction problems to exploring how diversity and group structure help humans distributed across the globe to organize dynamically and solve collaboration problems.</p><p>While significant progress has been made in the development of AI, as well as the social scientific development of CI, what has developed more slowly is the holistic, integrated understanding of human&#x02013;machine systems. <italic toggle="yes">How do we know that such a sociotechnical system as a whole, consisting of a complex web of hundreds of human&#x02013;machine interactions, is exhibiting CI?</italic> Extant research on human&#x02013;machine interactions occurs in different disciplinary silos and focuses primarily on the phenomena of interest to the specific discipline. Consideration of adjacent domains is secondary and results in the implementation of technical systems that produce &#x0201c;unexpected&#x0201d; adverse outcomes that were arguably foreseeable had they been developed in a more interdisciplinary environment. We assert that creating vehicles to integrate the sciences at this juncture <italic toggle="yes">is critical</italic>. This needs to occur during the earlier phases of development rather than at later stages when we are left to deal with the unintended consequences. Not doing so opens us up to not just organizational or market inefficiencies but also significant societal risks. Given the cumulative nature of this work, understanding how to design and implement effective human&#x02013;machine collaboration can have important implications for the design of future intelligent systems and artificial general intelligence. Unfortunately, we lack a vehicle for systematically translating and integrating insights across fields into a shared and holistic frame (see related efforts in Galesic et&#x000a0;al., <xref rid="tops12679-bib-0045" ref-type="bibr">2023</xref>).</p><p>In this paper, we address this gap by proposing a research agenda for <italic toggle="yes">Collective Human&#x02010;Machine Intelligence</italic> (COHUMAIN)&#x02014;an interdisciplinary research domain to facilitate the development of holistic models that inform the design and study of collaboration dynamics in sociotechnical systems. The initial development of the field of AI benefited significantly from the variety of cognitive architectures that articulated the key components and processes of an individual agent's decision&#x02010;making (e.g., general problem solver by Newell, &#x00026; Simon, <xref rid="tops12679-bib-0090" ref-type="bibr">1972</xref>; ACT&#x02010;R by Anderson, Conrad, &#x00026; Corbett, <xref rid="tops12679-bib-0004" ref-type="bibr">1989</xref>). Drawing a parallel to cognitive architectures, our main claim is to use sociocognitive architectures to study this issue systematically, integrate interdisciplinary knowledge, and push COHUMAIN research for multiagent systems. We identify four problems unique to this endeavor and recommend two features necessary for sociocognitive architectures. And briefly review extant work on human&#x02013;machine interaction, human&#x02013;AI trust, and machine theory of mind that address our understanding of these issues so far.</p><p>We then present a new sociocognitive architecture, the transactive systems model of collective intelligence (TSM&#x02010;CI; Gupta &#x00026; Woolley, <xref rid="tops12679-bib-0057" ref-type="bibr">2021</xref>), which articulates the three functional systems governing collective memory, attention, and reasoning that form the core of any intelligent sociotechnical system, including the domain of collective human&#x02013;machine intelligence. We extend the transactive systems model to COHUMAIN by discussing how AI agents can augment collective memory, attention, and reasoning systems. Finally, as a third contribution, we highlight the value of designing AI agents with cognitive architectures that align with the encompassing sociocognitive architecture. Specifically, discussing instance&#x02010;based learning theory (IBLT; Gonzalez, <xref rid="tops12679-bib-0048" ref-type="bibr">2013</xref>; Gonzalez, Lerch, &#x00026; Lebiere, <xref rid="tops12679-bib-0051" ref-type="bibr">2003</xref>), a cognitive architecture for developing AI agents compatible with the TSM&#x02010;CI.</p><p>By proposing COHUMAIN and illustrating a sociocognitive architecture as a vehicle for integrating disciplinary perspectives, we wish to spark the interest of researchers across fields to not only engage with our proposal but also develop their own sociocognitive architectures and unlock the real potential of human&#x02013;machine intelligence.</p></sec><sec id="tops12679-sec-0020"><label>2</label><title>COHUMAIN: A holistic and interdisciplinary approach to design of sociotechnical systems</title><p>Tapping into the true potential of human&#x02013;AI collaboration requires a systems&#x02010;level comprehension of how humans and machines coordinate interdependent actions in response to their environment and how humans and machines make sense of each others&#x02019; cognitive states and resources that guide their said interdependent actions. This understanding will require the integration of social science and AI as well as the integration of traditional research and applied technical design, as the scientific and applied approaches can iteratively build knowledge together more quickly to advance progress. The scientific analysis of the system's emergent behaviors guides architectural design choices, which in turn changes system behavior.</p><p>Advocacy for a systems&#x02010;level approach dates back to Newell (<xref rid="tops12679-bib-0089" ref-type="bibr">1973</xref>), who argued for the value of systems&#x02010;level research as a vehicle for integration in cognitive science and AI, claiming &#x0201c;You can't play 20 questions with nature and win.&#x0201d; A cognitive architecture provides a theoretical framework to unify many relationships that enables the testing of multicausal theories rather than the more narrowly scoped questions of traditional research that test one or two causal links. Cognitive architectures enable researchers to refine systems theory by testing claims, playing out implications, and iteratively shaping the architectural design for additional investigation cycles.</p><p>Building on the intellectual heritage of cognitive architectures, we propose that researchers collaborate to develop systems&#x02010;level sociocognitive architectures to advance research in COHUMAIN. Doing so will help advance COHUMAIN by providing common ground for integrating disciplinary perspectives. Just as a cognitive architecture specifies the underlying infrastructure, components, and functional processes of an individually intelligent agent (Anderson &#x00026; Lebiere, <xref rid="tops12679-bib-0005" ref-type="bibr">2014</xref>; Langley., Laird, &#x00026; Rogers, <xref rid="tops12679-bib-0069" ref-type="bibr">2009</xref>), a sociocognitive architecture specifies the underlying infrastructure, components, and functional processes for a multiagent, sociotechnical system, particularly a complex adaptive system that is capable of general problem&#x02010;solving. That is, exhibit collective intelligence, as CI is broadly defined as the ability of any group to solve a broad range of problems or maintain performance in a continuously changing environment (Gupta, <xref rid="tops12679-bib-0055" ref-type="bibr">2022</xref>; Riedl et&#x000a0;al., <xref rid="tops12679-bib-0104" ref-type="bibr">2021</xref>; Woolley et&#x000a0;al., <xref rid="tops12679-bib-0131" ref-type="bibr">2010</xref>).</p><p>Unfortunately, there is no straightforward method for building and combining individual&#x02010;level cognitive architectures into the collective, sociocognitive architectures needed to support an integrated interdisciplinary approach to COHUMAIN research. Cognitive architectures aim to build autonomous general problem solvers or AI by asking how an autonomous agent perceives, understands, and acts in the environment productively. By contrast, sociocognitive architectures ask how <italic toggle="yes">multiple</italic> autonomous agents (humans and AI agents) collaborate and problem&#x02010;solve <italic toggle="yes">together</italic>. This involves working interdependently by collectively perceiving, thinking, and acting together in the environment productively. Progress on the former does not guarantee progress on the latter, as sociocognitive architectures require both an understanding of how individual agents process information and make decisions as well as how, in a collective context, they affect one another and adapt to complement the processes of other agents and serve to maintain the coherence of the system as a whole. Thus, cognitive architectures provide an important and complementary input. Yet, we need to build on them using a slightly different approach for COHUMAIN research, one that captures the nature of the complex adaptive systems required for CI.</p><p>We assert that any sociocognitive architecture, even one that is minimally scoped, will need to address four core problems to enable the alignment and coordination between humans and AI agents necessary for CI's emergence. The four core problems (P1&#x02013;P4 depicted in Table&#x000a0;<xref rid="tops12679-tbl-0001" ref-type="table">1</xref> and Fig.&#x000a0;<xref rid="tops12679-fig-0001" ref-type="fig">1</xref>) reveal two categories of processes that are necessary for any sociocognitive architecture that exhibits CI. First, collaborators engage in metacognitive processes to access each others&#x02019; mental states and collective cognitive resources, that is, develop a reasonable theory of mind (ToM) (P1 and P3). Second, through interacting with one another, collaborators gain information about environmental changes and dynamically evolve shared norms and routines to align mental states and coordinate collective cognitive resources (P2 and P4). The successful result of these processes will be the formation of collective cognition, whereby collaborators vastly expand their collective cognitive capabilities. The effective enactment of these two sets of processes will serve to build a foundation of trust in the human&#x02013;AI system, as perceiving the expansion of collective capability will contribute to the cognitive bases of trust and observing ongoing engagement in joint activity to achieve shared goals will contribute to the affective bases of trust (Glikson &#x00026; Woolley, <xref rid="tops12679-bib-0047" ref-type="bibr">2020</xref>).</p><table-wrap position="float" id="tops12679-tbl-0001" content-type="Table"><label>Table 1</label><caption><p>Four core problems (P1&#x02013;P4) underlying the emergence of collective intelligence in human&#x02013;machine systems: Formulating a research agenda for the design of sociocognitive architectures for COHUMAIN (collective human&#x02010;machine intelligence)</p></caption><table frame="hsides" rules="groups"><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/><thead><tr style="border-bottom:solid 1px #000000" valign="bottom"><th align="center" valign="bottom" rowspan="1" colspan="1"/><th align="center" valign="bottom" rowspan="1" colspan="1">Between&#x02010;Member Metacognitive Processes</th><th align="center" valign="bottom" rowspan="1" colspan="1">Between&#x02010;Member Interactions</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Mental states</td><td align="left" rowspan="1" colspan="1">
<bold>P1</bold>. How do individual members perceive and represent each others&#x02019; mental states (e.g., goals, beliefs, preferences)? How does doing so shape their own mental states and support the emergence of collective cognition?</td><td align="left" rowspan="1" colspan="1">
<bold>P2</bold>. Given diverse and changing mental states, how do members engage in trustworthy interactions to dynamically align their mental states and select joint priorities that maximize collective outcomes?</td></tr><tr><td align="left" rowspan="1" colspan="1">Cognitive resources</td><td align="left" rowspan="1" colspan="1">
<bold>P3</bold>. How do individual members perceive and represent each others' cognitive resources (e.g., specialized knowledge and skills, information&#x02010;processing capacity)? How does recognizing self&#x02010;other differences in cognitive resources facilitate the development of collective cognition?</td><td align="left" rowspan="1" colspan="1">
<bold>P4</bold>. Given distributed and changing cognitive resources, how do members develop and engage shared norms of interactions to dynamically coordinate interdependent actions that ensure efficient utilization of collective resources?</td></tr></tbody></table><permissions><copyright-holder>John Wiley &#x00026; Sons, Ltd.</copyright-holder></permissions></table-wrap><fig position="float" fig-type="Fig." id="tops12679-fig-0001"><label>Fig. 1</label><caption><p>Schematic for the design of the sociocognitive architecture of sociotechnical systems. The two generic features of a minimal sociocognitive architecture are highlighted: metacognitive processes (P1 and P3) and human&#x02013;AI interactions (P2 and P4).</p><p>Note. It only depicts the schema for human&#x02013;AI interactions and does not show human&#x02013;human and AI&#x02013;AI schemas.</p></caption><graphic xlink:href="TOPS-17-189-g002" position="anchor" id="jats-graphic-1"/></fig><p>A recent information&#x02010;theoretic approach that models CI from first principles finds that agent features consistent with ToM and goal alignment are necessary conditions for multiple agents to optimize their joint outcomes (Kaufmann, Gupta, &#x00026; Taylor, <xref rid="tops12679-bib-0064" ref-type="bibr">2021</xref>). Thus, <italic toggle="yes">we claim that any sociocognitive architecture developed to address COHUMAIN needs to specify mechanisms for (1) between&#x02010;member metacognition and (2) the development of engagement rules that enable coordinated action and trust development</italic>.</p><p>It is important to note that a key assumption we make here is that all autonomous machines or AI agents are &#x0201c;designed systems&#x0201d; and hence, unlike humans, do not possess higher order goal autonomy.<xref rid="tops12679-note-0001" ref-type="fn">1</xref> While one of their key goals is to serve humans by playing different roles, they are likely to have other goals (e.g., profit) that serve the designers of the AI that are not part of the collective. As such, we do not claim AI agents to be humans&#x02019; cultural peers. They may be considered part of the technological context with features that allow humans to interact with them as distinct entities or &#x0201c;anthropomorphized&#x0201d; team members (e.g., Siri or ChatGPT). This assumption about AI agents&#x02019; goal autonomy may or may not hold in the future. Nevertheless, we think this is a reasonable assumption. In most organizational cases, even humans (i.e., employees) do not simply act on their intrinsic motivations. Their goals must be aligned with or subordinated by their organizations. And the extent of this alignment affects their ability to perform. In this way, the core problem of coordinating the members' cognitive states (goals, preferences, and beliefs) still needs to be resolved to achieve CI. Humans and AI agents together form the fabric of the sociotechnical system.</p><p>In practice, the AI agents' goals are likely to become more complex over time. While their development is guided by the goals of their designers, at the same time, if they are intended to learn and adapt to enhance the capability of a human&#x02013;AI system, those goals will also be influenced through interaction with human collaborators. The degree to which an AI agent imposes its goals versus adapting to human collaborators&#x02019; goals will depend on the role they were designed to play. Gupta and Woolley (<xref rid="tops12679-bib-0057" ref-type="bibr">2021</xref>) discuss three types of roles AI agents can play in a collective: (1) assistive AI that scaffolds or augments individual cognition, (2) coach AI that facilitates and nudges collective cognition, and (3) diagnostic AI that monitors emergent collective behavior. Clearly, for each of these roles, an AI agent is initially endowed with a set of desired goal states which guide how they assist, nudge, or manage human users; however, across these roles, AI assistants will likely adapt to the goals and needs of their human user while AI coaches could be more assertive in finding ways to shape human behavior by adjusting how they encourage the human(s) to move toward desired goal states. As the capability of AI agents grows, they will become more skillful in influencing human action in the direction of their own goal states. Unless there are clear mechanisms for humans to influence their goals, we will stand to lose as a society and exhibit lower CI due to the one&#x02010;directional shaping of collective cognition.</p><p>In summary, the development of sociocognitive architectures for COHUMAIN will depend on researchers&#x02019; understanding of how to best design agents to facilitate effective collaboration. We discuss two categories of processes that are necessary for any sociocognitive architecture. Next, we review insights for a few relevant areas of research and then describe our take on a candidate sociocognitive architecture, the TSM&#x02010;CI, and a compatible learning&#x02010;based cognitive architecture.</p></sec><sec id="tops12679-sec-0030"><label>3</label><title>Review of extant research on foundations for COHUMAIN</title><p>A few bodies of research are particularly relevant to COHUMAIN and provide preliminary principles for developing sociocognitive architectures. These works of literature include human&#x02013;machine interaction, human&#x02013;AI trust, and machine ToM.</p><sec id="tops12679-sec-0040"><label>3.1</label><title>Human and machine interaction</title><p>Research on the ways that humans and technology interact has been ongoing for several decades, including work in areas such as human&#x02010;computer interaction (HCI) and human&#x02013;autonomy integration (HAI; O'Neill, McNeese, Barron, &#x00026; Schelble, <xref rid="tops12679-bib-0096" ref-type="bibr">2020</xref>; Schelble, Flathmann, &#x00026; McNeese, <xref rid="tops12679-bib-0113" ref-type="bibr">2020</xref>). HCI has traditionally focused on how humans use and interact with computing devices, with an initial focus on interface design, and has evolved relatively sophisticated models in some areas to deal with multimodal inputs and outputs, and ways for algorithms to read and adapt based on human cues (G. J. Kim, <xref rid="tops12679-bib-0066" ref-type="bibr">2015</xref>). HAI, by contrast, has been less focused on systems or interface design and more on how humans and automated systems interact and collaborate, by some accounts beginning as far back as the 1980s (O'Neill et&#x000a0;al., <xref rid="tops12679-bib-0096" ref-type="bibr">2020</xref>). In much of the HAI work, however, technology has been viewed as an aid that is subservient to humans, with frameworks for considering a technology's level of ability serving as a means for assessing the ways collaboration could evolve as technological capability increases (Endsley, <xref rid="tops12679-bib-0040" ref-type="bibr">2017</xref>).</p><p>Recent research on human&#x02013;autonomy teaming (HAT) focuses on teams in which humans and autonomous AI agents function as coordinated units to achieve a common goal (McNeese, Demir, Cooke, &#x00026; Myers, <xref rid="tops12679-bib-0085" ref-type="bibr">2018</xref>) and more directly addresses the ways that technology can collaborate with humans as a teammate (O'Neill et&#x000a0;al., <xref rid="tops12679-bib-0096" ref-type="bibr">2020</xref>; O'Neill, Flathmann, McNeese, &#x00026; Salas, <xref rid="tops12679-bib-0095" ref-type="bibr">2023</xref>) compared to other extant research on human&#x02013;AI interaction. Across much of HAT research, human&#x02013;AI team goals are associated with a reward that is equally shared among the agents (Matignon, Laurent, &#x00026; Le Fort&#x02010;Piat, <xref rid="tops12679-bib-0080" ref-type="bibr">2012</xref>), but the autonomous agents have been primarily designed to carry out independent performance on a specific task. Thus HATs are often trained to function as the sum of individual parts rather than as highly interdependent collaborators (Burke, Murphy, Coovert, &#x00026; Riddle, <xref rid="tops12679-bib-0020" ref-type="bibr">2004</xref>; Salas, Bowers, &#x00026; Cannon&#x02010;Bowers, <xref rid="tops12679-bib-0108" ref-type="bibr">1995</xref>, <xref rid="tops12679-bib-0109" ref-type="bibr">2008</xref>; Tsifetakis &#x00026; Kontogiannis, <xref rid="tops12679-bib-0122" ref-type="bibr">2019</xref>). That is, computational modeling of autonomous agents has been mostly used to model how teams operate via stable, pre&#x02010;programmed processes instead of as adaptive, complex, and self&#x02010;organizing systems (O'Neill et&#x000a0;al., <xref rid="tops12679-bib-0096" ref-type="bibr">2020</xref>). Recognizing the potential value of greater integration of human and AI teammate inputs, there are increasing calls for the development of models to enable human and autonomous agents to interact in team&#x02010;like structures to achieve common objectives (Cooke, Demir, &#x00026; McNeese, <xref rid="tops12679-bib-0026" ref-type="bibr">2016</xref>; Glikson &#x00026; Woolley, <xref rid="tops12679-bib-0047" ref-type="bibr">2020</xref>; Larson &#x00026; DeChurch, <xref rid="tops12679-bib-0070" ref-type="bibr">2020</xref>; M. D. McNeese &#x00026; McNeese, <xref rid="tops12679-bib-0084" ref-type="bibr">2020</xref>; Myers et&#x000a0;al., <xref rid="tops12679-bib-0088" ref-type="bibr">2019</xref>). Consequently, some argue that to be considered a legitimate team member, the autonomous agents must have both process and outcome interdependence with the human team members (Lyons, Mahoney, Wynne, &#x00026; Roebke, <xref rid="tops12679-bib-0076" ref-type="bibr">2018</xref>; Wynne &#x00026; Lyons, <xref rid="tops12679-bib-0136" ref-type="bibr">2018</xref>).</p><p>In related research, some HAT studies examine the question of the level of autonomy agents should have, and the results are mixed. For instance, some studies report that humans perceive autonomous teammates to be easier to work with and their collaboration to be better when the agents have high levels of autonomy (Azhar &#x00026; Sklar, <xref rid="tops12679-bib-0010" ref-type="bibr">2017</xref>; Johnson et&#x000a0;al., <xref rid="tops12679-bib-0061" ref-type="bibr">2012</xref>; J. L. Wright, Chen, &#x00026; Barnes, <xref rid="tops12679-bib-0133" ref-type="bibr">2018</xref>; J. L. Wright, Chen, Quinn, &#x00026; Barnes, <xref rid="tops12679-bib-0134" ref-type="bibr">2013</xref>). Others report that a moderate level of agent autonomy was perceived as more effective compared to a lower or higher level (M. C. Wright &#x00026; Kaber, <xref rid="tops12679-bib-0135" ref-type="bibr">2005</xref>). Some studies suggest that an important moderator of the effect of the level of agent autonomy is the human participants&#x02019; level of ability. For instance, participants with low spatial ability experienced the greatest performance benefits from increases in agent autonomy (Chen et&#x000a0;al., <xref rid="tops12679-bib-0024" ref-type="bibr">2013</xref>; J. L. Wright et&#x000a0;al., <xref rid="tops12679-bib-0134" ref-type="bibr">2013</xref>, <xref rid="tops12679-bib-0033" ref-type="bibr">2018</xref>). Therefore, a key benefit of HATs is achieved when they can assess human teammates and adjust to variations in their abilities. The ability to assess the human teammate has also been identified as one important aspect of agents&#x02019; situation awareness in the context of HATs (Endsley, <xref rid="tops12679-bib-0040" ref-type="bibr">2017</xref>) and is aligned with research on human teamwork demonstrating the benefits of team members, awareness of members&#x02019; diverse task&#x02010;related capabilities, and functional expertise for team effectiveness (Van Knippenberg &#x00026; Schippers, <xref rid="tops12679-bib-0125" ref-type="bibr">2007</xref>).</p><p>The need for situational awareness extends beyond agents' knowledge of human teammates' abilities, as research also underscores the need for <italic toggle="yes">shared</italic> situational awareness, that is, humans&#x02019; situational awareness of autonomous agents and vice versa, for effective human interaction and collective performance (Cummings &#x00026; Guerlain, <xref rid="tops12679-bib-0029" ref-type="bibr">2007</xref>; Endsley, <xref rid="tops12679-bib-0040" ref-type="bibr">2017</xref>; Grimm, Demir, Gorman, &#x00026; Cooke, <xref rid="tops12679-bib-0053" ref-type="bibr">2018a</xref>, <xref rid="tops12679-bib-0054" ref-type="bibr">2018b</xref>; Salmon et&#x000a0;al., <xref rid="tops12679-bib-0111" ref-type="bibr">2009</xref>). Humans&#x02019; situational awareness strongly influences the degree to which they need to oversee the autonomous agents (Boardman &#x00026; Butcher, <xref rid="tops12679-bib-0017" ref-type="bibr">2019</xref>), and autonomous agents also need to maintain a model of the state of their human teammates to perform their tasks (Barnes &#x00026; Van Dyne, <xref rid="tops12679-bib-0015" ref-type="bibr">2009</xref>; Carroll et&#x000a0;al., <xref rid="tops12679-bib-0021" ref-type="bibr">2019</xref>; Chakraborti, Kambhampati, Scheutz, &#x00026; Zhang, <xref rid="tops12679-bib-0023" ref-type="bibr">2017</xref>). In one study, autonomous monitoring of excessive workload or insufficient training prompted members to shift tasks to optimize team performance (Dierdorff, Fisher, &#x00026; Rubin, <xref rid="tops12679-bib-0035" ref-type="bibr">2019</xref>; Dorneich et&#x000a0;al., <xref rid="tops12679-bib-0036" ref-type="bibr">2017</xref>). In order to exert autonomy in a timely and appropriate manner, the agents need to formulate a mental model that refers to team members&#x02019; mental model and perception of current states, situational dynamics, and contextual cues. That is, agents can have preprogrammed mental models that script heuristic responses to an inventory of human behaviors, or if more advanced they can develop a machine theory of the human mind to adapt to the situation. Extant research on teamwork shows that members can anticipate and predict the needs of others when they have shared mental models, which is important for supporting mutual coordination (Goodwin, Blacksmith, &#x00026; Coats, <xref rid="tops12679-bib-0052" ref-type="bibr">2018</xref>) and underscores the need for this capability development in HATs.</p><p>As in regular human teams, feedback mechanisms play a significant role in HATs in enabling team members to monitor, evaluate their task performance, and provide opportunities to improve it (Salas, Dickinson, Converse, &#x00026; Tannenbaum, <xref rid="tops12679-bib-0110" ref-type="bibr">1992</xref>; Sottilare et&#x000a0;al., <xref rid="tops12679-bib-0118" ref-type="bibr">2018</xref>). Additionally, feedback processes help team members share experiences and develop mutual trust (Cuevas, Fiore, Caldwell, &#x00026; Strater, <xref rid="tops12679-bib-0028" ref-type="bibr">2007</xref>; Fan &#x00026; Yen, <xref rid="tops12679-bib-0043" ref-type="bibr">2011</xref>; Fan et&#x000a0;al., <xref rid="tops12679-bib-0042" ref-type="bibr">2008</xref>). Large bodies of research on HATs found that human&#x02013;human teams outperform HATs due to more efficient information sharing among human teammates compared to HATs (Cooke et&#x000a0;al., <xref rid="tops12679-bib-0026" ref-type="bibr">2016</xref>; Demir, Cooke, &#x00026; Amazeen, <xref rid="tops12679-bib-0030" ref-type="bibr">2018</xref>; Demir, McNeese, &#x00026; Cooke, <xref rid="tops12679-bib-0030" ref-type="bibr">2018</xref>; Demir, Likens, Cooke, Amazeen, &#x00026; McNeese, <xref rid="tops12679-bib-0031" ref-type="bibr">2019</xref>; Demir, McNeese, &#x00026; Cooke, <xref rid="tops12679-bib-0032" ref-type="bibr">2016</xref>; N. J. McNeese et&#x000a0;al., <xref rid="tops12679-bib-0085" ref-type="bibr">2018</xref>; Myers et&#x000a0;al., <xref rid="tops12679-bib-0088" ref-type="bibr">2019</xref>) as well as better organization and adaptation (Grimm et&#x000a0;al., <xref rid="tops12679-bib-0054" ref-type="bibr">2018b</xref>). Efficient information sharing does not always mean high communication frequency, as the latter can result in higher cognitive load, misunderstandings, and inefficiency and thus undermine performance (MacMillan, Entin, &#x00026; Serfaty, <xref rid="tops12679-bib-0078" ref-type="bibr">2004</xref>). Hence, the investigation of communication frequency and quality related to team outcomes has become an essential branch of HAT research (Cooke et&#x000a0;al., <xref rid="tops12679-bib-0026" ref-type="bibr">2016</xref>; Demir, Cooke, &#x00026; Amazeen, <xref rid="tops12679-bib-0030" ref-type="bibr">2018</xref>; Demir, McNeese, &#x00026; Cooke, <xref rid="tops12679-bib-0032" ref-type="bibr">2016</xref>, Demir, Likens, Cooke, Amazeen, &#x00026; McNeese, <xref rid="tops12679-bib-0031" ref-type="bibr">2019</xref>; Demir, McNeese, &#x00026; Cooke, <xref rid="tops12679-bib-0033" ref-type="bibr">2018</xref>; N. J. McNeese et&#x000a0;al., <xref rid="tops12679-bib-0085" ref-type="bibr">2018</xref>).</p><p>Extant work on cognitive modeling has focused primarily on individual cognition and cognitive models of situation awareness to understand and emulate human behavior by representing the cognitive steps by which a task is performed (Adams, Tenney, &#x00026; Pew, <xref rid="tops12679-bib-0003" ref-type="bibr">1995</xref>; Bolstad et&#x000a0;al., <xref rid="tops12679-bib-0018" ref-type="bibr">2010</xref>; Endsley, <xref rid="tops12679-bib-0037" ref-type="bibr">1995a</xref>, <xref rid="tops12679-bib-0038" ref-type="bibr">1995b</xref>, <xref rid="tops12679-bib-0039" ref-type="bibr">2015</xref>; Wickens, <xref rid="tops12679-bib-0128" ref-type="bibr">2008</xref>, <xref rid="tops12679-bib-0129" ref-type="bibr">2015</xref>). Very little work in this literature addresses team cognition, with only a handful of studies considering collective cognition in HATs (Cuevas et&#x000a0;al., <xref rid="tops12679-bib-0028" ref-type="bibr">2007</xref>; Saner, Bolstad, Gonzalez, &#x00026; Cuevas, <xref rid="tops12679-bib-0112" ref-type="bibr">2009</xref>; Wiltshire, Warta, Barber, &#x00026; Fiore, <xref rid="tops12679-bib-0130" ref-type="bibr">2017</xref>). Consequently, there are few models in this area for researchers to build on to model the cognition that AI teammates need to collaborate as part of a human team and make the kinds of contributions humans expect from a genuine team member.</p><p>Therefore, a critical need for supporting COHUMAIN research is work that can bridge between individual and collective&#x02010;level models of cognition and interaction. Such work is essential for enabling progress on developing sociocognitive architectures and guiding the design of AI agents.</p></sec><sec id="tops12679-sec-0050"><label>3.2</label><title>Trust in human&#x02013;AI collaboration</title><p>The interaction and communication that serves as the engine for developing collective cognition is also a basis for the formation and maintenance of human&#x02013;AI trust, an essential quality which influences the ability of a sociotechnical system to achieve CI. Hence, advancing COHUMAIN research requires continuing to develop a deeper understanding of issues that facilitate or inhibit the formation, maintenance, and repair of trust between humans and AI collaborators. While human&#x02013;AI trust is a new area of investigation, a long line of research on trust and trustworthiness in humans demonstrates the importance of demonstrating competence, benevolence, and integrity (McAllister, <xref rid="tops12679-bib-0083" ref-type="bibr">1995</xref>).</p><p>In considering human&#x02013;AI collaboration, an important question is examining the degree to which trust development is dependent on these same factors. If so, how are they demonstrated and established by the AI agent and by the human (Stanton &#x00026; Jensen, <xref rid="tops12679-bib-0120" ref-type="bibr">2021</xref>). In their review of the extant literature on human trust in AI, Glikson and Woolley (<xref rid="tops12679-bib-0047" ref-type="bibr">2020</xref>) concluded that the focus to date has been almost exclusively on dimensions related to competence, particularly reliability. Even the more recent work on explainable AI (T, Miller, <xref rid="tops12679-bib-0087" ref-type="bibr">2019</xref>; Phillips, Hahn, Fontana, Broniatowski, &#x00026; Przybocki, <xref rid="tops12679-bib-0099" ref-type="bibr">2020</xref>) is largely focused on promoting human&#x02013;AI trust by providing more comprehensive information on the reasons for various actions which will reinforce perceptions of its competence. Related work on AI and transparency (T. Miller, <xref rid="tops12679-bib-0087" ref-type="bibr">2019</xref>) contributes to competence perceptions in a similar manner but also begins to connect to perceptions of integrity as well, where an agent is providing more demonstrable evidence of its reasoning and thereby allowing human users to observe that it is pursuing the goals that are intended, and nothing else. Issues of data privacy and disclosure continue to put pressure on perceptions of AI integrity as different groups of AI developers, users, and increasingly government and nonprofit agencies, and institutions get involved in establishing guidelines for disclosure and user control over private information.</p><p>One area of human&#x02013;AI trust which has received considerably less attention relates to humans&#x02019; perceptions of agent benevolence and related affective bases of trust (Glikson &#x00026; Woolley, <xref rid="tops12679-bib-0047" ref-type="bibr">2020</xref>; McAllister, <xref rid="tops12679-bib-0083" ref-type="bibr">1995</xref>). Much of the work to date in this area has focused on AI agent characteristics and user&#x02010;interface design, such as the level of embodiment of the agent and other attributes related to its identity, or how the agent looks and sounds, and the resulting impressions of users. However, the general patterns across existing studies demonstrate that these elements only influence initial impressions; even users who begin with a strong positive impression of agents typically exhibit a loss of trust, particularly when an agent's capabilities were not clearly presented, and the subsequent performance falls below users&#x02019; expectations (Glikson &#x00026; Woolley, <xref rid="tops12679-bib-0047" ref-type="bibr">2020</xref>). Beyond the issues of how AI agent features affect users' reactions, at least initially, very little is known about how human perceptions of AI benevolence develop or the degree to which human users perceive that their motives are aligned, and the agent is acting in their best interests and, possibly, even cares about them (Hancock et&#x000a0;al., <xref rid="tops12679-bib-0058" ref-type="bibr">2011</xref>). This is an important area for further development, as research on trust between humans, or even between humans and institutions, demonstrates that it is strongly influenced by perceivers&#x02019; assessment that their goals and motivations are aligned with those of the other party (be it a human, organization, or a non&#x02010;human actor) and the other party cares about them and is working toward the same outcomes.</p><p>Issues of trust repair in human&#x02013;AI interaction are not yet well understood, but as AI agents become more involved in human collaboration, it will be important to understand how AI agents not only convey trustworthiness but also establish trust and detect whether trust has been broken. The value of adaptively calibrating and managing human&#x02013;AI's dyadic trust dynamics has been explored to some degree in autonomous car driving and drone flying (Akash et&#x000a0;al., <xref rid="tops12679-bib-0002" ref-type="bibr">2020</xref>; Okamura &#x00026; Yamada, <xref rid="tops12679-bib-0098" ref-type="bibr">2020</xref>). This will be essential to developing a nuanced understanding of human&#x02013;AI interaction as an ongoing relationship, one that develops and changes over time as the needs and capabilities of both parties change, and to identify ways of communicating and resolving conflict that enable the relationship to evolve as well. For example, an AI agent can establish trustworthiness by being transparent about whether the capabilities needed to help pursue specific goals are or are not within their established repertoire. Such a level of proactive communication in any relationship reduces fears of deception and consistently serves to prevent conflict and promote trust. The process of developing detailed models of how AI agents establish and maintain trust may actually change our basic understanding of trust development and repair in all relationships. This capability will also draw extensively on &#x0201c;machine theory of human mind&#x0201d; (MToHM) as an extension of the human ToM and thus move related research forward as well.</p></sec><sec id="tops12679-sec-0060"><label>3.3</label><title>Machine theory of mind</title><p>Recent advances in AI and computation have led to increased development of learning ToM agents, which are AI agents that can predict cognitive states (e.g., desires, intentions, beliefs) of other agents. This work follows existing research that has been focusing almost exclusively on investigating how a machine can predict another machine's cognition (MToMM&#x02014;machine theory of machine mind) and how a human is able to understand a machine's cognition (HToMM&#x02014;human theory of machine mind). Much of this work resides in the cognitive science literature. Here, humans or ToM&#x02010;enabled AI agents serve in the role of an &#x0201c;observer&#x0201d; who observes the actions of an AI &#x0201c;actor&#x0201d; and make predictions about the actor's mental state.</p><p>Traditionally, ToM agents have been developed using the plan and goal recognition algorithms (Geib &#x00026; Goldman, <xref rid="tops12679-bib-0046" ref-type="bibr">2009</xref>; Kautz &#x00026; Allen, <xref rid="tops12679-bib-0065" ref-type="bibr">1986</xref>); however, such an approach requires a detailed description of the domain to use as a basis for modeling the full range of goals and plans. The Bayesian ToM observer (Baker, Jara&#x02010;Ettinger, Saxe, &#x00026; Tenenbaum, <xref rid="tops12679-bib-0012" ref-type="bibr">2017</xref>; Baker, Saxe, &#x00026; Tenenbaum, <xref rid="tops12679-bib-0013" ref-type="bibr">2011</xref>), one of the prominent computational ToM frameworks, is developed by constructing a model of the actor's cognition by relying on the assumption that the actor will take actions that maximize its utility based on partial observations. This assumption, however, tends to deviate from actual human behavior in many decision&#x02010;making tasks showing that humans are often boundedly rational (Kahneman, Slovic, &#x00026; Tversky, <xref rid="tops12679-bib-0062" ref-type="bibr">1982</xref>; Simon, <xref rid="tops12679-bib-0117" ref-type="bibr">1997</xref>) and that their decisions are constrained by human cognitive capabilities for storing and retrieving information from memory (Gonzalez et&#x000a0;al., <xref rid="tops12679-bib-0051" ref-type="bibr">2003</xref>). Recently, the deep learning approach to ToM has received extensive attention since it leverages the computational efficiency and the architecture of neural networks (Oguntola, Hughes, &#x00026; Sycara, <xref rid="tops12679-bib-0094" ref-type="bibr">2021</xref>; Rabinowitz et&#x000a0;al., <xref rid="tops12679-bib-0101" ref-type="bibr">2018</xref>). Despite the robustness of the neural network ToM models, their agreement with human observers&#x02019; judgments remains unclear.</p><p>Despite many promising developments, these aforementioned ToM models do not capture human biases such as bounded rationality and fall short of the same significant attention or limited processing capacity of humans. This suggests the need for a cognitive approach to ToM. For instance, in an attempt to simulate human ToM representation, Nguyen and Gonzalez (<xref rid="tops12679-bib-0092" ref-type="bibr">2022</xref>) developed a cognitive model of the observer (CogToM), which relies on the cognitive theory of decisions from experience, IBLT. As such, the CogToM observer model is boundedly rational by considering decisions constrained within the limitations of human memory (e.g., recency and frequency biases of information and errors in the retrieval of information). Experimental results demonstrate that the CogToM observer can make inferences that are in agreement with human observers&#x02019; judgments on the same task. At this stage, CogToM has not yet been applied to predict humans&#x02019; behavior as a player in the observed environment.</p><p>Given the above, research on extending the understanding from MToM to developing a deeper knowledge of how a machine can model and predict the cognitive states of genuine humans (MToHM) is an important and relatively underexplored area. Furthermore, there is a lack of computational ToM methods that have direct applicability to COHUMAIN research, wherein the learning AI agents must not only learn to form mental states such as beliefs about the knowledge possessed by their collaborators (i.e., humans or autonomous AI agents) but also leverage such beliefs to make appropriate decisions on which actions to take.</p><p>Hence, MToHM and HToMM are foundational to the development of well&#x02010;functioning sociocognitive architecture. Importantly, AI agents with cognitive architectures that support the development of both MToHM and HToMM will be especially important for supporting the emergence of CI and thus central to COHUMAIN research.</p></sec></sec><sec id="tops12679-sec-0070"><label>4</label><title>A sociocognitive architecture for COHUMAIN: TSM&#x02010;CI</title><p>In the previous sections, we outlined four core problems for COHUMAIN research and advocated for the use of sociocognitive architectures as a vehicle for a holistic approach to its design and development. We then reviewed the relevant literature on human&#x02013;machine interaction, human&#x02013;AI trust, and machine ToM which supply key inputs to solving the core problems of this nascent domain. In this section, we describe a possible sociocognitive architecture, the TSM&#x02010;CI (Gupta &#x00026; Woolley, <xref rid="tops12679-bib-0057" ref-type="bibr">2021</xref>), and extend it to the COHUMAIN domain by discussing how AI agents can augment its core processes. Following this, in the final section, we discuss the value of choosing a compatible cognitive architecture and illustrate it in this context by describing work on instance&#x02010;based learning theory.</p><p>For decades, research on intelligence has studied the functions that enable systems to adapt and accomplish goals in a wide range of environments that vary in complexity (Legg &#x00026; Hutter, <xref rid="tops12679-bib-0072" ref-type="bibr">2007</xref>). Some parallels across studies of intelligence in different domains suggest that intelligence in any system&#x02014; biological, technological, or hybrid&#x02014;requires the fulfillment of certain memory, attention, and reasoning functions. In parallel, over the last few decades, there is increasing recognition in the management literature that human organizations operate less as static structures, as traditionally portrayed, and more as complex adaptive systems, requiring a deeper understanding of the process dynamics that underlie different modes of organizing (Arrow, McGrath, &#x00026; Berdahl, <xref rid="tops12679-bib-0009" ref-type="bibr">2000</xref>). These parallel developments in the intelligence and management literature have been reflected in the increasingly common inclusion of concepts originating in intelligence in organizational theory (Csaszar &#x00026; Steinberger, <xref rid="tops12679-bib-0027" ref-type="bibr">2021</xref>).</p><p>TSM&#x02010;CI explicitly integrates research on intelligence across fields with extant work on teamwork and collaboration to support the premise that CI is fostered by the emergence and ongoing adaptation of three interlocking sociocognitive systems centered around collective memory, attention, and reasoning (Gupta &#x00026; Woolley, <xref rid="tops12679-bib-0057" ref-type="bibr">2021</xref>). TSM&#x02010;CI is a process model describing how individual agent&#x02010;level cognitive functions, between&#x02010;member metacognitive processes, and between&#x02010;member transactive processes interact and lead to the formation of three dynamically stable sociocognitive systems. When strong transactive memory, attention, and reasoning systems develop, they enable collaborators to overcome the limits of individual cognitive capacity and expand the collective's total memory, attention, and reasoning capacity. The concomitant alignment of goals and mental states creates a readiness for coordinated action as an adaptive response to environmental changes.</p><p>Here, we provide a brief overview of the transactive memory, attention, and reasoning systems that form the foundation of the TSM&#x02010;CI. As we describe each component, we also discuss opportunities for AI&#x02010;based agents to facilitate the development and maintenance of associated functions and enhance CI (see Fig.&#x000a0;<xref rid="tops12679-fig-0002" ref-type="fig">2</xref>).</p><fig position="float" fig-type="Fig." id="tops12679-fig-0002"><label>Fig. 2</label><caption><p>Overview of the extended transactive systems model. The collective memory, attention, and reasoning systems emerge due to between&#x02010;member processes, and together, they adaptively respond to a changing environment.</p></caption><graphic xlink:href="TOPS-17-189-g001" position="anchor" id="jats-graphic-3"/></fig><sec id="tops12679-sec-0080"><label>4.1</label><title>Transactive memory system</title><p>A transactive memory system (TMS) is one of the three sociocognitive functions in the TSM&#x02010;CI that addresses two of the core problems of COHUMAIN. Specifically, TMS is a dynamic system of processes through which collaborator's knowledge and skills (i.e., cognitive resources) and their beliefs about who knows what (i.e., metamemory) are dynamically updated to facilitate the allocation and retrieval of knowledge to and from the most appropriate collaborator (Wegner, <xref rid="tops12679-bib-0126" ref-type="bibr">1987</xref>, <xref rid="tops12679-bib-0127" ref-type="bibr">1995</xref>). This enables an effective response in the face of changing knowledge interdependencies in the environment. The concept of TMS was initially developed in the context of couples in close relationships by Wegner (<xref rid="tops12679-bib-0126" ref-type="bibr">1987</xref>), but then extended to the group level and associated with team performance (Ren &#x00026; Argote, <xref rid="tops12679-bib-0102" ref-type="bibr">2011</xref>) as well as CI (Y. J. Kim, Aggarwal, &#x00026; Woolley, <xref rid="tops12679-bib-0067" ref-type="bibr">2016</xref>).</p><p>The foundational component of TMS is the collaborators&#x02019; individual memory systems. Its function is to (1) reliably store knowledge, thereby building member skills and (2) accurately retrieve and apply this stored knowledge to complete tasks successfully. Technology plays a significant role in augmenting individual human memory. Search engines and online knowledge repositories are resources that individuals regularly use as external memory aids&#x02014;both for their information searches, as well as the proactive alerts that make them aware of new knowledge. This access has already changed individual human behavior.</p><p>Research demonstrates that when individuals expect to have future access to information they found online, they have lower recall rates for the information itself and enhanced recall instead of where on the internet to access it (Sparrow, Liu, &#x00026; Wegner, <xref rid="tops12679-bib-0119" ref-type="bibr">2011</xref>). The encoding of the location of the information, also referred to as metaknowledge, instead of the contents of the information itself, is formed in metamemory. Metaknowledge encoding also occurs with respect to the knowledge and skills of other collaborators. As TMS develops, with multiple experiences successfully updating, allocating, and retrieving information from one another, collaborators&#x02019; knowledge becomes more differentiated and specializations emerge. Moreover, repeated interactions also establish trust and credibility with others. Both of these patterns are validated markers of a well&#x02010;developed TMS (Ren &#x00026; Argote, <xref rid="tops12679-bib-0102" ref-type="bibr">2011</xref>).</p></sec><sec id="tops12679-sec-0090"><label>4.2</label><title>The role of AI collaborators in TMS</title><p>The processes described for developing a strong collective memory via TMS is one that has been studied mostly in all&#x02010;human groups but could involve a mix of human and AI collaborators, In addition to the role of AI in augmenting individual memory mentioned above, AI&#x02010;based teammates could also enhance collective memory by speeding up the process of learning who knows what and facilitating the allocation of tasks and information. AI could also connect individuals needing to learn a skill to someone who can teach them or facilitate adaptation in response to membership changes by helping realign specializations with a new configuration of skillsets.</p><p>While the possibilities resulting from a deeper integration of AI into human teams are exciting, a small cautionary note is also important to consider, related back to the earlier discussion of human&#x02013;AI trust. On the one hand, a certain level of trust will be required in order for humans to allow AI to have access to the level of knowledge necessary to facilitate collective memory in some of the ways described. On the other hand, it is possible that humans might come to trust such AI teammates too much and become too reliant on their facilitation in ways that undercut individual memory formation as well as the formation of collective memory. For example, Gupta and Woolley (<xref rid="tops12679-bib-0056" ref-type="bibr">2018</xref>) found that a digital dashboard that tracked information about team members&#x02019; knowledge and specialization actually undermined collective cognition and performance when the number of team members was small enough that collaborators could have kept track without such a tool. This underscores the importance of a holistic sociocognitive architecture that integrates AI&#x02010;based tools into teams in a manner that enhances individual and collective cognition rather than detracting from it.</p></sec><sec id="tops12679-sec-0100"><label>4.3</label><title>Transactive attention system</title><p>In any collective, the total attention of collaborators creates the upper bound of the system's capacity to handle information (Simon, <xref rid="tops12679-bib-0114" ref-type="bibr">1973</xref>). In addition to coordinating collective memory consisting of distributed knowledge and skills, collectives must also distribute their members&#x02019; limited and often fragmented attention to accomplish interdependent work per its importance to the group. Just as was described in the case of a TMS, a transactive attention system (TAS) is a process for coordinating collaborators&#x02019; attentional resources and aligning their shared beliefs about each other (meta&#x02010;attention) to produce collective cognition&#x02014;in this case, jointly allocating and retrieving their collective attention. In the TSM&#x02010;CI sociocognitive architecture, TAS is intended to complement TMS, in that the two mutually regulate and efficiently balance the use of both members&#x02019; knowledge and attention.</p><p>The foundational component of TAS is the individual attention system, whose job it is to reliably filter, chunk, and process information to complete tasks successfully (Knudsen, <xref rid="tops12679-bib-0068" ref-type="bibr">2007</xref>). It is often the case that individuals have different tasks competing for attention, requiring them to switch among them frequently. A person's meta&#x02010;attention provides globalized cognitive control to help them expertly navigate situations involving choice among multiple tasks (Lavie, Hirst, de Fockert, &#x00026; Viding, <xref rid="tops12679-bib-0071" ref-type="bibr">2004</xref>; P. H. Miller &#x00026; Bigi, <xref rid="tops12679-bib-0086" ref-type="bibr">1979</xref>) for minimizing switching costs. A well&#x02010;developed meta&#x02010;attention also allows collaborators to develop a joint awareness of each other's workload and availabilities to help reduce the coordination costs associated with interdependent tasks. For instance, groups with a strong TAS will exhibit organized patterns of synchronous attention, sometimes manifesting as &#x0201c;burstiness,&#x0201d; where periods of independent work are punctuated by periods where members are highly responsive to each others&#x02019; requests (Mayo &#x00026; Woolley, <xref rid="tops12679-bib-0082" ref-type="bibr">2021</xref>; Riedl &#x00026; Woolley, <xref rid="tops12679-bib-0105" ref-type="bibr">2017</xref>). These bursty patterns are interpreted as evidence that collaborators have developed routines that support the need for synchronous coordination while also enabling collaborators to flexibly juggle other responsibilities without the expectation of constant availability.</p><sec id="tops12679-sec-0110"><label>4.3.1</label><title>The role of AI collaborators in TAS</title><p>Just as there are AI&#x02010;based tools that enhance individual memory, many tools are commonly used to augment individual attention. Calendar&#x02010;based algorithms and personal digital assistants prompt individuals with reminders depending on time or location based on the triangulation of information or instructions. Tools that filter incoming communications based on past behavior to limit interruptions or distractions are also becoming more widely used. However, very few tools exist to help develop and maintain meta&#x02010;attention or foster collective attention by facilitating TAS. Building tools to do so would be a great way to further develop COHUMAIN research. A key hurdle for developing TAS among human collaborators is a broad understanding of collaborators&#x02019; workloads, plans, and progress vis&#x02010;a&#x02010;vis individual and collective priorities. Tracking all of those details would result in information overload, but without a way to do so it is difficult for collaborators to know enough to manage collective attention. An AI&#x02010;based teammate could help make information available and processes more visible at the level of detail necessary to enable ongoing coordination. Certainly, AI tools could take over and &#x0201c;manage&#x0201d; the entire task flow of all collaborators; however, tools that deprive humans of autonomy and remove the need for mutual attention by handling work assignments can undermine motivation and integration of teamwork products, ultimately impeding performance (Woolley, Gerbasi, Chabris, Kosslyn, &#x00026; Hackman, <xref rid="tops12679-bib-0132" ref-type="bibr">2008</xref>). Therefore, just as highly sophisticated AI tools can inadvertently undermine collective memory, micromanaging the coordination of work can similarly undermine collective attention.</p><p>Some sophisticated approaches to managing collective attention are being developed in the context of crowd&#x02010;based work. For example, studies using the experimental platform &#x0201c;Foundry&#x0201d; examine ways to automate the structure of temporary online (or &#x0201c;flash&#x0201d;) teams to collaborate on more creative, open&#x02010;ended projects than are generally conducted using crowd workers online (Retelny et&#x000a0;al., <xref rid="tops12679-bib-0103" ref-type="bibr">2014</xref>; Valentine et&#x000a0;al., <xref rid="tops12679-bib-0123" ref-type="bibr">2017</xref>). This temporary teaming model facilitates the workflow of short&#x02010;term decomposable projects in relatively small groups of collaborators. Solving a poorly specified problem over longer time horizons will likely need different strategies. Thus it is essential in developing sociocognitive architectures for COHUMAIN that researchers remain cognizant of supporting the development of human collective cognition and avoids introducing AI tools that displace it.</p></sec></sec><sec id="tops12679-sec-0120"><label>4.4</label><title>Transactive reasoning system</title><p>Thus far, we have described two of the systems forming TSM&#x02010;CI sociocognitive architecture, TMS and TAS, which both function to enable the efficient use of collaborators&#x02019; distributed memory and attentional resources to achieve coordinated action. However, while TMS and TAS serve to enhance the efficient use of cognitive resources, they do not address another essential element which is the alignment of cognitive states (goals, preferences, and beliefs) with outcomes valued by collaborators and/or the environment. Tracking changes in the environment with implications for the relative value of different goals is critical to a system's ability to maintain itself in addition to being productive. Collective reasoning serves these functions: it evaluates collective goals in the context of a constantly changing environment to ensure the pursuit of those with the greatest value with respect to related resource uncertainties and the alignment between individual and collective goals (Bacharach, <xref rid="tops12679-bib-0011" ref-type="bibr">1999</xref>; Locke &#x00026; Latham, <xref rid="tops12679-bib-0074" ref-type="bibr">1990</xref>).</p><p>An individual's reasoning system maintains a hierarchy of cognitive structures that represent a set of goals along with a set of tasks that are their means of attainment. Goals are typically associated with motivational needs, and continuously fulfilling them sustains progress toward valued distal goals (Bandura, <xref rid="tops12679-bib-0014" ref-type="bibr">1991</xref>). While goal hierarchies maximize short&#x02010;term rewards and generate goal commitment, individual metareasoning is needed to achieve metacognitive control that maximizes longer&#x02010;term rewards. Metareasoning involves monitoring and determining whether to continue, switch strategies, or terminate pursuing the current set of proximal goals to avoid local reward maximas (Ackerman &#x00026; Thompson, <xref rid="tops12679-bib-0001" ref-type="bibr">2017</xref>). Individuals with well&#x02010;developed metareasoning are able to effectively adapt to the changing situation by reconfiguring their goal hierarchies and ensuring reward maximization. Research on COHUMAIN can build models that represent how individuals break down tasks and build goal hierarchies which facilitate metareasoning by enabling the comparison across goals.</p><p>In human groups, the transactive reasoning system (TRS) emerges as a consequence of humans&#x02019; ability to infer, understand, and reason about others&#x02019; goals and motivations. This metareasoning ability is necessary for the collective exploration of diverse goals and the selection of joint priorities via a process of negotiation among collaborators. When done well, the resulting alignment of collective actions with individual goals as well as the adoption of transactive, that is, other&#x02010; and system&#x02010;oriented goals, elicits commitment toward the collective as a whole (Fitzsimons &#x00026; Finkel, <xref rid="tops12679-bib-0044" ref-type="bibr">2018</xref>). Consequently, two markers of a highly effective TRS are a high level of collective effort and strong individual commitment. These, in turn, facilitate the ongoing updating of goals, as highly motivated individuals are better at recognizing and creating opportunities from their environment (Carsrud, Br&#x000e4;nnback, Elfving, &#x00026; Brandt, <xref rid="tops12679-bib-0022" ref-type="bibr">2009</xref>). The guidance on goals and priorities from the TRS, in turn, shapes decisions about resources enabling the TAS and TMS processes to execute collective actions effectively.</p><sec id="tops12679-sec-0130"><label>4.4.1</label><title>The role of AI collaborators in TRS</title><p>Unlike the current context for TMS and TAS, there are very few tools at the individual or collective level to facilitate collective reasoning. There are a handful of technologies, including AI&#x02010;enabled tools, which nudge the information in the collective choice environments to facilitate the human members' joint decision&#x02010;making. Decision support systems can help to structure and facilitate the surfacing and exchange of different points of view and identification of member preferences to guide decision&#x02010;making (Chidambaram, Summers, Miranda, Young, &#x00026; Bostrom, <xref rid="tops12679-bib-0025" ref-type="bibr">2020</xref>). Algorithm&#x02010;assisted prediction and auction markets can facilitate negotiation around limited resources and maximization of joint outcomes via market&#x02010;like bidding systems (Malone et&#x000a0;al., <xref rid="tops12679-bib-0079" ref-type="bibr">2017</xref>). Recent developments incorporate models of &#x0201c;swarm intelligence&#x0201d; to gauge collective sentiment and provide a high&#x02010;level view to all members to help facilitate consensus (Rosenberg, Willcox, Palosuo, &#x00026; Mani, <xref rid="tops12679-bib-0106" ref-type="bibr">2021</xref>). However, there are additional opportunities for AI to initiate such exchanges and prompt collective reasoning based on indicators that members may have misaligned goals, such as when the level of member engagement declines based on the pace of activity and emotional states (Van Kleef, Homan, &#x00026; Cheshin, <xref rid="tops12679-bib-0124" ref-type="bibr">2012</xref>).</p><p>In this section, we described the three sociocognitive systems that together form the sociocognitive architecture guided by the TSM&#x02010;CI. In extending its possibilities for shaping COHUMAIN, we discussed some examples of ways AI&#x02010;based teammates could enhance the three essential functions. In the next and final section, we make a case for designing AI agents with cognitive architectures that are compatible with the sociocognitive architecture of the collective. In doing so, we discuss a learning&#x02010;based cognitive architecture, specifically IBLT, which we identified to be most compatible with extended TSM&#x02010;CI.</p></sec></sec></sec><sec id="tops12679-sec-0140"><label>5</label><title>Illustrating a compatible learning&#x02010;based cognitive architecture for agent cognition</title><p>A core premise of COHUMAIN is that CI is manifest when environmental changes trigger a coordinated response, where the response is a collection of member interactions (human&#x02013;human, human&#x02013;AI, and AI&#x02013;AI) working in tandem. Achieving this requires the coordination of distributed cognitive resources and the alignment of diverse mental states to develop collective cognition that results in intelligent behavior. In the TSM&#x02010;CI sociocognitive architecture, this coordinated response results from the dynamic regulation of collective memory, attention, and reasoning systems.</p><p>Ideally, one would want all the independent AI agents facilitating and improving various aspects of the collective's TMS, TAS, and TRS to operate as one holistic system. In an integrated AI system, all the AI agents could seamlessly feed into each other to ensure the maintenance of CI. Yet, as technology develops and AI agents get good at solving specific coordination problems, one should reasonably expect collectives to comprise multiple AI agents that do not necessarily play well with each other. Hence, it matters the kind of design choices companies and developers make when building the cognitive architecture of their AI agents.</p><p>Some cognitive architectures are better suited for interfacing with a given sociocognitive architecture in that the paradigm guiding an AI agent's internal representations aligns with the intermember processes driving the larger sociocognitive architecture of the collective they are participating in. Furthermore, the AI agent needs to be capable of generating human&#x02010;understandable explanations of their ongoing actions and underlying internal cognitive states as well as infer the humans&#x02019; cognitive states from their communication to enable human&#x02013;AI collaboration. Thus, a cognitive architecture that has the most congruent mechanisms for representing ToM is likely to be more successful.</p><p>
<italic toggle="yes">We claim that investigating the features across various cognitive architectures used to develop AI agents and what makes them most compatible with a given sociocognitive architecture is an important agenda item for realizing the integration envisioned for COHUMAIN research</italic>. Here, we illustrate this by discussing work on a learning&#x02010;based cognitive architecture, specifically IBLT, which results in models that are highly compatible with the extended TSM&#x02010;CI sociocognitive architecture.</p><sec id="tops12679-sec-0150"><label>5.1</label><title>Learning&#x02010;based models of individual cognition</title><p>Information&#x02010;processing theories are perhaps best suited to describe individual cognition as an interaction between an information&#x02010;processing system (e.g., the human) and a task environment (Simon, <xref rid="tops12679-bib-0116" ref-type="bibr">1978</xref>). The information&#x02010;processing system involves a set of complex processes, including perception and sensorial information, attention, a memory system (e.g., working memory and long&#x02010;term memory), decision&#x02010;making and problem&#x02010;solving, motor action components, and feedback or learning processes. Each of these elements is a complex system in itself. Furthermore, the information&#x02010;processing system is adaptive and capable of adjusting to dynamic changes in the environment and improving behavior through learning (Gonzalez, <xref rid="tops12679-bib-0048" ref-type="bibr">2013</xref>).</p><p>One aspect of individual cognition that is essential for developing a sociocognitive architecture of COHUMAIN is the individual learning system, which converts experience in the environment into the individual's current level of understanding of the task and the consequences of their actions. Learning is an essential process in the context of collaboration, as the knowledge individuals gain from experience with others in the environment influences how the individual formulates their goal and where they direct their attention in the task environment. Learning is achieved by processing experiences stored in the individual's memory system, which is commonly defined by its capacity, duration, and speed (e.g., short&#x02010;term and long&#x02010;term memory), and other factors. However, beyond these factors, memory is a complex dynamic system that functions largely based on a number of intricate processes of storage, retrieval, organization, recognition, and updates (Simon, <xref rid="tops12679-bib-0115" ref-type="bibr">1976</xref>). Decades of work by psychologists have resulted in an enormous amount of research on learning and human memory as an information&#x02010;processing system (e.g., Anderson &#x00026; Milson, <xref rid="tops12679-bib-0006" ref-type="bibr">1989</xref>; Anderson &#x00026; Schooler, <xref rid="tops12679-bib-0008" ref-type="bibr">1991</xref>; Anderson, Reder, &#x00026; Lebiere, <xref rid="tops12679-bib-0007" ref-type="bibr">1996</xref>). There is also a large and growing body of work on the computational representation of such memory processes (e.g., Borst &#x00026; Anderson, <xref rid="tops12679-bib-0019" ref-type="bibr">2013</xref>; Hintzman, <xref rid="tops12679-bib-0060" ref-type="bibr">1984</xref>; Lovett, Reder &#x00026; Lebiere, <xref rid="tops12679-bib-0075" ref-type="bibr">1999</xref>; O'Reilly, Braver, &#x00026; Cohen, <xref rid="tops12679-bib-0097" ref-type="bibr">1999</xref>). Given the infeasibility of a comprehensive review of this large literature, here we will focus on the most relevant elements of individual cognitive models that use learning as the basis for taking action and making decisions. These are also chosen for their congruence with the larger transactive systems model, which relies on memory and attention processes at the collective level.</p><p>Memory&#x02010;based models that represent and explain the dynamics of human decisions and learning from experience are highly specialized types of models that rely on theories of choice and cognitive theories of memory processes (see Hertwig, <xref rid="tops12679-bib-0059" ref-type="bibr">2015</xref> for a discussion of models of decisions from experience). The general idea from theories of choice is that decisions are made according to some form of the expected value of the alternatives considered based on a combination of the value of each option and its probability of occurring. This is an idea that dates back to Bernoulli (1700&#x02013;1782), and that was formalized in theories of expected utility and psychological theories such as prospect theory (Kahneman &#x00026; Tversky, <xref rid="tops12679-bib-0063" ref-type="bibr">1979</xref>). These ideas have also informed models of experience&#x02010;based choice, for which the values of the alternatives are formed from the decision makers&#x02019; experience (Gonzalez &#x00026; Dutt, <xref rid="tops12679-bib-0050" ref-type="bibr">2011</xref>; Gonzalez et&#x000a0;al., <xref rid="tops12679-bib-0051" ref-type="bibr">2003</xref>; Nguyen et&#x000a0;al., <xref rid="tops12679-bib-0093" ref-type="bibr">2023</xref>).</p><p>The process models of decisions from experience are associative learning models that conceptualize choice as a dynamic learning process that relies on the associations of behavior and outcome contingent on a particular situation. Many common models fall into this modeling approach, including reinforcement learning (Sutton &#x00026; Barto, <xref rid="tops12679-bib-0121" ref-type="bibr">1998</xref>), mathematical models of choice (Denrell, <xref rid="tops12679-bib-0034" ref-type="bibr">2007</xref>; March, <xref rid="tops12679-bib-0081" ref-type="bibr">1996</xref>), and cognitive models of decisions from experience (Erev et&#x000a0;al., <xref rid="tops12679-bib-0041" ref-type="bibr">2010</xref>; Gonzalez &#x00026; Dutt, <xref rid="tops12679-bib-0050" ref-type="bibr">2011</xref>; Lejarraga, Dutt, &#x00026; Gonzalez, <xref rid="tops12679-bib-0073" ref-type="bibr">2012</xref>). Here we focus on IBLT, a theory of decisions from experience that articulates the general cognitive processes of experiential choice (Hertwig, <xref rid="tops12679-bib-0059" ref-type="bibr">2015</xref>), which results in models that generalize and outperform the models based on many other theories of decisions from experience proposed in modeling competitions (Erev et&#x000a0;al., <xref rid="tops12679-bib-0041" ref-type="bibr">2010</xref>).</p></sec><sec id="tops12679-sec-0160"><label>5.2</label><title>Instance&#x02010;based learning theory</title><p>IBLT emerged from the need to explain the process of dynamic decision&#x02010;making, where a sequence of interdependent decisions are made sequentially and over time (Gonzalez et&#x000a0;al., <xref rid="tops12679-bib-0051" ref-type="bibr">2003</xref>). IBLT provides a single general algorithm and mathematical formulation of memory retrieval that relies on the well&#x02010;known ACT&#x02010;R cognitive architecture (Anderson &#x00026; Lebiere, <xref rid="tops12679-bib-0005" ref-type="bibr">2014</xref>). The theory proposes a representation of decisions in the form of instances, which are triplets involving the state, actions, and utilities. States are a representation of the features of the situation in a task, actions are decisions an agent makes in such states, and utilities are the expectations the agent generates or the outcomes the agent receives from performing such actions. IBLT also provides a process for generating accumulated value (expectation from experience) for each choice alternative based on a mechanism called blending, which is a function of the payoffs experienced and the probability of the agent retrieving those instances from memory (Gonzalez &#x00026; Dutt, <xref rid="tops12679-bib-0050" ref-type="bibr">2011</xref>; Lejarraga et&#x000a0;al., <xref rid="tops12679-bib-0073" ref-type="bibr">2012</xref>).</p><p>IBLT is particularly useful in the context of the transactive systems model as it encodes actions that the AI agent takes (in the world or interactions with others) as experiences in its memory. And, owing to its learning mechanism, specific sets of action, or decision sequences emerge (akin to attentional hierarchy) that prove to be most productive given its reward function. Importantly, we can also query IBLT models for experiences that constitute these productive decision sequences.</p><p>Recently, the instance&#x02013;based learning (IBL) algorithm has been applied to multistate grid world tasks (Nguyen &#x00026; Gonzalez, <xref rid="tops12679-bib-0091" ref-type="bibr">2020</xref>, <xref rid="tops12679-bib-0092" ref-type="bibr">2022</xref>) and to tasks in which multidimensional state&#x02010;action&#x02010;utility representations are required to build real&#x02010;time interactivity between models and humans (Nguyen, Phan, &#x00026; Gonzalez, <xref rid="tops12679-bib-0093" ref-type="bibr">2022</xref>). With the increased use of IBLT in generating models on tasks of greater complexity and in multiple domains, models in tasks that involve multiple players are also becoming more common. Initial theoretical developments of IBLT in this direction involved two&#x02010;person game theoretical models (Gonzalez, Ben&#x02010;Asher, Martin, &#x00026; Dutt, <xref rid="tops12679-bib-0049" ref-type="bibr">2015</xref>). More recently, other interesting representations have been proposed, including the ability to represent a ToM (Nguyen &#x00026; Gonzalez, <xref rid="tops12679-bib-0092" ref-type="bibr">2022</xref>).</p><p>ToM refers to the ability to infer and interpret the beliefs, desires, and intentions of others (Premack &#x00026; Woodruff, <xref rid="tops12679-bib-0100" ref-type="bibr">1978</xref>; Rusch, Steixner&#x02010;Kumar, Doshi, Spezio, &#x00026; Gl&#x000e4;scher, <xref rid="tops12679-bib-0107" ref-type="bibr">2020</xref>), and it is an essential component of human learning and social cognition, including the acquisition of social norms and social beliefs (MacLean, <xref rid="tops12679-bib-0077" ref-type="bibr">2016</xref>). Nguyen and Gonzalez (<xref rid="tops12679-bib-0092" ref-type="bibr">2022</xref>) address the challenge of creating computational models of machine theory of mind (MToM) and verify whether those models are able to emulate human ToM. Creating computational representations of MToM provides an important foundation for AI research, and researchers have primarily used one of two prominent computational approaches based on Bayesian models (Baker et&#x000a0;al., <xref rid="tops12679-bib-0013" ref-type="bibr">2011</xref>, <xref rid="tops12679-bib-0012" ref-type="bibr">2017</xref>) or deep learning (Rabinowitz et&#x000a0;al., <xref rid="tops12679-bib-0101" ref-type="bibr">2018</xref>). Nguyen and Gonzalez (<xref rid="tops12679-bib-0092" ref-type="bibr">2022</xref>) additionally demonstrate how an IBL model can provide a more accurate representation of human ToM compared to the other approaches, which is confirmed by experimental evidence in which humans make predictions about others&#x02019; actions that are consistent with the IBL model's predictions. IBL models can also predict the false beliefs of an acting agent, another ability that is essential to ToM (Baron&#x02010;Cohen, Leslie, &#x00026; Frith, <xref rid="tops12679-bib-0016" ref-type="bibr">1985</xref>).</p><p>In summary, extant work on learning&#x02010;based cognitive modeling, specifically IBLT, provides an important understanding of how individual agents generate knowledge by learning from the environment that helps them attend to their goals and direct their actions. In addition, researchers can use the same mechanisms for building human&#x02010;like ToM models by observing others' behavior. Thus, IBLT supplies critical building blocks for modeling shared cognition processes&#x02014;memory, attention, and reasoning&#x02014; central to TSM&#x02010;CI.</p><p>More generally, a well&#x02010;designed sociocognitive architecture that successfully leads to the emergence of collective human&#x02013;machine intelligence is likely to comprise AI agents with internal mechanisms for dealing with interactions and MToM that easily interfaces with the sociocognitive mechanisms. Thus, we assert that evaluating various combinations of cognitive and sociocognitive architectures for compatibility will be critical for advancing COHUMAIN research.</p></sec></sec><sec id="tops12679-sec-0170"><label>6</label><title>Conclusion</title><p>In this paper, in addition to proposing a guiding research agenda for studying sociocognitive architectures that allow collective human&#x02013;machine intelligence to emerge, we also present one. Specifically, we describe and extend the TSM&#x02010;CI&#x02014;an integrated and interdisciplinary systems approach&#x02014;for building a sociocognitive architecture that breaks down the phenomenon of CI into three coregulatory systems for coordinating collective memory, attention, and reasoning. We also highlight the value of using AI agents with cognitive architectures that align with the sociocognitive one. Specifically, discussing IBLT, a particularly compatible cognitive architecture, for developing the AI agents within the transactive systems model.</p><p>The early&#x02010;stage development in the field of AI (1970s through the 1990s) significantly benefited from the numerous and diverse attempts at proposing and testing a variety of cognitive architectures. Hence, we think there is tremendous value in creating many different approaches to theorize, design, and test sociocognitive architectures that deal with the dynamics of how humans and machines work together. This demands playing around with models that integrate and expand the research findings from management and behavioral sciences and design lessons from cognitive sciences and AI. We take this opportunity to call upon researchers across fields to not only engage with our proposal but also develop new and varied sociocognitive architectures to help unlock the potential impact of COHUMAIN.</p></sec></body><back><ack id="tops12679-sec-0180"><title>Acknowledgments</title><p>This research is based upon work supported by the Defense Advanced Research Projects Agency, award number: W911NF&#x02010;20&#x02010;1&#x02010;0006. Any opinions, findings, conclusions, or recommendations expressed in this paper are those of the author(s) and do not necessarily reflect the views of DARPA.</p></ack><fn-group id="tops12679-ntgp-0001"><title>Note</title><fn id="tops12679-note-0001"><label>1</label><p>In this paper, we refer to autonomous machines or AI agents to be <italic toggle="yes">autonomous</italic> only in the sense of independently perceiving and processing information from a changing environment as well as teammates to generate plausible actions that are aligned with their designed goals. While the agents may generate internal goal hierarchies at the task level, unlike humans, these AI agents do not have complete goal autonomy. That is, they lack intrinsic motivation and the overarching or ultimate goal (or a set of AI system constraints) that they optimize for are chosen by their developers. For example, a search engine generates results that are &#x0201c;relevant&#x0201d; to the user and &#x0201c;profitable&#x0201d; for the company. In this way, AI agents are developed with desired goal that may or may not align with their human collaborators. And may vary in how flexibly they will adjust those goal states in response to their interaction. As these goals/values are ostensibly hidden it is beneficial for the humans in the collective to understand and use them with caution. Thanks to an anonymous reviewer for pointing out this distinction between autonomous action and goal autonomy.</p></fn></fn-group><ref-list id="tops12679-bibl-0001"><title>References</title><ref id="tops12679-bib-0001"><mixed-citation publication-type="journal" id="tops12679-cit-0001">
<string-name>
<surname>Ackerman</surname>, <given-names>R.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Thompson</surname>, <given-names>V. A.</given-names>
</string-name> (<year>2017</year>). <article-title>Meta&#x02010;reasoning: Monitoring and control of thinking and reasoning</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>21</volume>(<issue>8</issue>), <fpage>607</fpage>&#x02013;<lpage>617</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.05.004</pub-id>
<pub-id pub-id-type="pmid">28625355</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0002"><mixed-citation publication-type="book" id="tops12679-cit-0002">
<string-name>
<surname>Akash</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Jain</surname>, <given-names>N.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Misu</surname>, <given-names>T.</given-names>
</string-name> (<year>2020</year>). <article-title>Toward adaptive trust calibration for level 2 driving automation</article-title>. In <article-title>
Proceedings of the 2020 international conference on multimodal interaction
</article-title> (pp. <fpage>538</fpage>&#x02013;<lpage>547</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>. <pub-id pub-id-type="doi">10.1145/3382507.3418885</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0003"><mixed-citation publication-type="journal" id="tops12679-cit-0003">
<string-name>
<surname>Adams</surname>, <given-names>M. J.</given-names>
</string-name>, <string-name>
<surname>Tenney</surname>, <given-names>Y. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Pew</surname>, <given-names>R. W.</given-names>
</string-name> (<year>1995</year>). <article-title>Situation awareness and the cognitive management of complex systems</article-title>. <source>Human Factors</source>, <volume>37</volume>(<issue>1</issue>), <fpage>85</fpage>&#x02013;<lpage>104</lpage>. <pub-id pub-id-type="doi">10.1518/001872095779049462</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0004"><mixed-citation publication-type="journal" id="tops12679-cit-0004">
<string-name>
<surname>Anderson</surname>, <given-names>J. R.</given-names>
</string-name>, <string-name>
<surname>Conrad</surname>, <given-names>F. G.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Corbett</surname>, <given-names>A. T.</given-names>
</string-name> (<year>1989</year>). <article-title>Skill acquisition and the LISP tutor</article-title>. <source>Cognitive Science</source>, <volume>13</volume>(<issue>4</issue>), <fpage>467</fpage>&#x02013;<lpage>505</lpage>. <pub-id pub-id-type="doi">10.1207/s15516709cog1304_1</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0005"><mixed-citation publication-type="book" id="tops12679-cit-0005">
<string-name>
<surname>Anderson</surname>, <given-names>J. R.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Lebiere</surname>, <given-names>C. J.</given-names>
</string-name> (<year>2014</year>). <source>The atomic components of thought</source>. <publisher-loc>Hove, England</publisher-loc>: <publisher-name>Psychology Press</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0006"><mixed-citation publication-type="journal" id="tops12679-cit-0006">
<string-name>
<surname>Anderson</surname>, <given-names>J. R.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Milson</surname>, <given-names>R.</given-names>
</string-name> (<year>1989</year>). <article-title>Human memory: An adaptive perspective</article-title>. <source>Psychological Review</source>, <volume>96</volume>(<issue>4</issue>), <fpage>703</fpage>&#x02013;<lpage>719</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.96.4.703</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0007"><mixed-citation publication-type="journal" id="tops12679-cit-0007">
<string-name>
<surname>Anderson</surname>, <given-names>J. R.</given-names>
</string-name>, <string-name>
<surname>Reder</surname>, <given-names>L. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Lebiere</surname>, <given-names>C.</given-names>
</string-name> (<year>1996</year>). <article-title>Working memory: Activation limitations on retrieval</article-title>. <source>Cognitive Psychology</source>, <volume>30</volume>(<issue>3</issue>), <fpage>221</fpage>&#x02013;<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1006/cogp.1996.0007</pub-id>
<pub-id pub-id-type="pmid">8660785</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0008"><mixed-citation publication-type="journal" id="tops12679-cit-0008">
<string-name>
<surname>Anderson</surname>, <given-names>J. R.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Schooler</surname>, <given-names>L. J.</given-names>
</string-name> (<year>1991</year>). <article-title>Reflections of the Environment in memory</article-title>. <source>Psychological Science</source>, <volume>2</volume>(<issue>6</issue>), <fpage>396</fpage>&#x02013;<lpage>408</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.1991.tb00174.x</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0009"><mixed-citation publication-type="book" id="tops12679-cit-0009">
<string-name>
<surname>Arrow</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>McGrath</surname>, <given-names>J. E.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Berdahl</surname>, <given-names>J. L.</given-names>
</string-name> (<year>2000</year>). <source>Small groups as complex systems: Formation, coordination, development and adaptation</source>. <publisher-loc>Thousand Oaks, CA</publisher-loc>: <publisher-name>Sage Publications</publisher-name>. <pub-id pub-id-type="doi">10.4135/9781452204666</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0010"><mixed-citation publication-type="journal" id="tops12679-cit-0010">
<string-name>
<surname>Azhar</surname>, <given-names>M. Q.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Sklar</surname>, <given-names>E. I.</given-names>
</string-name> (<year>2017</year>). <article-title>A study measuring the impact of shared decision making in a human&#x02010;robot team</article-title>. <source>The International Journal of Robotics Research</source>, <volume>36</volume>(<issue>5&#x02013;7</issue>), <fpage>461</fpage>&#x02013;<lpage>482</lpage>. <pub-id pub-id-type="doi">10.1177/0278364917710540</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0011"><mixed-citation publication-type="journal" id="tops12679-cit-0011">
<string-name>
<surname>Bacharach</surname>, <given-names>M.</given-names>
</string-name> (<year>1999</year>). <article-title>Interactive team reasoning: A contribution to the theory of co&#x02010;operation</article-title>. <source>Research in Economics</source>, <volume>53</volume>(<issue>2</issue>), <fpage>117</fpage>&#x02013;<lpage>147</lpage>. <pub-id pub-id-type="doi">10.1006/reec.1999.0188</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0012"><mixed-citation publication-type="journal" id="tops12679-cit-0012">
<string-name>
<surname>Baker</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Jara&#x02010;Ettinger</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Saxe</surname>, <given-names>R.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Tenenbaum</surname>, <given-names>J. B.</given-names>
</string-name> (<year>2017</year>). <article-title>Rational quantitative attribution of beliefs, desires and percepts in human mentalizing</article-title>. <source>Nature Human Behaviour</source>, <volume>1</volume>(<issue>4</issue>), <fpage>0064</fpage>. <pub-id pub-id-type="doi">10.1038/s41562-017-0064</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0013"><mixed-citation publication-type="journal" id="tops12679-cit-0013">
<string-name>
<surname>Baker</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Saxe</surname>, <given-names>R.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Tenenbaum</surname>, <given-names>J.</given-names>
</string-name> (<year>2011</year>). <article-title>Bayesian theory of mind: Modeling joint belief&#x02010;desire attribution</article-title>. <article-title>
Proceedings of the annual meeting of the Cognitive Science Society
</article-title>, <volume>33</volume>, <fpage>2469</fpage>&#x02013;<lpage>2474</lpage>. <ext-link xlink:href="https://escholarship.org/uc/item/5rk7z59q" ext-link-type="uri">https://escholarship.org/uc/item/5rk7z59q</ext-link>
</mixed-citation></ref><ref id="tops12679-bib-0014"><mixed-citation publication-type="journal" id="tops12679-cit-0014">
<string-name>
<surname>Bandura</surname>, <given-names>A.</given-names>
</string-name> (<year>1991</year>). <article-title>Social cognitive theory of self&#x02010;regulation</article-title>. <source>Organizational Behavior and Human Decision Processes</source>, <volume>50</volume>(<issue>2</issue>), <fpage>248</fpage>&#x02013;<lpage>287</lpage>. <pub-id pub-id-type="doi">10.1016/0749-5978(91)90022-L</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0015"><mixed-citation publication-type="journal" id="tops12679-cit-0015">
<string-name>
<surname>Barnes</surname>, <given-names>C. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Van Dyne</surname>, <given-names>L.</given-names>
</string-name> (<year>2009</year>). `<article-title>I'm tired&#x02019;: Differential effects of physical and emotional fatigue on workload management strategies</article-title>. <source>Human Relations</source>, <volume>62</volume>(<issue>1</issue>), <fpage>59</fpage>&#x02013;<lpage>92</lpage>. <pub-id pub-id-type="doi">10.1177/0018726708099518</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0016"><mixed-citation publication-type="journal" id="tops12679-cit-0016">
<string-name>
<surname>Baron&#x02010;Cohen</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Leslie</surname>, <given-names>A. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Frith</surname>, <given-names>U.</given-names>
</string-name> (<year>1985</year>). <article-title>Does the autistic child have a &#x0201c;theory of mind&#x0201d;?</article-title>
<source>Cognition</source>, <volume>21</volume>(<issue>1</issue>), <fpage>37</fpage>&#x02013;<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1016/0010-0277(85)90022-8</pub-id>
<pub-id pub-id-type="pmid">2934210</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0017"><mixed-citation publication-type="book" id="tops12679-cit-0017">
<string-name>
<surname>Boardman</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Butcher</surname>, <given-names>F.</given-names>
</string-name> (<year>2019</year>). <article-title>
<italic toggle="yes">An exploration of maintaining human control in AI enabled systems and the challenges of achieving it</italic> (Technical Report)</article-title>. <publisher-name>NATO</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0018"><mixed-citation publication-type="journal" id="tops12679-cit-0018">
<string-name>
<surname>Bolstad</surname>, <given-names>C. A.</given-names>
</string-name>, <string-name>
<surname>Cuevas</surname>, <given-names>H. M.</given-names>
</string-name>, <string-name>
<surname>Connors</surname>, <given-names>E. S.</given-names>
</string-name>, <string-name>
<surname>Gonz&#x000e1;lez</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Foltz</surname>, <given-names>P. W.</given-names>
</string-name>, <string-name>
<surname>Lau</surname>, <given-names>N. K. C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Warwick</surname>, <given-names>W. J.</given-names>
</string-name> (<year>2010</year>). <article-title>Advances in modeling situation awareness, decision making, and performance in complex operational environments</article-title>. <source>Proceedings of the Human Factors and Ergonomics Society Annual Meeting</source>, <volume>54</volume>(<issue>13</issue>), <fpage>1047</fpage>&#x02013;<lpage>1051</lpage>. <pub-id pub-id-type="doi">10.1177/154193121005401310</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0019"><mixed-citation publication-type="journal" id="tops12679-cit-0019">
<string-name>
<surname>Borst</surname>, <given-names>J. P.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Anderson</surname>, <given-names>J. R.</given-names>
</string-name> (<year>2013</year>). <article-title>Using model&#x02010;based functional MRI to locate working memory updates and declarative memory retrievals in the fronto&#x02010;parietal network</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume>(<issue>5</issue>), <fpage>1628</fpage>&#x02013;<lpage>1633</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1221572110</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0020"><mixed-citation publication-type="journal" id="tops12679-cit-0020">
<string-name>
<surname>Burke</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Murphy</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Coovert</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Riddle</surname>, <given-names>D.</given-names>
</string-name> (<year>2004</year>). <article-title>Moonlight in Miami: Field study of human&#x02010;robot interaction in the context of an urban search and rescue disaster response training exercise</article-title>. <source>Human&#x02010;Computer Interaction</source>, <volume>19</volume>(<issue>1</issue>), <fpage>85</fpage>&#x02013;<lpage>116</lpage>. <pub-id pub-id-type="doi">10.1207/s15327051hci1901&#x00026;2_5</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0021"><mixed-citation publication-type="journal" id="tops12679-cit-0021">
<string-name>
<surname>Carroll</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Shah</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Ho</surname>, <given-names>M. K.</given-names>
</string-name>, <string-name>
<surname>Griffiths</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Seshia</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Abbeel</surname>, <given-names>P.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Dragan</surname>, <given-names>A.</given-names>
</string-name> (<year>2019</year>). <article-title>On the utility of learning about humans for human&#x02010;AI coordination</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>32</volume>, <fpage>5174</fpage>&#x02013;<lpage>5185</lpage>. <ext-link xlink:href="https://dl.acm.org/doi/10.5555/3454287.3454752" ext-link-type="uri">https://dl.acm.org/doi/10.5555/3454287.3454752</ext-link>
</mixed-citation></ref><ref id="tops12679-bib-0022"><mixed-citation publication-type="book" id="tops12679-cit-0022">
<string-name>
<surname>Carsrud</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Br&#x000e4;nnback</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Elfving</surname>, <given-names>J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Brandt</surname>, <given-names>K.</given-names>
</string-name> (<year>2009</year>). <part-title>Motivations: The entrepreneurial mind and behavior</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>A. L.</given-names>
<surname>Carsrud</surname>
</string-name>
</person-group> &#x00026; <person-group person-group-type="editor">
<string-name>
<given-names>M.</given-names>
<surname>Br&#x000e4;nnback</surname>
</string-name>
</person-group> (Eds.), <source>Understanding the entrepreneurial mind: Opening the black box</source> (pp. <fpage>141</fpage>&#x02013;<lpage>165</lpage>). Berlin, Germany: <publisher-name>Springer&#x02010;Verlag</publisher-name>. <pub-id pub-id-type="doi">10.1007/978-1-4419-0443-0</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0023"><mixed-citation publication-type="miscellaneous" id="tops12679-cit-0023">
<string-name>
<surname>Chakraborti</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Kambhampati</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Scheutz</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Zhang</surname>, <given-names>Y.</given-names>
</string-name> (<year>2017</year>). <article-title>AI challenges in human&#x02010;robot cognitive teaming. arXiv</article-title>. arXiv:1707.04775. <ext-link xlink:href="http://arxiv.org/abs/1707.04775" ext-link-type="uri">http://arxiv.org/abs/1707.04775</ext-link>
</mixed-citation></ref><ref id="tops12679-bib-0024"><mixed-citation publication-type="book" id="tops12679-cit-0024">
<string-name>
<surname>Chen</surname>, <given-names>J. Y. C.</given-names>
</string-name>, <string-name>
<surname>Quinn</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Wright</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Barnes</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Barber</surname>, <given-names>D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Adams</surname>, <given-names>D.</given-names>
</string-name> (<year>2013</year>). <part-title>Human&#x02010;agent teaming for robot management in multitasking environments</part-title>. In <article-title>
2013 8th ACM/IEEE International Conference on Human&#x02010;Robot Interaction (HRI)
</article-title>, (pp. <fpage>103</fpage>&#x02013;<lpage>104</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>. <pub-id pub-id-type="doi">10.1109/HRI.2013.6483522</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0025"><mixed-citation publication-type="book" id="tops12679-cit-0025">
<string-name>
<surname>Chidambaram</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Summers</surname>, <given-names>J. D.</given-names>
</string-name>, <string-name>
<surname>Miranda</surname>, <given-names>S. M.</given-names>
</string-name>, <string-name>
<surname>Young</surname>, <given-names>A. G.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Bostrom</surname>, <given-names>R. P.</given-names>
</string-name> (<year>2020</year>). <part-title>Time, technology, and teams: From GSS to collective action</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>D. M.</given-names>
<surname>Kilgour</surname>
</string-name>
</person-group>
<person-group person-group-type="editor">
<string-name>
<given-names>&#x00026; C.</given-names>
<surname>Eden</surname>
</string-name>
</person-group> (Eds.), <source>Handbook of group decision and negotiation</source> (pp. <fpage>1</fpage>&#x02013;<lpage>27</lpage>). <publisher-loc>Cham, Switzerland</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>. <pub-id pub-id-type="doi">10.1007/978-3-030-12051-1_28-1</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0026"><mixed-citation publication-type="book" id="tops12679-cit-0026">
<string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name>, <string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2016</year>). <source>Synthetic teammates as team players: Coordination of human and synthetic teammates</source> (RE2016844 01). <publisher-loc>Mesa, AZ</publisher-loc>: <publisher-name>Cognitive Engineering Research Institute</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0027"><mixed-citation publication-type="journal" id="tops12679-cit-0027">
<string-name>
<surname>Csaszar</surname>, <given-names>F.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Steinberger</surname>, <given-names>T.</given-names>
</string-name> (<year>2021</year>). <article-title>Organizations as artificial intelligences: The use of artificial intelligence analogies in organization theory</article-title>. <source>Academy of Management Annals</source>, <volume>16</volume>(<issue>1</issue>). <fpage>1</fpage>&#x02013;<lpage>37</lpage>. <pub-id pub-id-type="doi">10.5465/annals.2020.0192</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0028"><mixed-citation publication-type="journal" id="tops12679-cit-0028">
<string-name>
<surname>Cuevas</surname>, <given-names>H. M.</given-names>
</string-name>, <string-name>
<surname>Fiore</surname>, <given-names>S. M.</given-names>
</string-name>, <string-name>
<surname>Caldwell</surname>, <given-names>B. S.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Strater</surname>, <given-names>L.</given-names>
</string-name> (<year>2007</year>). <article-title>Augmenting team cognition in human&#x02010;automation teams performing in complex operational environments</article-title>. <source>Aviation, Space, and Environmental Medicine</source>, <volume>78</volume>(<issue>5</issue>), <fpage>B63</fpage>&#x02013;<lpage>B70</lpage>.<pub-id pub-id-type="pmid">17547306</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0029"><mixed-citation publication-type="journal" id="tops12679-cit-0029">
<string-name>
<surname>Cummings</surname>, <given-names>M. L.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Guerlain</surname>, <given-names>S.</given-names>
</string-name> (<year>2007</year>). <article-title>Developing operator capacity estimates for supervisory control of autonomous vehicles</article-title>. <source>Human Factors</source>, <volume>49</volume>(<issue>1</issue>), <fpage>1</fpage>&#x02013;<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1518/001872007779598109</pub-id>
<pub-id pub-id-type="pmid">17315838</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0030"><mixed-citation publication-type="journal" id="tops12679-cit-0030">
<string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Amazeen</surname>, <given-names>P. G.</given-names>
</string-name> (<year>2018</year>). <article-title>A conceptual model of team dynamical behaviors and performance in human&#x02010;autonomy teaming</article-title>. <source>Cognitive Systems Research</source>, <volume>52</volume>, <fpage>497</fpage>&#x02013;<lpage>507</lpage>. <pub-id pub-id-type="doi">10.1016/j.cogsys.2018.07.029</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0031"><mixed-citation publication-type="journal" id="tops12679-cit-0031">
<string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Likens</surname>, <given-names>A. D.</given-names>
</string-name>, <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name>, <string-name>
<surname>Amazeen</surname>, <given-names>P. G.</given-names>
</string-name>, &#x00026; <string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2019</year>). <article-title>Team coordination and effectiveness in human&#x02010;autonomy teaming</article-title>. <source>IEEE Transactions on Human&#x02010;Machine Systems</source>, <volume>49</volume>(<issue>2</issue>), <fpage>150</fpage>&#x02013;<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1109/THMS.2018.2877482</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0032"><mixed-citation publication-type="book" id="tops12679-cit-0032">
<string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2016</year>). <article-title>Team communication behaviors of the human&#x02010;automation teaming</article-title>. In <article-title>
2016 IEEE International Multi&#x02010;Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)
</article-title> (pp. <fpage>28</fpage>&#x02013;<lpage>34</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>. <pub-id pub-id-type="doi">10.1109/COGSIMA.2016.7497782</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0033"><mixed-citation publication-type="journal" id="tops12679-cit-0033">
<string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2018</year>). <article-title>The impact of perceived autonomous agents on dynamic team behaviors</article-title>. <source>IEEE Transactions on Emerging Topics in Computational Intelligence</source>, <volume>2</volume>(<issue>4</issue>), <fpage>258</fpage>&#x02013;<lpage>267</lpage>. <pub-id pub-id-type="doi">10.1109/TETCI.2018.2829985</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0034"><mixed-citation publication-type="journal" id="tops12679-cit-0034">
<string-name>
<surname>Denrell</surname>, <given-names>J.</given-names>
</string-name> (<year>2007</year>). <article-title>Adaptive learning and risk&#x02010;taking</article-title>. <source>Psychological Review</source>, <volume>114</volume>(<issue>1</issue>), <fpage>177</fpage>&#x02013;<lpage>187</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.114.1.177</pub-id>
<pub-id pub-id-type="pmid">17227186</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0035"><mixed-citation publication-type="journal" id="tops12679-cit-0035">
<string-name>
<surname>Dierdorff</surname>, <given-names>E. C.</given-names>
</string-name>, <string-name>
<surname>Fisher</surname>, <given-names>D. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Rubin</surname>, <given-names>R. S.</given-names>
</string-name> (<year>2019</year>). <article-title>The power of percipience: Consequences of self&#x02010;awareness in teams on team&#x02010;level functioning and performance</article-title>. <source>Journal of Management</source>, <volume>45</volume>(<issue>7</issue>), <fpage>2891</fpage>&#x02013;<lpage>2919</lpage>. <pub-id pub-id-type="doi">10.1177/0149206318774622</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0036"><mixed-citation publication-type="journal" id="tops12679-cit-0036">
<string-name>
<surname>Dorneich</surname>, <given-names>M. C.</given-names>
</string-name>, <string-name>
<surname>Passinger</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Hamblin</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Keinrath</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Va&#x00161;ek</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Whitlow</surname>, <given-names>S. D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Beekhuyzen</surname>, <given-names>M.</given-names>
</string-name> (<year>2017</year>). <article-title>Evaluation of the display of cognitive state feedback to drive adaptive task sharing</article-title>. <source>Frontiers in Neuroscience</source>, <volume>11</volume>, <fpage>144</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2017.00144</pub-id>
<pub-id pub-id-type="pmid">28400716</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0037"><mixed-citation publication-type="journal" id="tops12679-cit-0037">
<string-name>
<surname>Endsley</surname>, <given-names>M. R.</given-names>
</string-name> (<year>1995a</year>). <article-title>Toward a theory of situation awareness in dynamic systems</article-title>. <source>Human Factors</source>, <volume>37</volume>(<issue>1</issue>), <fpage>32</fpage>&#x02013;<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1518/001872095779049543</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0038"><mixed-citation publication-type="journal" id="tops12679-cit-0038">
<string-name>
<surname>Endsley</surname>, <given-names>M. R.</given-names>
</string-name> (<year>1995b</year>). <article-title>Measurement of situation awareness in dynamic systems</article-title>. <source>Human Factors</source>, <volume>37</volume>(<issue>1</issue>), <fpage>65</fpage>&#x02013;<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1518/001872095779049499</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0039"><mixed-citation publication-type="journal" id="tops12679-cit-0039">
<string-name>
<surname>Endsley</surname>, <given-names>M. R.</given-names>
</string-name> (<year>2015</year>). <article-title>Situation awareness misconceptions and misunderstandings</article-title>. <source>Journal of Cognitive Engineering and Decision Making</source>, <volume>9</volume>(<issue>1</issue>), <fpage>4</fpage>&#x02013;<lpage>32</lpage>. <pub-id pub-id-type="doi">10.1177/1555343415572631</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0040"><mixed-citation publication-type="book" id="tops12679-cit-0040">
<string-name>
<surname>Endsley</surname>, <given-names>M. R.</given-names>
</string-name> (<year>2017</year>). <part-title>Toward a theory of situation awareness in dynamic systems</part-title>. In <source>Situational awareness</source> (pp. <fpage>9</fpage>&#x02013;<lpage>42</lpage>). <publisher-loc>Milton, Park, England</publisher-loc>: <publisher-name>Routledge</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0041"><mixed-citation publication-type="journal" id="tops12679-cit-0041">
<string-name>
<surname>Erev</surname>, <given-names>I.</given-names>
</string-name>, <string-name>
<surname>Ert</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Roth</surname>, <given-names>A. E.</given-names>
</string-name>, <string-name>
<surname>Haruvy</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Herzog</surname>, <given-names>S. M.</given-names>
</string-name>, <string-name>
<surname>Hau</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Hertwig</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Stewart</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>West</surname>, <given-names>R.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Lebiere</surname>, <given-names>C.</given-names>
</string-name> (<year>2010</year>). <article-title>A choice prediction competition: Choices from experience and from description</article-title>. <source>Journal of Behavioral Decision Making</source>, <volume>23</volume>(<issue>1</issue>), <fpage>15</fpage>&#x02013;<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1002/bdm.683</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0042"><mixed-citation publication-type="book" id="tops12679-cit-0042">
<string-name>
<surname>Fan</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Oh</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>McNeese</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Yen</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Cuevas</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Strater</surname>, <given-names>L.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Endsley</surname>, <given-names>M. R.</given-names>
</string-name> (<year>2008</year>). <article-title>The influence of agent reliability on trust in human&#x02010;agent collaboration</article-title>. In <article-title>
<italic toggle="yes">Proceedings of the 15th European conference on cognitive ergonomics the ergonomics of cool interaction (ECCE &#x02019;08)</italic> (pp. 1&#x02013;8)</article-title>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>ACM</publisher-name>. <pub-id pub-id-type="doi">10.1145/1473018.1473028</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0043"><mixed-citation publication-type="journal" id="tops12679-cit-0043">
<string-name>
<surname>Fan</surname>, <given-names>X.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Yen</surname>, <given-names>J.</given-names>
</string-name> (<year>2011</year>). <article-title>Modeling cognitive loads for evolving shared mental models in human&#x02013;agent collaboration</article-title>. <source>IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</source>, <volume>41</volume>(<issue>2</issue>), <fpage>354</fpage>&#x02013;<lpage>367</lpage>. <pub-id pub-id-type="doi">10.1109/TSMCB.2010.2053705</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0044"><mixed-citation publication-type="journal" id="tops12679-cit-0044">
<string-name>
<surname>Fitzsimons</surname>, <given-names>G. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Finkel</surname>, <given-names>E. J.</given-names>
</string-name> (<year>2018</year>). <article-title>Transactive&#x02010;goal&#x02010;dynamics theory: A discipline&#x02010;wide perspective</article-title>. <source>Current Directions in Psychological Science</source>, <volume>27</volume>(<issue>5</issue>), <fpage>332</fpage>&#x02013;<lpage>338</lpage>. <pub-id pub-id-type="doi">10.1177/0963721417754199</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0045"><mixed-citation publication-type="journal" id="tops12679-cit-0045">
<string-name>
<surname>Galesic</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Barkoczi</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Berdahl</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Biro</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Carbone</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Kandler</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Kao</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Kendal</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Kline</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Lee</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Massari</surname>, <given-names>G. F.</given-names>
</string-name>, <string-name>
<surname>Mesoudi</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Olsson</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Pescetelli</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Sloman</surname>, <given-names>S. J.</given-names>
</string-name>, <string-name>
<surname>Smaldimo</surname>, <given-names>P. E.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Stein</surname>, <given-names>D. L.</given-names>
</string-name> (<year>2023</year>). <article-title>Beyond collective intelligence: Collective adaptation</article-title>. <source>Journal of The Royal Society Interface</source>, <volume>20</volume>(<issue>200</issue>), <elocation-id>20220736</elocation-id>. <pub-id pub-id-type="doi">10.1098/rsif.2022.0736</pub-id>
<pub-id pub-id-type="pmid">36946092</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0046"><mixed-citation publication-type="journal" id="tops12679-cit-0046">
<string-name>
<surname>Geib</surname>, <given-names>C. W.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Goldman</surname>, <given-names>R. P.</given-names>
</string-name> (<year>2009</year>). <article-title>A probabilistic plan recognition algorithm based on plan tree grammars</article-title>. <source>Artificial Intelligence</source>, <volume>173</volume>(<issue>11</issue>), <fpage>1101</fpage>&#x02013;<lpage>1132</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0047"><mixed-citation publication-type="journal" id="tops12679-cit-0047">
<string-name>
<surname>Glikson</surname>, <given-names>E.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name> (<year>2020</year>). <article-title>Human trust in artificial intelligence: Review of empirical research</article-title>. <source>Academy of Management Annals</source>, <volume>14</volume>(<issue>2</issue>), <fpage>627</fpage>&#x02013;<lpage>660</lpage>. <pub-id pub-id-type="doi">10.5465/annals.2018.0057</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0048"><mixed-citation publication-type="book" id="tops12679-cit-0048">
<string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name> (<year>2013</year>). <article-title>The boundaries of instance&#x02010;based learning theory for explaining decisions from experience</article-title>. <source>Progress in Brain Research</source>, <volume>202</volume>, <fpage>73</fpage>&#x02013;<lpage>98</lpage>. <publisher-name>Elsevier</publisher-name>. <pub-id pub-id-type="doi">10.1016/B978-0-444-62604-2.00005-8</pub-id>
<pub-id pub-id-type="pmid">23317827</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0049"><mixed-citation publication-type="journal" id="tops12679-cit-0049">
<string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Ben&#x02010;Asher</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Martin</surname>, <given-names>J. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Dutt</surname>, <given-names>V.</given-names>
</string-name> (<year>2015</year>). <article-title>A cognitive model of dynamic cooperation with varied interdependency information</article-title>. <source>Cognitive Science</source>, <volume>39</volume>(<issue>3</issue>), <fpage>457</fpage>&#x02013;<lpage>495</lpage>. <pub-id pub-id-type="doi">10.1111/cogs.12170</pub-id>
<pub-id pub-id-type="pmid">25250832</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0050"><mixed-citation publication-type="journal" id="tops12679-cit-0050">
<string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Dutt</surname>, <given-names>V.</given-names>
</string-name> (<year>2011</year>). <article-title>Instance&#x02010;based learning: Integrating sampling and repeated decisions from experience</article-title>. <source>Psychological Review</source>, <volume>118</volume>(<issue>4</issue>), <fpage>523</fpage>&#x02013;<lpage>551</lpage>. <pub-id pub-id-type="doi">10.1037/a0024558</pub-id>
<pub-id pub-id-type="pmid">21806307</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0051"><mixed-citation publication-type="journal" id="tops12679-cit-0051">
<string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Lerch</surname>, <given-names>J. F.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Lebiere</surname>, <given-names>C.</given-names>
</string-name> (<year>2003</year>). <article-title>Instance&#x02010;based learning in dynamic decision making</article-title>. <source>Cognitive Science</source>, <volume>27</volume>(<issue>4</issue>), <fpage>591</fpage>&#x02013;<lpage>635</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0052"><mixed-citation publication-type="journal" id="tops12679-cit-0052">
<string-name>
<surname>Goodwin</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Blacksmith</surname>, <given-names>N.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Coats</surname>, <given-names>M.</given-names>
</string-name> (<year>2018</year>). <article-title>The science of teams in the military: Contributions from over 60 years of research</article-title>. <source>American Psychologist</source>, <volume>73</volume>, <fpage>322</fpage>&#x02013;<lpage>333</lpage>. <pub-id pub-id-type="doi">10.1037/amp0000259</pub-id>
<pub-id pub-id-type="pmid">29792451</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0053"><mixed-citation publication-type="book" id="tops12679-cit-0053">
<string-name>
<surname>Grimm</surname>, <given-names>D. A.</given-names>
</string-name>, <string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Gorman</surname>, <given-names>J. C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2018a</year>). <article-title>The complex dynamics of team situation awareness in human&#x02010;autonomy teaming</article-title>. In <article-title>
2018 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)
</article-title> (pp. <fpage>103</fpage>&#x02013;<lpage>109</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>. <pub-id pub-id-type="doi">10.1109/COGSIMA.2018.8423990</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0054"><mixed-citation publication-type="journal" id="tops12679-cit-0054">
<string-name>
<surname>Grimm</surname>, <given-names>D. A.</given-names>
</string-name>, <string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Gorman</surname>, <given-names>J. C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2018b</year>). <article-title>Team situation awareness in human&#x02010;autonomy teaming: A systems level approach</article-title>. <source>Proceedings of the Human Factors and Ergonomics Society Annual Meeting</source>, <volume>62</volume>(<issue>1</issue>), <fpage>149</fpage>&#x02013;<lpage>149</lpage>. <pub-id pub-id-type="doi">10.1177/1541931218621034</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0055"><mixed-citation publication-type="book" id="tops12679-cit-0055">
<string-name>
<surname>Gupta</surname>, <given-names>P.</given-names>
</string-name> (<year>2022</year>). <article-title>
<italic toggle="yes">Transactive systems model of collective intelligence: The emergence and regulation of collective memory, attention, and reasoning</italic> (Unpublished Doctoral dissertation)</article-title>. <publisher-loc>Pittsburgh, PA</publisher-loc>: <publisher-name>Carnegie Mellon University</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0056"><mixed-citation publication-type="journal" id="tops12679-cit-0056">
<string-name>
<surname>Gupta</surname>, <given-names>P.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name> (<year>2018</year>). <article-title>Productivity in an era of multi&#x02010;teaming: The role of information dashboards and shared cognition in team performance</article-title>. <source>Proceedings of the ACM on Human&#x02010;Computer Interaction</source>, <volume>2</volume>, <fpage>1</fpage>&#x02010;<lpage>18</lpage>. <pub-id pub-id-type="doi">10.1145/3274331</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0057"><mixed-citation publication-type="journal" id="tops12679-cit-0057">
<string-name>
<surname>Gupta</surname>, <given-names>P.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name> (<year>2021</year>). <article-title>Articulating the role of artificial intelligence in collective intelligence: A transactive systems framework</article-title>. <source>Proceedings of the Human Factors and Ergonomics Society</source>, <volume>65</volume>(<issue>1</issue>), <fpage>670</fpage>&#x02013;<lpage>674</lpage>. <pub-id pub-id-type="doi">10.1177/1071181321651354c</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0058"><mixed-citation publication-type="journal" id="tops12679-cit-0058">
<string-name>
<surname>Hancock</surname>, <given-names>P. A.</given-names>
</string-name>, <string-name>
<surname>Billings</surname>, <given-names>D. R.</given-names>
</string-name>, <string-name>
<surname>Schaefer</surname>, <given-names>K. E.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>J. Y. C.</given-names>
</string-name>, de <string-name>
<surname>Visser</surname>, <given-names>E. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Parasuraman</surname>, <given-names>R.</given-names>
</string-name> (<year>2011</year>). <article-title>A meta&#x02010;analysis of factors affecting trust in human&#x02010;robot interaction</article-title>. <source>Human Factors</source>, <volume>53</volume>(<issue>5</issue>), <fpage>517</fpage>&#x02013;<lpage>527</lpage>. <pub-id pub-id-type="doi">10.1177/0018720811417254</pub-id>
<pub-id pub-id-type="pmid">22046724</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0059"><mixed-citation publication-type="book" id="tops12679-cit-0059">
<string-name>
<surname>Hertwig</surname>, <given-names>R.</given-names>
</string-name> (<year>2015</year>). <part-title>Decisions from Experience</part-title>. In <source>The Wiley Blackwell handbook of judgment and decision making</source> (pp. <fpage>239</fpage>&#x02013;<lpage>267</lpage>). <publisher-loc>Oxford, England</publisher-loc>: <publisher-name>John Wiley &#x00026; Sons</publisher-name>. <pub-id pub-id-type="doi">10.1002/9781118468333.ch8</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0060"><mixed-citation publication-type="journal" id="tops12679-cit-0060">
<string-name>
<surname>Hintzman</surname>, <given-names>D. L.</given-names>
</string-name> (<year>1984</year>). <article-title>MINERVA 2: A simulation model of human memory</article-title>. <source>Behavior Research Methods, Instruments, &#x00026; Computers</source>, <volume>16</volume>(<issue>2</issue>), <fpage>96</fpage>&#x02013;<lpage>101</lpage>. <pub-id pub-id-type="doi">10.3758/BF03202365</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0061"><mixed-citation publication-type="journal" id="tops12679-cit-0061">
<string-name>
<surname>Johnson</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Bradshaw</surname>, <given-names>J. M.</given-names>
</string-name>, <string-name>
<surname>Feltovich</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Jonker</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>van Riemsdijk</surname>, <given-names>B.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Sierhuis</surname>, <given-names>M.</given-names>
</string-name> (<year>2012</year>). <article-title>Autonomy and interdependence in human&#x02010;agent&#x02010;robot teams</article-title>. <source>IEEE Intelligent Systems</source>, <volume>27</volume>(<issue>2</issue>), <fpage>43</fpage>&#x02013;<lpage>51</lpage>. <pub-id pub-id-type="doi">10.1109/MIS.2012.1</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0062"><mixed-citation publication-type="book" id="tops12679-cit-0062">
<string-name>
<surname>Kahneman</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Slovic</surname>, <given-names>P.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Tversky</surname>, <given-names>A.</given-names>
</string-name> (Eds.). (<year>1982</year>). <source>Judgement under uncertainty: Heuristics and biases</source>. <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>. <pub-id pub-id-type="doi">10.1017/CBO9780511809477</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0063"><mixed-citation publication-type="journal" id="tops12679-cit-0063">
<string-name>
<surname>Kahneman</surname>, <given-names>D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Tversky</surname>, <given-names>A.</given-names>
</string-name> (<year>1979</year>). <article-title>Prospect theory: An analysis of decision under risk</article-title>. <source>Econometrica</source>, <volume>47</volume>(<issue>2</issue>), <fpage>263</fpage>&#x02013;<lpage>291</lpage>. <pub-id pub-id-type="doi">10.2307/1914185</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0064"><mixed-citation publication-type="journal" id="tops12679-cit-0064">
<string-name>
<surname>Kaufmann</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Gupta</surname>, <given-names>P.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Taylor</surname>, <given-names>J.</given-names>
</string-name> (<year>2021</year>). <article-title>An active inference model of collective intelligence</article-title>. <source>Entropy</source>, <volume>23</volume>(<issue>7</issue>), <fpage>830</fpage>. <pub-id pub-id-type="doi">10.3390/e23070830</pub-id>
<pub-id pub-id-type="pmid">34210008</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0065"><mixed-citation publication-type="journal" id="tops12679-cit-0065">
<string-name>
<surname>Kautz</surname>, <given-names>H. A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Allen</surname>, <given-names>J. F.</given-names>
</string-name> (<year>1986</year>). <article-title>Generalized plan recognition</article-title>. <source>AAAI</source>, <volume>86</volume>(<issue>3237</issue>), <fpage>5</fpage>.</mixed-citation></ref><ref id="tops12679-bib-0066"><mixed-citation publication-type="book" id="tops12679-cit-0066">
<string-name>
<surname>Kim</surname>, <given-names>G. J.</given-names>
</string-name> (<year>2015</year>). <source>Human&#x02010;computer interaction: Fundamentals and practice</source>. Boca Raton, FL: <publisher-name>CRC press</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0067"><mixed-citation publication-type="book" id="tops12679-cit-0067">
<string-name>
<surname>Kim</surname>, <given-names>Y. J.</given-names>
</string-name>, <string-name>
<surname>Aggarwal</surname>, <given-names>I.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name> (<year>2016</year>). <source>How communication impacts team performance: Exploring collective intelligence and transactive memory system as mechanisms</source>. <publisher-loc>Fukuoka, Japan</publisher-loc>: <publisher-name>Annual Convention of the International Communication Association</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0068"><mixed-citation publication-type="journal" id="tops12679-cit-0068">
<string-name>
<surname>Knudsen</surname>, <given-names>E. I.</given-names>
</string-name> (<year>2007</year>). <article-title>Fundamental Components of Attention</article-title>. <source>Annual Review of Neuroscience</source>, <volume>30</volume>(<issue>1</issue>), <fpage>57</fpage>&#x02013;<lpage>78</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.neuro.30.051606.094256</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0069"><mixed-citation publication-type="journal" id="tops12679-cit-0069">
<string-name>
<surname>Langley</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Laird</surname>, <given-names>J. E.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Rogers</surname>, <given-names>S.</given-names>
</string-name> (<year>2009</year>). <article-title>Cognitive architectures: Research issues and challenges</article-title>. <source>Cognitive Systems Research</source>, <volume>10</volume>(<issue>2</issue>), <fpage>141</fpage>&#x02013;<lpage>160</lpage>. <pub-id pub-id-type="doi">10.1016/j.cogsys.2006.07.004</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0070"><mixed-citation publication-type="journal" id="tops12679-cit-0070">
<string-name>
<surname>Larson</surname>, <given-names>L.</given-names>
</string-name>, &#x00026; <string-name>
<surname>DeChurch</surname>, <given-names>L. A.</given-names>
</string-name> (<year>2020</year>). <article-title>Leading teams in the digital age: Four perspectives on technology and what they mean for leading teams</article-title>. <source>The Leadership Quarterly</source>, <volume>31</volume>(<issue>1</issue>), <elocation-id>101377</elocation-id>. <pub-id pub-id-type="doi">10.1016/j.leaqua.2019.101377</pub-id>
<pub-id pub-id-type="pmid">32863679</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0071"><mixed-citation publication-type="journal" id="tops12679-cit-0071">
<string-name>
<surname>Lavie</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Hirst</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>de Fockert</surname>, <given-names>J. W.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Viding</surname>, <given-names>E.</given-names>
</string-name> (<year>2004</year>). <article-title>Load theory of selective attention and cognitive control</article-title>. <source>Journal of Experimental Psychology. General</source>, <volume>133</volume>(<issue>3</issue>), <fpage>339</fpage>&#x02013;<lpage>354</lpage>. <pub-id pub-id-type="doi">10.1037/0096-3445.133.3.339</pub-id>
<pub-id pub-id-type="pmid">15355143</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0072"><mixed-citation publication-type="journal" id="tops12679-cit-0072">
<string-name>
<surname>Legg</surname>, <given-names>S.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Hutter</surname>, <given-names>M.</given-names>
</string-name> (<year>2007</year>). <article-title>Universal intelligence: A definition of machine intelligence</article-title>. <source>Minds and Machines</source>, <volume>17</volume>(<issue>4</issue>), <fpage>391</fpage>&#x02013;<lpage>444</lpage>. <pub-id pub-id-type="doi">10.1007/s11023-007-9079-x</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0073"><mixed-citation publication-type="journal" id="tops12679-cit-0073">
<string-name>
<surname>Lejarraga</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Dutt</surname>, <given-names>V.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name> (<year>2012</year>). <article-title>Instance&#x02010;based learning: A general model of repeated binary choice</article-title>. <source>Journal of Behavioral Decision Making</source>, <volume>25</volume>(<issue>2</issue>), <fpage>143</fpage>&#x02013;<lpage>153</lpage>. <pub-id pub-id-type="doi">10.1002/bdm.722</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0074"><mixed-citation publication-type="book" id="tops12679-cit-0074">
<string-name>
<surname>Locke</surname>, <given-names>E. A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Latham</surname>, <given-names>G. P.</given-names>
</string-name> (<year>1990</year>). <source>A theory of goal setting &#x00026; task performance</source>. <publisher-loc>Upper Saddle River, NJ</publisher-loc>: <publisher-name>Prentice&#x02010;Hall</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0075"><mixed-citation publication-type="book" id="tops12679-cit-0075">
<string-name>
<surname>Lovett</surname>, <given-names>M. C.</given-names>
</string-name>, <string-name>
<surname>Reder</surname>, <given-names>L. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Lebiere</surname>, <given-names>C.</given-names>
</string-name> (<year>1999</year>). <part-title>Modeling Working Memory in a Unified Architecture: An ACT&#x02010;R Perspective</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>A.</given-names>
<surname>Miyake</surname>
</string-name>
</person-group> &#x00026; <person-group person-group-type="editor">
<string-name>
<given-names>P.</given-names>
<surname>Shah</surname>
</string-name>
</person-group> (Eds.), <source>Models of working memory</source> (<edition>1st ed.</edition>, pp. <fpage>135</fpage>&#x02013;<lpage>182</lpage>). <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>. <pub-id pub-id-type="doi">10.1017/CBO9781139174909.008</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0076"><mixed-citation publication-type="book" id="tops12679-cit-0076">
<string-name>
<surname>Lyons</surname>, <given-names>J. B.</given-names>
</string-name>, <string-name>
<surname>Mahoney</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Wynne</surname>, <given-names>K. T.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Roebke</surname>, <given-names>M. A.</given-names>
</string-name> (<year>2018</year>). <article-title>
Viewing machines as teammates: A qualitative study
</article-title>. <article-title>AAAI Spring Symposium Series</article-title>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>AAAI Press</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0077"><mixed-citation publication-type="journal" id="tops12679-cit-0077">
<string-name>
<surname>MacLean</surname>, <given-names>E. L.</given-names>
</string-name> (<year>2016</year>). <article-title>Unraveling the evolution of uniquely human cognition</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>113</volume>(<issue>23</issue>), <fpage>6348</fpage>&#x02013;<lpage>6354</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1521270113</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0078"><mixed-citation publication-type="book" id="tops12679-cit-0078">
<string-name>
<surname>Macmillan</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Entin</surname>, <given-names>E. E.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Serfaty</surname>, <given-names>D.</given-names>
</string-name> (<year>2004</year>). <part-title>Communication overhead: The hidden cost of team cognition</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>E.</given-names>
<surname>Salas</surname>
</string-name>
</person-group> &#x00026; <person-group person-group-type="editor">
<string-name>
<given-names>S. M.</given-names>
<surname>Fiore</surname>
</string-name>
</person-group> (Eds.), <source>Team cognition: Understanding the factors that drive process and performance</source> (pp. <fpage>61</fpage>&#x02013;<lpage>82</lpage>). American Psychological Association. <pub-id pub-id-type="doi">10.1037/10690-004</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0079"><mixed-citation publication-type="book" id="tops12679-cit-0079">
<string-name>
<surname>Malone</surname>, <given-names>T. W.</given-names>
</string-name>, <string-name>
<surname>Nickerson</surname>, <given-names>J. V.</given-names>
</string-name>, <string-name>
<surname>Laubacher</surname>, <given-names>R. J.</given-names>
</string-name>, <string-name>
<surname>Fisher</surname>, <given-names>L. H.</given-names>
</string-name>, <string-name>
<surname>De Boer</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Han</surname>, <given-names>Y.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Towne</surname>, <given-names>W. B.</given-names>
</string-name> (<year>2017</year>). <article-title>Putting the pieces back together again: Contest webs for large&#x02010;scale problem solving</article-title>. In <article-title>
Proceedings of ACM CSCW 2017
</article-title> (pp. <fpage>1661</fpage>&#x02013;<lpage>1674</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>ACM</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0080"><mixed-citation publication-type="journal" id="tops12679-cit-0080">
<string-name>
<surname>Matignon</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Laurent</surname>, <given-names>G. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Le Fort&#x02010;Piat</surname>, <given-names>N.</given-names>
</string-name> (<year>2012</year>). <article-title>Independent reinforcement learners in cooperative Markov games: A survey regarding coordination problems</article-title>. <source>The Knowledge Engineering Review</source>, <volume>27</volume>(<issue>1</issue>), <fpage>1</fpage>&#x02013;<lpage>31</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0081"><mixed-citation publication-type="journal" id="tops12679-cit-0081">
<string-name>
<surname>March</surname>, <given-names>J. G.</given-names>
</string-name> (<year>1996</year>). <article-title>Learning to be risk averse</article-title>. <source>Psychological Review</source>, <volume>103</volume>(<issue>2</issue>), <fpage>309</fpage>&#x02013;<lpage>319</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.103.2.309</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0082"><mixed-citation publication-type="journal" id="tops12679-cit-0082">
<string-name>
<surname>Mayo</surname>, <given-names>A. T.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name> (<year>2021</year>). <article-title>Variance in group ability to transform resources into performance, and the role of coordinated attention</article-title>. <source>Academy of Management Discoveries</source>, <volume>7</volume>(<issue>2</issue>), <fpage>225</fpage>&#x02013;<lpage>246</lpage>. <pub-id pub-id-type="doi">10.5465/amd.2019.0231</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0083"><mixed-citation publication-type="journal" id="tops12679-cit-0083">
<string-name>
<surname>McAllister</surname>, <given-names>D. J.</given-names>
</string-name> (<year>1995</year>). <article-title>Affect&#x02010; and cognition&#x02010;based trust as foundations for interpersonal cooperation in organizations</article-title>. <source>Academy of Management Journal</source>, <volume>38</volume>(<issue>1</issue>), <fpage>24</fpage>&#x02013;<lpage>59</lpage>. <pub-id pub-id-type="doi">10.2307/256727</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0084"><mixed-citation publication-type="book" id="tops12679-cit-0084">
<string-name>
<surname>McNeese</surname>, <given-names>M. D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2020</year>). <part-title>Humans interacting with intelligent machines: At the crossroads of symbiotic teamwork</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>R.</given-names>
<surname>Pak</surname>
</string-name>
</person-group>, <person-group person-group-type="editor">
<string-name>
<given-names>E. J.</given-names>
<surname>de Visser</surname>
</string-name>
</person-group>, &#x00026; <person-group person-group-type="editor">
<string-name>
<given-names>E.</given-names>
<surname>Rovira</surname>
</string-name>
</person-group> (Eds.), <source>Living with robots</source> (pp. <fpage>165</fpage>&#x02013;<lpage>197</lpage>). <publisher-loc>Amsterdam, the Netherlands</publisher-loc>: <publisher-name>Elsevier</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0085"><mixed-citation publication-type="journal" id="tops12679-cit-0085">
<string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name>, <string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Myers</surname>, <given-names>C.</given-names>
</string-name> (<year>2018</year>). <article-title>Teaming with a synthetic teammate: Insights into human&#x02010;autonomy teaming</article-title>. <source>Human Factors</source>, <volume>60</volume>(<issue>2</issue>), <fpage>262</fpage>&#x02013;<lpage>273</lpage>. <pub-id pub-id-type="doi">10.1177/0018720817743223</pub-id>
<pub-id pub-id-type="pmid">29185818</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0086"><mixed-citation publication-type="journal" id="tops12679-cit-0086">
<string-name>
<surname>Miller</surname>, <given-names>P. H.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Bigi</surname>, <given-names>L.</given-names>
</string-name> (<year>1979</year>). <article-title>The development of children's understanding of attention</article-title>. <source>Merrill&#x02010;Palmer Quarterly</source>, <volume>25</volume>(<issue>4</issue>), <fpage>235</fpage>&#x02013;<lpage>250</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0087"><mixed-citation publication-type="journal" id="tops12679-cit-0087">
<string-name>
<surname>Miller</surname>, <given-names>T.</given-names>
</string-name> (<year>2019</year>). <article-title>Explanation in artificial intelligence: Insights from the social sciences</article-title>. <source>Artificial Intelligence</source>, <volume>267</volume>, <fpage>1</fpage>&#x02013;<lpage>38</lpage>. <pub-id pub-id-type="doi">10.1016/j.artint.2018.07.007</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0088"><mixed-citation publication-type="journal" id="tops12679-cit-0088">
<string-name>
<surname>Myers</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Ball</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Cooke</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Freiman</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Caisse</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Rodgers</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Demir</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name> (<year>2019</year>). <article-title>Autonomous intelligent agents for team training</article-title>. <source>IEEE Intelligent Systems</source>, <volume>34</volume>(<issue>2</issue>), <fpage>3</fpage>&#x02013;<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1109/MIS.2018.2886670</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0089"><mixed-citation publication-type="book" id="tops12679-cit-0089">
<string-name>
<surname>Newell</surname>, <given-names>A.</given-names>
</string-name> (<year>1973</year>). <part-title>You can't play 20 questions with nature and win: Projective comments on the papers of this symposium</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>W. G.</given-names>
<surname>Chase</surname>
</string-name>
</person-group> (Ed.), <source>Visual Information Processing</source> (pp. <fpage>283</fpage>&#x02013;<lpage>308</lpage>). <publisher-loc>Amsterdam, the Netherlands</publisher-loc>: <publisher-name>Elsevier</publisher-name>. <pub-id pub-id-type="doi">10.1016/B978-0-12-170150-5.50012-3</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0090"><mixed-citation publication-type="book" id="tops12679-cit-0090">
<string-name>
<surname>Newell</surname>, <given-names>A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Simon</surname>, <given-names>H. A.</given-names>
</string-name> (<year>1972</year>). <source>Human problem solving</source>. <publisher-loc>Upper Saddle River, NJ</publisher-loc>: <publisher-name>Prentice&#x02010;Hall</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0091"><mixed-citation publication-type="book" id="tops12679-cit-0091">
<string-name>
<surname>Nguyen</surname>, <given-names>T. N.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name> (<year>2020</year>). <source>Cognitive machine theory of mind</source>. <publisher-loc>Pittsburgh, PA</publisher-loc>: <publisher-name>Carnegie Mellon University</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0092"><mixed-citation publication-type="journal" id="tops12679-cit-0092">
<string-name>
<surname>Nguyen</surname>, <given-names>T. N.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name> (<year>2022</year>). <article-title>Theory of mind from observation in cognitive models and humans</article-title>. <source>Topics in Cognitive Science</source>, <volume>14</volume>(<issue>4</issue>), <fpage>665</fpage>&#x02013;<lpage>686</lpage>. <pub-id pub-id-type="doi">10.1111/tops.12553</pub-id>
<pub-id pub-id-type="pmid">34165919</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0093"><mixed-citation publication-type="journal" id="tops12679-cit-0093">
<string-name>
<surname>Nguyen</surname>, <given-names>T. N.</given-names>
</string-name>, <string-name>
<surname>Phan</surname>, <given-names>D. N.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name> (<year>2023</year>). <article-title>SpeedyIBL: A comprehensive, precise, and fast implementation of instance&#x02010;based learning theory</article-title>. <source>Behavior Research Methods</source>, <volume>55</volume>, <fpage>1734</fpage>&#x02013;<lpage>1757</lpage>.<pub-id pub-id-type="pmid">35768745</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0094"><mixed-citation publication-type="book" id="tops12679-cit-0094">
<string-name>
<surname>Oguntola</surname>, <given-names>I.</given-names>
</string-name>, <string-name>
<surname>Hughes</surname>, <given-names>D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Sycara</surname>, <given-names>K.</given-names>
</string-name> (<year>2021</year>). <article-title>Deep interpretable models of theory of mind</article-title>. In <article-title>
2021 30th IEEE International Conference on Robot &#x00026; Human Interactive Communication (RO&#x02010;MAN)
</article-title> (pp. <fpage>657</fpage>&#x02013;<lpage>664</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>. <pub-id pub-id-type="doi">10.1109/RO-MAN50785.2021.9515505</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0095"><mixed-citation publication-type="journal" id="tops12679-cit-0095">
<string-name>
<surname>O'Neill</surname>, <given-names>T. A.</given-names>
</string-name>, <string-name>
<surname>Flathmann</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>McNeese</surname>, <given-names>N. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Salas</surname>, <given-names>E.</given-names>
</string-name> (<year>2023</year>). <article-title>Human&#x02010;autonomy teaming: Need for a guiding team&#x02010;based framework?</article-title>
<source>Computers in Human Behavior</source>, <volume>146</volume>, <elocation-id>107762</elocation-id>. <pub-id pub-id-type="doi">10.1016/j.chb.2023.107762</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0096"><mixed-citation publication-type="journal" id="tops12679-cit-0096">
<string-name>
<surname>O'Neill</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>McNeese</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Barron</surname>, <given-names>A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Schelble</surname>, <given-names>B.</given-names>
</string-name> (<year>2020</year>). <article-title>Human&#x02013;autonomy teaming: A review and analysis of the empirical literature</article-title>. <source>Human Factors</source>, <volume>64</volume>(<issue>5</issue>). <elocation-id>0018720820960865</elocation-id>. <pub-id pub-id-type="doi">10.1177/0018720820960865</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0097"><mixed-citation publication-type="book" id="tops12679-cit-0097">
<string-name>
<surname>O'Reilly</surname>, <given-names>R. C.</given-names>
</string-name>, <string-name>
<surname>Braver</surname>, <given-names>T. S.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cohen</surname>, <given-names>J. D.</given-names>
</string-name> (<year>1999</year>). <part-title>A biologically based computational model of working memory</part-title>. In <source>Models of working memory: Mechanisms of active maintenance and executive control</source> (pp. <fpage>375</fpage>&#x02013;<lpage>411</lpage>). <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>. <pub-id pub-id-type="doi">10.1017/CBO9781139174909.014</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0098"><mixed-citation publication-type="journal" id="tops12679-cit-0098">
<string-name>
<surname>Okamura</surname>, <given-names>K.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Yamada</surname>, <given-names>S.</given-names>
</string-name> (<year>2020</year>). <article-title>Adaptive trust calibration for human&#x02010;AI collaboration</article-title>. <source>PLoS ONE</source>, <volume>15</volume>(<issue>2</issue>), <elocation-id>e0229132</elocation-id>. <pub-id pub-id-type="doi">10.1371/journal.pone.0229132</pub-id>
<pub-id pub-id-type="pmid">32084201</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0099"><mixed-citation publication-type="book" id="tops12679-cit-0099">
<string-name>
<surname>Phillips</surname>, <given-names>P. J.</given-names>
</string-name>, <string-name>
<surname>Hahn</surname>, <given-names>C. A.</given-names>
</string-name>, <string-name>
<surname>Fontana</surname>, <given-names>P. C.</given-names>
</string-name>, <string-name>
<surname>Broniatowski</surname>, <given-names>D. A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Przybocki</surname>, <given-names>M. A.</given-names>
</string-name> (<year>2020</year>). <source>Four principles of explainable artificial intelligence</source>. <publisher-loc>Gaithersburg, MD</publisher-loc>: NIST.</mixed-citation></ref><ref id="tops12679-bib-0100"><mixed-citation publication-type="journal" id="tops12679-cit-0100">
<string-name>
<surname>Premack</surname>, <given-names>D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woodruff</surname>, <given-names>G.</given-names>
</string-name> (<year>1978</year>). <article-title>Does the chimpanzee have a theory of mind?</article-title>
<source>Behavioral and Brain Sciences</source>, <volume>1</volume>(<issue>4</issue>), <fpage>515</fpage>&#x02013;<lpage>526</lpage>. <pub-id pub-id-type="doi">10.1017/S0140525x00076512</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0101"><mixed-citation publication-type="book" id="tops12679-cit-0101">
<string-name>
<surname>Rabinowitz</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Perbet</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Song</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Eslami</surname>, <given-names>S. M. A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Botvinick</surname>, <given-names>M.</given-names>
</string-name> (<year>2018</year>). <article-title>Machine theory of mind</article-title>. In <article-title>
Proceedings of the 35th international conference on machine learning
</article-title> (pp. <fpage>4218</fpage>&#x02013;<lpage>4227</lpage>). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>. <ext-link xlink:href="https://proceedings.mlr.press/v80/rabinowitz18a.html" ext-link-type="uri">https://proceedings.mlr.press/v80/rabinowitz18a.html</ext-link>
</mixed-citation></ref><ref id="tops12679-bib-0102"><mixed-citation publication-type="journal" id="tops12679-cit-0102">
<string-name>
<surname>Ren</surname>, <given-names>Y.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Argote</surname>, <given-names>L.</given-names>
</string-name> (<year>2011</year>). <article-title>Transactive memory systems 1985&#x02013;2010: An integrative framework of key dimensions, antecedents, and consequences</article-title>. <source>The Academy of Management Annals</source>, <volume>5</volume>(<issue>1</issue>), <fpage>189</fpage>&#x02013;<lpage>229</lpage>. <pub-id pub-id-type="doi">10.1080/19416520.2011.590300</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0103"><mixed-citation publication-type="book" id="tops12679-cit-0103">
<string-name>
<surname>Retelny</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Robaszkiewicz</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>To</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Lasecki</surname>, <given-names>W. S.</given-names>
</string-name>, <string-name>
<surname>Patel</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Rahmati</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Doshi</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Valentine</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Bernstein</surname>, <given-names>M. S.</given-names>
</string-name> (<year>2014</year>). <article-title>Expert crowdsourcing with flash teams</article-title>. In <article-title>
Proceedings of the 27th annual ACM symposium on user interface software and technology
</article-title> (pp. <fpage>75</fpage>&#x02013;<lpage>85</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>ACM</publisher-name>. <pub-id pub-id-type="doi">10.1145/2642918.2647409</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0104"><mixed-citation publication-type="journal" id="tops12679-cit-0104">
<string-name>
<surname>Riedl</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Kim</surname>, <given-names>Y. J.</given-names>
</string-name>, <string-name>
<surname>Gupta</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Malone</surname>, <given-names>T. W.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name> (<year>2021</year>). <article-title>Quantifying collective intelligence in human groups</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>118</volume>(<issue>21</issue>), <elocation-id>e2005737118</elocation-id>. <pub-id pub-id-type="doi">10.1073/pnas.2005737118</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0105"><mixed-citation publication-type="journal" id="tops12679-cit-0105">
<string-name>
<surname>Riedl</surname>, <given-names>C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name> (<year>2017</year>). <article-title>Teams vs. crowds: A field test of the relative contribution of incentives, member ability, and emergent collaboration to crowd&#x02010;based problem solving performance</article-title>. <source>Academy of Management Discoveries</source>, <volume>3</volume>(<issue>4</issue>), <fpage>382</fpage>&#x02013;<lpage>403</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0106"><mixed-citation publication-type="book" id="tops12679-cit-0106">
<string-name>
<surname>Rosenberg</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Willcox</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Palosuo</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Mani</surname>, <given-names>G.</given-names>
</string-name> (<year>2021</year>). <article-title>Forecasting of volatile assets using artificial swarm intelligence</article-title>. In <article-title>
2021 4th International Conference on Artificial Intelligence for Industries (AI4I)
</article-title> (pp. <fpage>30</fpage>&#x02013;<lpage>33</lpage>). <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0107"><mixed-citation publication-type="journal" id="tops12679-cit-0107">
<string-name>
<surname>Rusch</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Steixner&#x02010;Kumar</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Doshi</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Spezio</surname>, <given-names>M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Gl&#x000e4;scher</surname>, <given-names>J.</given-names>
</string-name> (<year>2020</year>). <article-title>Theory of mind and decision science: Towards a typology of tasks and computational models</article-title>. <source>Neuropsychologia</source>, <volume>146</volume>, <elocation-id>107488</elocation-id>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2020.107488</pub-id>
<pub-id pub-id-type="pmid">32407906</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0108"><mixed-citation publication-type="journal" id="tops12679-cit-0108">
<string-name>
<surname>Salas</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Bowers</surname>, <given-names>C. A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cannon&#x02010;Bowers</surname>, <given-names>J. A.</given-names>
</string-name> (<year>1995</year>). <article-title>Military Team Research: 10 Years of Progress</article-title>. <source>Military Psychology</source>, <volume>7</volume>(<issue>2</issue>), <fpage>55</fpage>&#x02013;<lpage>75</lpage>. <pub-id pub-id-type="doi">10.1207/s15327876mp0702_2</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0109"><mixed-citation publication-type="journal" id="tops12679-cit-0109">
<string-name>
<surname>Salas</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Cooke</surname>, <given-names>N. J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Rosen</surname>, <given-names>M. A.</given-names>
</string-name> (<year>2008</year>). <article-title>On teams, teamwork, and team performance: Discoveries and developments</article-title>. <source>Human Factors</source>, <volume>50</volume>(<issue>3</issue>), <fpage>540</fpage>&#x02013;<lpage>547</lpage>. <pub-id pub-id-type="doi">10.1518/001872008x288457</pub-id>
<pub-id pub-id-type="pmid">18689065</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0110"><mixed-citation publication-type="book" id="tops12679-cit-0110">
<string-name>
<surname>Salas</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Dickinson</surname>, <given-names>T. L.</given-names>
</string-name>, <string-name>
<surname>Converse</surname>, <given-names>S. A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Tannenbaum</surname>, <given-names>S. I.</given-names>
</string-name> (<year>1992</year>). <part-title>Toward an understanding of team performance and training</part-title>. In <source>Teams: Their training and performance</source> (pp. <fpage>3</fpage>&#x02013;<lpage>29</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Ablex Publishing</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0111"><mixed-citation publication-type="journal" id="tops12679-cit-0111">
<string-name>
<surname>Salmon</surname>, <given-names>P. M.</given-names>
</string-name>, <string-name>
<surname>Stanton</surname>, <given-names>N. A.</given-names>
</string-name>, <string-name>
<surname>Walker</surname>, <given-names>G. H.</given-names>
</string-name>, <string-name>
<surname>Jenkins</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Ladva</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Rafferty</surname>, <given-names>L.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Young</surname>, <given-names>M.</given-names>
</string-name> (<year>2009</year>). <article-title>Measuring situation awareness in complex systems: Comparison of measures study</article-title>. <source>International Journal of Industrial Ergonomics</source>, <volume>39</volume>(<issue>3</issue>), <fpage>490</fpage>&#x02013;<lpage>500</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0112"><mixed-citation publication-type="journal" id="tops12679-cit-0112">
<string-name>
<surname>Saner</surname>, <given-names>L. D.</given-names>
</string-name>, <string-name>
<surname>Bolstad</surname>, <given-names>C. A.</given-names>
</string-name>, <string-name>
<surname>Gonzalez</surname>, <given-names>C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cuevas</surname>, <given-names>H. M.</given-names>
</string-name> (<year>2009</year>). <article-title>Measuring and predicting shared situation awareness in teams</article-title>. <source>Journal of Cognitive Engineering and Decision Making</source>, <volume>3</volume>(<issue>3</issue>), <fpage>280</fpage>&#x02013;<lpage>308</lpage>. <pub-id pub-id-type="doi">10.1518/155534309x474497</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0113"><mixed-citation publication-type="book" id="tops12679-cit-0113">
<string-name>
<surname>Schelble</surname>, <given-names>B. G.</given-names>
</string-name>, <string-name>
<surname>Flathmann</surname>, <given-names>C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>McNeese</surname>, <given-names>N.</given-names>
</string-name> (<year>2020</year>). <article-title>Towards meaningfully integrating human&#x02010;autonomy teaming in applied settings</article-title>. In <article-title>
Proceedings of the 8th international conference on human&#x02010;agent interaction
</article-title> (pp. <fpage>149</fpage>&#x02013;<lpage>156</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>ACM</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0114"><mixed-citation publication-type="journal" id="tops12679-cit-0114">
<string-name>
<surname>Simon</surname>, <given-names>H. A.</given-names>
</string-name> (<year>1973</year>). <article-title>Applying information technology to organization design</article-title>. <source>Public Administration Review</source>, <volume>33</volume>(<issue>3</issue>), <fpage>268</fpage>&#x02013;<lpage>278</lpage>. <pub-id pub-id-type="doi">10.2307/974804</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0115"><mixed-citation publication-type="book" id="tops12679-cit-0115">
<string-name>
<surname>Simon</surname>, <given-names>H. A.</given-names>
</string-name> (<year>1976</year>). <part-title>The information&#x02010;storage system called &#x0201c;human memory</part-title>.&#x0201d; In <person-group person-group-type="editor">
<string-name>
<given-names>E. L.</given-names>
<surname>Bennet</surname>
</string-name>
</person-group> &#x00026; <person-group person-group-type="editor">
<string-name>
<given-names>M. R.</given-names>
<surname>Rosenzweig</surname>
</string-name>
</person-group> (Eds.), <source>Neural mechanisms of learning and memory</source> (p. 18). <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0116"><mixed-citation publication-type="book" id="tops12679-cit-0116">
<string-name>
<surname>Simon</surname>, <given-names>H. A.</given-names>
</string-name> (<year>1978</year>). <part-title>Information&#x02010;processing theory of human problem solving</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>W.</given-names>
<surname>Estes</surname>
</string-name>
</person-group> (Ed.), <source>Handbook of learning &#x00026; cognitive processes: V. Human information</source> (pp. <fpage>271</fpage>&#x02013;<lpage>295</lpage>). <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0117"><mixed-citation publication-type="book" id="tops12679-cit-0117">
<string-name>
<surname>Simon</surname>, <given-names>H. A.</given-names>
</string-name> (<year>1997</year>). <source>Administrative Behavior: A study of decision&#x02010;making processes in administrative organizations</source> (<edition>4th ed</edition>). London, England: <publisher-name>Free Press</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0118"><mixed-citation publication-type="journal" id="tops12679-cit-0118">
<string-name>
<surname>Sottilare</surname>, <given-names>R. A.</given-names>
</string-name>, <string-name>
<surname>Shawn Burke</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Salas</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Sinatra</surname>, <given-names>A. M.</given-names>
</string-name>, <string-name>
<surname>Johnston</surname>, <given-names>J. H.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Gilbert</surname>, <given-names>S. B.</given-names>
</string-name> (<year>2018</year>). <article-title>Designing adaptive instruction for teams: A meta&#x02010;analysis</article-title>. <source>International Journal of Artificial Intelligence in Education</source>, <volume>28</volume>(<issue>2</issue>), <fpage>225</fpage>&#x02013;<lpage>264</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0119"><mixed-citation publication-type="journal" id="tops12679-cit-0119">
<string-name>
<surname>Sparrow</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Liu</surname>, <given-names>J.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Wegner</surname>, <given-names>D. M.</given-names>
</string-name> (<year>2011</year>). <article-title>Google effects on memory: Cognitive consequences of having information at our fingertips</article-title>. <source>Science</source>, <volume>333</volume>(<issue>6043</issue>), <fpage>776</fpage>&#x02013;<lpage>778</lpage>.<pub-id pub-id-type="pmid">21764755</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0120"><mixed-citation publication-type="book" id="tops12679-cit-0120">
<string-name>
<surname>Stanton</surname>, <given-names>B.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Jensen</surname>, <given-names>T.</given-names>
</string-name> (<year>2021</year>). <article-title>Trust and artificial intelligence (Preprint</article-title>). <publisher-loc>Gaithersburg, MD</publisher-loc>: <publisher-name>NIST</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0121"><mixed-citation publication-type="book" id="tops12679-cit-0121">
<string-name>
<surname>Sutton</surname>, <given-names>R. S.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Barto</surname>, <given-names>A. G.</given-names>
</string-name> (<year>1998</year>). <source>Reinforcement learning: An introduction</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0122"><mixed-citation publication-type="journal" id="tops12679-cit-0122">
<string-name>
<surname>Tsifetakis</surname>, <given-names>E.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Kontogiannis</surname>, <given-names>T.</given-names>
</string-name> (<year>2019</year>). <article-title>Evaluating non&#x02010;technical skills and mission essential competencies of pilots in military aviation environments</article-title>. <source>Ergonomics</source>, <volume>62</volume>(<issue>2</issue>), <fpage>204</fpage>&#x02013;<lpage>218</lpage>.<pub-id pub-id-type="pmid">28534423</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0123"><mixed-citation publication-type="book" id="tops12679-cit-0123">
<string-name>
<surname>Valentine</surname>, <given-names>M. A.</given-names>
</string-name>, <string-name>
<surname>Retelny</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>To</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Rahmati</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Doshi</surname>, <given-names>T.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Bernstein</surname>, <given-names>M. S.</given-names>
</string-name> (<year>2017</year>). <article-title>Flash organizations: Crowdsourcing complex work by structuring crowds as organizations</article-title>. In <article-title>
Proceedings of the 2017 CHI conference on human factors in computing systems
</article-title> (pp. <fpage>3523</fpage>&#x02013;<lpage>3537</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>ACM</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0124"><mixed-citation publication-type="journal" id="tops12679-cit-0124">
<string-name>
<surname>Van Kleef</surname>, <given-names>G. A.</given-names>
</string-name>, <string-name>
<surname>Homan</surname>, <given-names>A. C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Cheshin</surname>, <given-names>A.</given-names>
</string-name> (<year>2012</year>). <article-title>Emotional influence at work: Take it EASI</article-title>. <source>Organizational Psychology Review</source>, <volume>2</volume>(<issue>4</issue>), <fpage>311</fpage>&#x02013;<lpage>339</lpage>. <pub-id pub-id-type="doi">10.1177/2041386612454911</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0125"><mixed-citation publication-type="journal" id="tops12679-cit-0125">
<string-name>
<surname>Van Knippenberg</surname>, <given-names>D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Schippers</surname>, <given-names>M.</given-names>
</string-name> (<year>2007</year>). <article-title>Work group diversity</article-title>. <source>Annual Review of Psychology</source>, <volume>58</volume>, <fpage>515</fpage>&#x02013;<lpage>541</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0126"><mixed-citation publication-type="book" id="tops12679-cit-0126">
<string-name>
<surname>Wegner</surname>, <given-names>D. M.</given-names>
</string-name> (<year>1987</year>). <part-title>Transactive memory: A contemporary analysis of the group mind</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>B.</given-names>
<surname>Mullen</surname>
</string-name>
</person-group> &#x00026; <person-group person-group-type="editor">
<string-name>
<given-names>G. R.</given-names>
<surname>Goethals</surname>
</string-name>
</person-group> (Eds.), <source>Theories of group behavior</source> (pp. <fpage>185</fpage>&#x02013;<lpage>208</lpage>). <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer</publisher-name>. <pub-id pub-id-type="doi">10.1007/978-1-4612-4634-3_9</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0127"><mixed-citation publication-type="journal" id="tops12679-cit-0127">
<string-name>
<surname>Wegner</surname>, <given-names>D. M.</given-names>
</string-name> (<year>1995</year>). <article-title>A computer network model of human transactive memory</article-title>. <source>Social Cognition; New York</source>, <volume>13</volume>(<issue>3</issue>), <fpage>319</fpage>&#x02013;<lpage>339</lpage>. <ext-link xlink:href="http://doi.org.proxy.library.cmu.edu/10.1521/soco.1995.13.3.319" ext-link-type="uri">http://doi.org.proxy.library.cmu.edu/10.1521/soco.1995.13.3.319</ext-link>
</mixed-citation></ref><ref id="tops12679-bib-0128"><mixed-citation publication-type="journal" id="tops12679-cit-0128">
<string-name>
<surname>Wickens</surname>, <given-names>C. D.</given-names>
</string-name> (<year>2008</year>). <article-title>Situation awareness: Review of Mica Endsley's 1995 articles on situation awareness theory and measurement</article-title>. <source>Human Factors</source>, <volume>50</volume>(<issue>3</issue>), <fpage>397</fpage>&#x02013;<lpage>403</lpage>. <pub-id pub-id-type="doi">10.1518/001872008x288420</pub-id>
<pub-id pub-id-type="pmid">18689045</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0129"><mixed-citation publication-type="journal" id="tops12679-cit-0129">
<string-name>
<surname>Wickens</surname>, <given-names>C. D.</given-names>
</string-name> (<year>2015</year>). <article-title>Situation awareness: Its applications value and its fuzzy dichotomies</article-title>. <source>Journal of Cognitive Engineering and Decision Making</source>, <volume>9</volume>(<issue>1</issue>), <fpage>90</fpage>&#x02013;<lpage>94</lpage>. <pub-id pub-id-type="doi">10.1177/1555343414564571</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0130"><mixed-citation publication-type="journal" id="tops12679-cit-0130">
<string-name>
<surname>Wiltshire</surname>, <given-names>T. J.</given-names>
</string-name>, <string-name>
<surname>Warta</surname>, <given-names>S. F.</given-names>
</string-name>, <string-name>
<surname>Barber</surname>, <given-names>D.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Fiore</surname>, <given-names>S. M.</given-names>
</string-name> (<year>2017</year>). <article-title>Enabling robotic social intelligence by engineering human social&#x02010;cognitive mechanisms</article-title>. <source>Cognitive Systems Research</source>, <volume>43</volume>, <fpage>190</fpage>&#x02013;<lpage>207</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0131"><mixed-citation publication-type="journal" id="tops12679-cit-0131">
<string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name>, <string-name>
<surname>Chabris</surname>, <given-names>C. F.</given-names>
</string-name>, <string-name>
<surname>Pentland</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Hashmi</surname>, <given-names>N.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Malone</surname>, <given-names>T. W.</given-names>
</string-name> (<year>2010</year>). <article-title>Evidence for a collective intelligence factor in the performance of human groups</article-title>. <source>Science</source>, <volume>330</volume>(<issue>6004</issue>), <fpage>686</fpage>&#x02013;<lpage>688</lpage>.<pub-id pub-id-type="pmid">20929725</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0132"><mixed-citation publication-type="journal" id="tops12679-cit-0132">
<string-name>
<surname>Woolley</surname>, <given-names>A. W.</given-names>
</string-name>, <string-name>
<surname>Gerbasi</surname>, <given-names>M. E.</given-names>
</string-name>, <string-name>
<surname>Chabris</surname>, <given-names>C. F.</given-names>
</string-name>, <string-name>
<surname>Kosslyn</surname>, <given-names>S. M.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Hackman</surname>, <given-names>J. R.</given-names>
</string-name> (<year>2008</year>). <article-title>Bringing in the experts: How team composition and work strategy jointly shape analytic effectiveness</article-title>. <source>Small Group Research</source>, <volume>39</volume>(<issue>3</issue>), <fpage>352</fpage>&#x02013;<lpage>371</lpage>.</mixed-citation></ref><ref id="tops12679-bib-0133"><mixed-citation publication-type="journal" id="tops12679-cit-0133">
<string-name>
<surname>Wright</surname>, <given-names>J. L.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>J. Y.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Barnes</surname>, <given-names>M. J.</given-names>
</string-name> (<year>2018</year>). <article-title>Human&#x02013;automation interaction for multiple robot control: The effect of varying automation assistance and individual differences on operator performance</article-title>. <source>Ergonomics</source>, <volume>61</volume>(<issue>8</issue>), <fpage>1033</fpage>&#x02013;<lpage>1045</lpage>.<pub-id pub-id-type="pmid">29451105</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0134"><mixed-citation publication-type="book" id="tops12679-cit-0134">
<string-name>
<surname>Wright</surname>, <given-names>J. L.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>J. Y.</given-names>
</string-name>, <string-name>
<surname>Quinn</surname>, <given-names>S. A.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Barnes</surname>, <given-names>M. J.</given-names>
</string-name> (<year>2013</year>). <source>The effects of level of autonomy on human&#x02010;agent teaming for multi&#x02010;robot control and local security maintenance</source>. <publisher-name>Aberdeen Proving Ground, MD: Army Research Lab</publisher-name>.</mixed-citation></ref><ref id="tops12679-bib-0135"><mixed-citation publication-type="journal" id="tops12679-cit-0135">
<string-name>
<surname>Wright</surname>, <given-names>M. C.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Kaber</surname>, <given-names>D. B.</given-names>
</string-name> (<year>2005</year>). <article-title>Effects of automation of information&#x02010;processing functions on teamwork</article-title>. <source>Human Factors</source>, <volume>47</volume>(<issue>1</issue>), <fpage>50</fpage>&#x02013;<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1518/0018720053653776</pub-id>
<pub-id pub-id-type="pmid">15960086</pub-id>
</mixed-citation></ref><ref id="tops12679-bib-0136"><mixed-citation publication-type="journal" id="tops12679-cit-0136">
<string-name>
<surname>Wynne</surname>, <given-names>K. T.</given-names>
</string-name>, &#x00026; <string-name>
<surname>Lyons</surname>, <given-names>J. B.</given-names>
</string-name> (<year>2018</year>). <article-title>An integrative model of autonomous agent teammate&#x02010;likeness</article-title>. <source>Theoretical Issues in Ergonomics Science</source>, <volume>19</volume>(<issue>3</issue>), <fpage>353</fpage>&#x02013;<lpage>374</lpage>.</mixed-citation></ref></ref-list></back></article>