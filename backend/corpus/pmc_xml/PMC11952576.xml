<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title-group><journal-title>bioRxiv</journal-title></journal-title-group><issn pub-type="epub">2692-8205</issn><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40161819</article-id><article-id pub-id-type="pmc">PMC11952576</article-id>
<article-id pub-id-type="doi">10.1101/2025.03.12.642917</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>High-Density Multi-Distance fNIRS Enhances Detection of Brain Activity during a Word-Color Stroop Task</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-4549-8717</contrib-id><name><surname>Anderson</surname><given-names>Jessica E.</given-names></name><xref rid="A1" ref-type="aff">1</xref><xref rid="CR1" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0009-0008-0337-686X</contrib-id><name><surname>Carlton</surname><given-names>Laura</given-names></name><xref rid="A1" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Kura</surname><given-names>Sreekanth</given-names></name><xref rid="A1" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0009-0006-0920-3869</contrib-id><name><surname>O&#x02019;Brien</surname><given-names>Walker J.</given-names></name><xref rid="A1" ref-type="aff">1</xref><xref rid="A2" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-5112-4324</contrib-id><name><surname>Rogers</surname><given-names>De&#x02019;Ja</given-names></name><xref rid="A1" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Rahimi</surname><given-names>Parisa</given-names></name><xref rid="A3" ref-type="aff">3</xref></contrib><contrib contrib-type="author"><name><surname>Farzam</surname><given-names>Parya Y.</given-names></name><xref rid="A1" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Zaman</surname><given-names>Muhammad H.</given-names></name><xref rid="A4" ref-type="aff">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6709-7711</contrib-id><name><surname>Boas</surname><given-names>David A.</given-names></name><xref rid="A1" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-4291-2847</contrib-id><name><surname>Y&#x000fc;cel</surname><given-names>Meryem A.</given-names></name><xref rid="A1" ref-type="aff">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>Neurophotonics Center, Biomedical Engineering, Boston University, Boston, Massachusetts, 02215</aff><aff id="A2"><label>2</label>Department of Electrical and Computer Engineering, Boston University, USA</aff><aff id="A3"><label>3</label>Questrom School of Business, Boston University, Boston, MA 02215, USA</aff><aff id="A4"><label>4</label>Department of Biomedical Engineering, Boston University, Boston, Massachusetts, 02215</aff><author-notes><fn fn-type="con" id="FN1"><label>8</label><p id="P1">AUTHOR CONTRIBUTIONS</p><p id="P2">JEA, DAB, and MAY conceptualized the research question and analysis. JEA designed the experimental approach and protocol and executed the experiments. JEA, SK, and WJO prepared the materials for data collection. JEA, PR, and PF managed the recruitment of participants. JEA, MAY, DAB, and LC analyzed and discussed the data. JEA and LC drafted the original manuscript. All authors reviewed, provided feedback, and edited the manuscript.</p></fn><corresp id="CR1"><label>*</label>address all correspondence to Jessica E. Anderson, <email>andersoj@bu.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>14</day><month>3</month><year>2025</year></pub-date><elocation-id>2025.03.12.642917</elocation-id><permissions><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</ext-link>, which allows reusers to distribute, remix, adapt, and build upon the material in any medium or format, so long as attribution is given to the creator. The license allows for commercial use.</license-p></license></permissions><self-uri content-type="pdf">nihpp-2025.03.12.642917.pdf</self-uri><abstract id="ABS1"><sec id="S1"><title>Significance:</title><p id="P3">Functional Near-Infrared Spectroscopy (fNIRS) enables neuroimaging in scenarios where other modalities are less suitable, such as during motion tasks or in low-resource environments. Sparse fNIRS arrays with 30mm channel spacing are widely used but have limited spatial resolution. High-density (HD) arrays with overlapping, multi-distance channels improve sensitivity and localization but increase costs and setup times. A statistical comparison of HD and sparse arrays is needed for evaluating the benefits and trade-offs of HD arrays.</p></sec><sec id="S2"><title>Aim:</title><p id="P4">This study provides a statistical comparison of HD and sparse fNIRS performance to inform array selection in future research.</p></sec><sec id="S3"><title>Approach:</title><p id="P5">We measured prefrontal cortex (PFC) activation during congruent and incongruent Word-Color Stroop (WCS) tasks using both Sparse and HD arrays for 17 healthy adult participants, comparing dorsolateral PFC channel and image results at the group level.</p></sec><sec id="S4"><title>Results:</title><p id="P6">While both arrays detected activation in channel space during incongruent WCS, channel and image space results demonstrated superior localization and sensitivity with the HD array for all WCS.</p></sec><sec id="S5"><title>Conclusions:</title><p id="P7">Sparse channel data may suitably detect activation from cognitively demanding tasks, like incongruent WCS. However, the HD array outperformed Sparse in detecting and localizing brain activity in image space, particularly during lower cognitive load tasks, making them more suitable for neuroimaging applications.</p></sec></abstract><kwd-group><kwd>fNIRS</kwd><kwd>Diffuse Optical Tomography</kwd><kwd>High-Density fNIRS</kwd><kwd>Word-Color Stroop</kwd><kwd>Pre-Frontal Cortex</kwd></kwd-group></article-meta></front><body><sec id="S6"><label>1</label><title>INTRODUCTION</title><p id="P8">The use of fNIRS has grown exponentially since its inception<sup><xref rid="R1" ref-type="bibr">1</xref>,<xref rid="R2" ref-type="bibr">2</xref></sup> expanding our understanding of brain activity in a variety of contexts, such as in psychiatry<sup><xref rid="R3" ref-type="bibr">3</xref>&#x02013;<xref rid="R7" ref-type="bibr">7</xref></sup>, naturalistic environments<sup><xref rid="R8" ref-type="bibr">8</xref></sup>, developmental research<sup><xref rid="R9" ref-type="bibr">9</xref>&#x02013;<xref rid="R11" ref-type="bibr">11</xref></sup>, low-resource contexts and global health<sup><xref rid="R11" ref-type="bibr">11</xref>&#x02013;<xref rid="R17" ref-type="bibr">17</xref></sup>, and for hyperscanning studies<sup><xref rid="R18" ref-type="bibr">18</xref>&#x02013;<xref rid="R21" ref-type="bibr">21</xref></sup>. Benefits of functional Near Infrared Spectroscopy (fNIRS) over other neuroimaging modalities are well-defined for its comparative motion artifact resistance, temporal resolution, portability and wearability, operational requirements and ease of use, comfort, and general ecological validity<sup><xref rid="R22" ref-type="bibr">22</xref></sup>.</p><p id="P9">The traditional optode layout employed by most commercially-available fNIRS systems and studies arranges sources and detectors in a non-overlapping, 30-mm, grid pattern. This low-density or sparse arrangement suffers limited spatial resolution, sensitivity, and localization. For example, the ability to differentiate regions of activation is hindered because the channel density and spatial arrangement are directly related to the anatomical specificity<sup><xref rid="R23" ref-type="bibr">23</xref></sup>. The downstream impacts of this vary. One possible scenario is that the channels miss a region entirely; another is that channels may read signal from multiple nearby regions, and without enough spatial diversity of channels to specify regional activation, the activation from multiple regions essentially get averaged together. Either scenario prevents robust interpretation of brain behavior whether in magnitude, region specificity or both.</p><p id="P10">Additionally, Sparse arrays are known to exhibit poor fNIRS signal reproducibility because of non-uniform spatial sensitivity<sup><xref rid="R24" ref-type="bibr">24</xref></sup>. Though several works demonstrate that additional use of short-separation channels to the traditional Sparse array improves data quality and sensitivity to cerebral hemodynamics by enabling regression of hemodynamics from superficial tissue from the long channel measurements<sup><xref rid="R25" ref-type="bibr">25</xref>&#x02013;<xref rid="R27" ref-type="bibr">27</xref></sup>, truly improved depth sensitivity additionally requires overlapping, high-density, multi-distance channels at lengths which allow for cortical sensitivity. This type of layout can improve spatial resolution as well as related signal characteristics such as partial volume blurring, spatial and depth sensitivity, localization of brain response, and inter-subject consistency<sup><xref rid="R28" ref-type="bibr">28</xref></sup>. These improvements are necessary to overcome limits of fNIRS&#x02019; ability to compare task-evoked response between conditions or between brain regions<sup><xref rid="R29" ref-type="bibr">29</xref>,<xref rid="R30" ref-type="bibr">30</xref></sup>, for example, and in applications toward current important work in malnutrition in global contexts<sup><xref rid="R31" ref-type="bibr">31</xref></sup>, brain disorders<sup><xref rid="R32" ref-type="bibr">32</xref>,<xref rid="R33" ref-type="bibr">33</xref></sup>, surgery assistance<sup><xref rid="R34" ref-type="bibr">34</xref>,<xref rid="R35" ref-type="bibr">35</xref></sup>, and brain-computer interfaces<sup><xref rid="R36" ref-type="bibr">36</xref></sup> among others.</p><p id="P11">Recent advances in miniaturization of hardware components and fNIRS technology have made it possible to develop systems with high-density and overlapping, multi-distance channels. This approach, High-Density Diffuse Optical Tomography (HD-DOT), was first introduced in 2007<sup><xref rid="R37" ref-type="bibr">37</xref></sup> and the first fiberless HD-DOT was introduced in 2016<sup><xref rid="R38" ref-type="bibr">38</xref></sup>. The fiberless nature makes a system &#x02018;wearable&#x02019; and is important for approaching true ecological validity. HD-DOT attains high degrees of sensitivity and in fact, Eggebrecht <italic toggle="yes">et al.</italic> showed their system&#x02019;s sensitivity approaches that of fMRI<sup><xref rid="R39" ref-type="bibr">39</xref></sup>.</p><p id="P12">It has been demonstrated that localization can be improved through various methods to resolve high-density fNIRS signal depth<sup><xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R40" ref-type="bibr">40</xref>&#x02013;<xref rid="R43" ref-type="bibr">43</xref></sup>. Currently, there are few commercially-available HD-DOT systems<sup><xref rid="R44" ref-type="bibr">44</xref>&#x02013;<xref rid="R46" ref-type="bibr">46</xref></sup> as well as several systems developed in labs<sup><xref rid="R38" ref-type="bibr">38</xref>,<xref rid="R44" ref-type="bibr">44</xref>,<xref rid="R47" ref-type="bibr">47</xref>,<xref rid="R48" ref-type="bibr">48</xref></sup>.</p><p id="P13">As more fNIRS and DOT options become available, it will be necessary for users to be able to quantitatively compare systems in order to select an optimal setup for the needs of their application. A key drawback of using an HD system over a Sparse system for a given regional coverage is the increased cost of resources such as materials &#x02013; optodes, optode-to-cap attachments, control boards, other hardware &#x02013; and computing processing required to efficiently process the larger amounts of data especially when considering whole-head arrays. When considering application to resource-limited settings, for example, the priority of this characteristic increases. Additionally, regardless of application, increasing the number and density of optode modules needed for the HD system especially in regions with hair incurs an increased setup and signal optimization time. The potential user needs to assess if the improved signal quality characteristics afforded by HD-DOT over traditional Sparse fNIRS are necessary to achieve the goals set out in their investigation and justify the disadvantages that come from having a denser array. It may be that the goal is to simply capture activation in a broad field-of-view, or to compare task evoked-response, localize activation, perform connectivity analysis, or achieve localization consistency, all of which may have varying degrees of improvement from a HD array. It is critical, therefore, that the field provides direct quantitative comparison of HD performance to that of traditional fNIRS arrays.</p><p id="P14">A relevant study by Shin <italic toggle="yes">et al.</italic> compared various fNIRS channel length combinations ranging from 15mm to 35mm and effectively compared HD to Sparse fNIRS. The signal comparison was evaluated by classification accuracy, which demonstrated that the combination of multi-distance and overlapping channels resulted in better classification accuracy than did a standard 30mm grid layout<sup><xref rid="R40" ref-type="bibr">40</xref></sup>. While this supports moving toward overlapping HD arrays for specific application, there remains need to statistically compare other metrics of fNIRS measurements of functional activity.</p><p id="P15">To that end, to the best of our knowledge there are two studies, from Fishell <italic toggle="yes">et al.</italic><sup><xref rid="R31" ref-type="bibr">31</xref></sup> and Frijia <italic toggle="yes">et al.</italic><sup><xref rid="R49" ref-type="bibr">49</xref></sup>, which performed a direct comparison between a Sparse and HD layout with matching field-of-views and concluded HD arrays provide better localization of functional activity. The studies were in developing age populations and the array comparisons were made between their entire HD probe and a subset of channels to form a sparse array from the same data collection.</p><p id="P16">Fishell <italic toggle="yes">et al.</italic>&#x02019;s fiber-based HD system was composed of three channel lengths (13mm, 29mm, 39mm) and spanned the temporal and occipital regions; the &#x0201c;Sparse&#x0201d; array measurements were compiled from the 29mm channel data. The image results qualitatively showed that the HD-DOT layout provides greatly improved localization of functional activity at the subject and group level and demonstrated inter-subject localization consistency, though the results did not report a statistical comparison between the array results. Additionally, the Sparse sub-layout did not include short-separation channels for superficial tissue regression and was not a grid pattern, so it therefore did not best represent what is currently most commonly seen in sparse fNIRS systems.</p><p id="P17">Frijia <italic toggle="yes">et al.</italic>&#x02019;s study used the wearable, fiberless GowerLabs&#x02019; Lumo components for their HD layout with multiple channel lengths (ranging from 10mm to 45mm) primarily over the superior temporal lobes; the &#x0201c;Sparse&#x0201d; array uses only the data from a subset of non-overlapping channels whose length is between 20mm-24.5mm. Their HD results showed higher amplitude of hemodynamic response (HRF) compared to Sparse results in both channel and image space. Additionally, the SNR of their channel HRF was reduced in HD measurements compared to Sparse, and qualitatively the images showed improved and more consistent localization by the HD array. While these results take the comparison of sparse and HD arrays a step further, neither array included short-separation channels for regression of superficial tissue hemodynamics. Statistical comparison between array measurements was not provided.</p><p id="P18">The agreement among these studies&#x02019; findings is encouraging and reinforces the potential for improved localization with HD fNIRS. Building on this foundation, our study provides complementary evidence by conducting a direct statistical comparison of Sparse and HD fNIRS arrays. Furthermore, it extends prior work by examining array performance across different conditions, including varying cognitive loads, as well as applying short-separation regression, offering deeper insights into optimal array design for specific applications.</p><p id="P19">Our work performs a direct comparison of measured Word-Color Stroop (WCS) induced frontotemporal activation in 17 healthy adult subjects as detected by both a traditional grid-pattern, Sparse fNIRS array and a hexagonal-pattern, overlapping and multi-distance, high-density (HD) array to quantify the expected improvements afforded by the HD array. The WCS paradigm has been shown to elicit activation in the dorsolateral prefrontal cortex (dlPFC) due to the required response inhibition processing<sup><xref rid="R50" ref-type="bibr">50</xref>&#x02013;<xref rid="R57" ref-type="bibr">57</xref></sup> so our probes are designed to extend across the PFC. We have modeled a Sparse optode layout after one of the most commonly used commercially-available systems, ETG-4000 (Hitachi Medical Co., Tokyo, Japan) and our novel HD array is patterned after the NinjaNIRS<sup><xref rid="R47" ref-type="bibr">47</xref></sup> layout and designed to have a field-of-view matching that of the Sparse array. After standard signal pre-processing and image reconstruction we generate concentration amplitude and t-statistics per subject for oxygenated and deoxygenated hemoglobin across WCS blocks for the channel data as well as brain surface vertices in image data. These metrics are both visualized and statistically compared at the group level. We find, in agreement with previous studies, that the HD array provides better localization than the Sparse array. We also find that the HD array captures, on average, stronger signal than does the Sparse array as defined by t-statistic per channel. The Sparse array is suitable for detecting, though not localizing, presence of activity for the incongruent WCS but not for congruent WCS. Our resulting comparison of layout and paradigm conditions provides a useful reference for future fNIRS users to make an evidence-based evaluation of optimal probe design for their application given experimental needs and limitations.</p></sec><sec id="S7"><label>2</label><title>MATERIALS AND METHODS</title><sec id="S8"><label>2.1</label><title>Participants</title><p id="P20">Twenty-three healthy adult subjects were recruited from the Boston, MA area for this study via methods approved by the Boston University Charles River Campus Institutional Review Board (IRB Protocol 4502). Subjects gave written consent prior to the start of data collection. Subjects were not eligible for the study if they were outside the range of 18-89 years of age, had history of neurological trauma or neurological or psychiatric disorders, were currently taking psychoactive medications, were wearing a pacemaker or implantable cardioverter defibrillator, were wearing a deep brain stimulator, were wearing cochlear implants, had an uncorrected visual problem, or had a history of hearing problems. After subject exclusions due to technical errors (i.e. loss of signal transmission between devices during data collection) and poor data quality assessed during processing, 17 subjects remained whose data was used in analysis. Their demographics are as follows: mean age = 25.8 &#x000b1; 4.3 years; 8 females, 9 males; 14 right-handed, 2 left-handed, 1 not reported; 10 White, 8 Asian, 1 Not Reported.</p></sec><sec id="S9"><label>2.2</label><title>fNIRS Measurements</title><sec id="S10"><label>2.2.1</label><title>Optode Arrays</title><p id="P21">We designed two optode layouts using the open-source AtlasViewer platform<sup><xref rid="R58" ref-type="bibr">58</xref></sup>. They are openly accessible at <ext-link xlink:href="http://openfnirs.org" ext-link-type="uri">openfnirs.org</ext-link>. We refer to our &#x0201c;Sparse&#x0201d; array as one which represents a traditional arrangement, depicted in the top row of <xref rid="F1" ref-type="fig">Figure 1</xref>. Its channels are in a grid pattern with lengths of 30mm. The centered and bottom-most optode is anchored to FPz and the optodes at the left and right bottom corners are anchored to T7 and T8, respectively. This layout includes 17 sources and 16 detectors for 52 channels, with an additional 8 detectors at 8mm separation (for a total of 24 detectors and 60 channels). Our multi-distance, high-density probe layout, referred to as the &#x0201c;HD&#x0201d; array, is shown in the bottom row of <xref rid="F1" ref-type="fig">Figure 1</xref>. The HD array was designed such that its field-of-view is as close as possible to that of the Sparse array, given pattern allowance. The centered optode on the bottom row is similarly anchored to FPz; the left and right corner optodes are just outside of the T7 and T8 landmarks with spring lengths of 2mm to the landmarks. Following the hexagonal pattern recommended by von L&#x000fc;hmann <italic toggle="yes">et al.</italic>, first nearest-neighbor (NN) channels are 8mm, second NN are 19mm, and third NN are 33mm. There are 25 sources and 58 detectors which produce 112 19mm channels and 94 33m channels, along with the additional 8 detectors at 8mm length short separation channels (for a total of 66 detectors and 214 channels). The files for each of these arrays are available to download at <ext-link xlink:href="https://openfnirs.org/hardware/ninjaCap/" ext-link-type="uri">openfnirs.org/hardware/ninjaCap/</ext-link>.</p><p id="P22">To identify Brodman regions underlying each channel, we employed AtlasViewer&#x02019;s &#x0201c;project channels to surface&#x0201d; function to calculate MNI coordinates for each channel of our Sparse and HD array. We then utilized the BioImage Suite Platform (<ext-link xlink:href="http://www.bioimagesuite.org" ext-link-type="uri">www.bioimagesuite.org</ext-link>) which maps the Colin27 brain surface (as used in AtlasViewer and therefore in creating our digital probe design) to the Talairach atlas surface and identifies Brodman regions from the calculated MNI coordinates<sup><xref rid="R59" ref-type="bibr">59</xref></sup>. In our case, not every channel was assigned a region from these steps because the coordinate was not fully projected to the cortex. To complete the anatomical labeling of our probes as shown in the right-hand column of <xref rid="F1" ref-type="fig">Figure 1</xref>, we developed four steps. The first is spatial interpolation per array, meaning that if an unlabeled channel is surrounded by channels with uniform labeling, that label was applied. Next, we compare an overlay of Sparse and HD channel labels; if one array&#x02019;s unlabeled channel overlaps or is surrounded by labeled channels from the other array it was assigned correspondingly. Thirdly, within each array we assigned still unlabeled channels with that of the matching channel in the other hemisphere. We acknowledge no individual brain, and thus the Colin27 template itself, is perfectly symmetric across hemispheres but at the group level symmetry can be assumed for the sake of region identification. Finally, for remaining unlabeled channels, we projected them to the cortex by applying incremental coordinate adjustments in the BioImage platform.</p></sec><sec id="S11"><label>2.2.2</label><title>Hardware</title><p id="P23">For both the Sparse and HD layouts we used NIRSport2 optodes and systems (four cascaded NIRSport2 16&#x000d7;16 devices for HD and three for Sparse) and Aurora data acquisition software (NIRx, Berlin, Germany). We used the dual-tip sources, which emit light at 760nm and 850nm, and silicone photodiode detectors. The sampling frequencies were 24.4Hz for Sparse and 17.5Hz for HD. We manually optimized the spatial multiplexing of the HD array from its default settings in order to achieve its sampling frequency. We used fully customizable, conformable NinjaCap<sup><xref rid="R60" ref-type="bibr">60</xref></sup>, 3D printed in three sizes (54cm, 56cm, 58cm circumference) with NinjaFlex (Fenner Precision Polymers, Lititz, Pennsylvania, United States), a flexible thermoplastic polyurethane (TPU) filament. Each cap included a reference marker for the Cz landmark. The open webbing design of the cap improves accessibility to maneuver hair to improve scalp coupling across diverse demographics. This cap structure also allows more escape of heat, thus increasing subject comfort.</p></sec></sec><sec id="S12"><label>2.3</label><title>Experimental procedures and paradigm</title><sec id="S13"><label>2.3.1</label><title>Experimental Procedure</title><p id="P24">For a given session, a subject first wore one array while performing the task, then after an approximately 30-minute break while optodes were moved to the other cap, the subject repeated the task while wearing the other array. We randomized the order in which the arrays are worn to ensure roughly half the data was from subjects who first wore the Sparse array and half from subjects who first wore the HD array.</p><p id="P25">To place the head caps, we first measured circumference, distance from inion (Iz) to nasion (Nz), and distance from ear-to-ear or LPA (T9) to RPA (T10). The cap for the selected measurement was placed to align both the Cz landmark and FPz optode on the cap to the subject&#x02019;s head. Cz was measured as the intersection of the midpoint of a line connecting the Iz and Nz landmarks with the midpoint of a line connecting the LPA and RPA landmarks. FPz was measured from Iz as 10% of the total distance from Iz to Nz. Due to the nature of skull shape and size variety, cap placement according to one of these landmarks did not always converge to placement according to the other landmark. In cases where this was observed, alignment to FPz was prioritized because the array is focused on the frontal region. To reduce likelihood of hair falling between the optodes and scalp especially on the forehead and temple we first requested subjects look upward and set the frontal portion of the cap on first, then instructed them to look straight ahead and gently unfolded the cap over the rest of the head from front-to-back with one hand while lightly holding the front of the cap in place with the other. Scalp coupling optimization generally required more time and care for the HD array due to the increased number of optodes, which not only required more optodes be attended to, but additionally prevented easy displacing of hair from under one optode without accidentally pushing it under the next. Generally, moving hair was performed with a cotton-tipped applicator. To achieve best signal quality, with the permission of the subject we sometimes applied clear ultrasound gel via the applicator. The optode was removed from the grommet, gel applied to the region as hair was pushed to the sides, and optode replaced; the gel aided to maintain hair position so that it did not move back under the optode. While sometimes good scalp-coupling &#x02013; as defined by the Aurora &#x02018;green&#x02019; thresholds of covariance &#x0003c; 2.5% and raw signal detection &#x0003e; 3mV &#x02013; was achieved near immediately for most or all channels especially with bald or short hair, we would spend a maximum of approximately 20 minutes to optimize the scalp-coupling before moving on. Room lighting was provided by halogen floor lamps rather than overhead fluorescent bulbs in order to avoid interference from ambient pulsed light. To prevent effects on frontal detectors from ambient signal emitted by the paradigm-presentation laptop, we placed a black shower cap on the subjects&#x02019; head over the optodes.</p><p id="P26">Duration of sessions from the time of consent to completion was approximately 2-2.5 hours.</p></sec><sec id="S14"><label>2.3.2</label><title>Paradigm</title><p id="P27">Our modified WCS task (<xref rid="F2" ref-type="fig">Figure 2</xref>) was based on previous work by Jahani <italic toggle="yes">et al.</italic><sup><xref rid="R51" ref-type="bibr">51</xref></sup>. We compiled and presented it via PsychoPy<sup><xref rid="R61" ref-type="bibr">61</xref></sup> with the full paradigm available on GitHub (<ext-link xlink:href="https://github.com/andersonjessie/WordColorStroop" ext-link-type="uri">https://github.com/andersonjessie/WordColorStroop</ext-link>). Our WCS had two conditions: an easier congruent task, and more difficult incongruent task. A trial of the congruent condition would display two words on a black background. Prior to a run, instructions for the congruent condition were provided on the screen and read aloud to the subject as follows: &#x0201c;For the following, two words will appear. Press either the Left Arrow or Right Arrow to indicate which word matches its font color. Press space to proceed to the practice.&#x0201d; The subject practiced twice with feedback, with additional practice if needed for clearer understanding. The design of the congruent task ensured that per trial, one word was congruent to its font color and the other was incongruent to its font color. A trial of the incongruent condition would display four words on a black background. Instructions for incongruent were provided on the screen and read aloud to the subject as follows: &#x0201c;For the following, a word will appear in the middle and a set of three words will appear above it. Press the Left Arrow, Up Arrow, or Right Arrow to indicate which word of the top row (left, middle, and right, respectively) describes the font color of the word below. Press space to proceed to the practice.&#x0201d; Again, the subject practiced twice with feedback, with additional practice if needed for clearer understanding. Instructions and practices were repeated when the subject performed another run for the second array. The design of the incongruent task ensured all four words (the prompt word and three option words) were always incongruent to their own font color. In both conditions, the location of the correct response was randomized.</p><p id="P28">After completing instruction and practice, a run began with a 20 s rest then 18x18 s blocks with interstimulus rest jittered between 10-15 s. There were 9 blocks of each condition with total block order randomized. Each block had 6 trials with duration 3 s per trial, and a given block was either all congruent or all incongruent trials with no feedback on accuracy provided to the subject. Total run time was approximately 11 minutes.</p></sec></sec><sec id="S15"><label>2.4</label><title>Data Pre-Processing</title><p id="P29">We performed the following pre-processing steps in the open-source Homer3 platform<sup><xref rid="R62" ref-type="bibr">62</xref></sup>. First, channels with raw signal levels less than 0.001 intensity units (for NIRSport2 data, V) or with a signal-to-noise ratio value less than 5 were pruned from further analysis (hmrPruneChannels). Intensity was converted to optical density (OD) (hmrR_Intensity2OD). We used the SplineSG motion correction function which applies both spline-interpolation and Savitzky&#x02013;Golay filtering to correct for baseline shifts and spikes, respectively (hmrR_MotionCorrectSplineSG)<sup><xref rid="R63" ref-type="bibr">63</xref></sup>, setting recommended parameter p value for smoothing to 0.99 and using a 10 second frame size. A low-pass filter (hmrR_BandassFilt: Bandpass_Filter_OpticalDensity) of 0.5 Hz was used to remove high-frequency noise such as cardiac signal before OD was converted to oxygenated-, deoxygenated-hemoglobin concentrations (HbO, HbR, HbT, respectively) via the Beer-Lambert Law (hmrR_OD2Conc)<sup><xref rid="R64" ref-type="bibr">64</xref></sup>. Upon visual inspection of raw signal, OD, and concentration timeseries data, it was apparent that some of the slow motion artifacts in the temporal regions could not be fully corrected via available detection or correction functions, so we performed manual rejection of blocks which contained such artifacts. We then applied a general linear model (hmrR_GLM) to estimate the hemodynamic response function (HRF) from two seconds prior to block onset to 23s after block onset. This captures 5s after stimulus offset, at 18s, in order to cover the recovery period. In the GLM we used ordinary least squares and applied a consecutive sequence of gaussian functions of 1 s width and step. For each long channel we use the short-separation (8mm) channel with greatest correlation to regress superficial tissue signal. The GLM included a polynomial drift correction of order 3.</p><p id="P30">If a subject had fewer than half the maximum blocks remaining in analysis due to manual block rejection (i.e. if they had four or fewer blocks for either condition) they were excluded from further analysis, which was the case for four subjects.</p></sec><sec id="S16"><label>2.5</label><title>Image Reconstruction</title><p id="P31">To generate our sensitivity matrices per array, we performed forward modeling of photon migration via AtlasViewer&#x02019;s &#x0201c;runMCXlab&#x0201d; function. This uses the MCXLAB package<sup><xref rid="R65" ref-type="bibr">65</xref></sup> to perform a Monte Carlo simulation in which the random walk of photons between each source and detector is mapped to generate the sensitivity profiles<sup><xref rid="R66" ref-type="bibr">66</xref>&#x02013;<xref rid="R68" ref-type="bibr">68</xref>
<xref rid="R66" ref-type="bibr">66</xref>&#x02013;<xref rid="R68" ref-type="bibr">68</xref></sup>. This represents the spatial sensitivity of each measurement channel to changes in cortical absorption. We chose to use the default parameters for photons launched (1e7) per optode and used wavelength-appropriate tissue properties for scalp, CSF, gray matter, and white matter tissues<sup><xref rid="R27" ref-type="bibr">27</xref></sup>. Each row of the sensitivity matrix represents the sensitivity profile of an individual channel. By summing over all channels, one can visualize the total sensitivity of the probe design as shown in the middle column of <xref rid="F1" ref-type="fig">Figure 1</xref>.</p><p id="P32">For a point activation on a cortical surface element, localization error (shown in <xref rid="SD1" ref-type="supplementary-material">Supplementary material Figure S1</xref>) can be summarized as the Euclidian distance between the true center of activation and center of mass of the reconstructed image. The position of center of mass <italic toggle="yes">r<sub>CM</sub></italic> is calculated as:
<disp-formula id="FD1">
<label>(1)</label>
<mml:math id="M1" display="block"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x02211;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>&#x02211;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula></p><p id="P33">Where the <italic toggle="yes">i</italic>th surface element had intensity <italic toggle="yes">I<sub>i</sub></italic> at position <italic toggle="yes">r<sub>i</sub></italic>.</p><p id="P34">Resolution profiles <italic toggle="yes">R<sub>CM</sub></italic>, also available in <xref rid="SD1" ref-type="supplementary-material">Supplementary material Figure S1</xref>, were calculated at each surface element by:
<disp-formula id="FD2">
<label>(2)</label>
<mml:math id="M2" display="block"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x02211;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>&#x02211;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula></p><p id="P35">Image reconstruction was performed to project optical density in channel space to concentration on the cortical and scalp surfaces. To do this, the estimated HRF output for HbO and HbR from the GLM were first converted back to optical density. Channel space optical density measurements can be expressed as the product of the sensitivity matrix and the concentration changes on the cortical surface using the forward model:
<disp-formula id="FD3">
<label>(3)</label>
<mml:math id="M3" display="block"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math>
</disp-formula></p><p id="P36">Where <italic toggle="yes">y</italic> is the channel space measurements in optical density, <italic toggle="yes">A</italic> is the sensitivity matrix and <italic toggle="yes">x</italic> is the changes in HbO and HbR on the cortical surface. To obtain these cortical measurements of HbO and HbR, we could solve the corresponding inverse problem:
<disp-formula id="FD4">
<label>(4)</label>
<mml:math id="M4" display="block"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>y</mml:mi></mml:mrow></mml:math>
</disp-formula></p><p id="P37">Reconstructing images on both the brain and scalp simultaneously has been shown to improve image resolution and localization<sup><xref rid="R27" ref-type="bibr">27</xref>,<xref rid="R42" ref-type="bibr">42</xref></sup>. Since the scalp is significantly more sensitive than the brain, spatially variant regularization is used to tune the reconstruction to the appropriate depth<sup><xref rid="R42" ref-type="bibr">42</xref></sup>. This is done by rescaling <italic toggle="yes">A</italic> as <inline-formula><mml:math id="M5" display="inline"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> using the diagonal matrix <italic toggle="yes">L</italic> defined as:
<disp-formula id="FD5">
<mml:math id="M6" display="block"><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt><mml:mspace linebreak="newline"/><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi>max</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>
</disp-formula></p><p id="P38">Then, 
<disp-formula id="FD6">
<mml:math id="M7" display="block"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math>
</disp-formula></p><p id="P39">The parameter <italic toggle="yes">&#x003b1;<sub>spatial</sub></italic> is used to control the reconstruction depth and is set to 0.001.</p><p id="P40">This inverse problem is ill-posed and underdetermined, however, so Tikhonov regularization was used to improve the estimation of <italic toggle="yes">x</italic>. The regularization parameter <italic toggle="yes">&#x003b1;<sub>meas</sub></italic> was used to scale the measurement covariance such that, when combined with the spatially variant regularization, the inverse problem became:
<disp-formula id="FD7">
<label>(5)</label>
<mml:math id="M8" display="block"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>y</mml:mi></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD8">
<label>(6)</label>
<mml:math id="M9" display="block"><mml:mrow><mml:mi>&#x003bb;</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math>
</disp-formula></p><p id="P41">The parameter <italic toggle="yes">&#x003b1;<sub>meas</sub></italic> was used to smooth the image and was set to 0.001. We refer to this method as &#x0201c;brain and scalp&#x0201d; image reconstruction throughout.</p><p id="P42">To visualize a subject&#x02019;s given set of vertices&#x02019; time course, we extracted the Homer GLM output HRF concentration data, generated the brain and scalp image for each second of HRF results, and plotted the mean of the vertices&#x02019; reconstructed image concentration over time.</p></sec><sec id="S17"><label>2.6</label><title>Statistical Analysis</title><sec id="S18"><label>2.6.1</label><title>Region of Interest</title><p id="P43">We selected the dorsolateral PFC (dlPFC) as our region of interest (ROI) as that is where we expect greatest activation to Stroop task based on previous studies<sup><xref rid="R54" ref-type="bibr">54</xref></sup>. We included channels with this labeling in <xref rid="F1" ref-type="fig">Figure 1</xref> and with similar field of view, excluding the ones assigned as dlPFC (dorsal) which fall in the medial area. In selecting ROI channels, we preserved symmetry of channels selected within and between each array, as well as account for inter-subject brain variability, which led to including several channels not initially marked as in the dlPFC. (Sparse ROI channels included: 8 dlPFC, 3 Anterior PFC, 1 Broca. HD ROI channels included: 42 dlPFC, 4 Anterior PFC, 2 Broca, 1 Frontal Eye Fields). The channels from each array selected per ROI appear in the left column of <xref rid="F3" ref-type="fig">Figure 3</xref>. Per ROI, there are 6x30mm channels from the Sparse array, 11x19mm channels from the HD array, and 14x33mm channels from the HD array. In selecting image space ROIs, because both the Sparse and HD array have the same total vertices and placement we selected exactly matching ROI vertices. We first identified the vertices whose sensitivity to the HD ROI channels were above the same 0.01 threshold used in visualizing the sensitivity matrices. We then kept the vertices with sensitivity above the average per from each ROI.</p></sec><sec id="S19"><label>2.6.2</label><title>Array Comparison Statistics</title><p id="P44">We analyzed the GLM-processed concentration timeseries data for HbO and HbR, and for both congruent and incongruent conditions. For each block at a given channel of an individual subject, we calculated a delta concentration by subtracting the mean of the concentration time course from &#x02212;2 to 0 seconds prior to block onset from the mean of the concentration time course between 7 to 18 seconds after the block onset. The mean delta concentration across blocks was divided by the standard error across blocks to produce a t-statistic particular to that concentration, WCS condition, channel, fNIRS array, and subject. For visualization purposes, group-level concentration means and standard error from across subjects&#x02019; own block-averages was used in calculating group-level t-statistics per channel.</p><p id="P45">To compare Sparse and HD HbO results, we selected from each subject the channel per left and right ROI which had the highest t-statistic. For HbR results, we selected based on lowest t-statistic with the evidenced expectation that HbR decreases when HbO increases for typical brain activation<sup><xref rid="R69" ref-type="bibr">69</xref></sup>. We performed a paired Student&#x02019;s <italic toggle="yes">t</italic>-test to statistically compare array performance.</p><p id="P46">To analyze in image space, we first reconstructed the image of each block based on the peak minus baseline values per channel previously calculated. We then used similar methodology to analyze the image data as used to analyze channel data, applying it to the mean of the 25 image vertices with highest t-statistics.</p></sec></sec></sec><sec id="S20"><label>3</label><title>RESULTS</title><sec id="S21"><label>3.1</label><title>Data Quality and Retention</title><p id="P47">Channel quality results are presented in <xref rid="T1" ref-type="table">Table 1</xref>. Here we focus on the report of all length HD channels. By paired Student&#x02019;s <italic toggle="yes">t</italic>-test, there was no significant difference between the SNR of the Sparse Array channels and the SNR of the HD Array channels (p = 0.36). There was, however, a significant difference in the number and percentage of channels pruned from each cap (p = 4.3e<sup>&#x02212;7</sup> and p = 2.1e<sup>&#x02212;7</sup>, respectively). The differences were also significant when looking specifically within the ROIs (p = 4.5e<sup>&#x02212;4</sup> and p = 8.7e<sup>&#x02212;4</sup> for number and percentage of channels pruned, respectively). The number of channels kept (pruned) in the analysis were, on average, 196.1 &#x000b1; 9.4 (17.9 &#x000b1; 9.4) HD channels and 59.6 &#x000b1; 0.9 (0.4 &#x000b1; 0.9) Sparse channels across the entire array; within our ROIs there were on average 48.3 &#x000b1; 1.6 HD channels and 12.0 &#x000b1; 0.1 Sparse channels included in the analysis. There was no significant difference between the number of blocks available for a given WCS task when the subject wore the Sparse array versus when they wore the HD array (p = 0.36 for incongruent, p = 0.21 for congruent by paired Student&#x02019;s <italic toggle="yes">t</italic>-test). There was also no significant difference between the number of blocks available when wearing a given array for the incongruent versus congruent task (p = 0.31 for the Sparse array, p = 0.36 for the HD array via paired Student&#x02019;s <italic toggle="yes">t</italic>-test).</p></sec><sec id="S22"><label>3.2</label><title>Performance Metrics</title><p id="P48"><xref rid="T2" ref-type="table">Table 2</xref> provides the group accuracy and response times (RT) per array and WCS condition of 16 subjects whose performance metrics were recorded and available for analysis. Between arrays, there was no significant difference in the accuracy or RT (p = 0.54 for congruent accuracy, p = 0.94 for incongruent accuracy, p = 0.40 for congruent RT, p = 0.99 for incongruent RT, via paired Student&#x02019;s <italic toggle="yes">t</italic>-test). There was not a significant drop in accuracy when performing incongruent task as compared to congruent (p = 0.05 for Sparse array accuracy, p = 0.07 for HD array accuracy via paired Student&#x02019;s <italic toggle="yes">t</italic>-test); however, there was a significant difference in response times between the conditions (p = 9.11e<sup>&#x02212;10</sup> for Sparse array RT, p = 4.24e<sup>&#x02212;7</sup> for HD array RT, via paired Student&#x02019;s <italic toggle="yes">t</italic>-test).</p></sec><sec id="S23"><label>3.3</label><title>Functional Activation</title><p id="P49">For each WCS condition and array, group-averaged mean HbO and t-statistic are shown in channel space in <xref rid="F4" ref-type="fig">Figure 4</xref>. The reconstructed image results for group-averaged HbO mean and t-statistics are shown in <xref rid="F5" ref-type="fig">Figure 5</xref>. Functional activation was present in the lateral regions for the HD array for both conditions. Functional deactivation was also present in the medial PFC for the HD array, more strongly during incongruent WCS than during congruent WCS. The pattern of activation in the Sparse image is difficult to distinguish and for the most part opposite of what is expected according to the channel group results. Due to variation of channels pruned per subject, not all the group channel calculations had the same number of subjects whose data are contributing. On average, HD channels&#x02019; group data had 15.6 &#x000b1; 2.4 subjects per channel and Sparse channels&#x02019; group data had 16.9 &#x000b1; 0.4 subjects per channel. For visual and comparative continuity across caps and between channel and image space, the maximum <italic toggle="yes">n</italic> of 17 (with two-tailed &#x003b1;=0.05) was used to calculate the critical t-statistic value of 2.1 for group data regardless. This number is used here only for visual thresholding of group data.</p><p id="P50"><xref rid="SD1" ref-type="supplementary-material">Supplementary materials</xref> include similar plots for HbR in channel and brain and scalp image space (<xref rid="SD1" ref-type="supplementary-material">Figures S8</xref> and <xref rid="SD1" ref-type="supplementary-material">S9</xref>), and both HbO and HbR group-average channel timeseries (<xref rid="SD1" ref-type="supplementary-material">Figure S10</xref>). We have also included all individual subject HbO mean and statistical results for congruent WCS in channel and image space in <xref rid="SD1" ref-type="supplementary-material">Supplementary material</xref> (<xref rid="SD1" ref-type="supplementary-material">Figures S11</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">S14</xref>).</p></sec><sec id="S24"><label>3.4</label><title>Statistical Comparison</title><p id="P51">From the ROIs, maximum HbO t-statistics per subject were compared between arrays as in <xref rid="F6" ref-type="fig">Figure 6</xref>. The corresponding average time course from each channel or vertices selected for a given condition, array, and ROI across subjects is shown underneath the bars with which it is associated. (The results for HbR data are in <xref rid="SD1" ref-type="supplementary-material">Supplementary Figure S15</xref>, and values for both <xref rid="F6" ref-type="fig">Figure 6</xref> and <xref rid="SD1" ref-type="supplementary-material">S15</xref> are provided in <xref rid="SD1" ref-type="supplementary-material">Supplementary Table S3</xref>.) Of the HD channels selected from each subjects&#x02019; ROI for its maximum HbO t-statistic during incongruent WCS, 8 out of the 17 were 19mm. During congruent WCS, 8 of 17 channels selected in the left ROI and 5 of 17 in the right ROI were 19mm. Further comparison of channel statistics if selecting from only the 33mm channels or from only the 19mm channels of the HD array is available in <xref rid="SD1" ref-type="supplementary-material">Supplementary material Figure S16</xref> and <xref rid="SD1" ref-type="supplementary-material">Table S4</xref>.</p><p id="P52">The channel statistical data from the HD array was significantly greater in magnitude than that of the Sparse array in the right ROI for both HbO incongruent WCS data and HbR congruent WCS data. In channel space, the HD array consistently provided a higher average maximum t-statistic than did the Sparse array for both HbO and HbR. As a whole, in both channel and image space the HbO statistics from the incongruent condition were greater than those from the congruent condition, with the exception of the right ROI for Sparse in channel space and for HD in image space. The difference was significant in the left ROI for the HbO data in either cap (channel Sparse p = 0.0011, channel HD p = 0.0441; image Sparse p = 0.0306, image HD p = 0.0228; image Sparse right p = 0.0252. All p-values provided in <xref rid="SD1" ref-type="supplementary-material">Supplementary Table S3</xref>). The average HbO channel and image space statistics also all exceeded the critical t-value, indicating significant brain activation, except the left congruent data for Sparse channel space and HD image space.</p></sec></sec><sec id="S25"><label>4</label><title>DISCUSSION</title><p id="P53">Though the prevalence of fiberless HD-DOT systems is increasing<sup><xref rid="R41" ref-type="bibr">41</xref>,<xref rid="R70" ref-type="bibr">70</xref>,<xref rid="R71" ref-type="bibr">71</xref></sup>, there has been a lack of adequate characterization of expected improvement of data obtained by such arrays over the commonly available traditional, grid Sparse fNIRS array. To our knowledge, this is the first study to perform a direct statistical comparison of two such arrays in a group of healthy adult subjects, providing statistical analysis in both channel and image space, including short-separation channels in the arrays to perform superficial tissue regression accordingly, and offering comparison for similar task conditions with differing cognitive load.</p><sec id="S26"><label>4.1</label><title>Channel and Image Statistics Array Comparison</title><p id="P54">Our analysis quantitatively compared the strength and consistency of signal detected from each array. In channel space, the group-averaged t-statistics from each ROI&#x02019;s chosen channel showed that the HD array can more consistently capture strength of activation than the Sparse array during both WCS conditions. Similar patterns emerged when looking at the HbR statistics (<xref rid="SD1" ref-type="supplementary-material">Figure S15</xref>). When comparing t-statistics from each subjects&#x02019; ROI vertices from reconstructed images, it was less clear that one array outperforms the other for either condition (<xref rid="F6" ref-type="fig">Figure 6</xref>), though the time courses from selected top vertices show the data analyzed with our image reconstruction pipeline results in higher magnitude of concentration with the HD array.</p><p id="P55">Interestingly, the 19mm channels comprised approximately half of the HD channels selected from each subjects&#x02019; ROI for its maximum HbO t-statistic during incongruent WCS, as well as half of the selected channels for congruent WCS in the left ROI. We anticipated the 33mm channels would yield signal with higher t-statistics than the 19mm channels due to higher brain sensitivity. Previous studies investigated the brain sensitivity of source-detector separations (SDS) ranging from 20 mm to 45 mm and found that for every 10 mm increase in SDS within this range, sensitivity to gray matter increased by approximately 4%. Additionally, the findings indicate that a minimum SDS of 25 mm is required to achieve relative sensitivity greater than 1% at a depth of 11.2 mm into the brain<sup><xref rid="R72" ref-type="bibr">72</xref></sup>. However, our data suggests that 19mm channels may perform comparatively well to 33mm channels for measuring dlPFC in our healthy adult population, based on the t-statistic metric. For possible explanation as to why the t-statistic is higher, we look at <xref rid="T1" ref-type="table">Table 1</xref>&#x02018;s report that the average raw signal SNR of un-pruned 19mm channels (57.3&#x000b1;18.6) was significantly higher than that of the un-pruned 33mm channels (40.9&#x000b1;13.5). Additionally, looking further into the standard error of HbO concentration across blocks, we found that the average SE of the 33mm channels selected for maximum t-statistic was consistently higher than that of the 19mm channels selected for maximum t-statistic (during congruent WCS: 33mm SE is 1.13 &#x000b1; 0.24 in left ROI and 1.76 &#x000b1; 0.27 in right ROI, vs the 19mm SE is 0.99 &#x000b1; 0.18 in left ROI and 1.32 &#x000b1; 0.25 in right ROI. During incongruent WCS: 33mm SE is 1.09 &#x000b1; 0.16 in left ROI and 1.37 &#x000b1; 0.24 in right ROI, vs the 19mm SE is 0.98 &#x000b1; 0.11 in left ROI and 1.11 &#x000b1; 0.22 in right ROI).</p><p id="P56">Our observation of the 19mm&#x02019;s surprisingly good performance inspired the re-running of the channel space statistical comparison, altered to select a HD channel from either only the ROI&#x02019;s 19mm channels, or only the ROI&#x02019;s 33mm channels (<xref rid="SD1" ref-type="supplementary-material">Figure S16</xref>). We recall that per ROI, there are 6x30mm channels from the Sparse array, 11x19mm channels from the HD array, and 14x33mm channels from the HD array. We found that having both 19mm and 33mm channels consistently yielded the strongest improvement over Sparse data, and that selecting from only 33mm channels did consistently provide slightly higher average maximum t-statistics than when selecting from only 19mm channels. It is not entirely clear if this may have occurred due to having more 33mm channels available than 19mm channels, or from improved signal from the 33mm channels.</p><p id="P57">We initially also had different expectations for the image space results &#x02013; specifically, that the HbO pattern from both arrays&#x02019; measurements would be similar to that of the channel space statistical comparison in <xref rid="F6" ref-type="fig">Figure 6</xref> where there is dlPFC activation and mFPC deactivation for both tasks, more so during incongruent WCS. While the HD array resulting pattern of activation aligned with the channel space results, the Sparse array images are almost opposite wherein there is more activation in mPFC and more deactivation in dlPFC.</p><p id="P58">We explored another method for pushing physiological and measurement noise to the scalp surface while isolating the cortical activity to the brain surface; Gao <italic toggle="yes">et al.</italic> developed a method that uses spatial basis functions modelled as Gaussian kernels with <italic toggle="yes">&#x003c3;</italic> = 5mm for the brain and <italic toggle="yes">&#x003c3;</italic> = 20mm for the scalp<sup><xref rid="R27" ref-type="bibr">27</xref></sup>. This has the advantage of reducing the degrees of freedom of the model and smoothing the resulting images. When we implemented this method, using parameters lambda1 = 0.01 and lambda2 = 0.1 in the sensitivity matrix inversion calculation, it seemed to appropriately handle the HD array data, however, we saw even more dramatic reduction of activation in the Sparse array due to its lack of overlapping channels. This suggests that the traditional Sparse array is ill-posed by nature for reconstructing an appropriate image which separates brain and scalp data.</p><p id="P59">We suspect that the Sparse array is better represented by not including scalp surface via spatially variant regularization when performing image reconstruction, and we have therefore generated such group result images in <xref rid="SD1" ref-type="supplementary-material">Supplementary Figure S17</xref> for the Sparse array which we refer to as &#x0201c;brain only&#x0201d; image reconstruction. In doing so we observe in the images and time course plots that there is strong cross-talk between the HbR and HbO data, which is not present in the regularized data. This demonstrates that the brain only method for reconstructing Sparse data is also unfit. Therefore, for the purpose of directly comparing HD and Sparse data, in our presented image results we chose to apply the same method to both arrays and include that in analysis in <xref rid="F6" ref-type="fig">Figure 6</xref>. Because our analysis selects the top vertices based on the HbO increase in the ROIs (and HbR decrease in the ROIs as shown in the <xref rid="SD1" ref-type="supplementary-material">supplementary material</xref>) we can still compare potentially-relevant results, but we argue that it may be inappropriate to assess Sparse image results as a whole.</p><p id="P60">For both arrays, it is possible that our ability to perform a more robust statistical comparison of image space results was hindered by the limitation that, like many other fNIRS studies, we did not have subject-specific MRIs to support more accurate probe localization. Rather, we used the AtlasViewer-provided Colin27 head atlas across all subjects.</p></sec><sec id="S27"><label>4.2</label><title>Capturing Different Cognitive Load</title><p id="P61">This study allowed us to observe each arrays&#x02019; comparative performance for different cognitive loads. The Stroop effect was clearly demonstrated in our data by the increased activation during incongruent task as compared to congruent in both caps (activation pattern is discussed further in <xref rid="S28" ref-type="sec">section 4.3</xref>) and performance metrics were comparable to what was expected based on previous literature<sup><xref rid="R53" ref-type="bibr">53</xref>,<xref rid="R73" ref-type="bibr">73</xref></sup>, so we are confident that our study setup generated desired brain activity. The performance metrics&#x02019; lack of significant difference in accuracy or response time between Sparse and HD array verifies comparability of the WCS brain response between arrays. The presence of significantly longer response time during incongruent WCS than during congruent WCS while maintaining accuracy, both when wearing Sparse and HD array, suggests and supports there is a higher cognitive load when performing incongruent WCS (<xref rid="T2" ref-type="table">Table 2</xref>). This is expected since the congruent condition does not require interference resolution and response inhibition to identify the correct response, which supplies non-interfering information.</p><p id="P62">We found that both the Sparse and HD arrays&#x02019; channel and image statistical data in the left ROI were significantly different between congruent and incongruent WCS. Other studies have also found the left PFC to be more involved than the right in the Stroop effect<sup><xref rid="R74" ref-type="bibr">74</xref></sup>. While this might indicate either array is suitable to find difference between task-specific activation, looking at the activation patterns of each condition independently yields a more nuanced perspective. In channel space for the incongruent task, both arrays captured the presence of activation as seen in the statistical visualization of <xref rid="F4" ref-type="fig">Figure 4</xref>, to varying degrees of localization discussed further in <xref rid="S28" ref-type="sec">section 4.3</xref>. However, there was a markedly different ability between the arrays to capture activation during the congruent task. The HD array still captured robust activation patterns in channel space; by contrast the Sparse array results had very few channels &#x02013; none in the left ROI &#x02013; that detect significant activation at the group level. This aligns with the channel statistical comparison in <xref rid="F6" ref-type="fig">Figure 6</xref>, in which we observe that for congruent WCS in the left ROI the averaged maximum t-statistic does not exceed the critical t-value. Looking at image results in <xref rid="F5" ref-type="fig">Figure 5</xref>, the Sparse array is similarly devoid of activation in the ROIs. For both tasks, though the statistics in <xref rid="F6" ref-type="fig">Figure 6</xref> would suggest HD does not outperform Sparse especially in the left ROI, the visualization in <xref rid="F5" ref-type="fig">Figure 5</xref> clearly indicates the HD array consolidates, or localizes, activation for both tasks.</p><p id="P63">This has implications for future array choice which should depend on a given paradigm&#x02019;s difficulty or expected magnitude of activation, and intention to analyze results in channel or image space. It is worth noting that most of our subjects have similarly high educational attainment, and the age range is limited which may skew the data. Future work might implement a similar comparative method with other tasks and conditions and across other populations to build a bank of array detection characterizations. This could enable better-informed selection of paradigm pairing with selected array density and location, whether for research, clinical use, or other purposes. Additionally, due to the importance of differentiating subject-specific activity between conditions<sup><xref rid="R75" ref-type="bibr">75</xref></sup> or condition-specific activity between subjects<sup><xref rid="R3" ref-type="bibr">3</xref>,<xref rid="R7" ref-type="bibr">7</xref>,<xref rid="R52" ref-type="bibr">52</xref></sup>, more work could look at other condition-specific metrics, such as signal latency, integral value, or centroid value<sup><xref rid="R76" ref-type="bibr">76</xref>,<xref rid="R77" ref-type="bibr">77</xref></sup>.</p></sec><sec id="S28"><label>4.3</label><title>Localization Comparison</title><p id="P64">The pattern of HbO activation during WCS as detected by both arrays in channel space and by HD array in image space matched that of previous fNIRS and fMRI findings specific to WCS<sup><xref rid="R50" ref-type="bibr">50</xref>&#x02013;<xref rid="R52" ref-type="bibr">52</xref>,<xref rid="R54" ref-type="bibr">54</xref>,<xref rid="R73" ref-type="bibr">73</xref></sup> &#x02013; that is, lateral activation and medial deactivation, more strongly in the incongruent condition than in the congruent condition (<xref rid="F4" ref-type="fig">Figure 4</xref>, <xref rid="F5" ref-type="fig">5</xref>). From the visualization of both arrays in channel and HD array in image space (<xref rid="F4" ref-type="fig">Figure 4</xref>, <xref rid="F5" ref-type="fig">5</xref>) as well as the statistical comparison in channel space (<xref rid="F6" ref-type="fig">Figure 6</xref>), the incongruent task seemed to elicit a more uniformly bilateral response than the congruent task for which there is more activation present in the right ROI than the left. This hemispherical activation difference for congruent WCS was not observed in most other studies<sup><xref rid="R50" ref-type="bibr">50</xref>,<xref rid="R53" ref-type="bibr">53</xref>,<xref rid="R54" ref-type="bibr">54</xref></sup>. However, it is known that the left dlPFC is implicated in interference processes like that induced by Stroop effect<sup><xref rid="R56" ref-type="bibr">56</xref>,<xref rid="R57" ref-type="bibr">57</xref></sup>, so it follows that the difference of activation between congruent and incongruent tasks is greater in the left than right dlPFC which was true of our data as well (<xref rid="F6" ref-type="fig">Figure 6</xref>). Though we did not expect the lateral difference for congruent data, there is another published work of healthy adults which also found lesser activation in the left PFC than the right PFC for their non-incongruent task<sup><xref rid="R55" ref-type="bibr">55</xref></sup>.</p><p id="P65">Looking at the visualized regions of significance-thresholded activity (<xref rid="F4" ref-type="fig">Figures 4</xref> and <xref rid="F5" ref-type="fig">5</xref>), especially for the higher-cognitive load incongruent task, it becomes clear that the HD array better localizes the activation in both channel and image space. This validates the Monte Carlo simulated photon migration results which showed reduced localization error and improved sensitivity in the HD array (<xref rid="F1" ref-type="fig">Figures 1</xref> and <xref rid="SD1" ref-type="supplementary-material">S1</xref>). This also supports previous literature naming the same advantage in infant populations and without applying short-separation regression to all the data<sup><xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R49" ref-type="bibr">49</xref></sup>. This is most dramatically illustrated in the reconstructed image data (<xref rid="F5" ref-type="fig">Figure 5</xref>), for which the active region detected by HD is continuous and contains a relatively centered focus of higher activity. By contrast, the active region detected by Sparse is discontinuous and lacks a centered focus of activity. Our study, therefore, translates some of existing findings to the 3cm grid array which is commonly available and in use and to an adult population, better enabling comparison of the systems and for broader application.</p></sec><sec id="S29"><label>4.4</label><title>Signal Quality and Data Collection</title><p id="P66">Since our comparison occurred over the PFC, the probe designs did not cover as much hair as they would have for other regions like parietal or occipital. This enabled us to perform the study without the need to assess how the presence of hair might affect the layouts differently, providing more of an ideal baseline comparison between the two. The left and right extremities of the arrays, though, do extend into hair regions especially on the superior boundaries of the cap, and we would predict that the HD array signal is more impacted by hair. Surprisingly, we saw that the SNR of the Sparse and HD array were not significantly different for non-pruned channels (p=0.36), which demonstrates promise for comparable signal quality. However, the significantly greater percentage and number of channels pruned for low SNR and low raw intensity from the HD array than for Sparse point to increased difficulty in achieving optimized signal via the HD array. Even so, we note that on average we still had over three times as many channels available from the HD array as compared to Sparse; within our ROI we had over four times as many. On average, we retained 91.6% of channels in the HD array which is higher than the channel retention for previous HD studies<sup><xref rid="R31" ref-type="bibr">31</xref></sup>. The HD pruned channels were mainly located in the superior portions of the array so we conclude the increased proportion of pruned channels from the HD array was due to presence of hair (<xref rid="SD1" ref-type="supplementary-material">Figure S19</xref>). Future work may characterize these metric comparisons in other regions of the head where there is more hair and hopefully elaborate on methods to reduce the percentage of HD channels pruned for SNR and low signal. We do recommend that users of fNIRS systems follow our described methods of cap placement and scalp coupling to enhance signal quality and use of the ninjaCap<sup><xref rid="R60" ref-type="bibr">60</xref></sup> itself, in combination with other documented techniques<sup><xref rid="R78" ref-type="bibr">78</xref>&#x02013;<xref rid="R82" ref-type="bibr">82</xref></sup>, and look forward to further developments of user techniques or technologies to ensure good signal quality optimization across demographics. Anecdotally, we can speak to our subjects having a range of hair color, shape, and texture, as well as a range of skin tone, thus verifying the applicability of the findings across various racial demographics. However, we recognize the absence in our study and suggest future studies to regularly collect metrics of hair color, shape, and texture as well as skin melanin pigmentation metrics to continue documenting and improving fNIRS ability to accommodate for a full range of demographics<sup><xref rid="R82" ref-type="bibr">82</xref></sup>.</p><p id="P67">A challenge we faced was that the number of optodes we had available allowed for only one array to be assembled at a given time. Subjects provided their estimated head circumference ahead of the session, and therefore we could populate optodes on the NinjaCap for either HD or Sparse for the estimated size. Unfortunately, subjects did not always provide an accurate head measurement as determined once we measured after consenting (differences were no larger than 2cm). Due to time constraints for the full session duration, we chose to proceed with the pre-assembled cap size; when moving optodes to the other layout for the second run of the session we used the same cap size for per-subject size consistency. If a cap was too large for the subjects head it may loosen the optode contact with the subjects&#x02019; head, which we accounted for by creating a fold in the occipital region (similar to a sewing dart) and securing with a clip. While using caps of incorrect head size would not affect pairwise comparison of data, it is likely to, in small ways, have affected localization of group results<sup><xref rid="R83" ref-type="bibr">83</xref></sup>. We recommend future work to navigate a challenge like this by a variety of methods, such as pre-study head measurements, digitizing probe localization after cap placement, using a size-adjustable cap design, or simply populating multiple cap sizes if the resources are available.</p><p id="P68">In order to perform a direct comparison of our HD array to the Sparse grid array, we were constrained to using two separate printed caps and populating them separately due to non-overlapping optode locations. Though this potentially introduced variability in cap placement per subject, our pair-wise analytical methods overcome this by selecting one channel or vertex per ROI with greatest t-statistic. Additionally, any effect of variability in per-subject cap placement in group results would not be any greater than effects due to inter-subject cap placement variability.</p></sec></sec><sec id="S30"><label>5</label><title>CONCLUSION</title><p id="P69">As fNIRS development and research progresses toward whole-head HD systems, this work&#x02019;s characterization in the PFC of the improvement our HD layout affords over that of the traditional sparse array may apply across the whole-head. Several key implications of Sparse and HD array use emerged from our study which can inform future selection of array and paradigm to best elicit and capture functional activity. Comparison of congruent task results suggest that the Sparse array is inadequate for capturing brain activity when used for tasks which have a lower cognitive load in healthy adult subjects; conversely, our HD array is sufficient for capturing such brain activity. For both WCS conditions, localization is better achieved with the HD array and image reconstruction can be more appropriately performed with the HD array. If localization is not of high importance and analysis of image space results is not necessary, our incongruent results indicate that either array can be sufficient to capture the presence of activation when designed with continuous coverage over the ROI. The WCS task is relevant for many studies in psychiatric well-being and other cognitive applications, thus these results can hopefully translate directly to inform future studies using WCS and related Stroop or response-inhibition paradigms. We hope our methods and findings offer a foundation on which ongoing fNIRS array comparisons, expansions, and applications may build.</p></sec><sec sec-type="supplementary-material" id="SM1"><title>Supplementary Material</title><supplementary-material id="SD1" position="float" content-type="local-data"><label>Supplement 1</label><media xlink:href="media-1.pdf" id="d67e1454" position="anchor"/></supplementary-material></sec></body><back><ack id="S31"><label>9</label><title>ACKNOWLEDGMENTS</title><p id="P70">We thank Yuanyuan Gao, Antonio Ortega, Sudan Duwadi, Darash Desai, Alexander Von L&#x000fc;hmann, Jack Giblin, Xiaojun Cheng, Byungchan (Kenny) Kim, Chantal Stern, Alice Cronin-Golomb, Rini Kaplan, and Neila Gross for helpful lab training and insightful discussions and feedback. This project was supported by NIH NEW grant U01-EB 029856 and Boston University research funds.</p></ack><fn-group><fn fn-type="COI-statement" id="FN2"><label>6</label><p id="P81">DISCLOSURES</p><p id="P82">The authors declare that there are no financial interests, commercial affiliations, or other potential conflicts of interest that could have influenced the objectivity of this research or the writing of this paper.</p></fn><fn id="FN3"><label>7</label><p id="P83">CODE AND DATA AVAILABILITY</p><p id="P84">Both the Sparse and HD frontotemporal array designs are openly accessible at <ext-link xlink:href="https://openfnirs.org/hardware/ninjacap/" ext-link-type="uri">https://openfnirs.org/hardware/ninjacap/</ext-link> in file formats of .SD and .SNIRF for use with the AtlasViewer and Homer3 platforms, and in three circumference size files (54cm, 56cm, 58cm) in .stl and Cura file formats for 3D printing. Code to run the Word-Color Stroop paradigm in PsychoPy is publicly accessible at <ext-link xlink:href="https://github.com/andersonjessie/WordColorStroop" ext-link-type="uri">https://github.com/andersonjessie/WordColorStroop</ext-link>). De-identified recorded fNIRS and task performance data are available in separate datasets at <ext-link xlink:href="https://openneuro.org" ext-link-type="uri">openneuro.org</ext-link>.</p></fn></fn-group><bio id="d67e1461"><p id="P71">Jessica E. Anderson is a PhD candidate in Biomedical Engineering at Boston University. Her work focuses on fNIRS&#x02019; development, application to studying emotional regulation in developing populations, and translation to global contexts.</p></bio><bio id="d67e1464"><p id="P72">Laura Carlton a PhD candidate in Biomedical Engineering at Boston University. She completed her undergraduate degree in bioengineering at McGill University. Her current research centers on developing advanced computational methods and data analysis techniques to enhance the application of fNIRS technology in naturalistic studies, with the aim of improving its utility in real-world environments.</p></bio><bio id="d67e1467"><p id="P73">Sreekanth Kura is a Research Fellow at Boston University, specializing in fNIRS system development and acquisition software. His work also encompasses computational methods for optical microscopy.</p></bio><bio id="d67e1470"><p id="P74">W. Joseph O&#x02019;Brien, MS, works primarily with the design development of optical neuroimaging equipment. While with the Boas Lab, he worked towards the design of high-density fNIRS (HD-fNIRS) and the integration of other modalities into a whole head HD-fNIRS capable device.</p></bio><bio id="d67e1473"><p id="P75">De&#x02019;Ja Rogers is a biomedical engineering doctoral research fellow at Boas Lab, Boston University. She received her BS degree in electrical and electronics engineering from Norfolk State University and her MS degree in biomedical engineering from Boston University. She focuses on optimizing the combination functional near-infrared spectroscopy (fNIRS) and electroencephalography (EEG), with the goal of investigating neurodegeneration in the future.</p></bio><bio id="d67e1476"><p id="P76">Parisa Haji Rahimi holds degrees in Physics, and Business Administration, with a focus on artificial intelligence and deep learning. She is passionate about leveraging these technologies to solve real-world problems across various industries.</p></bio><bio id="d67e1479"><p id="P77">Parya Y. Farzam is a research fellow at the Boston University (BU) Neurophotonics Center. She uses fNIRS to perform cognitive neuroscience study and mainly focuses on the brain function of children with autism spectrum disorder. She prior to joining BU, she was a visiting student at the Martinos Center for Biomedical Imaging at Massachusetts General Hospital. She has a bachelor&#x02019;s degree in software engineering. She has hands-on experience with fNIRS in the research field of cognitive neuroscience, and also using diffuse correlation spectroscopy (DCS) on patients with stroke.</p></bio><bio id="d67e1482"><p id="P78">Muhammad H. Zaman, PhD, is an HHMI professor of Biomedical Engineering and Global Health at Boston University and the Director of Center on Forced Displacement. His research focuses on disease dynamics and access to healthcare among forcibly displaced persons - including refugees, internally displaced persons and stateless communities.</p></bio><bio id="d67e1485"><p id="P79">David A. Boas, PhD, is a professor of biomedical engineering at Boston University. He is the founding president of the Society for Functional Near-Infrared Spectroscopy and founding Editor-in-Chief of the SPIE journal Neurophotonics. He received the Britton Chance Biomedical Optics Award in 2016 for his development of several novel, high-impact biomedical optical technologies in the neurosciences, as well as following through with impactful application studies, and fostering the widespread adoption of these technologies.</p></bio><bio id="d67e1488"><p id="P80">Meryem A. Y&#x000fc;cel, PhD, is a research associate professor at Boston University (BU). Prior to her position at BU, she was an assistant in biomedical engineering at Massachusetts General Hospital and an instructor at Harvard Medical School, Radiology. Her primary research interest is to understand how the brain works in health and disease. Throughout her career, she has gained expertise in mathematical modeling of biological systems and functional brain imaging (fNIRS, fMRI, and EEG).</p></bio><ref-list><label>11</label><title>REFERENCES</title><ref id="R1"><label>1.</label><mixed-citation publication-type="book"><name><surname>von L&#x000fc;hmann</surname><given-names>A</given-names></name>, <etal/>
<article-title>Toward Neuroscience of the Everyday World (NEW) using functional near-infrared spectroscopy</article-title>. <source>Curr Opin Biomed Eng [Internet]</source>. <publisher-name>Elsevier B.V.</publisher-name>; <year>2021</year>
<month>Jun</month>
<day>1</day> [<date-in-citation>cited 2023 May 3</date-in-citation>];<fpage>18</fpage>. <comment>Available from: /pmc/articles/PMC7943029/</comment></mixed-citation></ref><ref id="R2"><label>2.</label><mixed-citation publication-type="book"><name><surname>Ferrari</surname><given-names>M</given-names></name>, <name><surname>Quaresima</surname><given-names>V</given-names></name>. <part-title>A brief review on the history of human functional near-infrared spectroscopy (fNIRS) development and fields of application</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2012</year>
<month>Nov</month>
<day>1</day>;<volume>63</volume>(<issue>2</issue>):<fpage>921</fpage>&#x02013;<lpage>935</lpage>.<pub-id pub-id-type="pmid">22510258</pub-id>
</mixed-citation></ref><ref id="R3"><label>3.</label><mixed-citation publication-type="book"><name><surname>Li</surname><given-names>R</given-names></name>, <etal/>
<article-title>Current opinions on the present and future use of functional near-infrared spectroscopy in psychiatry</article-title>. <source>Neurophotonics [Internet]</source>. <publisher-name>Society of Photo-Optical Instrumentation Engineers</publisher-name>; <year>2023</year>
<month>Feb</month>
<day>7</day> [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>10</volume>(<issue>1</issue>). <comment>Available from: /pmc/articles/PMC9904322/</comment></mixed-citation></ref><ref id="R4"><label>4.</label><mixed-citation publication-type="book"><name><surname>Ehlis</surname><given-names>AC</given-names></name>
<etal/>
<part-title>Application of functional near-infrared spectroscopy in psychiatry</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2014</year>
<month>Jan</month>
<day>15</day>;<volume>85</volume>:<fpage>478</fpage>&#x02013;<lpage>488</lpage>.<pub-id pub-id-type="pmid">23578578</pub-id>
</mixed-citation></ref><ref id="R5"><label>5.</label><mixed-citation publication-type="book"><name><surname>Chang</surname><given-names>F</given-names></name>, <etal/>
<source>Research progress of functional near-infrared spectroscopy in patients with psychiatric disorders</source>. <comment>https://doi.org/101080/2096179020201720901 [Internet]</comment>. <publisher-name>Taylor &#x00026; Francis</publisher-name>; <year>2020</year> [<date-in-citation>cited 2021 Dec 7</date-in-citation>];<volume>6</volume>(<issue>2</issue>):<fpage>141</fpage>&#x02013;<lpage>147</lpage>. <comment>Available from: <ext-link xlink:href="https://www.tandfonline.com/doi/abs/10.1080/20961790.2020.1720901" ext-link-type="uri">https://www.tandfonline.com/doi/abs/10.1080/20961790.2020.1720901</ext-link></comment></mixed-citation></ref><ref id="R6"><label>6.</label><mixed-citation publication-type="book"><name><surname>Ho</surname><given-names>CSH</given-names></name>, <etal/>
<part-title>Diagnostic and Predictive Applications of Functional Near-Infrared Spectroscopy for Major Depressive Disorder: A Systematic Review</part-title>. <source>Front Psychiatry</source>. <publisher-name>Frontiers</publisher-name>; <year>2020</year>;<volume>0</volume>:<fpage>378</fpage>.</mixed-citation></ref><ref id="R7"><label>7.</label><mixed-citation publication-type="book"><name><surname>Feng</surname><given-names>K</given-names></name>, <etal/>
<article-title>Differentiating between bipolar and unipolar depression using prefrontal activation patterns: Promising results from functional near infrared spectroscopy (fNIRS) findings</article-title>. <source>J Affect Disord [Internet]</source>. <publisher-name>Elsevier B.V.</publisher-name>; <year>2021</year>
<month>Feb</month>
<day>15</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>281</volume>:<fpage>476</fpage>&#x02013;<lpage>484</lpage>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.1016/j.jad.2020.12.048</pub-id><pub-id pub-id-type="pmid">33373907</pub-id>
</mixed-citation></ref><ref id="R8"><label>8.</label><mixed-citation publication-type="journal"><name><surname>Quaresima</surname><given-names>V</given-names></name>, <name><surname>Ferrari</surname><given-names>M</given-names></name>. <article-title>Functional Near-Infrared Spectroscopy (fNIRS) for Assessing Cerebral Cortex Function During Human Behavior in Natural/Social Situations: A Concise Review</article-title>. <source>Organ Res Methods</source>. <year>2019</year>;<volume>22</volume>(<issue>1</issue>):<fpage>46</fpage>&#x02013;<lpage>68</lpage>.</mixed-citation></ref><ref id="R9"><label>9.</label><mixed-citation publication-type="book"><name><surname>Wilcox</surname><given-names>T</given-names></name>, <name><surname>Biondi</surname><given-names>M</given-names></name>. <article-title>fNIRS in the developmental sciences</article-title>. <source>Wiley Interdiscip Rev Cogn Sci [Internet]</source>. <publisher-name>John Wiley &#x00026; Sons, Ltd</publisher-name>; <year>2015</year>
<month>May</month>
<day>1</day> [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>6</volume>(<issue>3</issue>):<fpage>263</fpage>&#x02013;<lpage>283</lpage>. <comment>Available from: <ext-link xlink:href="https://onlinelibrary.wiley.com/doi/full/10.1002/wcs.1343" ext-link-type="uri">https://onlinelibrary.wiley.com/doi/full/10.1002/wcs.1343</ext-link></comment><pub-id pub-id-type="pmid">26263229</pub-id>
</mixed-citation></ref><ref id="R10"><label>10.</label><mixed-citation publication-type="book"><name><surname>Baek</surname><given-names>S</given-names></name>, <etal/>
<article-title>Attrition rate in infant fNIRS research: A meta-analysis</article-title>. <source>Infancy [Internet]</source>. <publisher-name>John Wiley &#x00026; Sons, Ltd</publisher-name>; <year>2023</year>
<month>May</month>
<day>1</day> [<date-in-citation>cited 2023 May 4</date-in-citation>];<volume>28</volume>(<issue>3</issue>):<fpage>507</fpage>&#x02013;<lpage>531</lpage>. <comment>Available from: <ext-link xlink:href="https://onlinelibrary.wiley.com/doi/full/10.1111/infa.12521" ext-link-type="uri">https://onlinelibrary.wiley.com/doi/full/10.1111/infa.12521</ext-link></comment><pub-id pub-id-type="pmid">36748788</pub-id>
</mixed-citation></ref><ref id="R11"><label>11.</label><mixed-citation publication-type="book"><name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <etal/>
<article-title>fNIRS in Africa &#x00026; Asia: an Objective Measure of Cognitive Development for Global Health Settings</article-title>. <source>The FASEB Journal [Internet]</source>. <publisher-name>John Wiley &#x00026; Sons, Ltd</publisher-name>; [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>30</volume>:<fpage>1149.18</fpage>&#x02013;<lpage>1149.18</lpage>. <comment>Available from: <ext-link xlink:href="https://onlinelibrary.wiley.com/doi/full/10.1096/fasebj.30.1_supplement.1149.18" ext-link-type="uri">https://onlinelibrary.wiley.com/doi/full/10.1096/fasebj.30.1_supplement.1149.18</ext-link></comment></mixed-citation></ref><ref id="R12"><label>12.</label><mixed-citation publication-type="book"><name><surname>Elwell</surname><given-names>CE</given-names></name>. <article-title>Brain Imaging for Global Health</article-title>. <source>J Neurosurg Anesthesiol [Internet]</source>. <publisher-name>Lippincott Williams and Wilkins</publisher-name>; <year>2020</year>
<month>Jul</month>
<day>1</day> [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>32</volume>(<issue>3</issue>):<fpage>188</fpage>&#x02013;<lpage>190</lpage>. <comment>Available from: <ext-link xlink:href="https://journals.lww.com/jnsa/Fulltext/2020/07000/Brain_Imaging_for_Global_Health.2.aspx" ext-link-type="uri">https://journals.lww.com/jnsa/Fulltext/2020/07000/Brain_Imaging_for_Global_Health.2.aspx</ext-link></comment><pub-id pub-id-type="pmid">32510906</pub-id>
</mixed-citation></ref><ref id="R13"><label>13.</label><mixed-citation publication-type="book"><name><surname>Lloyd-Fox</surname><given-names>S</given-names></name>, <etal/>
<article-title>Habituation and novelty detection fNIRS brain responses in 5- and 8-month-old infants: The Gambia and UK</article-title>. <source>Dev Sci [Internet]</source>. <publisher-name>John Wiley &#x00026; Sons, Ltd</publisher-name>; <year>2019</year>
<month>Sep</month>
<day>1</day> [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>22</volume>(<issue>5</issue>):<fpage>e12817</fpage>. <comment>Available from: <ext-link xlink:href="https://onlinelibrary.wiley.com/doi/full/10.1111/desc.12817" ext-link-type="uri">https://onlinelibrary.wiley.com/doi/full/10.1111/desc.12817</ext-link></comment><pub-id pub-id-type="pmid">30771264</pub-id>
</mixed-citation></ref><ref id="R14"><label>14.</label><mixed-citation publication-type="book"><name><surname>Pirazzoli</surname><given-names>L</given-names></name>, <etal/>
<part-title>Association of psychosocial adversity and social information processing in children raised in a low-resource setting: an fNIRS study</part-title>. <source>Dev Cogn Neurosci</source>. <publisher-name>Elsevier</publisher-name>; <year>2022</year>
<month>Aug</month>
<day>1</day>;<volume>56</volume>:<fpage>101125</fpage>.<pub-id pub-id-type="pmid">35763916</pub-id>
</mixed-citation></ref><ref id="R15"><label>15.</label><mixed-citation publication-type="book"><name><surname>Wijeakumar</surname><given-names>S</given-names></name>, <etal/>
<article-title>Early adversity in rural India impacts the brain networks underlying visual working memory</article-title>. <source>Dev Sci [Internet]</source>. <publisher-name>John Wiley &#x00026; Sons, Ltd</publisher-name>; <year>2019</year>
<month>Sep</month>
<day>1</day> [<date-in-citation>cited 2023 May 1</date-in-citation>];<volume>22</volume>(<issue>5</issue>):<fpage>e12822</fpage>. <comment>Available from: <ext-link xlink:href="https://onlinelibrary.wiley.com/doi/full/10.1111/desc.12822" ext-link-type="uri">https://onlinelibrary.wiley.com/doi/full/10.1111/desc.12822</ext-link></comment><pub-id pub-id-type="pmid">30803122</pub-id>
</mixed-citation></ref><ref id="R16"><label>16.</label><mixed-citation publication-type="webpage"><name><surname>Perdue</surname><given-names>KL</given-names></name>, <etal/>
<source>Using functional near-infrared spectroscopy to assess social information processing in poor urban Bangladeshi infants and toddlers</source>. <year>2019</year> [<date-in-citation>cited 2022 Apr 11</date-in-citation>]; <comment>Available from: </comment><pub-id pub-id-type="doi">10.1111/desc.12839</pub-id></mixed-citation></ref><ref id="R17"><label>17.</label><mixed-citation publication-type="journal"><name><surname>Jasi&#x00144;ska</surname><given-names>KK</given-names></name>, <name><surname>Guei</surname><given-names>S</given-names></name>. <article-title>Neuroimaging Field Methods Using Functional Near Infrared Spectroscopy (NIRS) Neuroimaging to Study Global Child Development: Rural Sub-Saharan Africa</article-title>. <source>J Vis Exp [Internet]</source>. <year>2018</year> [<date-in-citation>cited 2022 Apr 11</date-in-citation>];(<volume>132</volume>):<fpage>57165</fpage>. <comment>Available from: <ext-link xlink:href="https://doi.org/10.3791%2F57165" ext-link-type="uri">https://doi.org/10.3791%2F57165</ext-link></comment></mixed-citation></ref><ref id="R18"><label>18.</label><mixed-citation publication-type="book"><name><surname>Czeszumski</surname><given-names>A</given-names></name>, <etal/>
<article-title>Cooperative Behavior Evokes Interbrain Synchrony in the Prefrontal and Temporoparietal Cortex: A Systematic Review and Meta-Analysis of fNIRS Hyperscanning Studies</article-title>. <source>eNeuro [Internet]</source>. <publisher-name>Society for Neuroscience</publisher-name>; <year>2022</year>
<month>Mar</month>
<day>1</day> [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>9</volume>(<issue>2</issue>). <comment>Available from: /pmc/articles/PMC9014979/</comment></mixed-citation></ref><ref id="R19"><label>19.</label><mixed-citation publication-type="book"><name><surname>Reindl</surname><given-names>V</given-names></name>, <etal/>
<part-title>Brain-to-brain synchrony in parent-child dyads and the relationship with emotion regulation revealed by fNIRS-based hyperscanning</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2018</year>
<month>Sep</month>
<day>1</day>;<volume>178</volume>:<fpage>493</fpage>&#x02013;<lpage>502</lpage>.<pub-id pub-id-type="pmid">29807152</pub-id>
</mixed-citation></ref><ref id="R20"><label>20.</label><mixed-citation publication-type="webpage"><name><surname>Azhari</surname><given-names>A</given-names></name>, <etal/>
<source>parenting Stress Undermines Mother-child Brain-to-Brain Synchrony: A Hyperscanning Study</source>. [<date-in-citation>cited 2023 May 4</date-in-citation>]; <comment>Available from: <ext-link xlink:href="http://www.nature.com/scientificreports" ext-link-type="uri">www.nature.com/scientificreports</ext-link></comment></mixed-citation></ref><ref id="R21"><label>21.</label><mixed-citation publication-type="book"><name><surname>Miller</surname><given-names>JG</given-names></name>, <etal/>
<part-title>Inter-brain synchrony in mother-child dyads during cooperation: An fNIRS hyperscanning study</part-title>. <source>Neuropsychologia</source>. <publisher-name>Pergamon</publisher-name>; <year>2019</year>
<month>Feb</month>
<day>18</day>;<volume>124</volume>:<fpage>117</fpage>&#x02013;<lpage>124</lpage>.<pub-id pub-id-type="pmid">30594570</pub-id>
</mixed-citation></ref><ref id="R22"><label>22.</label><mixed-citation publication-type="book"><name><surname>Pinti</surname><given-names>P</given-names></name>, <etal/>
<article-title>The present and future use of functional near-infrared spectroscopy (fNIRS) for cognitive neuroscience</article-title>. <source>Ann N Y Acad Sci [Internet]</source>. <publisher-name>Blackwell Publishing Inc.</publisher-name>; <year>2020</year> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>1464</volume>(<issue>1</issue>):<fpage>5</fpage>&#x02013;<lpage>29</lpage>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.1111/nyas.13948</pub-id><pub-id pub-id-type="pmid">30085354</pub-id>
</mixed-citation></ref><ref id="R23"><label>23.</label><mixed-citation publication-type="book"><name><surname>White</surname><given-names>BR</given-names></name>, <name><surname>Culver</surname><given-names>JP</given-names></name>. <source>Quantitative evaluation of high-density diffuse optical tomography: in vivo resolution and mapping performance</source>. <comment>https://doi.org/101117/13368999 [Internet].</comment>
<publisher-name>SPIE</publisher-name>; <year>2010</year>
<month>Mar</month>
<day>1</day> [<date-in-citation>cited 2024 Jun 2</date-in-citation>];<volume>15</volume>(<issue>2</issue>):<fpage>026006</fpage>. <comment>Available from: <ext-link xlink:href="https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-15/issue-2/026006/Quantitative-evaluation-of-high-density-diffuse-optical-tomography--in/10.1117/1.3368999.full" ext-link-type="uri">https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-15/issue-2/026006/Quantitative-evaluation-of-high-density-diffuse-optical-tomography--in/10.1117/1.3368999.full</ext-link></comment></mixed-citation></ref><ref id="R24"><label>24.</label><mixed-citation publication-type="book"><name><surname>Novi</surname><given-names>SL</given-names></name>, <etal/>
<part-title>Integration of Spatial Information Increases Reproducibility in Functional Near-Infrared Spectroscopy</part-title>. <source>Front Neurosci</source>. <publisher-name>Frontiers Media S.A.</publisher-name>; <year>2020</year>
<month>Jul</month>
<day>28</day>;<volume>14</volume>:<fpage>746</fpage>.<pub-id pub-id-type="pmid">32848543</pub-id>
</mixed-citation></ref><ref id="R25"><label>25.</label><mixed-citation publication-type="journal"><name><surname>Wyser</surname><given-names>DG</given-names></name>, <etal/>
<article-title>Characterizing reproducibility of cerebral hemodynamic responses when applying short-channel regression in functional near-infrared spectroscopy</article-title>. <source>Neurophotonics [Internet]</source>. <comment>SPIE-Intl Soc Optical Eng</comment>; <year>2022</year>
<month>Mar</month>
<day>7</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>9</volume>(<issue>01</issue>). <comment>Available from: </comment><pub-id pub-id-type="doi">10.1117/1.NPh.9.1.015004</pub-id></mixed-citation></ref><ref id="R26"><label>26.</label><mixed-citation publication-type="book"><name><surname>Santosa</surname><given-names>H</given-names></name>, <etal/>
<article-title>Quantitative comparison of correction techniques for removing systemic physiological signal in functional near-infrared spectroscopy studies</article-title>. <source>Neurophotonics [Internet]</source>. <publisher-name>SPIE-Intl Soc Optical Eng</publisher-name>; <year>2020</year>
<month>Sep</month>
<day>23</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>7</volume>(<issue>03</issue>). <comment>Available from: </comment><pub-id pub-id-type="doi">10.1117/1.NPh.7.3.035009</pub-id></mixed-citation></ref><ref id="R27"><label>27.</label><mixed-citation publication-type="book"><name><surname>Gao</surname><given-names>Y</given-names></name>, <etal/>
<source>Short-separation regression incorporated diffuse optical tomography image reconstruction modeling for high-density functional near-infrared spectroscopy</source>. <comment>https://doi.org/101117/1NPh102025007 [Internet]</comment>. <publisher-name>SPIE</publisher-name>; <year>2023</year>
<month>May</month>
<day>23</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>10</volume>(<issue>2</issue>):<fpage>025007</fpage>. <comment>Available from: <ext-link xlink:href="https://www.spiedigitallibrary.org/journals/neurophotonics/volume-10/issue-2/025007/Short-separation-regression-incorporated-diffuse-optical-tomography-image-reconstruction-modeling/10.1117/1.NPh.10.2.025007.full" ext-link-type="uri">https://www.spiedigitallibrary.org/journals/neurophotonics/volume-10/issue-2/025007/Short-separation-regression-incorporated-diffuse-optical-tomography-image-reconstruction-modeling/10.1117/1.NPh.10.2.025007.full</ext-link></comment></mixed-citation></ref><ref id="R28"><label>28.</label><mixed-citation publication-type="book"><name><surname>Tremblay</surname><given-names>J</given-names></name>, <etal/>
<article-title>Comparison of source localization techniques in diffuse optical tomography for fNIRS application using a realistic head model</article-title>. <source>Biomed Opt Express [Internet]</source>. <publisher-name>Optica Publishing Group</publisher-name>; <year>2018</year>
<month>Jul</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>97</volume>(<issue>7</issue>):<fpage>2994</fpage>&#x02013;<lpage>3016</lpage>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.1364/BOE.9.002994</pub-id></mixed-citation></ref><ref id="R29"><label>29.</label><mixed-citation publication-type="book"><name><surname>Leff</surname><given-names>DR</given-names></name>, <etal/>
<part-title>Assessment of the cerebral cortex during motor task behaviours in adults: A systematic review of functional near infrared spectroscopy (fNIRS) studies</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2011</year>
<month>Feb</month>
<day>14</day>;<volume>54</volume>(<issue>4</issue>):<fpage>2922</fpage>&#x02013;<lpage>2936</lpage>.<pub-id pub-id-type="pmid">21029781</pub-id>
</mixed-citation></ref><ref id="R30"><label>30.</label><mixed-citation publication-type="book"><name><surname>Fishburn</surname><given-names>FA</given-names></name>, <etal/>
<part-title>Sensitivity of fNIRS to cognitive state and load</part-title>. <source>Front Hum Neurosci</source>. <publisher-name>Frontiers Media S. A.</publisher-name>; <year>2014</year>
<month>Feb</month>
<day>20</day>;<volume>8</volume>(<issue>1</issue>
<month>FEB</month>):<fpage>73786</fpage>.</mixed-citation></ref><ref id="R31"><label>31.</label><mixed-citation publication-type="book"><name><surname>Fishell</surname><given-names>AK</given-names></name>, <etal/>
<part-title>Portable, field-based neuroimaging using high-density diffuse optical tomography</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2020</year>
<month>Jul</month>
<day>15</day>;<volume>215</volume>:<fpage>116541</fpage>.<pub-id pub-id-type="pmid">31987995</pub-id>
</mixed-citation></ref><ref id="R32"><label>32.</label><mixed-citation publication-type="journal"><name><surname>Irani</surname><given-names>F</given-names></name>, <etal/>
<article-title>Functional Near Infrared Spectroscopy (fNIRS): An Emerging Neuroimaging Technology with Important Applications for the Study of Brain Disorders</article-title>. <source>Clin Neuropsychol [Internet]</source>. <year>2007</year>
<month>Jan</month> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>21</volume>(<issue>1</issue>):<fpage>37</fpage>&#x02013;<lpage>9</lpage>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.1080/13854040600910018</pub-id></mixed-citation></ref><ref id="R33"><label>33.</label><mixed-citation publication-type="book"><name><surname>Yeung</surname><given-names>MK</given-names></name>, <name><surname>Lin</surname><given-names>J</given-names></name>. <part-title>Probing depression, schizophrenia, and other psychiatric disorders using fNIRS and the verbal fluency test: A systematic review and meta-analysis</part-title>. <source>J Psychiatr Res [Internet]</source>. <publisher-name>J Psychiatr Res</publisher-name>; <year>2021</year>
<month>Aug</month>
<day>1</day> [<date-in-citation>cited 2021 Dec 7</date-in-citation>];<volume>140</volume>:<fpage>416</fpage>&#x02013;<lpage>435</lpage>. <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/34146793/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/34146793/</ext-link></comment><pub-id pub-id-type="pmid">34146793</pub-id>
</mixed-citation></ref><ref id="R34"><label>34.</label><mixed-citation publication-type="book"><name><surname>Green</surname><given-names>S</given-names></name>, <etal/>
<article-title>fNIRS brain measures of ongoing nociception during surgical incisions under anesthesia</article-title>. <source>Neurophotonics [Internet]</source>. <publisher-name>SPIE-Intl Soc Optical Eng</publisher-name>; <year>2022</year>
<month>Jan</month>
<day>27</day> [<date-in-citation>cited 2024 Nov 12]</date-in-citation>;<volume>9</volume>(<issue>01</issue>). <comment>Available from: </comment><pub-id pub-id-type="doi">10.1117/1.NPh.9.1.015002</pub-id></mixed-citation></ref><ref id="R35"><label>35.</label><mixed-citation publication-type="book"><name><surname>Goble</surname><given-names>M</given-names></name>
<etal/>
<article-title>Optical neuroimaging and neurostimulation in surgical training and assessment: A state-of-the-art review</article-title>. <source>Frontiers in Neuroergonomics [Internet]</source>. <publisher-name>Frontiers Media SA</publisher-name>; <year>2023</year> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>4</volume>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.3389/fnrgo.2023.1142182</pub-id></mixed-citation></ref><ref id="R36"><label>36.</label><mixed-citation publication-type="book"><name><surname>Naseer</surname><given-names>N</given-names></name>, <name><surname>Hong</surname><given-names>KS</given-names></name>. <article-title>fNIRS-based brain-computer interfaces: A review</article-title>. <source>Front Hum Neurosci [Internet]</source>. <publisher-name>Frontiers Media S. A.</publisher-name>; <year>2015</year>
<month>Jan</month>
<day>28</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>9</volume>(<month>JAN</month>). <comment>Available from: </comment><pub-id pub-id-type="doi">10.3389/fnhum.2015.00003</pub-id></mixed-citation></ref><ref id="R37"><label>37.</label><mixed-citation publication-type="journal"><name><surname>Zeff</surname><given-names>BW</given-names></name>, <etal/>
<article-title>Retinotopic mapping of adult human visual cortex with high-density diffuse optical tomography</article-title>. <source>Proc Natl Acad Sci U S A [Internet]</source>. <comment>Proc Natl Acad Sci U S A</comment>; <year>2007</year>
<month>Jul</month>
<day>17</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>104</volume>(<issue>29</issue>):<fpage>12169</fpage>&#x02013;<lpage>12174</lpage>. <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/17616584/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/17616584/</ext-link></comment><pub-id pub-id-type="pmid">17616584</pub-id>
</mixed-citation></ref><ref id="R38"><label>38.</label><mixed-citation publication-type="book"><name><surname>Chitnis</surname><given-names>D</given-names></name>, <etal/>
<article-title>Functional imaging of the human brain using a modular, fibre-less, high-density diffuse optical tomography system</article-title>. <source>Biomed Opt Express [Internet]</source>. <publisher-name>Optica Publishing Group</publisher-name>; <year>2016</year>
<month>Oct</month>
<day>10</day> [<date-in-citation>cited 2024 Jun 6</date-in-citation>];<volume>7</volume>(<issue>10</issue>):<fpage>4275</fpage>. <comment>Available from: /pmc/articles/PMC5102535/</comment><pub-id pub-id-type="pmid">27867731</pub-id>
</mixed-citation></ref><ref id="R39"><label>39.</label><mixed-citation publication-type="book"><name><surname>Eggebrecht</surname><given-names>AT</given-names></name>, <etal/>
<article-title>A quantitative spatial comparison of high-density diffuse optical tomography and fMRI cortical mapping</article-title>. <source>Neuroimage [Internet]</source>. <publisher-name>NIH Public Access</publisher-name>; <year>2012</year>
<month>Jul</month>
<day>16</day> [<date-in-citation>cited 2021 Dec 7</date-in-citation>];<volume>61</volume>(<issue>4</issue>):<fpage>1120</fpage>. <comment>Available from: /pmc/articles/PMC3581336/</comment><pub-id pub-id-type="pmid">22330315</pub-id>
</mixed-citation></ref><ref id="R40"><label>40.</label><mixed-citation publication-type="book"><name><surname>Shin</surname><given-names>J</given-names></name>, <etal/>
<article-title>Performance enhancement of a brain-computer interface using high-density multi-distance NIRS</article-title>. <source>Scientific Reports 2017 7:1 [Internet]</source>. <publisher-name>Nature Publishing Group</publisher-name>; <year>2017</year>
<month>Nov</month>
<day>29</day> [<date-in-citation>cited 2024 Jun 2</date-in-citation>];<volume>7</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>10</lpage>. <comment>Available from: <ext-link xlink:href="https://www.nature.com/articles/s41598-017-16639-0" ext-link-type="uri">https://www.nature.com/articles/s41598-017-16639-0</ext-link></comment></mixed-citation></ref><ref id="R41"><label>41.</label><mixed-citation publication-type="journal"><name><surname>Vidal-Rosas</surname><given-names>EE</given-names></name>, <etal/>
<article-title>Evaluating a new generation of wearable high-density diffuse optical tomography technology via retinotopic mapping of the adult visual cortex</article-title>. <source>Neurophotonics</source>. <year>2021</year>;<volume>8</volume>(<issue>02</issue>):<fpage>1</fpage>&#x02013;<lpage>24</lpage>.</mixed-citation></ref><ref id="R42"><label>42.</label><mixed-citation publication-type="book"><name><surname>Wheelock</surname><given-names>MD</given-names></name>, <name><surname>Culver</surname><given-names>JP</given-names></name>, <name><surname>Eggebrecht</surname><given-names>AT</given-names></name>. <article-title>High-density diffuse optical tomography for imaging human brain function</article-title>. <source>Review of Scientific Instruments [Internet]</source>. <publisher-name>American Institute of Physics Inc.</publisher-name>; <year>2019</year>
<month>May</month>
<day>1</day> [<date-in-citation>cited 2024 Jun 2</date-in-citation>];<volume>90</volume>(<issue>5</issue>):<fpage>51101</fpage>. <comment>Available from: /aip/rsi/article/90/5/051101/361289/High-density-diffuse-optical-tomography-for</comment></mixed-citation></ref><ref id="R43"><label>43.</label><mixed-citation publication-type="book"><name><surname>Yaqub</surname><given-names>MA</given-names></name>, <name><surname>Woo</surname><given-names>SW</given-names></name>, <name><surname>Hong</surname><given-names>KS</given-names></name>. <part-title>Compact, Portable, High-Density Functional Near-Infrared Spectroscopy System for Brain Imaging</part-title>. <source>IEEE Access</source>. <publisher-name>Institute of Electrical and Electronics Engineers Inc.</publisher-name>; <year>2020</year>;<volume>8</volume>:<fpage>128224</fpage>&#x02013;<lpage>128238</lpage>.</mixed-citation></ref><ref id="R44"><label>44.</label><mixed-citation publication-type="book"><name><surname>Zhao</surname><given-names>H</given-names></name>, <etal/>
<source>Design and validation of a mechanically flexible and ultra-lightweight high-density diffuse optical tomography system for functional neuroimaging of newborns</source>. <comment>https://doi.org/101117/1NPh81015011 [Internet].</comment>
<publisher-name>SPIE</publisher-name>; <year>2021</year>
<month>Mar</month>
<day>26</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>8</volume>(<issue>1</issue>):<fpage>015011</fpage>. <comment>Available from: <ext-link xlink:href="https://www.spiedigitallibrary.org/journals/neurophotonics/volume-8/issue-1/015011/Design-and-validation-of-a-mechanically-flexible-and-ultra-lightweight/10.1117/1.NPh.8.1.015011.full" ext-link-type="uri">https://www.spiedigitallibrary.org/journals/neurophotonics/volume-8/issue-1/015011/Design-and-validation-of-a-mechanically-flexible-and-ultra-lightweight/10.1117/1.NPh.8.1.015011.full</ext-link></comment></mixed-citation></ref><ref id="R45"><label>45.</label><mixed-citation publication-type="book"><name><surname>Ban</surname><given-names>HY</given-names></name>
<etal/>
<article-title>Kernel Flow: a high channel count scalable time-domain functional near-infrared spectroscopy system</article-title>. <source>J Biomed Opt [Internet]</source>. <publisher-name>J Biomed Opt</publisher-name>; <year>2022</year>
<month>Jan</month>
<day>18</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>27</volume>(<issue>7</issue>). <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/35043610/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/35043610/</ext-link></comment></mixed-citation></ref><ref id="R46"><label>46.</label><mixed-citation publication-type="book"><name><surname>Anaya</surname><given-names>D</given-names></name>, <etal/>
<article-title>Scalable, modular continuous wave functional near-infrared spectroscopy system (Spotlight)</article-title>. <source>J Biomed Opt [Internet]</source>. <publisher-name>SPIE-Intl Soc Optical Eng</publisher-name>; <year>2023</year>
<month>Jun</month>
<day>13</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>28</volume>(<issue>6</issue>):<fpage>065003</fpage>. <comment>Available from: <ext-link xlink:href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10261976/" ext-link-type="uri">https://pmc.ncbi.nlm.nih.gov/articles/PMC10261976/</ext-link></comment><pub-id pub-id-type="pmid">37325190</pub-id>
</mixed-citation></ref><ref id="R47"><label>47.</label><mixed-citation publication-type="book"><name><surname>O&#x02019;Brien</surname><given-names>WJ</given-names></name>, <etal/>
<article-title>ninjaNIRS: an open hardware solution for wearable whole-head high-density functional near-infrared spectroscopy</article-title>. <source>Biomedical Optics Express</source>, Vol <volume>15</volume>, Issue <issue>10</issue>, pp <fpage>5625</fpage>&#x02013;<lpage>5644</lpage>
<comment>[Internet].</comment>
<publisher-name>Optica Publishing Group</publisher-name>; <year>2024</year>
<month>Oct</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<comment>15(10):5625-013;5644</comment>. <comment>Available from: <ext-link xlink:href="https://opg.optica.org/viewmedia.cfm?uri=boe-15-10-5625&#x00026;seq=0&#x00026;html=true" ext-link-type="uri">https://opg.optica.org/viewmedia.cfm?uri=boe-15-10-5625&#x00026;seq=0&#x00026;html=true</ext-link></comment><pub-id pub-id-type="pmid">39421779</pub-id>
</mixed-citation></ref><ref id="R48"><label>48.</label><mixed-citation publication-type="journal"><name><surname>von L&#x000fc;hmann</surname><given-names>A</given-names></name>, <etal/>
<article-title>Can the fNIRS community design a standard cap layout for uniform whole-head HD fNIRS coverage? A discussion</article-title>. <source>Society of fNIRS</source>. <year>2022</year>;</mixed-citation></ref><ref id="R49"><label>49.</label><mixed-citation publication-type="book"><name><surname>Frijia</surname><given-names>EM</given-names></name>
<etal/>
<part-title>Functional imaging of the developing brain with wearable high-density diffuse optical tomography: A new benchmark for infant neuroimaging outside the scanner environment</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2021</year>
<month>Jan</month>
<day>15</day>;<volume>225</volume>:<fpage>117490</fpage>.<pub-id pub-id-type="pmid">33157266</pub-id>
</mixed-citation></ref><ref id="R50"><label>50.</label><mixed-citation publication-type="book"><name><surname>Plenger</surname><given-names>P</given-names></name>, <etal/>
<article-title>fNIRS-based investigation of the Stroop task after TBI</article-title>. <source>Brain Imaging Behav [Internet]</source>. <publisher-name>Springer New York LLC</publisher-name>; <year>2016</year>
<month>Jun</month>
<day>1</day> [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>10</volume>(<issue>2</issue>):<fpage>357</fpage>&#x02013;<lpage>366</lpage>. <comment>Available from: <ext-link xlink:href="https://link.springer.com/article/10.1007/s11682-015-9401-9" ext-link-type="uri">https://link.springer.com/article/10.1007/s11682-015-9401-9</ext-link></comment><pub-id pub-id-type="pmid">26058665</pub-id>
</mixed-citation></ref><ref id="R51"><label>51.</label><mixed-citation publication-type="confproc"><name><surname>Jahani</surname><given-names>S</given-names></name>, <etal/>
<source>Attention level quantification during a modified stroop color word experiment: An fNIRS based study</source>. <conf-name>2015 22nd Iranian Conference on Biomedical Engineering, ICBME 2015</conf-name>. <publisher-name>Institute of Electrical and Electronics Engineers Inc.</publisher-name>; <year>2016</year>
<month>Feb</month>
<day>9</day>;<fpage>99</fpage>&#x02013;<lpage>103</lpage>.</mixed-citation></ref><ref id="R52"><label>52.</label><mixed-citation publication-type="book"><name><surname>Lagu&#x000eb;-Beauvais</surname><given-names>M</given-names></name>, <etal/>
<part-title>A fNIRS investigation of switching and inhibition during the modified Stroop task in younger and older adults</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2013</year>
<month>Jan</month>
<day>1</day>;<volume>64</volume>(<issue>1</issue>):<fpage>485</fpage>&#x02013;<lpage>495</lpage>.<pub-id pub-id-type="pmid">23000257</pub-id>
</mixed-citation></ref><ref id="R53"><label>53.</label><mixed-citation publication-type="book"><name><surname>Schroeter</surname><given-names>ML</given-names></name>, <etal/>
<article-title>Near-infrared spectroscopy can detect brain activity during a color&#x02013;word matching Stroop task in an event-related design</article-title>. <source>Hum Brain Mapp [Internet]</source>. <publisher-name>John Wiley &#x00026; Sons, Ltd</publisher-name>; <year>2002</year>
<month>Sep</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>17</volume>(<issue>1</issue>):<fpage>61</fpage>&#x02013;<lpage>71</lpage>. <comment>Available from: <ext-link xlink:href="https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.10052" ext-link-type="uri">https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.10052</ext-link></comment><pub-id pub-id-type="pmid">12203689</pub-id>
</mixed-citation></ref><ref id="R54"><label>54.</label><mixed-citation publication-type="book"><name><surname>Yennu</surname><given-names>A</given-names></name>, <etal/>
<article-title>Prefrontal responses to Stroop tasks in subjects with post-traumatic stress disorder assessed by functional near infrared spectroscopy</article-title>. <source>Scientific Reports</source>
<year>2016</year>
<volume>6</volume>:<fpage>1</fpage>
<comment>[Internet].</comment>
<publisher-name>Nature Publishing Group</publisher-name>; <comment>2016</comment>
<month>Jul</month>
<day>25</day> [<date-in-citation>cited 2021 Jul 25</date-in-citation>];<comment>6(1):1-14</comment>. <comment>Available from: <ext-link xlink:href="https://www.nature.com/articles/srep30157" ext-link-type="uri">https://www.nature.com/articles/srep30157</ext-link></comment><pub-id pub-id-type="pmid">28442746</pub-id>
</mixed-citation></ref><ref id="R55"><label>55.</label><mixed-citation publication-type="book"><name><surname>Zhang</surname><given-names>L</given-names></name>, <etal/>
<article-title>Studying hemispheric lateralization during a Stroop task through near-infrared spectroscopy-based connectivity</article-title>. <source>J Biomed Opt [Internet]</source>. <publisher-name>J Biomed Opt</publisher-name>; <year>2014</year>
<month>May</month>
<day>26</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>19</volume>(<issue>5</issue>):<fpage>057012</fpage>. <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/24862561/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/24862561/</ext-link></comment></mixed-citation></ref><ref id="R56"><label>56.</label><mixed-citation publication-type="book"><name><surname>Mason</surname><given-names>SA</given-names></name>, <etal/>
<part-title>Association between carotid atherosclerosis and brain activation patterns during the Stroop task in older adults: An fNIRS investigation</part-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2022</year>
<month>Aug</month>
<day>15</day>;<volume>257</volume>:<fpage>119302</fpage>.<pub-id pub-id-type="pmid">35595200</pub-id>
</mixed-citation></ref><ref id="R57"><label>57.</label><mixed-citation publication-type="book"><name><surname>Jonides</surname><given-names>J</given-names></name>, <etal/>
<article-title>Age Differences in Behavior and PET Activation Reveal Differences in Interference Resolution in Verbal Working Memory</article-title>. <source>J Cogn Neurosci [Internet]</source>. <publisher-name>MIT Press</publisher-name>; <year>2000</year>
<month>Jan</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>12</volume>(<issue>1</issue>):<fpage>188</fpage>&#x02013;<lpage>196</lpage>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.1162/089892900561823</pub-id><pub-id pub-id-type="pmid">10769315</pub-id>
</mixed-citation></ref><ref id="R58"><label>58.</label><mixed-citation publication-type="book"><name><surname>Aasted</surname><given-names>CM</given-names></name>, <etal/>
<source>Anatomical guidance for functional near-infrared spectroscopy: AtlasViewer tutorial</source>. <comment>https://doi.org/101117/1NPh22020801 [Internet].</comment>
<publisher-name>SPIE</publisher-name>; <year>2015</year>
<month>May</month>
<day>5</day> [<date-in-citation>cited 2023 May 1</date-in-citation>];<volume>2</volume>(<issue>2</issue>):<fpage>020801</fpage>. <comment>Available from: <ext-link xlink:href="https://www.spiedigitallibrary.org/journals/neurophotonics/volume-2/issue-2/020801/Anatomical-guidance-for-functional-near-infrared-spectroscopy-AtlasViewer-tutorial/10.1117/1.NPh.2.2.020801.full" ext-link-type="uri">https://www.spiedigitallibrary.org/journals/neurophotonics/volume-2/issue-2/020801/Anatomical-guidance-for-functional-near-infrared-spectroscopy-AtlasViewer-tutorial/10.1117/1.NPh.2.2.020801.full</ext-link></comment></mixed-citation></ref><ref id="R59"><label>59.</label><mixed-citation publication-type="journal"><name><surname>Lacadie</surname><given-names>CM</given-names></name>, <etal/>
<article-title>More Accurate Talairach Coordinates for NeuroImaging using Nonlinear Registration</article-title>. <source>Neuroimage [Internet]</source>. <year>2008</year>
<month>Aug</month>
<day>15</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>42</volume>(<issue>2</issue>):<fpage>717</fpage>. <comment>Available from: <ext-link xlink:href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2603575/" ext-link-type="uri">https://pmc.ncbi.nlm.nih.gov/articles/PMC2603575/</ext-link></comment><pub-id pub-id-type="pmid">18572418</pub-id>
</mixed-citation></ref><ref id="R60"><label>60.</label><mixed-citation publication-type="book"><name><surname>von L&#x000fc;hmann</surname><given-names>A</given-names></name>, <etal/>
<article-title>ninjaCap: a fully customizable and 3D printable headgear for functional near-infrared spectroscopy and electroencephalography brain imaging</article-title>. <source>Neurophotonics [Internet]</source>. <publisher-name>Neurophotonics</publisher-name>; <year>2024</year>
<month>Aug</month>
<day>27</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>11</volume>(<issue>3</issue>). <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/39193445/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/39193445/</ext-link></comment></mixed-citation></ref><ref id="R61"><label>61.</label><mixed-citation publication-type="book"><name><surname>Peirce</surname><given-names>JW</given-names></name>. <article-title>Generating stimuli for neuroscience using PsychoPy</article-title>. <source>Front Neuroinform</source>. <publisher-name>Frontiers Media S.A.</publisher-name>; <year>2009</year>
<month>Jan</month>
<day>15</day>;<volume>2</volume>(<month>JAN</month>):<fpage>343</fpage>.</mixed-citation></ref><ref id="R62"><label>62.</label><mixed-citation publication-type="book"><name><surname>Huppert</surname><given-names>TJ</given-names></name>, <etal/>
<article-title>HomER: a review of time-series analysis methods for near-infrared spectroscopy of the brain</article-title>. <source>Applied Optics</source>, Vol <volume>48</volume>, Issue <issue>10</issue>, pp <fpage>D280</fpage>&#x02013;<lpage>D298</lpage>
<comment>[Internet].</comment>
<publisher-name>Optica Publishing Group</publisher-name>; <year>2009</year>
<month>Apr</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<comment>48(10):D280-D298</comment>. <comment>Available from: <ext-link xlink:href="https://opg.optica.org/viewmedia.cfm?uri=ao-48-10-D280&#x00026;seq=0&#x00026;html=true" ext-link-type="uri">https://opg.optica.org/viewmedia.cfm?uri=ao-48-10-D280&#x00026;seq=0&#x00026;html=true</ext-link></comment><pub-id pub-id-type="pmid">19340120</pub-id>
</mixed-citation></ref><ref id="R63"><label>63.</label><mixed-citation publication-type="book"><name><surname>Jahani</surname><given-names>S</given-names></name>, <etal/>
<article-title>Motion artifact detection and correction in functional near-infrared spectroscopy: a new hybrid method based on spline interpolation method and Savitzky-Golay filtering</article-title>. <source>Neurophotonics [Internet]</source>. <publisher-name>Neurophotonics</publisher-name>; <year>2018</year>
<month>Feb</month>
<day>8</day> [<date-in-citation>cited 2023 May 1</date-in-citation>];<volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>. <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/29430471/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/29430471/</ext-link></comment></mixed-citation></ref><ref id="R64"><label>64.</label><mixed-citation publication-type="journal"><name><surname>Swinehart</surname><given-names>DF</given-names></name>. <article-title>The Beer-Lambert Law</article-title>. <source>J Chem Educ</source>. <year>1962</year>;<volume>39</volume>(<issue>7</issue>):<fpage>333</fpage>.</mixed-citation></ref><ref id="R65"><label>65.</label><mixed-citation publication-type="book"><name><surname>Fang</surname><given-names>Q</given-names></name>, <name><surname>Yan</surname><given-names>S</given-names></name>. <article-title>MCX Cloud-a modern, scalable, high-performance and in-browser Monte Carlo simulation platform with cloud computing</article-title>. <source>J Biomed Opt [Internet]</source>. <publisher-name>J Biomed Opt</publisher-name>; <year>2022</year>
<month>Jan</month>
<day>5</day> [<date-in-citation>cited 2025 Mar 10</date-in-citation>];<volume>27</volume>(<issue>8</issue>). <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/34989198/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/34989198/</ext-link></comment></mixed-citation></ref><ref id="R66"><label>66.</label><mixed-citation publication-type="book"><name><surname>Yu</surname><given-names>L</given-names></name>, <etal/>
<source>Scalable and massively parallel Monte Carlo photon transport simulations for heterogeneous computing platforms</source>. <comment>https://doi.org/101117/1JBO231010504 [Internet].</comment>
<publisher-name>SPIE</publisher-name>; <year>2018</year>
<month>Jan</month>
<day>26</day> [<date-in-citation>cited 2025 Mar 10</date-in-citation>];<volume>23</volume>(<issue>1</issue>):<fpage>010504</fpage>. <comment>Available from: <ext-link xlink:href="https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-23/issue-1/010504/Scalable-and-massively-parallel-Monte-Carlo-photon-transport-simulations-for/10.1117/1.JBO.23.1.010504.full" ext-link-type="uri">https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-23/issue-1/010504/Scalable-and-massively-parallel-Monte-Carlo-photon-transport-simulations-for/10.1117/1.JBO.23.1.010504.full</ext-link></comment></mixed-citation></ref><ref id="R67"><label>67.</label><mixed-citation publication-type="book"><name><surname>Fang</surname><given-names>Q</given-names></name>, <name><surname>Boas</surname><given-names>DA</given-names></name>. <article-title>Monte Carlo simulation of photon migration in 3D turbid media accelerated by graphics processing units</article-title>. <source>Opt Express [Internet]</source>. <publisher-name>Optica Publishing Group</publisher-name>; <year>2009</year>
<month>Oct</month>
<day>26</day> [<date-in-citation>cited 2025 Mar 10</date-in-citation>];<volume>17</volume>(<issue>22</issue>):<fpage>20178</fpage>. <comment>Available from: <ext-link xlink:href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2863034/" ext-link-type="uri">https://pmc.ncbi.nlm.nih.gov/articles/PMC2863034/</ext-link></comment><pub-id pub-id-type="pmid">19997242</pub-id>
</mixed-citation></ref><ref id="R68"><label>68.</label><mixed-citation publication-type="book"><name><surname>Custo</surname><given-names>A</given-names></name>, <etal/>
<article-title>Anatomical atlas-guided diffuse optical tomography of brain activation</article-title>. <source>Neuroimage</source>. <publisher-name>Academic Press</publisher-name>; <year>2010</year>
<month>Jan</month>
<day>1</day>;<volume>49</volume>(<issue>1</issue>):<fpage>561</fpage>&#x02013;<lpage>567</lpage>.<pub-id pub-id-type="pmid">19643185</pub-id>
</mixed-citation></ref><ref id="R69"><label>69.</label><mixed-citation publication-type="book"><name><surname>Strangman</surname><given-names>G</given-names></name>, <name><surname>Boas</surname><given-names>DA</given-names></name>, <name><surname>Sutton</surname><given-names>JP</given-names></name>. <part-title>Non-invasive neuroimaging using near-infrared light</part-title>. <source>Biol Psychiatry</source>. <publisher-name>Elsevier</publisher-name>; <year>2002</year>
<month>Oct</month>
<day>1</day>;<volume>52</volume>(<issue>7</issue>):<fpage>679</fpage>&#x02013;<lpage>693</lpage>.<pub-id pub-id-type="pmid">12372658</pub-id>
</mixed-citation></ref><ref id="R70"><label>70.</label><mixed-citation publication-type="book"><name><surname>Zhao</surname><given-names>H</given-names></name>, <name><surname>Cooper</surname><given-names>RJ</given-names></name>. <article-title>Review of recent progress toward a fiberless, whole-scalp diffuse optical tomography system</article-title>. <source>Neurophotonics [Internet]</source>. <publisher-name>Society of Photo-Optical Instrumentation Engineers</publisher-name>; <year>2018</year>
<month>Sep</month>
<day>26</day> [<date-in-citation>cited 2021 Sep 30</date-in-citation>];<volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>. <comment>Available from: /pmc/articles/PMC5613216/</comment></mixed-citation></ref><ref id="R71"><label>71.</label><mixed-citation publication-type="book"><name><surname>Vidal-Rosas</surname><given-names>EE</given-names></name>, <etal/>
<source>Wearable, high-density fNIRS and diffuse optical tomography technologies: a perspective</source>. <comment>https://doi.org/101117/1NPh102023513 [Internet].</comment>
<publisher-name>SPIE</publisher-name>; <year>2023</year>
<month>May</month>
<day>17</day> [<date-in-citation>cited 2024 Jun 2</date-in-citation>];<volume>10</volume>(<issue>2</issue>):<fpage>023513</fpage>. <comment>Available from: <ext-link xlink:href="https://www.spiedigitallibrary.org/journals/neurophotonics/volume-10/issue-2/023513/Wearable-high-density-fNIRS-and-diffuse-optical-tomography-technologies/10.1117/1.NPh.10.2.023513.full" ext-link-type="uri">https://www.spiedigitallibrary.org/journals/neurophotonics/volume-10/issue-2/023513/Wearable-high-density-fNIRS-and-diffuse-optical-tomography-technologies/10.1117/1.NPh.10.2.023513.full</ext-link></comment></mixed-citation></ref><ref id="R72"><label>72.</label><mixed-citation publication-type="journal"><name><surname>Strangman</surname><given-names>GE</given-names></name>, <name><surname>Li</surname><given-names>Z</given-names></name>, <name><surname>Zhang</surname><given-names>Q</given-names></name>. <article-title>Depth Sensitivity and Source-Detector Separations for Near Infrared Spectroscopy Based on the Colin27 Brain Template</article-title>. <source>PLoS One [Internet]</source>. <year>2013</year>
<month>Aug</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>8</volume>(<issue>8</issue>):<fpage>e66319</fpage>. <comment>Available from: <ext-link xlink:href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3731322/" ext-link-type="uri">https://pmc.ncbi.nlm.nih.gov/articles/PMC3731322/</ext-link></comment><pub-id pub-id-type="pmid">23936292</pub-id>
</mixed-citation></ref><ref id="R73"><label>73.</label><mixed-citation publication-type="book"><name><surname>Harrison</surname><given-names>BJ</given-names></name>, <etal/>
<article-title>Task-Induced Deactivation from Rest Extends beyond the Default Mode Brain Network</article-title>. <source>PLoS One [Internet]</source>. <publisher-name>PLOS</publisher-name>; <year>2011</year> [<date-in-citation>cited 2023 May 3</date-in-citation>];<volume>6</volume>(<issue>7</issue>). <comment>Available from: /pmc/articles/PMC3146521/</comment></mixed-citation></ref><ref id="R74"><label>74.</label><mixed-citation publication-type="book"><name><surname>Chen</surname><given-names>Z</given-names></name>, <etal/>
<part-title>Lateralization difference in functional activity during Stroop tasks: a functional near-infrared spectroscopy and EEG simultaneous study</part-title>. <source>Front Psychiatry</source>. <publisher-name>Frontiers Media SA</publisher-name>; <year>2023</year>
<month>Aug</month>
<day>23</day>;<volume>14</volume>:<fpage>1221381</fpage>.<pub-id pub-id-type="pmid">37680451</pub-id>
</mixed-citation></ref><ref id="R75"><label>75.</label><mixed-citation publication-type="book"><name><surname>Nishizawa</surname><given-names>Y</given-names></name>, <etal/>
<article-title>fNIRS Assessment during an Emotional Stroop Task among Patients with Depression: Replication and Extension</article-title>. <source>Psychiatry Investig [Internet]</source>. <publisher-name>Korean Neuropsychiatric Association</publisher-name>; <year>2019</year>
<month>Jan</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 12</date-in-citation>];<volume>16</volume>(<issue>1</issue>):<fpage>80</fpage>. <comment>Available from: <ext-link xlink:href="https://pmc.ncbi.nlm.nih.gov/articles/PMC6354038/" ext-link-type="uri">https://pmc.ncbi.nlm.nih.gov/articles/PMC6354038/</ext-link></comment></mixed-citation></ref><ref id="R76"><label>76.</label><mixed-citation publication-type="book"><name><surname>Takizawa</surname><given-names>R</given-names></name>, <etal/>
<article-title>Neuroimaging-aided differential diagnosis of the depressive state</article-title>. <source>Neuroimage [Internet]</source>. <publisher-name>Elsevier Inc.</publisher-name>; <year>2014</year>;<volume>85</volume>:<fpage>498</fpage>&#x02013;<lpage>507</lpage>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.126</pub-id><pub-id pub-id-type="pmid">23764293</pub-id>
</mixed-citation></ref><ref id="R77"><label>77.</label><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>Y</given-names></name>, <etal/>
<article-title>Functional near-infrared spectroscopy (fNIRS) as a tool to assist the diagnosis of major psychiatric disorders in a Chinese population</article-title>. <source>Eur Arch Psychiatry Clin Neurosci [Internet]</source>. <year>2021</year> [<date-in-citation>cited 2021 Jul 13</date-in-citation>];<volume>271</volume>:<fpage>745</fpage>&#x02013; <lpage>757</lpage>. <comment>Available from: </comment><pub-id pub-id-type="doi">10.1007/s00406-020-01125-y</pub-id><pub-id pub-id-type="pmid">32279143</pub-id>
</mixed-citation></ref><ref id="R78"><label>78.</label><mixed-citation publication-type="book"><name><surname>Khan</surname><given-names>B</given-names></name>, <etal/>
<article-title>Improving optical contact for functional near-infrared brain spectroscopy and imaging with brush optodes</article-title>. <source>Biomed Opt Express [Internet]</source>. <publisher-name>Optica Publishing Group</publisher-name>; <year>2012</year>
<month>May</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 13</date-in-citation>];<volume>3</volume>(<issue>5</issue>):<fpage>878</fpage>. <comment>Available from: <ext-link xlink:href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3342194/" ext-link-type="uri">https://pmc.ncbi.nlm.nih.gov/articles/PMC3342194/</ext-link></comment><pub-id pub-id-type="pmid">22567582</pub-id>
</mixed-citation></ref><ref id="R79"><label>79.</label><mixed-citation publication-type="book"><name><surname>Song</surname><given-names>C</given-names></name>, <etal/>
<article-title>Augmented reality-based electrode guidance system for reliable electroencephalography</article-title>. <source>Biomed Eng Online [Internet]</source>. <publisher-name>BioMed Central Ltd.</publisher-name>; <year>2018</year>
<month>May</month>
<day>24</day> [<date-in-citation>cited 2024 Nov 13</date-in-citation>];<volume>17</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>10</lpage>. <comment>Available from: <ext-link xlink:href="https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/s12938-018-0500-x" ext-link-type="uri">https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/s12938-018-0500-x</ext-link></comment><pub-id pub-id-type="pmid">29310661</pub-id>
</mixed-citation></ref><ref id="R80"><label>80.</label><mixed-citation publication-type="book"><name><surname>Louis</surname><given-names>CC</given-names></name>, <etal/>
<article-title>Hair me out: Highlighting systematic exclusion in psychophysiological methods and recommendations to increase inclusion</article-title>. <source>Front Hum Neurosci [Internet]</source>. <publisher-name>Front Hum Neurosci</publisher-name>; <year>2022</year>
<month>Dec</month>
<day>8</day> [<date-in-citation>cited 2024 Nov 13</date-in-citation>];<volume>16</volume>. <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/36569470/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/36569470/</ext-link></comment></mixed-citation></ref><ref id="R81"><label>81.</label><mixed-citation publication-type="confproc"><name><surname>Etienne</surname><given-names>A</given-names></name>, <etal/>
<source>Novel Electrodes for Reliable EEG Recordings on Coarse and Curly Hair</source>. <conf-name>Annu Int Conf IEEE Eng Med Biol Soc [Internet]. Annu Int Conf IEEE Eng Med Biol Soc</conf-name>; <year>2020</year>
<month>Jul</month>
<day>1</day> [<date-in-citation>cited 2024 Nov 13</date-in-citation>];<volume>2020</volume>:<fpage>6151</fpage>&#x02013;<lpage>6154</lpage>. <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/33019375/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/33019375/</ext-link></comment></mixed-citation></ref><ref id="R82"><label>82.</label><mixed-citation publication-type="book"><name><surname>Y&#x000fc;cel</surname><given-names>MA</given-names></name>, <etal/>
<article-title>Inclusivity in fNIRS Studies: Quantifying the Impact of Hair and Skin Characteristics on Signal Quality with Practical Recommendations for Improvement</article-title>. <source>bioRxiv [Internet]</source>. <publisher-name>Cold Spring Harbor Laboratory</publisher-name>; <year>2024</year>
<month>Oct</month>
<day>28</day> [<date-in-citation>cited 2025 Mar 10</date-in-citation>];<comment>2024.10.28.620644</comment>. <comment>Available from: <ext-link xlink:href="https://www.biorxiv.org/content/10.1101/2024.10.28.620644v1" ext-link-type="uri">https://www.biorxiv.org/content/10.1101/2024.10.28.620644v1</ext-link></comment></mixed-citation></ref><ref id="R83"><label>83.</label><mixed-citation publication-type="journal"><name><surname>Zhai</surname><given-names>X</given-names></name>, <name><surname>Santosa</surname><given-names>H</given-names></name>, <name><surname>Huppert</surname><given-names>TJ</given-names></name>. <article-title>Using anatomically defined regions-of-interest to adjust for head-size and probe alignment in functional near-infrared spectroscopy</article-title>. <source>Neurophotonics [Internet]</source>. <comment>Neurophotonics</comment>; <year>2020</year>
<month>Sep</month>
<day>23</day> [<date-in-citation>cited 2024 Nov 13</date-in-citation>];<volume>7</volume>(<issue>3</issue>). <comment>Available from: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/32995360/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/32995360/</ext-link></comment></mixed-citation></ref></ref-list></back><floats-group><fig position="float" id="F1"><label>Figure 1:</label><caption><p id="P85">For each of the Sparse and High-Density (HD) probe design columns display physical appearance, sensitivity matrices via Monte-Carlo photon path modeling with probe overlay (red dots: sources, blue dots: detectors, pink lines: emphasize &#x02018;grid&#x02019; layout of sparse array&#x02019;s 30mm channels, black/white lines: emphasize &#x02018;hexagonal&#x02019; layout of HD array&#x02019;s 19mm/33mm channels), and Brodmann areas underlying each channel. Sensitivity profile is on a log 10 scale; vertices with values &#x0003e; 0.01 are not masked and not considered part of the relevant sensitivity profile.</p></caption><graphic xlink:href="nihpp-2025.03.12.642917v1-f0001" position="float"/></fig><fig position="float" id="F2"><label>Figure 2:</label><caption><p id="P86">Word-Color Stroop paradigm adapted from Jahani, et al. After instruction and initial rest, 18 blocks of 6x3-s trials each were presented with a jittered inter-block interval (10-15 s). A given block consisted of either all congruent (Easy) trials, or all incongruent (Difficult) trials. The lower-right legend demonstrates accurate user keyboard press for each condition. Order of blocks was randomized for a total of 9 blocks of each condition. Total run time approximates 11min.</p></caption><graphic xlink:href="nihpp-2025.03.12.642917v1-f0002" position="float"/></fig><fig position="float" id="F3"><label>Figure 3:</label><caption><p id="P87">Channels and vertices selected in the region of interest for the Sparse and HD array. On the left panel, black dots mark the center of each channel included in the ROIs. On the right panel, black lines indicate the channels included in the ROIs and the white (unshaded) region of the brain indicates the vertices included. Vertices for both arrays are chosen based on those sensitive to the HD ROI channels.</p></caption><graphic xlink:href="nihpp-2025.03.12.642917v1-f0003" position="float"/></fig><fig position="float" id="F4"><label>Figure 4:</label><caption><p id="P88">Channel space brain response recorded by Sparse and HD arrays during WCS, from Superior view. &#x0201c;HbO Mean&#x0201d;: Group-average hemodynamic response (HbO) for each channel, averaged across 7 to 18 seconds of the blocks for each condition. &#x0201c;T-statistic&#x0201d;: Group-averaged t-statistic of each channel is plotted. Color-scale is grey for absolute values less than t-crit = 2.12 as calculated for 17 subjects.</p></caption><graphic xlink:href="nihpp-2025.03.12.642917v1-f0004" position="float"/></fig><fig position="float" id="F5"><label>Figure 5:</label><caption><p id="P89">Brain and scalp image space brain response recorded by Sparse and HD arrays during WCS, from Anterior view. &#x0201c;HbO Mean&#x0201d;: Group-average hemodynamic response (HbO) for each condition. &#x0201c;T-statistic&#x0201d;: Group-averaged t-statistic of each vertex is plotted. Color-scale is grey for absolute values less than t-crit = 2.12 as calculated for 17 subjects.</p></caption><graphic xlink:href="nihpp-2025.03.12.642917v1-f0005" position="float"/></fig><fig position="float" id="F6"><label>Figure 6:</label><caption><p id="P90">From within the ROIs, group-averaged HbO maximum t-statistics are presented in both channel and brain and scalp image space for each array and WCS conditions. T-critical is 2.12, as calculated for 17 subjects with two-tailed &#x003b1;=0.05. Asterisk indicates p &#x0003c; 0.05 for paired Student&#x02019;s t-test between arrays (black) and conditions (blue). The subjects&#x02019; selected channel or averaged 25 vertices&#x02019; concentration time courses are averaged for the timeseries plots. Numerical average, standard error, and paired Student&#x02019;s t-test values available in <xref rid="SD1" ref-type="supplementary-material">Table S3</xref>.</p></caption><graphic xlink:href="nihpp-2025.03.12.642917v1-f0006" position="float"/></fig><table-wrap position="float" id="T1"><label>Table 1:</label><caption><p id="P91">Channel signal quality metrics are provided in terms of mean and standard deviation across subjects. Congruent and incongruent WCS blocks are blocks remaining after rejections due to motion artifacts. * for p &#x0003c; 0.05, ** for p &#x0003c; 0.01, *** for p &#x0003c; 0.001 by paired t-test.</p></caption><table frame="void" rules="none"><colgroup span="1"><col align="center" valign="middle" span="1"/></colgroup><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<graphic xlink:href="nihpp-2025.03.12.642917v1-t0007" position="float"/>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="T2"><label>Table 2:</label><caption><p id="P92">Performance metrics are provided as average across subjects&#x02019; trial averages. Three asterisks indicate p &#x0003c; 0.001</p></caption><table frame="void" rules="none"><colgroup span="1"><col align="center" valign="middle" span="1"/></colgroup><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<graphic xlink:href="nihpp-2025.03.12.642917v1-t0008" position="float"/>
</td></tr></tbody></table></table-wrap></floats-group></article>