<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS One</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40397863</article-id><article-id pub-id-type="pmc">PMC12094754</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0323490</article-id><article-id pub-id-type="publisher-id">PONE-D-24-39822</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Nonverbal Communication</subject><subj-group><subject>Facial Expressions</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Nonverbal Communication</subject><subj-group><subject>Facial Expressions</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Industrial Engineering</subject><subj-group><subject>Control Engineering</subject><subj-group><subject>Automation</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Mental Health and Psychiatry</subject><subj-group><subject>Mental Health Therapies</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Computers</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Clinical Psychology</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Clinical Psychology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Clinical Psychology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Computer Networks</subject><subj-group><subject>Internet</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Emotional engagement and perceived empathy in live vs. automated psychological interviews</article-title><alt-title alt-title-type="running-head">Live vs. automated psychological interviews</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6409-2528</contrib-id><name><surname>Nyman</surname><given-names>Thomas J.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="aff004" ref-type="aff">
<sup>4</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Noromies</surname><given-names>Anna-Karin</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9253-0049</contrib-id><name><surname>Pompedda</surname><given-names>Francesco</given-names></name><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff005" ref-type="aff">
<sup>5</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Santtila</surname><given-names>Pekka</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="aff004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Antfolk</surname><given-names>Jan</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>School of Psychology and Clinical Language Sciences, University of Reading, Reading, United Kingdom</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>Faculty of Arts, Psychology and Theology, &#x000c5;bo Akademi University, Turku, Finland</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Faculty of Arts and Sciences, New York University Shanghai, Shanghai, People&#x02019;s Republic of China</addr-line></aff><aff id="aff004"><label>4</label>
<addr-line>Shanghai Frontiers Science Center of Artificial Intelligence and Deep Learning, New York University Shanghai, Shanghai, People&#x02019;s Republic of China</addr-line></aff><aff id="aff005"><label>5</label>
<addr-line>INVESThub, INVEST Research Flagship Centre, University of Turku, Turku, Finland</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Khan</surname><given-names>Iftikhar Ahmed</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>University of Lahore - Raiwind Road Campus: The University of Lahore, PAKISTAN</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>t.nyman@reading.ac.uk</email></corresp></author-notes><pub-date pub-type="epub"><day>21</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>20</volume><issue>5</issue><elocation-id>e0323490</elocation-id><history><date date-type="received"><day>18</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>8</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 Nyman et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Nyman et al</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0323490.pdf">
</self-uri><abstract><p>In clinical in-person conditions, social presence, perceived empathy, and emotional engagement are related to positive outcomes. In online settings, it is unclear how these factors affect outcomes. Here, in 10&#x02013;15-minute interviews, we investigated the influence of automation. Participants (<italic toggle="yes">N</italic>&#x02009;=&#x02009;75) engaged in one of three possible interviews: live semi-scripted, live scripted, or video scripted. In the first two, participants communicated with a live interviewer and, in the third, with pre-recorded interviewer questions and answers. Emotion recognition software revealed that expressed joy differed between conditions (<italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) = 18.08, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001); both live conditions had higher scores (vs. video scripted). Self-rated perceived interviewer empathy also differed between conditions in the same way (<italic toggle="yes">F</italic>[2, 72] = 9.445, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;0.001). We found a positive correlation between perceived empathy and expressed joy (<italic toggle="yes">r</italic>&#x02009;=&#x02009;.35; <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.01). In sum, automatized interviews differed in perceived empathy and expressed emotion compared with live interviews.</p></abstract><funding-group><funding-statement>The author(s) received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="3"/><table-count count="0"/><page-count count="22"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The data and analyses code associated with this article is freely available at the open science framework, and can be retrieved via the following URL: <ext-link xlink:href="https://osf.io/gnbp2/" ext-link-type="uri">https://osf.io/gnbp2/</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The data and analyses code associated with this article is freely available at the open science framework, and can be retrieved via the following URL: <ext-link xlink:href="https://osf.io/gnbp2/" ext-link-type="uri">https://osf.io/gnbp2/</ext-link>.</p></notes></front><body><sec id="sec001"><title>Introduction</title><p>According to the World Health Organization (WHO), globally one in eight individuals suffer from a mental disorder, with an estimated yearly cost of approximately $2.5 trillion in 2010, which is expected to rise to $6 trillion by 2030 [<xref rid="pone.0323490.ref001" ref-type="bibr">1</xref>]. The efficacies of psychological and psychotherapeutic treatments and interventions have been well established [<xref rid="pone.0323490.ref002" ref-type="bibr">2</xref>], nevertheless access is limited with less than 50%, and in some countries less than 10%, of individuals suffering from mental disorders receiving adequate treatment. The problem has been aggravated by the negative effects of increased waiting times [<xref rid="pone.0323490.ref003" ref-type="bibr">3</xref>,<xref rid="pone.0323490.ref004" ref-type="bibr">4</xref>] and, more recently, during the COVID-19 pandemic due to the global disruption in mental health services [<xref rid="pone.0323490.ref005" ref-type="bibr">5</xref>]. Finding new ways of reaching those in need of psychological treatment and offering evidence-based interventions is becoming increasingly important. Digital mental health interventions (DMHIs) present one clear path to providing such interventions [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>]. The key components in successful psychological therapies include the therapeutic alliance and the emotional engagement of both the therapist and the client [<xref rid="pone.0323490.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0323490.ref008" ref-type="bibr">8</xref>]. Consequently, research is still needed to understand how to successfully deliver online interventions and to what extent this process, at least in some cases, can be automatized [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>].</p><p>The present study aimed to investigate how the automation of a human presence in a 10&#x02013;15-minute online psychological interview on wellbeing affects factors that are central to the therapeutic alliance; that is, the emotional engagement and reactions of the interviewees and the empathy they perceived from the interviewer. To achieve this aim, we created three conditions ranging from a normal online interview (live semi-scripted), a more rigid interview (live scripted), and an automated condition (video scripted). In each interview condition, we used pre and post self-reports and objective emotion recognition software to measure the reactions of the interviewees and their perceptions of the interviewer.</p><sec id="sec002"><title>Digital mental health interventions</title><p>Internet-based technology offers ways to overcome some of the barriers that can hinder the possibility of receiving face-to-face treatment (e.g., physical travel distance to clinics or hospitals), which has prompted research on internet-based mental health interventions [<xref rid="pone.0323490.ref009" ref-type="bibr">9</xref>]. Overall, digital mental health interventions (DMHIs) have evolved over the past 25 years [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>] and can offer several benefits relative to traditional face-to-face interventions. For example, they can be delivered through personal devices and potentially to any location at any time, which is crucial for those who do not currently have access to mental health treatment [<xref rid="pone.0323490.ref010" ref-type="bibr">10</xref>,<xref rid="pone.0323490.ref011" ref-type="bibr">11</xref>]. Some DMHIs (e.g., internet-based cognitive behavioral therapy) are presently as effective as traditional face-to-face interventions and many researchers and practitioners are advocating that they be researched and utilized to a greater degree [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0323490.ref012" ref-type="bibr">12</xref>&#x02013;<xref rid="pone.0323490.ref014" ref-type="bibr">14</xref>].</p><p>To date, one of the most widely studied online methods is internet-based cognitive behavioral therapy (iCBT), which has been found to be as effective as face-to-face interventions for a variety of different psychiatric conditions (e.g., phobias and social anxiety), demonstrating both short-term and long-term effects [<xref rid="pone.0323490.ref015" ref-type="bibr">15</xref>]. This approach is based on cognitive behavioral therapy, an evidence-based treatment method that focuses on improving the way an individual feels by challenging unhelpful thoughts and behaviors, which can help them overcome psychological problems [<xref rid="pone.0323490.ref016" ref-type="bibr">16</xref>]. Research on internet-based interventions indicates that the effectiveness and adherence to internet-based interventions can be improved by human support [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0323490.ref017" ref-type="bibr">17</xref>].</p><p>Nevertheless, studies on unguided or automated internet-based interventions delivered by a computer or mobile phone with no human input or presence have also been found to be effective [<xref rid="pone.0323490.ref018" ref-type="bibr">18</xref>&#x02013;<xref rid="pone.0323490.ref022" ref-type="bibr">22</xref>]. It has even been found that such methods can have long-term effects [<xref rid="pone.0323490.ref023" ref-type="bibr">23</xref>]. However, adherence to unguided interventions can often be low [<xref rid="pone.0323490.ref017" ref-type="bibr">17</xref>,<xref rid="pone.0323490.ref024" ref-type="bibr">24</xref>&#x02013;<xref rid="pone.0323490.ref028" ref-type="bibr">28</xref>]. Attempts have been made to improve automated interventions by including a simulated human presence (i.e., a virtual representation of a psychologist) and this has been proven to foster a therapeutic relationship with the program [<xref rid="pone.0323490.ref029" ref-type="bibr">29</xref>&#x02013;<xref rid="pone.0323490.ref031" ref-type="bibr">31</xref>]. For example, Pinto and colleagues [<xref rid="pone.0323490.ref030" ref-type="bibr">30</xref>,<xref rid="pone.0323490.ref031" ref-type="bibr">31</xref>] found that participants experienced a sense of rapport and social presence with the simulated avatar of a health-care professional. Their results show that the group who interacted with the avatar had significantly fewer depression symptoms compared to the attentional control group (receiving a computer-based health education). Pinto and colleagues [<xref rid="pone.0323490.ref031" ref-type="bibr">31</xref>] speculated that this could be related to the interaction with the avatar.</p><p>In traditional face-to-face therapies, the therapeutic relationship formed with the therapist predicts a positive treatment outcome [<xref rid="pone.0323490.ref008" ref-type="bibr">8</xref>] and it is likely that this is also an important factor in internet-based interventions. However, research on online methods, such as iCBT, indicates that online approaches may not always require live human support to be effective and that simulated human presence can be as effective as a traditional method. This highlights the need to further understand the role that human presence plays in online treatment processes and the minimum amount and form of presence necessary for a treatment to be effective. Indeed, while guided online interventions often result in better outcomes, and are favored by clients [<xref rid="pone.0323490.ref032" ref-type="bibr">32</xref>,<xref rid="pone.0323490.ref033" ref-type="bibr">33</xref>], they are less scalable, more expensive and more difficult to implement compared to unguided interventions [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0323490.ref033" ref-type="bibr">33</xref>,<xref rid="pone.0323490.ref034" ref-type="bibr">34</xref>]. Automated programs are an attractive alternative to traditional methods since they would be a cost-effective alternative offered to individuals that may otherwise be placed on a waiting list. Nevertheless, although internet-based interventions show promise as alternative methods for treating less complex psychological problems, online methods may not necessarily be suitable for more severe psychological problems [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0323490.ref035" ref-type="bibr">35</xref>].</p></sec><sec id="sec003"><title>Social presence in clinical interactions</title><p>An essential aspect of the human-computer interaction is the subjective experience of contact with the real or artificial other, also referred to as social presence [<xref rid="pone.0323490.ref036" ref-type="bibr">36</xref>]. Social presence has been shown to contribute to positive communication outcomes in mediated environments [<xref rid="pone.0323490.ref037" ref-type="bibr">37</xref>], thus making it relevant to the design of computer programs in health care and technologies simulating clinical interactions [<xref rid="pone.0323490.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0323490.ref036" ref-type="bibr">36</xref>]. A technological feature that influences the sense of social presence is the communication modality used [<xref rid="pone.0323490.ref037" ref-type="bibr">37</xref>]. It has, for example, been found that text-based computer-mediated communication (CMC) evokes less social presence than richer forms of media (e.g., video, audio, or avatar) [<xref rid="pone.0323490.ref038" ref-type="bibr">38</xref>]. Studies have, however, shown that with longer interactions even media with richer social cues can evoke an equally viable sense of social presence and contact that is comparable with to face-to-face interactions. This is because individuals adapt to less rich social cues and take on other communication strategies such as direct questioning or self-disclosure [<xref rid="pone.0323490.ref039" ref-type="bibr">39</xref>&#x02013;<xref rid="pone.0323490.ref041" ref-type="bibr">41</xref>].</p><p>Another important influential factor on social presence is visual representation. Previous research has concluded that the extent to which a visual representation performs in a similar manner to a human being (i.e., behavioral realism) has positive effects on perceived social presence [<xref rid="pone.0323490.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0323490.ref042" ref-type="bibr">42</xref>,<xref rid="pone.0323490.ref043" ref-type="bibr">43</xref>]. For example, Von Der P&#x000fc;tten and colleagues [<xref rid="pone.0323490.ref043" ref-type="bibr">43</xref>] found that participants felt a higher social presence when a computerized agent nodded its head compared to an agent that did not. Similar effects have also been found for maintenance of mutual eye contact [<xref rid="pone.0323490.ref038" ref-type="bibr">38</xref>], and a virtual agent blushing strongly after making a mistake during a presentation [<xref rid="pone.0323490.ref042" ref-type="bibr">42</xref>]. Researchers have also shown that the effect of behavioral realism is dependent on the appearance of the representation. For example, the more realistic a representation looks, the more realistic its behavior needs to be in order for a higher social presence to be evoked [<xref rid="pone.0323490.ref044" ref-type="bibr">44</xref>,<xref rid="pone.0323490.ref045" ref-type="bibr">45</xref>].</p><p>To date, there is no widely accepted, validated, and generalized measure of presence across varied media or settings, due to the different existing conceptualizations of presence [<xref rid="pone.0323490.ref044" ref-type="bibr">44</xref>]. Nevertheless, social presence has often been operationalized either in terms of an individual&#x02019;s perceptions that another person is present or in terms of an individual&#x02019;s social response to the other [<xref rid="pone.0323490.ref044" ref-type="bibr">44</xref>]. In the present study, we did not explicitly evaluate social presence but instead manipulated the social presence of the interviewer through an experimental design (live semi-scripted, live scripted, or video scripted). We then asked participants to self-rate their own emotional engagement and to rate the perceived empathy of the interviewer. We also measured the emotional reactions of the interviewees during the interactions.</p></sec><sec id="sec004"><title>The therapeutic alliance, emotional engagement, and perceived empathy</title><p>It has been shown that a strong therapeutic alliance or relationship (i.e., the emotional bond and agreement concerning the tasks and goals of the treatment between the client and the therapist) is an important predictor of positive outcomes in traditional face-to-face psychotherapy and counselling [<xref rid="pone.0323490.ref008" ref-type="bibr">8</xref>]. A central element of the therapeutic alliance is the emotional engagement of both the therapist and the client, and it has also been shown that the empathic ability of the therapist is a predictor of a client&#x02019;s progress [<xref rid="pone.0323490.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0323490.ref008" ref-type="bibr">8</xref>]. Moreover, the perception of a therapist as empathetic contributes to the development of a positive therapeutic alliance [<xref rid="pone.0323490.ref046" ref-type="bibr">46</xref>,<xref rid="pone.0323490.ref047" ref-type="bibr">47</xref>] and promotes therapeutic change by facilitating client initiative, social interaction, and engagement [<xref rid="pone.0323490.ref047" ref-type="bibr">47</xref>].</p><p>Interestingly, it is specifically the perceived empathy by clients or patient rather than by observers or therapists that has been shown to be a medium-sized predictor of therapeutic outcomes [<xref rid="pone.0323490.ref007" ref-type="bibr">7</xref>]. This highlights the importance of the perceiver&#x02019;s experience in face-to-face therapy. However, empathy is a complex concept [<xref rid="pone.0323490.ref048" ref-type="bibr">48</xref>] and knowing how and when (and when not) to explicitly display empathetic behavior in an interaction is a skill that denotes sensitivity to the individual, the context, and the working relationship [<xref rid="pone.0323490.ref007" ref-type="bibr">7</xref>]. Moreover, a therapeutic process does not only entail displays of empathy but may also include instances of challenging the thoughts and judgements of a client or patient [<xref rid="pone.0323490.ref049" ref-type="bibr">49</xref>], which further illustrating that how to act as a therapist requires skill. Lastly, considering that empathy is more of a co-production between therapist and client or patient rather than something solely displayed by a therapist [<xref rid="pone.0323490.ref007" ref-type="bibr">7</xref>], it is also important to consider that there are metaperceptual aspects to judging what another is thinking. Here, findings show that the metaperception of an individual concerning another&#x02019;s thoughts of them can be a substantial source of error [<xref rid="pone.0323490.ref050" ref-type="bibr">50</xref>]. Therefore, perceived empathy may also be associated with differences in the ability of an individual, such as a client or patient, to evaluate the empathy displayed by another, such as a therapist. Overall, there is still much research needed to understand the role of perceived empathy in therapeutic contexts.</p><p>In studies on guided internet-based interventions, it has been found that the working alliance (i.e., the agreement on tasks and goals of the treatment) has been rated to be as positive and as stable as that in face-to-face interactions [<xref rid="pone.0323490.ref051" ref-type="bibr">51</xref>&#x02013;<xref rid="pone.0323490.ref053" ref-type="bibr">53</xref>]. However, in internet-based interventions the working alliance can rarely be considered to be a predictor of a positive outcome [<xref rid="pone.0323490.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0323490.ref054" ref-type="bibr">54</xref>]. For example, Knaevelsrud and Maercker [<xref rid="pone.0323490.ref051" ref-type="bibr">51</xref>] found that the alliance in a guided iCBT program for posttraumatic stress reactions was not as clearly related to the outcome compared to face-to-face approaches, despite high ratings of a therapeutic alliance. It has also been found that a client can develop a relationship with a computer program [<xref rid="pone.0323490.ref055" ref-type="bibr">55</xref>&#x02013;<xref rid="pone.0323490.ref058" ref-type="bibr">58</xref>]. This relationship is possible because individuals tend to treat computers as social beings, a tendency that is known as the Computers as Social Actors (CASA) paradigm, which implies that an individual reacts to the social cues provided by a computer, an avatar, or an algorithm [<xref rid="pone.0323490.ref059" ref-type="bibr">59</xref>&#x02013;<xref rid="pone.0323490.ref061" ref-type="bibr">61</xref>]. While people attribute social responses to computers, little is known whether computer interactions are perceived as empathetic and emotionally engaging. As computer interactions are becoming more frequently used in clinical interactions, knowledge about how they are perceived and experienced is required due to their increasing significance in clinical interactions.</p></sec><sec id="sec005"><title>The current study and hypotheses</title><p>The current study had two main aims: First, in 10&#x02013;15-minute online psychological interviews on wellbeing, we investigated whether the pre- and post-measures of valence and activation, emotional reactions, and perceptions of empathy differed when participants interacted with a live semi-scripted online interviewer (live semi-scripted condition) versus an automated interviewer (live video scripted condition). In the live semi-scripted condition, the participants were seated in a laboratory in front of a computer and communicated online with a live interviewer. Here, the interviewer used a semi-scripted approach to ask and answer questions in the online interview. In the live video scripted condition, the participants were also seated in a laboratory in front of a computer, but here they were communicating with pre-recorded video clips and not a live human being. They were not informed that they were interacting with pre-recorded video clips. Instead, we simulated a live online discussion by presenting participants with a seamless integration of pre-recorded video clips of questions and answers. The pre-recorded questions and answers were recordings of the same interviewer as in the live semi-scripted condition. During the live video scripted condition, the test instructor (not visible to the participant) listened to what the responses of the participant and selected, in accordance with a decision-logic, what pre-recorded question or answer clips to present to the participant. In this way, we simulated an automatized online discussion and participants were led to believe that they were conversing with a real human being.</p><p>Second, we wanted to compare the live semi-scripted condition to a live scripted condition. In the live scripted condition, the participants were seated in a laboratory in front of a computer and communicated online with a live interviewer. However, here the interviewer was not as free to choose answers as in the semi-scripted condition. Instead, the live scripted condition followed the same decision-logic as the video scripted condition. We added the live scripted condition to evaluate the difference between the decision-logic and the video presentation. Consequently, if the live semi-scripted gave rise to different emotional reactions or engagement or perceived empathy, we wanted to understand if that was due to the format (i.e., the pre-recordings) or the script (i.e., the decision-logic). Our setup resulted in three computer-based online interview conditions: 1) live semi-scripted, 2) live scripted, 3) video scripted.</p><p>Furthermore, in accordance with the CASA paradigm [<xref rid="pone.0323490.ref059" ref-type="bibr">59</xref>], we assumed that the interviewee would interact with the automated interviewer (i.e., video scripted condition) as if communicating with a live interviewer. Thus, we expected that the video scripted condition would elicit similar reactions and emotional engagement in the participant as in the live conditions, consistent with studies on social reactions to computers and avatars [<xref rid="pone.0323490.ref043" ref-type="bibr">43</xref>,<xref rid="pone.0323490.ref062" ref-type="bibr">62</xref>]. This was also because the interviews were short and highly consistent. However, we also assumed that the live interactions would contain richer social cues compared to the automated interaction (i.e., video scripted condition) and could thus evoke a higher social presence. The rigidity of the interaction in the video scripted condition might negatively affect the feeling of social presence, as the interaction would be less spontaneous and natural. Overall, we expect the conditions to evoke similar responses, however, if the rigidity was found to lead to a decreased perception of social presence or engagement, we should be able to detect differences between by comparing all three conditions. Additionally, we wanted to investigate whether self-rated emotional engagement, emotional reactions, and perceptions of interviewer empathy correlated positively. This was in part because previous research has shown that perceived empathy contributes to an overall positive alliance [<xref rid="pone.0323490.ref046" ref-type="bibr">46</xref>,<xref rid="pone.0323490.ref047" ref-type="bibr">47</xref>]. Our hypotheses were that the increased automation of presence (i.e., less rich social cues) would lead to the following:</p><statement><p>Hypothesis 1 (H1): Lower self-rated emotional engagement by the interviewees.</p></statement><statement><p>Hypothesis 2 (H2): Lower positive emotional reactions from interviewees.</p></statement><statement><p>Hypothesis 3 (H3): Lower ratings of perceived empathy of the interviewer.</p></statement><p>To summarize, in all three hypotheses (H1-H3), we expected the live semi-scripted condition to evoke the highest ratings of perceived emotional engagement, emotional reactions, and perceptions of empathy, followed by lower ratings in the live scripted condition, and the lowest ratings in the video scripted condition. However, based on studies on social reactions to computers and avatars [<xref rid="pone.0323490.ref043" ref-type="bibr">43</xref>,<xref rid="pone.0323490.ref062" ref-type="bibr">62</xref>], we also included an alternative consideration &#x02013; that we might not detect differences between conditions. This might be the case if the video scripted condition would elicit similar reactions and emotional engagement in the participant as in the live conditions. Additionally, we also hypothesized that:</p><statement><p>Hypothesis 4 (H4): There will be a positive correlation between engagement, reactions, and perceived empathy.</p></statement></sec></sec><sec id="sec006"><title>Methods</title><sec id="sec007"><title>Participants</title><p>The participants were contacted through mailing lists at universities and vocational schools, through social media, and by recruitment in the university canteen. Our sample consists of 75 Swedish-speaking students recruited at &#x000c5;bo Akademi University. The recruitment and testing took place from 25/10/2017&#x02013;20/03/2018. The sample consists of 49 female participants (<italic toggle="yes">M</italic><sub>age</sub>&#x02009;=&#x02009;22.67, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;2.31) and 25 male participants (<italic toggle="yes">M</italic><sub>age</sub>&#x02009;=&#x02009;24.68, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;6.12). One participant did not report age or gender. The age of the participants ranged from 19 to 52 years (<italic toggle="yes">M</italic><sub>age</sub>&#x02009;=&#x02009;23.35, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;4.09; <italic toggle="yes">n</italic>&#x02009;=&#x02009;74). The participants were pseudo-randomized into three separate experimental conditions with 25 participants per condition: 1) the live semi-scripted group (<italic toggle="yes">M</italic><sub>age</sub>&#x02009;=&#x02009;24.04, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;6.17, female&#x02009;=&#x02009;19, male&#x02009;=&#x02009;6), 2) the live scripted group (<italic toggle="yes">M</italic><sub>age</sub>&#x02009;=&#x02009;23.24, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;2.77, female&#x02009;=&#x02009;17, male&#x02009;=&#x02009;8), and 3) the video scripted group (<italic toggle="yes">M</italic><sub>age</sub>&#x02009;=&#x02009;22.75, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;2.11, female&#x02009;=&#x02009;13, male&#x02009;=&#x02009;11). Participants received a lunch coupon for their participation.</p></sec><sec id="sec008"><title>Ethics statement</title><p>All participants were informed of the voluntary nature of the studies, their right to end their participation at any stage (without giving a reason), and a written and fully informed consent was obtained from all participants. The current study was approved by the Research Ethics Committee of Psychology and Logopedics at &#x000c5;bo Akademi University.</p></sec><sec id="sec009"><title>Design</title><p>The experimental setup was a between-subjects design with three conditions: 1) live semi-scripted, 2) live scripted, and 3) video scripted. In the live semi-scripted condition, participants were seated in a laboratory and interviewed live via a computer by a psychologist graduate student who followed a pre-defined and fixed order list of questions and answers (see Procedure). In this condition, the interviewer could respond by freely validating or paraphrasing the interviewee&#x02019;s responses either non-verbally or verbally before continuing to the next question. The interview was conducted as a video call (including both audio and video). In the live scripted condition, participants were also seated in a laboratory and interviewed live via a computer by a psychologist graduate student. Here, during the video call the interviewer was verbally limited to six pre-defined answers and used a decision-logic to decide which answer to give (see Procedure). Lastly, in the video scripted condition, participants were seated in a laboratory and interviewed live via a computer by pre-recorded video clips that were seamlessly presented on the computer screen to mimic a live video call interview. Each pre-recorded video clip was played on the screen by the test instructor who was listening to (but could not see) the participants responses. The video clips to be played (i.e., the pre-recordings of the interviewer questions and answers) followed the same order as the live semi-scripted and scripted condition. Additionally, the presentation of the video clips was limited to the same six pre-defined interviewer answers as in the live scripted condition. The test instructor used the same decision-logic to decide which response to play as was used in the live scripted condition. The participants were not informed that they were interacting with pre-recorded video clips in the video scripted condition but were instead informed that they would participate in a live video call interview for all conditions. The test instructor was the same person as the interviewer and all interviews (live and video) included the same interviewer.</p><p>The independent variable was the automation of presence (i.e., richness of social cues) and was represented by the degree to which the answers followed a decision-logic that was lenient (live semi-scripted) or rigid (live scripted and video scripted) and to what extent the interview was conducted by a live human (live scripted and live scripted) or represented by pre-recorded video clips (video scripted). The dependent variables were the participant self-ratings of emotional engagement, emotional expressions during the experiment, and post-interview ratings of the degree to which the interviewer was empathic.</p></sec><sec id="sec010"><title>Materials</title><p>We used an iMac desktop (24-inch, 1920x1200, early 2009) and a Hewlett Packard desktop (HP Compac 8200 Elite MT PC) to conduct the interviews in all three conditions. To conduct the live interviews, we used the website <italic toggle="yes">Doxy.me</italic> (&#x000a9; Doxy.me, LLC 2014). <italic toggle="yes">Doxy.me</italic> was chosen since it was considered to comply with HIPAA (the Health Insurance Portability and Accountability Act) and HITECH (the Health Information Technology for Economic and Clinical Health). HIPAA is a standard for privacy and security rules that protect patient data.</p><p>For the video interview, we filmed the interview questions and responses using a digital camera (Canon EOS 1300D; lens: Canon EF 50mm f/1.8). The video recordings were recorded to capture the psychology student from shoulder-height upwards and were edited with <italic toggle="yes">OpenShot Video Editor</italic>. In total, the recorded material consisted of 27 video clips, which included four clips of the introductory part of the interview, 14 clips of the main interview questions, one clip that functioned as a bridge when changing the theme in the interview (i.e., to produce a seamless viewing experience when presenting different clips), one clip that was the concluding part of the interview, six clips representing the different interviewer responses, and one clip that functioned as a dynamic background clip. To simulate the live scripted interview, we further edited the video-clips and then displayed them using <italic toggle="yes">Resolume Arena 5</italic> so that the video clips could transition seamlessly during the interview. In the <italic toggle="yes">Resolume Arena 5</italic> software tool we created a composition of video clips organized in layers and in the desired order. The test instructor operated this simulation remotely in the video scripted condition.</p></sec><sec id="sec011"><title>Measures</title><sec id="sec012"><title>Symptoms of depression.</title><p>We used a Swedish translation of the Patient Health Questionnaire (PHQ-9) to investigate the intensity of symptoms of depression during the previous two weeks. We included this measure because depression has been shown to reduce emotional responses [<xref rid="pone.0323490.ref063" ref-type="bibr">63</xref>]. We chose the PHQ-9 measure since it is suitable as a screening tool for depression in research settings and shows good validity and reliability [<xref rid="pone.0323490.ref064" ref-type="bibr">64</xref>]. The answers were scored on a four-point Likert-type scale ranging from 0 (not at all) to 3 (almost every day), with a total score ranging from 0 to 27. Scores ranging from 0&#x02013;4 are categorized as minimal, 5&#x02013;9 as mild, 10&#x02013;14 as moderate, 15&#x02013;19 as moderately severe, and 20&#x02013;27 as severe [<xref rid="pone.0323490.ref064" ref-type="bibr">64</xref>]. In addition, we also collected the following demographic data: gender, age, as well as previous experience of counselling or psychotherapy. The last of which was collected because experience of interaction with a mental health professional could affect the expectations of the participants and thus also affect the perceptions of and reactions of the participant toward the interviewer. The demographic data were obtained via a background questionnaire.</p></sec><sec id="sec013"><title>The self-rated emotional engagement of the interviewees.</title><p>To assess the emotional engagement of the participants (H1), we measured self- reported emotional engagement and facial expressions. We assessed the perceived emotional state of the participants using the self-report measure Swedish Core and Affect Scale (SCAS), administered before and after the interview. This tool was used because all interviews were conducted in Swedish. The SCAS measures the valence and activation of the current mood of the individual based on an affect grid [<xref rid="pone.0323490.ref065" ref-type="bibr">65</xref>]. The 12 pre and 12 post items are graded on a 9-point Likert-type scale ranging from (-) 4 to (+) 4, with the end points of the scale defined by adjective pairs (e. g., sad-glad, bored-interested, engaged-disengaged). In the SCAS measure, participants are asked to rate how they felt at that very moment (at both pre and post interview) regarding the following items: 1) displeased&#x02013;pleased 2) sad&#x02013;glad, 3) depressed&#x02013;happy, 4) sleepy&#x02013;awake, 5) dull&#x02013;peppy, 6) passive&#x02013;active, 7) bored&#x02013;interested, 8) indifferent&#x02013;engaged, 9) pessimistic&#x02013;optimistic, 10) tense&#x02013;serene, 11) anxious&#x02013;calm, 12) nervous&#x02013;relaxed. Moreover, the SCAS measure allows for the creation of a composite of valence and activation. The pre- and post-valance composite and the pre- and post-activation composite were calculated after imputing the missing data for these variables (see <italic toggle="yes">Statistical Analyses</italic>) based on the average of three variables for valence (pleased, glad, and happy) and the average of three variables for activation (awake, peppy and active). This calculation was based on the original works [<xref rid="pone.0323490.ref065" ref-type="bibr">65</xref>,<xref rid="pone.0323490.ref066" ref-type="bibr">66</xref>]. The SCAS measure shows adequate reliability and validity for composite scores of valence and activation [<xref rid="pone.0323490.ref066" ref-type="bibr">66</xref>].</p></sec><sec id="sec014"><title>The emotional reactions of the interviewees.</title><p>We measured the emotional reactions of the participants in the interviews with automated facial expression analysis (H2). Facial expression analysis provides a simple, low time consuming, and less intrusive measurement of emotion and shows adequate sensitivity to the valence of emotional states [<xref rid="pone.0323490.ref067" ref-type="bibr">67</xref>&#x02013;<xref rid="pone.0323490.ref069" ref-type="bibr">69</xref>]. This analysis was performed with the use of the <italic toggle="yes">AFFDEX</italic> Software Development Kit (SDK) 2.0 [<xref rid="pone.0323490.ref070" ref-type="bibr">70</xref>]. Using the built-in computer camera, the program software analyzes facial action units (AU) (i.e., facial movements) and classifies specific combinations of these units as emotions, based on a facial coding scheme [<xref rid="pone.0323490.ref071" ref-type="bibr">71</xref>]. In a validation study of the <italic toggle="yes">AFFDEX</italic> software it was found (Study 1) that the overall accuracy of valence was 73% for picture-based prototypical facial expressions and 55% (study 2) for video-based dynamic facial expressions [<xref rid="pone.0323490.ref072" ref-type="bibr">72</xref>]. The emotions were coded on a scale from 0 to&#x02009;+&#x02009;100. We calculated the mean value for all the seven emotions measured by the <italic toggle="yes">AFFDEX</italic> software development kit <italic toggle="yes">(</italic>SDK). The emotions measured were anger, sadness, disgust, joy, surprise, fear, and contempt.</p></sec><sec id="sec015"><title>The perceived empathy of the interviewer.</title><p>We measured the reactions of the participants to the interviewer and the participant&#x02019;s perceptions of the interviewer (H3) using a Swedish translation of the Consultation and Relational Empathy (CARE) measure [<xref rid="pone.0323490.ref073" ref-type="bibr">73</xref>]. The CARE measure is considered to have high acceptability, face validity, and internal construct validity [<xref rid="pone.0323490.ref074" ref-type="bibr">74</xref>] and is designed to evaluate the extent to which the patient judges the consultant to be empathic in a one-on-one consultation. The CARE measure includes 10 questions that are graded on a six-point scale ranging from 1 (poor) to 5 (excellent), including a Not Applicable (NA) option [<xref rid="pone.0323490.ref075" ref-type="bibr">75</xref>]. Additionally, the ten questions are combined to produce a composite score of empathy, which ranges from 10&#x02013;50. The ten questions are based on asking how good was the doctor at: 1) Making you feel at ease, 2) Letting you tell your &#x0201c;story&#x0201d;, 3) Really listening, 4) Being interested in you as a whole person, 5) Fully understanding your concerns, 6) Showing care and compassion, 7) Being positive, 8) Explaining things clearly, 9) Helping you take control, 10) Making a plan of action with you.</p></sec></sec><sec id="sec016"><title>Procedure</title><p>Before conducting the experiment, we piloted the experimental design in a small sample (<italic toggle="yes">n</italic>&#x02009;=&#x02009;10) of university students who were not included in the main study. We found no previously validated structured clinical interview for our experiment, so we devised a draft version and tested the interview to establish its comprehensibility and functionality, and the functionality of the pre-recorded video interview. No alterations were made between the pilot and the main experiment. None of the participants reported any disturbing or irritating aspects of the pre-recorded video interview, however, for the live interviews some reported being disturbed by occasional desynchronization of audio and graphics, which was likely due to a poor internet connection.</p><p>We conducted the interviews in rooms on the university campus. We asked the participants to take part in an approximately 10&#x02013;15-minute online interview concerning their health and everyday life (i.e., wellbeing). At this point they were given incomplete information regarding the nature of the study, and we did not reveal the specific hypothesis concerning the effect of the automation of presence (i.e., less rich social cues) on emotional engagement and perceived empathy. This was necessary for us to test our hypothesis in a valid manner. The participants were assured anonymity and were informed that participation was voluntary and could be discontinued at any time. Upon arrival, a research assistant welcomed and gave each participant instructions. The setup was a double-blind as the assistant was unaware of the research question, the study design, and the group to which the participant had been assigned. The participants read, agreed, and signed a standard consent form before starting the experiment.</p><p>Once seated in the test room, the participant first completed a background information questionnaire, then the Patient Health Questionnaire (PHQ-9) and finally the Swedish Core and Affect Scale (SCAS). The participant was then repositioned in front of an iMac computer at an adjoining table, asked to put on headphones, and wait for the interview to begin. We used the <italic toggle="yes">Doxy.me</italic> platform and the <italic toggle="yes">AFFDEX</italic> software program on the iMac. Participants also used sound-dampening headphones to hinder them hearing the interviewer talk in the adjacent test room (in addition to hearing them via the headphones via the computer) &#x02013; that is, the participants were led to believe that the online interviewer was communicating from a separate location, while the interviewer was in fact in the adjacent room.</p><p>Prior to the interview, the research assistant also instructed the participants to avoid changing their sitting position and to avoid turning their head during the interview. The reason for this was to enable the <italic toggle="yes">AFFDEX</italic> software to identify facial expressions and analyze them as accurately as possible during the interview. In each condition, the interview followed the same interview structure, thus allowing for comparisons between groups (see <xref rid="pone.0323490.g001" ref-type="fig">Fig 1</xref>).</p><fig position="float" id="pone.0323490.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0323490.g001</object-id><label>Fig 1</label><caption><title>The interview structure, comments, and questions.</title><p>The figure represents the order of questions and comments presented in the psychological interview for all experimental conditions. The theme refers to the stage of the interview and the comment/question refers to the comments and questions asked by the interviewer. In the live conditions the questions were asked in the live video call, whereas in the video scripted condition, the comments/questions were presented as pre-recorded video clips of the interviewer commenting/asking. The original interview language was Swedish, and the comments and questions in <xref rid="pone.0323490.g001" ref-type="fig">Fig 1</xref> have been translated to English by the first author (a native English speaker) for this publication.</p></caption><graphic xlink:href="pone.0323490.g001" position="float"/></fig><p>The introductory part of the interview was to establish contact, explain the aims of the interview, and restate that their participation could be discontinued at any time without explanation, and obtaining a verbal affirmation to continue. The main part of the interview consisted of open questions (e.g., &#x0201c;Tell me about a typical day in your life&#x0201d;, &#x0201c;How would you describe your overall health?&#x0201d;) relating to central themes discussed in an intake interview [<xref rid="pone.0323490.ref076" ref-type="bibr">76</xref>]. In the live semi-scripted condition, the interviewer was to a limited extent free to choose how to respond to the participant&#x02019;s answer. We operationalized the term &#x0201c;free&#x0201d; as spontaneously being able to validate or paraphrase what the participant has said (e.g., &#x0201c;You say that...&#x0201d;, &#x0201c;It seems like you think that&#x02026;&#x0201d;, &#x0201c;If I understand you correctly you say that&#x02026;&#x0201d;). The live scripted and the video scripted conditions differed in the number of ways the interviewer could respond. In these two conditions, the interviewer&#x02019;s answer followed a decision-logic based on the response of the participant (see <xref rid="pone.0323490.g002" ref-type="fig">Fig 2</xref>).</p><fig position="float" id="pone.0323490.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0323490.g002</object-id><label>Fig 2</label><caption><title>The decision-logic of the interviewer during the psychological interview.</title><p>Schematic of the response decision-logic. In the live semi-scripted interview, each response of the participant was followed by a validating paraphrasing statement. In the live scripted and video scripted interview, each response of the participant was followed by either a line trying to engage the participant or a line indicating that the interview should continue to the next question. The original interview language was Swedish, and the interviewer responses in <xref rid="pone.0323490.g002" ref-type="fig">Fig 2</xref> have been translated to English by the first author (a native English speaker) for this publication.</p></caption><graphic xlink:href="pone.0323490.g002" position="float"/></fig><p>During the post-interview, the participant completed the SCAS questionnaire and the Consultation and Relational Empathy (CARE) questionnaire. Immediately after completion, the research assistant thanked them for their participation and gave the study participants a debriefing document. The debriefing document contained information concerning the real purpose of the study (however, the hypotheses were not disclosed), relevant background information pertaining to the study, the contact information of the researcher for follow-up questions and the study results, and information about counselling services in the city.</p></sec><sec id="sec017"><title>Statistical analyses</title><p>All analyses reported in this article were conducted using R [<xref rid="pone.0323490.ref077" ref-type="bibr">77</xref>] and the specific packages and their references have been specified for each analysis.</p><sec id="sec018"><title>Missing data of the self-rated emotional engagement of the interviewees.</title><p>We evaluated all variables in the dataset for missing data. In the pre-test SCAS answers, which contained 12 questions, we found a total of four missing values from four participants (i.e., 0.004%) which were all in the live scripted condition. Additionally, we found 10 missing values all from one person in the post-test SCAS answers (i.e., 0.011%). The pattern of missing values for the pre-test SCAS answers suggests that they are missing at random (MAR) [<xref rid="pone.0323490.ref078" ref-type="bibr">78</xref>,<xref rid="pone.0323490.ref079" ref-type="bibr">79</xref>]. However, for the post-test SCAS answers, the patterns of missing data were due to only one participant: hence not missing at random (NMAR). We have addressed the missing values by using the R package &#x0201c;mice&#x0201d; [<xref rid="pone.0323490.ref080" ref-type="bibr">80</xref>], which is a Bayesian multiple imputation method that employs Markov Chain Monte Carlo (MCMC) algorithms. This is considered a robust approach and recommend to be used with MAR data [<xref rid="pone.0323490.ref081" ref-type="bibr">81</xref>]. Here, we also calculated the missing values within each condition and not across the entire dataset to better represent the responses within each condition and any differences there may be between conditions. For the NMAR data, we adopted two strategies: 1) we used the same approach to the imputation as for the MAR data, 2) we ran the analysis twice, once with the participant present with imputed data and once with the participant excluded. As there were no differences between the two analyses, we have reported results with the participants included.</p></sec><sec id="sec019"><title>Missing data of the emotional reactions of the interviewees.</title><p>Subsequently, when evaluating the <italic toggle="yes">AFFDEX</italic> data we found a total of 49 missing observations from seven participants (five participants in the live scripted group, two in the live group, and no participants in pre-recorded group). The data loss was a result of computer software failure. The <italic toggle="yes">AFFDEX</italic> software stopped in cases where the program was started before signing into the website <italic toggle="yes">Doxy.me</italic>. Moreover, as we only used <italic toggle="yes">Doxy.me</italic> in the live semi-scripted and live scripted interviews, this software failure was only possible in these conditions, thus related to the group variable. As there was no other clear pattern, we have treated this as MAR. For this reason, we once again employed the R package &#x0201c;mice&#x0201d; to impute the missing values. Lastly, we did not exclude any outliers in the <italic toggle="yes">AFFDEX</italic> dataset because any extreme values could represent an aspect of the inherent variability of the data (i.e., outliers can be legitimate emotional reactions in an online setting).</p></sec><sec id="sec020"><title>Missing data of the perceived empathy of the interviewer.</title><p>In the CARE questionnaire we received 128 Not Applicable (NA) responses. The majority of the NA responses (99) were given for questions 9 (<italic toggle="yes">Helping you to take control</italic>) and 10 (<italic toggle="yes">Making a plan of action with you</italic>). These NA answers are not specifically missing because they represent answers where the participants did not feel that the questions applied. As there was no other clear pattern, we have treated this as MAR and again used the Bayesian multiple imputation method to deal with the NA responses. Lastly, due to the large number of participants in all three conditions who felt that questions 9 and 10 were not applicable, we have interpreted these results with caution.</p></sec><sec id="sec021"><title>Analysis of the self-rated emotional engagement of the interviewees.</title><p>Our first hypothesis (H1) was that the increased automation of the interviewer would decrease the emotional engagement. This meant that we expected the self-rated emotional engagement of the interviewees to be the highest in the live semi-scripted condition followed by lower ratings in the live scripted condition, and the lowest ratings in the pre-recorded video condition. To investigate H1, we performed a mixed-model ANOVA with time as the within-subject factor and condition as the between-subject factor. We used the valance composite and activation composite of the SCAS measure as dependent variables. To investigate the main and interactive effects, we used the afex package [<xref rid="pone.0323490.ref082" ref-type="bibr">82</xref>]. To investigate Tukey post hoc comparisons, we used the emmeans package [<xref rid="pone.0323490.ref083" ref-type="bibr">83</xref>].</p></sec><sec id="sec022"><title>Analysis of the emotional reactions of the interviewees.</title><p>Similar to H1, our second hypothesis (H2) was that increasing the automation of the interviewer would decrease the emotional reactions among the interviewers. To investigate if the total amount of expressed emotional reactions differed between groups and if there were differences between groups in emotions, we aimed to conduct a one-way MANOVA on all <italic toggle="yes">AFFDEX</italic> data, followed by one-way ANOVAs on each emotion separately. The dependent variables were the average of each of the seven measured emotions. For the MANOVA we used the car package [<xref rid="pone.0323490.ref084" ref-type="bibr">84</xref>] and for the multivariate normality tests we used the MVN package [<xref rid="pone.0323490.ref085" ref-type="bibr">85</xref>]. However, due to multiple assumption violations, we replaced the MANOVA analysis by running multiple non-parametric Kruskal&#x02013;Wallis tests (with Bonferroni corrections). Additionally, to further investigate the main and interactive effects, we conducted non-parametric pairwise multiple comparison tests using the Dunn test via the dunn.test package [<xref rid="pone.0323490.ref086" ref-type="bibr">86</xref>].</p></sec><sec id="sec023"><title>Analysis of the perceived empathy of the interviewer.</title><p>Our third hypothesis (H3) was in line with H1 and H2. Here, we expected that the automation of the interviewer would decrease the perceived empathy of the interviewer. To investigate differences between groups on perceived empathy, we performed a one-way ANOVA with the condition as the predictor and the composite empathy (based on the CARE measure) as the outcome. Moreover, due to violations of normality we also followed up with a Kruskal&#x02013;Wallis test. To investigate the main and interactive effects, we conducted post-hoc Tukey tests. Following this, we aimed to run a MANOVA of the ten CARE measures, but, instead, due to multiple assumption violations we conducted multiple Kruskal&#x02013;Wallis tests (with Bonferroni corrections), followed by post-hoc Dunn tests.</p></sec><sec id="sec024"><title>Analysis of the measures of engagement, reactions, and perceived empathy.</title><p>To investigate our fourth hypothesis (H4), which was that self-rated engagement, emotional reactions, and perceptions of empathy of the interviewer would be correlated, we conducted correlational analyses between the pre and post SCAS measures, the AFFDEX emotion measures, and the CARE empathy measure. Due to earlier assumption violations, we opted for the non-parametric Spearman&#x02019;s correlation.</p></sec></sec></sec><sec id="sec025"><title>Results</title><sec id="sec026"><title>Balance checks of the experimental conditions</title><p>Prior to the main analyses, we confirmed that each condition had twenty-five subjects. Next, we investigated whether there were any group differences based on the PHQ-9 scores, gender, and previous experience. When investigating group differences based on the PHQ-9 scores, we found that the assumption of normality was violated (Shapiro-Wilk test, <italic toggle="yes">W</italic>&#x02009;=&#x02009;0.92192, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). Based on a substitute non-parametric Kruskal&#x02013;Wallis test, we found no evidence of significant differences in median scores across groups (<italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) = 0.691, <italic toggle="yes">p</italic>&#x02009;=&#x02009;0.708). We then investigated group differences based on gender, by running a Chi-Square test and found that gender was equally distributed across groups (<italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2, N&#x02009;=&#x02009;74) = 2.663, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.264). Lastly, using a Chi-Square test, we found that previous experience of psychotherapy or counselling did not differ significantly between groups (<italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2, N&#x02009;=&#x02009;74) = 0.239, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.888). Accordingly, the variables PhQ-9, gender, and previous experience of psychotherapy or counselling were excluded from subsequent analyses.</p></sec><sec id="sec027"><title>The self-rated emotional engagement of the interviewees</title><p>We aimed to conduct a mixed-model ANOVA to assess the effects of condition (live semi-scripted, live scripted, or video scripted), SCAS composites (valence or activation), and time (pre or post) on participants&#x02019; emotional engagement measured as the SCAS composite score. Assessing the assumptions of data distribution, we found that both normality (Shapiro Wilk, <italic toggle="yes">W</italic>&#x02009;=&#x02009;0.993, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.204) and homogeneity of variances (<italic toggle="yes">F</italic>[11, 288] = 1.34, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.202) were upheld. Subsequently, we conducted a mixed-model ANOVA and found no main effects of condition (<italic toggle="yes">F</italic>[2, 72] = 0.65, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.526) or the SCAS composites (<italic toggle="yes">F</italic>[1, 72) = 2.59, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.112), but we did find a main effect of time (<italic toggle="yes">F</italic>[1, 72] = 37.63, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). Additionally, there was a significant interaction between the SCAS composites and time (<italic toggle="yes">F</italic>[1, 71] = 14.70, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). No other interactions were significant.</p><p>For the interaction effect between SCAS composite and time, Tukey post hoc comparisons showed that participants&#x02019; valence composites post-interview (<italic toggle="yes">M</italic>&#x02009;=&#x02009;1.54, <italic toggle="yes">SD&#x02009;</italic>=&#x02009;1.51) were significantly higher compared to the valence composites pre-interview (<italic toggle="yes">M</italic>&#x02009;=&#x02009;1.15, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.41, E&#x02009;=&#x02009;0.40, <italic toggle="yes">SE</italic>&#x02009;=&#x02009;0.12, 95% CI [0.08, 0.71], <italic toggle="yes">p</italic>&#x02009;=&#x02009;.008). Similarly, the activation composites of participants post-interview (<italic toggle="yes">M</italic>&#x02009;=&#x02009;1.61, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.37) were significantly higher compared to the activation composites pre-interview (<italic toggle="yes">M</italic>&#x02009;=&#x02009;0.60, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.91, <italic toggle="yes">E</italic>&#x02009;=&#x02009;1.00, <italic toggle="yes">SE</italic>&#x02009;=&#x02009;0.16, 95% CI [0.59, 1.43], <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.0001). Moreover, as the post-SCAS measures included NMAR data from one participant, we also re-ran the analysis after excluding this one participant (#38). The exclusion of the participant did not change the main results, so we have only reported the results that include the participant.</p><p>The results indicate that the live semi-scripted, the live scripted, and the video scripted conditions elicited similar emotional engagement among our participants, with valence and activation increasing between the pre and post measures. The fact that valence and activation increased signifies that participants were engaged by the experimental setup.</p></sec><sec id="sec028"><title>The emotional reactions of the interviewees</title><p>To evaluate group differences in emotional reactivity during the interview, we first conducted a MANOVA on the <italic toggle="yes">AFFDEX</italic> measures of facial expressions of emotions. Assessing the assumptions of the data distribution, we found that multivariate normality (Mardia&#x02019;s test, <italic toggle="yes">&#x003c7;</italic><sup>2</sup>&#x02009;=&#x02009;875.08, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001) was violated and that the univariate normality assumption was violated for all individual emotional reactions (Anderson-Darling tests, for all <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). Additionally, when evaluating assumptions of homogeneity of variance, we found that contempt (Bartlett&#x02019;s test <italic toggle="yes">p</italic>&#x02009;=&#x02009;.481) and surprise (<italic toggle="yes">p</italic>&#x02009;=&#x02009;.514) satisfied the criterion, while the other emotional reactions displayed violations (all <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.01). Lastly, we found that sphericity was violated (Mauchly&#x02019;s Test, <italic toggle="yes">W</italic>&#x02009;=&#x02009;1.4482e-06, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). Therefore, to address the multiple assumption violations, we used non-parametric Kruskal&#x02013;Wallis tests with Bonferroni corrections to evaluate the group differences of expressed facial emotions.</p><p>The results only revealed a significant difference for expressed joy (<italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) = 18.08, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). Follow-up post-hoc analyses using the Dunn test revealed no significant difference in expressed joy between the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;15.00, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;16.11) and live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;18.28, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;19.99) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;0.63, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.265). However, there were significant differences between the live semi-scripted and video scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;4.24, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;6.52) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;3.36, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001) and between the live scripted and video scripted conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;3.98, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001).</p><p>The findings suggest that the live semi-scripted, live scripted, and video scripted conditions elicited overall similar emotional reactions, except for expressed joy. Notably, expressed joy was markedly higher in both the live semi-scripted and live scripted compared to the video scripted condition.</p></sec><sec id="sec029"><title>The perceived empathy of the interviewer</title><p>To investigate group differences of the effect of the automation of presence (i.e., less rich social cues) on the interviewees&#x02019; perceptions of the interviewer, we first performed a one-way ANOVA on the group differences for composite empathy (i.e., composite score of perceived empathy). Assessing the assumptions of the data distribution, we found that normality was violated (Shapiro-Wilk test, <italic toggle="yes">W</italic>&#x02009;=&#x02009;0.96018, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.019) but the homogeneity of variance was upheld (Levene&#x02019;s test, <italic toggle="yes">F</italic>[2, 72] = 0.338, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.714). The results from the one-way ANOVA revealed a significant main effect of condition on empathy (<italic toggle="yes">F</italic>[2, 72] = 9.445, p&#x02009;&#x0003c;&#x02009;0.001). Due to the violation of normality, we also conducted a Kruskal&#x02013;Wallis test and confirmed the main effect of condition on empathy ratings (<italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) = 16.934, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). A Tukey post-hoc test revealed no difference between the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;38.87, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;8.27) and the live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;38.53, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;6.24) conditions (<italic toggle="yes">E</italic>&#x02009;=&#x02009;1.34, <italic toggle="yes">SE</italic>&#x02009;=&#x02009;2.08, 95% CI [-3.62, 6.31], <italic toggle="yes">p</italic>&#x02009;=&#x02009;.795). However, there was a significant difference between the live semi-scripted and the video scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;31.47, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;7.37) conditions (<italic toggle="yes">E</italic>&#x02009;=&#x02009;8.40, <italic toggle="yes">SE</italic>&#x02009;=&#x02009;2.08, 95% CI [3.43, 13.37], <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001) and between the live scripted and the video scripted conditions (<italic toggle="yes">E</italic>&#x02009;=&#x02009;7.06, <italic toggle="yes">SE</italic>&#x02009;=&#x02009;2.08, 95% CI [2.09, 12.02], <italic toggle="yes">p</italic>&#x02009;=&#x02009;.003).</p><p>Next, we aimed to conduct a MANOVA, but when assessing the assumptions of the data distribution we found that the homogeneity of variance (Shapiro-Wilk test, <italic toggle="yes">W</italic>&#x02009;=&#x02009;0.96018, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.019) and sphericity (Mauchly test, <italic toggle="yes">W</italic>&#x02009;=&#x02009;0.002, p&#x02009;&#x0003c;&#x02009;.001) were violated. To address the multiple assumption violations, we employed Kruskal&#x02013;Wallis tests with Bonferroni correction to evaluate group differences for the CARE measures.</p><p>We found significant differences in four of the ten measures. Specifically, we found differences between conditions for the CARE variables 1 (making you feel at ease; <italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) = 17.305, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001), 5 (fully understanding your concerns; <italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) = 16.055, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001), 6 (showing care and compassion; <italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) 12.504, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.001), and 7 (being positive; <italic toggle="yes">&#x003c7;</italic><sup>2</sup>(2) = 16.577, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). We ran follow-up post-hoc analyses (Holm-Bonferroni corrected) using the Dunn test for each of these four CARE measures.</p><p>The post-hoc analyses of the CARE 1 measure (making you feel at ease) revealed that there was no significant difference between the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;4.28, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;0.89) and the live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;4.02, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;0.77) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;-1.13, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.129). However, there were differences between the live semi-scripted and video scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;3.08, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.08) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;4.03, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001) and between the live scripted and the video scripted conditions (<italic toggle="yes">M</italic>&#x02009;=&#x02009;3.08, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.08) (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;2.90, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001).</p><p>The post-hoc analyses of the CARE 5 measure (fully understanding your concerns) demonstrated that there was no significant difference between the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;3.92, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.15) and live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;3.54, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.08) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;-1.12, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.131). However, there were differences between the live semi-scripted and video scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;2.55, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.19) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;3.89, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). and between the live scripted and the video scripted conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;2.77, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.003).</p><p>The post-hoc analyses of the CARE 6 measure (showing care and compassion) revealed no significant difference between the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;4.04, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.17) and live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;3.72, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;0.98) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;-1.25, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.105). However, there were significant differences between the live semi-scripted and video scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;2.76, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.31) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;3.49, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001) and between the live scripted and video scripted conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;2.24, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.013).</p><p>The post-hoc analyses of the CARE 7 measure (being positive) showed that there was no significant difference between the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;4.28, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;0.89) and live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;4.36, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;0.81) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;0.25, <italic toggle="yes">p</italic>&#x02009;=&#x02009;.403). However, there were significant differences between the live semi-scripted and video scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;3.26, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.03) conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;3.40, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001) and between the live scripted and video scripted conditions (<italic toggle="yes">Z</italic>&#x02009;=&#x02009;3.64, <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001).</p><p>Overall, similar to the composite CARE empathy score, the investigation of individual CARE measures demonstrated that the live semi-scripted and the live scripted did not differ but both conditions differed markedly from the video scripted. The results suggest that our video scripted condition had a negative effect on perceived empathy, especially for four measures: 1 (making you feel at ease), 5 (fully understanding your concerns), 6 (showing CARE and compassion), and 7 (being positive).</p></sec><sec id="sec030"><title>The correlation between engagement, emotional reactions, and perceived empathy</title><p>Lastly, we investigated the correlation between emotional engagement (SCAS: pre/post valence and activation), emotional reactions (<italic toggle="yes">AFFDEX</italic>: facial emotion expressions) and perceived empathy (CARE: empathy composite). See <xref rid="pone.0323490.g003" ref-type="fig">Fig 3</xref> for the correlation table.</p><fig position="float" id="pone.0323490.g003"><object-id pub-id-type="doi">10.1371/journal.pone.0323490.g003</object-id><label>Fig 3</label><caption><title>Correlation table of the pre- and post-measures.</title><p>The matrix values represent Spearman&#x02019;s rank correlations (<italic toggle="yes">r</italic>), and the significant correlations are represented as follows: *&#x02009;=&#x02009;<italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.05, **&#x02009;=&#x02009;<italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001, ***&#x02009;=&#x02009;<italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.0001.</p></caption><graphic xlink:href="pone.0323490.g003" position="float"/></fig><p>The most interesting correlations were those between perceived empathy and expressed joy (<italic toggle="yes">r</italic>&#x02009;=&#x02009;.35; <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.01). While causality cannot be inferred based on these analyses, the results suggest that participants may have had a more positive experience (i.e., greater positive change in affect and expressed more joy) when they perceived the interviewer as empathic.</p><p>Additionally, we found that several emotions were correlated. For example, we found a negative correlation between joy and contempt (<italic toggle="yes">r</italic>&#x02009;=&#x02009;-.20; <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.05), which is not surprising considering that joy is a positive emotion and contempt is a negative emotion. Moreover, we found correlations between fear and anger (<italic toggle="yes">r</italic>&#x02009;=&#x02009;.65; <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.0001), fear and disgust (<italic toggle="yes">r</italic>&#x02009;=&#x02009;.62; <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.05). and between fear and sadness (<italic toggle="yes">r</italic>&#x02009;=&#x02009;.59; <italic toggle="yes">p</italic>&#x02009;&#x0003c;&#x02009;.001). These correlations could be a result of the poor ability of the <italic toggle="yes">AFFDEX</italic> software to correctly identify fear and anger [<xref rid="pone.0323490.ref072" ref-type="bibr">72</xref>], implicating that some of the other emotions (e.g., sadness) could have been mistaken for fear. Other positive correlations between emotions on the <italic toggle="yes">AFFDEX</italic> measures were also found; these correlations suggest that participants who expressed one emotion were likely to express other emotions.</p></sec></sec><sec id="sec031"><title>Discussion</title><p>In our experiment the aim was to test how the automation of social presence (i.e., less rich social cues) would affect the experience of the interviewees in an online 10&#x02013;15-minute psychological interview on wellbeing. We included three conditions: 1) a live semi-scripted online interview, 2) a live scripted online interview, and 3) a video scripted online interview. The three conditions represented our operationalization of degrees of automation of social presence. We were interested in evaluating how participants would react to these conditions and, therefore, we measured their pre and post self-reported emotional engagement (SCAS), their emotional engagement during the interview (<italic toggle="yes">AFFDEX</italic>), and their perceived empathy of the interviewer post interview (CARE).</p><p>Based on the background literature on human-computer interactions that richer social cues increase social presence [<xref rid="pone.0323490.ref037" ref-type="bibr">37</xref>], we anticipated that the increased automation of presence (i.e., less rich social cues) would decrease emotional engagement, reactions and perceived empathy. This would result in perceived emotional engagement, emotional reactions, and perceived empathy receiving the highest scores in the live semi-scripted condition, followed by the live scripted condition and last the video scripted condition. However, we also anticipated that the video scripted condition could elicit similar reactions and emotional engagement in the participant as in the live conditions, based on studies on social reactions to computers and avatars [<xref rid="pone.0323490.ref043" ref-type="bibr">43</xref>,<xref rid="pone.0323490.ref062" ref-type="bibr">62</xref>]. Therefore, our alternative consideration was that we might not detect differences between conditions. Lastly, we also analyzed the relationship between self-rated emotional engagement, emotional reactions, and perceptions of empathy. Here, we anticipated that there would be a positive correlation between self-rated emotional engagement, emotional reactions, and perceptions of empathy, since perceived empathy has shown to contribute to a positive alliance, and thus also the emotional engagement in the interaction [<xref rid="pone.0323490.ref046" ref-type="bibr">46</xref>,<xref rid="pone.0323490.ref047" ref-type="bibr">47</xref>].</p><p>Based on a sample of 75 participants (25 per condition) we were able to investigate our hypotheses and have outlined our main findings and interpretations below.</p><sec id="sec032"><title>The self-rated emotional engagement of the interviewees</title><p>The outcome of our analysis of emotional engagement indicated that automation had no significant effect on either activation or valence, but there was an interaction between time and our SCAS composite measures (pre and post activation and valence). Post-interview valence (<italic toggle="yes">M</italic>&#x02009;=&#x02009;1.54, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.51) was higher compared to pre-interview valence (<italic toggle="yes">M</italic>&#x02009;=&#x02009;1.15, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.41). Similarly, post-interview activation (<italic toggle="yes">M</italic>&#x02009;=&#x02009;1.61, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.37) was higher compared to pre-interview activation (<italic toggle="yes">M</italic>&#x02009;=&#x02009;0.60, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;1.91). The results indicate that valence and activation increased between our pre to post measures, which signifies that participants were engaged by the experimental setup. Interestingly, there is an increasing amount of research showing that people tend to treat computers as social beings and react to them as if they were humans [<xref rid="pone.0323490.ref059" ref-type="bibr">59</xref>,<xref rid="pone.0323490.ref060" ref-type="bibr">60</xref>], and that people respond socially even more strongly to computer characters such as avatars due to their more pronounced human-like attributes [<xref rid="pone.0323490.ref043" ref-type="bibr">43</xref>]. The lack of significant differences between the conditions on activation and valence could be related to how the interaction was perceived. The pre-recorded video interaction might have led interviewees to believe that the interaction was a live human. Perceiving the interaction as human-operated influences the social presence positively while perceiving the interaction as computer-operated negatively affects social presence [<xref rid="pone.0323490.ref087" ref-type="bibr">87</xref>]. This could potentially mean that a real-life human psychologist interviewer could be replaced by an automated system of pre-recorded videos of questions and answers &#x02013; at least in some instances.</p></sec><sec id="sec033"><title>The emotional reactions of the interviewees</title><p>When analyzing the facial expression of emotional reactions, we found that emotional reactions were similar in all conditions except for expressed joy, which was higher in both the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;15.00, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;16.11) and live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;18.28, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;19.99) compared to the video scripted condition (<italic toggle="yes">M</italic>&#x02009;=&#x02009;4.24, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;6.52). The facial expression measure is perhaps a more objective measure (vs. self-reports) of the interviewee&#x02019;s emotional reactions as it is a non-intrusive and real-time measure of a participant&#x02019;s emotional reactions. The results provide some support for our hypothesis that the increased automation of presence decreases emotional reactions. A possible explanation for the difference in joyful expressions but not on other emotions is that <italic toggle="yes">AFFDEX</italic> detects happy expressions more often. <italic toggle="yes">AFFDEX</italic> identifies dynamic happy expressions particularly well (91% of the time), compared to the accuracy for other dynamic expressions: anger (49%), contempt (68%), disgust (79%), fear (1%), sadness (35%) and surprise (61%) [<xref rid="pone.0323490.ref072" ref-type="bibr">72</xref>]. The reason for this could be that happiness is the most distinctly expressed emotion, whereas fear and surprise are more often confused (since they are characterized by similar markers). In line with the results of the self-reported emotional engagement, the outcome of the emotional reactions in the pre-recorded video condition also supports the existing research that people react socially to computers and human representations [<xref rid="pone.0323490.ref059" ref-type="bibr">59</xref>].</p></sec><sec id="sec034"><title>The perceived empathy of the interviewer</title><p>The automation of presence was found to influence perceive empathy (CARE composite), so that the live semi-scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;38.87, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;8.27) and the live scripted (<italic toggle="yes">M</italic>&#x02009;=&#x02009;38.53, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;6.24) both had significantly higher ratings compared with the video scripted condition (<italic toggle="yes">M</italic>&#x02009;=&#x02009;31.47, <italic toggle="yes">SD</italic>&#x02009;=&#x02009;7.37). Additionally, examining the individual CARE measures, we found that the live conditions had higher ratings for four measures: 1 (making you feel at ease), 5 (fully understanding your concerns), 6 (showing CARE and compassion), and 7 (being positive). In line with our expectations, interviewees experienced the interviewer as most empathic in the live conditions and least empathic in the video scripted condition.</p><p>The outcomes suggest that the conditions differ in richness of social cues. This resonates with previous research showing that, for at least shorter interactions, media with richer social cues evoke more social presence than media with less rich social cues [<xref rid="pone.0323490.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0323490.ref044" ref-type="bibr">44</xref>]. A possible explanation for the lower empathy reports could be that the pre-recorded video interview was perceived as less realistic than the live interviews. Previous studies have shown that social presence is experienced when behavioral realism is higher [<xref rid="pone.0323490.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0323490.ref042" ref-type="bibr">42</xref>,<xref rid="pone.0323490.ref043" ref-type="bibr">43</xref>] and that incongruity between photographic and behavioral realism yields lesser experience of social presence [<xref rid="pone.0323490.ref037" ref-type="bibr">37</xref>]. Another possibility for the lower empathy reports in the video scripted interview is that the pre-recorded video interview was perceived as controlled by an algorithm. Perceiving the interview as controlled by a computer has been shown to negatively impact social presence compared to interviews that are perceived as being controlled by a human [<xref rid="pone.0323490.ref088" ref-type="bibr">88</xref>]. However, as we did not directly ask participants about their perceptions of realism of the interviews, this is speculation (see also limitations). Future studies could measure perceived agency to discount such explanations.</p><p>Lastly, in contrast to our expectation that the rigidity in the live scripted condition would lead to lower ratings of perceived empathy compared to the live semi-scripted condition, we found no significant difference between these conditions. Previous studies have shown that consistency between the level of realism of the visual appearance and the level of realism of the behavior increases social presence [<xref rid="pone.0323490.ref044" ref-type="bibr">44</xref>,<xref rid="pone.0323490.ref045" ref-type="bibr">45</xref>]. We argue that this result suggests that the live-scripted condition, where the flexibility of the verbal responses was restricted, was perhaps not perceived as less realistic than the live condition. Increased rigidity through adherence to a script might not have led to a significant decrease in richness of social cues, by which significant differences between the live and live-scripted condition could be detected. This is perhaps because social cues such as adequate eye contact, smiling, head nods and vocal pitch were still present in both conditions. Overall, our findings provide partial support for our hypothesis that increasing the automation of presence (i.e., less rich social cues) decreases perceived empathy, and suggests that a live interaction differs from a pre-recorded video interaction regarding perceptions of empathy.</p></sec><sec id="sec035"><title>The correlation between engagement, emotional reactions, and perceived empathy</title><p>We investigated the relationship between self-rated emotional engagement, emotional reactions, and perceived empathy. Our hypothesis was that there would be a positive correlation between the measures. In line with our hypothesis, participants who perceived the interviewer as more empathic were found to more likely have a positive experience (i.e., greater positive change in activation of affect and more expressed joy), which might indicate that perceiving the interviewer as more empathetic contributed to a more positive experience. This outcome mirrors the research on the importance of empathy for the development of positive alliance [<xref rid="pone.0323490.ref046" ref-type="bibr">46</xref>,<xref rid="pone.0323490.ref047" ref-type="bibr">47</xref>]. Our results suggest that the video scripted interaction was perceived and experienced differently (i.e., as less empathetic and eliciting fewer joyful expressions) compared to a live interaction with a human. This indicates that empathy has an impact on how online psychological interviews are experienced and that automation may reduce aspects that are central to positive psychological outcomes.</p></sec><sec id="sec036"><title>Limitations</title><p>There are a few limitations that are important to mention. First, in the video scripted condition, the test instructor could not see the interviewee on the computer screen while operating the interview simulation, and was, therefore, only able to hear the participant. For this reason, we cannot be certain that the participants had their head turned to the camera during the whole interview. If so, the <italic toggle="yes">AFFDEX</italic> software would not be able to analyze facial expressions since it is not applicable in different head poses. However, the <italic toggle="yes">AFFDEX</italic> data does suggest that the participants did have their heads turned to the camera as the program makes interpretations every second. Second, in each condition once or twice the <italic toggle="yes">AFFDEX</italic> data was missing for 20&#x02013;60 seconds during the interview for a few participants. Third, as was discussed in the results section, we encountered missing values in the <italic toggle="yes">AFFDEX</italic> data in the live and live-scripted condition due to a software malfunction. Fourth, we encountered bandwidth delays at times in the live interviews, which was likely due to a poor internet connection. However, it should be added that bandwidth delays are an inherent aspect of video conference communication and is as such a reflection of actual online communication.</p><p>Fifth, there was sometimes a lack of synchronized audio and graphics in the video scripted interview, and this could potentially have influenced how realistic the interview appeared and be a potential confounding variable. However, synchronization issues might also have been interpreted as bandwidth issues, which would reduce that potential confound. Sixth, the accuracies of the AFFDEX measures are not without their limitations and, therefore, due to the errors rates of the measures, these results need to be treated with some caution when generalizing. Nevertheless, we argue that evaluated together with the other self-reports these results present a balanced evaluation of our manipulations.</p><p>Lastly, in the present study we did not explicitly measure social presence and there are therefore some limitations to the generalizability of our results. We manipulated the social presence of the interviewer by creating conditions that represented various degrees of automation. In so doing, we did achieve different types of social presence, but as our measures concerned emotional engagement and perceived empathy, we could only evaluate social presence indirectly. Moreover, as we did not explicitly ask participants if they were aware at any point that the interviewer was automated (in the fully automated condition) it is unclear to what extent they perceived it to be realistic and how that perception may have impacted their engagement.</p></sec></sec><sec id="sec037"><title>Conclusions</title><p>In conclusion, our results add to the field of research aiming to examine the role of human presence in online psychological interventions and to the field of human-machine communication. As automated programs are emerging in clinical settings and people are now interacting with a computer instead of a human, it is interesting that little is known about how automated interactions are perceived and experienced. A deeper understanding of the role of human presence is needed for the development of automated internet-based self-help programs. It is also important to find ways to enhance the use of these programs by making them more engaging, since to date, adherence to these programs is low. To our knowledge, this is the first study investigating whether there are differences between a live semi-scripted online interaction, a live scripted interaction, and a video scripted interaction regarding social presence.</p><p>Our results suggest that the automatization of an interviewer decreased the perceived empathy of the interviewer and decreased the emotional engagement of the interviewees in terms of expressed joy; however, it did not affect the self-rated engagement of the interviewees. Furthermore, increased rigidity through adherence to a script, in the live scripted condition, did not significantly impact perceived empathy, emotional reactions, or expressed joy, compared with the live semi-scripted condition. Instead, the negative effect of automation was only found in the video scripted condition. However, although we were able to manipulate social presence experimentally, we did not explicitly measure social presence but instead measured it indirectly through perceived empathy and emotional engagement. Moreover, given that the lack of consensus of how to define the concept of social presence, our results may be difficult to compare to other studies on social presence. A key feature that was not addressed in the present study was how the perception of the other as a real human or how realistic the scenario was impacted our measures &#x02013; this may be an important avenue for future research. Nevertheless, we have attempted to contribute to the ongoing discussion of how to understand social presence, perceived empathy, and emotional engagement in online psychological interventions and the field of human-machine communication.</p><p>Considering the significant technological advancements since this study was conducted, future research should replicate these findings to investigate if psychological interviews can be automatized and still retain the beneficial elements of live interactions.</p></sec></body><back><ack><p>We would like to thank the research assistant who helped us with the data collection and all the participants.</p></ack><ref-list><title>References</title><ref id="pone.0323490.ref001"><label>1</label><mixed-citation publication-type="journal"><collab>The Lancet Global Health</collab>. <article-title>Mental health matters</article-title>. <source>Lancet Glob Health</source>. <year>2020</year>;<volume>8</volume>(<issue>11</issue>):<fpage>e1352</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S2214-109X(20)30432-0</pub-id>
<pub-id pub-id-type="pmid">33069297</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Straten</surname><given-names>V</given-names></name>, <name><surname>Oppen</surname><given-names>V</given-names></name>. <article-title>Recognition of psychotherapy effectiveness</article-title>. <source>J Psychother Integr</source>. <year>2013</year>;<volume>23</volume>(<issue>3</issue>):<fpage>320</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Patel</surname><given-names>V</given-names></name>, <name><surname>Saxena</surname><given-names>S</given-names></name>, <name><surname>Lund</surname><given-names>C</given-names></name>, <name><surname>Thornicroft</surname><given-names>G</given-names></name>, <name><surname>Baingana</surname><given-names>F</given-names></name>, <name><surname>Bolton</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>The Lancet Commission on global mental health and sustainable development</article-title>. <source>Lancet</source>. <year>2018</year>;<volume>392</volume>(<issue>10157</issue>):<fpage>1553</fpage>&#x02013;<lpage>98</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S0140-6736(18)31612-X</pub-id>
<pub-id pub-id-type="pmid">30314863</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Reichert</surname><given-names>A</given-names></name>, <name><surname>Jacobs</surname><given-names>R</given-names></name>. <article-title>The impact of waiting time on patient outcomes: Evidence from early intervention in psychosis services in England</article-title>. <source>Health Econ</source>. <year>2018</year>;<volume>27</volume>(<issue>11</issue>):<fpage>1772</fpage>&#x02013;<lpage>87</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/hec.3800</pub-id>
<pub-id pub-id-type="pmid">30014544</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref005"><label>5</label><mixed-citation publication-type="book"><collab>World Health Organization</collab>. <source>The impact of COVID-19 on mental, neurological and substance use services</source>. <publisher-name>World Health Organization</publisher-name>; <year>2020</year>. Available from: <ext-link xlink:href="https://www.who.int/publications/i/item/978924012455" ext-link-type="uri">https://www.who.int/publications/i/item/978924012455</ext-link></mixed-citation></ref><ref id="pone.0323490.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Lattie</surname><given-names>EG</given-names></name>, <name><surname>Stiles-Shields</surname><given-names>C</given-names></name>, <name><surname>Graham</surname><given-names>AK</given-names></name>. <article-title>An overview of and recommendations for more accessible digital mental health services</article-title>. <source>Nat Rev Psychol</source>. <year>2022</year>;<volume>1</volume>(<issue>2</issue>):<fpage>87</fpage>&#x02013;<lpage>100</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s44159-021-00003-1</pub-id>
<pub-id pub-id-type="pmid">38515434</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Elliott</surname><given-names>R</given-names></name>, <name><surname>Bohart</surname><given-names>AC</given-names></name>, <name><surname>Watson</surname><given-names>JC</given-names></name>, <name><surname>Murphy</surname><given-names>D</given-names></name>. <article-title>Therapist empathy and client outcome: An updated meta-analysis</article-title>. <source>Psychotherapy (Chic)</source>. <year>2018</year>;<volume>55</volume>(<issue>4</issue>):<fpage>399</fpage>&#x02013;<lpage>410</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037/pst0000175</pub-id>
<pub-id pub-id-type="pmid">30335453</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Norcross</surname><given-names>J</given-names></name>, <name><surname>Lambert</surname><given-names>M</given-names></name>. <article-title>Psychotherapy relationships that work III</article-title>. <source>Psychotherapy</source>. <year>2018</year>;<volume>55</volume>(<issue>4</issue>):<fpage>303</fpage>&#x02013;<lpage>15</lpage>.<pub-id pub-id-type="pmid">30335448</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Barak</surname><given-names>A</given-names></name>, <name><surname>Grohol</surname><given-names>J</given-names></name>. <article-title>Current and future trends in internet-supported mental health interventions</article-title>. <source>J Technol Hum Serv</source>. <year>2011</year>;<volume>29</volume>(<issue>3</issue>):<fpage>155</fpage>&#x02013;<lpage>96</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Sit</surname><given-names>HF</given-names></name>, <name><surname>Hong</surname><given-names>IW</given-names></name>, <name><surname>Burchert</surname><given-names>S</given-names></name>, <name><surname>Sou</surname><given-names>EKL</given-names></name>, <name><surname>Wong</surname><given-names>M</given-names></name>, <name><surname>Chen</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>A feasibility study of the WHO digital mental health intervention step-by-step to address depression among Chinese young adults</article-title>. <source>Front Psychiatry</source>. <year>2022</year>;<volume>12</volume>:<fpage>812667</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fpsyt.2021.812667</pub-id>
<pub-id pub-id-type="pmid">35069297</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Hilty</surname><given-names>DM</given-names></name>, <name><surname>Randhawa</surname><given-names>K</given-names></name>, <name><surname>Maheu</surname><given-names>MM</given-names></name>, <name><surname>McKean</surname><given-names>AJS</given-names></name>, <name><surname>Pantera</surname><given-names>R</given-names></name>, <name><surname>Mishkind</surname><given-names>MC</given-names></name>. <article-title>A review of telepresence, virtual reality, and augmented reality applied to clinical care</article-title>. <source>J Technol Behav Sci</source>. <year>2020</year>;<volume>5</volume>(<issue>2</issue>):<fpage>178</fpage>&#x02013;<lpage>205</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Maulik</surname><given-names>PK</given-names></name>, <name><surname>Thornicroft</surname><given-names>G</given-names></name>, <name><surname>Saxena</surname><given-names>S</given-names></name>. <article-title>Roadmap to strengthen global mental health systems to tackle the impact of the COVID-19 pandemic</article-title>. <source>Int J Ment Health Syst</source>. <year>2020</year>;<volume>14</volume>:<fpage>57</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13033-020-00393-4</pub-id>
<pub-id pub-id-type="pmid">32742305</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Campion</surname><given-names>J</given-names></name>, <name><surname>Javed</surname><given-names>A</given-names></name>, <name><surname>Sartorius</surname><given-names>N</given-names></name>, <name><surname>Marmot</surname><given-names>M</given-names></name>. <article-title>Addressing the public mental health challenge of COVID-19</article-title>. <source>Lancet Psychiatry</source>. <year>2020</year>;<volume>7</volume>(<issue>8</issue>):<fpage>657</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S2215-0366(20)30240-6</pub-id>
<pub-id pub-id-type="pmid">32531299</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Moreno</surname><given-names>C</given-names></name>, <name><surname>Wykes</surname><given-names>T</given-names></name>, <name><surname>Galderisi</surname><given-names>S</given-names></name>, <name><surname>Nordentoft</surname><given-names>M</given-names></name>, <name><surname>Crossley</surname><given-names>N</given-names></name>, <name><surname>Jones</surname><given-names>N</given-names></name>, <etal>et al</etal>. <article-title>How mental health care should change as a consequence of the COVID-19 pandemic</article-title>. <source>Lancet Psychiatry</source>. <year>2020</year>;<volume>7</volume>(<issue>9</issue>):<fpage>813</fpage>&#x02013;<lpage>24</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S2215-0366(20)30307-2</pub-id>
<pub-id pub-id-type="pmid">32682460</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Andersson</surname><given-names>G</given-names></name>. <article-title>Internet interventions: Past, present and future</article-title>. <source>Internet Interv</source>. <year>2018</year>;<volume>12</volume>:<fpage>181</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.invent.2018.03.008</pub-id>
<pub-id pub-id-type="pmid">30135782</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Hofmann</surname><given-names>SG</given-names></name>, <name><surname>Asnaani</surname><given-names>A</given-names></name>, <name><surname>Vonk</surname><given-names>IJJ</given-names></name>, <name><surname>Sawyer</surname><given-names>AT</given-names></name>, <name><surname>Fang</surname><given-names>A</given-names></name>. <article-title>The efficacy of cognitive behavioral therapy: a review of meta-analyses</article-title>. <source>Cognit Ther Res</source>. <year>2012</year>;<volume>36</volume>(<issue>5</issue>):<fpage>427</fpage>&#x02013;<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10608-012-9476-1</pub-id>
<pub-id pub-id-type="pmid">23459093</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Lattie</surname><given-names>EG</given-names></name>, <name><surname>Adkins</surname><given-names>EC</given-names></name>, <name><surname>Winquist</surname><given-names>N</given-names></name>, <name><surname>Stiles-Shields</surname><given-names>C</given-names></name>, <name><surname>Wafford</surname><given-names>QE</given-names></name>, <name><surname>Graham</surname><given-names>AK</given-names></name>. <article-title>Digital Mental Health Interventions for Depression, Anxiety, and Enhancement of Psychological Well-Being Among College Students: Systematic Review</article-title>. <source>J Med Internet Res</source>. <year>2019</year>;<volume>21</volume>(<issue>7</issue>):<fpage>e12869</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/12869</pub-id>
<pub-id pub-id-type="pmid">31333198</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Griffiths</surname><given-names>KM</given-names></name>, <name><surname>Farrer</surname><given-names>L</given-names></name>, <name><surname>Christensen</surname><given-names>H</given-names></name>. <article-title>The efficacy of internet interventions for depression and anxiety disorders: A review of randomised controlled trials</article-title>. <source>Med J Aust</source>. <year>2010</year>;<volume>192</volume>(<issue>suppl 11</issue>).</mixed-citation></ref><ref id="pone.0323490.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Titov</surname><given-names>N</given-names></name>, <name><surname>Andrews</surname><given-names>G</given-names></name>, <name><surname>Choi</surname><given-names>I</given-names></name>, <name><surname>Schwencke</surname><given-names>G</given-names></name>, <name><surname>Mahoney</surname><given-names>A</given-names></name>. <article-title>Shyness 3: randomized controlled trial of guided versus unguided Internet-based CBT for social phobia</article-title>. <source>Aust N Z J Psychiatry</source>. <year>2008</year>;<volume>42</volume>(<issue>12</issue>):<fpage>1030</fpage>&#x02013;<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/00048670802512107</pub-id>
<pub-id pub-id-type="pmid">19016091</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Titov</surname><given-names>N</given-names></name>, <name><surname>Andrews</surname><given-names>G</given-names></name>, <name><surname>Choi</surname><given-names>I</given-names></name>, <name><surname>Schwencke</surname><given-names>G</given-names></name>. <article-title>Treatment of social phobia without clinician guidance</article-title>. <source>Aust N Z J Psychiatry</source>. <year>2010</year>;<volume>43</volume>(<issue>10</issue>):<fpage>913</fpage>.</mixed-citation></ref><ref id="pone.0323490.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Carlbring</surname><given-names>P</given-names></name>, <name><surname>Andersson</surname><given-names>G</given-names></name>, <name><surname>Cuijpers</surname><given-names>P</given-names></name>, <name><surname>Riper</surname><given-names>H</given-names></name>, <name><surname>Hedman-Lagerl&#x000f6;f</surname><given-names>E</given-names></name>. <article-title>Internet-based vs. face-to-face cognitive behavior therapy for psychiatric and somatic disorders: an updated systematic review and meta-analysis</article-title>. <source>Cogn Behav Ther</source>. <year>2018</year>;<volume>47</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>18</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/16506073.2017.1401115</pub-id>
<pub-id pub-id-type="pmid">29215315</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Rathenau</surname><given-names>S</given-names></name>, <name><surname>Sousa</surname><given-names>D</given-names></name>, <name><surname>Vaz</surname><given-names>A</given-names></name>, <name><surname>Geller</surname><given-names>S</given-names></name>. <article-title>The effect of attitudes toward online therapy and the difficulties perceived in online therapeutic presence</article-title>. <source>Journal of Psychotherapy Integration</source>. <year>2022</year>;<volume>32</volume>(<issue>1</issue>):<fpage>19</fpage>&#x02013;<lpage>33</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037/int0000266</pub-id></mixed-citation></ref><ref id="pone.0323490.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Vedaa</surname><given-names>&#x000d8;</given-names></name>, <name><surname>Hagatun</surname><given-names>S</given-names></name>, <name><surname>Kallestad</surname><given-names>H</given-names></name>, <name><surname>Pallesen</surname><given-names>S</given-names></name>, <name><surname>Smith</surname><given-names>ORF</given-names></name>, <name><surname>Thorndike</surname><given-names>FP</given-names></name>, <etal>et al</etal>. <article-title>Long-Term Effects of an Unguided Online Cognitive Behavioral Therapy for Chronic Insomnia</article-title>. <source>J Clin Sleep Med</source>. <year>2019</year>;<volume>15</volume>(<issue>1</issue>):<fpage>101</fpage>&#x02013;<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5664/jcsm.7580</pub-id>
<pub-id pub-id-type="pmid">30621837</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Ellis</surname><given-names>D</given-names></name>, <name><surname>Draheim</surname><given-names>A</given-names></name>, <name><surname>Anderson</surname><given-names>P</given-names></name>. <article-title>Culturally adapted digital mental health interventions for ethnic/racial minorities: a systematic review and meta-analysis</article-title>. <source>J Consult Clin Psychol</source>. <year>2022</year>.</mixed-citation></ref><ref id="pone.0323490.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Himle</surname><given-names>JA</given-names></name>, <name><surname>Weaver</surname><given-names>A</given-names></name>, <name><surname>Zhang</surname><given-names>A</given-names></name>, <name><surname>Xiang</surname><given-names>X</given-names></name>. <article-title>Digital Mental Health Interventions for Depression</article-title>. <source>Cognitive and Behavioral Practice</source>. <year>2022</year>;<volume>29</volume>(<issue>1</issue>):<fpage>50</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cbpra.2020.12.009</pub-id></mixed-citation></ref><ref id="pone.0323490.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Lehtimaki</surname><given-names>S</given-names></name>, <name><surname>Martic</surname><given-names>J</given-names></name>, <name><surname>Wahl</surname><given-names>B</given-names></name>, <name><surname>Foster</surname><given-names>KT</given-names></name>, <name><surname>Schwalbe</surname><given-names>N</given-names></name>. <article-title>Evidence on Digital Mental Health Interventions for Adolescents and Young People: Systematic Overview</article-title>. <source>JMIR Ment Health</source>. <year>2021</year>;<volume>8</volume>(<issue>4</issue>):<fpage>e25847</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/25847</pub-id>
<pub-id pub-id-type="pmid">33913817</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Christensen</surname><given-names>H</given-names></name>, <name><surname>Griffiths</surname><given-names>KM</given-names></name>, <name><surname>Farrer</surname><given-names>L</given-names></name>. <article-title>Adherence in internet interventions for anxiety and depression</article-title>. <source>J Med Internet Res</source>. <year>2009</year>;<volume>11</volume>(<issue>2</issue>):<fpage>e13</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/jmir.1194</pub-id>
<pub-id pub-id-type="pmid">19403466</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Richards</surname><given-names>D</given-names></name>, <name><surname>Richardson</surname><given-names>T</given-names></name>. <article-title>Computer-based psychological treatments for depression: A systematic review and meta-analysis</article-title>. <source>Clin Psychol Rev [Internet</source>]. <year>2012</year>;<volume>32</volume>(<issue>4</issue>):<fpage>329</fpage>&#x02013;<lpage>42</lpage>. <source>Available from</source>: <pub-id pub-id-type="doi">10.1016/j.cpr.2012.02.004</pub-id><pub-id pub-id-type="pmid">22466510</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Rehm</surname><given-names>IC</given-names></name>, <name><surname>Foenander</surname><given-names>E</given-names></name>, <name><surname>Wallace</surname><given-names>K</given-names></name>, <name><surname>Abbott</surname><given-names>J-AM</given-names></name>, <name><surname>Kyrios</surname><given-names>M</given-names></name>, <name><surname>Thomas</surname><given-names>N</given-names></name>. <article-title>What Role Can Avatars Play in e-Mental Health Interventions? Exploring New Models of Client-Therapist Interaction</article-title>. <source>Front Psychiatry</source>. <year>2016</year>;<volume>7</volume>:<fpage>186</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fpsyt.2016.00186</pub-id>
<pub-id pub-id-type="pmid">27917128</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Pinto</surname><given-names>MD</given-names></name>, <name><surname>Hickman RL</surname><given-names>Jr</given-names></name>, <name><surname>Clochesy</surname><given-names>J</given-names></name>, <name><surname>Buchner</surname><given-names>M</given-names></name>. <article-title>Avatar-based depression self-management technology: promising approach to improve depressive symptoms among young adults</article-title>. <source>Appl Nurs Res</source>. <year>2013</year>;<volume>26</volume>(<issue>1</issue>):<fpage>45</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.apnr.2012.08.003</pub-id>
<pub-id pub-id-type="pmid">23265918</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Pinto</surname><given-names>MD</given-names></name>, <name><surname>Greenblatt</surname><given-names>AM</given-names></name>, <name><surname>Hickman</surname><given-names>RL</given-names></name>, <name><surname>Rice</surname><given-names>HM</given-names></name>, <name><surname>Thomas</surname><given-names>TL</given-names></name>, <name><surname>Clochesy</surname><given-names>JM</given-names></name>. <article-title>Assessing the Critical Parameters of eSMART-MH: A Promising Avatar-Based Digital Therapeutic Intervention to Reduce Depressive Symptoms</article-title>. <source>Perspect Psychiatr Care</source>. <year>2016</year>;<volume>52</volume>(<issue>3</issue>):<fpage>157</fpage>&#x02013;<lpage>68</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/ppc.12112</pub-id>
<pub-id pub-id-type="pmid">25800698</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Holst</surname><given-names>A</given-names></name>, <name><surname>Nejati</surname><given-names>S</given-names></name>, <name><surname>Bj&#x000f6;rkelund</surname><given-names>C</given-names></name>, <name><surname>Eriksson</surname><given-names>MCM</given-names></name>, <name><surname>Hange</surname><given-names>D</given-names></name>, <name><surname>Kivi</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Patients&#x02019; experiences of a computerised self-help program for treating depression - a qualitative study of Internet mediated cognitive behavioural therapy in primary care</article-title>. <source>Scand J Prim Health Care</source>. <year>2017</year>;<volume>35</volume>(<issue>1</issue>):<fpage>46</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/02813432.2017.1288813</pub-id>
<pub-id pub-id-type="pmid">28277055</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Karyotaki</surname><given-names>E</given-names></name>, <name><surname>Efthimiou</surname><given-names>O</given-names></name>, <name><surname>Miguel</surname><given-names>C</given-names></name>, <name><surname>Bermpohl</surname><given-names>FMG</given-names></name>, <name><surname>Furukawa</surname><given-names>TA</given-names></name>, <name><surname>Cuijpers</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Internet-Based Cognitive Behavioral Therapy for Depression: A Systematic Review and Individual Patient Data Network Meta-analysis</article-title>. <source>JAMA Psychiatry</source>. <year>2021</year>;<volume>78</volume>(<issue>4</issue>):<fpage>361</fpage>&#x02013;<lpage>71</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1001/jamapsychiatry.2020.4364</pub-id>
<pub-id pub-id-type="pmid">33471111</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Leykin</surname><given-names>Y</given-names></name>, <name><surname>Mu&#x000f1;oz</surname><given-names>RF</given-names></name>, <name><surname>Contreras</surname><given-names>O</given-names></name>, <name><surname>Latham</surname><given-names>MD</given-names></name>. <article-title>Results from a trial of an unsupported internet intervention for depressive symptoms</article-title>. <source>Internet Interv</source>. <year>2014</year>;<volume>1</volume>(<issue>4</issue>):<fpage>175</fpage>&#x02013;<lpage>81</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.invent.2014.09.002</pub-id>
<pub-id pub-id-type="pmid">25485233</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Andersson</surname><given-names>G</given-names></name>, <name><surname>Titov</surname><given-names>N</given-names></name>. <article-title>Advantages and limitations of Internet-based interventions for common mental disorders</article-title>. <source>World Psychiatry</source>. <year>2014</year>;<volume>13</volume>(<issue>1</issue>):<fpage>4</fpage>&#x02013;<lpage>11</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/wps.20083</pub-id>
<pub-id pub-id-type="pmid">24497236</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref036"><label>36</label><mixed-citation publication-type="book"><name><surname>Lee</surname><given-names>KM</given-names></name>. <source>Presence, Explicated</source>. <year>2004</year>. p. <fpage>27</fpage>&#x02013;<lpage>50</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Oh</surname><given-names>CS</given-names></name>, <name><surname>Bailenson</surname><given-names>JN</given-names></name>, <name><surname>Welch</surname><given-names>GF</given-names></name>. <article-title>A systematic review of social presence: definition, antecedents, and implications</article-title>. <source>Front Robot AI</source>. <year>2018</year>;<volume>5</volume>:<fpage>114</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/frobt.2018.00114</pub-id>
<pub-id pub-id-type="pmid">33500993</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Bente</surname><given-names>G</given-names></name>, <name><surname>R&#x000fc;ggenberg</surname><given-names>S</given-names></name>, <name><surname>Kr&#x000e4;mer</surname><given-names>NC</given-names></name>, <name><surname>Eschenburg</surname><given-names>F</given-names></name>. <article-title>Avatar-mediated networking: increasing social presence and interpersonal trust in net-based collaborations</article-title>. <source>Hum Commun Res</source>. <year>2008</year>;<volume>34</volume>(<issue>2</issue>):<fpage>287</fpage>&#x02013;<lpage>318</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Ramirez</surname><given-names>A</given-names></name>, <name><surname>Walther</surname><given-names>J</given-names></name>, <name><surname>Burgoon</surname><given-names>J</given-names></name>, <name><surname>Sunnafrank</surname><given-names>M</given-names></name>. <article-title>Information-seeking strategies, uncertainty, and computer-mediated communication</article-title>. <source>Hum Commun Res</source>. <year>2002</year>;<volume>28</volume>(<issue>2</issue>):<fpage>213</fpage>&#x02013;<lpage>28</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Antheunis</surname><given-names>ML</given-names></name>, <name><surname>Valkenburg</surname><given-names>PM</given-names></name>, <name><surname>Peter</surname><given-names>J</given-names></name>. <article-title>Getting acquainted through social network sites: Testing a model of online uncertainty reduction and social attraction</article-title>. <source>Computers in Human Behavior</source>. <year>2010</year>;<volume>26</volume>(<issue>1</issue>):<fpage>100</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.chb.2009.07.005</pub-id></mixed-citation></ref><ref id="pone.0323490.ref041"><label>41</label><mixed-citation publication-type="journal"><name><surname>Walther</surname><given-names>JB</given-names></name>. <article-title>Interpersonal effects in computer-mediated interaction: A relational perspective</article-title>. <source>Communic Res</source>. <year>1992</year>;<volume>19</volume>(<issue>1</issue>):<fpage>52</fpage>&#x02013;<lpage>90</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref042"><label>42</label><mixed-citation publication-type="book"><name><surname>Pan</surname><given-names>X</given-names></name>, <name><surname>Gillies</surname><given-names>M</given-names></name>, <name><surname>Slater</surname><given-names>M</given-names></name>. <source>The impact of avatar blushing on the duration of interaction between a real and virtual person</source>. <publisher-name>Presence</publisher-name>; <year>2008</year>. p. <fpage>100</fpage>&#x02013;<lpage>6</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>von der P&#x000fc;tten</surname><given-names>AM</given-names></name>, <name><surname>Kr&#x000e4;mer</surname><given-names>NC</given-names></name>, <name><surname>Gratch</surname><given-names>J</given-names></name>, <name><surname>Kang</surname><given-names>S-H</given-names></name>. <article-title>&#x0201c;It doesn&#x02019;t matter what you are!&#x0201d; Explaining social effects of agents and avatars</article-title>. <source>Computers in Human Behavior</source>. <year>2010</year>;<volume>26</volume>(<issue>6</issue>):<fpage>1641</fpage>&#x02013;<lpage>50</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.chb.2010.06.012</pub-id></mixed-citation></ref><ref id="pone.0323490.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Bailenson</surname><given-names>JN</given-names></name>, <name><surname>Swinth</surname><given-names>K</given-names></name>, <name><surname>Hoyt</surname><given-names>C</given-names></name>, <name><surname>Persky</surname><given-names>S</given-names></name>, <name><surname>Dimov</surname><given-names>A</given-names></name>, <name><surname>Blascovich</surname><given-names>J</given-names></name>. <article-title>The Independent and Interactive Effects of Embodied-Agent Appearance and Behavior on Self-Report, Cognitive, and Behavioral Markers of Copresence in Immersive Virtual Environments</article-title>. <source>Presence: Teleoperators &#x00026; Virtual Environments</source>. <year>2005</year>;<volume>14</volume>(<issue>4</issue>):<fpage>379</fpage>&#x02013;<lpage>93</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/105474605774785235</pub-id></mixed-citation></ref><ref id="pone.0323490.ref045"><label>45</label><mixed-citation publication-type="book"><name><surname>Garau</surname><given-names>M</given-names></name>, <name><surname>Slater</surname><given-names>M</given-names></name>, <name><surname>Vinayagamoorthy</surname><given-names>V</given-names></name>, <name><surname>Brogni</surname><given-names>A</given-names></name>, <name><surname>Steed</surname><given-names>A</given-names></name>, <name><surname>Sasse</surname><given-names>M</given-names></name>. <source>The impact of avatar realism and eye gaze control on perceived quality of communication in a shared immersive virtual environment</source>. <publisher-name>Conf Hum Factors Comput Syst &#x02013; Proc</publisher-name>; <year>2003</year>. p. <fpage>529</fpage>&#x02013;<lpage>36</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Nienhuis</surname><given-names>JB</given-names></name>, <name><surname>Owen</surname><given-names>J</given-names></name>, <name><surname>Valentine</surname><given-names>JC</given-names></name>, <name><surname>Winkeljohn Black</surname><given-names>S</given-names></name>, <name><surname>Halford</surname><given-names>TC</given-names></name>, <name><surname>Parazak</surname><given-names>SE</given-names></name>, <etal>et al</etal>. <article-title>Therapeutic alliance, empathy, and genuineness in individual adult psychotherapy: A meta-analytic review</article-title>. <source>Psychother Res</source>. <year>2018</year>;<volume>28</volume>(<issue>4</issue>):<fpage>593</fpage>&#x02013;<lpage>605</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/10503307.2016.1204023</pub-id>
<pub-id pub-id-type="pmid">27389666</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Watson</surname><given-names>JC</given-names></name>, <name><surname>Steckley</surname><given-names>PL</given-names></name>, <name><surname>McMullen</surname><given-names>EJ</given-names></name>. <article-title>The role of empathy in promoting change</article-title>. <source>Psychother Res</source>. <year>2014</year>;<volume>24</volume>(<issue>3</issue>):<fpage>286</fpage>&#x02013;<lpage>98</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/10503307.2013.802823</pub-id>
<pub-id pub-id-type="pmid">24040956</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>H. Alexander</surname><given-names>L</given-names></name>, <name><surname>Alessi</surname><given-names>EJ</given-names></name>. <article-title>A Critical Review of the Conceptualization of Empathy: Toward a Deeper Understanding for Clinical Social Work Practice</article-title>. <source>Clin Soc Work J</source>. <year>2023</year>;<volume>52</volume>(<issue>3</issue>):<fpage>300</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10615-023-00912-z</pub-id></mixed-citation></ref><ref id="pone.0323490.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Voutilainen</surname><given-names>L</given-names></name>, <name><surname>Henttonen</surname><given-names>P</given-names></name>, <name><surname>Kahri</surname><given-names>M</given-names></name>, <name><surname>Ravaja</surname><given-names>N</given-names></name>, <name><surname>Sams</surname><given-names>M</given-names></name>, <name><surname>Per&#x000e4;kyl&#x000e4;</surname><given-names>A</given-names></name>. <article-title>Empathy, Challenge, and Psychophysiological Activation in Therapist-Client Interaction</article-title>. <source>Front Psychol</source>. <year>2018</year>;<volume>9</volume>:<fpage>530</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fpsyg.2018.00530</pub-id>
<pub-id pub-id-type="pmid">29695992</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Vorauer</surname><given-names>JD</given-names></name>, <name><surname>Hodges</surname><given-names>SD</given-names></name>, <name><surname>Hall</surname><given-names>JA</given-names></name>. <article-title>Thought-feeling accuracy in person perception and metaperception: an integrative perspective</article-title>. <source>Annu Rev Psychol</source>. <year>2025</year>;<volume>76</volume>(<issue>1</issue>):<fpage>413</fpage>&#x02013;<lpage>41</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1146/annurev-psych-011624-024416</pub-id>
<pub-id pub-id-type="pmid">39823207</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Knaevelsrud</surname><given-names>C</given-names></name>, <name><surname>Maercker</surname><given-names>A</given-names></name>. <article-title>Does the quality of the working alliance predict treatment outcome in online psychotherapy for traumatized patients?</article-title>
<source>J Med Internet Res</source>. <year>2006</year>;<volume>8</volume>(<issue>4</issue>):<fpage>e31</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/jmir.8.4.e31</pub-id>
<pub-id pub-id-type="pmid">17213049</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Preschl</surname><given-names>B</given-names></name>, <name><surname>Maercker</surname><given-names>A</given-names></name>, <name><surname>Wagner</surname><given-names>B</given-names></name>. <article-title>The working alliance in a randomized controlled trial comparing online with face-to-face cognitive-behavioral therapy for depression</article-title>. <source>BMC Psychiatry</source>. <year>2011</year>;<volume>11</volume>:<fpage>189</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/1471-244X-11-189</pub-id>
<pub-id pub-id-type="pmid">22145768</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Wagner</surname><given-names>B</given-names></name>, <name><surname>Brand</surname><given-names>J</given-names></name>, <name><surname>Schulz</surname><given-names>W</given-names></name>, <name><surname>Knaevelsrud</surname><given-names>C</given-names></name>. <article-title>Online working alliance predicts treatment outcome for posttraumatic stress symptoms in Arab war-traumatized patients</article-title>. <source>Depress Anxiety</source>. <year>2012</year>;<volume>29</volume>(<issue>7</issue>):<fpage>646</fpage>&#x02013;<lpage>51</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/da.21962</pub-id>
<pub-id pub-id-type="pmid">22678971</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Berger</surname><given-names>T</given-names></name>. <article-title>The therapeutic alliance in internet interventions: a narrative review and suggestions for future research</article-title>. <source>Psychother Res</source>. <year>2017</year>;<volume>27</volume>(<issue>5</issue>):<fpage>511</fpage>&#x02013;<lpage>24</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/10503307.2015.1119908</pub-id>
<pub-id pub-id-type="pmid">26732852</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Bickmore</surname><given-names>T</given-names></name>, <name><surname>Gruber</surname><given-names>A</given-names></name>, <name><surname>Picard</surname><given-names>R</given-names></name>. <article-title>Establishing the computer-patient working alliance in automated health behavior change interventions</article-title>. <source>Patient Educ Couns</source>. <year>2005</year>;<volume>59</volume>(<issue>1</issue>):<fpage>21</fpage>&#x02013;<lpage>30</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.pec.2004.09.008</pub-id>
<pub-id pub-id-type="pmid">16198215</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>Miner</surname><given-names>AS</given-names></name>, <name><surname>Milstein</surname><given-names>A</given-names></name>, <name><surname>Hancock</surname><given-names>JT</given-names></name>. <article-title>Talking to machines about personal mental health problems</article-title>. <source>JAMA</source>. <year>2017</year>;<volume>318</volume>(<issue>13</issue>):<fpage>1217</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1001/jama.2017.14151</pub-id>
<pub-id pub-id-type="pmid">28973225</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref057"><label>57</label><mixed-citation publication-type="journal"><name><surname>Bickmore</surname><given-names>TW</given-names></name>, <name><surname>Caruso</surname><given-names>L</given-names></name>, <name><surname>Clough-Gorr</surname><given-names>K</given-names></name>, <name><surname>Heeren</surname><given-names>T</given-names></name>. <article-title>It&#x02019;s just like you talk to a friend relational agents for older adults</article-title>. <source>Interact Comput</source>. <year>2005</year>;<volume>17</volume>(<issue>6</issue>):<fpage>711</fpage>&#x02013;<lpage>35</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Ormrod</surname><given-names>JA</given-names></name>, <name><surname>Kennedy</surname><given-names>L</given-names></name>, <name><surname>Scott</surname><given-names>J</given-names></name>, <name><surname>Cavanagh</surname><given-names>K</given-names></name>. <article-title>Computerised cognitive behavioural therapy in an adult mental health service: a pilot study of outcomes and alliance</article-title>. <source>Cogn Behav Ther</source>. <year>2010</year>;<volume>39</volume>(<issue>3</issue>):<fpage>188</fpage>&#x02013;<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/16506071003675614</pub-id>
<pub-id pub-id-type="pmid">20485996</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref059"><label>59</label><mixed-citation publication-type="journal"><name><surname>Nass</surname><given-names>C</given-names></name>, <name><surname>Moon</surname><given-names>Y</given-names></name>. <article-title>Machines and mindlessness: social responses to computers</article-title>. <source>Journal of Social Issues</source>. <year>2000</year>;<volume>56</volume>(<issue>1</issue>):<fpage>81</fpage>&#x02013;<lpage>103</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/0022-4537.00153</pub-id></mixed-citation></ref><ref id="pone.0323490.ref060"><label>60</label><mixed-citation publication-type="book"><name><surname>Reeves</surname><given-names>B</given-names></name>, <name><surname>Nass</surname><given-names>C</given-names></name>. <source>The Media Equation: How People Treat Computers, Television and New Media Like Real People and Places</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>1996</year>.</mixed-citation></ref><ref id="pone.0323490.ref061"><label>61</label><mixed-citation publication-type="journal"><name><surname>Gambino</surname><given-names>A</given-names></name>, <name><surname>Fox</surname><given-names>J</given-names></name>, <name><surname>Ratan</surname><given-names>R</given-names></name>. <article-title>Building a Stronger CASA: Extending the Computers Are Social Actors Paradigm</article-title>. <source>HMC</source>. <year>2020</year>;<volume>1</volume>:<fpage>71</fpage>&#x02013;<lpage>86</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.30658/hmc.1.5</pub-id></mixed-citation></ref><ref id="pone.0323490.ref062"><label>62</label><mixed-citation publication-type="journal"><name><surname>Qu</surname><given-names>C</given-names></name>, <name><surname>Brinkman</surname><given-names>W-P</given-names></name>, <name><surname>Ling</surname><given-names>Y</given-names></name>, <name><surname>Wiggers</surname><given-names>P</given-names></name>, <name><surname>Heynderickx</surname><given-names>I</given-names></name>. <article-title>Conversations with a virtual human: Synthetic emotions and human responses</article-title>. <source>Computers in Human Behavior</source>. <year>2014</year>;<volume>34</volume>:<fpage>58</fpage>&#x02013;<lpage>68</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.chb.2014.01.033</pub-id></mixed-citation></ref><ref id="pone.0323490.ref063"><label>63</label><mixed-citation publication-type="journal"><name><surname>Bylsma</surname><given-names>LM</given-names></name>, <name><surname>Morris</surname><given-names>BH</given-names></name>, <name><surname>Rottenberg</surname><given-names>J</given-names></name>. <article-title>A meta-analysis of emotional reactivity in major depressive disorder</article-title>. <source>Clin Psychol Rev</source>. <year>2008</year>;<volume>28</volume>(<issue>4</issue>):<fpage>676</fpage>&#x02013;<lpage>91</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cpr.2007.10.001</pub-id>
<pub-id pub-id-type="pmid">18006196</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref064"><label>64</label><mixed-citation publication-type="journal"><name><surname>Kroenke</surname><given-names>K</given-names></name>, <name><surname>Spitzer</surname><given-names>RL</given-names></name>, <name><surname>Williams</surname><given-names>JB</given-names></name>. <article-title>The PHQ-9: validity of a brief depression severity measure</article-title>. <source>J Gen Intern Med</source>. <year>2001</year>;<volume>16</volume>(<issue>9</issue>):<fpage>606</fpage>&#x02013;<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1046/j.1525-1497.2001.016009606.x</pub-id>
<pub-id pub-id-type="pmid">11556941</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref065"><label>65</label><mixed-citation publication-type="journal"><name><surname>V&#x000e4;stfj&#x000e4;ll</surname><given-names>D</given-names></name>, <name><surname>Friman</surname><given-names>M</given-names></name>, <name><surname>G&#x000e4;rling</surname><given-names>T</given-names></name>, <name><surname>Kleiner</surname><given-names>M</given-names></name>. <article-title>The measurement of core affect: a Swedish self-report measure derived from the affect circumplex</article-title>. <source>Scand J Psychol</source>. <year>2002</year>;<volume>43</volume>(<issue>1</issue>):<fpage>19</fpage>&#x02013;<lpage>31</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/1467-9450.00265</pub-id>
<pub-id pub-id-type="pmid">11885757</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref066"><label>66</label><mixed-citation publication-type="journal"><name><surname>V&#x000e4;stfj&#x000e4;ll</surname><given-names>D</given-names></name>, <name><surname>G&#x000e4;rling</surname><given-names>T</given-names></name>. <article-title>Validation of a Swedish short self-report measure of core affect</article-title>. <source>Scand J Psychol</source>. <year>2007</year>;<volume>48</volume>(<issue>3</issue>):<fpage>233</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/j.1467-9450.2007.00595.x</pub-id>
<pub-id pub-id-type="pmid">17518915</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref067"><label>67</label><mixed-citation publication-type="journal"><name><surname>Russell</surname><given-names>JA</given-names></name>. <article-title>Is there universal recognition of emotion from facial expression? A review of the cross-cultural studies</article-title>. <source>Psychol Bull</source>. <year>1994</year>;<volume>115</volume>(<issue>1</issue>):<fpage>102</fpage>&#x02013;<lpage>41</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037/0033-2909.115.1.102</pub-id>
<pub-id pub-id-type="pmid">8202574</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref068"><label>68</label><mixed-citation publication-type="journal"><name><surname>Mauss</surname><given-names>IB</given-names></name>, <name><surname>Levenson</surname><given-names>RW</given-names></name>, <name><surname>McCarter</surname><given-names>L</given-names></name>, <name><surname>Wilhelm</surname><given-names>FH</given-names></name>, <name><surname>Gross</surname><given-names>JJ</given-names></name>. <article-title>The tie that binds? Coherence among emotion experience, behavior, and physiology</article-title>. <source>Emotion</source>. <year>2005</year>;<volume>5</volume>(<issue>2</issue>):<fpage>175</fpage>&#x02013;<lpage>90</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037/1528-3542.5.2.175</pub-id>
<pub-id pub-id-type="pmid">15982083</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref069"><label>69</label><mixed-citation publication-type="journal"><name><surname>Mauss</surname><given-names>IB</given-names></name>, <name><surname>Robinson</surname><given-names>MD</given-names></name>. <article-title>Measures of emotion: A review</article-title>. <source>Cogn Emot</source>. <year>2009</year>;<volume>23</volume>(<issue>2</issue>):<fpage>209</fpage>&#x02013;<lpage>37</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/02699930802204677</pub-id>
<pub-id pub-id-type="pmid">19809584</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref070"><label>70</label><mixed-citation publication-type="book"><name><surname>Bishay</surname><given-names>M</given-names></name>, <name><surname>Preston</surname><given-names>K</given-names></name>, <name><surname>Strafuss</surname><given-names>M</given-names></name>, <name><surname>Page</surname><given-names>G</given-names></name>, <name><surname>Turcot</surname><given-names>J</given-names></name>, <name><surname>Mavadati</surname><given-names>M</given-names></name>. <source>Affdex 2.0: A real-time facial expression analysis toolkit</source>. <year>2022</year>.</mixed-citation></ref><ref id="pone.0323490.ref071"><label>71</label><mixed-citation publication-type="journal"><name><surname>Ekman</surname><given-names>P</given-names></name>, <name><surname>Friesen</surname><given-names>WV</given-names></name>. <article-title>Constants across cultures in the face and emotion</article-title>. <source>J Pers Soc Psychol</source>. <year>1971</year>;<volume>17</volume>(<issue>2</issue>):<fpage>124</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037/h0030377</pub-id>
<pub-id pub-id-type="pmid">5542557</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref072"><label>72</label><mixed-citation publication-type="journal"><name><surname>St&#x000f6;ckli</surname><given-names>S</given-names></name>, <name><surname>Schulte-Mecklenbeck</surname><given-names>M</given-names></name>, <name><surname>Borer</surname><given-names>S</given-names></name>, <name><surname>Samson</surname><given-names>AC</given-names></name>. <article-title>Facial expression analysis with AFFDEX and FACET: A validation study</article-title>. <source>Behav Res Methods</source>. <year>2018</year>;<volume>50</volume>(<issue>4</issue>):<fpage>1446</fpage>&#x02013;<lpage>60</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3758/s13428-017-0996-1</pub-id>
<pub-id pub-id-type="pmid">29218587</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref073"><label>73</label><mixed-citation publication-type="journal"><name><surname>Mercer</surname><given-names>SW</given-names></name>, <name><surname>Maxwell</surname><given-names>M</given-names></name>, <name><surname>Heaney</surname><given-names>D</given-names></name>, <name><surname>Watt</surname><given-names>GC</given-names></name>. <article-title>The consultation and relational empathy (CARE) measure: development and preliminary validation and reliability of an empathy-based consultation process measure</article-title>. <source>Fam Pract</source>. <year>2004</year>;<volume>21</volume>(<issue>6</issue>):<fpage>699</fpage>&#x02013;<lpage>705</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/fampra/cmh621</pub-id>
<pub-id pub-id-type="pmid">15528286</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref074"><label>74</label><mixed-citation publication-type="journal"><name><surname>Crosta Ahlforn</surname><given-names>K</given-names></name>, <name><surname>Bojner Horwitz</surname><given-names>E</given-names></name>, <name><surname>Osika</surname><given-names>W</given-names></name>. <article-title>A Swedish version of the Consultation and Relational Empathy (CARE) measure</article-title>. <source>Scand J Prim Health Care</source>. <year>2017</year>;<volume>35</volume>(<issue>3</issue>):<fpage>286</fpage>&#x02013;<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/02813432.2017.1358853</pub-id>
<pub-id pub-id-type="pmid">28768444</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref075"><label>75</label><mixed-citation publication-type="journal"><name><surname>Kersten</surname><given-names>P</given-names></name>, <name><surname>White</surname><given-names>PJ</given-names></name>, <name><surname>Tennant</surname><given-names>A</given-names></name>. <article-title>The consultation and relational empathy measure: an investigation of its scaling structure</article-title>. <source>Disabil Rehabil</source>. <year>2012</year>;<volume>34</volume>(<issue>6</issue>):<fpage>503</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3109/09638288.2011.610493</pub-id>
<pub-id pub-id-type="pmid">21981037</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref076"><label>76</label><mixed-citation publication-type="book"><name><surname>Sommers-Flanagan</surname><given-names>J</given-names></name>, <name><surname>Shaw</surname><given-names>S.</given-names></name>
<article-title>Clinical interviews.</article-title> In: <name><surname>Wenzel</surname><given-names>A</given-names></name>, editor. <source>The SAGE Encyclopedia of Abnormal and Clinical Psychology</source>. <publisher-loc>Thousand Oaks, California</publisher-loc>: <publisher-name>SAGE Publications, Inc.</publisher-name>; <year>2017</year>.</mixed-citation></ref><ref id="pone.0323490.ref077"><label>77</label><mixed-citation publication-type="book"><collab>R Core Team</collab>. <source>R Development Core Team</source>. Vol. <volume>55</volume>. <publisher-name>R: A Language and Environment for Statistical Computing;</publisher-name>
<year>2016</year>. p. <fpage>275</fpage>&#x02013;<lpage>86</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref078"><label>78</label><mixed-citation publication-type="journal"><name><surname>RUBIN</surname><given-names>DB</given-names></name>. <article-title>Inference and missing data</article-title>. <source>Biometrika</source>. <year>1976</year>;<volume>63</volume>(<issue>3</issue>):<fpage>581</fpage>&#x02013;<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/63.3.581</pub-id></mixed-citation></ref><ref id="pone.0323490.ref079"><label>79</label><mixed-citation publication-type="book"><name><surname>Little</surname><given-names>RJ</given-names></name>, <name><surname>Rubin</surname><given-names>DB</given-names></name>. <article-title>Missing Data [Internet].</article-title>
<source>International Encyclopedia of the Social &#x00026; Behavioral Sciences: Second Edition</source>. <source>2nd ed</source>. Vol. <volume>15</volume>. <publisher-name>Elsevier</publisher-name>; <year>2015</year>. p. <fpage>602</fpage>&#x02013;<lpage>7</lpage>. Available from: <pub-id pub-id-type="doi">10.1016/B978-0-08-097086-8.42082-9</pub-id></mixed-citation></ref><ref id="pone.0323490.ref080"><label>80</label><mixed-citation publication-type="journal"><name><surname>van Buuren</surname><given-names>S</given-names></name>, <name><surname>Groothuis-Oudshoorn</surname><given-names>K</given-names></name>. <article-title>Mice: multivariate imputation by chained equations in R</article-title>. <source>J Stat Softw</source>. <year>2011</year>;<volume>45</volume>(<issue>3</issue>):<fpage>1</fpage>&#x02013;<lpage>67</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref081"><label>81</label><mixed-citation publication-type="journal"><name><surname>Schafer</surname><given-names>JL</given-names></name>, <name><surname>Graham</surname><given-names>JW</given-names></name>. <article-title>Missing data: our view of the state of the art</article-title>. <source>Psychol Methods</source>. <year>2002</year>;<volume>7</volume>(<issue>2</issue>):<fpage>147</fpage>&#x02013;<lpage>77</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037//1082-989x.7.2.147</pub-id>
<pub-id pub-id-type="pmid">12090408</pub-id>
</mixed-citation></ref><ref id="pone.0323490.ref082"><label>82</label><mixed-citation publication-type="book"><name><surname>Singmann</surname><given-names>E</given-names></name>, <name><surname>Bolker</surname><given-names>B</given-names></name>, <name><surname>Westfall</surname><given-names>J</given-names></name>, <name><surname>Aust</surname><given-names>F</given-names></name>, <name><surname>Ben-Shachar</surname><given-names>MS</given-names></name>. <source>afex: analysis of factorial experiments</source>. <publisher-name>R package</publisher-name>; <year>2019</year>.</mixed-citation></ref><ref id="pone.0323490.ref083"><label>83</label><mixed-citation publication-type="book"><name><surname>Lenth</surname><given-names>R</given-names></name>, <name><surname>Singmann</surname><given-names>H</given-names></name>, <name><surname>Love</surname><given-names>J</given-names></name>, <name><surname>Buerkner</surname><given-names>P</given-names></name>, <name><surname>Herve</surname><given-names>M</given-names></name>. <source>Package &#x0201c;emmeans.&#x0201d; CRAN</source>. <year>2019</year>.</mixed-citation></ref><ref id="pone.0323490.ref084"><label>84</label><mixed-citation publication-type="book"><name><surname>Fox</surname><given-names>J</given-names></name>, <name><surname>Weisberg</surname><given-names>S</given-names></name>. <source>An R Companion to Applied Regression: Appendices. 3rd ed</source>. <publisher-name>SAGE</publisher-name>; <year>2019</year>.</mixed-citation></ref><ref id="pone.0323490.ref085"><label>85</label><mixed-citation publication-type="journal"><name><surname>Korkmaz</surname><given-names>S</given-names></name>, <name><surname>Goksuluk</surname><given-names>D</given-names></name>, <name><surname>Zararsiz</surname><given-names>G</given-names></name>. <article-title>MVN: An R Package for Assessing Multivariate Normality</article-title>. <source>The R Journal</source>. <year>2014</year>;<volume>6</volume>(<issue>2</issue>):<fpage>151</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.32614/rj-2014-031</pub-id></mixed-citation></ref><ref id="pone.0323490.ref086"><label>86</label><mixed-citation publication-type="book"><name><surname>Dinno</surname><given-names>A</given-names></name>. <source>Dunn&#x02019;s test of multiple comparisons using rank sums</source>. <year>2017</year>.</mixed-citation></ref><ref id="pone.0323490.ref087"><label>87</label><mixed-citation publication-type="journal"><name><surname>Blascovich</surname><given-names>J</given-names></name>, <name><surname>Loomis</surname><given-names>J</given-names></name>, <name><surname>Beall</surname><given-names>AC</given-names></name>, <name><surname>Swinth</surname><given-names>KR</given-names></name>, <name><surname>Hoyt</surname><given-names>CL</given-names></name>, <name><surname>Bailenson</surname><given-names>JN</given-names></name>. <article-title>Immersive virtual environment technology as a methodological tool for social psychology</article-title>. <source>Psychol Inq</source>. <year>2002</year>;<volume>13</volume>(<issue>2</issue>):<fpage>103</fpage>&#x02013;<lpage>24</lpage>.</mixed-citation></ref><ref id="pone.0323490.ref088"><label>88</label><mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>J</given-names></name>, <name><surname>Ahn SJ</surname><given-names>(Grace)</given-names></name>, <name><surname>Janssen</surname><given-names>JH</given-names></name>, <name><surname>Yeykelis</surname><given-names>L</given-names></name>, <name><surname>Segovia</surname><given-names>KY</given-names></name>, <name><surname>Bailenson</surname><given-names>JN</given-names></name>. <article-title>Avatars Versus Agents: A Meta-Analysis Quantifying the Effect of Agency on Social Influence</article-title>. <source>Human&#x02013;Computer Interaction</source>. <year>2014</year>;<volume>30</volume>(<issue>5</issue>):<fpage>401</fpage>&#x02013;<lpage>32</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/07370024.2014.921494</pub-id></mixed-citation></ref></ref-list></back></article>