<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" dtd-version="1.3" xml:lang="EN" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Chem Inf Model</journal-id><journal-id journal-id-type="iso-abbrev">J Chem Inf Model</journal-id><journal-id journal-id-type="publisher-id">ci</journal-id><journal-id journal-id-type="coden">jcisd8</journal-id><journal-title-group><journal-title>Journal of Chemical Information and Modeling</journal-title></journal-title-group><issn pub-type="ppub">1549-9596</issn><issn pub-type="epub">1549-960X</issn><publisher><publisher-name>American Chemical Society</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39899705</article-id><article-id pub-id-type="pmc">PMC11863383</article-id>
<article-id pub-id-type="doi">10.1021/acs.jcim.4c01799</article-id><article-categories><subj-group><subject>Article</subject></subj-group></article-categories><title-group><article-title>OPLS-Based Multiclass
Classification and Data-Driven
Interclass Relationship Discovery</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="ath1"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1898-4453</contrib-id><name><surname>Forsgren</surname><given-names>Edvin</given-names></name><xref rid="cor1" ref-type="other">*</xref><xref rid="aff1" ref-type="aff">&#x02020;</xref></contrib><contrib contrib-type="author" id="ath2"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-9347-5790</contrib-id><name><surname>Bj&#x000f6;rkblom</surname><given-names>Benny</given-names></name><xref rid="aff2" ref-type="aff">&#x02021;</xref></contrib><contrib contrib-type="author" id="ath3"><name><surname>Trygg</surname><given-names>Johan</given-names></name><xref rid="aff1" ref-type="aff">&#x02020;</xref><xref rid="aff3" ref-type="aff">&#x000a7;</xref></contrib><contrib contrib-type="author" id="ath4"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8357-5018</contrib-id><name><surname>Jonsson</surname><given-names>P&#x000e4;r</given-names></name><xref rid="aff3" ref-type="aff">&#x000a7;</xref></contrib><aff id="aff1"><label>&#x02020;</label>Computational
Life Science Cluster (CLiC), Department of Chemistry, <institution>Ume&#x000e5; University</institution>, SE-901 87 Ume&#x000e5;, <country>Sweden</country></aff><aff id="aff2"><label>&#x02021;</label>Department
of Chemistry, <institution>Ume&#x000e5; University</institution>, SE-901 87 Ume&#x000e5;, <country>Sweden</country></aff><aff id="aff3"><label>&#x000a7;</label><institution>Sartorius
Corporate Research</institution>, SE-903
33 Ume&#x000e5;, <country>Sweden</country></aff></contrib-group><author-notes><corresp id="cor1"><label>*</label>Email: <email>edvin.forsgren@umu.se</email>.</corresp></author-notes><pub-date pub-type="epub"><day>03</day><month>02</month><year>2025</year></pub-date><pub-date pub-type="collection"><day>24</day><month>02</month><year>2025</year></pub-date><volume>65</volume><issue>4</issue><fpage>1762</fpage><lpage>1770</lpage><history><date date-type="received"><day>04</day><month>10</month><year>2024</year></date><date date-type="accepted"><day>17</day><month>01</month><year>2025</year></date><date date-type="rev-recd"><day>16</day><month>01</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 The Authors. Published by American Chemical Society</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>The Authors</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Permits the broadest form of re-use including for commercial purposes, provided that author attribution and integrity are maintained (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p content-type="toc-graphic"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_0005" id="ab-tgr1"/></p><p>Multiclass data sets and large-scale studies are increasingly
common
in omics sciences, drug discovery, and clinical research due to advancements
in analytical platforms. Efficiently handling these data sets and
discerning subtle differences across multiple classes remains a significant
challenge. In metabolomics, two-class orthogonal projection to latent
structures discriminant analysis (OPLS-DA) models are widely used
due to their strong discrimination capabilities and ability to provide
interpretable information on class differences. However, these models
face challenges in multiclass settings. A common solution is to transform
the multiclass comparison into multiple two-class comparisons, which,
while more effective than a global multiclass OPLS-DA model, unfortunately
results in a manual, time-consuming model-building process with complicated
interpretation. Here, we introduce an extension of OPLS-DA for data-driven
multiclass classification: orthogonal partial least squares-hierarchical
discriminant analysis (OPLS-HDA). OPLS-HDA integrates hierarchical
cluster analysis (HCA) with the OPLS-DA framework to create a decision
tree, addressing multiclass classification challenges and providing
intuitive visualization of interclass relationships. To avoid overfitting
and ensure reliable predictions, we use cross-validation during model
building. Benchmark results show that OPLS-HDA performs competitively
across diverse data sets compared to eight established methods. This
method represents a significant advancement, offering a powerful tool
to dissect complex multiclass data sets. With its versatility, interpretability,
and ease of use, OPLS-HDA is an efficient approach to multiclass data
analysis applicable across various fields.</p></abstract><custom-meta-group><custom-meta><meta-name>document-id-old-9</meta-name><meta-value>ci4c01799</meta-value></custom-meta><custom-meta><meta-name>document-id-new-14</meta-name><meta-value>ci4c01799</meta-value></custom-meta><custom-meta><meta-name>ccc-price</meta-name><meta-value/></custom-meta></custom-meta-group></article-meta></front><body><sec id="sec1"><title>Introduction</title><p>Partial least-squares or projection to
latent structures (PLS)
regression was first introduced in the 1970s by Herman Wold to handle
cases where there are more descriptor variables than observations.<sup><xref ref-type="bibr" rid="ref1">1</xref></sup> Back then, PLS was built to predict a single
response variable. Since then, it has evolved in several steps<sup><xref ref-type="bibr" rid="ref2">2</xref></sup> with orthogonal PLS (OPLS) being introduced in
2002.<sup><xref ref-type="bibr" rid="ref3">3</xref></sup> OPLS simplifies interpretation by
dividing the variation in descriptor variables into two parts: &#x0201c;predictive&#x0201d;
variation related to the response(s) and &#x0201c;orthogonal&#x0201d;
variation i.e., not related to the response(s). Regarding predictive
power, OPLS and PLS are identical for single response variable models
but due to the simplified interpretation, OPLS has gained popularity
in fields where understanding the connection between descriptor- and
response variables is crucial. Often, the response variable is categorical.
Although regression was the original use of both PLS and OPLS, they
are now commonly used for classification or discriminant analysis
(DA) to distinguish between two or more groups or classes of samples.
This type of classification works well for two classes, both in terms
of discrimination and interpreting differences between classes. Several
methods have been developed for interpreting differences between classes
in two-class OPLS-DA models e.g., statistical total correlation spectroscopy
(STOCSY),<sup><xref ref-type="bibr" rid="ref4">4</xref></sup> the S-plot<sup><xref ref-type="bibr" rid="ref5">5</xref></sup> and selective-ratio.<sup><xref ref-type="bibr" rid="ref6">6</xref></sup> The latter
was initially developed for PLS-DA but later adopted for OPLS-DA.<sup><xref ref-type="bibr" rid="ref7">7</xref></sup> However, as the number of classes increases,
PLS/OPLS-DA suffer in both interpretability and predictive power.
The decline in performance is due to the &#x0201c;one-vs-rest&#x0201d;
classification approach used in PLS/OPLS-DA models. This setup presents
a challenge when one class is positioned between two others, which,
combined with the linear nature of PLS/OPLS, results in weak models
and complex interpretation.</p><p>A common approach to deal with this
problem is to make multiple
pairwise comparisons, &#x0201c;one-vs-one&#x0201d; models. These models
can then be compared using SUS-plots (Shared and Unique Structure).<sup><xref ref-type="bibr" rid="ref5">5</xref></sup> SUS-plots are especially useful when multiple
groups are compared against one control or reference group, such as
different genotypes vs wild-type or different treatments vs untreated
controls. This manual approach works well when the number of classes
is small but quickly becomes challenging to manage as the number of
classes increases. Despite these challenges, pairwise OPLS-DA is still
widely adopted in omics for interpreting biological differences between
different classes. Applications include differentiating brain cancer
types,<sup><xref ref-type="bibr" rid="ref8">8</xref></sup> metabolomics in diet intervention
studies,<sup><xref ref-type="bibr" rid="ref9">9</xref></sup> metabolite distribution patterns,<sup><xref ref-type="bibr" rid="ref10">10</xref></sup> and gene feature selection with microarray data.<sup><xref ref-type="bibr" rid="ref11">11</xref></sup> While manually creating multiple &#x0201c;one-vs-one&#x0201d;
OPLS-DA models has been proven useful, it is a time-consuming process,
both when creating the models and to summarize them into comprehensive
results.</p><p>To circumvent most of the manual work, the Automatic
Hierarchical
Model Builder (AHiMBu)<sup><xref ref-type="bibr" rid="ref12">12</xref>,<xref ref-type="bibr" rid="ref13">13</xref></sup> was introduced to handle these
multiclass cases. And, although more effective than PLS-DA and a manual
approach, there is still improvements to be made in terms of flexibility
and interpretability.</p><p>Here, we introduce a data-driven methodology
that combines two
proven frameworks hierarchical cluster analysis (HCA) with OPLS-DA,
to create OPLS-hierarchical discriminant analysis (OPLS-HDA). OPLS-HDA
is developed to handle multiclass data sets where there are different
levels of variation to reveal the hierarchical relations between classes
while still detailing the discriminatory level. Employing OPLS-DA
models as the foundation and a flexible approach to the hierarchical
structure, provides OPLS-HDA with significant advantages over existing
methods. In addition to increased interpretability and flexibility,
we also show that OPLS-HDA has competitive classification abilities
compared to other popular methods on a wide range of data sets. In
this work, we use OPLS as the framework, though it is important to
note that a PLS-based framework would have the same predictive ability.</p></sec><sec id="sec2"><title>Theory</title><sec id="sec2.1"><title>Orthogonal Projections to Latent Structure Discriminant Analysis&#x02014;OPLS-DA</title><p>OPLS is a supervised multivariate projection method that uses latent
variables to establish a linear relationship between the descriptor
variables in the predictor matrix (<bold>X</bold>) and a response
vector (<bold>y</bold>) or matrix (<bold>Y</bold>) for a specified
set of observations. OPLS can be used even when the number of observations
is smaller than the number of variables. It can handle correlated
variables, noisy variables and missing values. This robust and versatile
technique is applicable to a wide range of analytical tasks, including
regression<sup><xref ref-type="bibr" rid="ref3">3</xref></sup> and discrimination,<sup><xref ref-type="bibr" rid="ref14">14</xref></sup> the latter being facilitated through OPLS-DA.
In OPLS-DA, the response matrix (<bold>Y</bold>) is a dummy matrix
that contains the information about class membership for each observation.
OPLS separates the variation described by the model into two different
parts, predictive and orthogonal. The predictive part is the variation
in <bold>X</bold> (<xref rid="eq1" ref-type="disp-formula">eq <xref rid="eq1" ref-type="disp-formula">1</xref></xref>) that is used to model the variation in <bold>Y</bold> (<xref rid="eq2" ref-type="disp-formula">eq <xref rid="eq2" ref-type="disp-formula">2</xref></xref>). The orthogonal part
contains variation in <bold>X</bold> (<xref rid="eq1" ref-type="disp-formula">eq <xref rid="eq1" ref-type="disp-formula">1</xref></xref>) that is unrelated to the response <bold>Y</bold>.
In the OPLS-DA context, the predictive part contains between class
variation while the orthogonal part contains within class variation.
By dividing the variation into two parts, the interpretation of the
model becomes easier.<disp-formula id="eq1"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_m001" position="anchor"/><label>1</label></disp-formula><disp-formula id="eq2"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_m002" position="anchor"/><label>2</label></disp-formula></p></sec><sec id="sec2.2"><title>Cross-Validation&#x02014;CV</title><p>By dividing the training
set into <italic>k</italic> groups and iterating over the groups,
leaving one group out at a time, we can validate our model and get
an estimation on how well it will perform on a test set. The cv-predictions
i.e., prediction of samples when they are left out of the model denoted
as <italic><bold>&#x00177;</bold></italic><sub>cv</sub>, are used to
determine the number of components to use in the final model by using
the prediction error to decide whether to keep an additional component
or not. The <italic><bold>&#x00177;</bold></italic><sub>cv</sub> and
the cv-scores of the samples in the training data set are also useful
to understand and interpret the data in a more realistic way than
pure predictions of samples that are present in the model and is especially
useful if data is scarce.<sup><xref ref-type="bibr" rid="ref15">15</xref></sup></p></sec><sec id="sec2.3"><title>Distance Metric</title><p>The cv-predictions from two-class OPLS-DA
models can be used to estimate the separability between classes. A
suitable distance metrics for this is Cohen&#x02019;s <italic>d</italic>,<sup><xref ref-type="bibr" rid="ref16">16</xref></sup> defined in <xref rid="eq3" ref-type="disp-formula">eq <xref rid="eq3" ref-type="disp-formula">3</xref></xref>, which takes into account both the distance
between classes and variation within them.<disp-formula id="eq3"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_m003" position="anchor"/><label>3</label></disp-formula>Here, <italic>m</italic><sub>0</sub> and <italic>m</italic><sub>1</sub> are the means of the <italic><bold>&#x00177;</bold></italic><sub>cv</sub> of the two classes and <italic>s</italic><sub>p</sub> the pooled standard deviations defined as in <xref rid="eq4" ref-type="disp-formula">eq <xref rid="eq4" ref-type="disp-formula">4</xref></xref>.<disp-formula id="eq4"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_m004" position="anchor"/><label>4</label></disp-formula>Here, <italic>ss</italic> is the pooled sum
of squares of the two classes and <italic>n</italic> is the number
of observations in each class. The distance between the class means
represents how well the OPLS-DA model can separate the classes, while
the pooled standard deviation is a measure of the variability within
the two classes. A model that can clearly distinguish between the
two classes will result in a strong and valid model, characterized
by predicted responses that are close to the actual targets (0 or
1) and a small pooled standard deviation, leading to a large Cohen&#x02019;s <italic>d</italic> value. Conversely, in the case of weak models, the predictions
for samples from both classes cluster close to the mean value of the <italic>y</italic>-vector. For a balanced data set, this value equals 0.5.
This clustering is typically accompanied by a large standard deviation,
which indicates poor separation between the classes. Consequently,
such a scenario results in a small Cohen&#x02019;s <italic>d</italic> value.</p></sec><sec id="sec2.4"><title>Hierarchical Cluster Analysis&#x02014;HCA</title><p>HCA seeks
the hierarchy of groups or individual observations based on a symmetrical
distance matrix. There are two types of HCA, &#x0201c;bottom-up&#x0201d;
(agglomerative) or &#x0201c;top-down&#x0201d; (divisive). For agglomerative,
each observation starts as their own cluster and is then grouped successively.
For divisive, all observations start in one cluster and are then divided
into smaller ones successively. In this paper, we will refer to agglomerative
HCA as HCA.</p></sec></sec><sec id="sec3"><title>Methodology</title><p>An OPLS-HDA model integrates the global
interpretation and visual
framework of dendrograms created with HCA with the predictive strength
and detailed interpretation benefits of two-class OPLS-DA models.
Put simply, an OPLS-HDA model is a top-down decision tree with a two-class
OPLS-DA model in each decision node.</p><p>To create the hierarchy
of the OPLS-HDA model, the relationships
between all classes are mapped. This mapping is achieved by calculating
all combinations of one-vs-one OPLS-DA models. Based on these models,
the Cohen&#x02019;s <italic>d</italic> between all the classes is calculated
and stored in a distance matrix. This matrix is then used to create
a dendrogram that forms the basis of the top-down decision tree populated
with two-class OPLS-DA models. This integration creates a model that
is interpretable at two levels: the hierarchical level, where the
structure of the decision tree reveals the similarities and differences
between classes, and the discrimination level, where the OPLS-DA models
reveal details regarding how classes or groups of classes are differentiated
from one another. An overview is shown in <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref> and a detailed description of the setup
and the model building is given below.</p><fig id="fig1" position="float"><label>Figure 1</label><caption><p>Observations of known
classes, characterized by a common set of
variables, serve as the starting point. The next step, (a), involves
calculating all possible pairwise OPLS-DA models. From these models,
Cohen&#x02019;s <italic>d</italic>s between classes are derived. These
distances are compiled into a distance matrix, (b), which then forms
the basis for hierarchical clustering analysis with a dendrogram as
an end result, (c). The dendrogram reveals the relationships between
classes and functions as the basis of a decision tree, with a two-class
OPLS-DA model at each split. This dendrogram, in conjunction with
OPLS-DA models, constitutes the OPLS-HDA model.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_0001" id="gr1" position="float"/></fig><p>The method is outlined in <xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>. All pairwise combinations of classes are
compared
using OPLS-DA models (<xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>a). The total number of models calculated in this step is <inline-formula id="d34e310"><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_m005.gif"/></inline-formula>, where <italic>N</italic> is the number
of classes. This step is the most time-consuming part of the process,
but when automated, still easily doable using a standard computer.
The calculated distances are summarized in a symmetrical distance
matrix, with each element representing the distance between two classes
(<xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>b). The matrix
captures the relational dynamics among all classes. The distance matrix
is used to reveal the hierarchical level of the data in a dendrogram
using HCA (<xref rid="fig1" ref-type="fig">Figure <xref rid="fig1" ref-type="fig">1</xref></xref>c). The dendrogram is then populated with decision making OPLS-DA
models in each split to create the decision tree, i.e., the OPLS-HDA
model.</p><p>When using the OPLS-HDA model for classification, an
observation
begins at the top of the decision tree and moves downward based on
the predictions of each OPLS-DA model. It ultimately reaches one of
the bottom leaves, indicating the class to which the observation belongs.</p><sec id="sec3.1"><title>Illustrative Comparison of OPLS-HDA and OPLS-DA</title><p>To
illustrate OPLS-HDA and show its benefits even in simple cases, we
compared it to OPLS-DA using the Iris three-class data set.<sup><xref ref-type="bibr" rid="ref17">17</xref></sup> For simplicity in visualization, we limited
the data set to only two variables: petal length and petal width.</p><p>OPLS-DA inherently struggles with this relatively simple data set
since the decision boundary of an OPLS-DA model will always have a
common center-point, due to its &#x0201c;one-vs-rest&#x0201d; setup.
This causes trouble if we have more than two classes and the classes
are separated along the same variables but at different scales. This
is the case for the Iris data set. When fitting an OPLS-DA model to
a simplified version of this data set the common center-point results
in a suboptimal decision boundary (<xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>a). OPLS-HDA handles the placement of decision
boundaries in a much better way (<xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>b). By first calculating the distances between
the three classes and performing HCA, we create a dendrogram (<xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>c), that acts as
the foundation for the OPLS-HDA model. We then create OPLS-DA models
in split #1 and #2 (<xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>d,e). The dendrogram complete with the two two-class models
creates the decision tree and makes up the OPLS-HDA model. The resulting
decision boundary of the OPLS-HDA model is a combination of the models
in split #1 and #2 shown in <xref rid="fig2" ref-type="fig">Figure <xref rid="fig2" ref-type="fig">2</xref></xref>b.</p><fig id="fig2" position="float"><label>Figure 2</label><caption><p>In (a, b) the decision boundaries of an OPLS-DA and an
OPLS-HDA
model are displayed. The OPLS-DA model has a common center-point leading
to a suboptimal decision boundary while OPLS-HDA creates a suitable
boundary. In (c), the dendrogram on which the OPLS-HDA model is based.
In each split of the dendrogram, a two-class OPLS-DA model is created.
In (d), the decision boundary of the model in split #1 is shown, and
in (e), the decision boundary of the model in split #2.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_0002" id="gr2" position="float"/></fig></sec></sec><sec id="sec4"><title>Software</title><p>For the OPLS-DA, we have utilized SIMCA, version
18.0.0 (Sartorius
Stedim Data Analytics, Ume&#x000e5;, Sweden), as the backbone for model
building including the cross-validation scheme. In HCA, the hierarchy
can be created by linking observations differently by choosing a specific
linkage algorithm. Throughout this work, we have applied SciPy to
perform the HCA calculations with existing linkage choices.<sup><xref ref-type="bibr" rid="ref18">18</xref></sup> The benchmarks presented in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.4c01799/suppl_file/ci4c01799_si_001.pdf">Supporting Information</ext-link> are performed in python using Scikit-learn<sup><xref ref-type="bibr" rid="ref19">19</xref></sup> and eigenvector for AHiMBu.<sup><xref ref-type="bibr" rid="ref12">12</xref>,<xref ref-type="bibr" rid="ref13">13</xref></sup></p></sec><sec id="sec5"><title>Data Sets</title><sec id="sec5.1"><title>Glioma Subtypes&#x02014;Metabolomics</title><p>The brain tumor
metabolomics data includes 232 observations and 240 identified metabolites
originating from cross-platform gas chromatography-mass spectrometry
(GC-MS) and liquid chromatography with tandem mass spectrometry (LC-MS/MS)
global metabolomics analysis.<sup><xref ref-type="bibr" rid="ref8">8</xref></sup> The observations
were subclassified based on molecular classifications according to
WHO 2016 classification of tumors of the central nervous system. According
to this molecular and histopathological classification, the material
is distributed over seven adult glioma subtypes: 1. glioblastoma,
IDH-wildtype; 2. glioblastoma, IDH mutant; 3. astrocytoma, IDH-wildtype;
4. astrocytoma, IDH mutant; 5. oligodendroglioma, IDH mutant and 1<italic>p</italic>/19q-codeleted; 6. oligodendroglioma, NEC (IDH-wildtype
and 1<italic>p</italic>/19q-codeleted); and 7. gliosarcoma, IDH-wildtype.</p><sec id="sec5.1.1"><title>Whitefish&#x02014;NIR Spectra</title><p>The Whitefish data set
includes 1,311 observations and 125 variables originating from near-infrared
(NIR) Spectral data. The data set contains 12 classes consisting of
4 fish species in 3 different states; frozen, fresh or thawed providing
two main sources of class variation. This data set is a robust use
case for evaluating the efficacy of classification in scenarios where
the variable space is correlated with a complex class structure. While
the full data set included 18 classes, we decided to restrict our
study to a subset of 12 classes including species that had all three
states measured.<sup><xref ref-type="bibr" rid="ref20">20</xref></sup></p></sec></sec></sec><sec id="sec6"><title>Results</title><sec id="sec6.1"><title>Metabolomics Glioma&#x02014;Streamlined Identification of Distinct
Metabolic Characteristics</title><p>In the previous study,<sup><xref ref-type="bibr" rid="ref8">8</xref></sup> a manual one-vs-one approach was performed to
understand the relationship between the different classes. The findings
were then summarized in a dendrogram with HCA and volcano plots were
generated based on the clustering. This process involved a lot of
manual work, the results of which we can efficiently replicate with
OPLS-HDA.</p><p>To illustrate this, we applied OPLS-HDA to the high-dimensional
mass spectrometry-based metabolomics data from the brain tumor tissues.
The data included seven tumor subtypes, based on the WHO classification
for tumors of the nervous system, including both molecular and histopathological
analysis.<sup><xref ref-type="bibr" rid="ref21">21</xref></sup> Using tumor metabolic phenotypes
as input, OPLS-HDA groups the seven glioma subtypes according to their
WHO classification in a dendrogram (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>a). The dendrogram, uses Cohen&#x02019;s <italic>d</italic> on the <italic>y</italic>-axis to reflect class proximity,
providing an intuitive understanding of the relationships between
the classes. The way OPLS-HDA visualize the data expedites initial
data analysis, making it particularly useful of understanding major
differences as well as unique features of defined classes in complex
data, such as clinical omics data. Split #1 reveals a pronounced distinction
between isocitrate dehydrogenase wild type (IDH-wt) and mutated tumors.
This separation can also be visualized through traditional cv-score
plots from the two-class OPLS-DA model (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>b).</p><fig id="fig3" position="float"><label>Figure 3</label><caption><p>OPLS-HDA results of brain tumor metabolomic
data. (a) Dendrogram
for the brain tumor metabolomics data of seven WHO defined glioma
subtypes. NEC = not elsewhere classified. (b) Cv-score plot for the
two-class OPLS-DA model in (a), Split #1, separating IDH wildtype
and IDH mutated tumors. (c&#x02013;h) Volcano plots for each two-class
OPLS-DA model in (a), Split #1&#x02013;6. A few important metabolites,
based on statistical significance (<italic>P</italic> &#x0003c; 0.01) and
expression level (&#x0003e;2-fold difference), are highlighted. Metabolite
fold differences are shown as ratios according to the analyzed Split,
as illustrated in the dendrogram in (a). I.e &#x0201c;High in Left&#x0201d;
or &#x0201c;High in Right&#x0201d; refers to left- or right-hand side
of the Split shown in (a).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_0003" id="gr3" position="float"/></fig><p>To further investigate the unique features driving
the separation
of the different tumor classes, we generate volcano plots for each
two-class OPLS-DA model, based on statistical significance and expression
level for individual metabolites (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>c&#x02013;h). This analysis shows that Split
#1, which separates the three IDH-mutated classes from the four IDH-wt
classes, is driven by 41 metabolites with significantly different
levels in the tissues (<italic>P</italic> &#x0003c; 0.01 and &#x0003e;2-fold
difference).
The most important metabolite is the high expression of 2-hydroxyglutaric
acid (2-HG) produced in IDH-mutated cells (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>c).</p><p>Focusing on the subsequent splits,
we see that Split #2 differentiates
IDH-wt classes; glioblastoma and astrocytoma from oligodendroglioma
(NEC) and gliosarcoma. This differentiation is primarily driven by
high levels of 5-hydroxyindoleacetate, a metabolite of serotonin catabolism
(<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>d).<sup><xref ref-type="bibr" rid="ref8">8</xref></sup> Turning our attention to the IDH-mutated classes,
Split #3 distinguishes high-grade glioblastoma from lower-grade astrocytoma
and oligodendroglioma tumors. Metabolic markers for rapid cell proliferation,
such as glycine and 2-aminoadipic acid, were prominent in high-grade
glioblastoma while <italic>N</italic>-acetylaspartic acid, a metabolic
marker for normal nervous tissue, was low as expected (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>e). As we move down the dendrogram,
the differences between analyzed classes becomes less pronounced,
which is anticipated as the tumors metabolic phenotypes becomes more
similar. However, both Split #4 and Split #5, regardless of IDH mutation
status, show reduced levels of a broad range of acyl-carnitines in
lower-grade astrocytoma tumors, highlighting these metabolites as
unique features (<xref rid="fig3" ref-type="fig">Figure <xref rid="fig3" ref-type="fig">3</xref></xref>f,g).</p></sec><sec id="sec6.2"><title>Whitefish Data Set&#x02014;Hierarchy and Score Plots</title><p>In the Whitefish study, 66 one-vs-one OPLS-DA models are summarized
and presented in a dendrogram, as shown in <xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref>a. This dendrogram provides clear insights
of how different groups relate to each other, namely that the state
of the fish is the main source of variation and thus frozen samples
differ significantly from fresh or thawed ones. Speculatively, this
is because of the presence of ice in the frozen samples. Next, we
see that the same species that are either fresh or thawed are more
similar to each other and that cod stands out distinctly from other
species, regardless of whether the samples are frozen or fresh/thawed.</p><fig id="fig4" position="float"><label>Figure 4</label><caption><p>(a) Dendrogram
of the whitefish data produced by the Cohen&#x02019;s <italic>d</italic> calculated from the <italic><bold>&#x00177;</bold></italic><sub>cv</sub> of 66 one-vs-one OPLS-DA models. Frozen classes are
separated from fresh/thawed and cod is separated from the other species.
(b) Confusion matrix of the test set with an accuracy of 90.4% with
the actual class belongings on the <italic>y</italic>-axis and the
predicted on the <italic>x</italic>-axis. (c&#x02013;f) Cross-validated
score plots from two-class OPLS-DA models in splits #1, #2, #3 and
#10, from the OPLS-HDA model shown in (a). Split #1&#x02013;3(c&#x02013;e)
are clearly separated while #10 has a significant overlap. The ellipses
around each class in the score-plots (c&#x02013;f) are 95% confidence
intervals for each class based upon Hotelling&#x02019;s T2.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_0004" id="gr4" position="float"/></fig><p>These observations are supported by the cv-score
plots from the
OPLS-DA models in the splits, shown in <xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref>c&#x02013;f. Similarly, the confusion matrix
in <xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref>b confirms
these findings, i.e., as we move down the tree, the likelihood of
correctly classifying a sample decreases. Notably, no frozen sample
was misclassified as fresh or thawed. Also, cod is consistently classified
separately from other species. The primary challenge involves confusing
fresh and thawed samples within the same species, as illustrated in <xref rid="fig4" ref-type="fig">Figure <xref rid="fig4" ref-type="fig">4</xref></xref>f, where the cross-validated
scores for fresh and thawed sole overlap significantly.</p></sec><sec id="sec6.3"><title>Benchmark Results</title><p>To compare OPLS-HDA with other multiclass
classification methods, we have performed a benchmark on a wide range
of data sets. The data sets range from simple ones as Iris<sup><xref ref-type="bibr" rid="ref17">17</xref></sup> to high-dimensional once such as the Breast
Cancer data set.<sup><xref ref-type="bibr" rid="ref22">22</xref></sup> We compare the performance
of OPLS-HDA to eight other methods (<xref rid="tbl1" ref-type="other">Table <xref rid="tbl1" ref-type="other">1</xref></xref>). From this, OPLS-HDA emerges as a strong
and flexible competitor to the other methods. Being in the top three
for all data sets except LIVECell results in OPLS-HDA having the highest
average accuracy of all the tested methods. This displays the robustness
and flexibility of OPLS-HDA to handle both low- and high-dimensional
data sets with varying characteristics. A more in-depth description
of the data sets and the tested methods are presented in <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.4c01799/suppl_file/ci4c01799_si_001.pdf">Supporting Information</ext-link>.</p><table-wrap id="tbl1" position="float"><label>Table 1</label><caption><title>Combined Dataset Summary and Benchmarking
Results<xref rid="t1fn1" ref-type="table-fn">a</xref></title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_0008" id="GRAPHIC-d14e630-autogenerated" position="float"/><table-wrap-foot><fn id="t1fn1"><label>a</label><p>The top-three methods are highlighted
in bold.</p></fn></table-wrap-foot></table-wrap></sec></sec><sec id="sec7"><title>Conclusions</title><p>In this paper, we have introduced a new
method for multiclass classification
called orthogonal partial least squares-hierarchical discriminant
analysis (OPLS-HDA). This method is based on OPLS, a widely used chemometric
tool with applications in both industry and academia. The motivation
behind this method is that OPLS-Discriminant Analysis (DA), which
can be used for multiclass classification, often struggles as the
number of classes increases. For two-class classification, OPLS-DA
is highly effective, offering strong discrimination between classes
and providing interpretable information on why the two classes differ.
OPLS-HDA integrates the strengths of two-class OPLS-DA models with
HCA to create a top-down OPLS-DA-based decision tree.</p><p>In the
glioma study, we showed that OPLS-HDA results in much less
manual work but with the same interpretation as the original paper.<sup><xref ref-type="bibr" rid="ref8">8</xref></sup> The whitefish NIR data set differs in both state
and species where OPLS-HDA clearly separated the biggest source of
variation to smaller sources. Further, we have benchmarked OPLS-HDA
on eight data sets and compared the classification test set accuracy
to eight popular machine learning models.</p><p>We demonstrate that
with OPLS-HDA&#x02019;s data-driven decision-making,
we avoid tedious manual work while still allowing for a detailed interpretation
of the difference between classes. This approach allows researchers
to focus on interpreting their data and find the answers to their
research questions instead of a time-consuming model-building process.
This methodology not only streamlines the analytical process but also
enhances the robustness and clarity of the results, paving the way
for more efficient and insightful multiclass research in the future.</p></sec></body><back><notes notes-type="data-availability" id="notes-4"><title>Data Availability Statement</title><p>All code and
data can be reached at: <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/edvinforsgren/OPLS-HDA/">https://github.com/edvinforsgren/OPLS-HDA/</uri>, except for the glioma study data, which can be shared upon reasonable
request to the authors. Publicly sharing of clinical data is not permitted
according to written informed consent.</p></notes><notes id="notes-1" notes-type="si"><title>Supporting Information Available</title><p>The Supporting
Information
is available free of charge at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/10.1021/acs.jcim.4c01799?goto=supporting-info">https://pubs.acs.org/doi/10.1021/acs.jcim.4c01799</ext-link>.<list id="silist" list-type="simple"><list-item><p>Benchmarking; method descriptions: soft independent
modeling of class analogy&#x02014;SIMCA;<sup><xref ref-type="bibr" rid="ref23">23</xref>&#x02212;<xref ref-type="bibr" rid="ref25">25</xref></sup> automatic hierarchical
classification model builder (AHIMBU)&#x02014;hierarchical model automatic
classifier (HMAC);<sup><xref ref-type="bibr" rid="ref12">12</xref>,<xref ref-type="bibr" rid="ref13">13</xref></sup> k-nearest neighbor;<sup><xref ref-type="bibr" rid="ref26">26</xref>,<xref ref-type="bibr" rid="ref27">27</xref></sup> decision tree;<sup><xref ref-type="bibr" rid="ref28">28</xref></sup> random forest;<sup><xref ref-type="bibr" rid="ref29">29</xref></sup> suport vector machines;<sup><xref ref-type="bibr" rid="ref30">30</xref></sup> multi-layer perceptron (MLP)&#x02014;artificial neural network (ANN);<sup><xref ref-type="bibr" rid="ref31">31</xref></sup> datasets; Iris;<sup><xref ref-type="bibr" rid="ref17">17</xref></sup> subset of CP1_JUMP; human activity;<sup><xref ref-type="bibr" rid="ref32">32</xref></sup> Salinas A;<sup><xref ref-type="bibr" rid="ref33">33</xref></sup> breast cancer;<sup><xref ref-type="bibr" rid="ref22">22</xref></sup> LIVECell&#x02014;cell morphology<sup><xref ref-type="bibr" rid="ref34">34</xref></sup> (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.4c01799/suppl_file/ci4c01799_si_001.pdf">PDF</ext-link>)</p></list-item></list></p></notes><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="sifile1"><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ci4c01799_si_001.pdf"><caption><p>ci4c01799_si_001.pdf</p></caption></media></supplementary-material></sec><notes notes-type="" id="notes-2"><title>Author Contributions</title><p>E.F: formal
analysis, investigation, methodology, software, validation, visualization,
roles/writing&#x02014;original draft, and writing&#x02014;review and
editing. B.B: conceptualization, validation, and writing&#x02014;review
and editing. J.T.: supervision and writing&#x02014;review and editing.
P.J.: supervision, conceptualization, investigation, methodology,
software, validation, visualization, roles/writing&#x02014;original
draft, and writing&#x02014;review and editing.</p></notes><notes notes-type="COI-statement" id="notes-3"><p>The authors
declare the following competing financial interest(s): Two of the
authors, P.J. and J.T., are affiliated with Sartoirus. Sartorius sells
the SIMCA software which is required to run the python script associated
with the method.</p></notes><ack><title>Acknowledgments</title><p>The authors
thank Dr. Lennart Eriksson for reviewing and commenting
on the text in the manuscript. The authors also thank Sean Roginski
for his helpfulness and insights regarding our benchmark tests of
AHiMBu.</p></ack><ref-list><title>References</title><ref id="ref1"><mixed-citation publication-type="journal" id="cit1"><name><surname>Wold</surname><given-names>S.</given-names></name>; <name><surname>Sj&#x000f6;str&#x000f6;m</surname><given-names>M.</given-names></name>; <name><surname>Eriksson</surname><given-names>L.</given-names></name>
<article-title>PLS-regression: a basic
tool of chemometrics</article-title>. <source>Chemom. Intell. Lab. Syst.</source>
<year>2001</year>, <volume>58</volume>, <fpage>109</fpage>&#x02013;<lpage>130</lpage>. <pub-id pub-id-type="doi">10.1016/S0169-7439(01)00155-1</pub-id>.</mixed-citation></ref><ref id="ref2"><mixed-citation publication-type="journal" id="cit2"><name><surname>Geladi</surname><given-names>P.</given-names></name>
<article-title>Notes on the
history and nature of partial least squares (PLS) modelling</article-title>. <source>J. Chemom.</source>
<year>1988</year>, <volume>2</volume>, <fpage>231</fpage>&#x02013;<lpage>246</lpage>. <pub-id pub-id-type="doi">10.1002/cem.1180020403</pub-id>.</mixed-citation></ref><ref id="ref3"><mixed-citation publication-type="journal" id="cit3"><name><surname>Trygg</surname><given-names>J.</given-names></name>; <name><surname>Wold</surname><given-names>S.</given-names></name>
<article-title>Orthogonal projections to latent structures (O-PLS)</article-title>. <source>J. Chemom.</source>
<year>2002</year>, <volume>16</volume>, <fpage>119</fpage>&#x02013;<lpage>128</lpage>. <pub-id pub-id-type="doi">10.1002/cem.695</pub-id>.</mixed-citation></ref><ref id="ref4"><mixed-citation publication-type="journal" id="cit4"><name><surname>Cloarec</surname><given-names>O.</given-names></name>; <name><surname>Dumas</surname><given-names>M.-E.</given-names></name>; <name><surname>Craig</surname><given-names>A.</given-names></name>; <name><surname>Barton</surname><given-names>R. H.</given-names></name>; <name><surname>Trygg</surname><given-names>J.</given-names></name>; <name><surname>Hudson</surname><given-names>J.</given-names></name>; <name><surname>Blancher</surname><given-names>C.</given-names></name>; <name><surname>Gauguier</surname><given-names>D.</given-names></name>; <name><surname>Lindon</surname><given-names>J. C.</given-names></name>; <name><surname>Holmes</surname><given-names>E.</given-names></name>; <name><surname>Nicholson</surname><given-names>J.</given-names></name>
<article-title>Statistical Total Correlation Spectroscopy:
An Exploratory Approach for Latent Biomarker Identification from Metabolic
1H NMR Data Sets</article-title>. <source>Anal. Chem.</source>
<year>2005</year>, <volume>77</volume>, <fpage>1282</fpage>&#x02013;<lpage>1289</lpage>. <pub-id pub-id-type="doi">10.1021/ac048630x</pub-id>.<pub-id pub-id-type="pmid">15732908</pub-id>
</mixed-citation></ref><ref id="ref5"><mixed-citation publication-type="journal" id="cit5"><name><surname>Wiklund</surname><given-names>S.</given-names></name>; <name><surname>Johansson</surname><given-names>E.</given-names></name>; <name><surname>Sj&#x000f6;str&#x000f6;m</surname><given-names>L.</given-names></name>; <name><surname>Mellerowicz</surname><given-names>E. J.</given-names></name>; <name><surname>Edlund</surname><given-names>U.</given-names></name>; <name><surname>Shockcor</surname><given-names>J. P.</given-names></name>; <name><surname>Gottfries</surname><given-names>J.</given-names></name>; <name><surname>Moritz</surname><given-names>T.</given-names></name>; <name><surname>Trygg</surname><given-names>J.</given-names></name>
<article-title>Visualization of GC/TOF-MS-Based
Metabolomics Data for Identification of Biochemically Interesting
Compounds Using OPLS Class Models</article-title>. <source>Anal. Chem.</source>
<year>2008</year>, <volume>80</volume>, <fpage>115</fpage>&#x02013;<lpage>122</lpage>. <pub-id pub-id-type="doi">10.1021/ac0713510</pub-id>.<pub-id pub-id-type="pmid">18027910</pub-id>
</mixed-citation></ref><ref id="ref6"><mixed-citation publication-type="journal" id="cit6"><name><surname>Rajalahti</surname><given-names>T.</given-names></name>; <name><surname>Arneberg</surname><given-names>R.</given-names></name>; <name><surname>Kroksveen</surname><given-names>A. C.</given-names></name>; <name><surname>Berle</surname><given-names>M.</given-names></name>; <name><surname>Myhr</surname><given-names>K.-M.</given-names></name>; <name><surname>Kvalheim</surname><given-names>O. M.</given-names></name>
<article-title>Discriminating Variable
Test and Selectivity Ratio
Plot: Quantitative Tools for Interpretation and Variable (Biomarker)
Selection in Complex Spectral or Chromatographic Profiles</article-title>. <source>Anal. Chem.</source>
<year>2009</year>, <volume>81</volume>, <fpage>2581</fpage>&#x02013;<lpage>2590</lpage>. <pub-id pub-id-type="doi">10.1021/ac802514y</pub-id>.<pub-id pub-id-type="pmid">19228047</pub-id>
</mixed-citation></ref><ref id="ref7"><mixed-citation publication-type="journal" id="cit7"><name><surname>Machleid</surname><given-names>R.</given-names></name>; <name><surname>Hoehse</surname><given-names>M.</given-names></name>; <name><surname>Scholze</surname><given-names>S.</given-names></name>; <name><surname>Mazarakis</surname><given-names>K.</given-names></name>; <name><surname>Nilsson</surname><given-names>D.</given-names></name>; <name><surname>Johansson</surname><given-names>E.</given-names></name>; <name><surname>Zehe</surname><given-names>C.</given-names></name>; <name><surname>Trygg</surname><given-names>J.</given-names></name>; <name><surname>Grimm</surname><given-names>C.</given-names></name>; <name><surname>Surowiec</surname><given-names>I.</given-names></name>
<article-title>Feasibility and performance of cross-clone
Raman calibration models in CHO cultivation</article-title>. <source>Biotechnol. J.</source>
<year>2024</year>, <volume>19</volume>, <elocation-id>2300289</elocation-id><pub-id pub-id-type="doi">10.1002/biot.202300289</pub-id>.</mixed-citation></ref><ref id="ref8"><mixed-citation publication-type="journal" id="cit8"><name><surname>Bj&#x000f6;rkblom</surname><given-names>B.</given-names></name>; <name><surname>Wibom</surname><given-names>C.</given-names></name>; <name><surname>Eriksson</surname><given-names>M.</given-names></name>; <name><surname>Bergenheim</surname><given-names>A. T.</given-names></name>; <name><surname>Sj&#x000f6;berg</surname><given-names>R. L.</given-names></name>; <name><surname>Jonsson</surname><given-names>P.</given-names></name>; <name><surname>Br&#x000e4;nnstr&#x000f6;m</surname><given-names>T.</given-names></name>; <name><surname>Antti</surname><given-names>H.</given-names></name>; <name><surname>Sandstr&#x000f6;m</surname><given-names>M.</given-names></name>; <name><surname>Melin</surname><given-names>B.</given-names></name>
<article-title>Distinct metabolic
hallmarks of WHO classified adult glioma subtypes</article-title>. <source>Neuro-Oncol.</source>
<year>2022</year>, <volume>24</volume>, <fpage>1454</fpage>&#x02013;<lpage>1468</lpage>. <pub-id pub-id-type="doi">10.1093/neuonc/noac042</pub-id>.<pub-id pub-id-type="pmid">35157758</pub-id>
</mixed-citation></ref><ref id="ref9"><mixed-citation publication-type="journal" id="cit9"><name><surname>Lindqvist</surname><given-names>H. M.</given-names></name>; <name><surname>Gjertsson</surname><given-names>I.</given-names></name>; <name><surname>Hulander</surname><given-names>E.</given-names></name>; <name><surname>B&#x000e4;rebring</surname><given-names>L.</given-names></name>; <name><surname>Winkvist</surname><given-names>A.</given-names></name>
<article-title>Exploring the differences in serum metabolite profiles
after intake of red meat in women with rheumatoid arthritis and a
matched control group</article-title>. <source>Eur. J. Nutr.</source>
<year>2024</year>, <volume>63</volume>, <fpage>221</fpage>&#x02013;<lpage>230</lpage>. <pub-id pub-id-type="doi">10.1007/s00394-023-03257-y</pub-id>.<pub-id pub-id-type="pmid">37814020</pub-id>
</mixed-citation></ref><ref id="ref10"><mixed-citation publication-type="journal" id="cit10"><name><surname>Madala</surname><given-names>N. E.</given-names></name>; <name><surname>Piater</surname><given-names>L.</given-names></name>; <name><surname>Steenkamp</surname><given-names>P.</given-names></name>; <name><surname>Dubery</surname><given-names>I.</given-names></name>
<article-title>Multivariate statistical
models of metabolomic data reveals different metabolite distribution
patterns in isonitrosoacetophenone-elicited Nicotiana tabacum and
Sorghum bicolor cells</article-title>. <source>SpringerPlus</source>
<year>2014</year>, <volume>3</volume>, <elocation-id>254</elocation-id><pub-id pub-id-type="doi">10.1186/2193-1801-3-254</pub-id>.<pub-id pub-id-type="pmid">24936386</pub-id>
</mixed-citation></ref><ref id="ref11"><mixed-citation publication-type="journal" id="cit11"><name><surname>Yang</surname><given-names>M.</given-names></name>; <name><surname>Li</surname><given-names>X.</given-names></name>; <name><surname>Li</surname><given-names>Z.</given-names></name>; <name><surname>Ou</surname><given-names>Z.</given-names></name>; <name><surname>Liu</surname><given-names>M.</given-names></name>; <name><surname>Liu</surname><given-names>S.</given-names></name>; <name><surname>Li</surname><given-names>X.</given-names></name>; <name><surname>Yang</surname><given-names>S.</given-names></name>
<article-title>Gene Features
Selection for Three-Class Disease Classification
via Multiple Orthogonal Partial Least Square Discriminant Analysis
and S-Plot Using Microarray Data</article-title>. <source>PLoS One</source>
<year>2013</year>, <volume>8</volume>, <elocation-id>e84253</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0084253</pub-id>.<pub-id pub-id-type="pmid">24386356</pub-id>
</mixed-citation></ref><ref id="ref12"><mixed-citation publication-type="journal" id="cit12"><name><surname>Marchi</surname><given-names>L.</given-names></name>; <name><surname>Krylov</surname><given-names>I.</given-names></name>; <name><surname>Roginski</surname><given-names>R. T.</given-names></name>; <name><surname>Wise</surname><given-names>B.</given-names></name>; <name><surname>Di Donato</surname><given-names>F.</given-names></name>; <name><surname>Nieto-Ortega</surname><given-names>S.</given-names></name>; <name><surname>Pereira</surname><given-names>J. F. Q.</given-names></name>; <name><surname>Bro</surname><given-names>R.</given-names></name>
<article-title>Automatic hierarchical
model builder</article-title>. <source>J. Chemom.</source>
<year>2022</year>, <volume>36</volume>, <elocation-id>e3455</elocation-id><pub-id pub-id-type="doi">10.1002/cem.3455</pub-id>.</mixed-citation></ref><ref id="ref13"><mixed-citation publication-type="weblink" id="cit13"><article-title>HMAC&#x02014;Eigenvector Research Documentation
Wiki</article-title>. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://wiki.eigenvector.com/index.php?title=Hmac">https://wiki.eigenvector.com/index.php?title=Hmac</uri>. (accessed: April 12 2024).</mixed-citation></ref><ref id="ref14"><mixed-citation publication-type="journal" id="cit14"><name><surname>Bylesj&#x000f6;</surname><given-names>M.</given-names></name>; <name><surname>Rantalainen</surname><given-names>M.</given-names></name>; <name><surname>Cloarec</surname><given-names>O.</given-names></name>; <name><surname>Nicholson</surname><given-names>J. K.</given-names></name>; <name><surname>Holmes</surname><given-names>E.</given-names></name>; <name><surname>Trygg</surname><given-names>J.</given-names></name>
<article-title>OPLS discriminant analysis: combining
the strengths of PLS-DA and SIMCA classification</article-title>. <source>J. Chemom.</source>
<year>2006</year>, <volume>20</volume>, <fpage>341</fpage>&#x02013;<lpage>351</lpage>. <pub-id pub-id-type="doi">10.1002/cem.1006</pub-id>.</mixed-citation></ref><ref id="ref15"><mixed-citation publication-type="journal" id="cit15"><name><surname>Wold</surname><given-names>S.</given-names></name>
<article-title>Cross-Validatory
Estimation of the Number of Components in Factor and Principal Components
Models</article-title>. <source>Technometrics</source>
<year>1978</year>, <volume>20</volume>, <fpage>397</fpage>&#x02013;<lpage>405</lpage>. <pub-id pub-id-type="doi">10.1080/00401706.1978.10489693</pub-id>.</mixed-citation></ref><ref id="ref16"><mixed-citation publication-type="book" id="cit16"><person-group person-group-type="allauthors"><name><surname>Cohen</surname><given-names>J.</given-names></name></person-group><source>Statistical Power Analysis
for the Behavioral Sciences</source>, <edition>2</edition>nd ed.; <publisher-name>Routledge</publisher-name>: <publisher-loc>New York</publisher-loc>, <year>1988</year>.</mixed-citation></ref><ref id="ref17"><mixed-citation publication-type="undeclared" id="cit17"><person-group person-group-type="allauthors"><name><surname>Fisher</surname><given-names>R. A.</given-names></name></person-group><article-title>The Use of
Multiple Measurements in Taxonomic Problems</article-title>. <year>1936</year>.</mixed-citation></ref><ref id="ref18"><mixed-citation publication-type="journal" id="cit18"><name><surname>Virtanen</surname><given-names>P.</given-names></name>; <name><surname>Gommers</surname><given-names>R.</given-names></name>; <name><surname>Oliphant</surname><given-names>T. E.</given-names></name>; et al. <article-title>SciPy 1.0: Fundamental
Algorithms for Scientific Computing in Python</article-title>. <source>Nat. Methods</source>
<year>2020</year>, <volume>17</volume>, <fpage>261</fpage>&#x02013;<lpage>272</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id>.<pub-id pub-id-type="pmid">32015543</pub-id>
</mixed-citation></ref><ref id="ref19"><mixed-citation publication-type="journal" id="cit19"><name><surname>Pedregosa</surname><given-names>F.</given-names></name>; <name><surname>Varoquaux</surname><given-names>G.</given-names></name>; <name><surname>Gramfort</surname><given-names>A.</given-names></name>; <name><surname>Michel</surname><given-names>V.</given-names></name>; <name><surname>Thirion</surname><given-names>B.</given-names></name>; <name><surname>Grisel</surname><given-names>O.</given-names></name>; <name><surname>Blondel</surname><given-names>M.</given-names></name>; <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>; <name><surname>Weiss</surname><given-names>R.</given-names></name>; <name><surname>Dubourg</surname><given-names>V.</given-names></name>; et al. <article-title>Scikit-learn: Machine
learning in Python</article-title>. <source>J. Mach. Learn. Res.</source>
<year>2011</year>, <volume>12</volume>, <fpage>2825</fpage>&#x02013;<lpage>2830</lpage>.</mixed-citation></ref><ref id="ref20"><mixed-citation publication-type="weblink" id="cit20"><person-group><collab>AZTI Whitefish Dataset</collab></person-group>. <year>2023</year>. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.azti.es/en/withefish-database/">https://www.azti.es/en/withefish-database/</uri>. (accessed: November 27, 2024).</mixed-citation></ref><ref id="ref21"><mixed-citation publication-type="journal" id="cit21"><name><surname>Louis</surname><given-names>D. N.</given-names></name>; <name><surname>Perry</surname><given-names>A.</given-names></name>; <name><surname>Wesseling</surname><given-names>P.</given-names></name>; <name><surname>Brat</surname><given-names>D. J.</given-names></name>; <name><surname>Cree</surname><given-names>I. A.</given-names></name>; <name><surname>Figarella-Branger</surname><given-names>D.</given-names></name>; <name><surname>Hawkins</surname><given-names>C.</given-names></name>; <name><surname>Ng</surname><given-names>H. K.</given-names></name>; <name><surname>Pfister</surname><given-names>S. M.</given-names></name>; <name><surname>Reifenberger</surname><given-names>G.</given-names></name>; <name><surname>Soffietti</surname><given-names>R.</given-names></name>; <name><surname>von Deimling</surname><given-names>A.</given-names></name>; <name><surname>Ellison</surname><given-names>D. W.</given-names></name>
<article-title>The 2021 WHO Classification of Tumors of the Central
Nervous System: a summary</article-title>. <source>Neuro-Oncol.</source>
<year>2021</year>, <volume>23</volume>, <fpage>1231</fpage>&#x02013;<lpage>1251</lpage>. <pub-id pub-id-type="doi">10.1093/neuonc/noab106</pub-id>.<pub-id pub-id-type="pmid">34185076</pub-id>
</mixed-citation></ref><ref id="ref22"><mixed-citation publication-type="weblink" id="cit22"><person-group><collab>Network, T. C. G. A</collab></person-group>. <article-title>Gene Expression Dataset of Breast Cancer Biopsy
Samples. NCBI GEO</article-title><year>2005</year>. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1456">https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1456</uri>.</mixed-citation></ref><ref id="ref23"><mixed-citation publication-type="journal" id="cit23"><name><surname>Wold</surname><given-names>S.</given-names></name>
<article-title>Pattern recognition
by means of disjoint principal components models</article-title>. <source>Pattern Recognit.</source>
<year>1976</year>, <volume>8</volume>, <fpage>127</fpage>&#x02013;<lpage>139</lpage>. <pub-id pub-id-type="doi">10.1016/0031-3203(76)90014-5</pub-id>.</mixed-citation></ref><ref id="ref24"><mixed-citation publication-type="journal" id="cit24"><name><surname>Bicciato</surname><given-names>S.</given-names></name>; <name><surname>Luchini</surname><given-names>A.</given-names></name>; <name><surname>Di Bello</surname><given-names>C.</given-names></name>
<article-title>Marker identification
and classification
of cancer types using gene expression data and SIMCA</article-title>. <source>Methods Inf. Med.</source>
<year>2004</year>, <volume>43</volume>, <fpage>4</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1055/s-0038-1633413</pub-id>.<pub-id pub-id-type="pmid">15026826</pub-id>
</mixed-citation></ref><ref id="ref25"><mixed-citation publication-type="book" id="cit25"><person-group person-group-type="allauthors"><name><surname>Wold</surname><given-names>S.</given-names></name>; <name><surname>Sj&#x000f6;str&#x000f6;m</surname><given-names>M.</given-names></name></person-group><article-title>SIMCA:
AMethod for Analyzing Chemical Data in Terms of Similarity and Analogy</article-title>. In <source>Chemometrics: Theory and Application</source>; <publisher-name>ACS Publication</publisher-name>, <year>1977</year>; Vol. <volume>52</volume>, pp <fpage>243</fpage>&#x02013;<lpage>282</lpage>.</mixed-citation></ref><ref id="ref26"><mixed-citation publication-type="undeclared" id="cit26"><person-group person-group-type="allauthors"><name><surname>Fix</surname><given-names>E.</given-names></name>; <name><surname>Hodges</surname><given-names>J. L.</given-names></name></person-group><source>PsycEXTRA Datase</source><year>1951</year>. <pub-id pub-id-type="doi">10.1037/e471672008-001</pub-id>.</mixed-citation></ref><ref id="ref27"><mixed-citation publication-type="journal" id="cit27"><name><surname>Cover</surname><given-names>T.</given-names></name>; <name><surname>Hart</surname><given-names>P.</given-names></name>
<article-title>Nearest neighbor pattern classification</article-title>. <source>IEEE
Trans. Inf. Theory</source>
<year>1967</year>, <volume>13</volume>, <fpage>21</fpage>&#x02013;<lpage>27</lpage>. <pub-id pub-id-type="doi">10.1109/TIT.1967.1053964</pub-id>.</mixed-citation></ref><ref id="ref28"><mixed-citation publication-type="journal" id="cit28"><name><surname>Quinlan</surname><given-names>J. R.</given-names></name>
<article-title>Induction
of decision trees</article-title>. <source>Mach. Learn.</source>
<year>1986</year>, <volume>1</volume>, <fpage>81</fpage>&#x02013;<lpage>106</lpage>. <pub-id pub-id-type="doi">10.1007/BF00116251</pub-id>.</mixed-citation></ref><ref id="ref29"><mixed-citation publication-type="journal" id="cit29"><name><surname>Breiman</surname><given-names>L.</given-names></name>
<article-title>Random forests</article-title>. <source>Mach. Learn.</source>
<year>2001</year>, <volume>45</volume>, <fpage>5</fpage>&#x02013;<lpage>32</lpage>. <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>.</mixed-citation></ref><ref id="ref30"><mixed-citation publication-type="journal" id="cit30"><name><surname>Cortes</surname><given-names>C.</given-names></name>; <name><surname>Vapnik</surname><given-names>V.</given-names></name>
<article-title>Support-vector networks</article-title>. <source>Mach.
Learn.</source>
<year>1995</year>, <volume>20</volume>, <fpage>273</fpage>&#x02013;<lpage>297</lpage>. <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id>.</mixed-citation></ref><ref id="ref31"><mixed-citation publication-type="journal" id="cit31"><name><surname>Rumelhart</surname><given-names>D. E.</given-names></name>; <name><surname>Hinton</surname><given-names>G. E.</given-names></name>; <name><surname>Williams</surname><given-names>R. J.</given-names></name>
<article-title>Learning representations by back-propagating
errors</article-title>. <source>Nature</source>
<year>1986</year>, <volume>323</volume>, <fpage>533</fpage>&#x02013;<lpage>536</lpage>. <pub-id pub-id-type="doi">10.1038/323533a0</pub-id>.</mixed-citation></ref><ref id="ref32"><mixed-citation publication-type="weblink" id="cit32"><person-group person-group-type="allauthors"><name><surname>Anguita</surname><given-names>D.</given-names></name>; <name><surname>Ghio</surname><given-names>A.</given-names></name>; <name><surname>Oneto</surname><given-names>L.</given-names></name>; <name><surname>Parra</surname><given-names>X.</given-names></name>; <name><surname>Reyes-Ortiz</surname><given-names>J. L.</given-names></name></person-group><article-title>Human Activity
Recognition Using Smartphones
Dataset. UCI Machine Learning Repository</article-title><year>2012</year>. <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones</uri>.</mixed-citation></ref><ref id="ref33"><mixed-citation publication-type="weblink" id="cit33"><person-group><collab>Group of Computational Intelligence,
U. o. t. B. C</collab></person-group>. <article-title>Salinas-A Scene
Hyperspectral Dataset.
Hyperspectral Remote Sensing Scenes</article-title><year>2023</year><uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes">https://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes</uri>.</mixed-citation></ref><ref id="ref34"><mixed-citation publication-type="journal" id="cit34"><name><surname>Edlund</surname><given-names>C.</given-names></name>; <name><surname>Jackson</surname><given-names>T. R.</given-names></name>; <name><surname>Khalid</surname><given-names>N.</given-names></name>; <name><surname>Bevan</surname><given-names>N.</given-names></name>; <name><surname>Dale</surname><given-names>T.</given-names></name>; <name><surname>Dengel</surname><given-names>A.</given-names></name>; <name><surname>Ahmed</surname><given-names>S.</given-names></name>; <name><surname>Trygg</surname><given-names>J.</given-names></name>; <name><surname>Sjogren</surname><given-names>R.</given-names></name>
<article-title>LIVECell -
A Large-scale Dataset for Label-free Live Cell Segmentation</article-title>. <source>Nat. Methods</source>
<year>2021</year>, <volume>18</volume>, <fpage>1038</fpage>&#x02013;<lpage>1045</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-021-01249-6</pub-id>.<pub-id pub-id-type="pmid">34462594</pub-id>
</mixed-citation></ref></ref-list></back></article>