<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id><journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id><journal-id journal-id-type="publisher-id">bioadv</journal-id><journal-title-group><journal-title>Bioinformatics Advances</journal-title></journal-title-group><issn pub-type="epub">2635-0041</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40401046</article-id><article-id pub-id-type="pmc">PMC12093311</article-id><article-id pub-id-type="doi">10.1093/bioadv/vbaf054</article-id><article-id pub-id-type="publisher-id">vbaf054</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject><subj-group subj-group-type="category-toc-heading"><subject>Gene Regulation</subject></subj-group></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI01060</subject></subj-group></article-categories><title-group><article-title>Enhancing gene set overrepresentation analysis with large language models</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhu</surname><given-names>Jiqing</given-names></name><aff>
<institution>Alector, Inc</institution>, South San Francisco, CA 94080, <country country="US">United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Rebecca Y</given-names></name><aff>
<institution>Alector, Inc</institution>, South San Francisco, CA 94080, <country country="US">United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Xiaoting</given-names></name><aff>
<institution>Alector, Inc</institution>, South San Francisco, CA 94080, <country country="US">United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Azevedo</surname><given-names>Ricardo</given-names></name><aff>
<institution>Alector, Inc</institution>, South San Francisco, CA 94080, <country country="US">United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Moreno</surname><given-names>Alexander</given-names></name><aff>
<institution>Alector, Inc</institution>, South San Francisco, CA 94080, <country country="US">United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Kuhn</surname><given-names>Julia A</given-names></name><aff>
<institution>Alector, Inc</institution>, South San Francisco, CA 94080, <country country="US">United States</country></aff></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7859-3489</contrib-id><name><surname>Khan</surname><given-names>Zia</given-names></name><aff>
<institution>Alector, Inc</institution>, South San Francisco, CA 94080, <country country="US">United States</country></aff><xref rid="vbaf054-cor1" ref-type="corresp"/><!--zia.khan@alector.com--></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Bateman</surname><given-names>Alex</given-names></name><role>Associate Editor</role></contrib></contrib-group><author-notes><corresp id="vbaf054-cor1">Corresponding author. Alector, Inc, 131 Oyster Point Boulevard, South San Francisco, CA 94080, United States. E-mail: <email>zia.khan@alector.com</email>.</corresp></author-notes><pub-date pub-type="collection"><year>2025</year></pub-date><pub-date pub-type="epub" iso-8601-date="2025-03-13"><day>13</day><month>3</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>13</day><month>3</month><year>2025</year></pub-date><volume>5</volume><issue>1</issue><elocation-id>vbaf054</elocation-id><history><date date-type="received"><day>26</day><month>11</month><year>2024</year></date><date date-type="rev-recd"><day>02</day><month>3</month><year>2025</year></date><date date-type="editorial-decision"><day>05</day><month>3</month><year>2025</year></date><date date-type="accepted"><day>10</day><month>3</month><year>2025</year></date><date date-type="corrected-typeset"><day>25</day><month>3</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025. Published by Oxford University Press.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="vbaf054.pdf"/><abstract><title>Abstract</title><sec id="s1"><title>Motivation</title><p>Gene set overrepresentation analysis (ORA) is widely used to interpret high-throughput transcriptomics and proteomics data, but traditional methods rely on human-curated gene set databases that lack flexibility.</p></sec><sec id="s2"><title>Results</title><p>We introduce <italic toggle="yes">llm2geneset</italic>, a framework that leverages large language models (LLMs) to dynamically generate gene set databases tailored to input query genes, such as differentially expressed genes and a biological context specified in natural language. These databases integrate with methods, such as ORA, to assign biological functions to input genes. Benchmarking against human-curated gene sets demonstrates that LLMs generate gene sets comparable in quality to those curated by humans. <italic toggle="yes">llm2geneset</italic> also identifies biological processes represented by input gene sets, outperforming traditional ORA and direct LLM prompting. Applying the framework to RNA-seq data from iPSC-derived microglia treated with a <italic toggle="yes">TREM2</italic> agonist highlights its potential for flexible, context-aware gene set generation and improved interpretation of high-throughput biological data.</p></sec><sec id="s3"><title>Availability and implementation</title><p>
<italic toggle="yes">llm2geneset</italic> is available as open source at <ext-link xlink:href="https://github.com/Alector-BIO/llm2geneset" ext-link-type="uri">https://github.com/Alector-BIO/llm2geneset</ext-link> and via a web interface at <ext-link xlink:href="https://llm2geneset.streamlit.app" ext-link-type="uri">https://llm2geneset.streamlit.app</ext-link>.</p></sec></abstract><funding-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Alector Inc</institution></institution-wrap>
</funding-source></award-group></funding-group><counts><page-count count="10"/></counts></article-meta></front><body><sec><title>1 Introduction</title><p>Gene sets, which group genes or proteins based on shared biological functions, pathways, or regulatory mechanisms, are essential tools in transcriptomics and proteomics for interpreting complex datasets (<xref rid="vbaf054-B21" ref-type="bibr">Maleki <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="vbaf054-B22" ref-type="bibr">Mubeen <italic toggle="yes">et al.</italic> 2022</xref>). By focusing on coordinated biological processes rather than individual genes, gene set analysis enhances the understanding of underlying biology and helps identify patterns that may be obscured in high-dimensional data. This approach allows molecular changes, such as differentially expressed genes (DEGs), to be connected to specific biological processes, supporting investigations into normal physiology, disease mechanisms, and therapeutic strategies. The generation and interpretation of gene sets are critical for deriving meaningful insights from transcriptomics and proteomics studies and for deepening our understanding of biological systems.</p><p>Methods for gene set enrichment analysis, such as overrepresentation analysis (ORA), are widely used to evaluate whether gene sets are significantly associated with a list of DEGs (<xref rid="vbaf054-B27" ref-type="bibr">Subramanian <italic toggle="yes">et al.</italic> 2005</xref>, <xref rid="vbaf054-B11" ref-type="bibr">Huang <italic toggle="yes">et al.</italic> 2009</xref>, <xref rid="vbaf054-B33" ref-type="bibr">Wu <italic toggle="yes">et al.</italic> 2010</xref>, <xref rid="vbaf054-B34" ref-type="bibr">Wu and Smyth 2012</xref>, <xref rid="vbaf054-B18" ref-type="bibr">Kuleshov <italic toggle="yes">et al.</italic> 2016</xref>). These methods typically rely on external, human-curated gene set databases, which must be regularly updated to incorporate advances in scientific knowledge. However, these databases often pose challenges when tailoring gene sets to specific research questions or experimental contexts, and the choice of gene sets can strongly influence the interpretation of transcriptomics and proteomics studies (<xref rid="vbaf054-B22" ref-type="bibr">Mubeen <italic toggle="yes">et al.</italic> 2022</xref>). In this paper, we demonstrate how large language models (LLMs) enable the generation of gene sets using natural language. This approach supports the customization of gene sets for specific research questions and enhances the identification of biologically relevant processes when integrated with enrichment analysis.</p><p>LLMs have recently found several uses in the analysis of transcriptomics datasets and their application to problems in computational biology is an active area of research. LLMs have been used to automate cell type annotation in single-cell datasets on the basis of their ability to capture marker genes of known cell types (<xref rid="vbaf054-B9" ref-type="bibr">Hou and Ji 2023</xref>). Recent work has evaluated whether LLMs can discern functional relationships within a given set of genes by prompting LLMs (<xref rid="vbaf054-B15" ref-type="bibr">Joachimiak <italic toggle="yes">et al.</italic> 2023</xref>, <xref rid="vbaf054-B10" ref-type="bibr">Hu <italic toggle="yes">et al.</italic> 2025</xref>). LLMs have been augmented with bioinformatic specific tools to solve tasks (<xref rid="vbaf054-B14" ref-type="bibr">Jin <italic toggle="yes">et al.</italic> 2024</xref>). Combining these approaches, LLMs as agents have been explored to discern the function of an input set of genes using self-verification approaches (<xref rid="vbaf054-B31" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024</xref>). Yet, use and evaluation of LLMs as a tool for flexible gene set generation and overrepresentation analyses has not been explored.</p><p>In this study, we introduce <italic toggle="yes">llm2geneset</italic>, a framework that leverages LLMs to generate a gene set database tailored to input query genes (e.g. DEGs) and a biological context specified in natural language (<xref rid="vbaf054-F1" ref-type="fig">Fig.&#x000a0;1</xref>). This dynamically generated database can be used by gene set analysis methods, such as ORA, to assign biological processes and functions to the input genes. We evaluate two key aspects of the framework: its ability to accurately generate gene sets from natural language descriptions and its ability to map input gene sets to known functions. Using human-curated gene sets, we test whether LLMs can recover genes curated by humans when provided with a natural language description and find that they perform comparably to human curators, with prompting strategies tuning precision. Additionally, we evaluate whether <italic toggle="yes">llm2geneset</italic> can identify the biological processes or functions represented in input gene sets, whether corresponding to single or multiple processes, and find that it outperforms traditional ORA and direct LLM prompting. Finally, we demonstrate the framework&#x02019;s potential as a flexible and steerable tool for gene set analysis by applying it to transcriptomics data from iPSC-derived microglia treated with a <italic toggle="yes">TREM2</italic> agonist.</p><fig position="float" id="vbaf054-F1"><label>Figure 1.</label><caption><p>Overview of the <italic toggle="yes">llm2geneset</italic> framework. The framework takes a set of query genes [e.g., differentially expressed genes (DEGs)] and an optional biological context as input. The LLM-based gene set database construction involves two stages: first, proposing biological processes relevant to the query genes within the context, and second, generating gene sets by associating relevant genes with these processes. The resulting customized gene set database can be utilized by gene set analysis methods, such as overrepresentation analysis (ORA), to identify enriched gene sets.</p></caption><graphic xlink:href="vbaf054f1" position="float"/></fig></sec><sec id="s22"><title>2 Methods</title><p>Detailed methods are provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary material</xref>. We used the following versions of OpenAI LLMs: GPT-4o mini (gpt-4o-mini-2024&#x02013;07-18), GPT-3.5 (gpt-3.5-turbo-0125), and GPT-4o (gpt-4o-2024&#x02013;08-06).</p><p>We used the following prompt to generate gene sets:</p><p>
<monospace>List all the known genes directly and indirectly involved in the following biological process or cellular component &#x0201c;&#x0201c;&#x0201c;{d</monospace>
<monospace>e</monospace>
<monospace>scr}&#x0201d;&#x0201d;&#x0201d;. Use the following JSON schema:</monospace>
</p><p>
<monospace>&#x02032;</monospace>&#x02009;<monospace>&#x02032;</monospace>&#x02009;<monospace>&#x02032;json</monospace></p><p>
<monospace>{{</monospace>
</p><p>
<monospace>&#x02003;&#x0201c;type&#x0201d;: &#x0201c;array&#x0201d;,</monospace>
</p><p>
<monospace>&#x02003;&#x0201c;items&#x0201d;: {{</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x0201c;type&#x0201d;: &#x0201c;object&#x0201d;,</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x0201c;properties&#x0201d;: {{</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x02003;&#x0201c;gene&#x0201d;: {{</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x02003;&#x02003;&#x0201c;type&#x0201d;: &#x0201c;string&#x0201d;,</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x02003;}}</monospace>
</p><p>
<monospace>&#x02003;&#x02003;}},</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x0201c;required&#x0201d;: [&#x0201c;gene&#x0201d;]</monospace>
</p><p>
<monospace>&#x02003;}}</monospace>
</p><p>
<monospace>}}</monospace>
</p><p>
<monospace>&#x02032; &#x02032; &#x02032;</monospace>
</p><p>
<monospace>The field &#x0201c;gene&#x0201d; is a gene involved in the following biological process or cellular component: &#x0201c;&#x0201c;&#x0201c;{descr}&#x0201d;&#x0201d;&#x0201d;. Use the HUGO Gene Nomenclature Committee (HGNC) gene abbreviations. Place the output in a JSON code block. Do not add any comments in the JSON code block.</monospace>
</p><p>In the above prompt <monospace>{descr}</monospace> was replaced with a natural language description of a gene set. The above prompt, query to an LLM, and parsing can be concisely written as a function that takes as input a string description of a gene set and returns a string list with the corresponding gene symbols:</p><p>
<monospace>G:List[str] &#x0003c;- GetGenes(D:str)</monospace>
</p><p>We used the following prompt to propose a set of gene set descriptions from a list of genes.</p><p>
<monospace>List {n_pathways} biological pathways, biological processes, or cellular components that contain the following genes &#x0201c;&#x0201c;&#x0201c;{genes}&#x0201d;&#x0201d;&#x0201d; with high confidence. Be as specific as possible. List non-overlapping pathways, processes, or components. Do not i</monospace>
<monospace>n</monospace>
<monospace>clude the gene names in the outputs. Use the following JSON schema:</monospace>
</p><p>
<monospace>&#x02032; &#x02032; &#x02032;json</monospace>
</p><p>
<monospace>{{</monospace>
</p><p>
<monospace>&#x02003;&#x0201c;type&#x0201d;: &#x0201c;array&#x0201d;,</monospace>
</p><p>
<monospace>&#x02003;&#x0201c;items&#x0201d;: {{</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x0201c;type&#x0201d;: &#x0201c;object&#x0201d;,</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x0201c;properties&#x0201d;: {{</monospace>
</p><p>&#x02003;&#x02003;&#x02003;<monospace>&#x0201c;p&#x0201d;: {{</monospace></p><p>
<monospace>&#x02003;&#x02003;&#x02003;&#x02003;&#x0201c;type&#x0201d;: &#x0201c;string&#x0201d;,</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x02003;}},</monospace>
</p><p>
<monospace>&#x02003;&#x02003;}},</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x0201c;required&#x0201d;: [&#x0201c;p&#x0201d;]</monospace>
</p><p>
<monospace>&#x02003;}}</monospace>
</p><p>
<monospace>}}</monospace>
</p><p>
<monospace>&#x02032; &#x02032; &#x02032;</monospace>
</p><p>
<monospace>Example output will look like the following:</monospace>
</p><p>
<monospace>&#x02032; &#x02032; &#x02032;json</monospace>
</p><p>
<monospace>[{{&#x0201c;p&#x0201d;:&#x0201d;BP or Pathway 1&#x0201d;}},</monospace>
</p><p>
<monospace>&#x02003;{{&#x0201c;p&#x0201d;:&#x0201d;BP or Pathway 2&#x0201d;}},</monospace>
</p><p>
<monospace>&#x02003;{{&#x0201c;p&#x0201d;:&#x0201d;BP or Pathway 3&#x0201d;}},</monospace>
</p><p>
<monospace>&#x02003;{{&#x0201c;p&#x0201d;:&#x0201d;BP or Pathway 4&#x0201d;}}</monospace>
</p><p>
<monospace>&#x02032; &#x02032; &#x02032;</monospace>
</p><p>
<monospace>The element &#x0201c;p&#x0201d; designates a pathway, biological process or cellular component. Place the output in a JSON code block. Do not add any comments in the JSON code block.</monospace>
</p><p>In the above prompt, <monospace>{n_pathways}</monospace> was replaced with the number of desired biological pathways and process descriptions. <monospace>{genes}</monospace> was replaced by a comma-separated list of genes for which we requested these biological processes and pathways. As with the gene set generation prompt, we used the <ext-link xlink:href="https://pypi.org/project/json-repair/" ext-link-type="uri">https://pypi.org/project/json-repair/</ext-link> package to parse out the returned genes and repair any minor JSON formatting errors. If the JSON output was not repairable, we queried the model again with a different seed value. To steer the model toward experimentally relevant biological processes and pathways, we additionally modified the above prompt to include contextual information when this contextual information was provided:</p><p>
<monospace>List {n_pathways} biological pathways, biological processes, or cellular components that contain the following genes &#x0201c;&#x0201c;&#x0201c;{genes}&#x0201d;&#x0201d;&#x0201d; with high confidence. Also consider the following context as related to the genes: &#x0201c;&#x0201c;&#x0201c;{context}&#x0201d;&#x0201d;&#x0201d; when selecting pathways, processes, and components.</monospace>
</p><p>Here, <monospace>{context}</monospace> was replaced with a user-provided string that provided additional context to steer the model generations (e.g. &#x0201c;<italic toggle="yes">in vitro</italic> microglia treated with a <italic toggle="yes">TREM2</italic> agonist antibody&#x0201d;). The above can be concisely written as a function that takes as input a list of genes D, a requested number of processes and pathways N, and optionally a C context string:</p><p>
<monospace>P:List[str] &#x0003c;- GetPathwaysProcesses(D:List[str], N:int, C:str)</monospace>
</p><p>
<italic toggle="yes">llm2geneset</italic> proposes pathways and biological process descriptions based on the input set of genes and an experimental context. These pathway descriptions, alone, are used to generate gene sets which are then tested for overrepresentation in the input set of DEGs. The <monospace>GetGenes()</monospace> function call below does not have access to any previous context. The parameters of the algorithm are as follows:</p><list list-type="bullet"><list-item><p>D = set of DEGs (or any set of genes)</p></list-item><list-item><p>N = number of biological pathways and processes to propose</p></list-item><list-item><p>C = (optional) contextual information regarding the experiment from which the DEGs were obtained</p></list-item><list-item><p>B = number of background gene sets for ORA</p></list-item></list><p>Pseudo-code is provided below:</p><p>
<monospace>llm2geneset(D: List[str], N: int, C: str)</monospace>
</p><p>
<monospace>&#x02003;&#x02003;R = []</monospace>
</p><p>
<monospace>&#x02003;&#x02003;P = GetPathwaysProcesses(D)</monospace>
</p><p>
<monospace>&#x02003;&#x02003;for pathway in P:</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x02003;&#x02003;G = GetGenes(pathway)</monospace>
</p><p>
<monospace>&#x02003;&#x02003;&#x02003;&#x02003;p = hgsf(|intersect(D, P)|- 1, B, |G|, |D|)</monospace>
</p><p>&#x02003;&#x02003;&#x02003;&#x02003;<monospace>R</monospace><monospace>=</monospace><monospace>R.append((pathway, p))</monospace></p><p>&#x02003;&#x02003;<monospace>return padjust(R)</monospace></p><p>In the above pseudo-code, the function <monospace>padjust()</monospace> computes <italic toggle="yes">q</italic>-values to account for multiple testing. <monospace>hgsf()</monospace> is one minus the cumulative distribution function (1&#x02212;CDF) of the hypergeometric distribution. The function call computes the <italic toggle="yes">P</italic>-value according to a one-tailed Fisher&#x02019;s exact test. <italic toggle="yes">llm2geneset</italic> returns a list of N pathways sorted on their overrepresentation <italic toggle="yes">P</italic>-values.</p></sec><sec><title>3 Results</title><sec><title>3.1 LLMs generate informative gene sets</title><p>We evaluated whether LLMs could be used to generate gene sets using flexible natural language descriptions of these gene sets. To achieve this, we used a fixed text prompt with a field that can be replaced by the natural language description of the gene set (see <xref rid="s22" ref-type="sec">Section 2</xref>) (<xref rid="vbaf054-B25" ref-type="bibr">Sahoo <italic toggle="yes">et al.</italic> 2024</xref>, <xref rid="vbaf054-B26" ref-type="bibr">Schulhoff <italic toggle="yes">et al.</italic> 2024</xref>). Our prompt consisted of several elements: (i) a role-prompt, a strategy whereby a system message is used to guide the generations of an LLM; (ii) the prompt itself requesting generation of genes for a given biological process or cellular component; and (iii) a formatting component to guide the LLM to produce output using standard HGNC gene symbols that can be programmatically loaded into data structures for downstream use in gene set tests (see <xref rid="s22" ref-type="sec">Section 2</xref>).</p><p>To evaluate the output of an LLM, we assessed whether the gene sets generated by an LLM were significantly overrepresented in corresponding human-curated gene sets (<xref rid="vbaf054-F2" ref-type="fig">Fig.&#x000a0;2A</xref>). To compute whether the overrepresentation we observed was not due to chance, we used the hypergeometric distribution to compute a <italic toggle="yes">P</italic>-value for a one-tailed Fisher&#x02019;s exact test and adjusted for multiple testing (see <xref rid="s22" ref-type="sec">Section 2</xref>). We performed this assessment using natural language descriptions of gene sets in three human-curated gene set databases: KEGG (<xref rid="vbaf054-B17" ref-type="bibr">Kanehisa and Goto 2000</xref>), Reactome (<xref rid="vbaf054-B16" ref-type="bibr">Joshi-Tope <italic toggle="yes">et al.</italic> 2005</xref>), WikiPathways (<xref rid="vbaf054-B20" ref-type="bibr">Martens <italic toggle="yes">et al.</italic> 2021</xref>), and 1000 randomly sampled gene sets from Gene Ontology Biological Process (GOBP) database (<xref rid="vbaf054-B1" ref-type="bibr">Ashburner <italic toggle="yes">et al.</italic> 2000</xref>). Curated for different applications, each gene set database captured differing underlying biology and varied in a total number of gene sets (<xref rid="sup1" ref-type="supplementary-material">Fig. S2A</xref>). In total, we examined overrepresentation in 3939 gene sets and the gene sets varied in size ranging from a median of 24&#x02013;78 genes (<xref rid="sup1" ref-type="supplementary-material">Fig. S2B</xref>). We evaluated LLM gene set generations from three different language models: GPT-3.5, GPT-4o-mini, and GPT-4o (<xref rid="vbaf054-B3" ref-type="bibr">Brown <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="vbaf054-B23" ref-type="bibr">OpenAI <italic toggle="yes">et al.</italic> 2024</xref>). We found that between 33% and 94% LLM-generated gene sets were overrepresented in human-curated gene sets at a Bonferroni-adjusted <italic toggle="yes">P</italic>-value of .01 (<xref rid="vbaf054-F2" ref-type="fig">Fig.&#x000a0;2B</xref>). We observed a higher fraction of overrepresented gene sets generated by the more capable GPT-4o model than GPT-3.5. This fraction tracked with the relative capabilities of each model we considered with GPT-4o mini ranking between GPT-4o and GPT-3.5. Overall, all models performed worst on the GOBP gene set database. Across most gene sets, the overrepresentation <italic toggle="yes">P</italic>-value was smallest for GPT-4o indicating that on an individual gene set level a more capable model yields gene sets in greater agreement with curated gene sets (<xref rid="vbaf054-F2" ref-type="fig">Fig.&#x000a0;2C</xref>).</p><fig position="float" id="vbaf054-F2"><label>Figure 2.</label><caption><p>Evaluating gene sets generated by LLMs. (A) Gene sets generated by LLMs were assessed for significant overrepresentation in human-curated gene sets. Significant overrepresentation indicates that the LLM accurately associates gene set descriptions with corresponding genes. (B) Fraction of gene sets showing significant enrichment in curated sets at a Bonferroni-adjusted <italic toggle="yes">P</italic>-value of .01 across databases and LLMs. Gene Ontology Biological Process (GOBP)(1000) refers to 1000 randomly sampled gene sets from GOBP. (C) Proportion of gene sets where the smallest overrepresentation <italic toggle="yes">P</italic>-value is associated with a specific model. (D) We identified 1418 gene set descriptions with cosine similarity &#x0003e;0.7 between the GOBP database and KEGG, Reactome, and WikiPathways. These gene sets allowed comparisons between human curators and established a baseline for human performance in gene set annotation. Gene sets were generated using LLMs based on KEGG, Reactome, and WikiPathways descriptions. (E) Fraction of gene sets significantly enriched in the GOBP reference across LLMs and human curators. &#x0201c;Human&#x0201d; refers to curator B from (D). (F and G) Boxplots showing recall and precision of gene sets generated by human curator B and LLMs.</p></caption><graphic xlink:href="vbaf054f2" position="float"/></fig><p>We next sought to compare how LLMs might perform head-to-head with human curators. To do so, we focused on 1418 gene sets in KEGG, Reactome, and WikiPathways (query gene sets) that had highly similar descriptions (cosine similarity &#x0003e;0.7 using a text embedding model, see <xref rid="s22" ref-type="sec">Section 2</xref>) to the gene set descriptions in the entire GOBP gene set database (reference gene sets) (see <xref rid="vbaf054-F2" ref-type="fig">Fig.&#x000a0;2D</xref>). Although they have highly similar descriptions, they originate from different databases and thus could be assumed to have been curated by different individuals. We found that 70% of these query gene sets from KEGG, Reactome, and WikiPathways were significantly enriched in the GOBP reference at a Bonferroni-adjusted <italic toggle="yes">P</italic>-value of .01 (<xref rid="vbaf054-F2" ref-type="fig">Fig.&#x000a0;2E</xref>). GPT-4o performed similarly at this task, with 69% of gene sets enriched in the human GOBP reference. We also computed the precision and recall of genes across these gene sets for LLMs as well as humans (<xref rid="vbaf054-F2" ref-type="fig">Fig.&#x000a0;2F</xref> and <xref rid="vbaf054-F2" ref-type="fig">G</xref>). We found that GPT-4o generated gene sets more conservatively than human curators with lower recall (<italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;13</sup>, Wilcoxon rank sum), but higher precision (<italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;12</sup>, Wilcoxon rank sum).</p><p>The prompt we evaluated above relied on two additional components: a role-prompt and a format specification to generate outputs that can be used for downstream applications. Role prompting is a strategy by which to shape the output of an LLM by asking it to take on a specific role (see <xref rid="s22" ref-type="sec">Section 2</xref>) (<xref rid="vbaf054-B26" ref-type="bibr">Schulhoff <italic toggle="yes">et al.</italic> 2024</xref>). We evaluated whether the role-prompt had any impact on the quality of the results. We found that the role-prompt had little impact on the evidence for overrepresentation of curated genes in LLM-generated gene sets (<xref rid="sup1" ref-type="supplementary-material">Fig. S2C</xref>). Formatting is crucial for subsequent use of the gene sets generated by LLMs. We assessed how often each LLM used HGNC symbols, as directed in the prompt, by comparison to gene symbols in Ensembl (GRCh38.p14, release 112). We found that on average 95% of the gene symbols returned by GPT-4o were HGNC gene symbols (<xref rid="sup1" ref-type="supplementary-material">Fig. S2D</xref>). This number was 88% for GPT-3.5 and GPT-4o mini. We additionally noticed a tendency of the models to return duplicate gene symbols for a given gene set description. We found that GPT-3.5 generated gene sets with one or more duplicate gene symbols across 13%&#x02013;24% of gene sets, which was greatly reduced for GPT-4o (5%&#x02013;6%) (<xref rid="sup1" ref-type="supplementary-material">Fig. S2E</xref>). Overall, the LLMs we evaluated followed formatting instructions enabling generation of HGNC gene symbols for downstream use.</p><p>Token use is a crucial metric for LLMs and directly tied to compute cost (<xref rid="vbaf054-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2023</xref>). Input tokens and output tokens are considered differently given that input tokens can be cached to reduce compute cost (<xref rid="vbaf054-B24" ref-type="bibr">Pope <italic toggle="yes">et al.</italic> 2022</xref>). We quantified the number of input and output tokens used to generate LLM version of each database and model (<xref rid="sup1" ref-type="supplementary-material">Fig. S2F</xref>). Given that GPT-4o and GPT-4o mini both use the same tokenizer, 707058 tokens were used as input to generate the gene sets using the descriptions from KEGG, Reactome, and WikiPathways. We found that GPT-4o used the most tokens in its output across databases. 1004497 output tokens were required to generate 3939 gene sets using GPT-4o. In contrast, GPT-4o mini required 756772 output tokens. Quantification of token usage indicates that the compute cost associated with gene set generation was minimal overall.</p></sec><sec><title>3.2 Ensembling and confidence improve the precision of gene set generation</title><p>LLM prompting is an active area of research (<xref rid="vbaf054-B26" ref-type="bibr">Schulhoff <italic toggle="yes">et al.</italic> 2024</xref>). On question-and-answer (Q&#x00026;A) benchmarking datasets various prompting strategies have been explored to increase LLM performance. We evaluated three prompting strategies on the problem of gene set generation: model reasoning, model confidence, and ensembling (<xref rid="vbaf054-F3" ref-type="fig">Fig.&#x000a0;3A</xref>, see <xref rid="s22" ref-type="sec">Section 2</xref>). Encouraging an LLM to provide reasoning for why and how it arrived at a particular answer has been demonstrated to be a powerful approach to improving performance on Q&#x00026;A datasets (<xref rid="vbaf054-B32" ref-type="bibr">Wei <italic toggle="yes">et al.</italic> 2024</xref>). We modified our prompt to require that the model provide a single sentence for its rationale for why a gene was included in a gene set (see <xref rid="s22" ref-type="sec">Section 2</xref>). We additionally considered whether we could elicit the model&#x02019;s confidence in whether it thought a gene belonged to a gene set. We required the model to indicate low, medium, and high confidence for each gene, limiting gene sets to high-confidence genes. We also considered ensembling. We used multiple generations of the model with differing random seed values. Across generations, we identified genes that the model consistently associated with a given gene set description. When a gene is consistently provided as output for a query for a gene set description, this may represent fixed and highly confident knowledge that the LLM captures.</p><fig position="float" id="vbaf054-F3"><label>Figure 3.</label><caption><p>Assessment of model reasoning, confidence, and ensembling for gene set generation. (A) Strategies to generate gene sets using an LLM prompt. (B) Fraction of genes where the LLM-generated gene set is significantly overrepresented in the human-curated gene set with the same natural language description. Bar plot color designates one of three prompting strategies illustrated in (A). (C) Precision of the gene sets returned or the fraction of LLM-generated genes in a gene set that are in the human-curated gene sets with the same description.</p></caption><graphic xlink:href="vbaf054f3" position="float"/></fig><p>For each of these approaches reasoning, confidence, and ensembling, we observed a small decrease in the number of LLM-generated gene sets that were overrepresented in human-curated gene sets (<xref rid="vbaf054-F3" ref-type="fig">Fig.&#x000a0;3B</xref>). The impact was more modest for GPT-4o. As expected, all of the gene sets generated by ensembling were the same size or smaller than those generated by our original prompt. We hypothesized that genes that appeared consistently in model generations with different seeds reflected the model&#x02019;s higher confidence that the gene belonged to a given gene set. To quantify this, we evaluated whether these gene sets were more precise. Precision can be quantified by the number of genes in the LLM-generated gene set that belong to a curated gene set over the total number of genes returned. We found that both ensembling and model confidence, but not model reasoning increased the number of gene sets with high precision (<xref rid="vbaf054-F3" ref-type="fig">Fig.&#x000a0;3C</xref>). These gene sets were only present when gene sets were restricted solely to high-confidence genes, but not medium- or low-confidence genes (<xref rid="sup1" ref-type="supplementary-material">Fig. S3A</xref>). We examined the overlap between genes generated by ensembling and model confidence. Among gene sets that were significantly enriched in curated gene sets, we found a range of overlap between the gene sets generated by these approaches indicating that ensembling yields different genes than model confidence (Fig S3B). Each of the strategies we considered requires additional tokens, thus increasing cost. As expected, token usage was highest for the ensembling strategy followed by model reasoning (<xref rid="sup1" ref-type="supplementary-material">Fig. S3C</xref> and <xref rid="sup1" ref-type="supplementary-material">D</xref>). Taken together, our results illustrate that prompting strategies can tune the precision of gene sets generated by LLMs.</p></sec><sec><title>3.3 LLM-generated gene sets enable discovery of multiple enriched biological processes</title><p>LLMs have recently been proposed as tools to discover biological processes represented by an input set of genes (<xref rid="vbaf054-B10" ref-type="bibr">Hu <italic toggle="yes">et al.</italic> 2025</xref>). In this setting, an LLM prompt includes a set of genes and asks an LLM to generate a natural language description of the biological process these genes participate in&#x02014;the reverse of our evaluation approach above. The prompt is evaluated based on how closely the LLM can recover the ground truth natural language description of the gene set in the output. In contrast to simple LLM prompting, <italic toggle="yes">llm2geneset</italic> generates a custom gene set database given a query gene set (<xref rid="vbaf054-F1" ref-type="fig">Fig.&#x000a0;1</xref>). As LLMs may not use the same exact description as a curator used for a gene set, agreement can be quantified by, for example, how many words (unigrams) or word pairs (bigrams) from the ground truth description are present in the output of the LLM gene description. Agreement can also be quantified by the use of text embedding models and computation of cosine similarity between an embedding of the LLM description and an embedding of the ground truth description for a gene set (<xref rid="vbaf054-B4" ref-type="bibr">Cao 2024</xref>).</p><p>We initially established a baseline using traditional ORA. To do so, we used query gene sets from KEGG, Reactome, and WikiPathways. We then used the GOBP database to identify (from GOBP) gene sets that were significantly enriched in the query gene sets (from KEGG, Reactome, and WikiPathways). We compared the &#x0201c;ground truth&#x0201d; descriptions of query gene sets (from KEGG, Reactome, and WikiPathways) to the top-5 significant gene sets returned by performing ORA using GOBP (<xref rid="vbaf054-F4" ref-type="fig">Fig.&#x000a0;4A</xref>). Across these significant gene set descriptions from GOBP, we used the maximum shared unigrams, bigrams, and cosine similarity between the &#x0201c;ground truth&#x0201d; descriptions from the original query gene sets to assess the quality of the results.</p><fig position="float" id="vbaf054-F4"><label>Figure 4.</label><caption><p>Gene set proposal enables discovery of multiple enriched biological functions. (A) Evaluation approach for traditional ORA using the GOBP database, GSAI, and <italic toggle="yes">llm2geneset</italic>. An input set of genes was provided. Each method was then allowed to propose gene set descriptions. These descriptions were compared using shared unigrams, bigrams, and cosine similarity with the ground truth description. (B) Mean fraction of shared unigrams (words) and bigrams (word pairs) and mean cosine similarity between gene set descriptions returned by the GSAI prompt and <italic toggle="yes">llm2geneset</italic> across databases for the GPT-4o model. Error bars designate the standard error of the mean. (C) To evaluate the ability of the approaches to identify multiple gene functions, we mixed gene sets that were easily identified by the approach in (A) and asked if each method recovered the mixed gene set descriptions. We also tested a modified GSAI prompt where we provided a hint indicating that two gene sets were present. (D) Mean fraction of shared unigrams (words) and bigrams (word pairs) and mean cosine similarity between gene set descriptions returned by GSAI, traditional ORA using GOBP, <italic toggle="yes">llm2geneset</italic> and the gene set descriptions originally assigned to mixed gene sets. Error bars designate the standard error of the mean.</p></caption><graphic xlink:href="vbaf054f4" position="float"/></fig><p>We also compared our approach to an LLM prompting strategy called GSAI (<xref rid="vbaf054-B10" ref-type="bibr">Hu <italic toggle="yes">et al.</italic> 2025</xref>). In contrast to our approach, GSAI used a single prompt to request the LLM return the biological process the input genes belong to along with both reasoning and confidence. Using benchmarking gene sets from KEGG, WikiPathways, and Reactome, we found that <italic toggle="yes">llm2geneset</italic> generated gene set descriptions had on average a higher fraction of shared unigrams and bigrams as well as higher cosine similarity with the ground truth gene set descriptions than GSAI and outperformed the ORA baseline (<xref rid="vbaf054-F4" ref-type="fig">Fig.&#x000a0;4B</xref>, <xref rid="sup1" ref-type="supplementary-material">Fig. S4A</xref>). This observation was highly significant for the GPT-4o model using shared bigrams (Wilcoxon rank sum, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;13</sup> for KEGG, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;5</sup> for Reactome, and <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;5</sup> for WikiPathways) and cosine similarity (Wilcoxon rank sum, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;11</sup> for KEGG, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;17</sup> for Reactome, and <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;9</sup> for WikiPathways) as evaluation metrics. In terms of computational cost, our approach required a comparable number of input tokens to GSAI, but a larger number of output tokens (<xref rid="sup1" ref-type="supplementary-material">Fig. S4B</xref>).</p><p>Experiments often influence multiple biological processes, leading to the discovery of distinct overrepresented gene sets that include DEGs. To simulate such a scenario, we selected gene sets where the biological processes were recovered by both the GSAI prompt and <italic toggle="yes">llm2geneset</italic> with high similarity to the ground truth gene set description (&#x0003e;0.7 cosine similarity) for each benchmarking gene set database. Next, we combined 50 pairs of these gene sets from each gene set database. We then evaluated the recovery of the distinct biological processes from these mixed gene sets, comparing the GSAI prompt with our approach across LLMs (see <xref rid="s22" ref-type="sec">Section 2</xref>).</p><p>We established a baseline using traditional ORA by measuring text similarity between the concatenated text of the top 2 significant gene sets returned from the GOBP database. We found that with the GSAI prompt LLMs were frequently unable to identify multiple gene functions in a gene set. This also held when we modified the original GSAI prompt to include a text &#x0201c;hint&#x0201d; that indicated that two distinct gene sets were present in the input query gene set (see <xref rid="s22" ref-type="sec">Section 2</xref>). Compared to both GSAI, GSAI with a two gene set hint, and the ORA baseline, <italic toggle="yes">llm2geneset</italic> more frequently recovered multiple functions as reflected by a higher fraction of shared unigrams and bigrams as well as cosine similarity (<xref rid="vbaf054-F4" ref-type="fig">Fig.&#x000a0;4D</xref>, <xref rid="sup1" ref-type="supplementary-material">Fig. S4C</xref>). This observation was highly significant for the GPT-4o model using shared bigrams (Wilcoxon rank sum, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;11</sup> for KEGG, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;4</sup> for Reactome, and <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;4</sup> for WikiPathways) and cosine similarity (Wilcoxon rank sum, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;3</sup> for KEGG, <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;5</sup> for Reactome, and <italic toggle="yes">P</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;5</sup> for WikiPathways) as evaluation metrics. Our analysis indicates that coupling generation of gene sets by LLM to ORA is a more effective strategy than model prompting to uncover multiple distinct gene set functions within a set of genes.</p></sec><sec><title>3.4 LLM-based gene set generation enables steerable ORA</title><p>After establishing that our LLM-based approach is more effective than using a single prompt to identify multiple biological processes within a gene set, we applied this method to the DEGs from an experiment involving microglia differentiated from induced pluripotent stem cells (iMGs), treated with AL002 (<italic toggle="yes">N</italic>&#x02009;=&#x02009;4) compared to an isotype control (<italic toggle="yes">N</italic>&#x02009;=&#x02009;4) (see <xref rid="s22" ref-type="sec">Section 2</xref>). AL002 is an investigational, humanized, <italic toggle="yes">TREM2</italic>-selective agonistic monoclonal antibody in Phase 2 trials for the treatment of early Alzheimer&#x02019;s disease (<xref rid="vbaf054-B12" ref-type="bibr">Jackson <italic toggle="yes">et al.</italic> 2022</xref>). Activation of microglia is hypothesized to be an important mechanism of AL002. In iMGs, we found that 30 genes were differentially expressed at an FDR of 10% between iMG that received AL002 to the isotype control (<xref rid="vbaf054-F5" ref-type="fig">Fig.&#x000a0;5A</xref>).</p><fig position="float" id="vbaf054-F5"><label>Figure 5.</label><caption><p>Comparison of overrepresentation analyses using human-curated (KEGG) and LLM-generated gene sets. (A) Volcano plot of DEGs comparing iPSC-derived microglia treated with a <italic toggle="yes">TREM2</italic> agonist antibody (AL002) to an IgG control antibody at 1ug/ml for 24&#x02009;hours. Differentially expressed genes at FDR 10% are shown as red points. (B) Overrepresentation analysis results for biological process and pathways in: (top) the KEGG database; (middle) GPT-4o generated gene set database using no contextual information about the experiment; (bottom) GPT-4o generated gene set database using the contextual text &#x0201c;<italic toggle="yes">in vitro</italic> microglia treated with a <italic toggle="yes">TREM2</italic> agonist antibody.&#x0201d; The lollipop plot indicates the &#x02212;log<sub>10</sub>(<italic toggle="yes">P</italic>-value) for overrepresentation of the gene sets in the set of DEGs in (a). Size of the circles in the plot designates fold enrichment of the gene set. Significant (sig) gene sets at an FDR of 1% are shown in red. Non-significant (n.s.) gene sets are shown in blue.</p></caption><graphic xlink:href="vbaf054f5" position="float"/></fig><p>Given that it is difficult to define ground truth overrepresented gene sets from RNA-seq data, we qualitatively compared the overrepresentation results of using a fixed database derived from KEGG to that of results of <italic toggle="yes">llm2geneset</italic> (<xref rid="vbaf054-F5" ref-type="fig">Fig.&#x000a0;5B</xref>). Using the KEGG database, we found several highly ranked pathways that were irrelevant to microglia. These include pathways of rheumatoid arthritis and measles which provide little information on the impact of AL002 <italic toggle="yes">in vitro</italic>. In contrast, a larger number of highly ranked pathways related to immune and osteoclast function were detected by <italic toggle="yes">llm2geneset</italic>. The enrichment in osteoclast function was driven by DEGs such as <italic toggle="yes">ACP5</italic> and <italic toggle="yes">DCSTAMP</italic>, which have also been associated with functions in the human immune system (<xref rid="vbaf054-B35" ref-type="bibr">Yagi <italic toggle="yes">et al.</italic> 2005</xref>, <xref rid="vbaf054-B2" ref-type="bibr">Briggs <italic toggle="yes">et al.</italic> 2011</xref>, <xref rid="vbaf054-B7" ref-type="bibr">Garcia-Hernandez <italic toggle="yes">et al.</italic> 2022</xref>). In this setting, the LLM was unaware of the experimental context of the input DEGs.</p><p>To address this scenario, we leveraged the ability of <italic toggle="yes">llm2geneset</italic> to steer the model toward gene set descriptions related to immune and microglial function (see <xref rid="s22" ref-type="sec">Section 2</xref>, <xref rid="vbaf054-F5" ref-type="fig">Fig.&#x000a0;5B</xref>). Here, the gene set proposal prompt included the context &#x0201c;<italic toggle="yes">in vitro</italic> microglia treated with a <italic toggle="yes">TREM2</italic> agonist antibody.&#x0201d; Using this approach we found the biological process &#x0201c;regulation of inflammatory responses&#x0201d; was significant at FDR 1%. This result is consistent with <italic toggle="yes">TREM2</italic>&#x02019;s function of the innate immune system in the brain (<xref rid="vbaf054-B29" ref-type="bibr">Ulland and Colonna 2018</xref>). Pathways and biological processes related to immune function were ranked highly overall and gene sets related to osteoclast function were not tested. Overall, this example illustrates that LLMs can be steered to generate gene set databases highly relevant to a specific RNA-seq experiment. These gene sets can be evaluated for overrepresentation in a set of DEGs to facilitate the interpretation of RNA-seq datasets and subsequent hypothesis generation.</p></sec></sec><sec><title>4 Discussion</title><p>Human-curated gene sets are difficult to tailor to specific input DEGs or proteins, as well as to the contextual details of the experiments that generated them. This limitation can lead to incorrect inferences about the biological processes impacted. <italic toggle="yes">llm2geneset</italic> offers an approach to dynamically generate gene set databases using LLMs, tailored to input genes and contextual information. It provides distinct advantages for gene set enrichment analysis by enabling researchers to customize gene sets based on the unique characteristics of their data and scientific questions, addressing a key limitation of human-curated databases. Additionally, <italic toggle="yes">llm2geneset</italic> leverages LLMs trained on continuously updated scientific literature, allowing researchers to update gene sets as scientific knowledge progresses. This provides a potential solution to the challenges associated with maintaining an up-to-date gene set database (<xref rid="vbaf054-B30" ref-type="bibr">Wadi <italic toggle="yes">et al.</italic> 2016</xref>). Furthermore, <italic toggle="yes">llm2geneset</italic> can be seamlessly integrated into existing gene set enrichment analysis methods, such as GSEA, Enrichr, and CAMERA. The generated databases can be readily used by these methods, enabling them to leverage the flexibility and adaptability of our framework while maintaining compatibility with established approaches. To broaden accessibility, a web application (<ext-link xlink:href="https://llm2geneset.streamlit.app" ext-link-type="uri">https://llm2geneset.streamlit.app</ext-link>), enables researchers to use <italic toggle="yes">llm2geneset</italic> without programming expertise, expanding its utility for experimental biologists (<xref rid="sup1" ref-type="supplementary-material">Fig. S5</xref>).</p><p>A single prompt, given a set of input query genes such as DEGs, can be used to prompt language models to infer the function of the input genes (<xref rid="vbaf054-B10" ref-type="bibr">Hu <italic toggle="yes">et al.</italic> 2025</xref>). However, we find that this approach is less effective than <italic toggle="yes">llm2geneset</italic> at inferring the function of a given input set of genes, particularly when multiple gene sets are mixed. This advantage arises from our framework&#x02019;s ability to propose and evaluate multiple candidate gene sets against the input query, enabling the discovery of distinct biological functions within complex gene sets. Additionally, a single prompt is more susceptible to being influenced by researchers steering the model too strongly through prompt phrasing. In contrast, steering within <italic toggle="yes">llm2geneset</italic> impacts only the proposed gene set descriptions, not the gene sets themselves, as the framework validates all generated gene sets against the input query genes.</p><p>Our work has several limitations. Certain gene sets cannot be recovered using LLM prompting alone. Integrating retrieval-augmented generation may enhance performance, but careful benchmarking is necessary to validate improvements (<xref rid="vbaf054-B6" ref-type="bibr">Gao <italic toggle="yes">et al.</italic> 2024</xref>). Our comparison between LLMs to human curators is limited to 1,418 gene sets. How human curators perform relative to LLMs needs further study. Our evaluation approach is knowledge-intensive, and one could argue primarily a test of the ability of LLMs to retrieve gene sets from their training data or pattern match against gene symbols and functions associated with genes. Evaluating whether reasoning approaches improve performance in inferring gene set function from DEGs given experimental context remains an area of future work (<xref rid="vbaf054-B8" ref-type="bibr">Hao <italic toggle="yes">et al.</italic> 2024</xref>). Additionally, our study evaluates only three LLMs&#x02014;GPT-3.5, GPT-4o mini, and GPT-4o. Differences in model architectures, training approaches, and inference algorithms must be further examined using the gene set tasks and ORA baselines introduced in this work. Some gene sets are molecularly defined based on transcriptomics data, and our direct prompting approach may not recover these sets (<xref rid="vbaf054-B19" ref-type="bibr">Liberzon <italic toggle="yes">et al.</italic> 2015</xref>). However, LLMs&#x02019; ability to generate code could enable the automated creation of such gene sets, or models trained on expression data may address this limitation (<xref rid="vbaf054-B28" ref-type="bibr">Theodoris <italic toggle="yes">et al.</italic> 2023</xref>, <xref rid="vbaf054-B13" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic> 2024</xref>). Despite these challenges, we anticipate LLMs will be essential tools for deriving insights from high-dimensional transcriptomics and proteomics datasets.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data"><label>vbaf054_Supplementary_Data</label><media xlink:href="vbaf054_supplementary_data.pdf"/></supplementary-material></sec></body><back><ack id="ack1"><title>Acknowledgements</title><p>The authors would like to acknowledge Hua Long, Peter Heutink, Sara Kenkare-Mitra, and Arnon Rosenthal for their support of these work.</p></ack><sec><title>Author contributions</title><p>Zia Khan and Jiqing Zhu conceived of the idea. Zia Khan, Jiqing Zhu, Rebecca Y. Wang, and Alex Moreno contributed ideas and analyses. Xiaoting Wang, Ricardo Azevedo, and Julia A. Kuhn contributed data. All authors read and approved the final manuscript.</p></sec><sec><title>Supplementary data</title><p>
<xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p></sec><sec sec-type="COI-statement"><title>Conflict of interest</title><p>All authors are current or former employees of Alector Inc.</p></sec><sec><title>Funding</title><p>This work was supported by Alector Inc.</p></sec><sec sec-type="data-availability"><title>Data availability</title><p>All code, notebooks, and benchmarking datasets are available: <ext-link xlink:href="https://github.com/Alector-BIO/llm2geneset" ext-link-type="uri">https://github.com/Alector-BIO/llm2geneset</ext-link>. The prompts used in this study are available for download: <ext-link xlink:href="https://github.com/Alector-BIO/llm2geneset/tree/main/src/llm2geneset/prompts" ext-link-type="uri">https://github.com/Alector-BIO/llm2geneset/tree/main/src/llm2geneset/prompts</ext-link>. A streamlit web application incorporating this tool is available: <ext-link xlink:href="https://github.com/Alector-BIO/llm2geneset/tree/main/webapp" ext-link-type="uri">https://github.com/Alector-BIO/llm2geneset/tree/main/webapp</ext-link>. An instance of the web application can also be accessed: <ext-link xlink:href="https://llm2geneset.streamlit.app" ext-link-type="uri">https://llm2geneset.streamlit.app</ext-link>.</p></sec><ref-list id="ref1"><title>References</title><ref id="vbaf054-B1"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ashburner</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Ball</surname><given-names>CA</given-names></string-name>, <string-name><surname>Blake</surname><given-names>JA</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Gene ontology: tool for the unification of biology</article-title>. <source>Nat Genet</source><year>2000</year>;<volume>25</volume>:<fpage>25</fpage>&#x02013;<lpage>9</lpage>.<pub-id pub-id-type="pmid">10802651</pub-id>
</mixed-citation></ref><ref id="vbaf054-B2"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Briggs</surname>
<given-names>TA</given-names>
</string-name>, <string-name><surname>Rice</surname><given-names>GI</given-names></string-name>, <string-name><surname>Daly</surname><given-names>S</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Tartrate-resistant acid phosphatase deficiency causes a bone dysplasia with autoimmunity and a type I interferon expression signature</article-title>. <source>Nat Genet</source><year>2011</year>;<volume>43</volume>:<fpage>127</fpage>&#x02013;<lpage>31</lpage>.<pub-id pub-id-type="pmid">21217755</pub-id>
</mixed-citation></ref><ref id="vbaf054-B3"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Brown</surname>
<given-names>TB</given-names>
</string-name>, <string-name><surname>Mann</surname><given-names>B</given-names></string-name><string-name><surname>Ryder</surname><given-names>N</given-names></string-name></person-group>
<etal>et al</etal> Language models are few-shot learners. In: <italic toggle="yes">NIPS&#x02019;20: Proceedings of the 34th International Conference on Neural Information Processing Systems</italic>. <year>2020</year>;<volume>159</volume>:<fpage>1877</fpage>&#x02013;<lpage>901</lpage>.</mixed-citation></ref><ref id="vbaf054-B4"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Cao</surname>
<given-names>H.</given-names>
</string-name>
</person-group> Recent advances in text embedding: A Comprehensive Review of Top-Performing Methods on the MTEB Benchmark. arXiv, arXiv:2406.01607, <year>2024</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B5"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Ch</surname>
</string-name>, <string-name><surname>en</surname><given-names>L</given-names></string-name>, <string-name><surname>Zaharia</surname><given-names>M</given-names></string-name><string-name><surname>Zou</surname><given-names>J</given-names></string-name></person-group>. FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance. In: <italic toggle="yes">Transactions on Machine Learning Research</italic>, 2024.</mixed-citation></ref><ref id="vbaf054-B6"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Gao</surname>
<given-names>Y</given-names>
</string-name>, <string-name><surname>Xiong</surname><given-names>Y</given-names></string-name><string-name><surname>Gao</surname><given-names>X</given-names></string-name></person-group>
<etal>et al</etal> Retrieval-Augmented Generation for Large Language Models: A Survey. arXiv, arXiv:2312.10997, <year>2024</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B7"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Garcia-Hernandez</surname>
<given-names>MdlL</given-names>
</string-name>, <string-name><surname>Rangel-Moreno</surname><given-names>J</given-names></string-name>, <string-name><surname>Garcia-Castaneda</surname><given-names>M</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Dendritic cell-specific transmembrane protein is required for synovitis and bone resorption in inflammatory arthritis</article-title>. <source>Front Immunol</source><year>2022</year>;<volume>13</volume>:<fpage>1026574</fpage>.<pub-id pub-id-type="pmid">36420272</pub-id>
</mixed-citation></ref><ref id="vbaf054-B8"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Hao</surname>
<given-names>S</given-names>
</string-name>
</person-group>
<etal>et al</etal>
<italic toggle="yes">LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models</italic>. <year>2024</year>.</mixed-citation></ref><ref id="vbaf054-B9"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Hou</surname>
<given-names>W</given-names>
</string-name>, <string-name><surname>Ji</surname><given-names>Z.</given-names></string-name></person-group> Assessing GPT-4 for cell type annotation in single-cell RNA-seq analysis. bioRxiv, <year>2023</year>.04.16.537094, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B10"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hu</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Alkhairy</surname><given-names>S</given-names></string-name>, <string-name><surname>Lee</surname><given-names>I</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Evaluation of large language models for discovery of gene set function</article-title>. <source>Nat Methods</source><year>2025</year>;<volume>22</volume>:<fpage>82</fpage>&#x02013;<lpage>91</lpage>.<pub-id pub-id-type="pmid">39609565</pub-id>
</mixed-citation></ref><ref id="vbaf054-B11"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Huang</surname>
<given-names>DW</given-names>
</string-name>, <string-name><surname>Sherman</surname><given-names>BT</given-names></string-name>, <string-name><surname>Lempicki</surname><given-names>RA</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Systematic and integrative analysis of large gene lists using DAVID bioinformatics resources</article-title>. <source>Nat Protoc</source><year>2009</year>;<volume>4</volume>:<fpage>44</fpage>&#x02013;<lpage>57</lpage>.<pub-id pub-id-type="pmid">19131956</pub-id>
</mixed-citation></ref><ref id="vbaf054-B12"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Jackson</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Paul</surname><given-names>R</given-names></string-name>, <string-name><surname>Joshi</surname><given-names>A</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>INVOKE-2 - a phase 2 randomized, Double-Blind, Placebo-Controlled study to evaluate the efficacy and safety of AL002 in participants with early Alzheimer&#x02019;s disease (P17-3.005)</article-title>. <source>Neurology</source><year>2022</year>;<volume>98</volume>:<fpage>2423</fpage>.</mixed-citation></ref><ref id="vbaf054-B13"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Jiang</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Wang</surname><given-names>F</given-names></string-name><string-name><surname>Shen</surname><given-names>J</given-names></string-name></person-group>
<etal>et al</etal> A Survey on Large Language Models for Code Generation. arXiv, arXiv:2406.00515, <year>2024</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B14"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Jin</surname>
<given-names>Q</given-names>
</string-name>, <string-name><surname>Yang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname><given-names>Q</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>GeneGPT: augmenting large language models with domain tools for improved access to biomedical information</article-title>. <source>Bioinformatics</source><year>2024</year>;<volume>40</volume>:btae075.</mixed-citation></ref><ref id="vbaf054-B15"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Joachimiak</surname>
<given-names>MP</given-names>
</string-name>, <string-name><surname>Caufield</surname><given-names>JH</given-names></string-name><string-name><surname>Harris</surname><given-names>NL</given-names></string-name></person-group>
<etal>et al</etal> Gene Set Summarization using Large Language Models. arXiv, arXiv:2305.13338, <year>2023</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B16"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Joshi-Tope</surname>
<given-names>G</given-names>
</string-name>, <string-name><surname>Gillespie</surname><given-names>M</given-names></string-name>, <string-name><surname>Vastrik</surname><given-names>I</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Reactome: a knowledgebase of biological pathways</article-title>. <source>Nucleic Acids Res</source><year>2005</year>;<volume>33</volume>:<fpage>D428</fpage>&#x02013;<lpage>432</lpage>.<pub-id pub-id-type="pmid">15608231</pub-id>
</mixed-citation></ref><ref id="vbaf054-B17"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Kanehisa</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Goto</surname><given-names>S.</given-names></string-name></person-group>
<article-title>KEGG: Kyoto encyclopedia of genes and genomes</article-title>. <source>Nucleic Acids Res</source><year>2000</year>;<volume>28</volume>:<fpage>27</fpage>&#x02013;<lpage>30</lpage>.<pub-id pub-id-type="pmid">10592173</pub-id>
</mixed-citation></ref><ref id="vbaf054-B18"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Kuleshov</surname>
<given-names>MV</given-names>
</string-name>, <string-name><surname>Jones</surname><given-names>MR</given-names></string-name>, <string-name><surname>Rouillard</surname><given-names>AD</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Enrichr: a comprehensive gene set enrichment analysis web server 2016 update</article-title>. <source>Nucleic Acids Res</source><year>2016</year>;<volume>44</volume>:<fpage>W90</fpage>&#x02013;<lpage>W97</lpage>.<pub-id pub-id-type="pmid">27141961</pub-id>
</mixed-citation></ref><ref id="vbaf054-B19"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Liberzon</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Birger</surname><given-names>C</given-names></string-name>, <string-name><surname>Thorvaldsd&#x000f3;ttir</surname><given-names>H</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>The molecular signatures database (MSigDB) hallmark gene set collection</article-title>. <source>Cell Syst</source><year>2015</year>;<volume>1</volume>:<fpage>417</fpage>&#x02013;<lpage>25</lpage>.<pub-id pub-id-type="pmid">26771021</pub-id>
</mixed-citation></ref><ref id="vbaf054-B20"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Martens</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Ammar</surname><given-names>A</given-names></string-name><string-name><surname>Riutta</surname><given-names>A</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>WikiPathways: connecting communities</article-title>. <source>Nucl Acids Res</source><year>2021</year>;<volume>49</volume>:D613&#x02013;D621.</mixed-citation></ref><ref id="vbaf054-B21"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Maleki</surname>
<given-names>F</given-names>
</string-name>, <string-name><surname>Ovens</surname><given-names>K</given-names></string-name>, <string-name><surname>Hogan</surname><given-names>DJ</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Gene set analysis: challenges, opportunities, and future research</article-title>. <source>Front Genet</source><year>2020</year>;<volume>11</volume>:<fpage>654</fpage>.<pub-id pub-id-type="pmid">32695141</pub-id>
</mixed-citation></ref><ref id="vbaf054-B22"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Mubeen</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Tom Kodamullil</surname><given-names>A</given-names></string-name>, <string-name><surname>Hofmann-Apitius</surname><given-names>M</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>On the influence of several factors on pathway enrichment analysis</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbac143</fpage>.<pub-id pub-id-type="pmid">35453140</pub-id>
</mixed-citation></ref><ref id="vbaf054-B23"><mixed-citation publication-type="other">OpenAI, Achim J, Adler S <etal>et al</etal> GPT-4 Technical Report. arXiv, arXiv:2303.08774, <year>2024</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B24"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Pope</surname>
<given-names>R, Singh AK, Sriparna S</given-names>
</string-name>
</person-group>
<etal>et al</etal> Efficiently Scaling Transformer Inference. In: <italic toggle="yes">Proceedings of Machine Learning and Systems</italic>, 2023;<volume>5</volume>:<fpage>606</fpage>&#x02013;<lpage>24</lpage>.</mixed-citation></ref><ref id="vbaf054-B25"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Sahoo</surname>
<given-names>P</given-names>
</string-name>, <string-name><surname>Singh</surname><given-names>AK</given-names></string-name><string-name><surname>Saha</surname><given-names>S</given-names></string-name></person-group>
<etal>et al</etal> A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications. arXiv, arXiv:2402.07927, <year>2024</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B26"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Schulhoff</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Ilie</surname><given-names>M</given-names></string-name><string-name><surname>Balepur</surname><given-names>N</given-names></string-name></person-group>
<etal>et al</etal> The Prompt Report: A Systematic Survey of Prompting Techniques. arXiv, arXiv:2406.06608, <year>2024</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B27"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Subramanian</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Tamayo</surname><given-names>P</given-names></string-name>, <string-name><surname>Mootha</surname><given-names>VK</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles</article-title>. <source>Proc Natl Acad Sci U S A</source><year>2005</year>;<volume>102</volume>:<fpage>15545</fpage>&#x02013;<lpage>50</lpage>.<pub-id pub-id-type="pmid">16199517</pub-id>
</mixed-citation></ref><ref id="vbaf054-B28"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Theodoris</surname>
<given-names>CV</given-names>
</string-name>, <string-name><surname>Xiao</surname><given-names>L</given-names></string-name>, <string-name><surname>Chopra</surname><given-names>A</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Transfer learning enables predictions in network biology</article-title>. <source>Nature</source><year>2023</year>;<volume>618</volume>:<fpage>616</fpage>&#x02013;<lpage>24</lpage>.<pub-id pub-id-type="pmid">37258680</pub-id>
</mixed-citation></ref><ref id="vbaf054-B29"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ulland</surname>
<given-names>TK</given-names>
</string-name>, <string-name><surname>Colonna</surname><given-names>M.</given-names></string-name></person-group>
<article-title>TREM2 - a key player in microglial biology and Alzheimer disease</article-title>. <source>Nat Rev Neurol</source><year>2018</year>;<volume>14</volume>:<fpage>667</fpage>&#x02013;<lpage>75</lpage>.<pub-id pub-id-type="pmid">30266932</pub-id>
</mixed-citation></ref><ref id="vbaf054-B30"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wadi</surname>
<given-names>L</given-names>
</string-name>, <string-name><surname>Meyer</surname><given-names>M</given-names></string-name>, <string-name><surname>Weiser</surname><given-names>J</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Impact of outdated gene annotations on pathway enrichment analysis</article-title>. <source>Nat Methods</source><year>2016</year>;<volume>13</volume>:<fpage>705</fpage>&#x02013;<lpage>6</lpage>.<pub-id pub-id-type="pmid">27575621</pub-id>
</mixed-citation></ref><ref id="vbaf054-B31"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname>
<given-names>Z</given-names>
</string-name>, <string-name><surname>Jin</surname><given-names>Q</given-names></string-name><string-name><surname>Chih-Hsuan</surname><given-names>W</given-names></string-name></person-group>
<etal>et al</etal> GeneAgent: Self-verification Language Agent for Gene Set Knowledge Discovery using Domain Databases. arXiv, arXiv:2405.16205, <year>2024</year>, preprint: not peer reviewed.</mixed-citation></ref><ref id="vbaf054-B32"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Wei</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Wang</surname><given-names>X</given-names></string-name><string-name><surname>Schuurmans</surname><given-names>D</given-names></string-name></person-group>
<etal>et al</etal> Chain-of-thought prompting elicits reasoning in large language models. In: <italic toggle="yes">Proceedings of the 36th International Conference on Neural Information Processing Systems</italic>, NIPS &#x02019;22. Red Hook, NY, USA: Curran Associates Inc, <year>2024</year>, <fpage>24824</fpage>&#x02013;<lpage>24837</lpage>.</mixed-citation></ref><ref id="vbaf054-B33"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wu</surname>
<given-names>D</given-names>
</string-name>, <string-name><surname>Lim</surname><given-names>E</given-names></string-name>, <string-name><surname>Vaillant</surname><given-names>F</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>ROAST: rotation gene set tests for complex microarray experiments</article-title>. <source>Bioinformatics</source><year>2010</year>;<volume>26</volume>:<fpage>2176</fpage>&#x02013;<lpage>82</lpage>.<pub-id pub-id-type="pmid">20610611</pub-id>
</mixed-citation></ref><ref id="vbaf054-B34"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wu</surname>
<given-names>D</given-names>
</string-name>, <string-name><surname>Smyth</surname><given-names>GK.</given-names></string-name></person-group>
<article-title>Camera: a competitive gene set test accounting for inter-gene correlation</article-title>. <source>Nucleic Acids Res</source><year>2012</year>;<volume>40</volume>:<fpage>e133</fpage>.<pub-id pub-id-type="pmid">22638577</pub-id>
</mixed-citation></ref><ref id="vbaf054-B35"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yagi</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Miyamoto</surname><given-names>T</given-names></string-name>, <string-name><surname>Sawatani</surname><given-names>Y</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>DC-STAMP is essential for cell&#x02013;cell fusion in osteoclasts and foreign body giant cells</article-title>. <source>J Exp Med</source><year>2005</year>;<volume>202</volume>:<fpage>345</fpage>&#x02013;<lpage>51</lpage>.<pub-id pub-id-type="pmid">16061724</pub-id>
</mixed-citation></ref></ref-list></back></article>