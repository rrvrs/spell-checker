<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS One</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40408639</article-id><article-id pub-id-type="pmc">PMC12101857</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0321008</article-id><article-id pub-id-type="publisher-id">PONE-D-24-40156</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Mathematical and Statistical Techniques</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth Sciences</subject><subj-group><subject>Hydrology</subject><subj-group><subject>Flooding</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Deep Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth Sciences</subject><subj-group><subject>Atmospheric Science</subject><subj-group><subject>Climatology</subject><subj-group><subject>Climate Change</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Ecology and Environmental Sciences</subject><subj-group><subject>Natural Resources</subject><subj-group><subject>Water Resources</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Signal Processing</subject><subj-group><subject>Autocorrelation</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Mathematical and Statistical Techniques</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Autocorrelation</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Autocorrelation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Data</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Forecasting monthly runoff in a glacierized catchment: A comparison of extreme gradient boosting (XGBoost) and deep learning models</article-title><alt-title alt-title-type="running-head">A comparison of extreme gradient boosting (XGBoost) and deep learning models for forecasting monthly runoff</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9366-9162</contrib-id><name><surname>Hameed</surname><given-names>Mohammed Majeed</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Masood</surname><given-names>Adil</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>hamid</surname><given-names>Aadil</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Elbeltagi</surname><given-names>Ahmed</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Razali</surname><given-names>Siti Fatin Mohd</given-names></name><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6176-8345</contrib-id><name><surname>Salem</surname><given-names>Ali</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff005" ref-type="aff">
<sup>5</sup>
</xref><xref rid="aff006" ref-type="aff">
<sup>6</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>Upper Euphrates Center for Sustainable Development Research, University of Anbar, Ramadi, Iraq</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>Department of Natural and Applied Sciences, TERI School of Advanced Studies, New Delhi, India</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Agricultural Engineering Department, Faculty of Agriculture, Mansoura University, Mansoura, Egypt</addr-line></aff><aff id="aff004"><label>4</label>
<addr-line>Department of Civil Engineering, Faculty of Engineering and Built Environment, Universiti Kebangsaan Malaysia (UKM), Bangi, Malaysia</addr-line></aff><aff id="aff005"><label>5</label>
<addr-line>Civil Engineering Department, Faculty of Engineering, Minia University, Minia, Egypt</addr-line></aff><aff id="aff006"><label>6</label>
<addr-line>Structural Diagnostics and Analysis Research Group, Faculty of Engineering and Information Technology, University of P&#x000e9;cs, P&#x000e9;cs, Hungary</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Li</surname><given-names>Shicheng</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>KTH Royal Institute of Technology: Kungliga Tekniska Hogskolan, SWEDEN</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>mohmmag1@gmail.com</email> (MMH); <email>ahmedelbeltagy81@mans.edu.eg</email> (AE); <email>salem.ali@mik.pte.hu</email> (AS)</corresp></author-notes><pub-date pub-type="epub"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>20</volume><issue>5</issue><elocation-id>e0321008</elocation-id><history><date date-type="received"><day>11</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>28</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 Hameed et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Hameed et al</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0321008.pdf">
</self-uri><abstract><p>Accurate monthly runoff forecasting is vital for water management, flood control, hydropower, and irrigation. In glacierized catchments affected by climate change, runoff is influenced by complex hydrological processes, making precise forecasting even more challenging. To address this, the study focuses on the Lotschental catchment in Switzerland, conducting a comprehensive comparison between deep learning and ensemble-based models. Given the significant autocorrelation in runoff time series data, which may hinder the evaluation of prediction models, a novel statistical method is employed to assess the effectiveness of forecasting models in detecting turning points in the runoff data. The performance of Extreme Gradient Boosting (XGBoost) was compared with long short-term memory (LSTM) and random forest (RF) models for one-month-ahead runoff forecasting. The study used 20 years of runoff data (2002&#x02013;2021), with 70% (2002&#x02013;2015) dedicated for training and calibration, and the remaining data (2016&#x02013;2021) for testing. The findings for the testing phase results show that the XGBoost model achieves the best accuracy, with <italic toggle="yes">R&#x000b2;</italic> of 0.904, <italic toggle="yes">RMSE</italic> of 1.554 m&#x000b3;/sec, an <italic toggle="yes">NSE</italic> of 0.797, and Willmott index (<italic toggle="yes">d</italic>) of 0.972, outperforming both the LSTM and RF models. The study also found that the XGBoost model estimated turning points more accurately, obtaining forecasting improvements of up to 22% to 34% compared to LSTM and RF models. Overall, the study&#x02019;s findings are essential for global water resource management, providing insights that can inform sustainable practices to support societies impacted by climate change.</p></abstract><funding-group><funding-statement>The author(s) received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="14"/><table-count count="5"/><page-count count="29"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the paper and its <xref rid="sec016" ref-type="sec">Supporting Information</xref> files.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the paper and its <xref rid="sec016" ref-type="sec">Supporting Information</xref> files.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>1. Introduction</title><p>Hydrological Runoff Forecasting plays a crucial role in today&#x02019;s water resource management, regional water resource system, controlling flood water for agriculture and hydrological power projects and environmental impact assessment [<xref rid="pone.0321008.ref001" ref-type="bibr">1</xref>,<xref rid="pone.0321008.ref002" ref-type="bibr">2</xref>]. Runoff denotes the fraction of precipitation or snowmelt that flows over the land surface and eventually confluences with streams, rivers, and other types of fluvial systems. River runoff constitutes a substantial replenishment source for the groundwater basin within the region. Accurate runoff forecasting is a vital engineering endeavor for mitigating the impacts of flood disasters. Improving the precision of runoff predictions remains a formidable challenge in the realm of water resources management research [<xref rid="pone.0321008.ref003" ref-type="bibr">3</xref>]. Various models have been created to predict runoff in Glacierized catchments. For example, the HBV (Hydrologiska Byr&#x000e5;ns Vattenbalansavdelning) model was utilized for studying the effect of climate change on the runoff and glacier changes in Yushugou Basin, China [<xref rid="pone.0321008.ref004" ref-type="bibr">4</xref>] and to calculate the snowmelt and its share to the overall streamflow in the Panchachuli glacier region of Central Himalaya [<xref rid="pone.0321008.ref005" ref-type="bibr">5</xref>].</p><p>Accurate runoff prediction is vital for managing water resources. It also allows for better flood and drought control, reservoir management, and hydropower generation, ultimately leading to more efficient water use [<xref rid="pone.0321008.ref006" ref-type="bibr">6</xref>]. In particular, monthly-scale runoff forecasting is essential for effectively monitoring natural hydrological disasters such as droughts and floods, as these forecasts enable the establishment of early warning systems [<xref rid="pone.0321008.ref007" ref-type="bibr">7</xref>&#x02013;<xref rid="pone.0321008.ref009" ref-type="bibr">9</xref>]. Also, this allows necessary measures to be taken in advance, mitigating their socio-economic impacts as well as improving water resources management. In general, the models used for runoff prediction are mainly divided into two sections: Process driven, and Data driven models [<xref rid="pone.0321008.ref010" ref-type="bibr">10</xref>]. These models are also widely used for runoff estimation and prediction ([<xref rid="pone.0321008.ref011" ref-type="bibr">11</xref>&#x02013;<xref rid="pone.0321008.ref013" ref-type="bibr">13</xref>]). Several studies have reported that process-driven models are primarily constructed based on an understanding of runoff development processes [<xref rid="pone.0321008.ref014" ref-type="bibr">14</xref>&#x02013;<xref rid="pone.0321008.ref016" ref-type="bibr">16</xref>]. These models aim to derive physical parameters that can be used for simulation or prediction tasks. On the other hand, data-driven models solely focus on the input-output relationship without making explicit causal inferences [<xref rid="pone.0321008.ref017" ref-type="bibr">17</xref>]. Also, the process of driven models relies on linear and partial differential equations [<xref rid="pone.0321008.ref018" ref-type="bibr">18</xref>,<xref rid="pone.0321008.ref019" ref-type="bibr">19</xref>]. Runoff prediction methods are primarily categorized into process-driven and data-driven models. Process-driven models like Soil and Water Assessment Tool (SWAT) [<xref rid="pone.0321008.ref020" ref-type="bibr">20</xref>] and Hydrological Simulation Program-Fortran (HSPF) [<xref rid="pone.0321008.ref021" ref-type="bibr">21</xref>] simulate hydrological processes using physical principles. They provide interpretable results but often being computationally intensive and require lots of hydrological and climate variables. While some researchers point out that runoff prediction is a multifaceted hurdle [<xref rid="pone.0321008.ref022" ref-type="bibr">22</xref>], it is influenced by numerous uncertain factors, which include high complexity, non-linear factors, non-stationarity, and dynamism, hence making it difficult to accurately predict runoff by process-driven methods. Moreover, conceptual models require extensive hydrological data, which may not be available in certain regions. Additionally, the implementation of such models is often more expensive and time-consuming. Therefore, various researchers inferred the input-output relationship of data-driven models to be linear and hence predicted runoff by methods like an autoregressive moving average (ARMA) model [<xref rid="pone.0321008.ref023" ref-type="bibr">23</xref>], autoregressive integrated moving average (ARIMA) model [<xref rid="pone.0321008.ref024" ref-type="bibr">24</xref>] and autoregressive (AR) model [<xref rid="pone.0321008.ref025" ref-type="bibr">25</xref>]. Also, other researchers inferred the prediction result could be made better by taking into consideration the non-linear nature [<xref rid="pone.0321008.ref026" ref-type="bibr">26</xref>&#x02013;<xref rid="pone.0321008.ref028" ref-type="bibr">28</xref>].</p><p>Moreover, a variety of other classical machine learning models such as artificial neural networks (ANN) [<xref rid="pone.0321008.ref029" ref-type="bibr">29</xref>], SVM [<xref rid="pone.0321008.ref030" ref-type="bibr">30</xref>], and Random Forest (RF) [<xref rid="pone.0321008.ref031" ref-type="bibr">31</xref>] have been applied for studying runoff prediction. Advanced models based on deep learning have also been developed for various activities involving prediction applications, which include Runoff-prediction [<xref rid="pone.0321008.ref032" ref-type="bibr">32</xref>], prediction of precipitation [<xref rid="pone.0321008.ref033" ref-type="bibr">33</xref>], properties and composition of soil [<xref rid="pone.0321008.ref034" ref-type="bibr">34</xref>], water table [<xref rid="pone.0321008.ref035" ref-type="bibr">35</xref>], and streamflow forecasting [<xref rid="pone.0321008.ref036" ref-type="bibr">36</xref>]. In recent years, machine learning and deep learning models have garnered significant interest from researchers in constructing highly computationally intensive and accurate forecasting systems. Some researchers compared three boosting models (Extreme Gradient Boosting (XGBoost), Light Gradient-Boosting Machine (Light GBM) &#x00026; Categorical Boosting (CatBoost)) to forecast daily streamflow in mountainous catchment [<xref rid="pone.0321008.ref037" ref-type="bibr">37</xref>]. The study concluded that the gradient boosting algorithms used in models such as XGBoost, are simple to implement, fast, and robust.</p><p>It is important to note that both long short-term memory (LSTM), and XGBoost are commonly used to model several hydrological parameters (e.g., runoff) due to their efficiency in handling time series data [<xref rid="pone.0321008.ref038" ref-type="bibr">38</xref>&#x02013;<xref rid="pone.0321008.ref040" ref-type="bibr">40</xref>]. The LSTM algorithm is highly effective for modeling time series data, as it captures both short- and long-term dependencies within sequential data. Furthermore, RF is a robust ensemble method that captures complex relationships in runoff data (e.g., reduces) overfitting by averaging across multiple decision trees [<xref rid="pone.0321008.ref041" ref-type="bibr">41</xref>&#x02013;<xref rid="pone.0321008.ref043" ref-type="bibr">43</xref>]. Besides, the XGBoost model is a powerful gradient-boosting algorithm that excels at modeling non-linear relationships and performs exceptionally well in time series forecasting, particularly with lagged variables due to its advanced optimization and ability to handle structured data.</p><p>Some investigations constructed a hybrid model which is formulated by using extreme gradient boosting and Gaussian mixture model, which they named as GMM-XGBoost [<xref rid="pone.0321008.ref029" ref-type="bibr">29</xref>]. They applied this model to predict monthly streamflow at Cuntan &#x00026; Hankou stations on Yangtze River and the result concluded that the XGBoost-based models performed well and are applicable for streamflow forecasting and are superior to SVM. In a similar work, [<xref rid="pone.0321008.ref044" ref-type="bibr">44</xref>] combined machine learning (ML) models XGBoost and SHAP to develop an explainable ML-based model (KXGBoost) and its results demonstrate a robust data-driven model for runoff prediction. Other scholars investigated the hybrid model created by integration of Fourier transform with LSTM to predict monthly runoff in Brahmani Rive, India [<xref rid="pone.0321008.ref045" ref-type="bibr">45</xref>]. The researchers found that the suggested model outperforms several classical and deep learning models. Some investigations have confirmed that classical ML models can be enhanced by incorporating bio-inspired algorithms and data preprocessing techniques [<xref rid="pone.0321008.ref046" ref-type="bibr">46</xref>&#x02013;<xref rid="pone.0321008.ref049" ref-type="bibr">49</xref>], thereby improving the models&#x02019; capability in forecasting runoff. An advanced model such as LSTM with AM (Attention mechanism) was developed for estimating runoff in Hun River, China [<xref rid="pone.0321008.ref050" ref-type="bibr">50</xref>]. It was reported that the model presented high accuracy, indicating its potential in hydrological modeling. Moreover, other researchers [<xref rid="pone.0321008.ref051" ref-type="bibr">51</xref>] demonstrated the framework efficacy of daily edge-of-field (EOF) runoff prediction using the XGBoost algorithm and concluded that the effectiveness of the XGBoost model in runoff prediction is well-supported by various studies emphasizing its accuracy, robustness, and efficiency. Its capability to minimize overfitting while maintaining high predictive accuracy makes it an invaluable tool in hydrological modeling and other environmental prediction tasks. As this field keeps on growing, XGBoost is likely to remain a cornerstone model for researchers and practitioners aiming to enhance predictive accuracy and efficiency in runoff prediction.</p><p>Despite the advancement of various models for runoff forecasting conducting in previous research, a significant knowledge gap remains regarding the comprehensive comparative effectiveness of machine learning approaches such as XGBoost, RF, and advanced deep learning models like LSTM. Moreover, the comparison of deep learning models such as LSTM, XGBoost offers an easier interpretation of the significance of predictors. Also, previous research indicates that very few studies have focused on modeling runoff in the Lotschental catchment in Switzerland. A comprehensive study of such catchments is hydrologically significant due to their provision of essential freshwater through glacial melt, particularly in the warmer months. Such catchments are important indicators of climate change, influencing local hydrology and downstream water availability, and they also pose flood risks during melt periods, necessitating effective management strategies. In prior works, researchers interested in modeling runoff time series data have often overlooked the importance of analyzing how well these predictive models can capture turning points. The turning points are essential for understanding significant shifts in hydrological dynamics.</p><p>In our study, we propose using the XGBoost model to forecast monthly rainfall one month ahead in the Lotschental catchment, Switzerland, and compared its performance with other AI model such as LSTM and regression tree model like RF. Runoff generation in mountain regions is affected by cyclogenetic processes [<xref rid="pone.0321008.ref052" ref-type="bibr">52</xref>] and the development of mesoscale circulations [<xref rid="pone.0321008.ref053" ref-type="bibr">53</xref>], which makes the process of runoff prediction extremely challenging. Therefore, developing a reliable projection model for runoff prediction is a difficult task. In order to address this challenge of limited accuracy and reliability in runoff prediction, we developed and compared three state-of-the-art machine learning models to determine the most effective technique for runoff forecasting. Additionally, tuning points in the runoff time series have been detected using a new algorithm. These tuning points are very important in analyzing time series data, as they identify significant shifts in trends (peaks and troughs) within the runoff data, providing valuable insights into the system&#x02019;s underlying dynamics. Thus, the efficiency of the applied forecasting models has been evaluated based on their ability to adequately capture these tuning points. By capitalizing the findings from these studies, this study aims to contribute to the existing knowledge on monthly runoff forecasting in glacierized catchments. Notably, this study is among the first to compare XGBoost, LSTM, and RF models for runoff prediction in glacier catchments, utilizing turning point analysis. The study aims to:</p><list list-type="simple"><list-item><p>1) Develop models using XGBoost and LSTM for forecasting runoff, focusing on selecting appropriate features using partial autocorrelation function.</p></list-item><list-item><p>2) Compare the performance of XGBoost and LSTM with other ML models based on statistical evaluation metrics such as <italic toggle="yes">RMSE</italic>, <italic toggle="yes">MAE</italic>, <italic toggle="yes">R&#x000b2;</italic>, and other metrics to assess their predictive accuracy and reliability.</p></list-item><list-item><p>3) Identify and analyze the turning points in monthly runoff time series data and assess the efficiency of forecasting models in accurately predicting these points.</p></list-item><list-item><p>4) Investigate the potential of XGBoost for forecasting runoff by analyzing its predictive capabilities, robustness, and scalability in different hydrological scenarios and datasets.</p></list-item></list><p>The comparative analysis between XGBoost and Deep Learning models will provide insights into the strengths and limitations of each approach, ultimately guiding decision-makers in selecting the most effective modeling technique for accurate and reliable runoff predictions in glacier-influenced watersheds.</p><p>To achieve the above-mentioned research objectives, four key research questions (RQs) have been developed:</p><list list-type="simple"><list-item><p>RQ1: How effective are XGBoost and LSTM models in forecasting runoff when using the Partial Autocorrelation Function (PACF) to select relevant features?</p></list-item><list-item><p>RQ2: How does the performance of XGBoost and LSTM models compare to other machine learning models in terms of <italic toggle="yes">RMSE</italic>, <italic toggle="yes">MAE</italic>, and <italic toggle="yes">R</italic>&#x000b2; for runoff forecasting?</p></list-item><list-item><p>RQ3: Can XGBoost and LSTM models accurately identify and predict turning points in monthly runoff time series data?</p></list-item><list-item><p>RQ4: How robust and scalable are XGBoost models for runoff forecasting across various hydrological scenarios and datasets?</p></list-item></list></sec><sec id="sec002"><title>2. Case study location</title><p>The L&#x004e7;tschental catchment occupies a unique transitional zone between the Mediterranean climate of the Southern Alps and the maritime climate of the Northern Alps. Located at 46&#x000b0; 24&#x02019; 59.99&#x0201c; N latitude and 7&#x000b0; 49&#x02019; 59.99&#x0201d; E longitude (See <xref rid="pone.0321008.g001" ref-type="fig">Fig 1</xref>), the catchment sits within the Jungfrau-Aletsch-Bietschhorn region of the Bernese Alps at an elevation of 2624 meters above sea level [<xref rid="pone.0321008.ref054" ref-type="bibr">54</xref>]. The Lonza River, fed by its primary tributaries, the Lang and Anun Glaciers, flows through the valley, with the glaciers themselves forming the eastern and northeastern boundaries of the L&#x004e7;tschental [<xref rid="pone.0321008.ref055" ref-type="bibr">55</xref>]. In recent years, the valley has experienced significant flooding due to increased discharge from mountain rivers in the Bernese Alps, highlighting the region&#x02019;s susceptibility to climate change-induced floods [<xref rid="pone.0321008.ref056" ref-type="bibr">56</xref>]. Previous studies have documented substantial changes in and around the study area due to the climate change [<xref rid="pone.0321008.ref057" ref-type="bibr">57</xref>]. Furthermore, active fault lines underpinning the region give rise to a series of earthquakes. The faults detected in the Canton of Bern potentially influenced by localized stress conditions, pose a threat to regional stability and enhance the susceptibility of landslides [<xref rid="pone.0321008.ref058" ref-type="bibr">58</xref>]. Also, the 2005 floods drastically affected the region, due to severe destruction in 900 municipalities and complete infrastructure damage in others, as well as some documented displacements within the Canton of Bern [<xref rid="pone.0321008.ref059" ref-type="bibr">59</xref>]</p><fig position="float" id="pone.0321008.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g001</object-id><label>Fig 1</label><caption><title>Case study location (Generated using ArcGIS 10.8.2).</title></caption><graphic xlink:href="pone.0321008.g001" position="float"/></fig><p>The surging tributaries of the Lonza River have caused substantial erosion and debris flow, underscoring the critical need for accurate runoff forecasting to mitigate flood risks in this area. Daily precipitation and mean air temperature data were acquired from MeteoSwiss for the Blatten, L&#x000f6;tschental station located at 1538 meters above sea level. Corresponding daily runoff (Q) measurements for the Lonza-Blatten hydrometric station were obtained from the Swiss Federal Office for the Environment (FOEN). This station sits at 1520 meters and drains an upstream area of approximately 77 km&#x000b2;, with 24.6% glacier coverage. <xref rid="pone.0321008.t001" ref-type="table">Table 1</xref> summarizes the key statistics of the meteorological and hydrometric data used, while <xref rid="pone.0321008.g002" ref-type="fig">Fig 2</xref> presents a bar chart depicting the monthly distribution of measured runoff during the study period. It is evident that the applied case study experienced the highest runoff rates in June, July, and August, with values of 11.919 m<sup>3</sup>/sec, 12.854 m<sup>3</sup>/sec, and 11.126 m<sup>3</sup>/sec respectively. As shown in <xref rid="pone.0321008.g002" ref-type="fig">Fig 2</xref>, runoff values demonstrate a clear seasonal pattern, with the highest values recorded in July (likely due to snowmelt) and the lowest values occurring in February. Notably, the data regarding the mean monthly runoff used in this study for L&#x004e7;tschental station are provided in the S Appendix (S1 Table) [<xref rid="pone.0321008.ref060" ref-type="bibr">60</xref>].</p><table-wrap position="float" id="pone.0321008.t001"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.t001</object-id><label>Table 1</label><caption><title>Statistical description of the monthly runoff records.</title></caption><alternatives><graphic xlink:href="pone.0321008.t001" id="pone.0321008.t001g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Month</th><th align="left" rowspan="1" colspan="1">Maximum m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1">Minimum m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1">Median m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1">Standard deviation m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1">Mean m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1">Skewness</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">January</td><td align="left" rowspan="1" colspan="1">0.764</td><td align="left" rowspan="1" colspan="1">0.488</td><td align="left" rowspan="1" colspan="1">0.601</td><td align="left" rowspan="1" colspan="1">0.076</td><td align="left" rowspan="1" colspan="1">0.601</td><td align="left" rowspan="1" colspan="1">0.327</td></tr><tr><td align="left" rowspan="1" colspan="1">February</td><td align="left" rowspan="1" colspan="1">0.734</td><td align="left" rowspan="1" colspan="1">0.458</td><td align="left" rowspan="1" colspan="1">0.537</td><td align="left" rowspan="1" colspan="1">0.060</td><td align="left" rowspan="1" colspan="1">0.541</td><td align="left" rowspan="1" colspan="1">1.498</td></tr><tr><td align="left" rowspan="1" colspan="1">March</td><td align="left" rowspan="1" colspan="1">1.013</td><td align="left" rowspan="1" colspan="1">0.444</td><td align="left" rowspan="1" colspan="1">0.634</td><td align="left" rowspan="1" colspan="1">0.160</td><td align="left" rowspan="1" colspan="1">0.673</td><td align="left" rowspan="1" colspan="1">0.627</td></tr><tr><td align="left" rowspan="1" colspan="1">April</td><td align="left" rowspan="1" colspan="1">3.805</td><td align="left" rowspan="1" colspan="1">0.956</td><td align="left" rowspan="1" colspan="1">1.751</td><td align="left" rowspan="1" colspan="1">0.696</td><td align="left" rowspan="1" colspan="1">1.904</td><td align="left" rowspan="1" colspan="1">1.452</td></tr><tr><td align="left" rowspan="1" colspan="1">May</td><td align="left" rowspan="1" colspan="1">8.438</td><td align="left" rowspan="1" colspan="1">3.016</td><td align="left" rowspan="1" colspan="1">5.094</td><td align="left" rowspan="1" colspan="1">1.692</td><td align="left" rowspan="1" colspan="1">5.514</td><td align="left" rowspan="1" colspan="1">0.339</td></tr><tr><td align="left" rowspan="1" colspan="1">June</td><td align="left" rowspan="1" colspan="1">16.887</td><td align="left" rowspan="1" colspan="1">8.201</td><td align="left" rowspan="1" colspan="1">11.606</td><td align="left" rowspan="1" colspan="1">2.555</td><td align="left" rowspan="1" colspan="1">11.919</td><td align="left" rowspan="1" colspan="1">0.627</td></tr><tr><td align="left" rowspan="1" colspan="1">July</td><td align="left" rowspan="1" colspan="1">16.343</td><td align="left" rowspan="1" colspan="1">9.547</td><td align="left" rowspan="1" colspan="1">12.851</td><td align="left" rowspan="1" colspan="1">1.949</td><td align="left" rowspan="1" colspan="1">12.854</td><td align="left" rowspan="1" colspan="1">-0.051</td></tr><tr><td align="left" rowspan="1" colspan="1">August</td><td align="left" rowspan="1" colspan="1">14.962</td><td align="left" rowspan="1" colspan="1">6.331</td><td align="left" rowspan="1" colspan="1">11.372</td><td align="left" rowspan="1" colspan="1">1.905</td><td align="left" rowspan="1" colspan="1">11.126</td><td align="left" rowspan="1" colspan="1">-0.382</td></tr><tr><td align="left" rowspan="1" colspan="1">September</td><td align="left" rowspan="1" colspan="1">8.565</td><td align="left" rowspan="1" colspan="1">3.103</td><td align="left" rowspan="1" colspan="1">6.590</td><td align="left" rowspan="1" colspan="1">1.234</td><td align="left" rowspan="1" colspan="1">6.317</td><td align="left" rowspan="1" colspan="1">-0.691</td></tr><tr><td align="left" rowspan="1" colspan="1">October</td><td align="left" rowspan="1" colspan="1">4.197</td><td align="left" rowspan="1" colspan="1">1.724</td><td align="left" rowspan="1" colspan="1">2.871</td><td align="left" rowspan="1" colspan="1">0.682</td><td align="left" rowspan="1" colspan="1">2.776</td><td align="left" rowspan="1" colspan="1">0.347</td></tr><tr><td align="left" rowspan="1" colspan="1">November</td><td align="left" rowspan="1" colspan="1">2.374</td><td align="left" rowspan="1" colspan="1">0.929</td><td align="left" rowspan="1" colspan="1">1.196</td><td align="left" rowspan="1" colspan="1">0.375</td><td align="left" rowspan="1" colspan="1">1.296</td><td align="left" rowspan="1" colspan="1">1.712</td></tr><tr><td align="left" rowspan="1" colspan="1">December</td><td align="left" rowspan="1" colspan="1">1.007</td><td align="left" rowspan="1" colspan="1">0.615</td><td align="left" rowspan="1" colspan="1">0.774</td><td align="left" rowspan="1" colspan="1">0.103</td><td align="left" rowspan="1" colspan="1">0.780</td><td align="left" rowspan="1" colspan="1">0.425</td></tr></tbody></table></alternatives></table-wrap><fig position="float" id="pone.0321008.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g002</object-id><label>Fig 2</label><caption><title>The Overall measured runoff values for each month.</title></caption><graphic xlink:href="pone.0321008.g002" position="float"/></fig></sec><sec id="sec003"><title>3. Machine learning models</title><p>This study employs three advanced machine learning models: Long Short-Term Memory (LSTM) networks, Extreme Gradient Boosting (XGBoost), and Random Forest (RF) to forecast runoff in the Lotschental catchment in Switzerland. These models are particularly well-suited for runoff forecasting due to their ability to capture complex, nonlinear relationships within hydrological data, handle long-term dependencies, and mitigate overfitting.</p><p>The LSTM algorithm is well-suited for modeling time series data as it effectively captures both short- and long-term dependencies in sequential data. Furthermore, RF is a robust ensemble method that captures complex relationships in runoff data and reduces overfitting by averaging across multiple decision trees. Lastly, XGBoost is a powerful gradient-boosting algorithm that efficiently models non-linear relationships. It performs exceptionally well in time series forecasting, especially with lagged variables, due to its advanced optimization and ability to handle structured data.</p><sec id="sec004"><title>3.1 LSTM</title><p>LSTM is a type of recurrent neural network that processes sequential data using memory cells within the hidden layer [<xref rid="pone.0321008.ref061" ref-type="bibr">61</xref>]. These cells control information flow through forget, input, and output gates (<xref rid="pone.0321008.g003" ref-type="fig">Fig 3</xref>). The forget gate discards irrelevant past information, the input gate selects new data to remember, and the output gate determines what processed information affects the next cell. This gating mechanism allows LSTMs to learn long-term dependencies in the sequential data. The LSTM&#x02019;s gated configuration enables long-term information retention over multiple time steps, effectively mitigating the vanishing gradient problem common in classical RNN models [<xref rid="pone.0321008.ref062" ref-type="bibr">62</xref>]. Mathematically, the operation of a memory cell in an LSTM can be described as follows [<xref rid="pone.0321008.ref063" ref-type="bibr">63</xref>]:</p><fig position="float" id="pone.0321008.g003"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g003</object-id><label>Fig 3</label><caption><title>a. Typical configuration of LSTM. b. Proposed LSTM model.</title></caption><graphic xlink:href="pone.0321008.g003" position="float"/></fig><disp-formula id="pone.0321008.e001">
<alternatives><graphic xlink:href="pone.0321008.e001.jpg" id="pone.0321008.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>&#x0222a;</mml:mo><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></alternatives>
<label>(1)</label>
</disp-formula><disp-formula id="pone.0321008.e002">
<alternatives><graphic xlink:href="pone.0321008.e002.jpg" id="pone.0321008.e002g" position="anchor"/><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>&#x0222a;</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives>
<label>(2)</label>
</disp-formula><disp-formula id="pone.0321008.e003">
<alternatives><graphic xlink:href="pone.0321008.e003.jpg" id="pone.0321008.e003g" position="anchor"/><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>O</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>&#x0222a;</mml:mo><mml:mi>O</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>O</mml:mi></mml:msub></mml:mrow></mml:math></alternatives>
<label>(3)</label>
</disp-formula><disp-formula id="pone.0321008.e004">
<alternatives><graphic xlink:href="pone.0321008.e004.jpg" id="pone.0321008.e004g" position="anchor"/><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>&#x0222a;</mml:mo><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
<label>(4)</label>
</disp-formula><disp-formula id="pone.0321008.e005">
<alternatives><graphic xlink:href="pone.0321008.e005.jpg" id="pone.0321008.e005g" position="anchor"/><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mtext>tanh</mml:mtext><mml:mfenced><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
<label>(5)</label>
</disp-formula><p>Where, <inline-formula id="pone.0321008.e006"><alternatives><graphic xlink:href="pone.0321008.e006.jpg" id="pone.0321008.e006g" position="anchor"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0321008.e007"><alternatives><graphic xlink:href="pone.0321008.e007.jpg" id="pone.0321008.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>and <inline-formula id="pone.0321008.e008"><alternatives><graphic xlink:href="pone.0321008.e008.jpg" id="pone.0321008.e008g" position="anchor"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> represent forget gate, input gate, and output gate, <inline-formula id="pone.0321008.e009"><alternatives><graphic xlink:href="pone.0321008.e009.jpg" id="pone.0321008.e009g" position="anchor"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> represents the input, <inline-formula id="pone.0321008.e010"><alternatives><graphic xlink:href="pone.0321008.e010.jpg" id="pone.0321008.e010g" position="anchor"/><mml:math id="e010" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. is the cell state, <inline-formula id="pone.0321008.e011"><alternatives><graphic xlink:href="pone.0321008.e011.jpg" id="pone.0321008.e011g" position="anchor"/><mml:math id="e011" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and tanh are the sigmoid and hyperbolic tangent activation functions, <inline-formula id="pone.0321008.e012"><alternatives><graphic xlink:href="pone.0321008.e012.jpg" id="pone.0321008.e012g" position="anchor"/><mml:math id="e012" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0321008.e013"><alternatives><graphic xlink:href="pone.0321008.e013.jpg" id="pone.0321008.e013g" position="anchor"/><mml:math id="e013" display="inline" overflow="scroll"><mml:mrow><mml:mtext/><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>O</mml:mi></mml:msub><mml:mtext/></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0321008.e014"><alternatives><graphic xlink:href="pone.0321008.e014.jpg" id="pone.0321008.e014g" position="anchor"/><mml:math id="e014" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> represent the biases in the network and<inline-formula id="pone.0321008.e015"><alternatives><graphic xlink:href="pone.0321008.e015.jpg" id="pone.0321008.e015g" position="anchor"/><mml:math id="e015" display="inline" overflow="scroll"><mml:mrow><mml:mtext/><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>
<inline-formula id="pone.0321008.e016"><alternatives><graphic xlink:href="pone.0321008.e016.jpg" id="pone.0321008.e016g" position="anchor"/><mml:math id="e016" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0321008.e017"><alternatives><graphic xlink:href="pone.0321008.e017.jpg" id="pone.0321008.e017g" position="anchor"/><mml:math id="e017" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>O</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0321008.e018"><alternatives><graphic xlink:href="pone.0321008.e018.jpg" id="pone.0321008.e018g" position="anchor"/><mml:math id="e018" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003c9;</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are the corresponding weigh for the forget gate, input gate, output gate, and cell state respectively.</p><p>In this study, a deep Long Short-Term Memory (LSTM) neural network architecture was utilized, as depicted in <xref rid="pone.0321008.g003" ref-type="fig">Fig 3b</xref>. This architecture comprises an input layer, two LSTM layers (LSTM-1 and LSTM-2), a dense layer, and a lambda layer.</p><p>The initial LSTM layer (LSTM-1) incorporates numerous units and employs a Rectified Linear Unit (ReLU) activation function to generate a sequence output. Subsequently, the second LSTM layer (LSTM-2) utilizes several units and a ReLU activation function, but without producing a sequence. The dense layer, consisting of n units, employs a sigmoid activation function. Finally, a lambda layer used to scale the output of the dense layer.</p></sec><sec id="sec005"><title>3.2 RF</title><p>Random forest, a supervised machine learning approach, leverages ensemble learning to improve prediction accuracy. They combine numerous estimator decision trees, each making individual predictions [<xref rid="pone.0321008.ref064" ref-type="bibr">64</xref>] (<xref rid="pone.0321008.g004" ref-type="fig">Fig 4</xref>). Training utilizes bagging, where subsets of data are used to grow each tree. This technique, called bootstrap aggregation, reduces overfitting and improves model robustness [<xref rid="pone.0321008.ref065" ref-type="bibr">65</xref>]. In this study, we employ random forest regression, where each tree node considers a random subset of input variables. The final prediction is the average of all individual tree predictions [<xref rid="pone.0321008.ref066" ref-type="bibr">66</xref>]. As the number of trees increases, so does the overall prediction accuracy.</p><fig position="float" id="pone.0321008.g004"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g004</object-id><label>Fig 4</label><caption><title>Random Forest based prediction process.</title></caption><graphic xlink:href="pone.0321008.g004" position="float"/></fig></sec><sec id="sec006"><title>3.3 XGBoost</title><p>The XGBoost model employs the concept of boosting, which aggregates the predictions of multiple weak learners to construct a potent and strong ensemble learner through an additive training approach [<xref rid="pone.0321008.ref067" ref-type="bibr">67</xref>]. This modeling technique, unlike other ML models, is complex with many tunable parameters [<xref rid="pone.0321008.ref068" ref-type="bibr">68</xref>]. Strategically designed to reduce overfitting and prediction variability while enhancing overall prediction accuracy, the technique is widely used in hydrology [<xref rid="pone.0321008.ref069" ref-type="bibr">69</xref>] for various applications, including modeling groundwater salinity, [<xref rid="pone.0321008.ref070" ref-type="bibr">70</xref>] water quality [<xref rid="pone.0321008.ref071" ref-type="bibr">71</xref>], ice phenomena, stream temperatures [<xref rid="pone.0321008.ref037" ref-type="bibr">37</xref>], and runoff prediction [<xref rid="pone.0321008.ref010" ref-type="bibr">10</xref>].</p><p>The following outlines the general algorithm for XGBoost applied to regression tasks:</p><list list-type="simple"><list-item><p>i. Set <inline-formula id="pone.0321008.e019"><alternatives><graphic xlink:href="pone.0321008.e019.jpg" id="pone.0321008.e019g" position="anchor"/><mml:math id="e019" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0321008.e020"><alternatives><graphic xlink:href="pone.0321008.e020.jpg" id="pone.0321008.e020g" position="anchor"/><mml:math id="e020" display="inline" overflow="scroll"><mml:mrow><mml:mo>&#x02192;</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi mathvariant="fraktur">i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>
<inline-formula id="pone.0321008.e021"><alternatives><graphic xlink:href="pone.0321008.e021.jpg" id="pone.0321008.e021g" position="anchor"/><mml:math id="e021" display="inline" overflow="scroll"><mml:mrow><mml:mo>&#x02200;</mml:mo></mml:mrow></mml:math></alternatives></inline-formula><italic toggle="yes">i</italic> in the training set (X, y).</p></list-item><list-item><p>ii. For T = 1: N</p></list-item><list-item><p>1. Development of cost function</p></list-item></list><disp-formula id="pone.0321008.e022">
<alternatives><graphic xlink:href="pone.0321008.e022.jpg" id="pone.0321008.e022g" position="anchor"/><mml:math id="e022" display="block" overflow="scroll"><mml:mrow><mml:mi>O</mml:mi><mml:mi>b</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mfenced><mml:mi>T</mml:mi></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mfenced><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x003a9;</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
<label>(6)</label>
</disp-formula><list list-type="order"><list-item><p>Train a decision tree (<inline-formula id="pone.0321008.e023"><alternatives><graphic xlink:href="pone.0321008.e023.jpg" id="pone.0321008.e023g" position="anchor"/><mml:math id="e023" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) to minimize the objective function (<inline-formula id="pone.0321008.e024"><alternatives><graphic xlink:href="pone.0321008.e024.jpg" id="pone.0321008.e024g" position="anchor"/><mml:math id="e024" display="inline" overflow="scroll"><mml:mrow><mml:mi>O</mml:mi><mml:mi>b</mml:mi><mml:msup><mml:mi>j</mml:mi><mml:mrow><mml:mfenced><mml:mi>T</mml:mi></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>) on the training data (X, R)</p></list-item><list-item><p>Update <italic toggle="yes">O</italic> by incorporating a new tree, scaled by the shrinkage factor <italic toggle="yes">&#x003b3;</italic>.</p></list-item></list><p><inline-formula id="pone.0321008.e027"><alternatives><graphic xlink:href="pone.0321008.e027.jpg" id="pone.0321008.e027g" position="anchor"/><mml:math id="e027" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula><inline-formula id="pone.0321008.e028"><alternatives><graphic xlink:href="pone.0321008.e028.jpg" id="pone.0321008.e028g" position="anchor"/><mml:math id="e028" display="inline" overflow="scroll"><mml:mrow><mml:mo/><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>+ <inline-formula id="pone.0321008.e029"><alternatives><graphic xlink:href="pone.0321008.e029.jpg" id="pone.0321008.e029g" position="anchor"/><mml:math id="e029" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>(<italic toggle="yes">x</italic>) (7)</p><list list-type="order"><list-item><p>Residual update</p></list-item></list><disp-formula id="pone.0321008.e031">
<alternatives><graphic xlink:href="pone.0321008.e031.jpg" id="pone.0321008.e031g" position="anchor"/><mml:math id="e031" display="block" overflow="scroll"><mml:mrow><mml:mo/><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi mathvariant="fraktur">i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives>
<label>(8)</label>
</disp-formula><list list-type="simple"><list-item><p>iii. The resulting boosted model is</p></list-item></list><disp-formula id="pone.0321008.e032">
<alternatives><graphic xlink:href="pone.0321008.e032.jpg" id="pone.0321008.e032g" position="anchor"/><mml:math id="e032" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi mathvariant="fraktur">i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mi>&#x003b3;</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mfenced><mml:mi>x</mml:mi></mml:mfenced></mml:mrow></mml:math></alternatives>
<label>(9)</label>
</disp-formula><p>Where, <inline-formula id="pone.0321008.e033"><alternatives><graphic xlink:href="pone.0321008.e033.jpg" id="pone.0321008.e033g" position="anchor"/><mml:math id="e033" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#x003a9;</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives></inline-formula> = <inline-formula id="pone.0321008.e034"><alternatives><graphic xlink:href="pone.0321008.e034.jpg" id="pone.0321008.e034g" position="anchor"/><mml:math id="e034" display="inline" overflow="scroll"><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>+ <inline-formula id="pone.0321008.e035"><alternatives><graphic xlink:href="pone.0321008.e035.jpg" id="pone.0321008.e035g" position="anchor"/><mml:math id="e035" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>&#x00394;</mml:mi><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>I</mml:mi></mml:munderover><mml:msubsup><mml:mi>&#x003c9;</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, <italic toggle="yes">l</italic> represents a convex loss function, that quantifies the difference between the predicted (<inline-formula id="pone.0321008.e037"><alternatives><graphic xlink:href="pone.0321008.e037.jpg" id="pone.0321008.e037g" position="anchor"/><mml:math id="e037" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>O</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) and the target value (<inline-formula id="pone.0321008.e038"><alternatives><graphic xlink:href="pone.0321008.e038.jpg" id="pone.0321008.e038g" position="anchor"/><mml:math id="e038" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>), <inline-formula id="pone.0321008.e039"><alternatives><graphic xlink:href="pone.0321008.e039.jpg" id="pone.0321008.e039g" position="anchor"/><mml:math id="e039" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the Tth decision tree, <inline-formula id="pone.0321008.e040"><alternatives><graphic xlink:href="pone.0321008.e040.jpg" id="pone.0321008.e040g" position="anchor"/><mml:math id="e040" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mtext>x</mml:mtext><mml:mtext>i</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes the ith sample, R represents the residual, N and I represent the tree and leaf count, <inline-formula id="pone.0321008.e041"><alternatives><graphic xlink:href="pone.0321008.e041.jpg" id="pone.0321008.e041g" position="anchor"/><mml:math id="e041" display="inline" overflow="scroll"><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mo/><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo/><mml:mi>&#x00394;</mml:mi><mml:mo/></mml:mrow></mml:math></alternatives></inline-formula>are coefficients of regularization.</p></sec><sec id="sec007"><title>3.4 Model Construction</title><p>The monthly runoff in the Lotschental catchment, located in Switzerland, has been predicted using various AI-based models, including XGBoost, RF, and a deep learning algorithm called LSTM. This study utilized runoff data spanning twenty years, from January 2002 to December 2021. The majority of the data, constituting 70% and covering the years 2002&#x02013;2015, was employed for training the models and optimizing their calibrations (See <xref rid="pone.0321008.g005" ref-type="fig">Fig 5</xref>). The remaining data, approximately from 2016 to 2022, was reserved for testing the models&#x02019; accuracies.</p><fig position="float" id="pone.0321008.g005"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g005</object-id><label>Fig 5</label><caption><title>Modeling Process.</title></caption><graphic xlink:href="pone.0321008.g005" position="float"/></fig><p>To identify the most suitable input data, partial autocorrelation was employed for selecting the best input lags. This method provides valuable insights into the time series properties, including stationarity, trend patterns, seasonality, and randomness [<xref rid="pone.0321008.ref072" ref-type="bibr">72</xref>]. The partial autocorrelation function (PACF) analysis, depicted in <xref rid="pone.0321008.g006" ref-type="fig">Fig 6</xref> led to the establishment of three different input combinations, as illustrated in <xref rid="pone.0321008.t002" ref-type="table">Table 2</xref>.</p><table-wrap position="float" id="pone.0321008.t002"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.t002</object-id><label>Table 2</label><caption><title>The input combinations adopted for forecasting runoff.</title></caption><alternatives><graphic xlink:href="pone.0321008.t002" id="pone.0321008.t002g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Combinations</th><th align="left" rowspan="1" colspan="1">Input and output</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Comb1</td><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0321008.e042">
<alternatives><graphic xlink:href="pone.0321008.e042" id="pone.0321008.e042g" position="anchor"/><mml:math id="e042" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo/><mml:mi>f</mml:mi><mml:mfenced><mml:mrow><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo/></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
</inline-formula>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Comb2</td><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0321008.e043">
<alternatives><graphic xlink:href="pone.0321008.e043" id="pone.0321008.e043g" position="anchor"/><mml:math id="e043" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo/><mml:mi>f</mml:mi><mml:mfenced><mml:mrow><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo/><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>7</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
</inline-formula>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Comb3</td><td align="left" rowspan="1" colspan="1">
<inline-formula id="pone.0321008.e044">
<alternatives><graphic xlink:href="pone.0321008.e044" id="pone.0321008.e044g" position="anchor"/><mml:math id="e044" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo/><mml:mi>f</mml:mi><mml:mfenced><mml:mrow><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo/><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>7</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>8</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>11</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>12</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mo/><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
</inline-formula>
</td></tr></tbody></table></alternatives></table-wrap><fig position="float" id="pone.0321008.g006"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g006</object-id><label>Fig 6</label><caption><title>Partial autocorrelation function for selecting the best lag runoff values.</title></caption><graphic xlink:href="pone.0321008.g006" position="float"/></fig></sec><sec id="sec008"><title>3.5 Statistical metrics</title><p>In this research, various statistical metrics commonly employed in the hydrological field were used to evaluate the forecasting reliability of each model [<xref rid="pone.0321008.ref073" ref-type="bibr">73</xref>]. These metrics include root mean square error (<italic toggle="yes">RMSE</italic>), mean absolute error (<italic toggle="yes">MAE</italic>), correlation coefficient and determination (<italic toggle="yes">R</italic>, and <italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup>), Maximum absolute relative error (<italic toggle="yes">erMAX</italic>), Nash-Sutcliffe efficiency index (<italic toggle="yes">NSE</italic>), Willmot index (<italic toggle="yes">d</italic>), and uncertainty at a 95% confidence interval (<italic toggle="yes">U</italic><sub><italic toggle="yes">95</italic></sub>) [<xref rid="pone.0321008.ref074" ref-type="bibr">74</xref>]. Also, the current research used a combined accuracy (<italic toggle="yes">CA</italic>) [<xref rid="pone.0321008.ref075" ref-type="bibr">75</xref>,<xref rid="pone.0321008.ref076" ref-type="bibr">76</xref>] which considered as efficient and global metrics, taking advantages of both error, and accuracy metrics. The mathematical equations for these metrics are provided in the following equations [<xref rid="pone.0321008.ref077" ref-type="bibr">77</xref>,<xref rid="pone.0321008.ref078" ref-type="bibr">78</xref>]:</p><disp-formula id="pone.0321008.e045">
<alternatives><graphic xlink:href="pone.0321008.e045.jpg" id="pone.0321008.e045g" position="anchor"/><mml:math id="e045" display="block" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo/><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo/></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives>
<label>(10)</label>
</disp-formula><disp-formula id="pone.0321008.e046">
<alternatives><graphic xlink:href="pone.0321008.e046.jpg" id="pone.0321008.e046g" position="anchor"/><mml:math id="e046" display="block" overflow="scroll"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives>
<label>(11)</label>
</disp-formula><disp-formula id="pone.0321008.e047">
<alternatives><graphic xlink:href="pone.0321008.e047.jpg" id="pone.0321008.e047g" position="anchor"/><mml:math id="e047" display="block" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo/></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives>
<label>(12)</label>
</disp-formula><disp-formula id="pone.0321008.e048">
<alternatives><graphic xlink:href="pone.0321008.e048.jpg" id="pone.0321008.e048g" position="anchor"/><mml:math id="e048" display="block" overflow="scroll"><mml:mrow><mml:mi>W</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mo/><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo/><mml:mo/><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mo/><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo/><mml:mo/></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives>
<label>(13)</label>
</disp-formula><disp-formula id="pone.0321008.e049">
<alternatives><graphic xlink:href="pone.0321008.e049.jpg" id="pone.0321008.e049g" position="anchor"/><mml:math id="e049" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo/></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives>
<label>(14)</label>
</disp-formula><disp-formula id="pone.0321008.e050">
<alternatives><graphic xlink:href="pone.0321008.e050.jpg" id="pone.0321008.e050g" position="anchor"/><mml:math id="e050" display="block" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="]" open="["><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mfenced><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo/><mml:mo/><mml:mo/><mml:mo/></mml:mrow></mml:msqrt><mml:mo/><mml:mo/><mml:mo/></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives>
<label>(15)</label>
</disp-formula><disp-formula id="pone.0321008.e051">
<alternatives><graphic xlink:href="pone.0321008.e051.jpg" id="pone.0321008.e051g" position="anchor"/><mml:math id="e051" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mn>95</mml:mn></mml:mrow></mml:msub><mml:mo/><mml:mo>=</mml:mo><mml:mo/><mml:mfrac><mml:mrow><mml:mn>1.96</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:msqrt><mml:mrow><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mfenced><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo/><mml:mo>+</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo/></mml:mrow></mml:msqrt><mml:mo/></mml:mrow></mml:math></alternatives>
<label>(16)</label>
</disp-formula><disp-formula id="pone.0321008.e052">
<alternatives><graphic xlink:href="pone.0321008.e052.jpg" id="pone.0321008.e052g" position="anchor"/><mml:math id="e052" display="block" overflow="scroll"><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo/><mml:mo>=</mml:mo><mml:mo/><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced><mml:mrow><mml:mfrac><mml:mrow><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
<label>(17)</label>
</disp-formula><disp-formula id="pone.0321008.e053">
<alternatives><graphic xlink:href="pone.0321008.e053.jpg" id="pone.0321008.e053g" position="anchor"/><mml:math id="e053" display="block" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>0.33</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mfenced><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>+</mml:mo><mml:mfenced><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
<label>(18)</label>
</disp-formula><p>Where for this study, <inline-formula id="pone.0321008.e054"><alternatives><graphic xlink:href="pone.0321008.e054.jpg" id="pone.0321008.e054g" position="anchor"/><mml:math id="e054" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0321008.e055"><alternatives><graphic xlink:href="pone.0321008.e055.jpg" id="pone.0321008.e055g" position="anchor"/><mml:math id="e055" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are the observed runoff at <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> data point and forecasted monthly runoff (Q), <italic toggle="yes">n</italic> is the total data points. The means of observed and forecasted Q values are respectively, <inline-formula id="pone.0321008.e056"><alternatives><graphic xlink:href="pone.0321008.e056.jpg" id="pone.0321008.e056g" position="anchor"/><mml:math id="e056" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0321008.e057"><alternatives><graphic xlink:href="pone.0321008.e057.jpg" id="pone.0321008.e057g" position="anchor"/><mml:math id="e057" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>.</p></sec><sec id="sec009"><title>3.6 Turning points in monthly runoff time series data</title><p>Turning points are essential in time series analysis as they indicate significant changes in the data&#x02019;s trend or direction. They mark transitions from one phase to another, highlighting shifts in behavior, growth, or decline within the dataset. These points provide critical insights into major events, changes in underlying processes, and the rise of new trends. Identifying turning points, such as peaks, troughs, cycles, and anomalies, is crucial for decision-making. Since time series data exhibit substantial autocorrelation (See <xref rid="pone.0321008.g006" ref-type="fig">Fig 6</xref>), forecasting models often achieve high accuracy (<italic toggle="yes">R</italic> &#x0003e; 0.9) [<xref rid="pone.0321008.ref079" ref-type="bibr">79</xref>] and low forecasting errors, according to metrics like <italic toggle="yes">RMSE</italic> and <italic toggle="yes">MAE</italic> [<xref rid="pone.0321008.ref080" ref-type="bibr">80</xref>]. However, special attention should be devoted to accuracy, specifically at turning points when evaluating forecasting models.</p><p>This study employed the Average Absolute Error of Turning Points (<italic toggle="yes">AAETP</italic>) to assess the accuracy of forecasting models in predicting turning points within a runoff dataset. The <italic toggle="yes">AAETP</italic> is a performance metric that can be used in time series analysis, focusing on the models&#x02019; abilities to replicate significant shifts and turning points in the data. To identify turning points, the first and second derivatives of the original time series data were computed. The first derivative captures the rate of change or slope of the data, while the second derivative identifies the points where the sign of the first derivative changes, indicating turning points. By comparing the forecasted monthly runoff values with the actual observed values at the identified turning points, the average absolute difference was calculated independently for each model. For more details, please refer to [<xref rid="pone.0321008.ref063" ref-type="bibr">63</xref>] where the mathematical equation for <italic toggle="yes">AAETP</italic> can be found in Equation 18. The analysis of error magnitudes specifically at turning points provides valuable insights into the models&#x02019; ability to accurately capture data shifts and transitions, thereby improving the assessment of their overall forecasting capabilities.</p><disp-formula id="pone.0321008.e058">
<alternatives><graphic xlink:href="pone.0321008.e058.jpg" id="pone.0321008.e058g" position="anchor"/><mml:math id="e058" display="block" overflow="scroll"><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mtext/><mml:mo>=</mml:mo><mml:mtext>average </mml:mtext><mml:mfenced><mml:mrow><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives>
<label>(18)</label>
</disp-formula><p>Where, <italic toggle="yes">E</italic><sub><italic toggle="yes">i</italic></sub> represents the forecasting error for turning points. It is computed by subtracting the forecasted values of the critical points from their corresponding actual runoff values.</p><p>The theoretical optimum value for <italic toggle="yes">AAETP</italic> is zero, indicating that the model perfectly captures turning points. However, in practice, achieving a value of zero is very difficult. Therefore, it is essential to identify the minimum values that are closest to zero when comparing models. These values serve as indicators of the most effective models, facilitating a more reliable evaluation of how well they capture turning points</p></sec></sec><sec id="sec010"><title>4 .&#x02002;Results and discussion</title><sec id="sec011"><title>4.1 Forecasting runoff using AI-based models</title><p>This study aimed to develop runoff forecasting models for the Lotschental catchment for one-month ahead timescale through three particular techniques Random Forest (RF), Long short-term Memory (LSTM), and XGBoost. In order to determine the optimal number of input lags, a backward selection strategy called Partial Autocorrelation Function (PACF) was applied. This resulted in three different sets of input variables. During the training stage, rigorous evaluation of each model employed several statistical measures such as Mean Absolute error (<italic toggle="yes">MAE</italic>), Root Mean Square Error (<italic toggle="yes">RMSE</italic>), Willmot index (<italic toggle="yes">d</italic>), Correlation Coefficient (<italic toggle="yes">R</italic>), Maximum absolute relative error (<italic toggle="yes">erMAX</italic>) and Nash-Sutcliffe efficiency index (<italic toggle="yes">NSE</italic>), and Combined accuracy(<italic toggle="yes">CA</italic>) to represent forecasting of models, error measurement and the degree of correlation and proportion of variance between the independent variables and the dependent variable respectively (refer to <xref rid="pone.0321008.t003" ref-type="table">Table 3</xref>). These parameters played a key role in assessing the relative performance of the models in predicting runoff for Lotschental catchment</p><table-wrap position="float" id="pone.0321008.t003"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.t003</object-id><label>Table 3</label><caption><title>Evaluating the performance of each model using different statistical metrics in the training phase.</title></caption><alternatives><graphic xlink:href="pone.0321008.t003" id="pone.0321008.t003g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Combinations</th><th align="left" rowspan="1" colspan="1">Models</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">RMSE</italic> m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">MAE</italic> m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">erMax</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">d</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">NSE</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">R</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">CA</italic>
</th></tr></thead><tbody><tr><td align="left" rowspan="3" colspan="1">Comb1</td><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="left" rowspan="1" colspan="1">1.302</td><td align="left" rowspan="1" colspan="1">0.937</td><td align="left" rowspan="1" colspan="1">3.645</td><td align="left" rowspan="1" colspan="1">0.979</td><td align="left" rowspan="1" colspan="1">0.767</td><td align="left" rowspan="1" colspan="1">0.960</td><td align="left" rowspan="1" colspan="1">0.772</td></tr><tr><td align="left" rowspan="1" colspan="1">LSTM</td><td align="left" rowspan="1" colspan="1">1.736</td><td align="left" rowspan="1" colspan="1">1.357</td><td align="left" rowspan="1" colspan="1">3.824</td><td align="left" rowspan="1" colspan="1">0.960</td><td align="left" rowspan="1" colspan="1">0.663</td><td align="left" rowspan="1" colspan="1">0.931</td><td align="left" rowspan="1" colspan="1">1.074</td></tr><tr><td align="left" rowspan="1" colspan="1">RF</td><td align="left" rowspan="1" colspan="1">1.185</td><td align="left" rowspan="1" colspan="1">0.727</td><td align="left" rowspan="1" colspan="1">2.187</td><td align="left" rowspan="1" colspan="1">0.983</td><td align="left" rowspan="1" colspan="1">0.819</td><td align="left" rowspan="1" colspan="1">0.967</td><td align="left" rowspan="1" colspan="1">0.658</td></tr><tr><td align="left" rowspan="3" colspan="1">Comb2</td><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="left" rowspan="1" colspan="1">1.157</td><td align="left" rowspan="1" colspan="1">0.752</td><td align="left" rowspan="1" colspan="1">2.309</td><td align="left" rowspan="1" colspan="1">0.984</td><td align="left" rowspan="1" colspan="1">0.810</td><td align="left" rowspan="1" colspan="1">0.968</td><td align="left" rowspan="1" colspan="1">0.657</td></tr><tr><td align="left" rowspan="1" colspan="1">LSTM</td><td align="left" rowspan="1" colspan="1">1.296</td><td align="left" rowspan="1" colspan="1">0.784</td><td align="left" rowspan="1" colspan="1">0.965</td><td align="left" rowspan="1" colspan="1">0.979</td><td align="left" rowspan="1" colspan="1">0.802</td><td align="left" rowspan="1" colspan="1">0.959</td><td align="left" rowspan="1" colspan="1">0.719</td></tr><tr><td align="left" rowspan="1" colspan="1">RF</td><td align="left" rowspan="1" colspan="1">1.054</td><td align="left" rowspan="1" colspan="1">0.613</td><td align="left" rowspan="1" colspan="1">2.113</td><td align="left" rowspan="1" colspan="1">0.986</td><td align="left" rowspan="1" colspan="1">0.845</td><td align="left" rowspan="1" colspan="1">0.974</td><td align="left" rowspan="1" colspan="1">0.572</td></tr><tr><td align="left" rowspan="3" colspan="1">Comb3</td><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="left" rowspan="1" colspan="1">1.156</td><td align="left" rowspan="1" colspan="1">0.776</td><td align="left" rowspan="1" colspan="1">1.142</td><td align="left" rowspan="1" colspan="1">0.984</td><td align="left" rowspan="1" colspan="1">0.806</td><td align="left" rowspan="1" colspan="1">0.968</td><td align="left" rowspan="1" colspan="1">0.664</td></tr><tr><td align="left" rowspan="1" colspan="1">LSTM</td><td align="left" rowspan="1" colspan="1">1.295</td><td align="left" rowspan="1" colspan="1">0.821</td><td align="left" rowspan="1" colspan="1">0.860</td><td align="left" rowspan="1" colspan="1">0.978</td><td align="left" rowspan="1" colspan="1">0.794</td><td align="left" rowspan="1" colspan="1">0.961</td><td align="left" rowspan="1" colspan="1">0.730</td></tr><tr><td align="left" rowspan="1" colspan="1">RF</td><td align="left" rowspan="1" colspan="1">0.993</td><td align="left" rowspan="1" colspan="1">0.582</td><td align="left" rowspan="1" colspan="1">1.638</td><td align="left" rowspan="1" colspan="1">0.988</td><td align="left" rowspan="1" colspan="1">0.854</td><td align="left" rowspan="1" colspan="1">0.977</td><td align="left" rowspan="1" colspan="1">0.540</td></tr></tbody></table></alternatives></table-wrap><p>This study utilized three forecasting models (RF, LSTM, and XGBoost) to forecast runoff one month ahead for Lotschental catchment. The input lags were selected using PACF, resulting in three different combinations. The performance of each forecasting model during the training phase was evaluated using various statistical metrics (refer to <xref rid="pone.0321008.t003" ref-type="table">Table 3</xref>).</p><p>The results demonstrated that all the models exhibited good forecasting accuracy, with the second and third combinations appearing to be more suitable, although the second combination shows a lower forecasting error. For example, XGBoost presented a higher <italic toggle="yes">MAE</italic> of 0.937 m<sup>3</sup>/sec in Comb1, whereas this value was reduced to 0.752 m<sup>3</sup>/sec and 0.776 m<sup>3</sup>/sec in Comb2 and Comb3, respectively. Similarly, for LSTM, the <italic toggle="yes">MAE</italic> values for the three combinations were 1.357 m<sup>3</sup>/sec, 0.784 m<sup>3</sup>/sec, and 0.821 m<sup>3</sup>/sec during the training phase. RF, on the other hand, exhibited slightly better performance than XGBoost across all three combinations, with lower <italic toggle="yes">MAE</italic> values of 0.727 m<sup>3</sup>/sec, 0.613 m<sup>3</sup>/sec, and 0.582 m<sup>3</sup>/sec.</p><p>with lowest <italic toggle="yes">MAE</italic> and <italic toggle="yes">CA</italic> values of 0.727 m<sup>3</sup>/sec, 0.613 m<sup>3</sup>/sec, and 0.582 m&#x000b3;/sec, and 0.658, 0.572, and 0.540, respectively. However, XGBoost and RF showed similar accuracy parameters, such as <italic toggle="yes">R</italic>, during the training phase. It&#x02019;s important to note that the training phase alone is not crucial for selecting the best model since the models are trained with available input and output runoff data. The testing phase, where the model is only provided with input data, determines the generalization capacity and efficiency of the model.</p><p>The hyperparameters of the applied models are selected using a trial-and-error method, with the objective function being <italic toggle="yes">RMSE</italic>. The models are trained on calibration data, and hyperparameters are chosen based on their performance in reducing <italic toggle="yes">RMSE</italic>. For example, the LSTM model is very sensitive to hidden units and dropout values, with hidden units ranging from 15 to 35 and dropout rates from 0.09 to 0.2. In the RF model, sensitivity was noted regarding the number of trees, with the optimum found to be 18 and the minimum number of samples required at a leaf node set at 5. Finally, for the XGBoost model, the best learning rate was determined to be 0.15, while the maximum tree depth was set to 7. <xref rid="pone.0321008.s002" ref-type="supplementary-material">S2 Table</xref> presents the hyperparameters for all models. Notably, the hyperparameters for each forecasting model used to forecast monthly runoff are listed in the S Appendix (<xref rid="pone.0321008.s002" ref-type="supplementary-material">S2 Table</xref>).</p><p><xref rid="pone.0321008.t004" ref-type="table">Table 4</xref> presents the performance of the forecasting models during the testing phase. Based on statistical parameters, the combination labeled Comb2, which involves seven previous runoff lags, exhibits the most favorable scenario for forecasting models. Within this particular scenario, XGBoost demonstrates superior performance compared to the other models, yielding the lowest values for <italic toggle="yes">RMSE</italic> (1.554 m<sup>3</sup>/sec), <italic toggle="yes">MAE</italic> (0.976 m<sup>3</sup>/sec), <italic toggle="yes">erMax</italic> (1.080), and <italic toggle="yes">CA</italic> (0.871), as well as the highest values for <italic toggle="yes">d</italic> (0.972), <italic toggle="yes">NSE</italic> (0.797), and <italic toggle="yes">R</italic> (0.956). Additionally, the XGBoost model achieves higher prediction accuracy by reducing <italic toggle="yes">RMSE</italic> by 14.57% and 17.03% compared to the LSTM and RF models, respectively. Overall, the statistical results from <xref rid="pone.0321008.t003" ref-type="table">Tables 3</xref> and <xref rid="pone.0321008.t004" ref-type="table">4</xref> indicate that the XGBoost model outperformed the other models for all three experimental combinations. The model was the one to have the best performance metrics throughout, followed by the LSTM network and the Random Forest (RF) model, which presented relatively below-par performance. It is important to note that the RF model is prone to overfitting, as it demonstrates excellent forecasting performance during the training phase but performs less effectively during the testing phase. These findings underscore the efficiency of XGBoost in forecasting runoff and its superior generalization capacity when compared to LSTM and RF.</p><table-wrap position="float" id="pone.0321008.t004"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.t004</object-id><label>Table 4</label><caption><title>Evaluating the performance of each model using different statistical metrics in the Testing phase.</title></caption><alternatives><graphic xlink:href="pone.0321008.t004" id="pone.0321008.t004g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Combinations</th><th align="left" rowspan="1" colspan="1">Models</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">RMSE</italic> m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1"><italic toggle="yes">MAE</italic> m<sup>3</sup>/sec</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">erMax</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">d</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">NSE</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">R</italic>
</th><th align="left" rowspan="1" colspan="1">
<italic toggle="yes">CA</italic>
</th></tr></thead><tbody><tr><td align="left" rowspan="3" colspan="1">Comb1</td><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="left" rowspan="1" colspan="1">2.032</td><td align="left" rowspan="1" colspan="1">1.252</td><td align="left" rowspan="1" colspan="1">2.938</td><td align="left" rowspan="1" colspan="1">0.951</td><td align="left" rowspan="1" colspan="1">0.713</td><td align="left" rowspan="1" colspan="1">0.916</td><td align="left" rowspan="1" colspan="1">1.147</td></tr><tr><td align="left" rowspan="1" colspan="1">LSTM</td><td align="left" rowspan="1" colspan="1">2.426</td><td align="left" rowspan="1" colspan="1">1.560</td><td align="left" rowspan="1" colspan="1">4.359</td><td align="left" rowspan="1" colspan="1">0.927</td><td align="left" rowspan="1" colspan="1">0.642</td><td align="left" rowspan="1" colspan="1">0.876</td><td align="left" rowspan="1" colspan="1">1.405</td></tr><tr><td align="left" rowspan="1" colspan="1">RF</td><td align="left" rowspan="1" colspan="1">2.823</td><td align="left" rowspan="1" colspan="1">1.351</td><td align="left" rowspan="1" colspan="1">2.094</td><td align="left" rowspan="1" colspan="1">0.899</td><td align="left" rowspan="1" colspan="1">0.690</td><td align="left" rowspan="1" colspan="1">0.835</td><td align="left" rowspan="1" colspan="1">1.491</td></tr><tr><td align="left" rowspan="3" colspan="1">Comb2</td><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="left" rowspan="1" colspan="1">1.554</td><td align="left" rowspan="1" colspan="1">0.976</td><td align="left" rowspan="1" colspan="1">1.080</td><td align="left" rowspan="1" colspan="1">0.972</td><td align="left" rowspan="1" colspan="1">0.797</td><td align="left" rowspan="1" colspan="1">0.956</td><td align="left" rowspan="1" colspan="1">0.871</td></tr><tr><td align="left" rowspan="1" colspan="1">LSTM</td><td align="left" rowspan="1" colspan="1">1.819</td><td align="left" rowspan="1" colspan="1">1.065</td><td align="left" rowspan="1" colspan="1">1.479</td><td align="left" rowspan="1" colspan="1">0.962</td><td align="left" rowspan="1" colspan="1">0.757</td><td align="left" rowspan="1" colspan="1">0.945</td><td align="left" rowspan="1" colspan="1">0.996</td></tr><tr><td align="left" rowspan="1" colspan="1">RF</td><td align="left" rowspan="1" colspan="1">1.873</td><td align="left" rowspan="1" colspan="1">1.063</td><td align="left" rowspan="1" colspan="1">2.725</td><td align="left" rowspan="1" colspan="1">0.957</td><td align="left" rowspan="1" colspan="1">0.737</td><td align="left" rowspan="1" colspan="1">0.925</td><td align="left" rowspan="1" colspan="1">1.026</td></tr><tr><td align="left" rowspan="3" colspan="1">Comb3</td><td align="left" rowspan="1" colspan="1">XGBoost</td><td align="left" rowspan="1" colspan="1">1.677</td><td align="left" rowspan="1" colspan="1">1.082</td><td align="left" rowspan="1" colspan="1">1.167</td><td align="left" rowspan="1" colspan="1">0.969</td><td align="left" rowspan="1" colspan="1">0.755</td><td align="left" rowspan="1" colspan="1">0.945</td><td align="left" rowspan="1" colspan="1">0.954</td></tr><tr><td align="left" rowspan="1" colspan="1">LSTM</td><td align="left" rowspan="1" colspan="1">1.769</td><td align="left" rowspan="1" colspan="1">1.107</td><td align="left" rowspan="1" colspan="1">1.704</td><td align="left" rowspan="1" colspan="1">0.961</td><td align="left" rowspan="1" colspan="1">0.750</td><td align="left" rowspan="1" colspan="1">0.942</td><td align="left" rowspan="1" colspan="1">0.995</td></tr><tr><td align="left" rowspan="1" colspan="1">RF</td><td align="left" rowspan="1" colspan="1">1.945</td><td align="left" rowspan="1" colspan="1">1.155</td><td align="left" rowspan="1" colspan="1">2.765</td><td align="left" rowspan="1" colspan="1">0.947</td><td align="left" rowspan="1" colspan="1">0.729</td><td align="left" rowspan="1" colspan="1">0.925</td><td align="left" rowspan="1" colspan="1">1.080</td></tr></tbody></table></alternatives></table-wrap><p>To comprehensively assess the predictive accuracy of the applied model, it is vital to verify its generalization capacity and accuracy in forecasting runoff across different seasons. Such evaluation provides further insights into how a model performs in each season, allowing us to understand the significant differences in model performance under varying conditions. According to <xref rid="pone.0321008.t005" ref-type="table">Table 5</xref>, XGBoost is the best performing model, offering predicted values that closely align with those measured over the seasonal period. Notably, XGBoost delivers the highest forecasting accuracy during the summer months (July to September). Additionally, the other models demonstrate very good forecasting accuracy from July to September. XGBoost has the lowest overall relative percentage error (4.15%), followed by LSTM (6.16%), while RF generates the lowest accuracy (7.07%).</p><table-wrap position="float" id="pone.0321008.t005"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.t005</object-id><label>Table 5</label><caption><title>Performance of predictive models for seasonal runoff forecasting.</title></caption><alternatives><graphic xlink:href="pone.0321008.t005" id="pone.0321008.t005g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Seasons</th><th align="left" rowspan="1" colspan="1">Observed (m<sup>3</sup>/sec)</th><th align="left" rowspan="1" colspan="1">XGBoost (m<sup>3</sup>/sec)</th><th align="left" rowspan="1" colspan="1">LSTM (m<sup>3</sup>/sec)</th><th align="left" rowspan="1" colspan="1">RF (m<sup>3</sup>/sec)</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">April to June</td><td align="left" rowspan="1" colspan="1">6.8620</td><td align="left" rowspan="1" colspan="1">6.5370</td><td align="left" rowspan="1" colspan="1">6.3467</td><td align="left" rowspan="1" colspan="1">6.1522</td></tr><tr><td align="left" rowspan="1" colspan="1">July to September</td><td align="left" rowspan="1" colspan="1">10.3389</td><td align="left" rowspan="1" colspan="1">10.0101</td><td align="left" rowspan="1" colspan="1">9.9042</td><td align="left" rowspan="1" colspan="1">9.5184</td></tr><tr><td align="left" rowspan="1" colspan="1">October to November</td><td align="left" rowspan="1" colspan="1">1.5456</td><td align="left" rowspan="1" colspan="1">1.4215</td><td align="left" rowspan="1" colspan="1">1.3412</td><td align="left" rowspan="1" colspan="1">1.7501</td></tr><tr><td align="left" rowspan="1" colspan="1">Overall</td><td align="left" rowspan="1" colspan="1">6.2488</td><td align="left" rowspan="1" colspan="1">5.9895</td><td align="left" rowspan="1" colspan="1">5.8640</td><td align="left" rowspan="1" colspan="1">5.8069</td></tr><tr><td align="left" colspan="2" rowspan="1">Overall relative percentage error %</td><td align="left" rowspan="1" colspan="1">4.15</td><td align="left" rowspan="1" colspan="1">6.16</td><td align="left" rowspan="1" colspan="1">7.07</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec012"><title>4.2 Graphical assessment</title><p>This chapter aims to visually demonstrate the effectiveness of each model in simulating the runoff time series data for each month. The line graph presented in <xref rid="pone.0321008.g007" ref-type="fig">Fig 7(a</xref>, <xref rid="pone.0321008.g007" ref-type="fig">b</xref>, <xref rid="pone.0321008.g007" ref-type="fig">c</xref>) illustrates that, in general, the models have successfully forecasted the runoff from May 2016 to approximately March 2019, capturing the overall pattern of the measured values. However, during this period, only the RF model exhibits relatively poorer forecast performance in terms of peak values (refer to <xref rid="pone.0321008.g006" ref-type="fig">Fig 6c</xref>).</p><fig position="float" id="pone.0321008.g007"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g007</object-id><label>Fig 7</label><caption><title>Line graph and Scatter plots comparing measured monthly runoff and forecasted values.</title><p>Panels a) XGBoost (Line Graph), a1) XGBoost (scatter Plot), b) LSTM (Line Graph), b1) LSTM (Scatter Plot), c) RF (Line Graph), c1) RF (Scatter Plot).</p></caption><graphic xlink:href="pone.0321008.g007" position="float"/></fig><p>From March 2019 to December 2021, the efficiency of the models varies significantly due to the presence of several peak points and substantial changes in the time series data. The XGBoost model demonstrates the closest fit to the measured values, with its forecasted values closely aligning with the measured values throughout the time series, particularly during peak points. Similarly, the LSTM model shows a good fit, with its forecasted values generally following the measured values, although there are some instances where slight deviations occur (refer to <xref rid="pone.0321008.g006" ref-type="fig">Fig 6b</xref>). On the other hand, the RF model exhibits a slightly wider range of forecasted values compared to the other two models, suggesting that it is less precise in its forecasts (refer to <xref rid="pone.0321008.g007" ref-type="fig">Fig 7c</xref>). According to the figure, the highest positive peak value is 16.887 m&#x000b3;/sec, which is simulated very well by XGBoost and LSTM, with predicted values of 15.8861 m&#x000b3;/sec and 15.4421 m&#x000b3;/sec, respectively. However, RF exhibits lower prediction performance for these peak points, with a value of 15.3793 m&#x000b3;/sec. With regard to the lowest runoff point, which is measured at 0.444 m&#x000b3;/sec, only XGBoost simulates this point with reasonable accuracy at 0.6851 m&#x000b3;/sec, while the other models generate values ranging from 1 m&#x000b3;/sec to 1.68 m&#x000b3;/sec. The accurate simulation of both maximum and minimum runoff points demonstrates the adaptability of the XGBoost model in providing reliable forecasts under varying hydrological conditions, including both drought and flood events.</p><p>The scatter plots in <xref rid="pone.0321008.g006" ref-type="fig">Fig 6</xref> a1, b1, and c1 illustrate the relationship between measured runoff and the forecasted values from the models in Comb2. The scatter plot for XGBoost (<xref rid="pone.0321008.g007" ref-type="fig">Fig 7</xref> a1) demonstrates a strong positive correlation with a tight clustering of data points around the diagonal line, indicating accurate predictions (<italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup> = 0.901). The LSTM plot (<xref rid="pone.0321008.g006" ref-type="fig">Fig 6b1</xref>) shows slightly more spread data points compared to XGBoost but less than RF, suggesting some errors in predictions (<italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup> = 0.869). Similarly, the RF plot ((<xref rid="pone.0321008.g006" ref-type="fig">Fig 6</xref> c1) exhibits a wider spread of data points, indicating deviations from the actual values (<italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup> = 0.861). Overall, The XGBoost model is the best-performing model, followed by LSTM and then RF.</p><p>Based on the results displayed in <xref rid="pone.0321008.g008" ref-type="fig">Fig 8</xref>, which presents the seasonal performance of each model, it is evident that all models exhibit varying accuracy across seasons, reflecting fluctuations in the runoff pattern over time. Overall, XGBoost demonstrates strong performance throughout all three seasonal periods, yielding the lowest absolute residuals of 0.325 m<sup>3</sup>/sec, 0.3288 m<sup>3</sup>/sec, and 0.1241 m<sup>3</sup>/sec, respectively. Notably, during the period from April to June, XGBoost consistently outperforms the other models. Overall, XGBoost consistently demonstrates the highest accuracy in modeling seasonal runoff patterns and effectively captures variations across various time periods.</p><fig position="float" id="pone.0321008.g008"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g008</object-id><label>Fig 8</label><caption><title>Absolute residual errors showing seasonal variation in model performance.</title></caption><graphic xlink:href="pone.0321008.g008" position="float"/></fig><p>A violin plot represents the distribution of numerical data across one or more groups through density curves. The width of each curve indicates the relative frequency of data points within specific intervals. As depicted in <xref rid="pone.0321008.g009" ref-type="fig">Fig 9</xref>, violin plot has been employed to facilitate a comprehensive comparison between the measured runoff and the forecasted runoff obtained from the applied models. In general, all models capture the overall trend and distribution of the runoff data. However, variations among the models become evident, particularly in the peak points. Notably, XGBoost demonstrates favorable forecasting performance for the peak runoff points when compared to the LSTM and RF models.</p><fig position="float" id="pone.0321008.g009"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g009</object-id><label>Fig 9</label><caption><title>Violin plot illustrating the comparison between observed and simulated Runoff.</title></caption><graphic xlink:href="pone.0321008.g009" position="float"/></fig><p>Moreover, the Taylor diagram has been used as a valuable tool to identify the most efficient model. These plots are mathematical constructs that graphically illustrate the relative accuracy of various model representations of a system, process, or phenomenon. The diagrams facilitate comparative analyses and provide a comprehensive visualization by summarizing the correlation, standard deviation ratio, and root mean square difference between the reference dataset (measured runoff) and multiple model simulations in a single plot. <xref rid="pone.0321008.g010" ref-type="fig">Fig 10</xref> demonstrates that XGBoost exhibits the closest proximity to the reference points (measured runoff), followed by the LSTM and RF models. Finally, uncertainty analysis, specifically in terms of <italic toggle="yes">U</italic><sub><italic toggle="yes">95</italic></sub>, was performed to determine which model produces the least uncertainty. According to <xref rid="pone.0321008.g011" ref-type="fig">Fig 11</xref>, XGBoost demonstrates the lowest <italic toggle="yes">U</italic><sub><italic toggle="yes">95</italic></sub> value of 1.231, which is lower than LSTM with 1.251 and RF with 1.259. Overall, the analysis of the Taylor plot, violin plot, and <italic toggle="yes">U</italic><sub><italic toggle="yes">95</italic></sub> indicates that XGBoost is the most effective model for predicting monthly runoff in the study area, demonstrating the lowest level of uncertainty.</p><fig position="float" id="pone.0321008.g010"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g010</object-id><label>Fig 10</label><caption><title>Taylor diagram for visual comparisons among comparable models.</title></caption><graphic xlink:href="pone.0321008.g010" position="float"/></fig><fig position="float" id="pone.0321008.g011"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g011</object-id><label>Fig 11</label><caption><title>Evaluating model performance in the testing phase: a comparative analysis based on <italic toggle="yes">U</italic><sub><italic toggle="yes">95</italic></sub> indicator.</title></caption><graphic xlink:href="pone.0321008.g011" position="float"/></fig></sec><sec id="sec013"><title>4.3 Analyzing forecasting models with turning point detection</title><p>This section of the paper focused on the assessment focused on the applied model&#x02019;s efficiency in detecting runoff turning points. <xref rid="pone.0321008.g012" ref-type="fig">Fig 12a</xref> visually depicts how the algorithm identifies turning points in the time series runoff data. The graph illustrates a cyclical pattern in the time series runoff data, with clearly defined peaks and valleys. The turning points denoted on the graph highlight substantial changes in the data. It is important to note that the graph enables an assessment of the accuracy of the applied models in predicting these critical turning points.</p><fig position="float" id="pone.0321008.g012"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g012</object-id><label>Fig 12</label><caption><title>Monthly runoff turning point detection:</title><p>a) illustration of the algorithm&#x02019;s capability in detecting turning points in the runoff time series data. b) calculated results of <italic toggle="yes">AAETP</italic>.</p></caption><graphic xlink:href="pone.0321008.g012" position="float"/></fig><p>The bar chart in <xref rid="pone.0321008.g012" ref-type="fig">Fig 12b</xref> showcases the accuracy of each applied model in forecasting the identified turning points. The comparison of <italic toggle="yes">AAETP</italic> values reveals that XGboost performs the best among the models, with an <italic toggle="yes">AAETP</italic> of 1.579 m<sup>3</sup>/sec. In contrast, the LSTM model has an <italic toggle="yes">AAETP</italic> of 1.924 m<sup>3</sup>/sec, and the RF model has an <italic toggle="yes">AAETP</italic> of 2.119 m<sup>3</sup>/sec. This indicates that XGboost outperforms LSTM and RF in accurately forecasting the turning points of runoff. Specifically, the accuracy of turning point forecast improves by approximately 21% and 34% compared to LSTM and RF models, respectively.</p></sec><sec sec-type="conclusions" id="sec014"><title>4.4 Discussion</title><p>The current study investigated the effectiveness of three different models, namely LSTM, RF, and XGBoost, in forecasting monthly runoff for the Lotschental catchment in Switzerland. Among these models, XGBoost demonstrated superior accuracy, achieving a forecasting accuracy of <italic toggle="yes">R</italic> = 0.956. These findings contribute to advancing the accuracy of previous studies in this field. In a similar vein, some researchers [<xref rid="pone.0321008.ref081" ref-type="bibr">81</xref>] have employed the hybrid model ELM-GWO, which combines the extreme learning machine (ELM) with the grey wolf optimizer (GWO), to forecast runoff in the Three Gorges region of China. During the testing phase, the hybrid model (ELM-GWO) exhibited good accuracy, achieving an <italic toggle="yes">R</italic>-value of 0.9228. Another study explored the application of the Emotional Artificial Neural Network (EANN) for monthly runoff forecasting in the Kallada River basin, located in Kerala [<xref rid="pone.0321008.ref082" ref-type="bibr">82</xref>]. The findings of this research demonstrated that the EANN model yielded satisfactory results, achieving a forecasting accuracy with an <italic toggle="yes">R</italic>-value of 0.877. Furthermore, machine learning models have also been utilized in the semi-arid Central Andes of Argentina to predict the runoff [<xref rid="pone.0321008.ref083" ref-type="bibr">83</xref>]. The study concluded that support vector regression (SVR) demonstrated effective forecasting of the runoff, achieving <italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup> values ranging from 0.75 to 0.89 during the testing phase. Moreover, the XGBoost model developed in this study demonstrates good accuracy compared to similar studies conducted to forecast runoff in glacierized catchments. For example, some researchers conducted a study forecasting runoff using a conceptual hydrological model called Glacial Snow Melt (GSM) and SVR based on several hydrological and meteorological parameters [<xref rid="pone.0321008.ref084" ref-type="bibr">84</xref>]. The results showed that the GSM achieved a good accuracy with an <italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup> of 0.77, while the standalone SVR reached an <italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup> of 0.83. Similarly, another study developed a conceptual hydrological model for modeling runoff in glacierized alpine areas and found that the model provided good accuracy, with <italic toggle="yes">R</italic><sup><italic toggle="yes">2</italic></sup> values ranging from 0.74 to 0.89 [<xref rid="pone.0321008.ref085" ref-type="bibr">85</xref>]. Among the models examined in the literature, XGBoost demonstrated superior forecasting accuracy compared to others in forecasting monthly runoff for the Lotschental catchment, highlighting its effectiveness in this context. Furthermore, it is important to highlight that the forecasting models developed in previous research did not include turning point analysis. However, this research demonstrates that such a metric is highly significant in evaluating and comparing models.</p><p>As the XGBoost model in this study provides good forecasting accuracy for modeling monthly runoff compared to previous works, it may also be suitable for forecasting runoff over other time scales, such as daily and weekly. In shorter time scales (daily and weekly), the autocorrelation in time series data is typically higher than that in monthly scales, which may increase the opportunity for achieving better results. Additionally, in shorter time scales, the number of data points is greater than in the monthly scale, which may help models to be trained effectively with sufficient data.</p><p>In this work, a deep learning model called LSTM is used for modeling time series data because of its ability to remember past events and capture patterns over time. While LSTM addresses the vanishing gradient problem faced by traditional models like recurrent neural network (RNNs) [<xref rid="pone.0321008.ref086" ref-type="bibr">86</xref>], it did not outperform XBGoost in modeling runoff. This is largely because LSTM requires a significant amount of data to train effectively and may need additional features to capture complex temporal dependencies in the runoff data. The results of the current study indicate that deep learning model (LSTM) were not superior to machine learning models (XGBoost). Thus, the findings of this research align with another study [<xref rid="pone.0321008.ref087" ref-type="bibr">87</xref>] on runoff prediction that found deep learning models gave an acceptable result but less accurate than their machine learning counterparts.</p><p>The selection of training and testing samples for model training and validation is a crucial step in developing predictive models. In this study, runoff measurements from 2002 to 2015 are utilized for model development, while data from 2016 to 2021 serve to assess the accuracy of the model. Ensuring balanced data and minimizing bias between the training and testing sets play a significant role in creating a robust model with strong generalization capacity [<xref rid="pone.0321008.ref088" ref-type="bibr">88</xref>]. <xref rid="pone.0321008.g013" ref-type="fig">Fig 13</xref> summarizes the key statistical metrics for both datasets. Notably, there is a strong similarity in the training characteristics. For instance, the minimum, maximum, average, and standard deviation values for the training and testing datasets are as follows: 0.461 m<sup>3</sup>/sec vs. 0.444 m<sup>3</sup>/sec, 16.778 m<sup>3</sup>/sec vs. 16.887 m<sup>3</sup>/sec, 4.5328 m<sup>3</sup>/sec vs. 4.962 m<sup>3</sup>/sec, and 4.5997 m<sup>3</sup>/sec vs. 5.0549 m<sup>3</sup>/sec. These statistics indicate that both datasets are homogeneous and well-balanced, further supporting the validity of the model.</p><fig position="float" id="pone.0321008.g013"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g013</object-id><label>Fig 13</label><caption><title>Key statistical metrics of training and testing datasets.</title></caption><graphic xlink:href="pone.0321008.g013" position="float"/></fig><p>The choice of input lag combinations plays a critical role in time series forecasting (e.g., runoff) as it can significantly affect the performance of forecasting models such as LSTM, XGBoost, and RF. Also, using various combinations of input lags helps to evaluate their impact on the performance of prediction models. In this work, three combinations are used based on PACF. The first combination involves only three input variables, while the second includes seven lags, and the last one involves a large number of variables, up to ten. The performance of the models varies from one combination to another. The models attempt to capture the overall temporal dependencies in the testing data and require optimum input choices. It can be seen that none of the models provided good prediction accuracy using the first combination due to the lack of significant information needed to effectively capture the patterns of the time series data. In this case, XGBoost achieved the lowest forecasting error with <italic toggle="yes">MAE</italic> of 1.252 m<sup>3</sup>/sec, followed by RF (1.351 m<sup>3</sup>/sec) and LSTM (1.560 m<sup>3</sup>/sec). Regarding the second input combination, all models presented significant improvement, with XGBoost providing an <italic toggle="yes">MAE</italic> of 0.976 m<sup>3</sup>/sec, followed by RF (1.063 m<sup>3</sup>/sec) and LSTM (1.065 m<sup>3</sup>/sec). However, the forecasting accuracy of all the models deteriorated with the third input combination, with the <italic toggle="yes">MAE</italic> for XGBoost, RF, and LSTM being higher than those in the second combination. The main reason may be related to the introduction of a large number of features, which could lead to redundancy in the data and significantly affect the generalization of the models, complicating the training process. Once the input combination contained fewer variables, as seen in the first scenario, the models exhibited lower prediction capacity because the available inputs did not contain significant information that could be mapped by the models to mimic the patterns of the time series data and effectively capture the temporal dependencies in the runoff.</p><p>The melting of snow and glaciers is increasingly important for runoff generation due to the impacts of climate change and global warming. Enhancing the accuracy of runoff forecasting models offers tangible benefits for managing water resources in cold regions affected by such environmental changes. This is particularly crucial for the effective allocation and conservation of water resources. In our study, we found that traditional models had limited effectiveness in forecasting peak flows, which are critical for water management and flood mitigation in climate-affected regions. Conversely, the XGBoost model demonstrated notable improvements, producing the most accurate runoff simulations. The model&#x02019;s performance metrics, including <italic toggle="yes">RMSE</italic> of 1.554 m<sup>3</sup>/s, <italic toggle="yes">MAE</italic> of 0.976 m<sup>3</sup>/s, <italic toggle="yes">U</italic><sub><italic toggle="yes">95</italic></sub> of 1.231<italic toggle="yes">, R</italic><sup>2</sup> of 0.91, and <italic toggle="yes">d</italic> of 0.972, reflect its proficiency. Besides, the model exhibited superior performance in forecasting runoff turning points, achieving the lowest <italic toggle="yes">AAAET</italic> (1.579 m<sup>3</sup>/sec) among the compared models. These results underscore the potential of XGBoost models in areas with glacierized catchments, which are particularly vulnerable to rapid climate change and glacial melt. The study offers evidence that the proposed model adeptly handles the complex, nonlinear interplay between historical and projected runoff data, thus enabling more reliable water resource management in these challenging environments.</p><p>Furthermore, as shown in <xref rid="pone.0321008.g014" ref-type="fig">Fig 14</xref>, the model demonstrates excellent monthly runoff performance across nearly all months, generating minimal errors as indicated by the <italic toggle="yes">RMSE</italic> values. The lowest forecasting errors occurred in January and December, with <italic toggle="yes">RMSE</italic> values of 0.068 m<sup>3</sup>/sec and 0.124 m<sup>3</sup>/sec, respectively. In contrast, the highest forecasting error was recorded in June, with an <italic toggle="yes">RMSE</italic> of 3.354 m<sup>3</sup>/sec. The increase in forecasting error can be attributed to the instability and significant variability of the flow during this month. As shown in <xref rid="pone.0321008.g002" ref-type="fig">Fig 2</xref>, this period corresponds to the highest runoff into the basin, which leads to greater discrepancies in the model&#x02019;s predictions and subsequently higher forecasting errors.</p><fig position="float" id="pone.0321008.g014"><object-id pub-id-type="doi">10.1371/journal.pone.0321008.g014</object-id><label>Fig 14</label><caption><title>Monthly <italic toggle="yes">RMSE</italic> values.</title></caption><graphic xlink:href="pone.0321008.g014" position="float"/></fig></sec></sec><sec sec-type="conclusions" id="sec015"><title>5. Conclusion</title><p>The current study provides a comprehensive comparison between LSTM, XGBoost, and RF models for forecasting mean monthly runoff one month in advance. This study was conducted in the L&#x000f6;tschental catchment, Switzerland, which is classified as a glacierized catchment. The glacierized catchments are highly sensitive to climate change, where surface runoff undergoes dynamic hydrological processes influenced by climatic conditions and the formation and melting of ice. Historical data spanning from January 2002 to December 2021 was utilized, with input lag values determined using PACF and supplied to the runoff forecasting models. The data was divided into two phases: a training phase, which included runoff data from 2002 to 2015, and a testing phase, which used data from 2016 to 2021. The results indicated that XGBoost provided superior forecasting results compared to the other models, enhancing forecasting accuracy by reducing <italic toggle="yes">RMSE</italic> by 14.57% and 17.03% compared to the LSTM and RF models, respectively.</p><p>The current study also analyzes the capacity of the applied models to accurately forecast turning points in runoff data. Since the time series data of monthly runoff records contain significant autocorrelation, most AI models tend to provide in general good forecasts according to classical statistical metrics. Therefore, a new statistical criterion has been introduced in this research called <italic toggle="yes">AAETP</italic>. The quantitative results indicate that the XGBoost model was the most effective in accurately identifying turning points in the runoff time series data, outperforming the LSTM and RF models by approximately 21% and 34%, respectively. The effectiveness of the XGBoost model in capturing the complex runoff dynamics of glacierized catchments may have practical implications for water resource management decision-making. Also, its accurate forecasts may provide decision-makers with valuable insights to optimize strategies, allocate resources, and promote sustainable practices in response to changing hydrological conditions.</p><p>However, the proposed study still has some major constraints. Models&#x02019; limitation to predict peak values of monthly runoff concentrations with high accuracy will be improved by using data decomposition techniques such as reliable wavelet transform techniques. Future studies could also investigate the potential of incorporating ensemble and hybrid models, such as CNN-LSTM (combining Convolutional Neural Network with LSTM), ELM-MHA (combining metaheuristic algorithms with ELM) and other hybrid techniques for predicting monthly runoff rates. Also, it is recommended to incorporate longer runoff and climate datasets from observed stations or satellites to enhance runoff forecasting and better understand the impacts of climate change.</p></sec><sec id="sec016" sec-type="supplementary-material"><title>Supporting information</title><supplementary-material id="pone.0321008.s001" position="float" content-type="local-data"><label>S1 Table</label><caption><title>Monthly runoff data that is used in this study.</title><p>(DOCX)</p></caption><media xlink:href="pone.0321008.s001.docx"/></supplementary-material><supplementary-material id="pone.0321008.s002" position="float" content-type="local-data"><label>S2 Table</label><caption><title>Hyperparameters for the applied models.</title><p>(DOCX)</p></caption><media xlink:href="pone.0321008.s002.docx"/></supplementary-material></sec></body><back><ack><p>The authors would like to thank University of Anbar for supporting this research.</p></ack><glossary><title>Abbreviations</title><def-list><def-item><term>AAETP</term><def><p>Average absolute error of turning points</p></def></def-item><def-item><term>ANN</term><def><p>Artificial Neural Network</p></def></def-item><def-item><term>AR</term><def><p>Autoregressive</p></def></def-item><def-item><term>ARIMA</term><def><p>Autoregressive Integrated Moving Average</p></def></def-item><def-item><term>ARMA</term><def><p>Autoregressive Moving Average</p></def></def-item><def-item><term>BiLSTM</term><def><p>Bidirectional Long Short-Term Memory</p></def></def-item><def-item><term>CEEMDAN</term><def><p>Complete Ensemble Empirical Mode Decomposition with Adaptive Noise</p></def></def-item><def-item><term>EANN</term><def><p>Emotional Artificial Neural Network</p></def></def-item><def-item><term>ELM</term><def><p>Extreme Learning Machine</p></def></def-item><def-item><term>EOF</term><def><p>Edge-Of-Field</p></def></def-item><def-item><term>FOEN</term><def><p>Swiss Federal Office for the environment</p></def></def-item><def-item><term>GBM</term><def><p>Gradient Boosting Machines</p></def></def-item><def-item><term>GMM</term><def><p>Gaussian Mixture Model</p></def></def-item><def-item><term>HBV</term><def><p>Hydrologiska Byr&#x000e5;ns Vattenbalansavdelning</p></def></def-item><def-item><term>LSSVM</term><def><p>Least Squares Support Vector Machine</p></def></def-item><def-item><term>LSTM</term><def><p>Long Short-Term Memory</p></def></def-item><def-item><term>MAE</term><def><p>Mean Absolute Error</p></def></def-item><def-item><term>NSE</term><def><p>Nash-Sutcliffe Efficiency Index</p></def></def-item><def-item><term>PACF</term><def><p>Partial Autocorrelation Function</p></def></def-item><def-item><term>R<sup>2</sup></term><def><p>Coefficient of Determination</p></def></def-item><def-item><term>RF</term><def><p>Random Forest</p></def></def-item><def-item><term>RMSE</term><def><p>Root Mean Square Error</p></def></def-item><def-item><term>RNN</term><def><p>Recurrent Neural Network</p></def></def-item><def-item><term>RNN</term><def><p>Recurrent Neural Network</p></def></def-item><def-item><term>SHAP</term><def><p>SHapley Additive exPlanations</p></def></def-item><def-item><term>SSA</term><def><p>Singular Spectrum Analysis</p></def></def-item><def-item><term>SVM</term><def><p>Support Vector Machine</p></def></def-item><def-item><term>SVR; U95</term><def><p>Uncertainty at a 95% Confidence Interval</p></def></def-item><def-item><term>VMD</term><def><p>Variational Mode Decomposition</p></def></def-item><def-item><term>XGBoost</term><def><p>Extreme Gradient Boostig.</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="pone.0321008.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>S</given-names></name>, <name><surname>Kang</surname><given-names>Y</given-names></name>, <name><surname>Gao</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>P</given-names></name>, <name><surname>Cheng</surname><given-names>X</given-names></name>, <name><surname>Song</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Optimal reservoir operation and risk analysis of agriculture water supply considering encounter uncertainty of precipitation in irrigation area and runoff from upstream</article-title>. <source>Agric Water Manag</source>
<year>2023</year>;<volume>277</volume>:<fpage>108091</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.agwat.2022.108091</pub-id></mixed-citation></ref><ref id="pone.0321008.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Guo</surname><given-names>S</given-names></name>, <name><surname>Wen</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>H</given-names></name>. <article-title>Runoff prediction of lower Yellow River based on CEEMDAN-LSSVM-GM(1,1) model</article-title>. <source>Sci Rep</source>. <year>2023</year>;<volume>13</volume>(<issue>1</issue>):<fpage>1511</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-023-28662-5</pub-id>
<pub-id pub-id-type="pmid">36707680</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Wu</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>Z</given-names></name>, <name><surname>Hu</surname><given-names>Y</given-names></name>, <name><surname>Tao</surname><given-names>S</given-names></name>, <name><surname>Dong</surname><given-names>J</given-names></name>. <article-title>Runoff forecasting using convolutional neural networks and optimized bi-directional long short-term memory</article-title>. <source>Water Resour Manag</source>. <year>n.d</year>.;<volume>37</volume>:<fpage>937</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11269-022-03414-8</pub-id></mixed-citation></ref><ref id="pone.0321008.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>P</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Li</surname><given-names>Z</given-names></name>. <article-title>Impact of climate change on the glacier and runoff of a glacierized basin in Harlik Mountain, Eastern Tianshan Mountains</article-title>. <source>Remote Sens</source>. <year>2022</year>;<volume>14</volume>(<issue>14</issue>):<fpage>3497</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/rs14143497</pub-id></mixed-citation></ref><ref id="pone.0321008.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Rautela</surname><given-names>KS</given-names></name>, <name><surname>Kuniyal</surname><given-names>JC</given-names></name>, <name><surname>Alam</surname><given-names>MA</given-names></name>, <name><surname>Bhoj</surname><given-names>AS</given-names></name>, <name><surname>Kanwar</surname><given-names>N</given-names></name>. <article-title>Assessment of daily streamflow, sediment fluxes, and erosion rate of a pro-glacial stream basin, Central Himalaya, Uttarakhand</article-title>. <source>Water Air Soil Pollut</source>. <year>2022</year>;<volume>233</volume>:<fpage>136</fpage>.</mixed-citation></ref><ref id="pone.0321008.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Sun</surname><given-names>S</given-names></name>, <name><surname>Liu</surname><given-names>F</given-names></name>. <article-title>Monthly runoff prediction based on a coupled VMD-SSA-BiLSTM model</article-title>. <source>Sci Rep</source>. <year>2023</year>;<volume>13</volume>(<issue>1</issue>):<fpage>13149</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-023-39606-4</pub-id>
<pub-id pub-id-type="pmid">37573389</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Mohd Razali</surname><given-names>S</given-names></name>, <name><surname>Wan Mohtar</surname><given-names>W</given-names></name>, <name><surname>Yaseen</surname><given-names>ZM</given-names></name>. <article-title>Improving multi-month hydrological drought forecasting in a tropical region using hybridized extreme learning machine model with Beluga Whale Optimization algorithm</article-title>. <source>Stoch Environ Res Risk Assess</source>. <year>2023</year>;<volume>37</volume>:<fpage>4963</fpage>&#x02013;<lpage>89</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/S00477-023-02548-4</pub-id></mixed-citation></ref><ref id="pone.0321008.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Gan</surname><given-names>R</given-names></name>, <name><surname>Gu</surname><given-names>S</given-names></name>, <name><surname>Tong</surname><given-names>X</given-names></name>, <name><surname>Lu</surname><given-names>J</given-names></name>, <name><surname>Tang</surname><given-names>H</given-names></name>. <article-title>A nonparametric standardized runoff index for characterizing hydrological drought in the Shaying River Basin, China</article-title>. <source>Nat Hazards</source>. <year>2023</year>;<volume>120</volume>(<issue>3</issue>):<fpage>2233</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11069-023-06179-4</pub-id></mixed-citation></ref><ref id="pone.0321008.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>WC</given-names></name>, <name><surname>Gu</surname><given-names>M</given-names></name>, <name><surname>Li</surname><given-names>Z</given-names></name>, <name><surname>Hong</surname><given-names>YH</given-names></name>, <name><surname>Zang</surname><given-names>HF</given-names></name>, <name><surname>Xu</surname><given-names>DM</given-names></name>. <article-title>A stacking ensemble machine learning model for improving monthly runoff prediction</article-title>. <source>Earth Sci Inform</source>. <year>2025</year>;<volume>18</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>27</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/S12145-024-01544-8</pub-id></mixed-citation></ref><ref id="pone.0321008.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Kratzert</surname><given-names>F</given-names></name>, <name><surname>Klotz</surname><given-names>D</given-names></name>, <name><surname>Brenner</surname><given-names>C</given-names></name>, <name><surname>Schulz</surname><given-names>K</given-names></name>, <name><surname>Herrnegger</surname><given-names>M</given-names></name>. <article-title>Rainfall&#x02013;runoff modelling using Long Short-Term Memory (LSTM) networks</article-title>. <source>Hydrol Earth Syst Sci</source>. <year>2018</year>;<volume>22</volume>(<issue>11</issue>):<fpage>6005</fpage>&#x02013;<lpage>22</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5194/hess-22-6005-2018</pub-id></mixed-citation></ref><ref id="pone.0321008.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Morales</surname><given-names>Y</given-names></name>, <name><surname>Querales</surname><given-names>M</given-names></name>, <name><surname>Rosas</surname><given-names>H</given-names></name>, <name><surname>Allende-Cid</surname><given-names>H</given-names></name>, <name><surname>Salas</surname><given-names>R</given-names></name>. <article-title>A self-identification Neuro-Fuzzy inference framework for modeling rainfall-runoff in a Chilean watershed</article-title>. <source>J Hydrol</source>. <year>2021</year>;<volume>594</volume>:<fpage>125910</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2020.125910</pub-id></mixed-citation></ref><ref id="pone.0321008.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Bartoletti</surname><given-names>N</given-names></name>, <name><surname>Casagli</surname><given-names>F</given-names></name>, <name><surname>Marsili-Libelli</surname><given-names>S</given-names></name>, <name><surname>Nardi</surname><given-names>A</given-names></name>, <name><surname>Palandri</surname><given-names>L</given-names></name>. <article-title>Data-driven rainfall/runoff modelling based on a neuro-fuzzy inference system</article-title>. <source>Environ Model Softw</source>. <year>2018</year>;<volume>106</volume>:<fpage>35</fpage>&#x02013;<lpage>47</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.envsoft.2017.11.026</pub-id></mixed-citation></ref><ref id="pone.0321008.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Safari</surname><given-names>MJS</given-names></name>, <name><surname>Rahimzadeh Arashloo</surname><given-names>S</given-names></name>, <name><surname>Danandeh Mehr</surname><given-names>A</given-names></name>. <article-title>Rainfall-runoff modeling through regression in the reproducing kernel Hilbert space algorithm</article-title>. <source>J Hydrol</source>. <year>2020</year>;<volume>587</volume>:<fpage>125014</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2020.125014</pub-id></mixed-citation></ref><ref id="pone.0321008.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Han</surname><given-names>H</given-names></name>, <name><surname>Morrison</surname><given-names>RR</given-names></name>. <article-title>Data-driven approaches for runoff prediction using distributed data</article-title>. <source>Stoch Environ Res Risk Assess</source>. <year>2021</year>;<volume>36</volume>(<issue>8</issue>):<fpage>2153</fpage>&#x02013;<lpage>71</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00477-021-01993-3</pub-id></mixed-citation></ref><ref id="pone.0321008.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Bi</surname><given-names>X</given-names></name>, <name><surname>Li</surname><given-names>B</given-names></name>, <name><surname>Lu</surname><given-names>W</given-names></name>, <name><surname>Zhou</surname><given-names>X</given-names></name>. <article-title>Daily runoff forecasting based on data-augmented neural network model</article-title>. <source>J Hydroinform</source>. <year>2020</year>;<volume>22</volume>(<issue>4</issue>):<fpage>900</fpage>&#x02013;<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2166/hydro.2020.017</pub-id></mixed-citation></ref><ref id="pone.0321008.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Vilaseca</surname><given-names>F</given-names></name>, <name><surname>Castro</surname><given-names>A</given-names></name>, <name><surname>Chreties</surname><given-names>C</given-names></name>, <name><surname>Gorgoglione</surname><given-names>A</given-names></name>. <article-title>Daily rainfall-runoff modeling at watershed scale: A comparison between physically-based and data-driven models</article-title>. <source>Comput Sci Its Appl &#x02013; ICCSA 2021</source>. <year>2021</year>:<fpage>18</fpage>&#x02013;<lpage>33</lpage>.</mixed-citation></ref><ref id="pone.0321008.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>&#x000d6;zdo&#x0011f;an-Sar&#x00131;ko&#x000e7;</surname><given-names>G</given-names></name>, <name><surname>Dadaser-Celik</surname><given-names>F</given-names></name>. <article-title>Physically based vs. data-driven models for streamflow and reservoir volume prediction at a data-scarce semi-arid basin</article-title>. <source>Environ Sci Pollut Res Int</source>. <year>2024</year>;<volume>31</volume>(<issue>27</issue>):<fpage>39098</fpage>&#x02013;<lpage>119</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11356-024-33732-w</pub-id>
<pub-id pub-id-type="pmid">38811456</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Partington</surname><given-names>D</given-names></name>, <name><surname>Brunner</surname><given-names>P</given-names></name>, <name><surname>Simmons</surname><given-names>CT</given-names></name>, <name><surname>Werner</surname><given-names>AD</given-names></name>, <name><surname>Therrien</surname><given-names>R</given-names></name>, <name><surname>Maier</surname><given-names>HR</given-names></name>, <etal>et al</etal>. <article-title>Evaluation of outputs from automated baseflow separation methods against simulated baseflow from a physically based, surface water-groundwater flow model</article-title>. <source>J Hydrol</source>. <year>2012</year>;458&#x02013;459:<fpage>28</fpage>&#x02013;<lpage>39</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2012.06.029</pub-id></mixed-citation></ref><ref id="pone.0321008.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Bittelli</surname><given-names>M</given-names></name>, <name><surname>Tomei</surname><given-names>F</given-names></name>, <name><surname>Pistocchi</surname><given-names>A</given-names></name>, <name><surname>Flury</surname><given-names>M</given-names></name>, <name><surname>Boll</surname><given-names>J</given-names></name>, <name><surname>Brooks</surname><given-names>ES</given-names></name>, <etal>et al</etal>. <article-title>Development and testing of a physically based, three-dimensional model of surface and subsurface hydrology</article-title>. <source>Adv Water Resour</source>. <year>2010</year>;<volume>33</volume>(<issue>1</issue>):<fpage>106</fpage>&#x02013;<lpage>22</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.advwatres.2009.10.013</pub-id></mixed-citation></ref><ref id="pone.0321008.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Al-Kubaisi</surname><given-names>MHD</given-names></name>. <article-title>Surface runoff estimation in kubaisa watershed using SWAT, Western Desert, Iraq</article-title>. <source>IGJ</source>. <year>2024</year>;<volume>57</volume>(2B):<fpage>286</fpage>&#x02013;<lpage>97</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.46717/igj.57.2b.19ms-2024-8-29</pub-id></mixed-citation></ref><ref id="pone.0321008.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Javan</surname><given-names>K</given-names></name>, <name><surname>Lialestani</surname><given-names>MRFH</given-names></name>, <name><surname>Nejadhossein</surname><given-names>M</given-names></name>. <article-title>A comparison of ANN and HSPF models for runoff simulation in Gharehsoo River watershed, Iran</article-title>. <source>Model Earth Syst Environ</source>. <year>2015</year>;<volume>1</volume>(<issue>4</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s40808-015-0042-1</pub-id></mixed-citation></ref><ref id="pone.0321008.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Yoon</surname><given-names>H</given-names></name>, <name><surname>Jun</surname><given-names>S-C</given-names></name>, <name><surname>Hyun</surname><given-names>Y</given-names></name>, <name><surname>Bae</surname><given-names>G-O</given-names></name>, <name><surname>Lee</surname><given-names>K-K</given-names></name>. <article-title>A comparative study of artificial neural networks and support vector machines for predicting groundwater levels in a coastal aquifer</article-title>. <source>J Hydrol</source>. <year>2011</year>;<volume>396</volume>(1&#x02013;2):<fpage>128</fpage>&#x02013;<lpage>38</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2010.11.002</pub-id></mixed-citation></ref><ref id="pone.0321008.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Mehdizadeh</surname><given-names>S</given-names></name>, <name><surname>Fathian</surname><given-names>F</given-names></name>, <name><surname>Adamowski</surname><given-names>JF</given-names></name>. <article-title>Hybrid artificial intelligence-time series models for monthly streamflow modeling</article-title>. <source>Appl Soft Comput</source>. <year>2019</year>;<volume>80</volume>:<fpage>873</fpage>&#x02013;<lpage>87</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.asoc.2019.03.046</pub-id></mixed-citation></ref><ref id="pone.0321008.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Valipour</surname><given-names>M</given-names></name>. <article-title>Long-term runoff study using SARIMA and ARIMA models in the United States</article-title>. <source>Meteorol Appl</source>. <year>2015</year>;<volume>22</volume>(<issue>4</issue>):<fpage>592</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/met.1491</pub-id></mixed-citation></ref><ref id="pone.0321008.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Pulukuri</surname><given-names>S</given-names></name>, <name><surname>Keesara</surname><given-names>VR</given-names></name>, <name><surname>Deva</surname><given-names>P</given-names></name>. <article-title>Flow forecasting in a watershed using autoregressive updating model</article-title>. <source>Water Resour Manag</source>. <year>2018</year>;<volume>32</volume>(<issue>1</issue>):<fpage>2701</fpage>&#x02013;<lpage>16</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11269-018-1953-1</pub-id></mixed-citation></ref><ref id="pone.0321008.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Vishwakarma</surname><given-names>DK</given-names></name>, <name><surname>Kumar</surname><given-names>P</given-names></name>, <name><surname>Yadav</surname><given-names>KK</given-names></name>, <name><surname>Ali</surname><given-names>R</given-names></name>, <name><surname>Markuna</surname><given-names>S</given-names></name>, <name><surname>Chauhan</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Evaluation of CatBoost method for predicting weekly pan evaporation in subtropical and sub-humid regions</article-title>. <source>Pure Appl Geophys</source>. <year>2024</year>;<volume>181</volume>:<fpage>719</fpage>&#x02013;<lpage>47</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00024-023-03426-4</pub-id></mixed-citation></ref><ref id="pone.0321008.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Elbeltagi</surname><given-names>A</given-names></name>, <name><surname>Al-Mukhtar</surname><given-names>M</given-names></name>, <name><surname>Kushwaha</surname><given-names>NL</given-names></name>, <name><surname>Al-Ansari</surname><given-names>N</given-names></name>, <name><surname>Vishwakarma</surname><given-names>DK</given-names></name>. <article-title>Forecasting monthly pan evaporation using hybrid additive regression and data-driven models in a semi-arid environment</article-title>. <source>Appl Water Sci</source>. <year>2022</year>;<volume>13</volume>:<fpage>42</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s13201-022-01846-6</pub-id></mixed-citation></ref><ref id="pone.0321008.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Amiri</surname><given-names>E</given-names></name>. <article-title>Forecasting daily river flows using nonlinear time series models</article-title>. <source>J Hydrol</source>. <year>2015</year>;<volume>527</volume>:<fpage>1054</fpage>&#x02013;<lpage>72</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2015.05.048</pub-id></mixed-citation></ref><ref id="pone.0321008.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Ni</surname><given-names>L</given-names></name>, <name><surname>Wang</surname><given-names>D</given-names></name>, <name><surname>Wu</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Tao</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Streamflow forecasting using extreme gradient boosting model coupled with Gaussian mixture model</article-title>. <source>J Hydrol</source>. <year>2020</year>;<volume>586</volume>:<fpage>124901</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2020.124901</pub-id></mixed-citation></ref><ref id="pone.0321008.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Feng</surname><given-names>Z</given-names></name>, <name><surname>Niu</surname><given-names>W</given-names></name>, <name><surname>Tang</surname><given-names>Z</given-names></name>, <name><surname>Jiang</surname><given-names>Z</given-names></name>, <name><surname>Xu</surname><given-names>Y</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>Monthly runoff time series prediction by variational mode decomposition and support vector machine based on quantum-behaved particle swarm optimization</article-title>. <source>J Hydrol</source>. <year>2020</year>;<volume>583</volume>:<fpage>124627</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2020.124627</pub-id></mixed-citation></ref><ref id="pone.0321008.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Behrouz</surname><given-names>MS</given-names></name>, <name><surname>Yazdi</surname><given-names>MN</given-names></name>, <name><surname>Sample</surname><given-names>DJ</given-names></name>. <article-title>Using Random Forest, a machine learning approach to predict nitrogen, phosphorus, and sediment event mean concentrations in urban runoff</article-title>. <source>J Environ Manage</source>. <year>2022</year>;<volume>317</volume>:<fpage>115412</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jenvman.2022.115412</pub-id>
<pub-id pub-id-type="pmid">35649331</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Yilmaz</surname><given-names>AG</given-names></name>, <name><surname>Muttil</surname><given-names>N</given-names></name>. <article-title>Runoff estimation by machine learning methods and application to the Euphrates Basin in Turkey</article-title>. <source>J Hydrol Eng</source>. <year>2014</year>;<volume>19</volume>:<fpage>1015</fpage>&#x02013;<lpage>25</lpage>.</mixed-citation></ref><ref id="pone.0321008.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>GF</given-names></name>, <name><surname>Jhong</surname><given-names>BC</given-names></name>, <name><surname>Chang</surname><given-names>CC</given-names></name>. <article-title>Development of an effective data-driven model for hourly typhoon rainfall forecasting</article-title>. <source>J Hydrol</source>. <year>2013</year>;<volume>495</volume>:<fpage>52</fpage>&#x02013;<lpage>63</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/J.JHYDROL.2013.04.050</pub-id></mixed-citation></ref><ref id="pone.0321008.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Feng</surname><given-names>Y</given-names></name>, <name><surname>Cui</surname><given-names>N</given-names></name>, <name><surname>Hao</surname><given-names>W</given-names></name>, <name><surname>Gao</surname><given-names>L</given-names></name>, <name><surname>Gong</surname><given-names>D</given-names></name>. <article-title>Estimation of soil temperature from meteorological data using different machine learning models</article-title>. <source>Geoderma</source>. <year>2019</year>;<volume>338</volume>:<fpage>67</fpage>&#x02013;<lpage>77</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.geoderma.2018.11.044</pub-id></mixed-citation></ref><ref id="pone.0321008.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Sahoo</surname><given-names>S</given-names></name>, <name><surname>Russo</surname><given-names>TA</given-names></name>, <name><surname>Elliott</surname><given-names>J</given-names></name>, <name><surname>Foster</surname><given-names>I</given-names></name>. <article-title>Machine learning algorithms for modeling groundwater level changes in agricultural regions of the U.S.</article-title>
<source>Water Resour Res</source>. <year>2017</year>;<volume>53</volume>(<issue>5</issue>):<fpage>3878</fpage>&#x02013;<lpage>95</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/2016wr019933</pub-id></mixed-citation></ref><ref id="pone.0321008.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Le</surname><given-names>X-H</given-names></name>, <name><surname>Nguyen</surname><given-names>D-H</given-names></name>, <name><surname>Jung</surname><given-names>S</given-names></name>, <name><surname>Yeon</surname><given-names>M</given-names></name>, <name><surname>Lee</surname><given-names>G</given-names></name>. <article-title>Comparison of deep learning techniques for river streamflow forecasting</article-title>. <source>IEEE Access</source>. <year>2021</year>;<volume>9</volume>:<fpage>71805</fpage>&#x02013;<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2021.3077703</pub-id></mixed-citation></ref><ref id="pone.0321008.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Szczepanek</surname><given-names>R</given-names></name>. <article-title>Daily streamflow forecasting in mountainous catchment using XGBoost, LightGBM and CatBoost</article-title>. <source>Hydrology</source>. <year>2022</year>;<volume>9</volume>(<issue>12</issue>):<fpage>226</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/hydrology9120226</pub-id></mixed-citation></ref><ref id="pone.0321008.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>S</given-names></name>, <name><surname>Peng</surname><given-names>H</given-names></name>. <article-title>Multiple spatio-temporal scale runoff forecasting and driving mechanism exploration by K-means optimized XGBoost and SHAP</article-title>. <source>J Hydrol</source>. <year>2024</year>;<volume>630</volume>:<fpage>130650</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2024.130650</pub-id></mixed-citation></ref><ref id="pone.0321008.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Guo</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Zou</surname><given-names>Q</given-names></name>, <name><surname>Ye</surname><given-names>L</given-names></name>, <name><surname>Zhu</surname><given-names>S</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>. <article-title>Study on optimization and combination strategy of multiple daily runoff prediction models coupled with physical mechanism and LSTM</article-title>. <source>J Hydrol</source>. <year>2023</year>;<volume>624</volume>:<fpage>129969</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2023.129969</pub-id></mixed-citation></ref><ref id="pone.0321008.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Xu</surname><given-names>Y</given-names></name>, <name><surname>Lin</surname><given-names>K</given-names></name>, <name><surname>Hu</surname><given-names>C</given-names></name>, <name><surname>Wang</surname><given-names>S</given-names></name>, <name><surname>Wu</surname><given-names>Q</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Interpretable machine learning on large samples for supporting runoff estimation in ungauged basins</article-title>. <source>J Hydrol</source>. <year>2024</year>;<volume>639</volume>:<fpage>131598</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2024.131598</pub-id></mixed-citation></ref><ref id="pone.0321008.ref041"><label>41</label><mixed-citation publication-type="journal"><name><surname>Alomar</surname><given-names>MK</given-names></name>, <name><surname>Khaleel</surname><given-names>F</given-names></name>, <name><surname>Aljumaily</surname><given-names>MM</given-names></name>, <name><surname>Masood</surname><given-names>A</given-names></name>, <name><surname>Razali</surname><given-names>SFM</given-names></name>, <name><surname>AlSaadi</surname><given-names>MA</given-names></name>, <etal>et al</etal>. <article-title>Data-driven models for atmospheric air temperature forecasting at a continental climate region</article-title>. <source>PLoS One</source>. <year>2022</year>;<volume>17</volume>(<issue>11</issue>):e0277079. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0277079</pub-id>
<pub-id pub-id-type="pmid">36327280</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>D&#x000f6;ll</surname><given-names>P</given-names></name>, <name><surname>Abbasi</surname><given-names>M</given-names></name>, <name><surname>Messager</surname><given-names>ML</given-names></name>, <name><surname>Trautmann</surname><given-names>T</given-names></name>, <name><surname>Lehner</surname><given-names>B</given-names></name>, <name><surname>Lamouroux</surname><given-names>N</given-names></name>. <article-title>Streamflow intermittence in Europe: Estimating high&#x02010;resolution monthly time series by downscaling of simulated runoff and random forest modeling</article-title>. <source>Water Resour Res</source>. <year>2024</year>;<volume>60</volume>(<issue>8</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1029/2023wr036900</pub-id></mixed-citation></ref><ref id="pone.0321008.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Zema</surname><given-names>DA</given-names></name>, <name><surname>Parhizkar</surname><given-names>M</given-names></name>, <name><surname>Plaza-Alvarez</surname><given-names>PA</given-names></name>, <name><surname>Xu</surname><given-names>X</given-names></name>, <name><surname>Lucas-Borja</surname><given-names>ME</given-names></name>. <article-title>Using random forest and multiple-regression models to predict changes in surface runoff and soil erosion after prescribed fire</article-title>. <source>Model Earth Syst Environ</source>. <year>2023</year>;<volume>10</volume>(<issue>1</issue>):<fpage>1215</fpage>&#x02013;<lpage>28</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s40808-023-01838-8</pub-id></mixed-citation></ref><ref id="pone.0321008.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>S</given-names></name>, <name><surname>Peng</surname><given-names>H</given-names></name>, <name><surname>Hu</surname><given-names>Q</given-names></name>, <name><surname>Jiang</surname><given-names>M</given-names></name>. <article-title>Analysis of runoff generation driving factors based on hydrological model and interpretable machine learning method</article-title>. <source>J Hydrol: Reg Stud</source>. <year>2022</year>;<volume>42</volume>:<fpage>101139</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ejrh.2022.101139</pub-id></mixed-citation></ref><ref id="pone.0321008.ref045"><label>45</label><mixed-citation publication-type="journal"><name><surname>Swagatika</surname><given-names>S</given-names></name>, <name><surname>Paul</surname><given-names>JC</given-names></name>, <name><surname>Sahoo</surname><given-names>BB</given-names></name>, <name><surname>Gupta</surname><given-names>SK</given-names></name>, <name><surname>Singh</surname><given-names>PK</given-names></name>. <article-title>Improving the forecasting accuracy of monthly runoff time series of the Brahmani River in India using a hybrid deep learning model</article-title>. <source>J Water Clim Change</source>. <year>2023</year>;<volume>15</volume>(<issue>1</issue>):<fpage>139</fpage>&#x02013;<lpage>56</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2166/wcc.2023.487</pub-id></mixed-citation></ref><ref id="pone.0321008.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Guo</surname><given-names>H</given-names></name>, <name><surname>Chen</surname><given-names>L</given-names></name>, <name><surname>Fang</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>S</given-names></name>. <article-title>Model and application of annual river runoff prediction based on complementary set empirical mode decomposition combined with particle swarm optimization adaptive neuro-fuzzy system</article-title>. <source>Water Supply</source>. <year>2023</year>;<volume>23</volume>(<issue>5</issue>):<fpage>1760</fpage>&#x02013;<lpage>74</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2166/ws.2023.075</pub-id></mixed-citation></ref><ref id="pone.0321008.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Kumar</surname><given-names>K</given-names></name>, <name><surname>Singh</surname><given-names>V</given-names></name>, <name><surname>Roshni</surname><given-names>T</given-names></name>. <article-title>Application of the PSO&#x02013;Neural network in rainfall&#x02013;runoff modeling</article-title>. <source>Water Pract Technol</source>. <year>2022</year>;<volume>18</volume>(<issue>1</issue>):<fpage>16</fpage>&#x02013;<lpage>26</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2166/wpt.2022.155</pub-id></mixed-citation></ref><ref id="pone.0321008.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Katipo&#x0011f;lu</surname><given-names>OM</given-names></name>, <name><surname>Sar&#x00131;g&#x000f6;l</surname><given-names>M</given-names></name>. <article-title>Improving the accuracy of rainfall-runoff relationship estimation using signal processing techniques, bio-inspired swarm intelligence and artificial intelligence algorithms</article-title>. <source>Earth Sci Inform</source>. <year>2023</year>;<volume>16</volume>(<issue>4</issue>):<fpage>3125</fpage>&#x02013;<lpage>41</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s12145-023-01081-w</pub-id></mixed-citation></ref><ref id="pone.0321008.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Katipo&#x0011f;lu</surname><given-names>OM</given-names></name>, <name><surname>Ye&#x0015f;ilyurt</surname><given-names>SN</given-names></name>, <name><surname>Dalk&#x00131;l&#x00131;&#x000e7;</surname><given-names>HY</given-names></name>, <name><surname>Akar</surname><given-names>F</given-names></name>. <article-title>Application of empirical mode decomposition, particle swarm optimization, and support vector machine methods to predict stream flows</article-title>. <source>Environ Monit Assess</source>. <year>2023</year>;<volume>195</volume>(<issue>9</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10661-023-11700-0</pub-id></mixed-citation></ref><ref id="pone.0321008.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>W</given-names></name>, <name><surname>Xu</surname><given-names>D</given-names></name>, <name><surname>Zhao</surname><given-names>Y</given-names></name>, <name><surname>Zang</surname><given-names>H</given-names></name>. <article-title>A compound approach for ten-day runoff prediction by coupling wavelet denoising, attention mechanism, and LSTM based on GPU parallel acceleration technology</article-title>. <source>Earth Sci Inform</source>. <year>2024</year>;<volume>17</volume>(<issue>2</issue>):<fpage>1281</fpage>&#x02013;<lpage>99</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s12145-023-01212-3</pub-id></mixed-citation></ref><ref id="pone.0321008.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>Y</given-names></name>, <name><surname>Ghosh</surname><given-names>C</given-names></name>, <name><surname>Malakpour-Estalaki</surname><given-names>S</given-names></name>. <article-title>A methodological framework for improving the performance of data-driven models: A case study for daily runoff prediction in the Maumee domain, USA</article-title>. <source>Geosci Model Dev</source>. <year>2023</year>;<volume>16</volume>(<issue>7</issue>):<fpage>1925</fpage>&#x02013;<lpage>36</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5194/gmd-16-1925-2023</pub-id></mixed-citation></ref><ref id="pone.0321008.ref052"><label>52</label><mixed-citation publication-type="book"><name><surname>Mesinger</surname><given-names>F</given-names></name>, <name><surname>Pierrehumbert</surname><given-names>R</given-names></name>. <source>Alpine lee cyclogenesis: Numerical simulation and theory. WMO Proceedings of the Conference on the Scientific Results of the Alpine Experiment(ALPEX), 1986</source>. <source>(ALPEX)</source>. <year>1986</year>.</mixed-citation></ref><ref id="pone.0321008.ref053"><label>53</label><mixed-citation publication-type="book"><name><surname>Wall&#x000e9;n</surname><given-names>CC</given-names></name>. <source>Climates of northern and western Europe</source>. (No Title). <year>1970</year>.</mixed-citation></ref><ref id="pone.0321008.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>R&#x000f6;&#x000df;ler</surname><given-names>O</given-names></name>, <name><surname>L&#x000f6;ffler</surname><given-names>J</given-names></name>. <article-title>Analyzing spatio-temporal hydrological processes and related gradients to improve hydrological modeling in high mountains</article-title>. <source>Lecture Notes in Earth Sciences</source>. <year>2010</year>;<volume>115</volume>: <fpage>243</fpage>&#x02013;<lpage>256</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/978-3-540-75761-0_15</pub-id></mixed-citation></ref><ref id="pone.0321008.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Leys</surname><given-names>M</given-names></name>, <name><surname>Keller</surname><given-names>I</given-names></name>, <name><surname>Robinson</surname><given-names>CT</given-names></name>, <name><surname>R&#x000e4;s&#x000e4;nen</surname><given-names>K</given-names></name>. <article-title>Cryptic lineages of a common alpine mayfly show strong life-history divergence</article-title>. <source>Mol Ecol</source>. <year>2017</year>;<volume>26</volume>(<issue>6</issue>):<fpage>1670</fpage>&#x02013;<lpage>86</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/mec.14026</pub-id>
<pub-id pub-id-type="pmid">28099770</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>R&#x000f6;ssler</surname><given-names>O</given-names></name>, <name><surname>Froidevaux</surname><given-names>P</given-names></name>, <name><surname>B&#x000f6;rst</surname><given-names>U</given-names></name>, <name><surname>Rickli</surname><given-names>R</given-names></name>, <name><surname>Martius</surname><given-names>O</given-names></name>, <name><surname>Weingartner</surname><given-names>R</given-names></name>. <article-title>Retrospective analysis of a nonforecasted rain-on-snow flood in the Alps &#x02013; A matter of model limitations or unpredictable nature?</article-title>. <source>Hydrol Earth Syst Sci</source>. <year>2014</year>;<volume>18</volume>(<issue>6</issue>):<fpage>2265</fpage>&#x02013;<lpage>85</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5194/hess-18-2265-2014</pub-id></mixed-citation></ref><ref id="pone.0321008.ref057"><label>57</label><mixed-citation publication-type="other">Frey E, Prof S, Zischg A, Prof A, Wunderle S. Methodological framework for long-term satellite-based forest monitoring in the canton of Bern: Combining geospatial forest data with 35 years of Landsat 5 and 7 imagery products. 2024.</mixed-citation></ref><ref id="pone.0321008.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Diehl</surname><given-names>T</given-names></name>, <name><surname>Deichmann</surname><given-names>N</given-names></name>, <name><surname>Clinton</surname><given-names>J</given-names></name>, <name><surname>K&#x000e4;stli</surname><given-names>P</given-names></name>, <name><surname>Cauzzi</surname><given-names>C</given-names></name>, <name><surname>Kraft</surname><given-names>T</given-names></name>, <etal>et al</etal>. <article-title>Earthquakes in Switzerland and surrounding regions during 2014</article-title>. <source>Swiss J Geosci</source>. <year>2015</year>;<volume>108</volume>(2&#x02013;3):<fpage>425</fpage>&#x02013;<lpage>43</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00015-015-0204-1</pub-id></mixed-citation></ref><ref id="pone.0321008.ref059"><label>59</label><mixed-citation publication-type="other">Synthesis report on the event analysis the floods of 2005 in Switzerland. 2005:1&#x02013;50.</mixed-citation></ref><ref id="pone.0321008.ref060"><label>60</label><mixed-citation publication-type="journal"><name><surname>Mohammadi</surname><given-names>B</given-names></name>, <name><surname>Vazifehkhah</surname><given-names>S</given-names></name>, <name><surname>Duan</surname><given-names>Z</given-names></name>. <article-title>A conceptual metaheuristic-based framework for improving runoff time series simulation in glacierized catchments</article-title>. <source>Eng Appl Artif Intell</source>. <year>2024</year>;<volume>127</volume>:<fpage>107302</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.engappai.2023.107302</pub-id></mixed-citation></ref><ref id="pone.0321008.ref061"><label>61</label><mixed-citation publication-type="journal"><name><surname>Moghar</surname><given-names>A</given-names></name>, <name><surname>Hamiche</surname><given-names>M</given-names></name>. <article-title>Stock market prediction using LSTM recurrent neural network</article-title>. <source>Procedia Comput Sci</source>. <year>2020</year>;<volume>170</volume>:<fpage>1168</fpage>&#x02013;<lpage>73</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.procs.2020.03.049</pub-id></mixed-citation></ref><ref id="pone.0321008.ref062"><label>62</label><mixed-citation publication-type="journal"><name><surname>Landi</surname><given-names>F</given-names></name>, <name><surname>Baraldi</surname><given-names>L</given-names></name>, <name><surname>Cornia</surname><given-names>M</given-names></name>, <name><surname>Cucchiara</surname><given-names>R</given-names></name>. <article-title>Working memory connections for LSTM</article-title>. <source>Neural Netw</source>. <year>2021</year>;<volume>144</volume>:<fpage>334</fpage>&#x02013;<lpage>41</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neunet.2021.08.030</pub-id>
<pub-id pub-id-type="pmid">34547671</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref063"><label>63</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Mohd Razali</surname><given-names>SF</given-names></name>, <name><surname>Wan Mohtar</surname><given-names>WHM</given-names></name>, <name><surname>Ahmad Alsaydalani</surname><given-names>MO</given-names></name>, <name><surname>Yaseen</surname><given-names>ZM</given-names></name>. <article-title>Deep learning versus hybrid regularized extreme learning machine for multi-month drought forecasting: A comparative study and trend analysis in tropical region</article-title>. <source>Heliyon</source>. <year>2023</year>;<volume>10</volume>(<issue>1</issue>):e22942. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.heliyon.2023.e22942</pub-id>
<pub-id pub-id-type="pmid">38187234</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref064"><label>64</label><mixed-citation publication-type="journal"><name><surname>Rokach</surname><given-names>L</given-names></name>. <article-title>Decision forest: Twenty years of research</article-title>. <source>Inf Fusion</source>. <year>2016</year>;<volume>27</volume>:<fpage>111</fpage>&#x02013;<lpage>25</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.inffus.2015.06.005</pub-id></mixed-citation></ref><ref id="pone.0321008.ref065"><label>65</label><mixed-citation publication-type="journal"><name><surname>Jollans</surname><given-names>L</given-names></name>, <name><surname>Boyle</surname><given-names>R</given-names></name>, <name><surname>Artiges</surname><given-names>E</given-names></name>, <name><surname>Banaschewski</surname><given-names>T</given-names></name>, <name><surname>Desrivi&#x000e8;res</surname><given-names>S</given-names></name>, <name><surname>Grigis</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Quantifying performance of machine learning methods for neuroimaging data</article-title>. <source>Neuroimage</source>. <year>2019</year>;<volume>199</volume>:<fpage>351</fpage>&#x02013;<lpage>65</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.05.082</pub-id>
<pub-id pub-id-type="pmid">31173905</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref066"><label>66</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Mohd Razali</surname><given-names>SF</given-names></name>, <name><surname>Wan Mohtar</surname><given-names>WHM</given-names></name>, <name><surname>Yaseen</surname><given-names>ZM</given-names></name>. <article-title>Examining optimized machine learning models for accurate multi-month drought forecasting: A representative case study in the USA</article-title>. <source>Environ Sci Pollut Res Int</source>. <year>2024</year>;<volume>31</volume>(<issue>39</issue>):<fpage>52060</fpage>&#x02013;<lpage>85</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11356-024-34500-6</pub-id>
<pub-id pub-id-type="pmid">39134798</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref067"><label>67</label><mixed-citation publication-type="journal"><name><surname>Fan</surname><given-names>J</given-names></name>, <name><surname>Wu</surname><given-names>L</given-names></name>, <name><surname>Zhang</surname><given-names>F</given-names></name>, <name><surname>Cai</surname><given-names>H</given-names></name>, <name><surname>Zeng</surname><given-names>W</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <etal>et al</etal>. <article-title>Empirical and machine learning models for predicting daily global solar radiation from sunshine duration: A review and case study in China</article-title>. <source>Renew Sustain Energy Rev</source>. <year>2019</year>;<volume>100</volume>:<fpage>186</fpage>&#x02013;<lpage>212</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.rser.2018.10.018</pub-id></mixed-citation></ref><ref id="pone.0321008.ref068"><label>68</label><mixed-citation publication-type="journal"><name><surname>Masood</surname><given-names>A</given-names></name>, <name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Srivastava</surname><given-names>A</given-names></name>, <name><surname>Pham</surname><given-names>QB</given-names></name>, <name><surname>Ahmad</surname><given-names>K</given-names></name>, <name><surname>Razali</surname><given-names>SFM</given-names></name>, <etal>et al</etal>. <article-title>Improving PM2.5 prediction in New Delhi using a hybrid extreme learning machine coupled with snake optimization algorithm</article-title>. <source>Sci Rep</source>. <year>2023</year>;<volume>13</volume>(<issue>1</issue>):<fpage>21057</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-023-47492-z</pub-id>
<pub-id pub-id-type="pmid">38030733</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref069"><label>69</label><mixed-citation publication-type="journal"><name><surname>Zounemat-Kermani</surname><given-names>M</given-names></name>, <name><surname>Batelaan</surname><given-names>O</given-names></name>, <name><surname>Fadaee</surname><given-names>M</given-names></name>, <name><surname>Hinkelmann</surname><given-names>R</given-names></name>. <article-title>Ensemble machine learning paradigms in hydrology: A review</article-title>. <source>J Hydrol</source>. <year>2021</year>;<volume>598</volume>:<fpage>126266</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2021.126266</pub-id></mixed-citation></ref><ref id="pone.0321008.ref070"><label>70</label><mixed-citation publication-type="journal"><name><surname>Sahour</surname><given-names>H</given-names></name>, <name><surname>Gholami</surname><given-names>V</given-names></name>, <name><surname>Vazifedan</surname><given-names>M</given-names></name>. <article-title>A comparative analysis of statistical and machine learning techniques for mapping the spatial distribution of groundwater salinity in a coastal aquifer</article-title>. <source>J Hydrol</source>. <year>2020</year>;<volume>591</volume>:<fpage>125321</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2020.125321</pub-id></mixed-citation></ref><ref id="pone.0321008.ref071"><label>71</label><mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>H</given-names></name>, <name><surname>Ma</surname><given-names>X</given-names></name>. <article-title>Hybrid decision tree-based machine learning models for short-term water quality prediction</article-title>. <source>Chemosphere</source>. <year>2020</year>;<volume>249</volume>:<fpage>126169</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.chemosphere.2020.126169</pub-id>
<pub-id pub-id-type="pmid">32078849</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref072"><label>72</label><mixed-citation publication-type="journal"><name><surname>Alomar</surname><given-names>MK</given-names></name>, <name><surname>Khaleel</surname><given-names>F</given-names></name>, <name><surname>Aljumaily</surname><given-names>MM</given-names></name>, <name><surname>Masood</surname><given-names>A</given-names></name>, <name><surname>Razali</surname><given-names>SFM</given-names></name>, <name><surname>AlSaadi</surname><given-names>MA</given-names></name>, <etal>et al</etal>. <article-title>Data-driven models for atmospheric air temperature forecasting at a continental climate region</article-title>. <source>PLoS One</source>. <year>2022</year>;<volume>17</volume>(<issue>11</issue>):e0277079. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0277079</pub-id>
<pub-id pub-id-type="pmid">36327280</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref073"><label>73</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>AlOmar</surname><given-names>MK</given-names></name>, <name><surname>Al-Saadi</surname><given-names>AAA</given-names></name>, <name><surname>AlSaadi</surname><given-names>MA</given-names></name>. <article-title>Inflow forecasting using regularized extreme learning machine: Haditha reservoir chosen as case study</article-title>. <source>Stoch Environ Res Risk Assess</source>. <year>2022</year>;<volume>36</volume>(<issue>12</issue>):<fpage>4201</fpage>&#x02013;<lpage>21</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00477-022-02254-7</pub-id></mixed-citation></ref><ref id="pone.0321008.ref074"><label>74</label><mixed-citation publication-type="journal"><name><surname>Mamat</surname><given-names>N</given-names></name>, <name><surname>Mohd Razali</surname><given-names>SF</given-names></name>. <article-title>Comparisons of various imputation methods for incomplete water quality data: A case study of The Langat River, Malaysia</article-title>. <source>jkukm</source>. <year>2023</year>;<volume>35</volume>(<issue>1</issue>):<fpage>191</fpage>&#x02013;<lpage>201</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.17576/jkukm-2023-35(1)-18</pub-id></mixed-citation></ref><ref id="pone.0321008.ref075"><label>75</label><mixed-citation publication-type="journal"><name><surname>Adnan</surname><given-names>RM</given-names></name>, <name><surname>Liang</surname><given-names>Z</given-names></name>, <name><surname>Trajkovic</surname><given-names>S</given-names></name>, <name><surname>Zounemat-Kermani</surname><given-names>M</given-names></name>, <name><surname>Li</surname><given-names>B</given-names></name>, <name><surname>Kisi</surname><given-names>O</given-names></name>. <article-title>Daily streamflow prediction using optimally pruned extreme learning machine</article-title>. <source>J Hydrol</source>. <year>2019</year>;<volume>577</volume>:<fpage>123981</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jhydrol.2019.123981</pub-id></mixed-citation></ref><ref id="pone.0321008.ref076"><label>76</label><mixed-citation publication-type="journal"><name><surname>Eray</surname><given-names>O</given-names></name>, <name><surname>Mert</surname><given-names>C</given-names></name>, <name><surname>Kisi</surname><given-names>O</given-names></name>. <article-title>Comparison of multi-gene genetic programming and dynamic evolving neural-fuzzy inference system in modeling pan evaporation</article-title>. <source>Hydrol Res</source>. <year>2017</year>;<volume>49</volume>(<issue>4</issue>):<fpage>1221</fpage>&#x02013;<lpage>33</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2166/nh.2017.076</pub-id></mixed-citation></ref><ref id="pone.0321008.ref077"><label>77</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Khaleel</surname><given-names>F</given-names></name>, <name><surname>AlOmar</surname><given-names>MK</given-names></name>, <name><surname>Mohd Razali</surname><given-names>SF</given-names></name>, <name><surname>AlSaadi</surname><given-names>MA</given-names></name>. <article-title>Optimising the selection of input variables to increase the predicting accuracy of shear strength for deep beams</article-title>. <source>Complexity</source>. <year>2022</year>;<volume>2022</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1155/2022/6532763</pub-id></mixed-citation></ref><ref id="pone.0321008.ref078"><label>78</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Abed</surname><given-names>MA</given-names></name>, <name><surname>Al-Ansari</surname><given-names>N</given-names></name>, <name><surname>Alomar</surname><given-names>MK</given-names></name>. <article-title>Predicting compressive strength of concrete containing industrial waste materials: Novel and hybrid machine learning model</article-title>. <source>Adv Civ Eng</source>. <year>2022</year>;<volume>2022</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1155/2022/5586737</pub-id></mixed-citation></ref><ref id="pone.0321008.ref079"><label>79</label><mixed-citation publication-type="journal"><name><surname>Mahmood</surname><given-names>OA</given-names></name>, <name><surname>Sulaiman</surname><given-names>SO</given-names></name>, <name><surname>Al-Jumeily</surname><given-names>D</given-names></name>. <article-title>Forecasting for Haditha reservoir inflow in the West of Iraq using Support Vector Machine (SVM)</article-title>. <source>PLoS One</source>. <year>2024</year>;<volume>19</volume>(<issue>9</issue>):e0308266. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0308266</pub-id>
<pub-id pub-id-type="pmid">39240996</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref080"><label>80</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Razali</surname><given-names>SFM</given-names></name>, <name><surname>Mohtar</surname><given-names>WHMW</given-names></name>, <name><surname>Rahman</surname><given-names>NA</given-names></name>, <name><surname>Yaseen</surname><given-names>ZM</given-names></name>. <article-title>Machine learning models development for accurate multi-months ahead drought forecasting: Case study of the Great Lakes, North America</article-title>. <source>PLoS One</source>. <year>2023</year>;<volume>18</volume>(<issue>10</issue>):e0290891. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0290891</pub-id>
<pub-id pub-id-type="pmid">37906556</pub-id>
</mixed-citation></ref><ref id="pone.0321008.ref081"><label>81</label><mixed-citation publication-type="journal"><name><surname>Cheng</surname><given-names>X</given-names></name>, <name><surname>Feng</surname><given-names>Z-K</given-names></name>, <name><surname>Niu</surname><given-names>W-J</given-names></name>. <article-title>Forecasting monthly runoff time series by single-layer feedforward artificial neural network and grey wolf optimizer</article-title>. <source>IEEE Access</source>. <year>2020</year>;<volume>8</volume>:<fpage>157346</fpage>&#x02013;<lpage>55</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/access.2020.3019574</pub-id></mixed-citation></ref><ref id="pone.0321008.ref082"><label>82</label><mixed-citation publication-type="journal"><name><surname>Reddy</surname><given-names>BSN</given-names></name>, <name><surname>Pramada</surname><given-names>SK</given-names></name>, <name><surname>Roshni</surname><given-names>T</given-names></name>. <article-title>Monthly surface runoff prediction using artificial intelligence: A study from a tropical climate river basin</article-title>. <source>J Earth Syst Sci</source>. <year>2021</year>;<volume>130</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s12040-020-01508-8</pub-id></mixed-citation></ref><ref id="pone.0321008.ref083"><label>83</label><mixed-citation publication-type="journal"><name><surname>Korsic</surname><given-names>SAT</given-names></name>, <name><surname>Notarnicola</surname><given-names>C</given-names></name>, <name><surname>Quirno</surname><given-names>MU</given-names></name>, <name><surname>Cara</surname><given-names>L</given-names></name>. <article-title>Assessing a data-driven approach for monthly runoff prediction in a mountain basin of the Central Andes of Argentina</article-title>. <source>Environ Chall</source>. <year>2023</year>;<volume>10</volume>:<fpage>100680</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.envc.2023.100680</pub-id></mixed-citation></ref><ref id="pone.0321008.ref084"><label>84</label><mixed-citation publication-type="journal"><name><surname>Mohammadi</surname><given-names>B</given-names></name>, <name><surname>Vazifehkhah</surname><given-names>S</given-names></name>, <name><surname>Duan</surname><given-names>Z</given-names></name>. <article-title>A conceptual metaheuristic-based framework for improving runoff time series simulation in glacierized catchments</article-title>. <source>Eng Appl Artif Intell</source>. <year>2024</year>;<volume>127</volume>:<fpage>107302</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.engappai.2023.107302</pub-id></mixed-citation></ref><ref id="pone.0321008.ref085"><label>85</label><mixed-citation publication-type="journal"><name><surname>Koboltschnig</surname><given-names>GR</given-names></name>, <name><surname>Sch&#x000f6;ner</surname><given-names>W</given-names></name>, <name><surname>Zappa</surname><given-names>M</given-names></name>, <name><surname>Kroisleitner</surname><given-names>C</given-names></name>, <name><surname>Holzmann</surname><given-names>H</given-names></name>. <article-title>Runoff modelling of the glacierized Alpine Upper Salzach basin (Austria): Multi&#x02010;criteria result validation</article-title>. <source>Hydrol Process</source>. <year>2008</year>;<volume>22</volume>(<issue>19</issue>):<fpage>3950</fpage>&#x02013;<lpage>64</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/hyp.7112</pub-id></mixed-citation></ref><ref id="pone.0321008.ref086"><label>86</label><mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Zhu</surname><given-names>Z</given-names></name>, <name><surname>Kong</surname><given-names>D</given-names></name>, <name><surname>Han</surname><given-names>H</given-names></name>, <name><surname>Zhao</surname><given-names>Y</given-names></name>. <article-title>EA-LSTM: Evolutionary attention-based LSTM for time series prediction</article-title>. <source>Knowl-Based Syst</source>. <year>2019</year>;<volume>181</volume>:<fpage>104785</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.knosys.2019.05.028</pub-id></mixed-citation></ref><ref id="pone.0321008.ref087"><label>87</label><mixed-citation publication-type="journal"><name><surname>Yan</surname><given-names>L</given-names></name>, <name><surname>Lei</surname><given-names>Q</given-names></name>, <name><surname>Jiang</surname><given-names>C</given-names></name>, <name><surname>Yan</surname><given-names>P</given-names></name>, <name><surname>Ren</surname><given-names>Z</given-names></name>, <name><surname>Liu</surname><given-names>B</given-names></name>. <article-title>Climate-informed monthly runoff prediction model using machine learning and feature importance analysis</article-title>. <source>Front Environ Sci</source>. <year>2022</year>;<volume>10</volume>:<fpage>1049840</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/FENVS.2022.1049840</pub-id></mixed-citation></ref><ref id="pone.0321008.ref088"><label>88</label><mixed-citation publication-type="journal"><name><surname>Hameed</surname><given-names>MM</given-names></name>, <name><surname>Masood</surname><given-names>A</given-names></name>, <name><surname>Srivastava</surname><given-names>A</given-names></name>, <name><surname>Abd Rahman</surname><given-names>N</given-names></name>, <name><surname>Mohd Razali</surname><given-names>SF</given-names></name>, <name><surname>Salem</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Investigating a hybrid extreme learning machine coupled with Dingo Optimization Algorithm for modeling liquefaction triggering in sand-silt mixtures</article-title>. <source>Sci Rep</source>. <year>2024</year>;<volume>14</volume>(<issue>1</issue>):<fpage>10799</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-024-61059-6</pub-id>
<pub-id pub-id-type="pmid">38734717</pub-id>
</mixed-citation></ref></ref-list></back><sub-article article-type="author-comment" id="pone.0321008.r001" specific-use="rebutted-decision-letter-unavailable"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0321008.r001</article-id><title-group><article-title>Author response to Decision Letter 0</article-title></title-group><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">11 Sep 2024</named-content>
</p></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0321008.r002" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0321008.r002</article-id><title-group><article-title>Decision Letter 0</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Shicheng</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2025 Shicheng Li</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Shicheng Li</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0321008" id="rel-obj002" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">19 Oct 2024</named-content>
</p><p>--&#x0003e;PONE-D-24-40156--&#x0003e;--&#x0003e;Forecasting Monthly Runoff in a Glacierized Catchment: A Comparison of Extreme Gradient Boosting (XGBoost) and Deep Learning Models.--&#x0003e;--&#x0003e;PLOS ONE</p><p>Dear Dr. Salem,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#x02019;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by Dec 03 2024 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#x000a0;<email>plosone@plos.org</email> . When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:--&#x0003e;</p><p><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list>
</p><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link> . Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols</ext-link> .</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Shicheng Li</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal Requirements:</p><p>When submitting your revision, we need you to address these additional requirements.</p><p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at&#x000a0;</p><p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and&#x000a0;</p><p>
<ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
</p><p>2. Please note that PLOS ONE has specific guidelines on code sharing for submissions in which author-generated code underpins the findings in the manuscript. In these cases, we expect all author-generated code to be made available without restrictions upon publication of the work. Please review our guidelines at <ext-link xlink:href="https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code" ext-link-type="uri">https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code</ext-link> and ensure that your code is shared in a way that follows best practice and facilitates reproducibility and reuse.</p><p>3. Please provide a complete Data Availability Statement in the submission form, ensuring you include all necessary access information or a reason for why you are unable to make your data freely accessible. If your research concerns only data provided within your submission, please write "All data are in the manuscript and/or supporting information files" as your Data Availability Statement.</p><p>4. We note that Figure 1 in your submission contain [map/satellite] images which may be copyrighted. All PLOS content is published under the Creative Commons Attribution License (CC BY 4.0), which means that the manuscript, images, and Supporting Information files will be freely available online, and any third party is permitted to access, download, copy, distribute, and use these materials in any way, even commercially, with proper attribution. For these reasons, we cannot publish previously copyrighted maps or satellite images created using proprietary data, such as Google software (Google Maps, Street View, and Earth). For more information, see our copyright guidelines: <ext-link xlink:href="http://journals.plos.org/plosone/s/licenses-and-copyright." ext-link-type="uri">http://journals.plos.org/plosone/s/licenses-and-copyright</ext-link>.</p><p>We require you to either (1) present written permission from the copyright holder to publish these figures specifically under the CC BY 4.0 license, or (2) remove the figures from your submission:</p><p>a. You may seek permission from the original copyright holder of Figure 1 to publish the content specifically under the CC BY 4.0 license.&#x000a0;&#x000a0;</p><p>We recommend that you contact the original copyright holder with the Content Permission Form (<ext-link xlink:href="http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf)" ext-link-type="uri">http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf</ext-link>) and the following text:</p><p>&#x0201c;I request permission for the open-access journal PLOS ONE to publish XXX under the Creative Commons Attribution License (CCAL) CC BY 4.0 (<ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/)." ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>). Please be aware that this license allows unrestricted use and distribution, even commercially, by third parties. Please reply and provide explicit written permission to publish XXX under a CC BY license and complete the attached form.&#x0201d;</p><p>Please upload the completed Content Permission Form or other proof of granted permissions as an ""Other"" file with your submission.</p><p>In the figure caption of the copyrighted figure, please include the following text: &#x0201c;Reprinted from [ref] under a CC BY license, with permission from [name of publisher], original copyright [original copyright year].&#x0201d;</p><p>b. If you are unable to obtain permission from the original copyright holder to publish these figures under the CC BY 4.0 license or if the copyright holder&#x02019;s requirements are incompatible with the CC BY 4.0 license, please either i) remove the figure or ii) supply a replacement figure that complies with the CC BY 4.0 license. Please check copyright information on all replacement figures and update the figure caption with source information. If applicable, please specify in the figure caption text when a figure is similar but not identical to the original image and is therefore for illustrative purposes only.</p><p>The following resources for replacing copyrighted map figures may be helpful:</p><p>USGS National Map Viewer (public domain): <ext-link xlink:href="http://viewer.nationalmap.gov/viewer/" ext-link-type="uri">http://viewer.nationalmap.gov/viewer/</ext-link></p><p>The Gateway to Astronaut Photography of Earth (public domain): <ext-link xlink:href="http://eol.jsc.nasa.gov/sseop/clickmap/" ext-link-type="uri">http://eol.jsc.nasa.gov/sseop/clickmap/</ext-link></p><p>Maps at the CIA (public domain): <ext-link xlink:href="https://www.cia.gov/library/publications/the-world-factbook/index.html" ext-link-type="uri">https://www.cia.gov/library/publications/the-world-factbook/index.html</ext-link> and <ext-link xlink:href="https://www.cia.gov/library/publications/cia-maps-publications/index.html" ext-link-type="uri">https://www.cia.gov/library/publications/cia-maps-publications/index.html</ext-link></p><p>NASA Earth Observatory (public domain): <ext-link xlink:href="http://earthobservatory.nasa.gov/" ext-link-type="uri">http://earthobservatory.nasa.gov/</ext-link></p><p>Landsat: <ext-link xlink:href="http://landsat.visibleearth.nasa.gov/" ext-link-type="uri">http://landsat.visibleearth.nasa.gov/</ext-link></p><p>USGS EROS (Earth Resources Observatory and Science (EROS) Center) (public domain): <ext-link xlink:href="http://eros.usgs.gov/#" ext-link-type="uri">http://eros.usgs.gov/#</ext-link></p><p>Natural Earth (public domain): <ext-link xlink:href="http://www.naturalearthdata.com/" ext-link-type="uri">http://www.naturalearthdata.com/</ext-link></p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>--&#x0003e;<bold>Comments to the Author</bold></p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. --&#x0003e;</p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Partly</p><p>**********</p><p>--&#x0003e;2. Has the statistical analysis been performed appropriately and rigorously? --&#x0003e;</p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p>--&#x0003e;3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.--&#x0003e;</p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p>--&#x0003e;4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.--&#x0003e;</p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p>--&#x0003e;5. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)--&#x0003e;</p><p>Reviewer #1:&#x000a0;In this work, the Extreme Gradient Boosting (XGBoost), random forest (RF) and long-short term memory (LSTM) model was used to forecast monthly runoff for one month ahead of time in the Lotschental watershed in Switzerland. The work is well organized. however, with the following minor corrections, it is acceptable:</p><p>SPECIFIC RECOMMENDATIONS</p><p>ABSTRACT</p><p>&#x02022; The abstract could briefly explain why these methods were chosen or how they contribute to the research.</p><p>&#x02022; The results could be more specific, including quantitative outcomes or more detailed</p><p>&#x02022; At the end of the Abstract, it is necessary to point out the global importance of this study for society. This would arouse greater interest from Journal readers.</p><p>INTRODUCTION SECTION</p><p>&#x02022; The introduction effectively covers the necessary elements but could be improved by providing a more detailed summary of methods, emphasizing the scientific gap, and enhancing the problem statement with a broader context.</p><p>&#x02022; If possible, reinforce the introduction with up-to-date references (2022-2024) below. Because it is important to include the most recent articles.</p><p>1. Improving the accuracy of rainfall-runoff relationship estimation using signal processing techniques, bio-inspired swarm intelligence and artificial intelligence algorithms</p><p>2. Monthly streamflow prediction in Amasya, T&#x000fc;rkiye, using an integrated approach of a feedforward backpropagation neural network and discrete wavelet transform</p><p>3. Improving the accuracy of rainfall-runoff relationship estimation using signal processing techniques, bio-inspired swarm intelligence and artificial intelligence algorithms</p><p>4. Application of empirical mode decomposition, particle swarm optimization, and support vector machine methods to predict stream flows</p><p>5. Simulation of the potential impacts of projected climate and land use change on runoff under CMIP6 scenarios</p><p>MATERIALS &#x00026; METHOD</p><p>METHODOLOGY</p><p>&#x02022; Consider adding brief explanations on why specific methods were chosen.</p><p>RESULTS</p><p>&#x02022; Improve the logical flow and ensure that each finding is clearly explained.</p><p>&#x02022; Please give applied model parameters.</p><p>CONCLUSIONS</p><p>&#x02022; Clearly stating the most significant findings, with specific reference to the data.</p><p>&#x02022; Offer more detailed and actionable recommendations based on the study's results.</p><p>&#x02022; Highlight the study's contribution to existing research and its potential implications for theory and practice.</p><p>&#x02022; Ensure that each paragraph is concise and directly contributes to the discussion.</p><p>Reviewer #2:&#x000a0;This paper proposes Extreme Gradient Boosting (XGBoost) and Deep Learning Models to predict the Monthly Runoff in a Glacierized Catchment. However, the quality of the paper should be improved a bit. Specific comments are as follows.</p><p>1. The graphical abstract/flow diagram is missing, it must be added.</p><p>2. The novelty statement and research gap should be highlights in innovative aspect of this study, specifically in abstract and Introduction.</p><p>3. The shortcomings of existing research should be summarized, and the innovation of this paper should be highlighted.</p><p>4. As described in the paper, Extreme Gradient Boosting (XGBoost) and Deep Learning Models has been widely applied in the various fields, such as river stage forecasting (<ext-link xlink:href="https://doi.org/10.1007/s13201-024-02103-8;" ext-link-type="uri">https://doi.org/10.1007/s13201-024-02103-8;</ext-link>
<ext-link xlink:href="https://doi.org/10.1016/j.heliyon.2023.e16290)," ext-link-type="uri">https://doi.org/10.1016/j.heliyon.2023.e16290</ext-link>), Drought Forecasting (<ext-link xlink:href="https://doi.org/10.3390/w15040765)" ext-link-type="uri">https://doi.org/10.3390/w15040765</ext-link>) and long-term rainfall prediction (<ext-link xlink:href="https://doi.org/10.1007/s00024-022-03189-4)," ext-link-type="uri">https://doi.org/10.1007/s00024-022-03189-4</ext-link>), Pan Evaporation (<ext-link xlink:href="https://doi.org/10.1007/s00024-023-03426-4;" ext-link-type="uri">https://doi.org/10.1007/s00024-023-03426-4;</ext-link>
<ext-link xlink:href="https://doi.org/10.1007/s13201-022-01846-6)." ext-link-type="uri">https://doi.org/10.1007/s13201-022-01846-6</ext-link>). However, several aspects in health monitoring, such as the reason for the adoption of Extreme Gradient Boosting (XGBoost) and Deep Learning Models in this paper is not clearly explained, it need to be appropriately supplemented.</p><p>5. The algorithms of machine learning models should be simplified, and the innovation of this paper should be highlighted. Readers are more concerned about the advantages of the deep learning model proposed in this study in forecasting.</p><p>6. Line no 62, " Several studies [11&#x02013;13]" the citation must be at the end of sentence.</p><p>7. Lin No 79, the referencing and citation must be according to the journal style. for instant, water table [28] and river stages (Choi et al., 2020), both type of citations are there. it should be check throughout the manuscript.</p><p>8. Due to the extensive use of abbreviations, it is essential to include a list of acronyms for clarity and ease of understanding.</p><p>9. More datasets/no of stations should be provided to demonstrate the generalization ability and robustness of AI models.</p><p>10. What is new in this manuscript that was not there in the previous study? And what are the differences between this study and the old study? The limitations should be differentiated in discussion.</p><p>11. Future study must be stated.</p><p>Reviewer #3:&#x000a0;The article titled "Forecasting Monthly Runoff in a Glacierized Catchment: A Comparison of Extreme Gradient Boosting (XGBoost) and Deep Learning Models" evaluates the effectiveness of XGBoost, LSTM, and Random Forest RF models in forecasting monthly runoff in the Lotschental catchment, Switzerland. This comparative analysis is beneficial for identifying the best model for monthly runoff forecasting under complex hydrological conditions, especially in glacierized catchments.</p><p>The article is interesting, but the following issues should be addressed.</p><p>Specific Comments and Suggestions:</p><p>1. Consider adding in Abstract a sentence highlighting the novelty of the study, such as the use of turning point analysis or the comparison of multiple machine learning models in this specific context.</p><p>2. In Introduction the literature review could be further strengthened by discussing recent advancements in machine learning and their potential applications in hydrological modeling.</p><p>The research questions could be explicitly stated at the end of the Introduction to provide a clear focus for the study.</p><p>3. Data Sources: Clearly indicate the specific sources of meteorological and hydrometric data used in the study.</p><p>4. Additional questions for consideration In the "Case Study Location" section:</p><p>- have there been any significant changes in land cover or vegetation patterns within the catchment in recent decades?</p><p>- are there any known geological faults or other factors that could influence the stability of the slopes and the risk of landslides?</p><p>- how have past flooding events affected the local communities and infrastructure?</p><p>5. Limited data temporal scope.</p><p>Although the study spans nearly two decades (2002-2021), integrating longer historical data could provide a more comprehensive understanding of long-term trends and improve the models' generalization capacity. Then the models could capture rare but critical climate events that affect runoff.</p><p>Why weren't earlier data and longer measurement series used?</p><p>6. Consider adding a more detailed explanation of the LSTM architecture</p><p>7. Discuss the process of hyperparameter tuning for each model, as this can significantly impact performance.</p><p>8. How did the choice of input lags affect the performance of the models?</p><p>9. Were any other machine learning models considered for comparison?</p><p>10. Were there any significant differences in model performance during different seasons or hydrological conditions?</p><p>11. How did the models perform in forecasting extreme events, such as floods or droughts?</p><p>12. While the study compares three individual models, it doesn&#x02019;t explore hybrid modeling approaches. Combining the strengths of XGBoost and LSTM, for instance, could yield a model that balances the interpretability and robustness of XGBoost with the sequential learning advantages of LSTM.</p><p>The authors should refer to the issue of potential for hybrid model.</p><p>13. Although LSTM is a robust model for time series data, other advanced deep learning architectures, could further improve forecasting accuracy by capturing long-term dependencies more effectively. The authors should address this probleme.</p><p>14. The sensitivity of the AETP metric should be assessed to different thresholds for defining turning points. This can help to evaluate the robustness of the results.</p><p>15. Including climate projections could significantly enhance the model's utility for long-term water resource planning in glacierized regions that are highly sensitive to global warming.</p><p>16. Are there any specific regions or time periods where one model consistently outperforms the others?</p><p>17. To improve the "Discussion" section, it would be necessary to specify"</p><p>- how do the findings of this study compare to other research on runoff forecasting in glacierized catchments located in different regions?</p><p>- are there any potential biases or uncertainties associated with the use of historical data for model training and validation?</p><p>- could the XGBoost model be adapted or improved to forecast runoff at different time scales (e.g., daily, weekly)?</p><p>Incorporating longer data records, exploring hybrid models, and integrating climate change scenarios could further enhance the model's applicability in hydrological forecasting.</p><p>**********</p><p>--&#x0003e;6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link> ). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link> .--&#x0003e;</p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;No</p><p>Reviewer #3:&#x000a0;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#x000a0;<ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link> . PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#x000a0;<email>figures@plos.org</email> . Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0321008.r003"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0321008.r003</article-id><title-group><article-title>Author response to Decision Letter 1</article-title></title-group><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0321008" id="rel-obj003" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">8 Feb 2025</named-content>
</p><p>Dear Editor,</p><p>We sincerely appreciate the opportunity to submit the revised version of our manuscript entitled &#x0201c;Forecasting Monthly Runoff in a Glacierized Catchment: A Comparison of Extreme Gradient Boosting (XGBoost) and Deep Learning Models.&#x0201d; to PLOS ONE.</p><p>We would also like to express our gratitude to the esteemed reviewers for their valuable and constructive comments. We have worked diligently to ensure that all authors have collaboratively addressed the comments raised by the reviewers and have made the necessary revisions to enhance the manuscript. Additionally, we would like to confirm that we have responded to the editorial comments, including the copyright concerns regarding Figure 1. We utilized a map sourced from open access source (please see Figure 1 in the main paper), and the relevant data availability details are incorporated within the manuscript and provided in the Appendix (please see the Suplimantary_file). Furthermore, our manuscript specifies that the models were developed using Python, which is open-access and freely available.</p><p>Below, we provide a point-by-point response to the comments raised by the reviewers:</p><p>Reviewer #1:</p><p>In this work, the Extreme Gradient Boosting (XGBoost), random forest (RF) and long-short term memory (LSTM) model was used to forecast monthly runoff for one month ahead of time in the Lotschental watershed in Switzerland. The work is well organized. however, with the following minor corrections, it is acceptable:</p><p>SPECIFIC RECOMMENDATIONS</p><p>ABSTRACT</p><p>- The abstract could briefly explain why these methods were chosen or how they contribute to the research.</p><p>Reply: We have explained in the abstract the reasons for selecting the applied models, as per your suggestion.</p><p>- The results could be more specific, including quantitative outcomes or more detailed.</p><p>Reply: We have incorporated additional quantitative results and details to make our findings more specific, as suggested.</p><p>- At the end of the Abstract, it is necessary to point out the global importance of this study for society. This would arouse greater interest from Journal readers.</p><p>Reply: We have emphasized the global significance of this study for society, as recommended.</p><p>INTRODUCTION SECTION</p><p>&#x02022; The introduction effectively covers the necessary elements but could be improved by providing a more detailed summary of methods, emphasizing the scientific gap, and enhancing the problem statement with a broader context.</p><p>Reply: We have enhanced our introduction by including a summary of the applied models and highlighting the existing scientific gaps, as recommended. Please see pages 5 (lines 102 to 110) and 6-7 (lines 133 to 146).</p><p>&#x02022; If possible, reinforce the introduction with up-to-date references (2022-2024) below. Because it is important to include the most recent articles.</p><p>1. Improving the accuracy of rainfall-runoff relationship estimation using signal processing techniques, bio-inspired swarm intelligence and artificial intelligence algorithms</p><p>2. Monthly streamflow prediction in Amasya, T&#x000fc;rkiye, using an integrated approach of a feedforward backpropagation neural network and discrete wavelet transform</p><p>3. Improving the accuracy of rainfall-runoff relationship estimation using signal processing techniques, bio-inspired swarm intelligence and artificial intelligence algorithms</p><p>4. Application of empirical mode decomposition, particle swarm optimization, and support vector machine methods to predict stream flows</p><p>5. Simulation of the potential impacts of projected climate and land use change on runoff under CMIP6 scenarios</p><p>Reply: We would like to confirm that we have improved our paper by incorporating new references, as suggested. Below is a list of some additional references included in the paper:</p><p>1. Al-Kubaisi MHD. Surface Runoff Estimation in Kubaisa Watershed Using SWAT, Western Desert, Iraq. Iraqi Geological Journal. 2024;57: 286&#x02013;297. doi:10.46717/igj.57.2B.19ms-2024-8-29</p><p>2. Javan K, Lialestani MRFH, Nejadhossein M. A comparison of ANN and HSPF models for runoff simulation in Gharehsoo River watershed, Iran. Model Earth Syst Environ. 2015;1: 41. doi:10.1007/s40808-015-0042-1</p><p>3. Vishwakarma DK, Kumar P, Yadav KK, Ali R, Markuna S, Chauhan S, et al. Evaluation of CatBoost Method for Predicting Weekly Pan Evaporation in Subtropical and Sub-Humid Regions. Pure Appl Geophys. 2024;181: 719&#x02013;747. doi:10.1007/s00024-023-03426-4</p><p>4. Elbeltagi A, Al-Mukhtar M, Kushwaha NL, Al-Ansari N, Vishwakarma DK. Forecasting monthly pan evaporation using hybrid additive regression and data-driven models in a semi-arid environment. Appl Water Sci. 2022;13: 42. doi:10.1007/s13201-022-01846-6</p><p>5. Amiri E. Forecasting daily river flows using nonlinear time series models. J Hydrol (Amst). 2015;527: 1054&#x02013;1072. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2015.05.048" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2015.05.048</ext-link></p><p>6. Wang S, Peng H. Multiple spatio-temporal scale runoff forecasting and driving mechanism exploration by K-means optimized XGBoost and SHAP. J Hydrol (Amst). 2024;630: 130650. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2024.130650" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2024.130650</ext-link></p><p>7. Guo J, Liu Y, Zou Q, Ye L, Zhu S, Zhang H. Study on optimization and combination strategy of multiple daily runoff prediction models coupled with physical mechanism and LSTM. J Hydrol (Amst). 2023;624: 129969. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2023.129969" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2023.129969</ext-link></p><p>8. Xu Y, Lin K, Hu C, Wang S, Wu Q, Zhang J, et al. Interpretable machine learning on large samples for supporting runoff estimation in ungauged basins. J Hydrol (Amst). 2024;639: 131598. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2024.131598" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2024.131598</ext-link></p><p>9. Wang Y, Wang W, Xu D, Zhao Y, Zang H. A compound approach for ten-day runoff prediction by coupling wavelet denoising, attention mechanism, and LSTM based on GPU parallel acceleration technology. Earth Sci Inform. 2024;17: 1281&#x02013;1299. doi:10.1007/s12145-023-01212-3</p><p>10. Guo H, Chen L, Fang Y, Zhang S. Model and application of annual river runoff prediction based on complementary set empirical mode decomposition combined with particle swarm optimization adaptive neuro-fuzzy system. Water Supply. 2023;23: 1760&#x02013;1774. doi:10.2166/ws.2023.075</p><p>11. Kumar K, Singh V, Roshni T. Application of the PSO&#x02013;neural network in rainfall&#x02013;runoff modeling. Water Pract Technol. 2022;18: 16&#x02013;26. doi:10.2166/wpt.2022.155</p><p>12. Katipo&#x0011f;lu OM, Sar&#x00131;g&#x000f6;l M. Improving the accuracy of rainfall-runoff relationship estimation using signal processing techniques, bio-inspired swarm intelligence and artificial intelligence algorithms. Earth Sci Inform. 2023;16: 3125&#x02013;3141. doi:10.1007/s12145-023-01081-w</p><p>13. Katipo&#x0011f;lu OM, Ye&#x0015f;ilyurt SN, Dalk&#x00131;l&#x00131;&#x000e7; HY, Akar F. Application of empirical mode decomposition, particle swarm optimization, and support vector machine methods to predict stream flows. Environ Monit Assess. 2023;195: 1108. doi:10.1007/s10661-023-11700-0</p><p>14. Hameed MM, Mohd Razali SF, Wan Mohtar WHM, Yaseen ZM. Examining optimized machine learning models for accurate multi-month drought forecasting: A representative case study in the USA. Environmental Science and Pollution Research. 2024. doi:10.1007/s11356-024-34500-6</p><p>15. Hameed MM, Masood A, Srivastava A, Abd Rahman N, Mohd Razali SF, Salem A, et al. Investigating a hybrid extreme learning machine coupled with Dingo Optimization Algorithm for modeling liquefaction triggering in sand-silt mixtures. Sci Rep. 2024;14: 10799. doi:10.1038/s41598-024-61059-6</p><p>15. Alomar MK, Khaleel F, Aljumaily MM, Masood A, Razali SFM, AlSaadi MA, et al. Data-driven models for atmospheric air temperature forecasting at a continental climate region. PLOS ONE. 2022;17: e0277079.</p><p>16. D&#x000f6;ll P, Abbasi M, Messager ML, Trautmann T, Lehner B, Lamouroux N. Streamflow Intermittence in Europe: Estimating High-Resolution Monthly Time Series by Downscaling of Simulated Runoff and Random Forest Modeling. Water Resources Research. 2024;60: e2023WR036900. doi: <ext-link xlink:href="https://doi.org/10.1029/2023WR036900" ext-link-type="uri">https://doi.org/10.1029/2023WR036900</ext-link></p><p>17. Zema DA, Parhizkar M, Plaza-Alvarez PA, Xu X, Lucas-Borja ME. Using random forest and multiple-regression models to predict changes in surface runoff and soil erosion after prescribed fire. Modeling Earth Systems and Environment. 2024;10: 1215&#x02013;1228. doi:10.1007/s40808-023-01838-8</p><p>MATERIALS &#x00026; METHOD</p><p>METHODOLOGY</p><p>&#x02022; Consider adding brief explanations on why specific methods were chosen.</p><p>Reply: We provide a brief explanation of the main reasons for using these models in runoff forecasting. Please refer to page 13 (lines 246 to 258) for more details.</p><p>RESULTS</p><p>&#x02022; Improve the logical flow and ensure that each finding is clearly explained.</p><p>Reply: We have improved the logical flow of the results section as suggested and have clearly presented the findings of this research. Please refer to pages 23, 26, 27, and 28, for details.</p><p>&#x02022;Please give applied model parameters.</p><p>Reply: The model parameters are provided in the Appendix; please see Table S2.</p><p>CONCLUSIONS</p><p>&#x02022; Clearly stating the most significant findings, with specific reference to the data.</p><p>&#x02022; Offer more detailed and actionable recommendations based on the study's results.</p><p>&#x02022; Highlight the study's contribution to existing research and its potential implications for theory and practice.</p><p>&#x02022; Ensure that each paragraph is concise and directly contributes to the discussion.</p><p>Reply: We have revised the Conclusion section in accordance with your constructive comments:</p><p>- We have clearly explained the key findings, incorporating specific data as suggested.</p><p>- The major contributions of the study are stated as you recommended.</p><p>- We have highlighted the potential implications and practical applications of the research findings.</p><p>- Each paragraph of the Conclusion has been made concise and now directly contributes to the discussion, as suggested.</p><p>- Recommendations have been provided as advised.</p><p>Reviewer #2:</p><p>This paper proposes Extreme Gradient Boosting (XGBoost) and Deep Learning Models to predict the Monthly Runoff in a Glacierized Catchment. However, the quality of the paper should be improved a bit. Specific comments are as follows.</p><p>1. The graphical abstract/flow diagram is missing, it must be added.</p><p>Reply: A flow diagram has been added and explained. Please see Figure 5 on page 19.</p><p>2. The novelty statement and research gap should be highlights in innovative aspect of this study, specifically in abstract and Introduction.</p><p>Reply: The novelty of the current research has been highlighted in both the introduction and abstract sections, as suggested. Please see page 2 (Abstract) , and pages 6, and 7 (lines 133 &#x02013; 146), in the introduction section.</p><p>3. The shortcomings of existing research should be summarized, and the innovation of this paper should be highlighted.</p><p>Reply: We have summarized the most essential shortcomings of existing research and highlighted the significance and innovation of our paper in the Introduction section. Please refer to pages 4 (lines, 75-85) and 6, and 7 (lines 133-146, 154-159).</p><p>4. As described in the paper, Extreme Gradient Boosting (XGBoost) and Deep Learning Models has been widely applied in the various fields, such as river stage forecasting (<ext-link xlink:href="https://doi.org/10.1007/s13201-024-02103-8;" ext-link-type="uri">https://doi.org/10.1007/s13201-024-02103-8;</ext-link></p><p><ext-link xlink:href="https://doi.org/10.1016/j.heliyon.2023.e16290)," ext-link-type="uri">https://doi.org/10.1016/j.heliyon.2023.e16290</ext-link>), Drought Forecasting (<ext-link xlink:href="https://doi.org/10.3390/w15040765)" ext-link-type="uri">https://doi.org/10.3390/w15040765</ext-link>) and long-term rainfall prediction (<ext-link xlink:href="https://doi.org/10.1007/s00024-022-03189-4)," ext-link-type="uri">https://doi.org/10.1007/s00024-022-03189-4</ext-link>), Pan Evaporation (<ext-link xlink:href="https://doi.org/10.1007/s00024-023-03426-4;" ext-link-type="uri">https://doi.org/10.1007/s00024-023-03426-4;</ext-link>
<ext-link xlink:href="https://doi.org/10.1007/s13201-022-01846-6)." ext-link-type="uri">https://doi.org/10.1007/s13201-022-01846-6</ext-link>). However, several aspects in health monitoring, such as the reason for the adoption of Extreme Gradient Boosting (XGBoost) and Deep Learning Models in this paper is not clearly explained, it need to be appropriately supplemented.</p><p>Reply: We have improved our paper accordingly. Below is a list of some additional references included in the paper:</p><p>1. Al-Kubaisi MHD. Surface Runoff Estimation in Kubaisa Watershed Using SWAT, Western Desert, Iraq. Iraqi Geological Journal. 2024;57: 286&#x02013;297. doi:10.46717/igj.57.2B.19ms-2024-8-29</p><p>2. Javan K, Lialestani MRFH, Nejadhossein M. A comparison of ANN and HSPF models for runoff simulation in Gharehsoo River watershed, Iran. Model Earth Syst Environ. 2015;1: 41. doi:10.1007/s40808-015-0042-1</p><p>3. Vishwakarma DK, Kumar P, Yadav KK, Ali R, Markuna S, Chauhan S, et al. Evaluation of CatBoost Method for Predicting Weekly Pan Evaporation in Subtropical and Sub-Humid Regions. Pure Appl Geophys. 2024;181: 719&#x02013;747. doi:10.1007/s00024-023-03426-4</p><p>4. Elbeltagi A, Al-Mukhtar M, Kushwaha NL, Al-Ansari N, Vishwakarma DK. Forecasting monthly pan evaporation using hybrid additive regression and data-driven models in a semi-arid environment. Appl Water Sci. 2022;13: 42. doi:10.1007/s13201-022-01846-6</p><p>5. Amiri E. Forecasting daily river flows using nonlinear time series models. J Hydrol (Amst). 2015;527: 1054&#x02013;1072. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2015.05.048" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2015.05.048</ext-link></p><p>6. Wang S, Peng H. Multiple spatio-temporal scale runoff forecasting and driving mechanism exploration by K-means optimized XGBoost and SHAP. J Hydrol (Amst). 2024;630: 130650. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2024.130650" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2024.130650</ext-link></p><p>7. Guo J, Liu Y, Zou Q, Ye L, Zhu S, Zhang H. Study on optimization and combination strategy of multiple daily runoff prediction models coupled with physical mechanism and LSTM. J Hydrol (Amst). 2023;624: 129969. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2023.129969" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2023.129969</ext-link></p><p>8. Xu Y, Lin K, Hu C, Wang S, Wu Q, Zhang J, et al. Interpretable machine learning on large samples for supporting runoff estimation in ungauged basins. J Hydrol (Amst). 2024;639: 131598. doi: <ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2024.131598" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2024.131598</ext-link></p><p>9. Wang Y, Wang W, Xu D, Zhao Y, Zang H. A compound approach for ten-day runoff prediction by coupling wavelet denoising, attention mechanism, and LSTM based on GPU parallel acceleration technology. Earth Sci Inform. 2024;17: 1281&#x02013;1299. doi:10.1007/s12145-023-01212-3</p><p>10. Guo H, Chen L, Fang Y, Zhang S. Model and application of annual river runoff prediction based on complementary set empirical mode decomposition combined with particle swarm optimization adaptive neuro-fuzzy system. Water Supply. 2023;23: 1760&#x02013;1774. doi:10.2166/ws.2023.075</p><p>11. Kumar K, Singh V, Roshni T. Application of the PSO&#x02013;neural network in rainfall&#x02013;runoff modeling. Water Pract Technol. 2022;18: 16&#x02013;26. doi:10.2166/wpt.2022.155</p><p>12. Katipo&#x0011f;lu OM, Sar&#x00131;g&#x000f6;l M. Improving the accuracy of rainfall-runoff relationship estimation using signal processing techniques, bio-inspired swarm intelligence and artificial intelligence algorithms. Earth Sci Inform. 2023;16: 3125&#x02013;3141. doi:10.1007/s12145-023-01081-w</p><p>13. Katipo&#x0011f;lu OM, Ye&#x0015f;ilyurt SN, Dalk&#x00131;l&#x00131;&#x000e7; HY, Akar F. Application of empirical mode decomposition, particle swarm optimization, and support vector machine methods to predict stream flows. Environ Monit Assess. 2023;195: 1108. doi:10.1007/s10661-023-11700-0</p><p>14. Hameed MM, Mohd Razali SF, Wan Mohtar WHM, Yaseen ZM. Examining optimized machine learning models for accurate multi-month drought forecasting: A representative case study in the USA. Environmental Science and Pollution Research. 2024. doi:10.1007/s11356-024-34500-6</p><p>15. Hameed MM, Masood A, Srivastava A, Abd Rahman N, Mohd Razali SF, Salem A, et al. Investigating a hybrid extreme learning machine coupled with Dingo Optimization Algorithm for modeling liquefaction triggering in sand-silt mixtures. Sci Rep. 2024;14: 10799. doi:10.1038/s41598-024-61059-6</p><p>15. Alomar MK, Khaleel F, Aljumaily MM, Masood A, Razali SFM, AlSaadi MA, et al. Data-driven models for atmospheric air temperature forecasting at a continental climate region. PLOS ONE. 2022;17: e0277079.</p><p>16. D&#x000f6;ll P, Abbasi M, Messager ML, Trautmann T, Lehner B, Lamouroux N. Streamflow Intermittence in Europe: Estimating High-Resolution Monthly Time Series by Downscaling of Simulated Runoff and Random Forest Modeling. Water Resources Research. 2024;60: e2023WR036900. doi: <ext-link xlink:href="https://doi.org/10.1029/2023WR036900" ext-link-type="uri">https://doi.org/10.1029/2023WR036900</ext-link></p><p>17. Zema DA, Parhizkar M, Plaza-Alvarez PA, Xu X, Lucas-Borja ME. Using random forest and multiple-regression models to predict changes in surface runoff and soil erosion after prescribed fire. Modeling Earth Systems and Environment. 2024;10: 1215&#x02013;1228. doi:10.1007/s40808-023-01838-8</p><supplementary-material id="pone.0321008.s004" position="float" content-type="local-data"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers.docx</named-content></p></caption><media xlink:href="pone.0321008.s004.docx"/></supplementary-material></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0321008.r004" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0321008.r004</article-id><title-group><article-title>Decision Letter 1</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Shicheng</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2025 Shicheng Li</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Shicheng Li</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0321008" id="rel-obj004" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">28 Feb 2025</named-content>
</p><p>Forecasting Monthly Runoff in a Glacierized Catchment: A Comparison of Extreme Gradient Boosting (XGBoost) and Deep Learning Models.</p><p>PONE-D-24-40156R1</p><p>Dear Dr. Salem,</p><p>We&#x02019;re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p><p>Within one week, you&#x02019;ll receive an e-mail detailing the required amendments. When these have been addressed, you&#x02019;ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p><p>An invoice will be generated when your article is formally accepted. Please note, if your institution has a publishing partnership with PLOS and your article meets the relevant criteria, all or part of your publication costs will be covered. Please make sure your user information is up-to-date by logging into Editorial Manager at <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">Editorial Manager&#x000ae;</ext-link> &#x000a0;and clicking the &#x02018;Update My Information' link at the top of the page. If you have any questions relating to publication charges, please contact our Author Billing department directly at authorbilling@plos.org.</p><p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they&#x02019;ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.</p><p>Kind regards,</p><p>Shicheng Li</p><p>Academic Editor</p><p>PLOS ONE</p><p>Additional Editor Comments (optional):</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>--&#x0003e;<bold>Comments to the Author</bold></p><p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#x0201c;Comments to the Author&#x0201d; section, enter your conflict of interest statement in the &#x0201c;Confidential to Editor&#x0201d; section, and submit your "Accept" recommendation.--&#x0003e;</p><p>Reviewer #3:&#x000a0;All comments have been addressed</p><p>Reviewer #4:&#x000a0;All comments have been addressed</p><p>Reviewer #5:&#x000a0;All comments have been addressed</p><p>**********</p><p>--&#x0003e;2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. --&#x0003e;</p><p>Reviewer #3:&#x000a0;(No Response)</p><p>Reviewer #4:&#x000a0;Yes</p><p>Reviewer #5:&#x000a0;Yes</p><p>**********</p><p>--&#x0003e;3. Has the statistical analysis been performed appropriately and rigorously? --&#x0003e;</p><p>Reviewer #3:&#x000a0;(No Response)</p><p>Reviewer #4:&#x000a0;Yes</p><p>Reviewer #5:&#x000a0;Yes</p><p>**********</p><p>--&#x0003e;4. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.--&#x0003e;</p><p>Reviewer #3:&#x000a0;(No Response)</p><p>Reviewer #4:&#x000a0;Yes</p><p>Reviewer #5:&#x000a0;Yes</p><p>**********</p><p>--&#x0003e;5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.--&#x0003e;</p><p>Reviewer #3:&#x000a0;(No Response)</p><p>Reviewer #4:&#x000a0;Yes</p><p>Reviewer #5:&#x000a0;Yes</p><p>**********</p><p>--&#x0003e;6. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)--&#x0003e;</p><p>Reviewer #3:&#x000a0;(No Response)</p><p>Reviewer #4:&#x000a0;As is been already reviewed and all the queries answer by authors successfully. Now it can be published.</p><p>Reviewer #5:&#x000a0;The paper titled &#x0201c;Forecasting Monthly Runoff in a Glacierized Catchment: A Comparison of Extreme Gradient Boosting (XGBoost) and Deep Learning Models&#x0201d; explores monthly runoff forecasting in a glacierized catchment. The authors utilize novel forecasting models along with a robust statistical assessment method, Average Absolute Error of Turning Points (AETP). This study could be a valuable addition to the existing literature. However, there are several issues that should be addressed:</p><p>1. The authors should better emphasize the significance of monthly runoff forecasting for drought and flood monitoring in the Introduction.</p><p>2. In the Results and Discussion, the authors analyze model accuracy only at the monthly and seasonal levels. A more detailed analysis for each month is needed to highlight which months AI models forecast runoff more accurately.</p><p>3. It is advisable to apply combined accuracy metrics rather than relying solely on single statistical measures such as RMSE and MAE to assess model performance more effectively.</p><p>4. The study should include limitations and future recommendations to provide a more comprehensive discussion.</p><p>5. The article could benefit from considering additional recent relevant references in the state-of-the-art analysis on runoff forecasting, such as:</p><p>
<ext-link xlink:href="https://doi.org/10.1016/j.rineng.2024.102104" ext-link-type="uri">https://doi.org/10.1016/j.rineng.2024.102104</ext-link>
</p><p>
<ext-link xlink:href="https://doi.org/10.1007/s00477-024-02760-w" ext-link-type="uri">https://doi.org/10.1007/s00477-024-02760-w</ext-link>
</p><p>
<ext-link xlink:href="https://doi.org/10.1016/j.jhydrol.2024.132175" ext-link-type="uri">https://doi.org/10.1016/j.jhydrol.2024.132175</ext-link>
</p><p>**********</p><p>--&#x0003e;7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link> ). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link> .--&#x0003e;</p><p>Reviewer #3:&#x000a0;No</p><p>Reviewer #4:&#x000a0;<bold>Yes:&#x000a0;</bold> Dr Bibhuti Bhusan Sahoo</p><p>Reviewer #5:&#x000a0;No</p><p>**********</p></body></sub-article><sub-article article-type="editor-report" id="pone.0321008.r005" specific-use="acceptance-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0321008.r005</article-id><title-group><article-title>Acceptance letter</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Shicheng</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2025 Shicheng Li</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Shicheng Li</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0321008" id="rel-obj005" related-article-type="reviewed-article"/></front-stub><body><p>PONE-D-24-40156R1</p><p>PLOS ONE</p><p>Dear Dr. Salem,</p><p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now being handed over to our production team.</p><p>At this stage, our production department will prepare your paper for publication. This includes ensuring the following:</p><p>* All references, tables, and figures are properly cited</p><p>* All relevant supporting information is included in the manuscript submission,</p><p>* There are no issues that prevent the paper from being properly typeset</p><p>If revisions are needed, the production department will contact you directly to resolve them. If no revisions are needed, you will receive an email when the publication date has been set. At this time, we do not offer pre-publication proofs to authors during production of the accepted work. Please keep in mind that we are working through a large volume of accepted articles, so please give us a few weeks to review your paper and let you know the next and final steps.</p><p>Lastly, if your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.</p><p>If we can help with anything else, please email us at customercare@plos.org.</p><p>Thank you for submitting your work to PLOS ONE and supporting open access.</p><p>Kind regards,</p><p>PLOS ONE Editorial Office Staff</p><p>on behalf of</p><p>Dr. Shicheng Li</p><p>Academic Editor</p><p>PLOS ONE</p></body></sub-article></article>