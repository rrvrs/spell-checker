<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Soc Netw Anal Min</journal-id><journal-id journal-id-type="iso-abbrev">Soc Netw Anal Min</journal-id><journal-title-group><journal-title>Social Network Analysis and Mining</journal-title></journal-title-group><issn pub-type="ppub">1869-5450</issn><issn pub-type="epub">1869-5469</issn><publisher><publisher-name>Springer Vienna</publisher-name><publisher-loc>Vienna</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC11861139</article-id><article-id pub-id-type="publisher-id">1327</article-id><article-id pub-id-type="doi">10.1007/s13278-024-01327-5</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Comparing methods for creating a national random sample of twitter users</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Alizadeh</surname><given-names>Meysam</given-names></name><address><email>alizadeh@ipz.uzh.ch</email><uri>https://scholar.google.com/citations?user=FyKst9AAAAAJ&#x00026;hl=en</uri></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zare</surname><given-names>Darya</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Samei</surname><given-names>Zeynab</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Alizadeh</surname><given-names>Mohammadamin</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Kubli</surname><given-names>Mael</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Aliahmadi</surname><given-names>Mohammadhadi</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Ebrahimi</surname><given-names>Sarvenaz</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Gilardi</surname><given-names>Fabrizio</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02crff812</institution-id><institution-id institution-id-type="GRID">grid.7400.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 0650</institution-id><institution>Department of Political Science, </institution><institution>University of Zurich, </institution></institution-wrap>Zurich, Switzerland </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04gzbav43</institution-id><institution-id institution-id-type="GRID">grid.411368.9</institution-id><institution-id institution-id-type="ISNI">0000 0004 0611 6995</institution-id><institution>Department of Computer Engineering, </institution><institution>Amirkabir University of Technology, </institution></institution-wrap>Tehran, Iran </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04xreqs31</institution-id><institution-id institution-id-type="GRID">grid.418744.a</institution-id><institution-id institution-id-type="ISNI">0000 0000 8841 7951</institution-id><institution>Department of Computer Science, </institution><institution>Institute For Research In Fundamental Sciences, </institution></institution-wrap>Tehran, Iran </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04gzbav43</institution-id><institution-id institution-id-type="GRID">grid.411368.9</institution-id><institution-id institution-id-type="ISNI">0000 0004 0611 6995</institution-id><institution>Department of Mathematics and Computer Science, </institution><institution>Amirkabir University of Technology, </institution></institution-wrap>Tehran, Iran </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01jw2p796</institution-id><institution-id institution-id-type="GRID">grid.411748.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 0387 0587</institution-id><institution>Department of Industrial Engineering, </institution><institution>Iran University of Science and Technology, </institution></institution-wrap>Tehran, Iran </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05vf56z40</institution-id><institution-id institution-id-type="GRID">grid.46072.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 0612 7950</institution-id><institution>Faculty of Entrepreneurship, </institution><institution>University of Tehran, </institution></institution-wrap>Tehran, Iran </aff></contrib-group><pub-date pub-type="epub"><day>14</day><month>8</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>14</day><month>8</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2024</year></pub-date><volume>14</volume><issue>1</issue><elocation-id>160</elocation-id><history><date date-type="received"><day>17</day><month>3</month><year>2024</year></date><date date-type="rev-recd"><day>28</day><month>7</month><year>2024</year></date><date date-type="accepted"><day>29</day><month>7</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Twitter data has been widely used by researchers across various social and computer science disciplines. A common aim when working with Twitter data is the construction of a random sample of users from a given country. However, while several methods have been proposed in the literature, their comparative performance is mostly unexplored. In this paper, we implement four common methods to create a random sample of Twitter users in the US: <italic>1% Stream</italic>, <italic>Bounding Box</italic>, <italic>Location Query</italic>, and <italic>Language Query</italic>. Then, we compare these methods according to their tweet- and user-level metrics as well as their accuracy in estimating the US population. Our results show that users collected by the <italic>1% Stream</italic> method tend to have more tweets, tweets per day, followers, and friends, a fewer number of likes, are younger accounts, and include more male users compared to the other three methods. Moreover, it achieves the minimum error in estimating the US population. However, the <italic>1% Stream</italic> method is time-consuming, cannot be used for the past time frames, and is not suitable when user engagement is part of the study. In situation where these three drawbacks are important, our results support the <italic>Bounding Box</italic> method as the second-best method.</p><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at. 10.1007/s13278-024-01327-5.</p></sec></abstract><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100019180</institution-id><institution>HORIZON EUROPE European Research Council</institution></institution-wrap></funding-source><award-id>883121</award-id><award-id>883121</award-id><award-id>883121</award-id><principal-award-recipient><name><surname>Alizadeh</surname><given-names>Meysam</given-names></name><name><surname>Kubli</surname><given-names>Mael</given-names></name><name><surname>Gilardi</surname><given-names>Fabrizio</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution>University of Zurich</institution></funding-source></award-group><open-access><p>Open access funding provided by University of Zurich</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer-Verlag GmbH Austria, part of Springer Nature 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Twitter data have been widely used by researchers across various social and computer sciences disciplines (King et&#x000a0;al. <xref ref-type="bibr" rid="CR18">2017</xref>). One of the key challenges in working with Twitter data is to obtain a random sample of users from a country (Kim et&#x000a0;al. <xref ref-type="bibr" rid="CR17">2018</xref>). The goal is usually to get a platform or population-representative sample of users (Wang et&#x000a0;al. <xref ref-type="bibr" rid="CR29">2019</xref>). The sample is then used for public opinion research, for experimental research, or for training machine learning algorithms. For example, random samples of Twitter users have been used for estimating public opinion (Barber&#x000e1; et&#x000a0;al. <xref ref-type="bibr" rid="CR6">2019</xref>; Alizadeh et&#x000a0;al. <xref ref-type="bibr" rid="CR2">2019</xref>; Alizadeh and Cioffi-Revilla <xref ref-type="bibr" rid="CR1">2014</xref>), studying the diffusion of misinformation (Shao et&#x000a0;al. <xref ref-type="bibr" rid="CR24">2018</xref>), studying conspiracy theories (Batzdorfer et&#x000a0;al. <xref ref-type="bibr" rid="CR8">2022</xref>), evaluating the performance of large language models for text annotation tasks (Alizadeh et&#x000a0;al. <xref ref-type="bibr" rid="CR5">2023</xref>), measuring the influence of information operations (Barrie and Siegel <xref ref-type="bibr" rid="CR7">2021</xref>), and developing supervised models for detecting inauthentic activities (Alizadeh et&#x000a0;al. <xref ref-type="bibr" rid="CR4">2020</xref>). However, there are at least two significant challenges in obtaining a random sample of users from a country: (1) while several methods have been proposed in the literature, it is not clear which one is the best, and (2) the extent to which these random samples are actually representative of the population is questionable.</p><p id="Par3">There are at least four popular methods to construct a random sample of Twitter users for a specific country. First, at the moment of writing, Twitter provides 1% of all tweets worldwide in real-time through its free stream API. One can collect this stream for a specific period of time, even with filtering for language or country of interest, obtain a list of users who posted tweets, and then sample from them. Second, it is possible to use Twitter&#x02019;s search-tweet API and query for a specific language, and after ingesting tweets for a period of time, filter for a language of interest, which matches different countries to different degrees. Third, one can directly query for a country of interest using the Search API. Fourth, the Twitter API allows queries based on the bounding box coordinates enclosing a specific country and researchers used it to get a random sample of a country&#x02019;s Twitter users (e.g. Barrie and Siegel <xref ref-type="bibr" rid="CR7">2021</xref>).</p><p id="Par4">The extent to which these four methods produce similar results, and which one produces a more representative sample of a population, is mostly unexplored. Although Twitter shut off the free access to the API in February 2023, many researchers have archived a wealth of data and still publishing novel research using Twitter data (e.g. Truong et&#x000a0;al. <xref ref-type="bibr" rid="CR25">2024</xref>; Mosleh and Rand <xref ref-type="bibr" rid="CR20">2024</xref>). Moreover, in compliance with the EU&#x02019;s Digital Service Act, Twitter is now accepting researcher API access applications. In this paper, we compare these methods with respect to fourteen metrics at the level of tweets (e.g. distribution of the number of tweets per day), users (e.g. distribution of age and gender), and population. For the population-level metrics, our goal is to investigate which of the four Twitter sampling methods provides the best data for creating a nationally representative sample of users. To this end, we follow the approach proposed in Wang et&#x000a0;al. (<xref ref-type="bibr" rid="CR29">2019</xref>) and create representative samples from each of the four Twitter sampling methods and use them separately to estimate a population of US from Twitter data.</p><p id="Par5">In the following text, we review the theoretical background and related work to highlight the need and importance of comparing various existing Twitter sampling methods. Next, we discuss our methodology to collect Twitter users, exclude non-active, non-individual, and bot-like accounts, infer the age, gender, and location, create nationally-representative samples from them, and compare them according to various evaluation metrics, which we devised from carefully reviewing the literature.</p><p id="Par6">The results show that the <italic>1%Stream</italic> Twitter sampling method is the one that produces the best population-representative sample and which exhibits different characteristics, compared to the other three sampling methods. The results further underscore the <italic>Bounding Box</italic> sampling method as the best replacement for situations under which the <italic>1% Stream</italic> method might not be feasible or suitable. Our results illuminate the positive and negative characteristics of each sampling method and help researchers choose the one that best suits their research goals and designs. By identifying the best sampling methods, our results also pave the way for conducting more accurate social listening studies and building more accurate machine learning models.</p></sec><sec id="Sec2"><title>Related work</title><p id="Par7">Generally speaking, there are two types of methodological approaches to collecting social media data, including Twitter: (1) <italic>keyword-based</italic> approach, and (2) <italic>sample-based</italic> approach. In the keyword-based approach, researchers create a list of hashtags or keywords and collect all matched tweets over a period of time. Although this approach is popular due to its ease of automation, it suffers from some shortcomings (see Kim et&#x000a0;al. <xref ref-type="bibr" rid="CR17">2018</xref> for a discussion). The most crucial drawback of the keyword-based data collection is that most researchers often pick keywords in ad hoc ways that are far from optimal and usually biased (see King et&#x000a0;al. <xref ref-type="bibr" rid="CR18">2017</xref>; Munger et&#x000a0;al. <xref ref-type="bibr" rid="CR21">2022</xref> for potential solutions). Other researchers take the sample-based approach, which is the focus of this study, and try to sample desired tweets or users.</p><p id="Par8">From the tweet sampling perspective, since Twitter has yet to be transparent about how its data sampling is performed, early research on getting data from Twitter data were focused on understanding its underlying mechanisms. Comparing the limited Streaming API with the unlimited but costly Firehose API, Morstatter et&#x000a0;al. (<xref ref-type="bibr" rid="CR19">2013</xref>) tried to answer whether data obtained through Twitter&#x02019;s sampled Streaming API is a sufficient representation of activity on Twitter as a whole. They found that for larger numbers of matched tweets, the Streaming API&#x02019;s coverage is reduced, but its ability to estimate the top hashtags is comparable to the Firehose. Interestingly, the results showed that the Streaming API almost returns the complete set of geotagged tweets despite sampling.</p><p id="Par9">One of the critical questions about the Twitter Streaming API is whether it provides similar results to that of multiple simultaneous API requests from different connections. Joseph et&#x000a0;al. (<xref ref-type="bibr" rid="CR15">2014</xref>) compared samples of tweets collected using the Streaming API that tracked the same set of keywords at the same time. Their results showed that, on average, over 96% of the tweets in various samples are the same. In practice, this means that an infinite number of Streaming API samples are required to collect most of the tweets containing a particular popular keyword (Joseph et&#x000a0;al. <xref ref-type="bibr" rid="CR15">2014</xref>). In another work, Tufekci (<xref ref-type="bibr" rid="CR26">2014</xref>) proposed a framework to address potential biases in tweet collection and how to mitigate them.</p><p id="Par10">More recently, Kim et&#x000a0;al. (<xref ref-type="bibr" rid="CR17">2018</xref>) compared simple daily random sampling with constructed weekly sampling. Their results underscored simple daily random sampling as the efficient way to obtain a representative sample of tweets for a specific period of time. In another important study, Pfeffer et&#x000a0;al. (<xref ref-type="bibr" rid="CR22">2018</xref>) showed that the Streaming API can be deliberately manipulated by adversarial actors due to the nature of Twitter&#x02019;s sampling mechanism. Their results further showed that technical artifacts of the Streaming API can skew tweet samples and therefore those samples should not be regarded as random.</p><p id="Par11">In a distinct investigation, researchers had reverse-engineered the sampling mechanism used by Twitter&#x02019;s Sample API. The sample was based on the timestamp of when tweets arrived at Twitter&#x02019;s servers and any tweet arriving between 657 and 666&#x000a0;ms was included in the 1% Sample API (Pfeffer et&#x000a0;al. <xref ref-type="bibr" rid="CR22">2018</xref>).</p><p id="Par12">In De Choudhury et&#x000a0;al. (<xref ref-type="bibr" rid="CR11">2010</xref>), researchers explored the impact of attribute and topology-based sampling strategies on the discovery of information diffusion in Twitter. The study analyzed several widely-adopted sampling methods that selected nodes based on attributes and topology, and developed metrics based on user activity, topology, and temporal characteristics to evaluate the sample&#x02019;s quality. The results showed that incorporating both network topology and user-contextual attributes significantly improved the estimation of information diffusion by 15&#x02013;20%.</p><p id="Par13">Another research highlighted the lack of common standards for data collection and sampling in the emerging field of digital media and social interactions. The paper focused on Twitter and compared the networks of communication reconstructed using different sampling strategies. The paper concluded that a more careful account of data quality and bias, and the creation of standards that can facilitate the comparability of findings, would benefit the emerging area of research (Gonz&#x000e1;lez-Bail&#x000f3;n et&#x000a0;al. <xref ref-type="bibr" rid="CR13">2014</xref>).</p><p id="Par14">In another work, Wang et&#x000a0;al. (<xref ref-type="bibr" rid="CR28">2015b</xref>) compared the representativeness of two Twitter data samples obtained from the Twitter stream API, Spritzer and Gardenhose, with a more complete Twitter dataset. The study found that both sample datasets capture the daily and hourly activity patterns of Twitter users and provide representative samples of the public tweets, but tend to overestimate the proportion of low-frequency users.</p><p id="Par15">A detailed analysis of the effects of Twitter data sampling on measurement and modeling studies across different timescales and subjects was presented in Wu et&#x000a0;al. (<xref ref-type="bibr" rid="CR30">2020</xref>). It validated the accuracy of Twitter rate limit messages in approximating the volume of missing tweets and identified significant temporal and structural variations in the sampling rates across different scales and entities. They also suggested the use of the Bernoulli process with a uniform rate for counting statistics and provided effective methods for estimating ground-truth statistics.</p><p id="Par16">This paper (Hino and Fahey <xref ref-type="bibr" rid="CR14">2019</xref>) addressed the challenges researchers face in accessing representative and high-quality data from social media platforms like Twitter. The authors proposed a methodology for creating a cost-effective and accessible archive of Twitter data through population sampling, resulting in a highly representative database. The study demonstrated the high degree of representativeness achieved by comparing the sample data with the ground truth of Twitter&#x02019;s full data feed, making it suitable for post-hoc analyses and enabling researchers to refine their keyword searches and collection strategies. Overall, this approach provided an alternative solution for researchers with limited resources to access social media data under resource constraints.</p><p id="Par17">In terms of comparing expert sampling and random sampling, Zafar et&#x000a0;al. (<xref ref-type="bibr" rid="CR33">2015</xref>) explored the advantages and disadvantages of the two methods. The study found that expert sampling offers a number of advantages over random sampling, including more rich information content, trustworthiness, and timely capture of important news and events. However, random sampling preserves the statistical properties of the entire data set and automatically adapts to the growth and changes of the network, while expert sampling does not. The authors suggested that both random and expert sampling techniques would be needed in the future, and called for equal focus on expert sampling of social network data.</p><p id="Par18">From the Twitter user sampling perspective, the most important issue that researchers have tried to tackle is the problem of sampling bias. Indeed, much of the extant literature on sampling users from Twitter is related to pointing out sampling biases in election prediction studies and the necessity to control for it (see Jungherr et&#x000a0;al. <xref ref-type="bibr" rid="CR16">2012</xref> for a discussion and Gayo-Avello <xref ref-type="bibr" rid="CR12">2013</xref> for an early review). More recently, Yang et&#x000a0;al. (<xref ref-type="bibr" rid="CR32">2022</xref>) focused on the issue of inauthentic accounts that could skew the behavior of voters. They proposed a method to identify potential voters on Twitter and compared their behavior with various samples of American Twitter users. The results showed that users sampled from the Streaming API are more active and conservative compared to the potential voters and randomly selected users. They further showed that the users in the Streaming API sample tend to exhibit more inauthentic behaviors, involve in more bot-like activities, and share more links to low-credibility sources.</p><p id="Par19">Although the problem of sampling bias in Twitter has been recognized in many works, none of the papers we discussed above addressed the issue, due to the lack of a valid methodology to do so. In a seminal work, Wang et&#x000a0;al. (<xref ref-type="bibr" rid="CR29">2019</xref>) proposed a method by combining demographic inference with post-stratification to make social media samples a more representative of a population. First, they created a multimodal deep neural network classifier for joint identification of age, gender, and non-individual accounts. Second, they proposed a multilevel logistic regression approach to correct for sampling biases. The proposed debiasing approach estimates inclusion probabilities of users from various demographic groups from inferred joint populations and ground-truth population histograms. They further showed that their fully debiased sample outperforms a baseline and marginally debiased samples in the prediction task of estimating European regions&#x02019; population from Twitter data.</p><p id="Par20">Creating a random sample of Twitter users from a country or geographical region has been cited in some of the research discussed above (e.g. Pfeffer et&#x000a0;al. <xref ref-type="bibr" rid="CR22">2018</xref>; Yang et&#x000a0;al. <xref ref-type="bibr" rid="CR32">2022</xref>). However, no study pointed out the fact that there are several methods for creating such a sample from Twitter users. For example, one can use Streaming API to collect tweets published in a certain country or language and then randomly sample from the list of tweets&#x02019; authors, or just simply use the Search API and query for country or language or both. We identified four such Twitter sampling methods in the literature (plus a fifth one which is not feasible anymore). The extent to which these random (or near-random) sampling methods produce similar results or are more representative of a population is unexplored. In this paper, we attempt to provide answers to the following research questions:<list list-type="bullet"><list-item><p id="Par21">RQ1: Do different methods for creating a random sample of Twitter users from a country produce similar results in terms of the tweet- and user-level metrics?</p></list-item><list-item><p id="Par22">RQ2: Are different methods for creating a random sample of Twitter users from a country produce representative sample of the population? If not, which method provides a more representative sample of the population?</p></list-item></list>To answer these research questions, we collect US Twitter data using four widely-used Twitter user sampling methods for one month and compare the results according to multiple tweet- (e.g. distribution of tweets), user- (e.g. distribution of age and gender), and population-level evaluation metrics. For our population-level metrics, following (Wang et&#x000a0;al. <xref ref-type="bibr" rid="CR29">2019</xref>), we use five different prediction errors for estimating the population of US from Twitter data. The goal of the population-level metrics is to explore which sampling and debiasing methods provide the minimum prediction error, and thus, more representative of the population.</p></sec><sec id="Sec3"><title>Methodology</title><sec id="Sec4"><title>Sampling methods</title><p id="Par23">We use four different Twitter sampling methods (Table <xref rid="Tab1" ref-type="table">1</xref>) that are widely used in the literature to create a random sample of Twitter users in a country. They include (1) <italic>1% Stream</italic>, in which we use Twitter Streaming API to get 1% stream tweets, and filter for languages or country of interest; (2) <italic>Country Query</italic>, in which we query for the country into Twitter Search API and get all tweets; (3) <italic>Language Query</italic>, in which we query for languages that are related to the country of interest and use Twitter Search API same as <italic>Country Query</italic>; and (4) <italic>Bounding Box</italic>, in which we divide a country to multiple small bounding-box coordinates and get all tweets within them by Twitter Search API. There is also a fifth sampling method, in which one could generate random Twitter user IDs, check whether it exists on Twitter, and if they existed, filter to country or language of interest (Barber&#x000e1; et&#x000a0;al. <xref ref-type="bibr" rid="CR6">2019</xref>). However, this method is no longer feasible due to technical changes on Twitter.<xref ref-type="fn" rid="Fn1">1</xref><table-wrap id="Tab1"><label>Table 1</label><caption><p>Four different methods of getting a random sample of users for a country</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">No.</th><th align="left">Method</th><th align="left">Name</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">Streaming API</td><td align="left">Stream 1%</td><td align="left">Get 1% stream tweets for a month, filter for potential country field</td></tr><tr><td align="left">2</td><td align="left">Country Query</td><td align="left">Loc</td><td align="left">Query for the country and get all tweets for a month</td></tr><tr><td align="left">3</td><td align="left">Language Query</td><td align="left">Lang</td><td align="left">Query for relevant languages and the country and get all tweets for a month</td></tr><tr><td align="left">4</td><td align="left">Bounding Box</td><td align="left">BB</td><td align="left">Divide a country to multiple small bounding-box coordinates and get all tweets within them for a month</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec5"><title>Data</title><p id="Par25">We used Twitter&#x02019;s V2 API to collect tweets over a month (i.e. from 2022-09-07 to 2022-10-08). As a first method, we used the sampled Streaming API. This is the simplest method that returns 1 % of all tweets during the listening period, but it generates the most amount of noise as well. For the second method, we used Twitter Search API and collected tweets posted in the United States by setting the filter argument as <italic>place_country:US</italic>. For the third method, we used the same endpoint as the second one but filtered tweets based on English language and US country by setting the filter argument as <italic>lang:en</italic> and <italic>place_country:US</italic>. As for the fourth method, we used the bounding boxes available in the Twitter Search API, which uses the coordinates of a specific area. The bounding boxes are limited in size (25 miles in height and width) and their form (rectangular). To mitigate the limitations of the bounding boxes, we implemented a grid of small boxes plotted over the US, with points defined by a longitudinal and latitudinal distance of 0.3<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{\circ }$$\end{document}</tex-math><mml:math id="M2"><mml:mmultiscripts><mml:mrow/><mml:mrow/><mml:mo>&#x02218;</mml:mo></mml:mmultiscripts></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq1.gif"/></alternatives></inline-formula>. We also included points along the borders of the countries by shifting the points diagonally up and down for one unit. This resulted in a comprehensive approximation of the United States, represented by 9,541 bounding boxes. In summary, Our research scope focuses on Twitter users in the United States. However, we applied certain query parameters in all four methods to narrow down our user selection within this context. It&#x02019;s important to note that we did not use any specific keywords or hashtags that could potentially introduce bias towards any particular topic.</p></sec><sec id="Sec6"><title>User pre-processing</title><p id="Par26">Following the data collection, the next step involves the pre-processing of accounts. Typically, when we generate a random sample of Twitter users from a specific country, our goal is to obtain a sample consisting of authentic individuals rather than organizations or malicious accounts like bots. This is important as the inclusion of such accounts could introduce bias into our sample (Yang et&#x000a0;al. <xref ref-type="bibr" rid="CR32">2022</xref>). To achieve this, we selected a random sample of 30K users from each dataset associated with each of the four Twitter sampling methods. This equalizes the dataset sizes and facilitates a more accurate comparison of changes in data volume after applying each pre-processing filter. From the initial sample of 30K randomly selected users, we applied several filters to exclude specific categories, including bots [identified using botometer (Yang et&#x000a0;al. <xref ref-type="bibr" rid="CR31">2022</xref>)], verified accounts, protected accounts, low-activity accounts (those with fewer than 100 tweets), recently created accounts (less than 9 months old), and suspended accounts (as detailed in Table <xref rid="Tab2" ref-type="table">2</xref>). Additionally, we eliminated accounts whose bios contain keywords such as "journalist," "magazine," "member," "organization," "mayor," "actress," etc., as outlined in Table <xref rid="Tab2" ref-type="table">2</xref>. This step ensures that our sample comprises regular individuals rather than celebrities or organizational accounts. Lastly, we excluded users whose tweet language is not English and those whose tweet coordinates did not correspond to locations in the United States.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Pre-processing steps for twitter users</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">No.</th><th align="left">Filter</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">Verified</td><td align="left">Exclude Twitter accounts that have been verified by Twitter</td></tr><tr><td align="left">2</td><td align="left">Activity</td><td align="left">Exclude users who have posted fewer than 100 tweets during their life time on Twitter</td></tr><tr><td align="left">3</td><td align="left">Tenure</td><td align="left">Exclude users who have created their accounts within the nine months leading up to the data collection</td></tr><tr><td align="left">4</td><td align="left">Biography</td><td align="left">Exclude users whose bios contain any of the following terms: journalist, anchor, newspaper, representative, congressman, congresswoman, senator, secretary, mayor, organization, organization, company, institute, charity, magazine, singer, bot, member, advisory, advisor, startup, venture, news, actor, actress, official page</td></tr><tr><td align="left">5</td><td align="left">Language</td><td align="left">Exclude users from the USA samples whose tweets are not in the English language</td></tr><tr><td align="left">6</td><td align="left">Country</td><td align="left">Exclude users whose tweets are not geotagged to locations within the United States</td></tr><tr><td align="left">7</td><td align="left">Protected</td><td align="left">Exclude users whose accounts are set to "protected" status at the time of analysis</td></tr><tr><td align="left">8</td><td align="left">Suspended</td><td align="left">Exclude users whose accounts are suspended or deleted at the time of analysis</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec7"><title>Inferring users&#x02019; demographics</title><p id="Par27">We utilized the M3 model (Wang et&#x000a0;al. <xref ref-type="bibr" rid="CR29">2019</xref>), which is a multimodal deep learning model, to predict the gender and age of Twitter users. This model functions across 32 languages and relies solely on users&#x02019; profile details, including their <italic>screen_name</italic>, <italic>user_name</italic>, <italic>bio</italic>, and <italic>profile picture</italic>. The M3 model offers two modes, and we employed the &#x02019;full&#x02019; model, which is more accurate and incorporates the profile image. In addition to gender and age, the model also discerns whether a Twitter account belongs to an organization. Consequently, we excluded organizational accounts from our dataset. Regarding location, we followed established research practices by utilizing self-reported user location or information from their close connections to estimate the users&#x02019; locations at the state level (Barber&#x000e1; et&#x000a0;al. <xref ref-type="bibr" rid="CR6">2019</xref>).</p></sec><sec id="Sec8"><title>Creating representative population estimates</title><p id="Par28">In this step, we&#x02019;ve inferred all the necessary features, enabling us to create our sample. We&#x02019;ve selected all the valid users that have passed through the previous filters, resulting in our final 10K samples for each method. From this point forward, we will use this 10K-sample dataset for our analysis. Previous research has demonstrated that when demographic information is available, and proper statistical adjustments like re-weighting and post-stratification are applied, non-representative polls can still yield accurate population estimates (Wang et&#x000a0;al. <xref ref-type="bibr" rid="CR27">2015a</xref>). The primary demographic characteristics that survey analysts focus on to address non-representativeness are age, gender, and location (Wang et&#x000a0;al. <xref ref-type="bibr" rid="CR29">2019</xref>). We follow the approach introduced in (Wang et&#x000a0;al. <xref ref-type="bibr" rid="CR29">2019</xref>) to learn inclusion probabilities based on users&#x02019; demographics. This method utilizes multilevel regression techniques to estimate the likelihood of an individual with specific demographics being present on a particular platform. It does this by considering inferred joint population counts and ground-truth population data. To implement this approach, we require gender, age, and geographic location information for each Twitter user, along with ground-truth data about the population. In the case of the United States, we rely on census data as our ground truth).<xref ref-type="fn" rid="Fn2">2</xref></p></sec><sec id="Sec9"><title>Evaluation metrics</title><p id="Par30">We compare the results of each method to create a nationally-random sample of Twitter users according to three categories of metrics including (1) tweet-level (Table <xref rid="Tab3" ref-type="table">3</xref>), (2) account-level (Table <xref rid="Tab3" ref-type="table">3</xref>), and (3) population-level metrics (Table <xref rid="Tab4" ref-type="table">4</xref>). Tweet-level metrics include total number of tweets generated by each sampling method, average number of tweets collected from each account, and share of English tweets. User-level metrics encompass various aspects, including: Total number of unique users, Distribution of tweet counts for accounts, considering the correlation between tweet count and account age, Distribution of the average tweet count, calculated by dividing the tweet count by the account&#x02019;s age in days, Distribution of the number of likes received by the last tweet of each user, Distribution of account creation dates, Distribution of the number of followers and friends by each user, and Distribution of age and gender among users.<table-wrap id="Tab3"><label>Table 3</label><caption><p>List of evaluation criteria for comparing various methods of creating a national-sample of Twitter users from tweet and account aspects</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Category</th><th align="left">Criteria</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left" rowspan="3">Tweet-level</td><td align="left">Number of tweets</td><td align="left">Total number of collected tweets</td></tr><tr><td align="left">Average tweet per account</td><td align="left">Average number of tweets per account</td></tr><tr><td align="left">Relevant language</td><td align="left">Share of tweets in country-specific languages</td></tr><tr><td align="left" rowspan="8">Account-level</td><td align="left">Number of accounts</td><td align="left">Number of unique accounts</td></tr><tr><td align="left">Distribution of tweet count</td><td align="left">Distribution of total number of tweets for each account</td></tr><tr><td align="left">Distribution of average tweet count</td><td align="left">The distribution of tweets per day is calculated as the total tweet count for each account, divided by the age of the account</td></tr><tr><td align="left">Distribution of likes</td><td align="left">For each account, distributions of the number of last tweets&#x02019; likes</td></tr><tr><td align="left">Account creation date</td><td align="left">Distributions of account creation date</td></tr><tr><td align="left">Distribution of followers</td><td align="left">Distributions of the numbers of followers</td></tr><tr><td align="left">Distribution of friends</td><td align="left">Distributions of the numbers of friends</td></tr><tr><td align="left">Distribution of age and gender</td><td align="left">Distribution of gender and age categories</td></tr></tbody></table></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>List of evaluation criteria for comparing various methods of creating a national-sample of Twitter users from population aspect</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Category</th><th align="left">Criteria</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left" rowspan="5">Population-level</td><td align="left">MAPE where N <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim $$\end{document}</tex-math><mml:math id="M4"><mml:mo>&#x0223c;</mml:mo></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq2.gif"/></alternatives></inline-formula> M</td><td align="left">Base model that uses only the total population count from the census (N) and Twitter (M)</td></tr><tr><td align="left">MAPE where N <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum _g$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq3.gif"/></alternatives></inline-formula> M(g)</td><td align="left">Uses gender marginal counts only</td></tr><tr><td align="left">MAPE where N <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum _a$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq4.gif"/></alternatives></inline-formula> M(a)</td><td align="left">Uses age marginal counts only</td></tr><tr><td align="left">MAPE where N <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum _{a,g}$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq5.gif"/></alternatives></inline-formula> M(a, g)</td><td align="left">Uses the joint distributions inferred from Twitter but only the total population counts from the census</td></tr><tr><td align="left">MAPE where log N(a, g) <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim $$\end{document}</tex-math><mml:math id="M12"><mml:mo>&#x0223c;</mml:mo></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq6.gif"/></alternatives></inline-formula> log M(a, g) + a + g</td><td align="left">Uses the joint distributions inferred from Twitter and the joint histograms from the census</td></tr></tbody></table></table-wrap></p><p id="Par31">For the population-level metric, our objective is to determine which of the four Twitter sampling methods is most effective for generating a nationally representative sample of users. To achieve this, we adopt a test outlined in Wang et&#x000a0;al. (<xref ref-type="bibr" rid="CR29">2019</xref>) and employ the representative samples detailed in Sect.&#x000a0;<xref rid="Sec7" ref-type="sec">Inferring users&#x02019; demographics</xref> to estimate the overall population of the United States based on Twitter data. In essence, we conduct a regression analysis that correlates the actual population sizes of various areas within the United States (such as states, divisions, or regions) with the number of American Twitter users from different age and gender groups in those specific locations. This analysis helps us assess the representativeness of the Twitter data for estimating the US population.</p><p id="Par32">In a more detailed breakdown, we compare five distinct models that rely on different data sources and operate under different assumptions. The first model (N <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim $$\end{document}</tex-math><mml:math id="M14"><mml:mo>&#x0223c;</mml:mo></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq7.gif"/></alternatives></inline-formula> M) serves as the baseline and utilizes solely the total population count obtained from the census data along with Twitter user data, without applying any debiasing coefficients. The subsequent three models are grounded on the assumption of homogeneous inclusion probabilities: The second model (N <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum _g$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq8.gif"/></alternatives></inline-formula> M(g)) uses only gender-specific marginal counts. The third model (N <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum _g$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq9.gif"/></alternatives></inline-formula> M(a)) uses only age-specific marginal counts. The fourth model (N <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum _{a,g}$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq10.gif"/></alternatives></inline-formula> M(a, g)) employs the joint distribution inferred from Twitter data alongside the total population counts from the census data. Finally, the fifth model (log N(a, g) <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim $$\end{document}</tex-math><mml:math id="M22"><mml:mo>&#x0223c;</mml:mo></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq11.gif"/></alternatives></inline-formula> log M(a, g) + a + g) leverages the joint distribution inferred from both Twitter data and census data. For each of these five prediction tasks, we assess their performance using the mean absolute percentage errors (MAPE) evaluation metric, calculated as specified in Eq.&#x000a0;<xref rid="Equ1" ref-type="disp-formula">1</xref>. In this equation, <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{N}}_i$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq12.gif"/></alternatives></inline-formula> represents the predicted population size, <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_i$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq13.gif"/></alternatives></inline-formula> is the actual population size, and the summation is performed over all geographical units of interest, such as states, regions, or divisions in the United States.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} MAPE(N) = \frac{100\%}{n} \sum _i^{Geo.} \frac{|{\hat{N}}_i - N_i|}{|N_i|} \end{aligned}$$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>100</mml:mn><mml:mo>%</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>e</mml:mi><mml:mi>o</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="13278_2024_1327_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p></sec></sec><sec id="Sec10"><title>Results</title><p id="Par33">The following subsections provide a detailed presentation of our results by comparing the four Twitter sampling methods. First, we present essential statistics regarding the outcomes of each sampling method. Second, in accordance with the methodology outlined in Sect.&#x000a0;<xref rid="Sec6" ref-type="sec">User pre-processing</xref>, we randomly sample 30K accounts from the output of each sampling method. Subsequently, we apply pre-processing filters and select a random sample of 10K users from the remaining pool. We then report the metrics at both tweet- and user-levels for this subset. Lastly, we generate debiased samples from each 10K random sample by computing inclusion probabilities. We compare their mean absolute percentage errors (MAPE) for the task of estimating the United States population using Twitter data.</p><sec id="Sec11"><title>Tweet-level and user-level metrics</title><p id="Par34">In Table <xref rid="Tab5" ref-type="table">5</xref>, we provide a comparison of various tweet-level metrics across the four Twitter sampling methods employed to create random user samples from a country. These metrics include the number of tweets, the count of unique users, the average number of tweets per account, and the percentage of tweets in English. The results show that the <italic>bounding box</italic> (BB) and <italic>location query</italic> (Loc) sampling methods produce a significantly higher number of tweets compared to the <italic>language query</italic> (Lang) and <italic>1% steam</italic> methods. Among the four Twitter sampling methods, BB and Loc methods produce more than 18 million tweets, whereas the Lang and 1% stream methods generate 4.5 million and 174,000 tweets, respectively, within the same timeframe. The same pattern is observed when examining the number of unique users and the average tweets per account metrics, except that the difference between BB and Loc methods and Lang method is notably smaller than their difference in the number of tweets. This suggests that the BB and Loc methods have a higher rate of account duplication compared to the other two sampling methods. Lastly, among the three methods that do not explicitly filter for language, the BB method has a higher proportion of English tweets.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Statistics of the number of tweets and users collected by each sampling method</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">BB</th><th align="left">Loc</th><th align="left">Lang</th><th align="left">1%</th></tr></thead><tbody><tr><td align="left">Number of tweets</td><td align="left">18,181,424</td><td align="left">18,804,550</td><td align="left">4,508,702</td><td align="left">174,084</td></tr><tr><td align="left">Number of accounts</td><td align="left">728,028</td><td align="left">738,595</td><td align="left">425,041</td><td align="left">94,250</td></tr><tr><td align="left">Average tweets per account</td><td align="left">24.974</td><td align="left">25.46</td><td align="left">10.608</td><td align="left">1.847</td></tr><tr><td align="left">Ratio of tweets in English</td><td align="left">0.823</td><td align="left">0.808</td><td align="left">1</td><td align="left">0.807</td></tr></tbody></table></table-wrap></p><p id="Par35">Due to the computational expense of bot detection and age, gender, and location inferences, our aim is to compare a random sample of 10K users from each Twitter sampling method. To ensure that we have at least 10K users from each method after applying pre-processing steps, we initially select a random sample of 30K users from each Twitter sampling method. We then execute all pre-processing steps on this larger sample and subsequently select a random sample of 10K users from the remaining pool. The table in Table <xref rid="Tab6" ref-type="table">6</xref> provides information about the number of accounts that have been removed after each filter has been applied to the 30K-sample.<table-wrap id="Tab6"><label>Table 6</label><caption><p>Number of accounts removed by each filtering method in USA 30K samples</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Filter method</th><th align="left" colspan="4">Number of accounts removed due to each filter</th></tr><tr><th align="left">BB</th><th align="left">Loc</th><th align="left">Lang</th><th align="left">1%</th></tr></thead><tbody><tr><td align="left">Verified accounts</td><td align="left">792</td><td align="left">705</td><td align="left">744</td><td align="left">862</td></tr><tr><td align="left">Accounts with less than 100 tweets</td><td align="left">3971</td><td align="left">3991</td><td align="left">2650</td><td align="left">1268</td></tr><tr><td align="left">Accounts with less than 9 month age</td><td align="left">830</td><td align="left">764</td><td align="left">928</td><td align="left">1073</td></tr><tr><td align="left">Accounts has keywords in description</td><td align="left">793</td><td align="left">675</td><td align="left">719</td><td align="left">768</td></tr><tr><td align="left">Non-English accounts</td><td align="left">4610</td><td align="left">4433</td><td align="left">0</td><td align="left">5004</td></tr><tr><td align="left">Non-US accounts accounts</td><td align="left">92</td><td align="left">0</td><td align="left">0</td><td align="left">0</td></tr></tbody></table></table-wrap></p><p id="Par36">The comparison results of tweet- and user-level metrics are reported in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> and Tables <xref rid="Tab7" ref-type="table">7</xref> and <xref rid="Tab8" ref-type="table">8</xref>, and the corresponding <italic>t</italic>-test results are illustrated in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. More specifically, the distributions of the total number of tweets are presented in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>a. Notably, the <italic>1% stream</italic> method generates more tweets (<italic>M</italic> = 19,873.9, <italic>p</italic> = 0.00) compared to the other methods (see Table <xref rid="Tab7" ref-type="table">7</xref> and Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). Additionally, since the number of generated tweets depends on account age, we also depict the distributions of the number of tweets per day in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>b. This metric is calculated by dividing a user&#x02019;s total number of tweets by the number of days since their account creation. Once again, we observe that users from the <italic>1% stream</italic> method tend to tweet more frequently (M = 5.81, <italic>p</italic> = 0.00) than those from other methods (see Table <xref rid="Tab7" ref-type="table">7</xref>). We have also conducted a comparison of the number of likes across the four Twitter sampling methods and have depicted the corresponding distributions in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>c. It&#x02019;s worth noting that the <italic>BB</italic>, <italic>Loc</italic>, and <italic>Lang</italic> methods exhibit nearly identical distributions. However, users sampled from the <italic>1% stream</italic> method tend to have significantly fewer likes (M = 0.00, <italic>p</italic> = 0.00). This discrepancy is primarily attributed to the fact that the <italic>1% stream</italic> method collects data in real-time, often when engagements with posts have just commenced. This is in contrast to the other methods, which may include tweets posted up to the past seven days, allowing for more time for engagements to accumulate. Additionally, we present the distributions of account creation times in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>d. Across all methods, we notice a peak around the year 2009, likely reflecting the rapid growth of Twitter during that period (Yang et&#x000a0;al. <xref ref-type="bibr" rid="CR32">2022</xref>). There is also an increase in the number of created accounts in 2011, coinciding with a period of significant user growth on Twitter.<xref ref-type="fn" rid="Fn3">3</xref> In comparison to other methods, the <italic>1% stream</italic> method appears to generate more younger accounts (<italic>p</italic> = 0.00), specially those that were created in 2022. However, for the remaining time period, the distributions appear similar across all four methods.</p><p id="Par38">Figures <xref rid="Fig1" ref-type="fig">1</xref>e and f display the distributions of the numbers of followers and friends, respectively. These figures illustrate that users in the <italic>1% stream</italic> method tend to have slightly more followers (M = 911.3, <italic>p</italic> = 0.00) and friends (M = 1059.6, <italic>p</italic> = 0.00) compared to users in the other sampling methods (see Table <xref rid="Tab8" ref-type="table">8</xref> and Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). Interestingly, in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>f, it becomes evident that nearly half of the users in the <italic>1% stream</italic> sample have over 1000 friends. Moreover, the <italic>1% method</italic> exhibits a higher number of accounts with approximately 5000 friends or more. It&#x02019;s worth noting that the peak around 5000 friends in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>f is attributed to a Twitter anti-abuse limitation, which stipulates that an account cannot follow more than 5000 friends unless it has more than 5000 followers.<xref ref-type="fn" rid="Fn4">4</xref> This policy leads to the observed distribution pattern.<fig id="Fig1"><label>Fig. 1</label><caption><p>Distributions of <bold>a</bold> number of tweets; <bold>b</bold> average number of tweets per day; <bold>c</bold> number of likes; <bold>d</bold> account creation date; <bold>e</bold> number of followers; and <bold>f</bold> number of friends for different groups. Distribution of users with respect to <bold>g</bold> gender and <bold>h</bold> age across the four Twitter sampling methods</p></caption><graphic xlink:href="13278_2024_1327_Fig1_HTML" id="MO1"/></fig><fig id="Fig2"><label>Fig. 2</label><caption><p>Heatmap of <italic>P</italic> values for Pairwise T-tests of <bold>a</bold> number of tweets; <bold>b</bold> average number of tweets per day; <bold>c</bold> number of likes; <bold>d</bold> account creation date; <bold>e</bold> number of followers; and <bold>f</bold> number of friends across the four Twitter sampling methods</p></caption><graphic xlink:href="13278_2024_1327_Fig2_HTML" id="MO2"/></fig></p><p id="Par40">As outlined in Sect.&#x000a0;<xref rid="Sec7" ref-type="sec">Inferring users&#x02019; demographics</xref>, age, gender, and location are critical demographics for constructing a nationally-representative sample of individuals. Consequently, it is essential to compare the user samples generated by each sampling method in terms of these three metrics. Figure&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> displays the distributions of age and gender across the four Twitter sampling methods. When examining gender distributions (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>g), two notable observations emerge: (1) All four methods yield unbalanced gender data, with a majority of users (over 64%) being male, (2) The <italic>1% stream</italic> method produces slightly fewer women compared to the other three methods, which generate a nearly equal fraction of women.</p><p id="Par41">Regarding the age (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>h), the percentage of users who are under 18 or over 40 is nearly identical across all methods. However, there is a significant difference for the 19&#x02013;29 and 30&#x02013;39 age cohorts in the <italic>1% stream</italic> method. While the other three methods generate approximately 27% of users in both the 19&#x02013;29 and 30&#x02013;39 age groups, the <italic>1% stream</italic> method has only 18% of users in the 19&#x02013;29 cohort and 35% in the 30&#x02013;39 cohort, indicating a notable deviation.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Average and standard deviation of the number of tweets and likes across the four Twitter sampling methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="2">Number of tweets</th><th align="left" colspan="2"> Average tweet count</th><th align="left" colspan="2">Number of likes</th></tr><tr><th align="left"/><th align="left">Mean</th><th align="left">Std</th><th align="left">Mean</th><th align="left">Std</th><th align="left">Mean</th><th align="left">Std</th></tr></thead><tbody><tr><td align="left">BB</td><td align="left">10,370.6</td><td align="left">23,388.4</td><td align="left">2.97</td><td align="left">6.86</td><td align="left">3.73</td><td align="left">36.44</td></tr><tr><td align="left">Loc</td><td align="left">10,235.9</td><td align="left">22,028.5</td><td align="left">2.96</td><td align="left">6.31</td><td align="left">3.40</td><td align="left">43.70</td></tr><tr><td align="left">Lang</td><td align="left">12,210.7</td><td align="left">23,731.2</td><td align="left">3.59</td><td align="left">7.53</td><td align="left">4.07</td><td align="left">52.05</td></tr><tr><td align="left">1%Stream</td><td align="left">19,873.9</td><td align="left">34,870.5</td><td align="left">5.81</td><td align="left">9.92</td><td align="left">0.00</td><td align="left">0.04</td></tr></tbody></table></table-wrap><table-wrap id="Tab8"><label>Table 8</label><caption><p>Average and standard deviation of the number of followers and friends across the four Twitter sampling methods</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="4">Number of followers Number of friends</th></tr><tr><th align="left"/><th align="left">Mean</th><th align="left">Std</th><th align="left">Mean</th><th align="left">Std</th></tr></thead><tbody><tr><td align="left">BB</td><td align="left">683.6</td><td align="left">869.3</td><td align="left">804.2</td><td align="left">913.9</td></tr><tr><td align="left">Loc</td><td align="left">668.1</td><td align="left">849.7</td><td align="left">795.6</td><td align="left">902.4</td></tr><tr><td align="left">Lang</td><td align="left">712.4</td><td align="left">888.7</td><td align="left">870.1</td><td align="left">966.2</td></tr><tr><td align="left">1% Stream</td><td align="left">911.3</td><td align="left">989.9</td><td align="left">1059.6</td><td align="left">1060.2</td></tr></tbody></table></table-wrap></p><p id="Par42">Finally, in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, we present the distribution of the number of users located in each state within the United States. As discussed in Sect.&#x000a0;<xref rid="Sec7" ref-type="sec">Inferring users&#x02019; demographics</xref>, we adopted the methodology proposed in Barber&#x000e1; et&#x000a0;al. (<xref ref-type="bibr" rid="CR6">2019</xref>) to estimate the location of Twitter users at the US state level. In general, the distribution pattern is highly similar across all four Twitter sampling methods, with no significant variations between them. As expected, states with larger populations such as California, New York, Texas, and Florida have a higher number of Twitter users. Additionally, within our 10K-user sample, all four sampling methods managed to provide at least one user from each state, ensuring a diverse geographical representation.<fig id="Fig3"><label>Fig. 3</label><caption><p>Map of the number of users located in US states. All four sampling methods produced at least one user in all 50 US states</p></caption><graphic xlink:href="13278_2024_1327_Fig3_HTML" id="MO3"/></fig></p></sec><sec id="Sec12"><title>Population-level metrics</title><p id="Par43">The objective of this section is to assess the accuracy of the four debiased samples created from the four Twitter sampling methods in predicting the population of the United States using Twitter data. This prediction task is conducted at the state level, which necessitates having a sufficient number of users for all age and gender groups in all 50 US states. However, despite all four sampling methods providing at least one user in each state (as shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>), none of them yielded enough data to cover all combinations of age and gender across all US states. Table <xref rid="Tab9" ref-type="table">9</xref> provides information on the number of US states where there are insufficient users to represent all age and gender groups, across different sample sizes (i.e., 5K, 8K, or 10K users) and Twitter sampling methods. As indicated in Table <xref rid="Tab9" ref-type="table">9</xref>, even with a sample size of 10K users, there are still between 7 and 11 states lacking at least one demographic group (e.g., women aged 30&#x02013;39 in the State of New York).<table-wrap id="Tab9"><label>Table 9</label><caption><p>Number of US states that Twitter sampling methods did not generate enough users in all demographics groups</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sampling method</th><th align="left">5K Sample</th><th align="left">8K Sample</th><th align="left">10K Sample</th></tr></thead><tbody><tr><td align="left">1% Stream</td><td align="left">14</td><td align="left">12</td><td align="left">10</td></tr><tr><td align="left">BB</td><td align="left">13</td><td align="left">8</td><td align="left">8</td></tr><tr><td align="left">Loc</td><td align="left">15</td><td align="left">8</td><td align="left">7</td></tr><tr><td align="left">Lang</td><td align="left">17</td><td align="left">12</td><td align="left">11</td></tr></tbody></table></table-wrap></p><p id="Par44">In our regression model for estimating the US population from Twitter data, each row corresponds to a specific demographic group within a particular state (e.g., men above 40 in New Jersey). If any demographic group is absent in the Twitter data for a specific state, all values in the corresponding row of the regression model would be zeros. However, it&#x02019;s important to note that no state has all demographic groups missing. Consequently, we made the decision to remove rows with all-zero values from our regression model. This led to the removal of 16 rows (3.92%) from the <italic>bounding-box</italic> sample, 12 rows (2.94%) from the <italic>Country Query</italic> sample, 16 rows (3.92%) from the <italic>Language Query</italic> sample, and 21 rows (5.15%) from the <italic>1% Stream</italic> sample. It&#x02019;s worth mentioning that all of these samples consist of an equal size of 10K users each.</p><p id="Par45">Following the approach outlined in Wang et&#x000a0;al. (<xref ref-type="bibr" rid="CR29">2019</xref>), we assess the accuracy of the four representative samples using a leave-one-state-out cross-validation framework. In this evaluation, we calculate the mean absolute percentage error (MAPE) for the population estimates of the state that is left out of the analysis. The MAPE is computed using the formula specified in Eq.&#x000a0;<xref rid="Equ1" ref-type="disp-formula">1</xref>. As mentioned in Table <xref rid="Fig1" ref-type="fig">1</xref>, we calculate MAPE under five different scenarios. These scenarios encompass a baseline model that relies solely on the total population without the use of debiasing coefficients. Additionally, there are three models based on homogeneity, which consider whether to include both age and gender or only one of these variables. Lastly, there is a full model that takes into account heterogeneity by including both age and gender as factors in the analysis.</p><p id="Par46">In Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, we observe that the results of the leave-one-state-out evaluation show a benefit to using the <italic>1% Stream</italic> Twitter sampling method. Across all five debiasing models, the <italic>1% Stream</italic> seems to achieve the minimum and the <italic>Language Query</italic> method achieves the maximum prediction error. For the N <inline-formula id="IEq14"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim $$\end{document}</tex-math><mml:math id="M30"><mml:mo>&#x0223c;</mml:mo></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq14.gif"/></alternatives></inline-formula> M model, which is a baseline that does not use any debiasing, the <italic>1% Stream</italic> method achieves MAPE of 27%, which is the least compared to <italic>BB</italic>, <italic>Loc</italic>, and <italic>Lang</italic>, which achieved MAPE of 33%, 39%, and 45%, respectively. The inclusion of the inferred age in the debiasing models N <inline-formula id="IEq15"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum $$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mo>&#x02211;</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq15.gif"/></alternatives></inline-formula> M (a) decreases MAPE of the <italic>1% Stream</italic> method to 21%, which again is the minimum among the <italic>BB</italic> (26%), <italic>Loc</italic> (25%), and <italic>Lang</italic> (31%) methods. The inclusion of the inferred gender in the debiasing models N <inline-formula id="IEq16"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum $$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mo>&#x02211;</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq16.gif"/></alternatives></inline-formula> M (g) decreases the MAPE of the <italic>1% Stream</italic> method, but not as big as the inclusion of the age. Nonetheless, the <italic>1% Stream</italic> sample shows the minimum prediction error with MAPE of 25% (the <italic>BB</italic>, <italic>Loc</italic>, and <italic>Lang</italic> methods obtained MAPE of 27%, 30%, and 41% respectively). Same pattern holds true for N <inline-formula id="IEq17"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim \sum $$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mo>&#x0223c;</mml:mo><mml:mo>&#x02211;</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq17.gif"/></alternatives></inline-formula> M (a, g) and logN(a,g) <inline-formula id="IEq18"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim $$\end{document}</tex-math><mml:math id="M38"><mml:mo>&#x0223c;</mml:mo></mml:math><inline-graphic xlink:href="13278_2024_1327_Article_IEq18.gif"/></alternatives></inline-formula> logM(a,g) + a + g models. Moreover, the results show that even the baseline model of the <italic>1% Stream</italic> sample outperforms the other three sampling methods in all five modelling scenarios.<fig id="Fig4"><label>Fig. 4</label><caption><p>Performance on leave one state out population inference across different debiasing models where rows with all zero value were removed from the regression. The bar shows MAPE(<italic>N</italic>) robust standard errors clustered on states</p></caption><graphic xlink:href="13278_2024_1327_Fig4_HTML" id="MO4"/></fig></p></sec><sec id="Sec13"><title>Robustness tests</title><p id="Par47">To ensure that the observed results are not the artifact of our regression settings, in which we removed the rows with all zero values, or artifact of our pre-processing decisions, we replicate the results of Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> for the following scenarios: (1) including the District of Columbia to the 50 states and remove rows with zero values in the regression model (see Fig.&#x000a0;S1 in Appendix), (2) removing all states that their Twitter data are missing at least one demographic group from the Twitter and census data and measure MAPE for the remaining states (see Fig.&#x000a0;S2 in Appendix), (3) aggregate data at the nine US divisions (the U.S. Census Bureau groups the 50 states and the District of Columbia into four geographic regions and nine divisions based on geographic proximity,<xref ref-type="fn" rid="Fn5">5</xref>) which results in no missing demographic group at all nine divisions (see Fig.&#x000a0;S3 in Appendix), (4) removing users with less than 200 tweets in the pre-processing step instead of the original 100 tweet threshold (note that due the recent restrictions imposed on Twitter API, we are not able to test the lower threshold because it will produce new users, for which, we cannot obtain bot score, age, gender, and location) (see Figs.&#x000a0;S4 and S5 in Appendix), and 5) removing users with the age of less than one year instead of the 9 month threshold (see Figs.&#x000a0;S6 and S7 in Appendix).</p><p id="Par49">Across all of these five robustness tests, the overall qualitative patterns of the comparison between the four Twitter sampling methods remain the same, with the <italic>1% Stream</italic> sampling method obtaining the minimum prediction error on the US population inference task. Interestingly, for the leave-one-division-out cross-validation setting, we see that the error rates drop nearly in half across the four sampling methods and five population inference tasks (Fig.&#x000a0;S3). This error reduction suggests that knowledge of the nine US division specific platform biases is more important than the state-specific ones for accurate estimates of the country population. In other words, to achieve a good performance, a model at least need to be exposed to some divisions within the US during its training period.</p></sec></sec><sec id="Sec14"><title>Discussion</title><p id="Par50">Twitter has become the most studied social media platform where people express their everyday opinions, especially about politics. This fact encouraged a wealth of social and computer science scholars to use Twitter data for measuring national-level statistics for political outcomes, health metrics, or public opinion research. However, Twitter is not a representative sample of the population due to demographic imbalance in usage and penetration rates. To address this fact, researchers often try to create a random sample of Twitter users from a country. However, at least four widely-used sampling methods exist in the literature, and the extent to which their outputs are similar or different has not been explored systematically so far.</p><p id="Par51">In this paper, we tackled this issue by comparing the performance of the four different Twitter sampling methods on some carefully devised evaluation metrics. More specifically, the four methods include (1) <italic>1% stream</italic>, in which one uses Twitter Stream API to get 1% of tweets in real-time and then sample from the authors of the tweets, (2) <italic>location query</italic>, in which one uses Twitter Search API and query for a country of interest, (3) <italic>language query</italic>, in which one uses Twitter Search API, query for language(s) representing the country of interest, and filter for the country, and (4) <italic>bounding-box</italic>, in which one uses the &#x02018;bounding-box&#x02019; field in the Search API and query for the coordinates enclosing the country of interest. After carefully reviewing the literature, we devised three tweet-level, eight user-level, and five population-level evaluation metrics to compare these four Twitter sampling methods.</p><p id="Par52">Our results highlight the <italic>1% Stream</italic> Twitter sampling method, which exhibits different characteristics compared to the other three sampling methods and fits as the top candidate in most use cases. More particularly, Twitter users collected by the <italic>1% Stream</italic> method tend to have more tweets, tweets per day, followers, and friends, and fewer number of likes. In addition, it appears that the <italic>1% Stream</italic> sampling method provides slightly younger accounts (i.e. accounts created around 2022), slightly more male users, significantly fewer users in the 19-29 age stratum, and significantly more users in the 30-39 age stratum, compared to the other three sampling methods.</p><p id="Par53">The <italic>1% Stream</italic> method achieves the minimum error, compared to the other three methods, in the prediction task of estimating the population of the US from Twitter users. This is true across five different debiasing models, each attempting to make the sample representative of the US population. A baseline model using the <italic>1% Stream</italic>, in which we do not implement any debiasing technique, outperforms or equates all debiased forms of the other sampling methods in terms of the prediction error (except for the <italic>Location Query</italic> method when using marginal age counts).</p><p id="Par54">However, the <italic>1% Stream</italic> Twitter sampling method has some practical and theoretical disadvantages. Practically, it is time-consuming because the Twitter Stream API provides tweets in real-time. This means that, for example, if one needs to collect a month of stream data, she cannot get it immediately and has to wait for a whole month. This is not true for the other sampling methods, in which one can get the same period of data in a few hours or days, depending on the size of the country. In addition, researchers cannot access historical stream data using the <italic>1% Stream</italic> method unless they began collecting it beforehand.</p><p id="Par55">Theoretically, although the location and language filters used in all Twitter sampling methods are consistent, the <italic>1% Stream</italic> method may produce a sample biased towards more active users. This is because the more frequently a user tweets, the higher the likelihood they will be included in the 1% sample. Conversely, the other three methods offer equal chances for all users to be sampled. Additionally, the <italic>1% Stream</italic> method is not ideal for studies focused on user engagement metrics (such as the number of likes, retweets, comments, and views). This is because it gathers tweets in real-time, often capturing very recent tweets that have not yet been widely viewed or engaged with, as demonstrated in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>.</p><p id="Par56">These drawbacks of the <italic>1% Stream</italic> Twitter sampling method underscore the importance of the second-best sampling method in our study, which is the <italic>bounding box</italic> method. While its results are identical to <italic>Location Query</italic> and <italic>Language Query</italic> methods in terms of tweet- and user-level metrics (see Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>), it clearly outperforms them with respect to the prediction error in the US population estimation task.</p><p id="Par57">While Twitter has been one of the most studied social media platforms, the advantages and disadvantages of different sampling strategies remain unclear. Our results illuminate the positive and negative characteristics of the four main sampling methods used in the literature and help researchers choose the one that best suits their research goals and designs. By identifying the best sampling methods, our results also pave the way for conducting more accurate social listening studies and building more accurate machine learning models. Moreover, our approach and results may be adapted to conduct similar studies for other social media platforms.</p><p id="Par58">The performance of the <italic>1% Stream</italic> and <italic>bounding box</italic> Twitter sampling methods is better compared to the other two sampling methods when used for estimation of the population of US. Future research should explore the role of large language models in improving the performance of or automating usage of different models used in the process of computing the inclusion probabilities (Cerina and Duch <xref ref-type="bibr" rid="CR10">2023</xref>), determine significant parameters in the calculation of inclusion probabilities (Alizadeh et&#x000a0;al. <xref ref-type="bibr" rid="CR3">2011</xref>), and test the temporal and regional validity of the results. Finally, due the the shutdown of the Twitter API, future work should compare the results of these study to those of data donation (Boeschoten et&#x000a0;al. <xref ref-type="bibr" rid="CR9">2022</xref>) and crawling methods.</p></sec><sec id="Sec23" sec-type="supplementary-material"><title>Supplementary Information</title><p>Below is the link to the electronic supplementary material.<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="13278_2024_1327_MOESM1_ESM.pdf"><caption><p>Supplementary file1 (pdf 807 kb)</p></caption></media></supplementary-material></p></sec></body><back><fn-group><fn id="Fn1"><label>1</label><p id="Par24">For a comprehensive explanation and description of our improved method, please refer to Appendix Random User ID Generation Sampling Method.</p></fn><fn id="Fn2"><label>2</label><p id="Par29">census.gov.</p></fn><fn id="Fn3"><label>3</label><p id="Par37"><ext-link ext-link-type="uri" xlink:href="https://www.theguardian.com/technology/pda/2011/sep/08/twitter-active-users">https://www.theguardian.com/technology/pda/2011/sep/08/twitter-active-users</ext-link>.</p></fn><fn id="Fn4"><label>4</label><p id="Par39"><ext-link ext-link-type="uri" xlink:href="https://help.twitter.com/en/using-twitter/twitter-follow-limit">https://help.twitter.com/en/using-twitter/twitter-follow-limit</ext-link>.</p></fn><fn id="Fn5"><label>5</label><p id="Par48"><ext-link ext-link-type="uri" xlink:href="https://www.census.gov/programs-surveys/economic-census/guidance-geographies/levels.html">https://www.census.gov/programs-surveys/economic-census/guidance-geographies/levels.html</ext-link>.</p></fn><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>This project received funding from the European Research Council under the EU&#x02019;s Horizon 2020 research and innovation program (Grant Agreement No. 883121). We thank conference participants at the IC2S2 2023 and APSA 2023 conferences for their helpful feedback. We thank Sara Yari Mehmandoust, Mahdis Abbasi, Sima Mojtahedi, Mohammad Hormati, and Zahra Baghshahi for outstanding research assistance.</p></ack><notes notes-type="funding-information"><title>Funding</title><p>Open access funding provided by University of Zurich.</p></notes><notes notes-type="data-availability"><title>Data Availibility Statement</title><p> All codes and tweet IDs are available at an OSF repository: https://osf.io/vmcn9/.</p></notes><notes><title>Declarations</title><notes id="FPar1" notes-type="COI-statement"><title>Conflicts of interest</title><p id="Par61">The authors declare no conflict of interest.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><mixed-citation publication-type="other">Alizadeh M, Cioffi-Revilla C (2014). Distributions of opinion and extremist radicalization: insights from agent-based modeling. In: Social Informatics: 6th international conference, SocInfo 2014, Barcelona, Spain, November 11&#x02013;13, 2014. proceedings 6. Springer, pp 348&#x02013;358</mixed-citation></ref><ref id="CR2"><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Alizadeh</surname><given-names>M</given-names></name><name><surname>Weber</surname><given-names>I</given-names></name><name><surname>Cioffi-Revilla</surname><given-names>C</given-names></name><name><surname>Fortunato</surname><given-names>S</given-names></name><name><surname>Macy</surname><given-names>M</given-names></name></person-group><article-title>Psychology and morality of political extremists: evidence from Twitter language analysis of alt-right and Antifa</article-title><source>EPJ Data Sci</source><year>2019</year><volume>8</volume><issue>1</issue><fpage>1</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1140/epjds/s13688-019-0193-9</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Alizadeh M, Weber I, Cioffi-Revilla C, Fortunato S, Macy M (2019) Psychology and morality of political extremists: evidence from Twitter language analysis of alt-right and Antifa. EPJ Data Sci 8(1):1&#x02013;35</mixed-citation></citation-alternatives></ref><ref id="CR3"><mixed-citation publication-type="other">Alizadeh M, Lewis M, Zarandi MHF, Jolai F (2011) Determining significant parameters in the design of ANFIS. In: 2011 Annual meeting of the North American fuzzy information processing society. IEEE, pp 1&#x02013;6</mixed-citation></ref><ref id="CR4"><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Alizadeh</surname><given-names>M</given-names></name><name><surname>Shapiro</surname><given-names>JN</given-names></name><name><surname>Buntain</surname><given-names>C</given-names></name><name><surname>Tucker</surname><given-names>JA</given-names></name></person-group><article-title>Content-based features predict social media influence operations</article-title><source>Sci Adv</source><year>2020</year><volume>6</volume><issue>30</issue><fpage>eabb5824</fpage><pub-id pub-id-type="doi">10.1126/sciadv.abb5824</pub-id><pub-id pub-id-type="pmid">32832674</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Alizadeh M, Shapiro JN, Buntain C, Tucker JA (2020) Content-based features predict social media influence operations. Sci Adv 6(30):eabb5824<pub-id pub-id-type="pmid">32832674</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><mixed-citation publication-type="other">Alizadeh M, Kubli M, Samei Z, Dehghani S, Bermeo J.&#x000a0;D, Korobeynikova M, Gilardi F (2023) Open-source large language models outperform crowd workers and approach ChatGPT in text-annotation tasks. arXiv:2307.02179</mixed-citation></ref><ref id="CR6"><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Barber&#x000e1;</surname><given-names>P</given-names></name><name><surname>Casas</surname><given-names>A</given-names></name><name><surname>Nagler</surname><given-names>J</given-names></name><name><surname>Egan</surname><given-names>PJ</given-names></name><name><surname>Bonneau</surname><given-names>R</given-names></name><name><surname>Jost</surname><given-names>JT</given-names></name><name><surname>Tucker</surname><given-names>JA</given-names></name></person-group><article-title>Who leads? Who follows? Measuring issue attention and agenda setting by legislators and the mass public using social media data</article-title><source>Am Polit Sci Rev</source><year>2019</year><volume>113</volume><issue>4</issue><fpage>883</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1017/S0003055419000352</pub-id><pub-id pub-id-type="pmid">33303996</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Barber&#x000e1; P, Casas A, Nagler J, Egan PJ, Bonneau R, Jost JT, Tucker JA (2019) Who leads? Who follows? Measuring issue attention and agenda setting by legislators and the mass public using social media data. Am Polit Sci Rev 113(4):883&#x02013;901<pub-id pub-id-type="pmid">33303996</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Barrie</surname><given-names>C</given-names></name><name><surname>Siegel</surname><given-names>AA</given-names></name></person-group><article-title>Kingdom of trolls? Influence operations in the Saudi Twittersphere</article-title><source>J Quantitat Descr</source><year>2021</year><volume>1</volume><fpage>1</fpage><lpage>41</lpage></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Barrie C, Siegel AA (2021) Kingdom of trolls? Influence operations in the Saudi Twittersphere. J Quantitat Descr 1:1&#x02013;41</mixed-citation></citation-alternatives></ref><ref id="CR8"><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Batzdorfer</surname><given-names>V</given-names></name><name><surname>Steinmetz</surname><given-names>H</given-names></name><name><surname>Biella</surname><given-names>M</given-names></name><name><surname>Alizadeh</surname><given-names>M</given-names></name></person-group><article-title>Conspiracy theories on Twitter: emerging motifs and temporal dynamics during the COVID-19 pandemic</article-title><source>Int J Data Sci Anal</source><year>2022</year><volume>13</volume><issue>4</issue><fpage>315</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1007/s41060-021-00298-6</pub-id><pub-id pub-id-type="pmid">34977334</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Batzdorfer V, Steinmetz H, Biella M, Alizadeh M (2022) Conspiracy theories on Twitter: emerging motifs and temporal dynamics during the COVID-19 pandemic. Int J Data Sci Anal 13(4):315&#x02013;333<pub-id pub-id-type="pmid">34977334</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Boeschoten</surname><given-names>L</given-names></name><name><surname>Ausloos</surname><given-names>J</given-names></name><name><surname>M&#x000f6;ller</surname><given-names>JE</given-names></name><name><surname>Araujo</surname><given-names>T</given-names></name><name><surname>Oberski</surname><given-names>DL</given-names></name></person-group><article-title>A framework for privacy preserving digital trace data collection through data donation</article-title><source>Comput Commun Res</source><year>2022</year><volume>4</volume><issue>2</issue><fpage>388</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.5117/CCR2022.2.002.BOES</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Boeschoten L, Ausloos J, M&#x000f6;ller JE, Araujo T, Oberski DL (2022) A framework for privacy preserving digital trace data collection through data donation. Comput Commun Res 4(2):388&#x02013;423</mixed-citation></citation-alternatives></ref><ref id="CR10"><mixed-citation publication-type="other">Cerina R, Duch R (2023) Artificially intelligent opinion polling. arXiv:2309.06029</mixed-citation></ref><ref id="CR11"><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>De Choudhury</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>Y-R</given-names></name><name><surname>Sundaram</surname><given-names>H</given-names></name><name><surname>Candan</surname><given-names>KS</given-names></name><name><surname>Xie</surname><given-names>L</given-names></name><name><surname>Kelliher</surname><given-names>A</given-names></name></person-group><article-title>How does the data sampling strategy impact the discovery of information diffusion in social media?</article-title><source>Proc Int AAAI Conf Web Soc Media</source><year>2010</year><volume>4</volume><fpage>34</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1609/icwsm.v4i1.14024</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">De Choudhury M, Lin Y-R, Sundaram H, Candan KS, Xie L, Kelliher A (2010) How does the data sampling strategy impact the discovery of information diffusion in social media? Proc Int AAAI Conf Web Soc Media 4:34&#x02013;41</mixed-citation></citation-alternatives></ref><ref id="CR12"><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Gayo-Avello</surname><given-names>D</given-names></name></person-group><article-title>A meta-analysis of state-of-the-art electoral prediction from Twitter data</article-title><source>Soc Sci Comput Rev</source><year>2013</year><volume>31</volume><issue>6</issue><fpage>649</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1177/0894439313493979</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Gayo-Avello D (2013) A meta-analysis of state-of-the-art electoral prediction from Twitter data. Soc Sci Comput Rev 31(6):649&#x02013;679</mixed-citation></citation-alternatives></ref><ref id="CR13"><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Gonz&#x000e1;lez-Bail&#x000f3;n</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>N</given-names></name><name><surname>Rivero</surname><given-names>A</given-names></name><name><surname>Borge-Holthoefer</surname><given-names>J</given-names></name><name><surname>Moreno</surname><given-names>Y</given-names></name></person-group><article-title>Assessing the bias in samples of large online networks</article-title><source>Soc Netw</source><year>2014</year><volume>38</volume><fpage>16</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/j.socnet.2014.01.004</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Gonz&#x000e1;lez-Bail&#x000f3;n S, Wang N, Rivero A, Borge-Holthoefer J, Moreno Y (2014) Assessing the bias in samples of large online networks. Soc Netw 38:16&#x02013;27</mixed-citation></citation-alternatives></ref><ref id="CR14"><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Hino</surname><given-names>A</given-names></name><name><surname>Fahey</surname><given-names>RA</given-names></name></person-group><article-title>Representing the Twittersphere: archiving a representative sample of Twitter data under resource constraints</article-title><source>Int J Inf Manag</source><year>2019</year><volume>48</volume><fpage>175</fpage><lpage>184</lpage><pub-id pub-id-type="doi">10.1016/j.ijinfomgt.2019.01.019</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Hino A, Fahey RA (2019) Representing the Twittersphere: archiving a representative sample of Twitter data under resource constraints. Int J Inf Manag 48:175&#x02013;184</mixed-citation></citation-alternatives></ref><ref id="CR15"><mixed-citation publication-type="other">Joseph K, Landwehr PM, Carley, KM (2014) Two 1% s don&#x02019;t make a whole: Comparing simultaneous samples from Twitter&#x02019;s streaming API. In: International conference on social computing, behavioral-cultural modeling, and prediction. Springer, pp 75&#x02013;83</mixed-citation></ref><ref id="CR16"><mixed-citation publication-type="other">Jungherr A, J&#x000fc;rgens P, Schoen H (2012) Why the pirate party won the german election of 2009 or the trouble with predictions: a response to tumasjan, a., sprenger, to, sander, pg, &#x00026; welpe, im &#x0201c;predicting elections with twitter: What 140 characters reveal about political sentiment. Soc Sci Comput Rev 30(2):229&#x02013;234</mixed-citation></ref><ref id="CR17"><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Jang</surname><given-names>SM</given-names></name><name><surname>Kim</surname><given-names>S-H</given-names></name><name><surname>Wan</surname><given-names>A</given-names></name></person-group><article-title>Evaluating sampling methods for content analysis of Twitter data</article-title><source>Soc Media Soc</source><year>2018</year><volume>4</volume><issue>2</issue><fpage>2056305118772836</fpage><pub-id pub-id-type="doi">10.1177/2056305118772836</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Kim H, Jang SM, Kim S-H, Wan A (2018) Evaluating sampling methods for content analysis of Twitter data. Soc Media Soc 4(2):2056305118772836</mixed-citation></citation-alternatives></ref><ref id="CR18"><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>G</given-names></name><name><surname>Lam</surname><given-names>P</given-names></name><name><surname>Roberts</surname><given-names>ME</given-names></name></person-group><article-title>Computer-assisted keyword and document set discovery from unstructured text</article-title><source>Am J Polit Sci</source><year>2017</year><volume>61</volume><issue>4</issue><fpage>971</fpage><lpage>988</lpage><pub-id pub-id-type="doi">10.1111/ajps.12291</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">King G, Lam P, Roberts ME (2017) Computer-assisted keyword and document set discovery from unstructured text. Am J Polit Sci 61(4):971&#x02013;988</mixed-citation></citation-alternatives></ref><ref id="CR19"><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Morstatter</surname><given-names>F</given-names></name><name><surname>Pfeffer</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Carley</surname><given-names>K</given-names></name></person-group><article-title>Is the sample good enough? comparing data from twitter&#x02019;s streaming api with twitter&#x02019;s firehose</article-title><source>Proc Int AAAI Conf Web Soc Media</source><year>2013</year><volume>7</volume><fpage>400</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1609/icwsm.v7i1.14401</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Morstatter F, Pfeffer J, Liu H, Carley K (2013) Is the sample good enough? comparing data from twitter&#x02019;s streaming api with twitter&#x02019;s firehose. Proc Int AAAI Conf Web Soc Media 7:400&#x02013;408</mixed-citation></citation-alternatives></ref><ref id="CR20"><mixed-citation publication-type="other">Mosleh M, Rand DG (2024) Who is on Twitter (&#x0201c;X&#x0201d;)? Identifying demographic of Twitter users</mixed-citation></ref><ref id="CR21"><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Munger</surname><given-names>K</given-names></name><name><surname>Egan</surname><given-names>PJ</given-names></name><name><surname>Nagler</surname><given-names>J</given-names></name><name><surname>Ronen</surname><given-names>J</given-names></name><name><surname>Tucker</surname><given-names>J</given-names></name></person-group><article-title>Political knowledge and misinformation in the era of social media: evidence from the 2015 UK election</article-title><source>Br J Polit Sci</source><year>2022</year><volume>52</volume><issue>1</issue><fpage>107</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1017/S0007123420000198</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Munger K, Egan PJ, Nagler J, Ronen J, Tucker J (2022) Political knowledge and misinformation in the era of social media: evidence from the 2015 UK election. Br J Polit Sci 52(1):107&#x02013;127</mixed-citation></citation-alternatives></ref><ref id="CR22"><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeffer</surname><given-names>J</given-names></name><name><surname>Mayer</surname><given-names>K</given-names></name><name><surname>Morstatter</surname><given-names>F</given-names></name></person-group><article-title>Tampering with Twitter&#x02019;s sample API</article-title><source>EPJ Data Sci</source><year>2018</year><volume>7</volume><issue>1</issue><fpage>50</fpage><pub-id pub-id-type="doi">10.1140/epjds/s13688-018-0178-0</pub-id></element-citation><mixed-citation id="mc-CR22" publication-type="journal">Pfeffer J, Mayer K, Morstatter F (2018) Tampering with Twitter&#x02019;s sample API. EPJ Data Sci 7(1):50</mixed-citation></citation-alternatives></ref><ref id="CR23"><mixed-citation publication-type="other">Pointer D (2023) System design interview: scalable unique ID generator (twitter snowflake or a similar service). Accessed: 2023-02-08</mixed-citation></ref><ref id="CR24"><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>C</given-names></name><name><surname>Hui</surname><given-names>P-M</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Flammini</surname><given-names>A</given-names></name><name><surname>Menczer</surname><given-names>F</given-names></name><name><surname>Ciampaglia</surname><given-names>GL</given-names></name></person-group><article-title>Anatomy of an online misinformation network</article-title><source>PLoS ONE</source><year>2018</year><volume>13</volume><issue>4</issue><fpage>e0196087</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0196087</pub-id><pub-id pub-id-type="pmid">29702657</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Shao C, Hui P-M, Wang L, Jiang X, Flammini A, Menczer F, Ciampaglia GL (2018) Anatomy of an online misinformation network. PLoS ONE 13(4):e0196087<pub-id pub-id-type="pmid">29702657</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Truong</surname><given-names>BT</given-names></name><name><surname>Allen</surname><given-names>OM</given-names></name><name><surname>Menczer</surname><given-names>F</given-names></name></person-group><article-title>Account credibility inference based on news-sharing networks</article-title><source>EPJ Data Sci</source><year>2024</year><volume>13</volume><issue>1</issue><fpage>10</fpage><pub-id pub-id-type="doi">10.1140/epjds/s13688-024-00450-9</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Truong BT, Allen OM, Menczer F (2024) Account credibility inference based on news-sharing networks. EPJ Data Sci 13(1):10</mixed-citation></citation-alternatives></ref><ref id="CR26"><mixed-citation publication-type="other">Tufekci Z (2014) Big questions for social media big data: representativeness, validity and other methodological pitfalls. In: Eighth international AAAI conference on weblogs and social media</mixed-citation></ref><ref id="CR27"><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>W</given-names></name><name><surname>Rothschild</surname><given-names>D</given-names></name><name><surname>Goel</surname><given-names>S</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name></person-group><article-title>Forecasting elections with non-representative polls</article-title><source>Int J Forecast</source><year>2015</year><volume>31</volume><issue>3</issue><fpage>980</fpage><lpage>991</lpage><pub-id pub-id-type="doi">10.1016/j.ijforecast.2014.06.001</pub-id></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Wang W, Rothschild D, Goel S, Gelman A (2015) Forecasting elections with non-representative polls. Int J Forecast 31(3):980&#x02013;991</mixed-citation></citation-alternatives></ref><ref id="CR28"><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Callan</surname><given-names>J</given-names></name><name><surname>Zheng</surname><given-names>B</given-names></name></person-group><article-title>Should we use the sample? Analyzing datasets sampled from Twitter&#x02019;s stream API</article-title><source>ACM Trans Web (TWEB)</source><year>2015</year><volume>9</volume><issue>3</issue><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1145/2746366</pub-id></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Wang Y, Callan J, Zheng B (2015) Should we use the sample? Analyzing datasets sampled from Twitter&#x02019;s stream API. ACM Trans Web (TWEB) 9(3):1&#x02013;23</mixed-citation></citation-alternatives></ref><ref id="CR29"><mixed-citation publication-type="other">Wang Z, Hale S, Adelani DI, Grabowicz P, Hartman T, Fl&#x000f6;ck F, Jurgens D (2019) Demographic inference and representative population estimates from multilingual social media data. In: The world wide web conference, pp 2056&#x02013;2067</mixed-citation></ref><ref id="CR30"><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Rizoiu</surname><given-names>M-A</given-names></name><name><surname>Xie</surname><given-names>L</given-names></name></person-group><article-title>Variation across scales: measurement fidelity under twitter data sampling</article-title><source>Proc Int AAAI Conf Web Soc Media</source><year>2020</year><volume>14</volume><fpage>715</fpage><lpage>725</lpage><pub-id pub-id-type="doi">10.1609/icwsm.v14i1.7337</pub-id></element-citation><mixed-citation id="mc-CR30" publication-type="journal">Wu S, Rizoiu M-A, Xie L (2020) Variation across scales: measurement fidelity under twitter data sampling. Proc Int AAAI Conf Web Soc Media 14:715&#x02013;725</mixed-citation></citation-alternatives></ref><ref id="CR31"><mixed-citation publication-type="other">Yang K-C, Ferrara E, Menczer F (2022) Botometer 101: social bot practicum for computational social scientists. J Computat Soc Sci 1&#x02013;18</mixed-citation></ref><ref id="CR32"><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>K-C</given-names></name><name><surname>Hui</surname><given-names>P-M</given-names></name><name><surname>Menczer</surname><given-names>F</given-names></name></person-group><article-title>How Twitter data sampling biases US voter behavior characterizations</article-title><source>PeerJ Comput Sci</source><year>2022</year><volume>8</volume><fpage>e1025</fpage><pub-id pub-id-type="doi">10.7717/peerj-cs.1025</pub-id></element-citation><mixed-citation id="mc-CR32" publication-type="journal">Yang K-C, Hui P-M, Menczer F (2022) How Twitter data sampling biases US voter behavior characterizations. PeerJ Comput Sci 8:e1025</mixed-citation></citation-alternatives></ref><ref id="CR33"><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Zafar</surname><given-names>MB</given-names></name><name><surname>Bhattacharya</surname><given-names>P</given-names></name><name><surname>Ganguly</surname><given-names>N</given-names></name><name><surname>Gummadi</surname><given-names>KP</given-names></name><name><surname>Ghosh</surname><given-names>S</given-names></name></person-group><article-title>Sampling content from online social networks: comparing random vs expert sampling of the twitter stream</article-title><source>ACM Trans Web (TWEB)</source><year>2015</year><volume>9</volume><issue>3</issue><fpage>1</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1145/2743023</pub-id></element-citation><mixed-citation id="mc-CR33" publication-type="journal">Zafar MB, Bhattacharya P, Ganguly N, Gummadi KP, Ghosh S (2015) Sampling content from online social networks: comparing random vs expert sampling of the twitter stream. ACM Trans Web (TWEB) 9(3):1&#x02013;33</mixed-citation></citation-alternatives></ref></ref-list></back></article>