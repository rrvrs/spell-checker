<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40410277</article-id><article-id pub-id-type="pmc">PMC12102208</article-id>
<article-id pub-id-type="publisher-id">2333</article-id><article-id pub-id-type="doi">10.1038/s41598-025-02333-z</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A robust and statistical analyzed predictive model for drug toxicity using machine learning</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Rawat</surname><given-names>Deepak</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Bajaj</surname><given-names>Rohit</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Manchanda</surname><given-names>Rachit</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Mehta</surname><given-names>Ankush</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Paramasivam</surname><given-names>Prabhu</given-names></name><address><email>lptprabhu@gmail.com</email></address><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Bhagat</surname><given-names>Suraj Kumar</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Ayanie</surname><given-names>Abinet Gosaye</given-names></name><address><email>abinet.gosaye@astu.edu.et</email></address><xref ref-type="aff" rid="Aff6">6</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05t4pvx35</institution-id><institution-id institution-id-type="GRID">grid.448792.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 4678 9721</institution-id><institution>Department of Mathematics, </institution><institution>Chandigarh University, </institution></institution-wrap>Mohali, Punjab 140413 India </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05t4pvx35</institution-id><institution-id institution-id-type="GRID">grid.448792.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 4678 9721</institution-id><institution>Department of Computer Sciences, </institution><institution>Chandigarh University, </institution></institution-wrap>Mohali, Punjab 140413 India </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/030dn1812</institution-id><institution-id institution-id-type="GRID">grid.508494.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 7424 8041</institution-id><institution>Marwadi University Research Center, Department of Mechanical Engineering, Faculty of Engineering &#x00026; Technology, </institution><institution>Marwadi University, </institution></institution-wrap>Rajkot, 360003 Gujarat India </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/0034me914</institution-id><institution-id institution-id-type="GRID">grid.412431.1</institution-id><institution-id institution-id-type="ISNI">0000 0004 0444 045X</institution-id><institution>Department of Research and Innovation, </institution><institution>Saveetha School of Engineering, SIMATS, </institution></institution-wrap>Chennai, 602105 Tamil Nadu India </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/030dn1812</institution-id><institution-id institution-id-type="GRID">grid.508494.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 7424 8041</institution-id><institution>Marwadi University Research Center, Department of Civil Engineering, Faculty of Engineering &#x00026; Technology, </institution><institution>Marwadi University, </institution></institution-wrap>Rajkot, 360003 Gujrat India </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02ccba128</institution-id><institution-id institution-id-type="GRID">grid.442848.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 0570 6336</institution-id><institution>Department of Mechanical Engineering, </institution><institution>Adama Science and Technology University, </institution></institution-wrap>Adama, 2552 Ethiopia </aff></contrib-group><pub-date pub-type="epub"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>15</volume><elocation-id>17993</elocation-id><history><date date-type="received"><day>5</day><month>9</month><year>2024</year></date><date date-type="accepted"><day>13</day><month>5</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Over the years, toxicity prediction has been a challenging task. Artificial intelligence and machine learning provide a platform to study toxicity prediction more accurately with a reduced time span. An optimized ensembled model is used to contrast the results of seven machine learning algorithms and three deep learning models with regard to state-of-the-art parameters. In the paper, optimized model is developed that combined eager random forest and sluggish k star techniques. State-of-the-art parameters have been evaluated and compared for three scenarios. In first scenario with original features, in the second scenario using feature selection and resampling technique with the percentage split method, and in the third scenario using feature selection and resampling technique with 10-fold cross-validation. The principal component analysis is performed for feature selection. An optimized ensembled model performs well in comparison to other models in all three scenarios. It achieved an accuracy of 77% in the first scenario, 89% in the second scenario, and 93% in the third scenario. The proposed model shows the performance increase in accuracy by 8% as compared to the top performer Kstar machine learning model and 21% as compared to deep learning model AIPs-DeepEnC-GA which is remarkable. Also there is significant improvement in other important evaluation parameters in comparison to top performing models. Further concept of W-saw score and L-saw is presented for all the scenarios. An optimized ensembled model using feature selection and resampling technique with tenfold cross-validation performs best among all machine learning models in all the scenarios.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Feature selection</kwd><kwd>Ensembling</kwd><kwd>Percentage split</kwd><kwd>Resampling</kwd><kwd>Saw score</kwd><kwd>10-Fold cross validation</kwd></kwd-group><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Engineering</kwd><kwd>Mathematics and computing</kwd><kwd>Toxicology</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">The degree to which a medicinal compound is hazardous to living things is known as its toxicity<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Toxicology prediction is extremely difficult. Worldwide, numerous medicinal compounds are created each year. Toxicity is related to the amount of chemicals that are inhaled, applied, or injected and can result in death, allergies, or negative consequences on living organisms<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. A drug&#x02019;s toxicity can differ from person to person as per their characteristics. Therefore, a dose that is curative for one patient may be poisonous for other<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Drugs are necessary for living beings to help with illness, disease diagnosis, or disease prevention<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. A new medication or chemical molecule must go through a lengthy, expensive process of development. There are two types of chemicals, namely active and inactive ingredients found in every medicine. The term &#x0201c;active ingredients&#x0201d; refers to the substance that constitutes the therapeutic essence of medicine<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. The other is known as an inactive component, which has no direct therapeutic benefit but is utilized to balance a drug&#x02019;s potency. Inactive medications are occasionally used to bind, coat, flavor, or even speed up the breakdown of active pharmaceuticals. Therefore, maintaining a balance between active and inactive medications is crucial. The imbalance of active and inactive medications results in toxicity<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Thus, predicting drug toxicity is vital. Over the last few decades, toxicity has been a crucial subject of ongoing research<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. In the past, drug testing was performed on animals followed by human trials but computational intelligence makes it possible to forecast and assess a drug&#x02019;s toxicity<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. It is possible to forecast drug toxicity using machine learning approaches<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>. These methods reduce the cost and duration of the evolution process. A critical phase in the machine learning pipeline is FS, where pertinent characteristics are selected in the dataset and excludes redundant attributes<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. Proper feature selection can shorten training times, prevent overfitting, and enhance model performance. There are numerous ways for selecting features, ranging from straightforward to sophisticated<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. The best feature subset for a particular machine learning assignment is detected by frequently considering a combination of approaches and experimenting carefully. Additionally to prevent data leakage and estimate performance of model precisely, feature selection must be carried out inside a validated framework<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. A common dimensionality reduction method in statistics and machine learning is principal component analysis<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. Its main applications are feature selection and data visualization, with the aim of decreasing a dataset&#x02019;s dimensionality while retaining as much crucial data as feasible. Principal component Analysis uses linear combinations to produce the main components, and the term &#x0201c;combinations&#x0201d; refers to the linear combinations of the original features<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. The goal of PCA is to identify a set of orthogonal (i.e., uncorrelated) linear combinations of the initial characteristics that best account for the data&#x02019;s variation. The original attributes are combined with particular weights or coefficients to create these linear combinations, which are known as the principal components. In brief, PCA diminishes the amplitude of the data by keeping as much information as feasible. The process of dimension reduction is applied by combining the actual features presented as principal components<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. These combinations are determined by assigning weight to original features that are necessary for structure and reducing the dimension of data. Resampling is a method to change the dataset by addition, deletion, or change of dataset points. This is used to overcome class imbalance and fitting problems in a dataset<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Oversampling and undersampling can add biases or lower the quantity of data accessible for training<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. It must be done with caution. The resampling approach and parameters are persuaded by the dataset, specific challenge, and the desired result. The appropriate model selection, hyperparameter tweaking, and cross-validation must be used in association with resampling to get a balanced and robust machine-learning model<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. The process of splitting a dataset into subsets for training, testing, and validation is termed as percentage split in machine learning<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. These subsets are given in terms of the percentage of a dataset. The percentage split selection is based on the size of the dataset and the data accessibility. In a typical percentage split, for training, testing, and validation for instance criteria of 80%, 10%, and 10% can be utilized<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. Depending upon data size we can build a robust model<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. However, depending upon the need of a project, the percentage split can be adjusted to get the best machine learning model. To avoid biases, it is important to split data at random or by the use of a method that ensures the best subsets of the entire dataset. K-fold cross-validation is a well-known technique to apply<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. It helps to estimate the performance on data when a dataset is small. In the technique, the dataset is split into equal size of k-folds. Noted the performance statistics or metrics<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. Calculate the performance metric(s) average and standard deviation over all K iterations. In comparison to a single train-test split, these statistics offer a more reliable estimation of your model&#x02019;s performance. The size of our dataset and the available computational resources are only two examples of the many variables that influence the choice of K. K frequently has values between 5 and 10, and 10-fold cross-validation is frequently a suitable place to start. We can experiment with several K values to discover which one gives the most accurate performance estimates for your model<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. K-fold cross-validation offers a more thorough review than a single train-test split, which can be impacted by the randomness of the split, and aids in evaluating. A number of machines learning algorithms are applied and the performance is evaluated which is quite satisfactory but still the challenges needs to be addressed are overfitting, generalization, dependency on a single factor i.e. accuracy. The presented paper uses k-fold cross validation method to deal with overfitting. Ensembling of lazy and eager is performed to address generalization. Saw scores are composite scores of all performance parameters which strengthens the optimized model.</p><p id="Par3">The main contribution of presented paper is to</p><p id="Par4">
<list list-type="bullet"><list-item><p id="Par5">A number of machine learning approaches are already used to improve the performance of the model.</p></list-item><list-item><p id="Par6">Optimize and strengthen the model with multidisciplinary domain operational research where W-saw and L-saw are calculated and their respective scores validate the performance of optimized model before deployment.</p></list-item></list>
</p></sec><sec id="Sec2"><title>Literature review</title><p id="Par7">In this section, different techniques used by researchers in machine learning have been discussed with their findings of the research. Sukumaran et al. created a mongrel method based on particle swarm optimisation and support vector machines to autonomously analyse computed tomography images, offering a high likelihood of detecting the existence of Covid-19-related pneumonia<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. The model was trained and clarifies the existence of disease in patients that saves time frame for physicians. Sarwar et al. exhibited an ensembled model in deaconing type II diabetes<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. The authors considered a total of 15 models but used five main approaches. To achieve the desired results they employed matrix laboratory and the weka tool. The voting technique is used in ensembling the classifiers. A medical dataset of 400 people around the globe is considered during the research. Verma et al. provided an analysis of machine learning methods, both supervised and unsupervised, for identifying incredulous behaviour<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. The authors studied the behavior of a single person in a crowd with artificial intelligence techniques. Bojamma et al. studied the importance of plant identification in balancing the nature and saving the geodiversity of a zone<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. The authors assessed the condition to explore latest approaches for systematic identifications of flora. The combined efforts of artificial intelligence and botanists are important to robotize the complete method of recognition of plants considering leaves as crucial characteristics that help identify between different plants. Shidnal et al. studied about lack of nutrients in a paddy crop. They used neural network to categorise the shortcomings using tensor flow<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. Clustering technique k means is applied to build clusters<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. The authors estimated state of deficiencies on a measurable basis. A rule-based matrix is also used to estimate cropland&#x02019;s yield. Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> represents the literature based on the algorithm used in the study.</p><p id="Par8">
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Literature based on the algorithms studied.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Author</th><th align="left" colspan="12">Algorithms</th></tr><tr><th align="left">SVM</th><th align="left">RF</th><th align="left">KNN</th><th align="left">NB</th><th align="left">NN</th><th align="left">DT</th><th align="left">ANN</th><th align="left">J48</th><th align="left">MLP</th><th align="left">BN</th><th align="left">LR</th><th align="left">Other</th></tr></thead><tbody><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>
</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>
</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>
</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr></tbody></table></table-wrap>
</p><p id="Par9">Tables&#x000a0;<xref rid="Tab2" ref-type="table">2</xref> and <xref rid="Tab3" ref-type="table">3</xref> present the study of evaluation parameters and approaches used in different research respectively.</p><p id="Par10">
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Literature based on the evaluation parameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Author</th><th align="left" colspan="10">Evaluation Parameters</th></tr><tr><th align="left">Q</th><th align="left">SE</th><th align="left">SP</th><th align="left">AUC</th><th align="left">F-1</th><th align="left">R</th><th align="left">R<sup>2</sup></th><th align="left">MAE</th><th align="left">RMSE</th><th align="left">Others</th></tr></thead><tbody><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>
</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr></tbody></table></table-wrap>
</p><p id="Par11">
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Literature based on the approaches used.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Author</th><th align="left" colspan="7">Approaches</th></tr><tr><th align="left">Classification</th><th align="left">Regression</th><th align="left">Ensemble</th><th align="left">Feature Selection</th><th align="left">Class Balancing</th><th align="left">Hybrid</th><th align="left">Others</th></tr></thead><tbody><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>
</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>
</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td></tr><tr><td align="left">
<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td></tr></tbody></table></table-wrap>
</p><p id="Par12">Renowned researchers are applying machine learning algorithms to understand highly complex problems. There is always a need for pre-processing to better understand complex data. New techniques are needed for pre-processing methods like feature selection and clustering as well. Prominent work is done by the researchers in the field, now ensembling in the feature selection is necessary to make a robust model. Gini index, principal component analysis, recursive feature selection, fisher filtering, Lasso regression, correlation attribute evaluator, and many more feature selection methods are used by researchers. Now researchers are optimizing their prominent work toward hybrid or ensembling of algorithms.</p><p id="Par13">The paper is structured as:</p><p id="Par14">
<list list-type="simple"><list-item><label>I)</label><p id="Par15">Section &#x0201c;<xref rid="Sec3" ref-type="sec">Proposed Methodology</xref>&#x0201d; depicts methodology adopted.</p></list-item><list-item><label>II)</label><p id="Par16">Section &#x0201c;<xref rid="Sec12" ref-type="sec">Results and discussions</xref>&#x0201d; presents detailed discussions about the dataset and results achieved in all the three scenarios described.</p></list-item><list-item><label>III)</label><p id="Par17">Section &#x0201c;<xref rid="Sec15" ref-type="sec">Conclusion</xref>&#x0201d; presents conclusion and future scope.</p></list-item></list>
</p></sec><sec id="Sec3"><title>Proposed methodology</title><p id="Par18">In the research, seven computer-aided machine learning models are evaluated and the performance is compared. Gaussian Process (GP), Linear Regression (LR), Sequential monitoring optimization (SMO), Kstar, Bagging, Decision Tree (DT) and Random Forest (RF) are taken into consideration to predict toxicity. Through ensemble of the Random Forest and Kstar algorithms, we were able to develop an optimized ensembled model (OEKRF). Three scenarios are introduced for the preprocessing and training of data. Seven machine learning algorithms and optimized KRF are evaluated and compared in all three scenarios. Results are compared in aspects state of art parameters. Further to strengthen the model, W-saw and L-saw scores are also evaluated, and the framework of a robust model is deployed. Figure&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> represents methodology proposed for the model.</p><p id="Par19">
<fig id="Fig1"><label>Fig. 1</label><caption><p>Methodology.</p></caption><graphic xlink:href="41598_2025_2333_Fig1_HTML" id="d33e1519"/></fig>
</p><p id="Par20">Pseudocode is also presented below to elaborate the process in detail:<graphic position="anchor" xlink:href="41598_2025_2333_Figa_HTML" id="d33e1525"/></p></sec><sec id="Sec12"><title>Results and discussions</title><p id="Par21">This section is divided into two subsections. First subsection presents the dataset description in which different attributes of dataset are described and the second subsection depicts the result analysis with discussions.</p><sec id="Sec13"><title>Dataset description</title><p id="Par22">The toxicity dataset that is used in an implementation is obtained from UC Irvine ML depository. There are 546 instances in the dataset, and there are eight predictive attributes. The attributes are listed in Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref> and a detailed description is also presented.</p><p id="Par23">
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Attribute description.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Attributes</th><th align="left">Description of Attributes</th></tr></thead><tbody><tr><td align="left">T.P.S.A.-(Tot)</td><td align="left">Area of the topological polar surface</td></tr><tr><td align="left">S.A.acc.</td><td align="left">Acceptors of surface area</td></tr><tr><td align="left">H (050)</td><td align="left">Count of hydrogen atoms</td></tr><tr><td align="left">M-LOG-P</td><td align="left">Moriguchi values of LOG P</td></tr><tr><td align="left">RDCHI</td><td align="left">Demonstrates the topological index</td></tr><tr><td align="left">GAT S1p</td><td align="left">Symbolizes the polarisability of molecules</td></tr><tr><td align="left">N.Nitrogen</td><td align="left">Count of atoms of nitrogen</td></tr><tr><td align="left">C (040)</td><td align="left">Count of atoms of carbon</td></tr></tbody></table></table-wrap>
</p><p id="Par24">Table&#x000a0;<xref rid="Tab5" ref-type="table">5</xref> shows some tuples of dataset which are representative of the entire dataset.</p><p id="Par25">
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Tuples of dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">TPSA(Tot)</th><th align="left">SAacc</th><th align="left">H-050</th><th align="left">MLOGP</th><th align="left">RDCHI</th><th align="left">GATS1p</th><th align="left">nN</th><th align="left">C-040</th></tr></thead><tbody><tr><td align="left">35.53</td><td char="." align="char">47.145</td><td char="." align="char">0</td><td char="." align="char">4.579</td><td char="." align="char">3.875</td><td char="." align="char">1.124</td><td char="." align="char">0</td><td char="." align="char">1</td></tr><tr><td align="left">17.07</td><td char="." align="char">25.145</td><td char="." align="char">0</td><td char="." align="char">0.202</td><td char="." align="char">1.225</td><td char="." align="char">1.66</td><td char="." align="char">0</td><td char="." align="char">0</td></tr><tr><td align="left">34.14</td><td char="." align="char">50.29</td><td char="." align="char">0</td><td char="." align="char">0.076</td><td char="." align="char">1.654</td><td char="." align="char">1.493</td><td char="." align="char">0</td><td char="." align="char">0</td></tr><tr><td align="left">67.51</td><td char="." align="char">103.973</td><td char="." align="char">1</td><td char="." align="char">3.204</td><td char="." align="char">3.344</td><td char="." align="char">0.938</td><td char="." align="char">0</td><td char="." align="char">1</td></tr><tr><td align="left">49.33</td><td char="." align="char">85.839</td><td char="." align="char">2</td><td char="." align="char">1.06</td><td char="." align="char">2.272</td><td char="." align="char">1.007</td><td char="." align="char">1</td><td char="." align="char">1</td></tr><tr><td align="left">122.22</td><td char="." align="char">155.543</td><td char="." align="char">2</td><td char="." align="char">1.406</td><td char="." align="char">3.511</td><td char="." align="char">1.456</td><td char="." align="char">5</td><td char="." align="char">2</td></tr></tbody></table></table-wrap>
</p><p id="Par26">In the paper, the principal component analysis technique is employed to procure prime combination of the features. Principal component analysis is performed in conjunction with ranker research method. Dimensionality reduction is done by choosing eigen vectors to account for some percentage of the variance in the original data. Five new combinations (NC) have been introduced for the optimized toxicity prediction model. Table&#x000a0;<xref rid="Tab6" ref-type="table">6</xref> presents the description of new features as per the technique.</p><p id="Par27">
<table-wrap id="Tab6"><label>Table 6</label><caption><p>New combinations by principal component analysis.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">NC1</th><th align="left">&#x02212;0.496SAacc-0.492 TPSA(Tot)&#x02212;0.439 H-050-0.374nN +&#x02009;0.282 MLOGP&#x02026;</th></tr></thead><tbody><tr><td align="left">NC2</td><td align="left">&#x02212;0.658 MLOGP-0.613RDCHI +&#x02009;0.411GATS1p-0.085SAacc-0.081nN&#x02026;</td></tr><tr><td align="left">NC3</td><td align="left">&#x02212;0.842GATS1p-0.374RDCHI +&#x02009;0.302 H-050 +&#x02009;0.174nN-0.163 MLOGP&#x02026;</td></tr><tr><td align="left">NC4</td><td align="left">0.873nN-0.357 H-050-0.309SAacc +&#x02009;0.096GATS1p-0.07RDCHI&#x02026;</td></tr><tr><td align="left">NC5</td><td align="left">0.69 H-050-0.58 TPSA(Tot) +&#x02009;0.278 MLOGP +&#x02009;0.242GATS1p +&#x02009;0.207nN&#x02026;</td></tr></tbody></table></table-wrap>
</p><p id="Par28">The correlation among the various combinations is shown in Table&#x000a0;<xref rid="Tab7" ref-type="table">7</xref>.</p><p id="Par29">
<table-wrap id="Tab7"><label>Table 7</label><caption><p>Coefficient of correlation among different combinations.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">NC1</th><th align="left">NC2</th><th align="left">NC3</th><th align="left">NC4</th><th align="left">NC5</th></tr></thead><tbody><tr><td align="left">NC1</td><td align="left">1</td><td align="left">0.02</td><td align="left">0.03</td><td align="left">&#x02212;0.21</td><td align="left">0.12</td></tr><tr><td align="left">NC2</td><td align="left">0.02</td><td align="left">1</td><td align="left">&#x02212;0.06</td><td align="left">&#x02212;0.01</td><td align="left">0.02</td></tr><tr><td align="left">NC3</td><td align="left">0.03</td><td align="left">&#x02212;0.06</td><td align="left">1</td><td align="left">&#x02212;0.01</td><td align="left">&#x02212;0.04</td></tr><tr><td align="left">NC4</td><td align="left">&#x02212;0.21</td><td align="left">&#x02212;0.01</td><td align="left">&#x02212;0.01</td><td align="left">1</td><td align="left">0.1</td></tr><tr><td align="left">NC5</td><td align="left">0.12</td><td align="left">0.02</td><td align="left">&#x02212;0.04</td><td align="left">0.1</td><td align="left">1</td></tr></tbody></table></table-wrap>
</p><p id="Par30">Heat map is a technique used for data visualization which represents numerical values in the dataset by using different color combinations. It depicts correlation coefficients by color gradients. In Fig. <xref rid="Fig2" ref-type="fig">2</xref>, red color depicts the highest value of correlation coefficient, yellow color shows the mediate values and green color shows the lowest value of correlation coefficient.</p><p id="Par31">
<fig id="Fig2"><label>Fig. 2</label><caption><p>Heat map.</p></caption><graphic xlink:href="41598_2025_2333_Fig2_HTML" id="d33e1893"/></fig>
</p><p id="Par32">Through ensemble of the Random Forest and Kstar algorithms, we were able to create a better regression model (OEKRF). Figure&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> represents the methodology for ensembled model and Classifier &#x02212;&#x02009;1 and classifier- 2 are applying a lazy and eager algorithm for prediction. Further ensembling is performed using different algorithms.</p><p id="Par33">
<fig id="Fig3"><label>Fig. 3</label><caption><p>Ensembled Model.</p></caption><graphic xlink:href="41598_2025_2333_Fig3_HTML" id="d33e1909"/></fig>
</p><p id="Par34">
<fig position="anchor" id="Figb"><caption><p>Algorithm: Prediction and Ensembling</p></caption><graphic position="anchor" xlink:href="41598_2025_2333_Figb_HTML" id="d33e1918"/></fig>
</p></sec><sec id="Sec14"><title>Results and discussions</title><p id="Par35">Three different scenarios have been considered for the evaluation and comparison of seven machine-learning algorithms and optimized KRF as follows:</p><p id="Par36">
<list list-type="simple"><list-item><label>I)</label><p id="Par37">Evaluation and comparison with original features.</p></list-item><list-item><label>II)</label><p id="Par38">Evaluation and comparison with feature selection, resampling, and percentage split method.</p></list-item><list-item><label>III)</label><p id="Par39">Evaluation and comparison with feature selection, resampling, and 10-fold cross-validation method.</p></list-item></list>
</p><p id="Par40">Coefficient of correlation is denoted by R value. It represents how much one variable is correlated to another variable. The value may be positive or negative. It varies from &#x02212;&#x02009;1 to 1. The coefficient of determination (COD), also referred to as the R2 score, is used to evaluate how effective a regression model is. The degree of change in the output dependent characteristic can be predicted from the input independent variables. When the COD score is 1, the data were correctly predicted by the regression. It ranges from 0 to 1. MAE and RMSE is a statistical indicator used to assess the efficacy of a machine learning algorithm on a particular dataset. It contrasts the variations between actual data and predictions while outlining the model evaluation error. Q represents the accuracy of the models in percentage. State of art parameters is presented in Table&#x000a0;<xref rid="Tab8" ref-type="table">8</xref> for a scenario I i.e. with original features. An optimized ensembled KRF is evaluated best with the R value as 0.9, COD value as 0.81, MAE value as 0.23, and RMSE value as 0.3. Accuracy is also best for an ensembled model and the observed value is 77% in scenario I.</p><p id="Par41">
<table-wrap id="Tab8"><label>Table 8</label><caption><p>State of art parameters in scenario I.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sr. No.</th><th align="left">Classifier</th><th align="left"><italic>R</italic> I</th><th align="left">COD I</th><th align="left">MAE I</th><th align="left">RMSE I</th><th align="left">Q I</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">GP</td><td char="." align="char">0.54</td><td char="." align="char">0.29</td><td char="." align="char">0.47</td><td char="." align="char">0.5</td><td align="left">53%</td></tr><tr><td align="left">2</td><td align="left">LR</td><td char="." align="char">0.59</td><td char="." align="char">0.35</td><td char="." align="char">0.42</td><td char="." align="char">0.5</td><td align="left">58%</td></tr><tr><td align="left">3</td><td align="left">SMO</td><td char="." align="char">0.59</td><td char="." align="char">0.35</td><td char="." align="char">0.43</td><td char="." align="char">0.5</td><td align="left">57%</td></tr><tr><td align="left">4</td><td align="left">Kstar</td><td char="." align="char">0.58</td><td char="." align="char">0.34</td><td char="." align="char">0.36</td><td char="." align="char">0.5</td><td align="left">64%</td></tr><tr><td align="left">5</td><td align="left">Bagging</td><td char="." align="char">0.61</td><td char="." align="char">0.37</td><td char="." align="char">0.4</td><td char="." align="char">0.5</td><td align="left">60%</td></tr><tr><td align="left">6</td><td align="left">DT</td><td char="." align="char">0.37</td><td char="." align="char">0.14</td><td char="." align="char">0.46</td><td char="." align="char">0.6</td><td align="left">54%</td></tr><tr><td align="left">7</td><td align="left">RF</td><td char="." align="char">0.63</td><td char="." align="char">0.4</td><td char="." align="char">0.37</td><td char="." align="char">0.5</td><td align="left">63%</td></tr><tr><td align="left">8</td><td align="left">OEKRF</td><td char="." align="char">0.90</td><td char="." align="char">0.81</td><td char="." align="char">0.23</td><td char="." align="char">0.3</td><td align="left">77%</td></tr></tbody></table></table-wrap>
</p><p id="Par42">State of art parameters is depicted in Table&#x000a0;<xref rid="Tab9" ref-type="table">9</xref> for scenario II i.e. with feature selection, resampling, and percentage split method. Optimized ensembled KRF has performed well again in comparison to other machine learning algorithms with R value as 0.91, COD value as 0.83, MAE value as 0.11, and RMSE value as 0.28. It performed well in terms of achieving an accuracy of 89% in scenario II.</p><p id="Par43">
<table-wrap id="Tab9"><label>Table 9</label><caption><p>State of art parameters in scenario II.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sr. No.</th><th align="left">Classifier</th><th align="left"><italic>R</italic> II</th><th align="left">COD II</th><th align="left">MAE II</th><th align="left">RMSE II</th><th align="left">Q II</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">GP</td><td char="." align="char">0.58</td><td char="." align="char">0.34</td><td char="." align="char">0.45</td><td char="." align="char">0.48</td><td align="left">55%</td></tr><tr><td align="left">2</td><td align="left">LR</td><td char="." align="char">0.62</td><td char="." align="char">0.38</td><td char="." align="char">0.4</td><td char="." align="char">0.47</td><td align="left">60%</td></tr><tr><td align="left">3</td><td align="left">SMO</td><td char="." align="char">0.61</td><td char="." align="char">0.37</td><td char="." align="char">0.36</td><td char="." align="char">0.43</td><td align="left">64%</td></tr><tr><td align="left">4</td><td align="left">Kstar</td><td char="." align="char">0.73</td><td char="." align="char">0.53</td><td char="." align="char">0.19</td><td char="." align="char">0.36</td><td align="left">81%</td></tr><tr><td align="left">5</td><td align="left">Bagging</td><td char="." align="char">0.69</td><td char="." align="char">0.48</td><td char="." align="char">0.36</td><td char="." align="char">0.42</td><td align="left">64%</td></tr><tr><td align="left">6</td><td align="left">DT</td><td char="." align="char">0.77</td><td char="." align="char">0.59</td><td char="." align="char">0.46</td><td char="." align="char">0.46</td><td align="left">54%</td></tr><tr><td align="left">7</td><td align="left">RF</td><td char="." align="char">0.82</td><td char="." align="char">0.67</td><td char="." align="char">0.24</td><td char="." align="char">0.42</td><td align="left">76%</td></tr><tr><td align="left">8</td><td align="left">OEKRF</td><td char="." align="char">0.91</td><td char="." align="char">0.83</td><td char="." align="char">0.11</td><td char="." align="char">0.28</td><td align="left">89%</td></tr></tbody></table></table-wrap>
</p><p id="Par44">State of art parameters is compared in Table&#x000a0;<xref rid="Tab10" ref-type="table">10</xref> for scenario III i.e. with feature selection, resampling, and 10-fold cross-validation method. The optimized ensembled model in scenario III outperforms all other models by achieving an accuracy of 93%, R value as 0.93, COD value as 0.86, MAE value as 0.07 and RMSE value as 0.25.</p><p id="Par45">
<table-wrap id="Tab10"><label>Table 10</label><caption><p>State of art parameters in scenario III.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sr. No.</th><th align="left">Classifier</th><th align="left"><italic>R</italic> III</th><th align="left">COD III</th><th align="left">MAE III</th><th align="left">RMSE III</th><th align="left">Q III</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">GP</td><td char="." align="char">0.63</td><td char="." align="char">0.40</td><td char="." align="char">0.43</td><td char="." align="char">0.48</td><td align="left">57%</td></tr><tr><td align="left">2</td><td align="left">LR</td><td char="." align="char">0.68</td><td char="." align="char">0.46</td><td char="." align="char">0.35</td><td char="." align="char">0.44</td><td align="left">65%</td></tr><tr><td align="left">3</td><td align="left">SMO</td><td char="." align="char">0.63</td><td char="." align="char">0.40</td><td char="." align="char">0.33</td><td char="." align="char">0.42</td><td align="left">67%</td></tr><tr><td align="left">4</td><td align="left">Kstar</td><td char="." align="char">0.82</td><td char="." align="char">0.67</td><td char="." align="char">0.15</td><td char="." align="char">0.34</td><td align="left">85%</td></tr><tr><td align="left">5</td><td align="left">Bagging</td><td char="." align="char">0.73</td><td char="." align="char">0.53</td><td char="." align="char">0.32</td><td char="." align="char">0.39</td><td align="left">68%</td></tr><tr><td align="left">6</td><td align="left">DT</td><td char="." align="char">0.79</td><td char="." align="char">0.62</td><td char="." align="char">0.42</td><td char="." align="char">0.43</td><td align="left">58%</td></tr><tr><td align="left">7</td><td align="left">RF</td><td char="." align="char">0.87</td><td char="." align="char">0.76</td><td char="." align="char">0.19</td><td char="." align="char">0.37</td><td align="left">81%</td></tr><tr><td align="left">8</td><td align="left">OEKRF</td><td char="." align="char">0.93</td><td char="." align="char">0.86</td><td char="." align="char">0.07</td><td char="." align="char">0.25</td><td align="left">93%</td></tr></tbody></table></table-wrap>
</p><p id="Par46">Figures&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> and <xref rid="Fig5" ref-type="fig">5</xref> present comparison of coefficient of correlation (R) and coefficient of determination (COD) in all the three scenarios respectively. Figures&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref> and <xref rid="Fig7" ref-type="fig">7</xref> depict the MAE and RMSE in all the three scenarios respectively.</p><p id="Par47">
<fig id="Fig4"><label>Fig. 4</label><caption><p>Coefficient of correlation comparison in all three scenarios.</p></caption><graphic xlink:href="41598_2025_2333_Fig4_HTML" id="d33e2448"/></fig>
</p><p id="Par48">
<fig id="Fig5"><label>Fig. 5</label><caption><p>Coefficient of determination comparison in all three scenarios.</p></caption><graphic xlink:href="41598_2025_2333_Fig5_HTML" id="d33e2459"/></fig>
</p><p id="Par49">
<fig id="Fig6"><label>Fig. 6</label><caption><p>Mean absolute error comparison in all three scenarios.</p></caption><graphic xlink:href="41598_2025_2333_Fig6_HTML" id="d33e2469"/></fig>
</p><p id="Par50">
<fig id="Fig7"><label>Fig. 7</label><caption><p>Root mean squared error comparison in all three scenarios.</p></caption><graphic xlink:href="41598_2025_2333_Fig7_HTML" id="d33e2479"/></fig>
</p><p id="Par51">The optimized ensembled toxicity prediction model KRF performs well in all the scenarios in comparison to seven machine learning algorithms. When the optimized model is compared in all three scenarios, it performed best in scenario III. Accuracy comparison is shown separately in Table&#x000a0;<xref rid="Tab11" ref-type="table">11</xref>; Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> to present the performance of all models together. The highest accuracy is achieved by optimized KRF in scenario III as 93%. For scenario I and scenario II, the accuracy achieved by the optimized model is 77% and 89% respectively.</p><p id="Par52">
<table-wrap id="Tab11"><label>Table 11</label><caption><p>Accuracy comparison for three scenarios.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2"/><th align="left" colspan="3">Accuracy</th></tr><tr><th align="left">Sr. No.</th><th align="left">Classifier</th><th align="left">Q I</th><th align="left">Q II</th><th align="left">Q III</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">GP</td><td align="left">53%</td><td align="left">55%</td><td align="left">57%</td></tr><tr><td align="left">2</td><td align="left">LR</td><td align="left">58%</td><td align="left">60%</td><td align="left">65%</td></tr><tr><td align="left">3</td><td align="left">SMO</td><td align="left">57%</td><td align="left">64%</td><td align="left">67%</td></tr><tr><td align="left">4</td><td align="left">Kstar</td><td align="left">64%</td><td align="left">81%</td><td align="left">85%</td></tr><tr><td align="left">5</td><td align="left">Bagging</td><td align="left">60%</td><td align="left">64%</td><td align="left">68%</td></tr><tr><td align="left">6</td><td align="left">DT</td><td align="left">54%</td><td align="left">54%</td><td align="left">58%</td></tr><tr><td align="left">7</td><td align="left">RF</td><td align="left">63%</td><td align="left">76%</td><td align="left">81%</td></tr><tr><td align="left">8</td><td align="left">OEKRF</td><td align="left">77%</td><td align="left">89%</td><td align="left">93%</td></tr></tbody></table></table-wrap>
</p><p id="Par53">
<fig id="Fig8"><label>Fig. 8</label><caption><p>Accuracy comparison in all three scenarios.</p></caption><graphic xlink:href="41598_2025_2333_Fig8_HTML" id="d33e2616"/></fig>
</p><p id="Par54">Further, the concept of W-saw and L-saw scores are introduced to strengthen the optimized toxicity prediction model. The operational research terms W-saw and L-saw are the composite score of multiple performance factors into a single score. W-saw score of the model should be high and L-saw score should be the lowest. Both scores show that the performance of the model is not dependent on the single factor. By pursue these scores leads to monitor changes to the model performance. Tables&#x000a0;<xref rid="Tab12" ref-type="table">12</xref> and <xref rid="Tab13" ref-type="table">13</xref> represent the W-saw score and L-saw score respectively for different machine learning algorithms. W-saw and L-saw scores comparison is shown separately in Figs.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref> and <xref rid="Fig10" ref-type="fig">10</xref> to present the performance of all models together. The W-saw score for an optimized model in scenario I is 0.83, for scenario II is 0.88, and is best for scenario III by achieving a 0.91 score.</p><p id="Par55">
<table-wrap id="Tab12"><label>Table 12</label><caption><p>W-saw score comparison for three scenarios.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sr. No.</th><th align="left">Classifier</th><th align="left">W-I</th><th align="left">W-II</th><th align="left">W-III</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">GP</td><td char="." align="char">0.45</td><td char="." align="char">0.49</td><td char="." align="char">0.53</td></tr><tr><td align="left">2</td><td align="left">LR</td><td char="." align="char">0.51</td><td char="." align="char">0.53</td><td char="." align="char">0.60</td></tr><tr><td align="left">3</td><td align="left">SMO</td><td char="." align="char">0.50</td><td char="." align="char">0.54</td><td char="." align="char">0.57</td></tr><tr><td align="left">4</td><td align="left">Kstar</td><td char="." align="char">0.52</td><td char="." align="char">0.69</td><td char="." align="char">0.78</td></tr><tr><td align="left">5</td><td align="left">Bagging</td><td char="." align="char">0.53</td><td char="." align="char">0.60</td><td char="." align="char">0.65</td></tr><tr><td align="left">6</td><td align="left">DT</td><td char="." align="char">0.35</td><td char="." align="char">0.63</td><td char="." align="char">0.66</td></tr><tr><td align="left">7</td><td align="left">RF</td><td char="." align="char">0.55</td><td char="." align="char">0.75</td><td char="." align="char">0.81</td></tr><tr><td align="left">8</td><td align="left">OEKRF</td><td char="." align="char">0.83</td><td char="." align="char">0.88</td><td char="." align="char">0.91</td></tr></tbody></table></table-wrap>
</p><p id="Par56">
<fig id="Fig9"><label>Fig. 9</label><caption><p>W-saw comparison in all three scenarios.</p></caption><graphic xlink:href="41598_2025_2333_Fig9_HTML" id="d33e2755"/></fig>
</p><p id="Par57">The L-saw score for an optimized model in the scenario I is 0.27, in scenario II is 0.20, and is best for scenario III by achieving the lowest value of 0.16.</p><p id="Par58">
<table-wrap id="Tab13"><label>Table 13</label><caption><p>L-saw score comparison for three scenarios.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Sr. No.</th><th align="left">Classifier</th><th align="left">L-I</th><th align="left">L-II</th><th align="left">L-III</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">GP</td><td char="." align="char">0.49</td><td char="." align="char">0.47</td><td char="." align="char">0.46</td></tr><tr><td align="left">2</td><td align="left">LR</td><td char="." align="char">0.46</td><td char="." align="char">0.44</td><td char="." align="char">0.40</td></tr><tr><td align="left">3</td><td align="left">SMO</td><td char="." align="char">0.47</td><td char="." align="char">0.40</td><td char="." align="char">0.38</td></tr><tr><td align="left">4</td><td align="left">Kstar</td><td char="." align="char">0.43</td><td char="." align="char">0.28</td><td char="." align="char">0.25</td></tr><tr><td align="left">5</td><td align="left">Bagging</td><td char="." align="char">0.45</td><td char="." align="char">0.39</td><td char="." align="char">0.36</td></tr><tr><td align="left">6</td><td align="left">DT</td><td char="." align="char">0.53</td><td char="." align="char">0.46</td><td char="." align="char">0.43</td></tr><tr><td align="left">7</td><td align="left">RF</td><td char="." align="char">0.44</td><td char="." align="char">0.33</td><td char="." align="char">0.28</td></tr><tr><td align="left">8</td><td align="left">OEKRF</td><td char="." align="char">0.27</td><td char="." align="char">0.20</td><td char="." align="char">0.16</td></tr></tbody></table></table-wrap>
</p><p id="Par59">
<fig id="Fig10"><label>Fig. 10</label><caption><p>L-saw comparison in all three scenarios.</p></caption><graphic xlink:href="41598_2025_2333_Fig10_HTML" id="d33e2883"/></fig>
</p><p id="Par60">Recent deep learning based models have been introduced and compared with proposed OEKRF model. AIPs-DeepEnC-GA is a deep learning model which combines the strength of deep EnC and genetic algorithm to find the nonlinear relation between molecular structure and toxicity, DeepAIPs-Pred model learns the toxic patterns by monitoring the sequence activities of features and Deepstacked-AVPs model embeds the features and finds all the possible patterns to extend the model generalization for unknown data<sup><xref ref-type="bibr" rid="CR42">42</xref></sup><sup>&#x02013;</sup><sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. Table&#x000a0;<xref rid="Tab14" ref-type="table">14</xref> depicts the performance of deep learning models. AIPs-DeepEnC-GA model performs better with R value as 0.82, COD value as 0.807, MAE as 0.24, RMSE as 0.30 and accuracy of 72%.</p><p id="Par61">
<table-wrap id="Tab14"><label>Table 14</label><caption><p>Evaluation parameters for deep learning models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifier</th><th align="left">R</th><th align="left">COD</th><th align="left">MAE</th><th align="left">RMSE</th><th align="left">Q</th></tr></thead><tbody><tr><td align="left">AIPs-DeepEnC-GA Model</td><td char="." align="char">0.82</td><td char="." align="char">0.807</td><td char="." align="char">0.24</td><td char="." align="char">0.30</td><td align="left">72%</td></tr><tr><td align="left">DeepAIPs-Pred</td><td char="." align="char">0.71</td><td char="." align="char">0.5</td><td char="." align="char">0.34</td><td char="." align="char">0.351</td><td align="left">66%</td></tr><tr><td align="left">Deepstacked-AVPs</td><td char="." align="char">0.62</td><td char="." align="char">0.296</td><td char="." align="char">0.415</td><td char="." align="char">0.419</td><td align="left">59%</td></tr></tbody></table></table-wrap>
</p><p id="Par62">So our results evaluate that optimized ensembled KRF is best in comparison to seven machine learning algorithms and three deep learning algorithms in all aspects. Table&#x000a0;<xref rid="Tab15" ref-type="table">15</xref> depicts the performance of optimized ensembled KRF in all the three scenarios. The OEKRF model achieved 93% accuracy in Scenario III that shows the strong ability of prediction for assessment of toxicity. Higher values of coefficient of correlation and coefficient of determination makes the model reliable for assessing toxic and non-toxic compounds. Low values of MAE and RMSE make the model compatible for real world applications where prediction of toxicity plays an important role for drug development and predictions at early stage reduces the requirement of extensive testing and saves resources and time.</p><p id="Par63">
<table-wrap id="Tab15"><label>Table 15</label><caption><p>OEKRF comparison for three scenarios.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Classifier</th><th align="left">R</th><th align="left">COD</th><th align="left">MAE</th><th align="left">RMSE</th><th align="left">Accuracy</th><th align="left">W-Saw</th><th align="left">L-Saw</th></tr></thead><tbody><tr><td align="left">OEKRF-I</td><td char="." align="char">0.90</td><td char="." align="char">0.81</td><td char="." align="char">0.23</td><td char="." align="char">0.3</td><td align="left">77%</td><td char="." align="char">0.83</td><td char="." align="char">0.27</td></tr><tr><td align="left">OEKRF-II</td><td char="." align="char">0.91</td><td char="." align="char">0.83</td><td char="." align="char">0.11</td><td char="." align="char">0.28</td><td align="left">89%</td><td char="." align="char">0.88</td><td char="." align="char">0.20</td></tr><tr><td align="left">OEKRF-III</td><td char="." align="char">0.93</td><td char="." align="char">0.86</td><td char="." align="char">0.07</td><td char="." align="char">0.25</td><td align="left">93%</td><td char="." align="char">0.91</td><td char="." align="char">0.16</td></tr></tbody></table></table-wrap>
</p><p id="Par64">State of art parameters for all the three scenarios is presented. Figure&#x000a0;<xref rid="Fig11" ref-type="fig">11</xref> presents the comparison of R and COD values; Fig.&#x000a0;<xref rid="Fig12" ref-type="fig">12</xref> presents comparison of MAE and RMSE values; Fig.&#x000a0;<xref rid="Fig13" ref-type="fig">13</xref> is representing accuracy; and Fig.&#x000a0;<xref rid="Fig14" ref-type="fig">14</xref> is presenting saw scores with highest and lowest scores.</p><p id="Par65">
<fig id="Fig11"><label>Fig. 11</label><caption><p>R and COD values comparison in all three scenarios for OEKRF.</p></caption><graphic xlink:href="41598_2025_2333_Fig11_HTML" id="d33e3081"/></fig>
</p><p id="Par66">
<fig id="Fig12"><label>Fig. 12</label><caption><p>MAE and RMSE comparison in all three scenarios for OEKRF.</p></caption><graphic xlink:href="41598_2025_2333_Fig12_HTML" id="d33e3091"/></fig>
</p><p id="Par67">
<fig id="Fig13"><label>Fig. 13</label><caption><p>Accuracy comparison in all three scenarios for OEKRF.</p></caption><graphic xlink:href="41598_2025_2333_Fig13_HTML" id="d33e3101"/></fig>
</p><p id="Par68">
<fig id="Fig14"><label>Fig. 14</label><caption><p>Saw score comparison in all three scenarios for OEKRF.</p></caption><graphic xlink:href="41598_2025_2333_Fig14_HTML" id="d33e3111"/></fig>
</p><p id="Par69">When the optimized ensembled model KRF itself is compared in three different scenarios, it performs exceptionally well in scenario III with feature selection, resampling, and 10 F-CV.</p></sec></sec><sec id="Sec15"><title>Conclusion</title><p id="Par70">Prediction of toxicity has been quite a challenging and crucial task from the start of the medical era. But now AI and ML brought a revolution in the healthcare industry. It is possible to optimize this challenging task now. We developed an optimized ensembled toxicity prediction model KRF in the research. We evaluated and compared state of art parameters for seven machine learning algorithms along with the optimized model. The optimized ensembled model performs well in all three scenarios mentioned in the presented work. Scenario-wise results are shown in the paper with evaluated values of state of art parameters. An optimized model performs exceptionally well in all the scenarios, But when compared to the model itself in all three scenarios, scenario III performs best in all the aspects. Deep learning algorithms are also introduced to compare with the optimized model. The optimized ensembled KRF achieves the highest accuracy of 93% in scenario III which was best in comparison to scenario I and scenario II with values of 77% and 89% respectively. The R value, COD value, MAE value, and RMSE values are 0.93, 0.86, 0.07, and 0.25 respectively for scenario III. Further W-saw and L-saw values for scenario III are 0.91 and 0.16 respectively. So the results are established and validated for all the scenarios but on applying feature selection, resampling, and 10 F-CV technique results are best and optimized. The future prospect of the proposed model (OEKRF) is to easily adopt the sudden changes and works in the dynamic environment and learn from large historical data to identify the patterns which helps to extend the model generalization for unseen data. In the coming era, results can be optimized by using new machine learning algorithms. Optimized combinations of features can be introduced by using new feature selection methods. Ensembling of more algorithms can be performed and results can be analyzed by using new parameters. Although the performance of the model is quite satisfactory but further there is a scope of improvement that leads to use computational science such as automata theory to reduce the computational overhead, recommendation at every level and explore all the possibilities with corresponding solutions.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author contributions</title><p>Deepak Rawat, Rohit Bajaj, Rachit Manchanda, Ankush Mehta&#x02013; Conceptualization, Methodology, Software, Former Analysis, Writing Original Draft, Funding Acquisition, Project Administration. Prabhu Paramasivam, Suraj Kumar Bhagat, Abinet Gosaye Ayanie &#x02013; Validation, Investigation, Resources, Data Curation, Supervision, Writing- Reviewing and Editing.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>Data is available within the manuscript and further can be requested from the corresponding author on reasonable request.</p></notes><notes><title>Declarations</title><notes id="FPar3"><title>Consent for publication</title><p id="Par71">All the authors have given consent for publication.</p></notes><notes id="FPar4" notes-type="COI-statement"><title>Competing interests</title><p id="Par72">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Antelo-Collado</surname><given-names>A</given-names></name><name><surname>Carrasco-Velar</surname><given-names>R</given-names></name><name><surname>Garc&#x000ed;a-Pedrajas</surname><given-names>N</given-names></name></person-group><article-title>Cerruela-Garc&#x000ed;a, G. Effective feature selection method for Class-Imbalance datasets applied to chemical toxicity prediction</article-title><source>J. Chem. Inf. Model.</source><year>2021</year><volume>61</volume><fpage>76</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1021/acs.jcim.0c00908</pub-id><pub-id pub-id-type="pmid">33350301</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Antelo-Collado, A., Carrasco-Velar, R. &#x00026; Garc&#x000ed;a-Pedrajas, N. Cerruela-Garc&#x000ed;a, G. Effective feature selection method for Class-Imbalance datasets applied to chemical toxicity prediction. <italic>J. Chem. Inf. Model.</italic><bold>61</bold>, 76&#x02013;94 (2021).<pub-id pub-id-type="pmid">33350301</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>L</given-names></name><etal/></person-group><article-title>Insights into pesticide toxicity against aquatic organism: QSTR models on Daphnia Magna</article-title><source>Ecotoxicol. Environ. Saf.</source><year>2019</year><volume>173</volume><fpage>285</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1016/j.ecoenv.2019.02.014</pub-id><pub-id pub-id-type="pmid">30776561</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">He, L. et al. Insights into pesticide toxicity against aquatic organism: QSTR models on Daphnia Magna. <italic>Ecotoxicol. Environ. Saf.</italic><bold>173</bold>, 285&#x02013;292 (2019).<pub-id pub-id-type="pmid">30776561</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Sharma</surname><given-names>D</given-names></name><name><surname>Singh Aujla</surname><given-names>G</given-names></name><name><surname>Bajaj</surname><given-names>R</given-names></name></person-group><article-title>Evolution from ancient medication to human-centered healthcare 4.0: A review on health care recommender systems</article-title><source>Int. J. Commun. Syst.</source><year>2023</year><volume>36</volume><fpage>1</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1002/dac.4058</pub-id></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Sharma, D., Singh Aujla, G. &#x00026; Bajaj, R. Evolution from ancient medication to human-centered healthcare 4.0: A review on health care recommender systems. <italic>Int. J. Commun. Syst.</italic><bold>36</bold>, 1&#x02013;40 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Karim</surname><given-names>A</given-names></name><etal/></person-group><article-title>Quantitative toxicity prediction via meta ensembling of multitask deep learning models</article-title><source>ACS Omega</source><year>2021</year><volume>6</volume><fpage>12306</fpage><lpage>12317</lpage><pub-id pub-id-type="doi">10.1021/acsomega.1c01247</pub-id><pub-id pub-id-type="pmid">34056383</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Karim, A. et al. Quantitative toxicity prediction via meta ensembling of multitask deep learning models. <italic>ACS Omega</italic>. <bold>6</bold>, 12306&#x02013;12317 (2021).<pub-id pub-id-type="pmid">34056383</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Mistry</surname><given-names>P</given-names></name><etal/></person-group><article-title>Prediction of the effect of formulation on the toxicity of chemicals</article-title><source>Toxicol. Res. (Camb)</source><year>2017</year><volume>6</volume><fpage>42</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1039/C6TX00303F</pub-id><pub-id pub-id-type="pmid">28261444</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Mistry, P. et al. Prediction of the effect of formulation on the toxicity of chemicals. <italic>Toxicol. Res. (Camb)</italic>. <bold>6</bold>, 42&#x02013;53 (2017).<pub-id pub-id-type="pmid">28261444</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Wu, Y. &#x00026; Wang, G. Machine learning based toxicity prediction: from chemical structural description to transcriptome analysis. <italic>Int. J. Mol. Sci.</italic><bold>19</bold>, 2358 (2018).</mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Usak</surname><given-names>M</given-names></name><etal/></person-group><article-title>Health care service delivery based on the internet of things: A systematic and comprehensive study</article-title><source>Int. J. Commun. Syst.</source><year>2020</year><volume>33</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1002/dac.4179</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Usak, M. et al. Health care service delivery based on the internet of things: A systematic and comprehensive study. <italic>Int. J. Commun. Syst.</italic><bold>33</bold>, 1&#x02013;17 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>NC</given-names></name><etal/></person-group><article-title>Characterizing cleft palate toxicants using ToxCast data, chemical structure, and the biomedical literature</article-title><source>Birth Defects Res.</source><year>2020</year><volume>112</volume><fpage>19</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1002/bdr2.1581</pub-id><pub-id pub-id-type="pmid">31471948</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Baker, N. C. et al. Characterizing cleft palate toxicants using ToxCast data, chemical structure, and the biomedical literature. <italic>Birth Defects Res.</italic><bold>112</bold>, 19&#x02013;39 (2020).<pub-id pub-id-type="pmid">31471948</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>U&#x000e7;ar</surname><given-names>MK</given-names></name></person-group><article-title>Classification Performance-Based feature selection algorithm for machine learning: P-Score</article-title><source>Irbm</source><year>2020</year><volume>41</volume><fpage>229</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1016/j.irbm.2020.01.006</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">U&#x000e7;ar, M. K. Classification Performance-Based feature selection algorithm for machine learning: P-Score. <italic>Irbm</italic><bold>41</bold>, 229&#x02013;239 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Takci</surname><given-names>H</given-names></name></person-group><article-title>Improvement of heart attack prediction by the feature selection methods</article-title><source>Turkish J. Electr. Eng. Comput. Sci.</source><year>2018</year><volume>26</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.3906/elk-1611-235</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Takci, H. Improvement of heart attack prediction by the feature selection methods. <italic>Turkish J. Electr. Eng. Comput. Sci.</italic><bold>26</bold>, 1&#x02013;10 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zeng</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Huang</surname><given-names>G</given-names></name></person-group><article-title>Bin. Unsupervised feature selection based extreme learning machine for clustering</article-title><source>Neurocomputing</source><year>2020</year><volume>386</volume><fpage>198</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2019.12.065</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Chen, J., Zeng, Y., Li, Y. &#x00026; Huang, G. Bin. Unsupervised feature selection based extreme learning machine for clustering. <italic>Neurocomputing</italic><bold>386</bold>, 198&#x02013;207 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Babaagba, K. O. &#x00026; Adesanya, S. O. A study on the effect of feature selection on malware analysis using machine learning. <italic>ACM Int. Conf. Proceeding Ser.</italic> Part F1481, 51&#x02013;55 (2019).</mixed-citation></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>SD</given-names></name><name><surname>Das</surname><given-names>S</given-names></name><name><surname>Kar</surname><given-names>D</given-names></name><name><surname>Schwenker</surname><given-names>F</given-names></name><name><surname>Sarkar</surname><given-names>R</given-names></name></person-group><article-title>Computer aided breast cancer detection using ensembling of texture and statistical image features</article-title><source>Sensors</source><year>2021</year><volume>21</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.3390/s21113628</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Roy, S. D., Das, S., Kar, D., Schwenker, F. &#x00026; Sarkar, R. Computer aided breast cancer detection using ensembling of texture and statistical image features. <italic>Sensors</italic><bold>21</bold>, 1&#x02013;17 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Gormez</surname><given-names>Y</given-names></name><name><surname>Aydin</surname><given-names>Z</given-names></name><name><surname>Karademir</surname><given-names>R</given-names></name><name><surname>Gungor</surname><given-names>VC</given-names></name></person-group><article-title>A deep learning approach with bayesian optimization and ensemble classifiers for detecting denial of service attacks</article-title><source>Int. J. Commun. Syst.</source><year>2020</year><volume>33</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1002/dac.4401</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Gormez, Y., Aydin, Z., Karademir, R. &#x00026; Gungor, V. C. A deep learning approach with bayesian optimization and ensemble classifiers for detecting denial of service attacks. <italic>Int. J. Commun. Syst.</italic><bold>33</bold>, 1&#x02013;16 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Sumonja</surname><given-names>N</given-names></name><name><surname>Gemovic</surname><given-names>B</given-names></name><name><surname>Veljkovic</surname><given-names>N</given-names></name><name><surname>Perovic</surname><given-names>V</given-names></name></person-group><article-title>Automated feature engineering improves prediction of protein&#x02013;protein interactions</article-title><source>Amino Acids</source><year>2019</year><volume>51</volume><fpage>1187</fpage><lpage>1200</lpage><pub-id pub-id-type="doi">10.1007/s00726-019-02756-9</pub-id><pub-id pub-id-type="pmid">31278492</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Sumonja, N., Gemovic, B., Veljkovic, N. &#x00026; Perovic, V. Automated feature engineering improves prediction of protein&#x02013;protein interactions. <italic>Amino Acids</italic>. <bold>51</bold>, 1187&#x02013;1200 (2019).<pub-id pub-id-type="pmid">31278492</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Greenstein-Messica</surname><given-names>A</given-names></name><name><surname>Rokach</surname><given-names>L</given-names></name></person-group><article-title>Machine learning and operation research based method for promotion optimization of products with no price elasticity history</article-title><source>Electron. Commer. Res. Appl.</source><year>2020</year><volume>40</volume><fpage>100914</fpage><pub-id pub-id-type="doi">10.1016/j.elerap.2019.100914</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Greenstein-Messica, A. &#x00026; Rokach, L. Machine learning and operation research based method for promotion optimization of products with no price elasticity history. <italic>Electron. Commer. Res. Appl.</italic><bold>40</bold>, 100914 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Raghuwanshi</surname><given-names>BS</given-names></name><name><surname>Shukla</surname><given-names>S</given-names></name></person-group><article-title>Classifying imbalanced data using BalanceCascade-based kernelized extreme learning machine</article-title><source>Pattern Anal. Appl.</source><year>2020</year><volume>23</volume><fpage>1157</fpage><lpage>1182</lpage><pub-id pub-id-type="doi">10.1007/s10044-019-00844-w</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Raghuwanshi, B. S. &#x00026; Shukla, S. Classifying imbalanced data using BalanceCascade-based kernelized extreme learning machine. <italic>Pattern Anal. Appl.</italic><bold>23</bold>, 1157&#x02013;1182 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>MR</given-names></name><name><surname>Martinez</surname><given-names>T</given-names></name></person-group><article-title>The robustness of majority voting compared to filtering misclassified instances in supervised classification tasks</article-title><source>Artif. Intell. Rev.</source><year>2018</year><volume>49</volume><fpage>105</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1007/s10462-016-9518-2</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Smith, M. R. &#x00026; Martinez, T. The robustness of majority voting compared to filtering misclassified instances in supervised classification tasks. <italic>Artif. Intell. Rev.</italic><bold>49</bold>, 105&#x02013;130 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>B</given-names></name><name><surname>Dalwadi</surname><given-names>G</given-names></name><name><surname>Pandey</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>H</given-names></name><name><surname>Kothari</surname><given-names>N</given-names></name></person-group><article-title>Online CQI-based optimization using k-means and machine learning approach under sparse system knowledge</article-title><source>Int. J. Commun. Syst.</source><year>2020</year><volume>33</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1002/dac.4200</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Shah, B., Dalwadi, G., Pandey, A., Shah, H. &#x00026; Kothari, N. Online CQI-based optimization using k-means and machine learning approach under sparse system knowledge. <italic>Int. J. Commun. Syst.</italic><bold>33</bold>, 1&#x02013;13 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>B</given-names></name><etal/></person-group><article-title>A comparison of machine learning approaches to detect botnet traffic</article-title><source>Proc. Int. Jt. Conf. Neural Networks</source><year>2018</year><volume>2018-July</volume><fpage>1</fpage><lpage>8</lpage></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Abraham, B. et al. A comparison of machine learning approaches to detect botnet traffic. <italic>Proc. Int. Jt. Conf. Neural Networks</italic>. <bold>2018-July</bold>, 1&#x02013;8 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Hooda</surname><given-names>N</given-names></name><name><surname>Bawa</surname><given-names>S</given-names></name><name><surname>Rana</surname><given-names>PS</given-names></name></person-group><article-title>Optimizing fraudulent firm prediction using ensemble machine learning: A case study of an external audit</article-title><source>Appl. Artif. Intell.</source><year>2020</year><volume>34</volume><fpage>20</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1080/08839514.2019.1680182</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Hooda, N., Bawa, S. &#x00026; Rana, P. S. Optimizing fraudulent firm prediction using ensemble machine learning: A case study of an external audit. <italic>Appl. Artif. Intell.</italic><bold>34</bold>, 20&#x02013;30 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Pham</surname><given-names>TH</given-names></name><etal/></person-group><article-title>Fusion of B-mode and shear wave elastography ultrasound features for automated detection of axillary lymph node metastasis in breast carcinoma</article-title><source>Expert Syst.</source><year>2022</year><volume>39</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1111/exsy.12947</pub-id></element-citation><mixed-citation id="mc-CR22" publication-type="journal">Pham, T. H. et al. Fusion of B-mode and shear wave elastography ultrasound features for automated detection of axillary lymph node metastasis in breast carcinoma. <italic>Expert Syst.</italic><bold>39</bold>, 1&#x02013;19 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Alwadi</surname><given-names>M</given-names></name><name><surname>Chetty</surname><given-names>G</given-names></name><name><surname>Yamin</surname><given-names>M</given-names></name></person-group><article-title>A framework for vehicle quality evaluation based on interpretable machine learning</article-title><source>Int. J. Inf. Technol.</source><year>2022</year><pub-id pub-id-type="doi">10.1007/s41870-022-01121-6</pub-id><pub-id pub-id-type="pmid">36466771</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Alwadi, M., Chetty, G. &#x00026; Yamin, M. A framework for vehicle quality evaluation based on interpretable machine learning. <italic>Int. J. Inf. Technol.</italic>10.1007/s41870-022-01121-6 (2022).<pub-id pub-id-type="pmid">36466771</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><etal/></person-group><article-title>Development of novel prediction model for drug-induced mitochondrial toxicity by using Na&#x000ef;ve Bayes classifier method</article-title><source>Food Chem. Toxicol.</source><year>2017</year><volume>110</volume><fpage>122</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1016/j.fct.2017.10.021</pub-id><pub-id pub-id-type="pmid">29042293</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Zhang, H. et al. Development of novel prediction model for drug-induced mitochondrial toxicity by using Na&#x000ef;ve Bayes classifier method. <italic>Food Chem. Toxicol.</italic><bold>110</bold>, 122&#x02013;129 (2017).<pub-id pub-id-type="pmid">29042293</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Sukumaran, C. et al. The Role of AI in Biochips for Early Disease Detection, <italic>2023 3rd International Conference on Technological Advancements in Computational Sciences (ICTACS)</italic>, Tashkent, Uzbekistan, pp. 1323&#x02013;1328, (2023). 10.1109/ICTACS59847.2023.10390419</mixed-citation></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Sarwar</surname><given-names>A</given-names></name><name><surname>Ali</surname><given-names>M</given-names></name><name><surname>Manhas</surname><given-names>J</given-names></name><name><surname>Sharma</surname><given-names>V</given-names></name></person-group><article-title>Diagnosis of diabetes type-II using hybrid machine learning based ensemble model</article-title><source>Int. J. Inf. Technol.</source><year>2020</year><volume>12</volume><fpage>419</fpage><lpage>428</lpage></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Sarwar, A., Ali, M., Manhas, J. &#x00026; Sharma, V. Diagnosis of diabetes type-II using hybrid machine learning based ensemble model. <italic>Int. J. Inf. Technol.</italic><bold>12</bold>, 419&#x02013;428 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Verma</surname><given-names>KK</given-names></name><name><surname>Singh</surname><given-names>BM</given-names></name><name><surname>Dixit</surname><given-names>A</given-names></name></person-group><article-title>A review of supervised and unsupervised machine learning techniques for suspicious behavior recognition in intelligent surveillance system</article-title><source>Int. J. Inf. Technol.</source><year>2022</year><volume>14</volume><fpage>397</fpage><lpage>410</lpage></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Verma, K. K., Singh, B. M. &#x00026; Dixit, A. A review of supervised and unsupervised machine learning techniques for suspicious behavior recognition in intelligent surveillance system. <italic>Int. J. Inf. Technol.</italic><bold>14</bold>, 397&#x02013;410 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Bojamma</surname><given-names>AM</given-names></name><name><surname>Shastry</surname><given-names>C</given-names></name></person-group><article-title>A study on the machine learning techniques for automated plant species identification: current trends and challenges</article-title><source>Int. J. Inf. Technol.</source><year>2021</year><volume>13</volume><fpage>989</fpage><lpage>995</lpage></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Bojamma, A. M. &#x00026; Shastry, C. A study on the machine learning techniques for automated plant species identification: current trends and challenges. <italic>Int. J. Inf. Technol.</italic><bold>13</bold>, 989&#x02013;995 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Shidnal</surname><given-names>S</given-names></name><name><surname>Latte</surname><given-names>MV</given-names></name><name><surname>Kapoor</surname><given-names>A</given-names></name></person-group><article-title>Crop yield prediction: two-tiered machine learning model approach</article-title><source>Int. J. Inf. Technol.</source><year>2021</year><volume>13</volume><fpage>1983</fpage><lpage>1991</lpage></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Shidnal, S., Latte, M. V. &#x00026; Kapoor, A. Crop yield prediction: two-tiered machine learning model approach. <italic>Int. J. Inf. Technol.</italic><bold>13</bold>, 1983&#x02013;1991 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Gini, G., Benfenati, E. &#x00026; Boley, D. Clustering and classification techniques to assess aquatic toxicity. <italic>4th Int. Conf. Knowledge-Based Intell. Eng. Syst. Allied Technol. KES 2000 - Proc.</italic> 1, 166&#x02013;172 (2000).</mixed-citation></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L</given-names></name><etal/></person-group><article-title>Applications of machine learning methods in drug toxicity prediction</article-title><source>Curr. Top. Med. Chem.</source><year>2018</year><volume>18</volume><fpage>987</fpage><lpage>997</lpage><pub-id pub-id-type="doi">10.2174/1568026618666180727152557</pub-id><pub-id pub-id-type="pmid">30051792</pub-id>
</element-citation><mixed-citation id="mc-CR31" publication-type="journal">Zhang, L. et al. Applications of machine learning methods in drug toxicity prediction. <italic>Curr. Top. Med. Chem.</italic><bold>18</bold>, 987&#x02013;997 (2018).<pub-id pub-id-type="pmid">30051792</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Basile</surname><given-names>AO</given-names></name><name><surname>Yahi</surname><given-names>A</given-names></name><name><surname>Tatonetti</surname><given-names>NP</given-names></name></person-group><article-title>Artificial intelligence for drug toxicity and safety</article-title><source>Trends Pharmacol. Sci.</source><year>2019</year><volume>40</volume><fpage>624</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1016/j.tips.2019.07.005</pub-id><pub-id pub-id-type="pmid">31383376</pub-id>
</element-citation><mixed-citation id="mc-CR32" publication-type="journal">Basile, A. O., Yahi, A. &#x00026; Tatonetti, N. P. Artificial intelligence for drug toxicity and safety. <italic>Trends Pharmacol. Sci.</italic><bold>40</bold>, 624&#x02013;635 (2019).<pub-id pub-id-type="pmid">31383376</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Borrero</surname><given-names>LA</given-names></name><name><surname>Guette</surname><given-names>LS</given-names></name><name><surname>Lopez</surname><given-names>E</given-names></name><name><surname>Pineda</surname><given-names>OB</given-names></name><name><surname>Castro</surname><given-names>EB</given-names></name></person-group><article-title>Predicting toxicity properties through machine learning</article-title><source>Procedia Comput. Sci.</source><year>2020</year><volume>170</volume><fpage>1011</fpage><lpage>1016</lpage><pub-id pub-id-type="doi">10.1016/j.procs.2020.03.093</pub-id></element-citation><mixed-citation id="mc-CR33" publication-type="journal">Borrero, L. A., Guette, L. S., Lopez, E., Pineda, O. B. &#x00026; Castro, E. B. Predicting toxicity properties through machine learning. <italic>Procedia Comput. Sci.</italic><bold>170</bold>, 1011&#x02013;1016 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name><surname>Hooda</surname><given-names>N</given-names></name><name><surname>Bawa</surname><given-names>S</given-names></name><name><surname>Rana</surname><given-names>PS</given-names></name></person-group><article-title>B2FSE framework for high dimensional imbalanced data: A case study for drug toxicity prediction</article-title><source>Neurocomputing</source><year>2018</year><volume>276</volume><fpage>31</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2017.04.081</pub-id></element-citation><mixed-citation id="mc-CR34" publication-type="journal">Hooda, N., Bawa, S. &#x00026; Rana, P. S. B2FSE framework for high dimensional imbalanced data: A case study for drug toxicity prediction. <italic>Neurocomputing</italic><bold>276</bold>, 31&#x02013;41 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>AJ</given-names></name><name><surname>Barnard</surname><given-names>AS</given-names></name></person-group><article-title>Selecting appropriate clustering methods for materials science applications of machine learning</article-title><source>Adv. Theory Simulations</source><year>2019</year><volume>2</volume><fpage>1</fpage><lpage>8</lpage></element-citation><mixed-citation id="mc-CR35" publication-type="journal">Parker, A. J. &#x00026; Barnard, A. S. Selecting appropriate clustering methods for materials science applications of machine learning. <italic>Adv. Theory Simulations</italic>. <bold>2</bold>, 1&#x02013;8 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Prabagar, S., Al-Jiboory, A. K., Nair, P. S., Mandal, P. &#x00026; Garse, K. M. N. L, Artificial Intelligence-Based Control Strategies for Unmanned Aerial Vehicles, <italic>10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer</italic> Engineering <italic>(UPCON)</italic>, Gautam Buddha Nagar, India, 2023, pp. 1624&#x02013;1629, (2023). 10.1109/UPCON59197.2023.10434918</mixed-citation></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name><surname>Gajewicz-Skretna</surname><given-names>A</given-names></name><name><surname>Furuhama</surname><given-names>A</given-names></name><name><surname>Yamamoto</surname><given-names>H</given-names></name><name><surname>Suzuki</surname><given-names>N</given-names></name></person-group><article-title>Generating accurate in Silico predictions of acute aquatic toxicity for a range of organic chemicals: towards similarity-based machine learning methods</article-title><source>Chemosphere</source><year>2021</year><volume>280</volume><fpage>130681</fpage><pub-id pub-id-type="doi">10.1016/j.chemosphere.2021.130681</pub-id><pub-id pub-id-type="pmid">34162070</pub-id>
</element-citation><mixed-citation id="mc-CR37" publication-type="journal">Gajewicz-Skretna, A., Furuhama, A., Yamamoto, H. &#x00026; Suzuki, N. Generating accurate in Silico predictions of acute aquatic toxicity for a range of organic chemicals: towards similarity-based machine learning methods. <italic>Chemosphere</italic><bold>280</bold>, 130681 (2021).<pub-id pub-id-type="pmid">34162070</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name><surname>Ai</surname><given-names>H</given-names></name><etal/></person-group><article-title>QSAR modelling study of the bioconcentration factor and toxicity of organic compounds to aquatic organisms using machine learning and ensemble methods</article-title><source>Ecotoxicol. Environ. Saf.</source><year>2019</year><volume>179</volume><fpage>71</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.ecoenv.2019.04.035</pub-id><pub-id pub-id-type="pmid">31026752</pub-id>
</element-citation><mixed-citation id="mc-CR38" publication-type="journal">Ai, H. et al. QSAR modelling study of the bioconcentration factor and toxicity of organic compounds to aquatic organisms using machine learning and ensemble methods. <italic>Ecotoxicol. Environ. Saf.</italic><bold>179</bold>, 71&#x02013;78 (2019).<pub-id pub-id-type="pmid">31026752</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Pathak, Y., Rana, P. S., Singh, P. K., &#x00026; Saraswat, M. Protein structure prediction (RMSD&#x02264; 5 &#x000c5;) using machine learning models. <italic>International Journal of Data Mining and Bioinformatics</italic>, <bold>14</bold>, 71&#x02013;85 (2016).</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Mishra, S., &#x00026; Ahirwar, A. Comparative study of machine learning models in protein structure prediction. <italic>Int J Comput Sci Inf Technol,</italic><bold>6</bold>, 5398&#x02013;5404 (2015).</mixed-citation></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name><surname>Aagashram Neelakandan</surname><given-names>ASA</given-names></name><name><surname>Doss</surname><given-names>N</given-names></name><name><surname>Lakshmaiya</surname></name></person-group><article-title>Computational design exploration of rocket nozzle using deep reinforcement learning</article-title><source>Results Eng.</source><year>2025</year><volume>25</volume><fpage>104439</fpage><pub-id pub-id-type="doi">10.1016/j.rineng.2025.104439</pub-id></element-citation><mixed-citation id="mc-CR41" publication-type="journal">Aagashram Neelakandan, A. S. A., Doss, N. &#x00026; Lakshmaiya Computational design exploration of rocket nozzle using deep reinforcement learning. <italic>Results Eng.</italic><bold>25</bold>, 104439. 10.1016/j.rineng.2025.104439 (2025).</mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>Tran</surname><given-names>TT</given-names></name><name><surname>Van</surname><given-names>S</given-names></name><name><surname>Wibowo</surname><given-names>A</given-names></name><name><surname>Tayara</surname><given-names>H</given-names></name><name><surname>Chong</surname><given-names>KT</given-names></name></person-group><article-title>Artificial intelligence in drug toxicity prediction: recent advances, challenges, and future perspectives</article-title><source>J. Chem. Inf. Model.</source><year>2023</year><volume>63</volume><fpage>2628</fpage><lpage>2643</lpage><pub-id pub-id-type="doi">10.1021/acs.jcim.3c00200</pub-id><pub-id pub-id-type="pmid">37125780</pub-id>
</element-citation><mixed-citation id="mc-CR42" publication-type="journal">Tran, T. T., Van, S., Wibowo, A., Tayara, H. &#x00026; Chong, K. T. Artificial intelligence in drug toxicity prediction: recent advances, challenges, and future perspectives. <italic>J. Chem. Inf. Model.</italic><bold>63</bold>, 2628&#x02013;2643 (2023).<pub-id pub-id-type="pmid">37125780</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name><surname>Akbar</surname><given-names>S</given-names></name><name><surname>Raza</surname><given-names>A</given-names></name><name><surname>Zou</surname><given-names>Q</given-names></name></person-group><article-title>Deepstacked-AVPs: predicting antiviral peptides using tri-segment evolutionary profile and word embedding based multi-perspective features with deep stacking model</article-title><source>BMC Bioinform.</source><year>2024</year><volume>25</volume><fpage>102</fpage><pub-id pub-id-type="doi">10.1186/s12859-024-05726-5</pub-id></element-citation><mixed-citation id="mc-CR43" publication-type="journal">Akbar, S., Raza, A. &#x00026; Zou, Q. Deepstacked-AVPs: predicting antiviral peptides using tri-segment evolutionary profile and word embedding based multi-perspective features with deep stacking model. <italic>BMC Bioinform.</italic><bold>25</bold>, 102 (2024).</mixed-citation></citation-alternatives></ref></ref-list></back></article>