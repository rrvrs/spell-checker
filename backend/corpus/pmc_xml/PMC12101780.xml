<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS One</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40408532</article-id><article-id pub-id-type="pmc">PMC12101780</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0322358</article-id><article-id pub-id-type="publisher-id">PONE-D-24-47635</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject><subj-group><subject>Cheeks</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject><subj-group><subject>Cheeks</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Biological Tissue</subject><subj-group><subject>Soft Tissues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Biological Tissue</subject><subj-group><subject>Soft Tissues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Equipment</subject><subj-group><subject>Optical Equipment</subject><subj-group><subject>Lasers</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Surgical and Invasive Medical Procedures</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject><subj-group><subject>Chin</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject><subj-group><subject>Chin</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject><subj-group><subject>Nose</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Head</subject><subj-group><subject>Face</subject><subj-group><subject>Nose</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>The accuracy of three-dimensional facial scan obtained from three different 3d scanners</article-title><alt-title alt-title-type="running-head">The accuracy of three-dimensional facial scan obtained from three different 3d scanners</alt-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0009-8616-1094</contrib-id><name><surname>Tangthaweesuk</surname><given-names>Nichakun</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8058-6010</contrib-id><name><surname>Raocharernporn</surname><given-names>Somchart</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="cor001" ref-type="corresp">*</xref><xref rid="aff001" ref-type="aff"/></contrib></contrib-group><aff id="aff001">
<addr-line>Department of Oral and Maxillofacial Surgery, Faculty of Dentistry, Mahidol University, Bangkok, Thailand</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Abdullah</surname><given-names>Johari Yap</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>Universiti Sains Malaysia, MALAYSIA</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>somchart.gj@gmail.com</email></corresp></author-notes><pub-date pub-type="epub"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>20</volume><issue>5</issue><elocation-id>e0322358</elocation-id><history><date date-type="received"><day>30</day><month>10</month><year>2024</year></date><date date-type="accepted"><day>20</day><month>3</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 Tangthaweesuk, Raocharernporn</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Tangthaweesuk, Raocharernporn</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0322358.pdf">
</self-uri><abstract><p>This study aimed to compare the accuracy (trueness and precision) and reproducibility of three 3D facial scanning systems: a laser scanner (Planmeca Proface), a dual-structured light scanner (EinScan H2), and a smartphone application (EM3D Scanner). Thirty subjects with skeletal deformities scheduled for orthognathic surgery were scanned using these systems, and the resulting 90 3D facial scans were compared with facial surfaces segmented from CBCT scans. Surface discrepancies were measured using root mean square (RMS) values across five facial aesthetic areas (cheeks, nasal, perioral, and mental units) through Geomagic Control X software. The EM3D Scanner showed significantly better trueness and precision compared to the EinScan H2, particularly for the overall face (p&#x02009;&#x0003c;&#x02009;0.01). Planmeca Proface showed no significant difference from the other scanners in terms of error. The nasal and perioral regions, scanned with Planmeca Proface, achieved the highest accuracy compared to other areas, while the left cheek demonstrated the lowest accuracy. Up to 80% of the scanned areas were classified as reproducible, falling within acceptable tolerance limits. Overall, trueness values ranged from 0.70 to 0.85&#x02009;mm, and precision ranged from 0.68 to 0.81&#x02009;mm, with deviations of less than 1.0&#x02009;mm deemed highly acceptable for clinical applications. Surface regions closer to the midline were found to have higher accuracy than those on the sides of the face. These findings highlight the potential of EM3D Scanner and Planmeca Proface for accurate and reliable facial scanning, particularly in clinical settings where minimal deviation is crucial.</p></abstract><funding-group><funding-statement>The author(s) received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="7"/><table-count count="7"/><page-count count="21"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the manuscript and its <xref rid="sec014" ref-type="sec">Supporting Information</xref> files.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the manuscript and its <xref rid="sec014" ref-type="sec">Supporting Information</xref> files.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Comprehensive diagnosis and treatment planning are essential components of oral and face rehabilitation [<xref rid="pone.0322358.ref001" ref-type="bibr">1</xref>,<xref rid="pone.0322358.ref002" ref-type="bibr">2</xref>]. In craniofacial-maxillofacial surgery, facial morphology study plays an important role for preoperative diagnosis, postoperative evaluation, symmetry analysis, and other purposes. Additionally, it can provide helpful reference values for prosthodontics and orthodontics [<xref rid="pone.0322358.ref003" ref-type="bibr">3</xref>]. Undoubtedly, technological advancements in Three-dimensional (3D) face scanning devices have revolutionized methods of facial soft tissue analysis. The conventional methods such as direct anthropometry and Two-dimensional photogrammetry (2D) are now being challenged by the superior capabilities of 3D face scanning [<xref rid="pone.0322358.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0322358.ref005" ref-type="bibr">5</xref>]. 3D imaging techniques have recently been increasingly utilized in the medical industry, especially in the fields of maxillofacial surgery and orthodontics. Applications for 3D analysis include the morphology of hard and soft tissues, the research of dentoskeletal relationships, and general facial aesthetics [<xref rid="pone.0322358.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0322358.ref007" ref-type="bibr">7</xref>]. First and foremost, the innovative 3D technology can accurately depict the realistic morphology of both the head and face, enabling simulation, planning, documentation, and prediction of outcomes for patients undergoing orthognathic surgery or maxillofacial reconstruction. Numerous previous studies have demonstrated that the integration of 3D facial photographs with Cone Beam Computed Tomography (CBCT) results in improved accuracy in soft tissue prediction compared to conventional 2D facial prediction methods or using only soft-tissue data provided by CBCT simulations [<xref rid="pone.0322358.ref008" ref-type="bibr">8</xref>&#x02013;<xref rid="pone.0322358.ref010" ref-type="bibr">10</xref>]. Additionally, 3D faces scanners have the potential to enhance surgical productivity. By utilizing a non-contact measuring instrument, they can significantly reduce time consumption, minimize patient compliance during acquisition, prevent distortion of soft tissue resulting from pressure-related surface changes, and decrease radiation exposure for the patient [<xref rid="pone.0322358.ref011" ref-type="bibr">11</xref>]. For these reasons, 3D facial scanning can accurately predict post-operative facial soft tissue changes. This capability benefits surgeons by aiding in doctor-patient communication and facilitating the determination of treatment options [<xref rid="pone.0322358.ref012" ref-type="bibr">12</xref>]. According to an increasing amount of the literature reports, 3D facial scanners exhibit a high degree of accuracy and precision, making them applicable in the field of dentistry [<xref rid="pone.0322358.ref013" ref-type="bibr">13</xref>&#x02013;<xref rid="pone.0322358.ref015" ref-type="bibr">15</xref>].</p><p>A variety of facial scanning techniques have been developed in recent years, primarily based on operating principles and 3D sensing techniques. These include 3D laser scanning, stereophotogrammetry and structured light scanning [<xref rid="pone.0322358.ref016" ref-type="bibr">16</xref>]. The 3D laser scanner is utilized to capture facial soft tissue by directing a laser beam vertically along the face and detecting the reflected light with a sensor. The image is then reconstructed into three-dimensional data by converting the reflected light into distance information [<xref rid="pone.0322358.ref017" ref-type="bibr">17</xref>]. In dentistry, stationary devices utilizing stereophotogrammetry represent the most prevalent facial scanning technologies. Their reliably reported geometric precision and trueness contribute to their widespread use and acceptance within the field [<xref rid="pone.0322358.ref018" ref-type="bibr">18</xref>&#x02013;<xref rid="pone.0322358.ref020" ref-type="bibr">20</xref>]. Stereophotogrammetry employs a multi-camera setup to capture two or more images of the same patient simultaneously from different viewpoints. Undoubtedly, this method offers benefits such as minimizing the impact of unintentional head or face movements or expressions on the accuracy of the scan [<xref rid="pone.0322358.ref013" ref-type="bibr">13</xref>]. However, due to limitations and cost considerations, handheld scanning devices employing laser or structured light technologies have emerged as alternatives [<xref rid="pone.0322358.ref021" ref-type="bibr">21</xref>,<xref rid="pone.0322358.ref022" ref-type="bibr">22</xref>]. While numerous professional handheld scanners are regarded as satisfactory in terms of scan image quality, they frequently entail high costs and require substantial training time to become proficient in their complex scanning protocols [<xref rid="pone.0322358.ref003" ref-type="bibr">3</xref>,<xref rid="pone.0322358.ref023" ref-type="bibr">23</xref>,<xref rid="pone.0322358.ref024" ref-type="bibr">24</xref>]. On the other hand, the most recent models of mobile devices, including smartphones and tablets, have cameras built around structured light, a potential 3D surface imaging reconstruction technology [<xref rid="pone.0322358.ref025" ref-type="bibr">25</xref>&#x02013;<xref rid="pone.0322358.ref028" ref-type="bibr">28</xref>]. Using the time-of-flight principle&#x02014;which measures how long it takes light to travel from a sensor array to an object and back again&#x02014;infrared structured light depth-sensing cameras create a three-dimensional image by rearranging the depth map of the item and its surrounding region [<xref rid="pone.0322358.ref029" ref-type="bibr">29</xref>,<xref rid="pone.0322358.ref030" ref-type="bibr">30</xref>]. Additionally, developers have the capability to create and customize 3D scanning programs using open-source scripts and software coding. Tablet and smartphone devices offer a simple and user-friendly interface for such applications [<xref rid="pone.0322358.ref025" ref-type="bibr">25</xref>,<xref rid="pone.0322358.ref031" ref-type="bibr">31</xref>].</p><p>Despite the extensive array of options available on the market and existing literature on the accuracy of specific 3D imaging systems, it remains essential to confirm inter-device accuracy to reliably utilize facial scanning as a clinical tool for diagnostic evaluation. This is achieved by comparing the relative performance of various devices and assessing the scans obtained with them. However, there is still limited research comparing their accuracy in orthodontic patients requiring orthognathic surgery.</p><p>Hence, this study aims to analyze and compare the overall and regional accuracy (trueness and precision) ranges between skin surface images derived from CBCT and 3D facial scans, suitable for face scanning in patients with skeletal deformities. Three different types of facial scanning technologies which are particularly promising viable, cost-effective option for general practitioners (GPs): - the Planmeca Promax 3D Proface (Planmeca USA, Inc.; Roselle IL, USA), EinScan H2 (SHINING 3D Tech Co., Ltd., Hangzhou, China), and the EM3D Scanner application version 1.4.1 (Brawny Lads Software, LLC., USA) are included for evaluation and comparison. There were two null hypotheses developed. The first null hypothesis stated that, when scanning the entire face, there is no statistically significant difference in accuracy between scanners. The second null hypothesis posited that there exists no statistically significant in accuracy between scanners when examining distinct facial regions.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Materials and methods</title><sec id="sec003"><title>Study sample</title><p>This study was approved by The Ethics Committee of Mahidol University (COA.No.MU-DT/PY-IRB 2021/005.2701.) The World Medical Association&#x02019;s Helsinki Declaration and the STROBE guidelines were followed throughout the study. All patients included via consecutive sampling method provided written informed consent for study participation. The individuals in this manuscript provided written informed consent to publish these case details. The study group consisted of 30 patients (18&#x02013;43 years old, mean&#x000b1;SD: 28.03&#x02009;&#x000b1;&#x02009;6.84 years), 18 females and 12 males, with Skeleton deformity and scheduled for orthognathic surgery in the Oral and Maxillofacial surgery clinic of Mahidol University (Bangkok, Thailand). Class III Skeleton deformity patients (n&#x02009;=&#x02009;21), Class II Skeleton deformity patients (n&#x02009;=&#x02009;5), Class I skeleton asymmetry (n&#x02009;=&#x02009;3) and Class I skeleton deformity with bimaxillary protrusion (n&#x02009;=&#x02009;1) are selected for this study from February 2022 to December 2022. The surgery provided for the patient was Bilateral sagittal Split Ramus osteotomy with or without Lefort I for the correction of Skeleton deformity. Patients with a cleft, craniofacial deformity, jaw defect, face muscle spasm symptoms and unstable tooth contacts in intercuspal occlusion (ICP) were excluded.</p></sec><sec id="sec004"><title>Experimental instrument</title><p>A variety of facial scanners are used in scientific and commercial settings. In this study, the facial scanners allocated for assessment included the Planmeca Promax 3D Proface (Planmeca USA, Inc.; Roselle IL, USA), EinScan H2 (SHINING 3D Tech Co., Ltd., Hangzhou, China), and the EM3D Scanner application version 1.4.1 (Brawny Lads Software, LLC., USA)</p><p>The Planmeca ProMax 3D ProFace is a CBCT imaging unit that incorporates an integrated 3D face scan system. This imaging unit, enhanced with ProFace technology, can capture both a 3D photo and a CBCT image in a single rotation. Alternatively, the 3D photo can be obtained independently. This process is entirely radiation-free, as lasers scan the facial geometry, while digital cameras capture the color texture of the face.</p><p>The EinScan H2 is a handheld 3D scanner utilizing a Hybrid LED and Infrared Light Source. This dual-light approach enhances scanning efficiency, with the LED light providing swift 3D scanning and precise, high-quality data. The Infrared VCSEL is well-suited for capturing dark surfaces, human body scanning, and environments with bright lighting. The scan accuracy is within the range of 0.05mm to 0.1mm. Additionally, it can generate 3D face models in OBJ, STL, ASC, PLY, P3, and 3MF formats with authentic color texture.</p><p>The EM3D Scanner application utilizes the TrueDepth camera integrated into Apple devices (Apple Store, Cupertino, CA, USA) running on iOS 13.0 and later, specifically designed for iPad Pro or iPhone models equivalent to or surpassing iPhone X for conducting scans. Using this device is similar to using a handheld 3D scanner, allowing the application to rapidly generate a 3D representation of a subject&#x02019;s face in less than 15 seconds, capturing measurements from diverse angles. Furthermore, it possesses the capacity to generate 3D face models in OBJ, STL, and PLY formats, inclusive of genuine color texture. In our study, we utilized an iPhone 13 (Apple Store, Cupertino, CA, USA) with the EM3D Scanner application version 1.4.1 (Brawny Lads Software, LLC., USA) to collect data for this research.</p></sec><sec id="sec005"><title>Face model acquisition</title><p>Morphologic points necessary for localized surface areas were identified through visual inspection and palpation, followed by marking on the face. All landmarks were marked using marker stickers designed for the 3D scanner. These stickers feature black rings and centers on a white background, facilitating easy identification of the black centers in 3D scanning images. The marking of morphologic points was consistently performed by a qualified examiner with expertise and certification in the field of oral and maxillofacial surgery. A total of nine markers were strategically placed on the patient&#x02019;s face in specified positions: (<xref rid="pone.0322358.t001" ref-type="table">Table 1</xref>)</p><table-wrap position="float" id="pone.0322358.t001"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.t001</object-id><label>Table 1</label><caption><title>Description of 3D soft tissue landmarks in the study.</title></caption><alternatives><graphic xlink:href="pone.0322358.t001" id="pone.0322358.t001g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Landmark</th><th align="left" rowspan="1" colspan="1">Definition</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Pronasale (Pn)</td><td align="left" rowspan="1" colspan="1">The most protruded point of the apex nasi.</td></tr><tr><td align="left" rowspan="1" colspan="1">Orbitale<break/>(Or&#x02019; Rt/ Lt)</td><td align="left" rowspan="1" colspan="1">The lowest point on the inferior margin of the orbit on right side/left side.</td></tr><tr><td align="left" rowspan="1" colspan="1">Pogonion&#x02019; (Pog&#x02019;)</td><td align="left" rowspan="1" colspan="1">The most anterior midpoint of chin</td></tr><tr><td align="left" rowspan="1" colspan="1">Menton&#x02019; (Me&#x02019;)</td><td align="left" rowspan="1" colspan="1">The lowest median landmark on the lower border of the mandible</td></tr><tr><td align="left" rowspan="1" colspan="1">Gonion<break/>(Go&#x02019; Rt/ Lt)</td><td align="left" rowspan="1" colspan="1">The midpoint between the most posterior and inferior points of the mandibular angle on right side/left side.</td></tr><tr><td align="left" rowspan="1" colspan="1">Cheek point<break/>(Ck Rt/Lt)</td><td align="left" rowspan="1" colspan="1">The point where a vertical line from exocanthion and a horizontal line from cheilion meet on right side/left side.</td></tr></tbody></table></alternatives></table-wrap><p>This study was performed with 90 3D photographs and 30 CBCT scans for the same subjects. The Planmeca ProMax&#x000ae; 3D Mid Cone Beam scanner (Planmeca USA, Inc.; Roselle IL, USA) was utilized for the scanning procedure. Subjects&#x02019; heads were positioned in a natural head posture with the face directed forward, and their teeth were in centric occlusion. Temple supports were employed to stabilize the patients&#x02019; heads, and no additional instruments such as chin caps, headbands, or biting rods were used to prevent soft tissue distortion and interference with the occlusal plane. The CBCT data for each individual patient were exported in Digital Imaging and Communications in Medicine (DICOM) format on a CD-ROM.</p><p>Subsequently, three-dimensional virtual models were generated from the CBCT data through segmentation using Simplant imaging-3D (SimPlant Ortho Pro software, version 2.0, Materialise Dental, Leuven, Belgium).</p><p>Each patient underwent three face-scanning operations, with data from three different scanners collected on the same day. All 3D face scanners were used to collect data within the same closed environment, specifically in the imaging room for cone beam computed tomography (CBCT) located in the Department of Radiology, Faculty of Dentistry, Mahidol University. This room was a fully enclosed space with no windows, ensuring that no natural light enters the environment. The room was illuminated solely by LED 22W Daylight bulbs. To ensure that each patient maintained the same expression for the three scanning processes, the following measures were adopted: every patient was strictly supervised by the well-trained examiners throughout the entire scanning process to maintain a sitting position, stable support for head and neck, natural head position (NHP), intercuspal position (ICP, a stable mandibular position) eyes and lips closing naturally and relaxed body. Patients were instructed to remove glasses, earrings, and necklaces for reducing a source of image artifacts. Any shiny surfaces, primarily due to oily skin, or cosmetics were removed and a light dusting of powder was applied around the nose, ear and forehead can reduce shininess.</p><p>The first scan was conducted using the Planmeca ProMax 3D ProFace (Planmeca USA, Inc.; Roselle IL, USA) which has the capability to capture both a 3D photo and a CBCT image simultaneously. Following that, the patient&#x02019;s facial model underwent 3D scanning using two additional scanners in accordance with the manufacturer&#x02019;s recommendations: EinScan H2 (SHINING 3D Tech Co., Ltd., Hangzhou, China), and iPhone 13 (Apple Store, Cupertino, CA, USA) using the EM3D Scanner application version 1.4.1 (Brawny Lads Software, LLC., USA).</p><p>To use the EinScan H2 scanner to scan a subject&#x02019;s face, the method involves connecting the handheld EinScan H2 device to the software, particularly the one provided with the device, through a laptop. It is important to ensure an unobstructed view of the display that shows the area currently being captured by the scanner. This allows for proper monitoring and control of the scanning process. Scanning was conducted as swiftly as possible by our trained operator, ensuring there were no delays in the procedure. The scanning direction started from the right side of the subject&#x02019;s face and rotated clockwise until obtaining the desired images of the subject&#x02019;s face. To use the EM3D Scanner application, the subject holds the iPhone with their right hand, treating it like an arm device, to ensure the distance is as consistent as possible on all sides and to reduce shaking while moving the device. Then, the same operator guides the subject&#x02019;s arm holding the device to determine the scanning direction of the face. The scanning starts from the right side of the face and rotates clockwise until obtaining the desired images of the subject&#x02019;s face on the iPhone screen.</p><p>To prevent results from being distorted by any long-term changes in the patient&#x02019;s face, both types of scans were taken at approximately the same time. All facial scans were conducted by a single operator with experience in handling scanning devices. The scan data files were saved in stereolithography (STL) format for subsequent measurements.</p></sec><sec id="sec006"><title>Modification, trim and division of face models</title><p>Our research&#x02019;s second phase consisted of modifying and setting the file scans in the ideal locations so that they overlapped and could be used to analyze facial points, areas, and characteristics in the future. There were multiple steps in this process shown in <xref rid="pone.0322358.g001" ref-type="fig">Fig 1</xref>.</p><fig position="float" id="pone.0322358.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.g001</object-id><label>Fig 1</label><caption><title>The diagrammatic representation of the proposed method.</title></caption><graphic xlink:href="pone.0322358.g001" position="float"/></fig><p>This study compared 90 facial 3D scans with 30 corresponding CBCT-segmented facial surfaces. The three face models of each patient were trimmed in the same boundary using Meshmixer software (MeshmixerTM Autodesk&#x000ae;, Inc., San Rafael, CA, USA) to further reduce the influence on 3D accuracy analysis of the noise data on face models (such as hair and ear data). The appearance of hair is typically unstable, and the area around the ears is particularly susceptible to the influence of hair. Large scanning errors consistently occur in these areas, which cannot be attributed to the scanner&#x02019;s capabilities. Furthermore, we eliminated these locations from our research to cleanse the data and saved overlapping parts in each group for accuracy analysis, considering the minimal attention that has been given to these areas.</p><p>We imported the facial 3D scans of the patients and the above-modified final CBCT scans in the Geomagic X Control software (3D Systems Inc, Rock Hill, SC, USA). For the purpose of evaluating the specimens&#x02019; accuracy based on the total or localized surface areas of the CBCT segmentation. Using this specific program, the control mesh was marked with different the facial aesthetic units which were based on Gonzales-Ulloa&#x02019;s original work that separated the CBCT segmentation into 5 different areas (from Area-1 to Area-5) as shown in <xref rid="pone.0322358.g002" ref-type="fig">Fig 2</xref> and <xref rid="pone.0322358.t002" ref-type="table">Table 2</xref>.</p><table-wrap position="float" id="pone.0322358.t002"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.t002</object-id><label>Table 2</label><caption><title>Description of surface deviations areas for aesthetic units.</title></caption><alternatives><graphic xlink:href="pone.0322358.t002" id="pone.0322358.t002g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Surface deviations area</th><th align="left" rowspan="1" colspan="1">Soft tissue landmark and boundaries</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Area-1 (Right Cheek unit)</td><td align="left" rowspan="1" colspan="1">Surface located between the superiorly by the infraorbital rims (Or&#x02019; Rt) and the superior aspects of the zygomatic arches, laterally by the preauricular creases, inferiorly by the jaw line, and medially by the nasolabial and melolabial (labiomandibular) grooves and the lateral aspects of nasal dorsal side walls.</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-2 (Left Cheek unit)</td><td align="left" rowspan="1" colspan="1">Surface located between the superiorly by the infraorbital rims (Or&#x02019; Lt) and the superior aspects of the zygomatic arches, laterally by the preauricular creases, inferiorly by the jaw line, and medially by the nasolabial and melolabial (labiomandibular) grooves and the lateral aspects of nasal dorsal side walls.</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-3 (Nasal unit)</td><td align="left" rowspan="1" colspan="1">Surface located between the nasion superiorly, junction of the cheeks and nasal dorsal side walls laterally, and the alar groove and columella inferiorly.</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-4 (Perioral unit)</td><td align="left" rowspan="1" colspan="1">Surface located between the alar grooves and columella superiorly, the nasolabial grooves laterally, the melolabial grooves laterally, and the mentolabial groove inferiorly.</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-5 (Mental unit)</td><td align="left" rowspan="1" colspan="1">Surface located between the mentolabial groove superiorly, forming a curvilinear border laterally, and ending at the submental crease, just inferoposterior to the jaw line.</td></tr></tbody></table></alternatives></table-wrap><fig position="float" id="pone.0322358.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.g002</object-id><label>Fig 2</label><caption><title>Soft tissue boundaries were outlined on the reference mesh to assist in posterior measurements.</title><p>A, Total face surface. B, Frontal view of the areas from 1 to 5. C, Lateral view of the areas from 1 to 5.</p></caption><graphic xlink:href="pone.0322358.g002" position="float"/></fig><p>We decided to limit the usage of the facial aesthetic unit only in the midface and lower face areas, as these are parts of the face that undergo changes after orthognathic surgery.</p></sec><sec id="sec007"><title>Data analysis and comparison</title><p>The test models from 3D face scan (Planmeca ProFace, EinScan H2, and EM3D Scanner application) and the reference (CBCT segmentation) were compared in three dimensions using the &#x0201c;3D compare&#x0201d; feature in the Geomagic X Control software. This software facilitated the superimposition of the reference and each test model through alignment processes. Specifically, the alignment was achieved using the best-fit algorithm, which automatically determined the optimal alignment by utilizing pre-established reference points. To investigate the qualitative congruency of the reference and test models, color difference images were produced. The root mean square (RMS) of all distances between the closest point pairs on the reference and test models was computed to determine the &#x0201c;3D deviation&#x0201d; between each pair for the total surface facial scan area and for each specific area (from Area-1 to Area-5), as shown in <xref rid="pone.0322358.g003" ref-type="fig">Fig 3</xref>.</p><fig position="float" id="pone.0322358.g003"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.g003</object-id><label>Fig 3</label><caption><title>Representative color-coded deviation map showing the discrepancy between the reference mesh and a facial scan using the best-fit algorithm.</title><p>A, Overall surface area. B, From area -1. C, From area -2. D, From area -3. E, From area -4. F, From area -5.</p></caption><graphic xlink:href="pone.0322358.g003" position="float"/></fig><p>The software&#x02019;s algorithm automatically found and matched the nearest point pairs. In this investigation, good test model 3D accuracy was indicated by low RMS scores, which show a strong 3D congruency of the superimposed models.</p><p>Intersystem evaluation: Trueness was defined as the mean of the average absolute dimensional discrepancy between the reference mesh and the facial scans (RMS). In other words, trueness evaluates how closely the digitized object aligns with its true dimensions.</p><p>Intrasystem evaluation: Precision was described as the standard deviation (SD) of the dimensional discrepancies between the reference mesh and the facial scans. Therefore, precision analyzes the reproducibility of the facial scanner [<xref rid="pone.0322358.ref032" ref-type="bibr">32</xref>].</p><p>The reliability of a digital face scanner can be classified into 4 categories [<xref rid="pone.0322358.ref033" ref-type="bibr">33</xref>]:</p><list list-type="bullet"><list-item><p>Highly reliable (deviation &#x0003c;1.0&#x02009;mm)</p></list-item><list-item><p>Reliable (deviation 1.0 mm-1.5&#x02009;mm)</p></list-item><list-item><p>Moderately reliable (deviation 1.5 mm-2.0&#x02009;mm)</p></list-item><list-item><p>Unreliable (deviation &#x0003e;2.0&#x02009;mm)</p></list-item></list><p>Furthermore, the data are presented as the average percentage of overlapping surfaces between each 3D facial scanner and the reference model, analyzed across five distinct areas as defined by the software. The tolerance ranges, which represent the deviations between the test models and the reference model, are divided into five predefined intervals. These intervals indicate the areas where each 3D facial scanner achieves high reproducibility and alignment accuracy. The details are outlined as follows:</p><list list-type="bullet"><list-item><p>-0.5mm to 0mm and 0mm to 0.5mm (highly reproducible)</p></list-item><list-item><p>-1&#x02009;mm to -0.5&#x02009;mm and 0.5&#x02009;mm to 1&#x02009;mm (moderately reproducible)</p></list-item><list-item><p>-1.5&#x02009;mm to 1- mm and1&#x02009;mm to1.5&#x02009;mm (poorly reproducible)</p></list-item><list-item><p>&#x0003e;1.5&#x02009;mm (not reproducible)</p></list-item><list-item><p>&#x0003c;&#x02009;-1.5&#x02009;mm (not reproducible)</p></list-item></list><p>For intraexaminer reliability assessment, ten CBCT soft tissue segmentations were randomly selected. Each segmentation was manually marked for five localized surface areas twice by the same examiner, with a minimum interval of seven days between each marking process. Additionally, the comparison reports were analyzed twice, also with an interval of seven days. The values were then analyzed using the Intraclass Correlation Coefficient (ICC).</p><p>&#x0201c;The individual pictured in <xref rid="pone.0322358.g001" ref-type="fig">Figs 1</xref>&#x02013;<xref rid="pone.0322358.g003" ref-type="fig">3</xref> has provided written informed consent (as outlined in PLOS consent form) to publish their image alongside the manuscript&#x0201d;.</p></sec><sec id="sec008"><title>Statistical analysis</title><p>Data were analyzed using IBM SPSS Statistics, Version 29.0 (Armonk, NY: IBM Corp). The intraclass correlation coefficient (ICC) was employed to assess the consistency and repeatability of the localized surface area of the reference mesh method. An ICC value greater than 0.9 was considered indicative of excellent reliability.</p><p>To examine the data distribution for trueness and precision, the Kolmogorov-Smirnov and Shapiro-Wilk normality tests were applied to all datasets, which included three groups, each consisting of ten computed values. When necessary, the data for trueness and precision were transformed to achieve normal distribution.</p><p>To evaluate the accuracy of each scanner across the entire face and five specific areas, the means and standard deviations (SD) for trueness (RMS) and precision (SD) were calculated. Differences in trueness and precision across the three groups were analyzed using one-way repeated measures ANOVA. Post-hoc comparisons were performed using the Bonferroni test, a statistical procedure for comparing multiple pairs of means within the data. A p-value of&#x02009;&#x0003c;&#x02009;0.05 was considered statistically significant.</p><p>Finally, tolerance values were analyzed as a function of the five ranges and the face side using descriptive analysis. The resulting model provided average percentages and estimated confidence intervals (lower and upper confidence limits, CL) for the tolerance measures of overlapping surfaces. These were calculated for comparisons between each 3D facial scanner and CBCT soft tissue segmentation. For all evaluations, a p-value of&#x02009;&#x0003c;&#x02009;0.05 was considered statistically significant.</p></sec></sec><sec sec-type="results" id="sec009"><title>Results</title><p>The intraexaminer reliability for the five localized surface areas (as shown in <xref rid="pone.0322358.t003" ref-type="table">Table 3</xref>.) was high, with all yielding an ICC index greater than 0.9. This suggests substantial consistency in the markings made by the examiner.</p><table-wrap position="float" id="pone.0322358.t003"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.t003</object-id><label>Table 3</label><caption><title>The Intraclass Correlation Coefficient (ICC) index and F-test of averages were calculated for the five localized surface areas as marked.</title></caption><alternatives><graphic xlink:href="pone.0322358.t003" id="pone.0322358.t003g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Surface area</th><th align="left" rowspan="2" colspan="1">ICC<sup>a</sup> (95% Cl<sup>b)</sup></th><th align="left" colspan="2" rowspan="1">F test with true value</th></tr><tr><th align="left" rowspan="1" colspan="1">Value</th><th align="left" rowspan="1" colspan="1">p-Value</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Area-1<break/>(Right Cheek unit)</td><td align="left" rowspan="1" colspan="1">0.99 (0.97&#x02013;1)</td><td align="left" rowspan="1" colspan="1">130.38</td><td align="left" rowspan="1" colspan="1">&#x0003c;.001<xref rid="t003fn001" ref-type="table-fn"><sup>*</sup></xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Area-2<break/>(Left Cheek unit)</td><td align="left" rowspan="1" colspan="1">1 (0.99&#x02013;1)</td><td align="left" rowspan="1" colspan="1">293.87</td><td align="left" rowspan="1" colspan="1">&#x0003c;.001<xref rid="t003fn001" ref-type="table-fn"><sup>*</sup></xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Area-3<break/>(Nasal unit)</td><td align="left" rowspan="1" colspan="1">0.98 (0.91&#x02013;0.99)</td><td align="left" rowspan="1" colspan="1">45.28</td><td align="left" rowspan="1" colspan="1">&#x0003c;.001<xref rid="t003fn001" ref-type="table-fn"><sup>*</sup></xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Area-4<break/>(Perioral unit)</td><td align="left" rowspan="1" colspan="1">0.99 (0.96&#x02013;1)</td><td align="left" rowspan="1" colspan="1">103.59</td><td align="left" rowspan="1" colspan="1">&#x0003c;.001<xref rid="t003fn001" ref-type="table-fn"><sup>*</sup></xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Area-5<break/>(Mental unit)</td><td align="left" rowspan="1" colspan="1">0.94 (0.77&#x02013;0.99)</td><td align="left" rowspan="1" colspan="1">17.82</td><td align="left" rowspan="1" colspan="1">&#x0003c;.001<xref rid="t003fn001" ref-type="table-fn"><sup>*</sup></xref></td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t003fn001"><label>*</label><p>p&#x02009;&#x0003c;&#x02009;0.05</p></fn><fn id="t003fn002"><p>a Intraclass correlation coefficient.</p></fn><fn id="t003fn003"><p>b 95% confidence interval</p></fn></table-wrap-foot></table-wrap><p>The overall mean values for trueness and precision associated with each 3D facial scanner are presented in <xref rid="pone.0322358.t004" ref-type="table">Table 4</xref>. Additionally, <xref rid="pone.0322358.t005" ref-type="table">Tables 5</xref> and <xref rid="pone.0322358.t006" ref-type="table">6</xref> provide the mean values for trueness and precision for each facial scanner divided by region.</p><table-wrap position="float" id="pone.0322358.t004"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.t004</object-id><label>Table 4</label><caption><title>Descriptive statistics of the overall scanning accuracy (trueness and precision) obtained using three different 3D scanners (Planmeca ProFace, EinScan H2, and EM3D Scanner application). Data provided in millimetres (mm).</title></caption><alternatives><graphic xlink:href="pone.0322358.t004" id="pone.0322358.t004g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Experimental instrument</th><th align="left" colspan="2" rowspan="1">Trueness</th><th align="left" rowspan="1" colspan="1">F-test</th><th align="left" rowspan="2" colspan="1">P-value</th><th align="left" rowspan="1" colspan="1">Partial Eta Squared</th><th align="left" colspan="2" rowspan="1">Precision</th><th align="left" rowspan="1" colspan="1">F-test</th><th align="left" rowspan="1" colspan="1">P-value</th><th align="left" rowspan="1" colspan="1">Partial Eta Squared</th></tr><tr><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Planmeca ProFace</td><td align="left" rowspan="1" colspan="1">0.75<sup>ab</sup></td><td align="left" rowspan="1" colspan="1">0.18</td><td align="left" rowspan="1" colspan="1">5.051</td><td align="left" rowspan="1" colspan="1">0.015<xref rid="t004fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.305</td><td align="left" rowspan="1" colspan="1">0.72<sup>ab</sup></td><td align="left" rowspan="1" colspan="1">0.17</td><td align="left" rowspan="1" colspan="1">4.622</td><td align="left" rowspan="1" colspan="1">0.021<xref rid="t004fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.287</td></tr><tr><td align="left" rowspan="1" colspan="1">EinScan H2</td><td align="left" rowspan="1" colspan="1">0.85<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.28</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">0.81<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.26</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">EM3D Scanner application</td><td align="left" rowspan="1" colspan="1">0.70<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.16</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">0.68<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.16</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/></tr></tbody></table></alternatives><table-wrap-foot><fn id="t004fn001"><label>*</label><p>p&#x02009;&#x0003c;&#x02009;0.05</p></fn><fn id="t004fn002"><p>SD, Standard deviation.</p></fn><fn id="t004fn003"><p>a, b post-hoc comparisons were performed using the Bonferroni test. when the superscripts (a,b) are the same, it indicates no statistically significant difference between the compared pairs of data.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="pone.0322358.t005"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.t005</object-id><label>Table 5</label><caption><title>Descriptive statistics of the scanning accuracy (trueness) values (RMS) obtained among the different areas. Data provided in millimeters (mm).</title></caption><alternatives><graphic xlink:href="pone.0322358.t005" id="pone.0322358.t005g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Surface area</th><th align="left" colspan="2" rowspan="1">Planmeca ProFace</th><th align="left" colspan="2" rowspan="1">EinScan H2</th><th align="left" colspan="2" rowspan="1">EM3D Scanner application</th><th align="left" rowspan="1" colspan="1">F-test</th><th align="left" rowspan="1" colspan="1">P-value</th><th align="left" rowspan="1" colspan="1">Partial Eta Squared</th></tr><tr><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Area-1<break/>(Right Cheek unit)</td><td align="left" rowspan="1" colspan="1">0.77</td><td align="left" rowspan="1" colspan="1">0.24</td><td align="left" rowspan="1" colspan="1">0.85</td><td align="left" rowspan="1" colspan="1">0.30</td><td align="left" rowspan="1" colspan="1">0.68</td><td align="left" rowspan="1" colspan="1">0.21</td><td align="left" rowspan="1" colspan="1">2.433</td><td align="left" rowspan="1" colspan="1">0.112</td><td align="left" rowspan="1" colspan="1">0.188</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-2<break/>(Left Cheek unit)</td><td align="left" rowspan="1" colspan="1">0.92<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.33</td><td align="left" rowspan="1" colspan="1">0.87<sup>ab</sup></td><td align="left" rowspan="1" colspan="1">0.34</td><td align="left" rowspan="1" colspan="1">0.73<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.22</td><td align="left" rowspan="1" colspan="1">3.603</td><td align="left" rowspan="1" colspan="1">0.042<xref rid="t005fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.217</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-3<break/>(Nasal unit)</td><td align="left" rowspan="1" colspan="1">0.36<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.08</td><td align="left" rowspan="1" colspan="1">0.52<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.19</td><td align="left" rowspan="1" colspan="1">0.57<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.18</td><td align="left" rowspan="1" colspan="1">9.939</td><td align="left" rowspan="1" colspan="1">0.002<xref rid="t005fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.554</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-4<break/>(Perioral unit)</td><td align="left" rowspan="1" colspan="1">0.50<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.17</td><td align="left" rowspan="1" colspan="1">0.69<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.25</td><td align="left" rowspan="1" colspan="1">0.69<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.20</td><td align="left" rowspan="1" colspan="1">6.988</td><td align="left" rowspan="1" colspan="1">0.004<xref rid="t005fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.359</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-5<break/>(Mental unit)</td><td align="left" rowspan="1" colspan="1">0.54</td><td align="left" rowspan="1" colspan="1">0.17</td><td align="left" rowspan="1" colspan="1">0.60</td><td align="left" rowspan="1" colspan="1">0.22</td><td align="left" rowspan="1" colspan="1">0.66</td><td align="left" rowspan="1" colspan="1">0.19</td><td align="left" rowspan="1" colspan="1">2.276</td><td align="left" rowspan="1" colspan="1">0.130</td><td align="left" rowspan="1" colspan="1">0.193</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t005fn001"><label>*</label><p>p&#x02009;&#x0003c;&#x02009;0.05</p></fn><fn id="t005fn002"><p>SD, Standard deviation.</p></fn><fn id="t005fn003"><p>a, b post-hoc comparisons were performed using the Bonferroni test. when the superscripts (a,b) are the same, it indicates no statistically significant difference between the compared pairs of data.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="pone.0322358.t006"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.t006</object-id><label>Table 6</label><caption><title>Descriptive statistics of the scanning accuracy (precision) values (RMS) obtained among the different areas. Data provided in millimeters (mm).</title></caption><alternatives><graphic xlink:href="pone.0322358.t006" id="pone.0322358.t006g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Surface area</th><th align="left" colspan="2" rowspan="1">Planmeca ProFace</th><th align="left" colspan="2" rowspan="1">EinScan H2</th><th align="left" colspan="2" rowspan="1">EM3D Scanner application</th><th align="left" rowspan="1" colspan="1">F-test</th><th align="left" rowspan="1" colspan="1">P-value</th><th align="left" rowspan="1" colspan="1">Partial Eta Squared</th></tr><tr><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1">Mean</th><th align="left" rowspan="1" colspan="1">SD</th><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"/></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Area-1<break/>(Right Cheek unit)</td><td align="left" rowspan="1" colspan="1">0.70</td><td align="left" rowspan="1" colspan="1">0.22</td><td align="left" rowspan="1" colspan="1">0.68</td><td align="left" rowspan="1" colspan="1">0.22</td><td align="left" rowspan="1" colspan="1">0.62</td><td align="left" rowspan="1" colspan="1">0.18</td><td align="left" rowspan="1" colspan="1">1.034</td><td align="left" rowspan="1" colspan="1">0.373</td><td align="left" rowspan="1" colspan="1">0.090</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-2<break/>(Left Cheek unit)</td><td align="left" rowspan="1" colspan="1">0.84<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.30</td><td align="left" rowspan="1" colspan="1">0.68<sup>ab</sup></td><td align="left" rowspan="1" colspan="1">0.25</td><td align="left" rowspan="1" colspan="1">0.66<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.19</td><td align="left" rowspan="1" colspan="1">3.557</td><td align="left" rowspan="1" colspan="1">0.043<xref rid="t006fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.215</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-3<break/>(Nasal unit)</td><td align="left" rowspan="1" colspan="1">0.30<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.05</td><td align="left" rowspan="1" colspan="1">0.50<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.19</td><td align="left" rowspan="1" colspan="1">0.52<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.18</td><td align="left" rowspan="1" colspan="1">14.958</td><td align="left" rowspan="1" colspan="1">&#x0003c;0.001<xref rid="t006fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.652</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-4<break/>(Perioral unit)</td><td align="left" rowspan="1" colspan="1">0.44<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.15</td><td align="left" rowspan="1" colspan="1">0.61<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.20</td><td align="left" rowspan="1" colspan="1">0.65<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.18</td><td align="left" rowspan="1" colspan="1">9.484</td><td align="left" rowspan="1" colspan="1">0.001<xref rid="t006fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.431</td></tr><tr><td align="left" rowspan="1" colspan="1">Area-5<break/>(Mental unit)</td><td align="left" rowspan="1" colspan="1">0.46<sup>b</sup></td><td align="left" rowspan="1" colspan="1">0.14</td><td align="left" rowspan="1" colspan="1">0.50<sup>ab</sup></td><td align="left" rowspan="1" colspan="1">0.20</td><td align="left" rowspan="1" colspan="1">0.59<sup>a</sup></td><td align="left" rowspan="1" colspan="1">0.18</td><td align="left" rowspan="1" colspan="1">4.202</td><td align="left" rowspan="1" colspan="1">0.031<xref rid="t006fn001" ref-type="table-fn"><sup>*</sup></xref></td><td align="left" rowspan="1" colspan="1">0.307</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t006fn001"><label>*</label><p>p&#x02009;&#x0003c;&#x02009;0.05</p></fn><fn id="t006fn002"><p>SD, Standard deviation.</p></fn><fn id="t006fn003"><p>a, b post-hoc comparisons were performed using the Bonferroni test. when the superscripts (a,b) are the same, it indicates no statistically significant difference between the compared pairs of data.</p></fn></table-wrap-foot></table-wrap><sec id="sec010"><title>Overall accuracy (trueness and precision)</title><p>For trueness, the Planmeca ProFace group obtained an overall mean&#x02009;&#x000b1;&#x02009;SD RMS value of 0.75&#x02009;&#x000b1;&#x02009;0.18&#x02009;mm. In comparison, the Einscan H2 obtained an overall trueness value of 0.85&#x02009;&#x000b1;&#x02009;0.28&#x02009;mm, and the EM3D Scanner application recorded an overall trueness value of 0.70&#x02009;&#x000b1;&#x02009;0.16&#x02009;mm.</p><p>The mean trueness values of the Planmeca ProFace, EinScan H2, and EM3D Scanner applications revealed significant differences, as indicated by the One-way repeated measures ANOVA analysis and Bonferroni&#x02019;s pairwise comparison. Pairwise comparisons indicated that the EM3D Scanner application exhibited significantly smaller errors compared to the EinScan H2 scanners (p&#x02009;&#x0003c;&#x02009;0.01). Following this, the Planmeca ProFace showed no significant difference in error compared to the other scanners. Finally, the EinScan H2 demonstrated statistically significantly lower trueness (p&#x02009;&#x0003c;&#x02009;0.01) compared to the EM3D Scanner application concerning the overall face (<xref rid="pone.0322358.t004" ref-type="table">Table 4</xref>, <xref rid="pone.0322358.g004" ref-type="fig">Fig 4</xref>).</p><fig position="float" id="pone.0322358.g004"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.g004</object-id><label>Fig 4</label><caption><title>Boxplot of the overall scanning accuracy (trueness) obtained using three different 3D scanners.</title></caption><graphic xlink:href="pone.0322358.g004" position="float"/></fig><p>In terms of precision, the Planmeca ProFace group obtained a mean&#x02009;&#x000b1;&#x02009;SD RMS value of 0.72&#x02009;&#x000b1;&#x02009;0.17&#x02009;mm overall. By contrast, the EM3D Scanner application recorded an overall precision value of 0.68&#x02009;&#x000b1;&#x02009;0.16&#x02009;mm, while the Einscan H2 obtained an overall precision value of 0.81&#x02009;&#x000b1;&#x02009;0.26&#x02009;mm. The One-way repeated measures ANOVA analysis and Bonferroni&#x02019;s pairwise comparison showed significant difference between mean Precision values from the Planmeca ProFace, EinScan H2, and EM3D Scanner application. Pairwise comparisons unveiled that the EM3D Scanner application displayed a statistically significantly higher precision compared to the EinScan H2 devices (p&#x02009;&#x0003c;&#x02009;0.01). Furthermore, the EinScan H2 exhibited less precision than the other tested devices, although there was no statistically significant difference with the Planmeca ProFace. (<xref rid="pone.0322358.t004" ref-type="table">Table 4</xref>, <xref rid="pone.0322358.g005" ref-type="fig">Fig 5</xref>).</p><fig position="float" id="pone.0322358.g005"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.g005</object-id><label>Fig 5</label><caption><title>Boxplot of the overall scanning accuracy (precision) obtained using three different 3D scanners.</title></caption><graphic xlink:href="pone.0322358.g005" position="float"/></fig></sec><sec id="sec011"><title>The accuracy (trueness and precision) varied among the different areas</title><p>All the localized surface areas examined in this study exhibited a significant difference in the trueness values across surface areas. When comparing the regions, the Planmeca ProFace exhibited the highest mean trueness value, which was 0.92&#x02009;mm in the Left Cheek unit (Area-2). The nasal unit (Area-3) exhibited the lowest mean trueness (mean&#x02009;=&#x02009;0.36&#x02009;mm) calculated by the Planmeca ProFace, suggesting that the localized surface of the nasal unit achieved the highest trueness score. Additionally, statistically significant differences were found between the various measurements of all three facial scanners, except for the right cheek unit (Area-1) and mental unit (Area-5), according to One-way repeated measures ANOVA and Bonferroni&#x02019;s pairwise tests (<xref rid="pone.0322358.t005" ref-type="table">Table 5</xref>, <xref rid="pone.0322358.g006" ref-type="fig">Fig 6</xref>).</p><fig position="float" id="pone.0322358.g006"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.g006</object-id><label>Fig 6</label><caption><title>Mean of the scanning accuracy (trueness) values (RMS) obtained among the different areas.</title></caption><graphic xlink:href="pone.0322358.g006" position="float"/></fig><p>Additionally, when comparing the different localized surface areas captured by the three face scanners, it was observed that the precision (SD) remained under 1.00&#x02009;mm. Notably, in the Left cheek unit (Area-2), the Planmeca ProFace exhibited the highest precision value (mean&#x02009;=&#x02009;0.84&#x02009;mm). Conversely, for the nasal unit (Area-3), the Planmeca ProFace produced the lowest precision values (mean&#x02009;=&#x02009;0.30&#x02009;mm), indicating that the localized surface of the nasal unit area achieved a higher precision score. Furthermore, One-way repeated measures ANOVA and Bonferroni&#x02019;s pairwise testing revealed statistically significant differences between the various measurements of all three facial scanners, except for the right cheek unit (Area-1) (<xref rid="pone.0322358.t006" ref-type="table">Table 6</xref>, <xref rid="pone.0322358.g007" ref-type="fig">Fig 7</xref>).</p><fig position="float" id="pone.0322358.g007"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.g007</object-id><label>Fig 7</label><caption><title>Mean of the scanning accuracy (precision) values (RMS) obtained among the different areas.</title></caption><graphic xlink:href="pone.0322358.g007" position="float"/></fig><p>The average percentage overlap of the 3D-scanned surfaces across the five bands of tolerance for the five distinct areas, along with the corresponding confidence intervals (lower CL and upper CL) between each 3D facial scanner and CBCT soft tissue segmentation, were presented in <xref rid="pone.0322358.t007" ref-type="table">Table 7</xref>.</p><table-wrap position="float" id="pone.0322358.t007"><object-id pub-id-type="doi">10.1371/journal.pone.0322358.t007</object-id><label>Table 7</label><caption><title>The average percentages and estimated confidence intervals of the tolerance measures for overlapping surfaces in five different areas across five tolerance bands, which were compared between each 3D facial scanner and CBCT soft tissue segmentation.</title></caption><alternatives><graphic xlink:href="pone.0322358.t007" id="pone.0322358.t007g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Tolerance ranges</th><th align="left" rowspan="2" colspan="1">Surface area</th><th align="left" colspan="3" rowspan="1">Mean %<sup>a</sup> (95% Cl<sup>b)</sup></th></tr><tr><th align="left" rowspan="1" colspan="1">Planmeca ProFace</th><th align="left" rowspan="1" colspan="1">EinScan H2</th><th align="left" rowspan="1" colspan="1">EM3D Scanner application</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">TOL: 0.5 to 0; 0 to -0.5 (mm)</td><td align="left" rowspan="1" colspan="1">Right cheek unit</td><td align="left" rowspan="1" colspan="1">62.16 (57.51-66.82)</td><td align="left" rowspan="1" colspan="1">47.55 (39.76-55.36)</td><td align="left" rowspan="1" colspan="1">52.94 (46.76-59.12)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1 to 0.5; -0.5 to -1 (mm)</td><td align="left" rowspan="1" colspan="1">Right cheek unit</td><td align="left" rowspan="1" colspan="1">22.22 (19.10-25.35)</td><td align="left" rowspan="1" colspan="1">27.70 (23.66-31.74)</td><td align="left" rowspan="1" colspan="1">28.35 (24.23-32.48)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1.5 to 1; -1 to -1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Right cheek unit</td><td align="left" rowspan="1" colspan="1">7.20 (5.44-8.96)</td><td align="left" rowspan="1" colspan="1">14.68 (11.28-18.08)</td><td align="left" rowspan="1" colspan="1">10.89 (8.14-13.66)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003e;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Right cheek unit</td><td align="left" rowspan="1" colspan="1">7.75 (5.39-10.19)</td><td align="left" rowspan="1" colspan="1">9.55 (6.34-12.76)</td><td align="left" rowspan="1" colspan="1">2.53 (0.88-4.20)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003c;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Right cheek unit</td><td align="left" rowspan="1" colspan="1">0.67 (0.24-1.10)</td><td align="left" rowspan="1" colspan="1">0.52 (0.01-1.04)</td><td align="left" rowspan="1" colspan="1">5.27 (1.30-9.23)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 0.5 to 0; 0 to -0.5 (mm)</td><td align="left" rowspan="1" colspan="1">Left cheek unit</td><td align="left" rowspan="1" colspan="1">60.61 (55.65-60.84)</td><td align="left" rowspan="1" colspan="1">46.55 (38.49-54.61)</td><td align="left" rowspan="1" colspan="1">54.96 (49.27-60.66)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1 to 0.5; -0.5 to -1 (mm)</td><td align="left" rowspan="1" colspan="1">Left cheek unit</td><td align="left" rowspan="1" colspan="1">21.17 (18.07-24.26)</td><td align="left" rowspan="1" colspan="1">26.95 (22.56-31.35)</td><td align="left" rowspan="1" colspan="1">26.39 (23.32-29.48)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1.5 to 1; -1 to -1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Left cheek unit</td><td align="left" rowspan="1" colspan="1">7.52 (5.95-9.08)</td><td align="left" rowspan="1" colspan="1">15.56 (11.40-19.71)</td><td align="left" rowspan="1" colspan="1">10.61 (7.99-13.24)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003e;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Left cheek unit</td><td align="left" rowspan="1" colspan="1">9.79 (6.65-12.93)</td><td align="left" rowspan="1" colspan="1">10.26 (6.29-14.24)</td><td align="left" rowspan="1" colspan="1">3.95 (1.67-6.23)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003c;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Left cheek unit</td><td align="left" rowspan="1" colspan="1">0.91 (0.40-1.43)</td><td align="left" rowspan="1" colspan="1">0.67 (0.23-1.33)</td><td align="left" rowspan="1" colspan="1">4.07 (1.42-6.73)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 0.5 to 0; 0 to -0.5 (mm)</td><td align="left" rowspan="1" colspan="1">Nasal unit</td><td align="left" rowspan="1" colspan="1">79.12 (73.29-84.95)</td><td align="left" rowspan="1" colspan="1">61.97 (53.86-70.08)</td><td align="left" rowspan="1" colspan="1">57.83 (50.85-64.80)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1 to 0.5; -0.5 to -1 (mm)</td><td align="left" rowspan="1" colspan="1">Nasal unit</td><td align="left" rowspan="1" colspan="1">18.34 (13.56-23.13)</td><td align="left" rowspan="1" colspan="1">24.96 (21.00-28.93)</td><td align="left" rowspan="1" colspan="1">24.46 (21.14-27.78)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1.5 to 1; -1 to -1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Nasal unit</td><td align="left" rowspan="1" colspan="1">2.18 (1.12-3.23)</td><td align="left" rowspan="1" colspan="1">8.62 (5.39-11.85)</td><td align="left" rowspan="1" colspan="1">10.23 (7.52-12.93)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003e;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Nasal unit</td><td align="left" rowspan="1" colspan="1">0.33 (0.30-0.63)</td><td align="left" rowspan="1" colspan="1">3.25 (0.93-5.57)</td><td align="left" rowspan="1" colspan="1">3.42 (1.21-5.65)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003c;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Nasal unit</td><td align="left" rowspan="1" colspan="1">0.039 (-0.01-0.07)</td><td align="left" rowspan="1" colspan="1">1.19 (0.39-1.99)</td><td align="left" rowspan="1" colspan="1">4.06 (1.46-6.66)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 0.5 to 0; 0 to -0.5 (mm)</td><td align="left" rowspan="1" colspan="1">Perioral unit</td><td align="left" rowspan="1" colspan="1">67.82 (61.97-73.65)</td><td align="left" rowspan="1" colspan="1">52.93 (46.22-59.63)</td><td align="left" rowspan="1" colspan="1">52.17 (45.74-58.60)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1 to 0.5; -0.5 to -1 (mm)</td><td align="left" rowspan="1" colspan="1">Perioral unit</td><td align="left" rowspan="1" colspan="1">21.99 (18.48-25.50)</td><td align="left" rowspan="1" colspan="1">27.88 (24.91-30.85)</td><td align="left" rowspan="1" colspan="1">28.13 (25.28-30.98)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1.5 to 1; -1 to -1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Perioral unit</td><td align="left" rowspan="1" colspan="1">5.57 (3.64-7.51)</td><td align="left" rowspan="1" colspan="1">12.36 (9.26-15.46)</td><td align="left" rowspan="1" colspan="1">11.96 (9.67-14.25)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003e;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Perioral unit</td><td align="left" rowspan="1" colspan="1">3.43 (0.87-5.99)</td><td align="left" rowspan="1" colspan="1">3.34 (1.36-5.32)</td><td align="left" rowspan="1" colspan="1">4.44 (1.47-7.40)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003c;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Perioral unit</td><td align="left" rowspan="1" colspan="1">1.19 (0.65-2.31)</td><td align="left" rowspan="1" colspan="1">3.49 (1.23-5.76)</td><td align="left" rowspan="1" colspan="1">3.30 (1.66-4.94)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 0.5 to 0; 0 to -0.5 (mm)</td><td align="left" rowspan="1" colspan="1">Mental unit</td><td align="left" rowspan="1" colspan="1">68.41 (60.75-76.06)</td><td align="left" rowspan="1" colspan="1">55.32 (47.29-63.35)</td><td align="left" rowspan="1" colspan="1">52.66 (45.11-60.21)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1 to 0.5; -0.5 to -1 (mm)</td><td align="left" rowspan="1" colspan="1">Mental unit</td><td align="left" rowspan="1" colspan="1">22.50 (17.01-27.99)</td><td align="left" rowspan="1" colspan="1">28.92 (24.81-33.03)</td><td align="left" rowspan="1" colspan="1">25.74 (23.02-28.46)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL: 1.5 to 1; -1 to -1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Mental unit</td><td align="left" rowspan="1" colspan="1">5.91 (3.26-8.56)</td><td align="left" rowspan="1" colspan="1">10.69 (7.27-14.11)</td><td align="left" rowspan="1" colspan="1">12.77 (9.53-16.01)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003e;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Mental unit</td><td align="left" rowspan="1" colspan="1">1.97(-0.13-4.07)</td><td align="left" rowspan="1" colspan="1">2.01 (0.14-3.88)</td><td align="left" rowspan="1" colspan="1">5.74 (2.67-8.80)</td></tr><tr><td align="left" rowspan="1" colspan="1">TOL:&#x02009;&#x0003c;&#x02009;1.5 (mm)</td><td align="left" rowspan="1" colspan="1">Mental unit</td><td align="left" rowspan="1" colspan="1">1.22 (0.52-1.91)</td><td align="left" rowspan="1" colspan="1">3.05 (0.21-5.90)</td><td align="left" rowspan="1" colspan="1">3.09 (1.13-5.06)</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t007fn001"><p>a Obtained from the marginal means of the descriptive analysis.</p></fn><fn id="t007fn002"><p>b 95% confidence interval, TOL indicates tolerance.</p></fn></table-wrap-foot></table-wrap><p>According, to <xref rid="pone.0322358.t007" ref-type="table">Table 7</xref>. For each of the three comparisons that were examined, between 80 and 90 percent of the overlapping areas were inside the tolerance limits. The nasal unit (Area-3) is the area with the fewest values outside the tolerance limits (&#x0003e; 1.5&#x02009;mm and&#x02009;&#x0003c;&#x02009;&#x02212; 1.5&#x02009;mm). Even though there were more participants with a percentage of overlap in the non-reproducible bands for the Surface area, these values never involved more than 10% of the area&#x02014;except for one comparison where the Left cheek unit (Area-2) in the Einscan H2 showed more than 10% of overlapping area&#x0003e;1.5&#x02009;mm.</p></sec></sec><sec sec-type="conclusions" id="sec012"><title>Discussion</title><p>Face scanners have become a prominent topic of discussion, with numerous authors examining the advancements of this technology in the medical field in recent years. Hence, the predominant choice for evaluating the accuracy of 3D scanners involves using inanimate mannequins as study subjects. This aims to mitigate any image distortions associated with involuntary movements [<xref rid="pone.0322358.ref028" ref-type="bibr">28</xref>,<xref rid="pone.0322358.ref034" ref-type="bibr">34</xref>&#x02013;<xref rid="pone.0322358.ref036" ref-type="bibr">36</xref>]. However, it is important to acknowledge the limitation of an in vitro study, as patients typically cannot maintain absolute stillness in clinical settings, which may affect the study&#x02019;s applicability. Furthermore, previous reviews have similarly highlighted the significance of artifacts caused by living subjects, underscoring their importance in research [<xref rid="pone.0322358.ref037" ref-type="bibr">37</xref>]. Hence, this study specifically concentrated on live subjects with skeleton deformity, aiming to delineate the attributes of various technologies utilized in clinical practice. The aim of this study is to assess three different face scanning systems: laser scanners (Planmeca ProFace), dual-structured light (EinScan H2), and the TrueDepth camera system found on Apple iPhones (EM3D Scanner application). A prior investigation categorized the digital face scanner into four groups: highly reliable (deviation &#x0003c;1.0&#x02009;mm), reliable (deviation 1.0&#x02009;mm -1.5&#x02009;mm), moderately reliable (deviation 1.5&#x02013;2.0&#x02009;mm), and unreliable (deviation &#x0003e;2.0&#x02009;mm). Statistically significant differences in scanning accuracy were observed among the three facial scanning modalities for both the overall face and the five separate regions of the face (Area-1 to Area-5). Consequently, both null hypotheses were rejected. In clinical applications, particularly for tasks like facial aesthetic analysis in patient diagnosis and treatment planning, deviations less than 1.0&#x02009;mm were deemed highly acceptable [<xref rid="pone.0322358.ref003" ref-type="bibr">3</xref>,<xref rid="pone.0322358.ref031" ref-type="bibr">31</xref>,<xref rid="pone.0322358.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0322358.ref039" ref-type="bibr">39</xref>]. The superimposition procedures that were tested exhibited notable variances in both trueness and precision RMS values. The tested scanner yielded an overall trueness ranging from 0.70 to 0.85&#x02009;mm and an overall precision ranging from 0.68 to 0.81&#x02009;mm. Consequently, the computed accuracy values fall within the clinically acceptable scanning accuracy range.</p><p>In this study, the EM3D scanner application exhibited the highest overall accuracy performance in both the middle face and lower face areas, with trueness values of 0.70&#x02009;&#x000b1;&#x02009;0.16&#x02009;mm and precision values of 0.68&#x02009;&#x000b1;&#x02009;0.16&#x02009;mm. However, when investigating the scanning trueness and precision of the tested devices across five different localized surface areas of the face, it was found that the EM3D scanner application exhibited greater trueness value compared to both the EinScan H2 and Planmeca ProFace scanners, particularly in the cheek unit area. Furthermore, statistical analysis showed that there was no significant difference in trueness between the EM3D scanner application and the other scanners, particularly in the mental unit area. As of now, there are no existing studies in the literature investigating the scanning accuracy of the EM3D scanner application. This is attributed to its recent introduction to the 3D face scanner market in 2020. According to Amornvit et al. (2019) [<xref rid="pone.0322358.ref028" ref-type="bibr">28</xref>], a smartphone&#x02019;s 3D depth-sensing sensor scanner is accurate when measuring linearly in the frontal plane, but it is less accurate when measuring depth when compared to professional face scanners. These findings align with those of Liu et al. (2019) [<xref rid="pone.0322358.ref040" ref-type="bibr">40</xref>], who concluded that professional 3D facial scanners and mobile device-compatible face scanners perform similarly for simple and flat facial regions such as the forehead, cheeks, and chin. However, when complex facial regions such as the external ears, eyelids, nostrils, and teeth were scanned using mobile device-compatible face scanners, the scanning accuracy was notably low [<xref rid="pone.0322358.ref028" ref-type="bibr">28</xref>,<xref rid="pone.0322358.ref041" ref-type="bibr">41</xref>,<xref rid="pone.0322358.ref042" ref-type="bibr">42</xref>]. Depending on the depth of the fault, facial regions with defects exhibited higher levels of inaccuracy [<xref rid="pone.0322358.ref025" ref-type="bibr">25</xref>]. The results from our study indicate that there are differences in accuracy between the right and left cheek units. Specifically, the right cheek unit shows no statistically significant differences between the various measurements of all three facial scanners. However, the left cheek unit demonstrates statistically significant differences between the EM3D scanner application and the Planmeca Proface scanner. In this case, the researchers speculate that the differences in accuracy between the right and left cheek units may stem from the data collection method used by the EM3D scanner application. When subjects use their right arm to hold the device, it may not capture the left side of the face comprehensively during movements, particularly the left cheek area. This incomplete coverage could result in certain parts of the facial surface data being replaced by the program during the generation of the 3D facial reconstruction. Consequently, the left side of the face may not accurately reflect reality, affecting accuracy when compare in the research study. Therefore, when using face scanners compatible with mobile devices, careful consideration based on the purpose and the individual&#x02019;s characteristics may be necessary. The mean discrepancy values of scanned faces obtained utilizing mobile device-compatible 3D facial scanners ranged from 0.34 to 1.40&#x02009;mm in the studies that Mai HN &#x00026; Lee DH (2020) [<xref rid="pone.0322358.ref043" ref-type="bibr">43</xref>] analyzed based on their systematic reviews and meta-analysis. Furthermore, the meta-analysis revealed that professional 3D facial scanners were shown to be more accurate than 3D scanners compatible with mobile devices. Our findings are consistent with those of K&#x000fc;hlman et al. (2023) [<xref rid="pone.0322358.ref044" ref-type="bibr">44</xref>], as they also observed that when comparing all four scan applications based on 3D depth-sensing cameras, the mean absolute differences and standard deviations among the ten different areas of the face were all less than 1.0&#x02009;mm. Additionally, the scan accuracy (both trueness and precision) of depth measurements for all scan applications showed values less than 1.00&#x02009;mm. In the context of clinical applications, a deviation less than 1&#x02009;mm was considered highly reliable. The trueness of each scan application was deemed clinically acceptable for both diagnosis and treatment planning purposes [<xref rid="pone.0322358.ref044" ref-type="bibr">44</xref>]. A subgroup meta-analysis revealed a substantial difference in the accuracy of 3D facial scans performed on living subjects and inanimate items. This finding suggests that the results of research conducted in vitro or in a lab may differ from those acquired from human subjects [<xref rid="pone.0322358.ref043" ref-type="bibr">43</xref>]. According to the results of the present study, direct comparison with other studies is not feasible due to fundamental differences in study design. These differences include the use of either inanimate subjects or real patients, variations in the type of applications based on 3D depth-sensing cameras used, and differences in the number and location of surface areas evaluated.</p><p>While smartphone depth-sensing cameras operate on principles similar to those of professional laser scanning systems, it&#x02019;s worth noting that laser systems tend to be more sensitive to depths. This sensitivity arises from their construction with higher sensitivity sensors [<xref rid="pone.0322358.ref022" ref-type="bibr">22</xref>,<xref rid="pone.0322358.ref025" ref-type="bibr">25</xref>]. The literature has provided in vivo studies assessing the overall facial scanning accuracy of the Planmeca Proface laser scanner using reference anthropometric measurements. Menendez Lopez-Mateos et al. (2019) reported that the Planmeca scanner exhibited a mean error in accuracy of 1.04&#x02009;mm when compared to direct anthropometric measurements. Similarly, Liberton et al. (2019) found that, except for a few landmarks around the eyes, the mean error in accuracy of this laser scanner, compared to two stereophotogrammetry systems, was less than 2.00&#x02009;mm. In the present study, based on the facial partition divided into localized surface areas, both the nasal and perioral units exhibited significantly higher mean trueness values when calculated using the Planmeca ProFace scanner compared to the other scanners employed. Amornvit et al. (2019) [<xref rid="pone.0322358.ref028" ref-type="bibr">28</xref>] reported limitations of the Proface 3D Mid laser scanner, stating it was unable to scan undercuts wider than 6&#x02009;mm at a depth exceeding 2&#x02009;mm. Additionally, Koban et al. (2020) [<xref rid="pone.0322358.ref041" ref-type="bibr">41</xref>] noted lower accuracy in scanning nasal areas using a laser scanner. However, this specific finding was not corroborated in the present study. Based on the results of our study, we utilized a control mesh to compare against CBCT soft tissue segmentation obtained from the Planmeca Promax3D Mid cone beam scanner. This imaging unit, enhanced with the Planmeca ProFace scanner, has the capability to capture both a 3D photo and a CBCT image in a single rotation. This leads to improved trueness accuracy when assessing 3D deviation errors, particularly in the perioral region, where micro-motion movements or changes in resting lip position can be problematic. This improvement is achieved by utilizing face scans to test different machines at different time intervals. Aung et al. (1995) [<xref rid="pone.0322358.ref033" ref-type="bibr">33</xref>] also proposed that the orbital, circumoral, and nasal regions were reliable for laser scanners. Furthermore, Revilla-Le&#x000f3;n et al. (2021) have revealed that the position of the scanned surface area affected the accuracy of facial scanning for both trueness and precision. It was discovered that accuracy reduced when positioned more laterally and increased in the surface areas located closer to the facial midline.</p><p>Regarding the performance of the dual-structured light scanner in the present study, it was determined to have the least accuracy, with statistically significantly lower mean values for both trueness and precision compared to the EM3D Scanner application in terms of overall accuracy, encompassing both middle and lower facial regions. However, when investigating the scanning accuracy of the tested devices in separate facial regions, there were no statistically significant differences compared to the application in the surface areas located closer to the facial midline. The Einscan H2, a portable 3D scanner that uses a hybrid LED and infrared light source, has not yet been the subject of any research published in the literature that examines scanning accuracy. Its recent entry into the 3D face scanner market in 2023 is the reason for this. In order to compare with comparable technology, Piedra-Cascon et al. (2020) [<xref rid="pone.0322358.ref027" ref-type="bibr">27</xref>] utilized direct anthropometry as a reference method to evaluate the accuracy of a dual structured-light scanner connected to a tablet in generating 3D facial models of 10 individuals. Their mean accuracy of 0.910&#x02009;&#x000b1;&#x02009;0.320&#x02009;mm was deemed acceptable for virtual treatment planning, according to their findings. Liu et al. (2021) [<xref rid="pone.0322358.ref045" ref-type="bibr">45</xref>] demonstrated that both stationary stereophotogrammetry and a dual structured-light scanner system coupled to a tablet exhibited good accuracy and precision for clinical purposes when compared to direct anthropometry. Similar to this, in a recent paper by Cascos et al. (2023) [<xref rid="pone.0322358.ref046" ref-type="bibr">46</xref>], this technology achieved a mean accuracy value of 0.61 (&#x000b1;1.65) and 0.28 (&#x000b1;2.03) in maximum intercuspation and smile in sixty participants. However, Mai HN &#x00026; Lee DH (2020) [<xref rid="pone.0322358.ref043" ref-type="bibr">43</xref>] suggest that when utilizing external structured-light scanners, the overall accuracy should be interpreted as a result that encompasses the performance of the compatible mobile or tablet device. In previous studies on handheld 3D structured light scanners from the Einscan lineup, Amornvit et al. (2019) [<xref rid="pone.0322358.ref028" ref-type="bibr">28</xref>] reported accuracy findings that differ from the results of our study. They found that the EinScan Pro 2X Plus and EinScan Pro structured light scanners exhibited significantly higher trueness values compared to the ProFace 3D Mid laser scanner and the iPhone X using the Bellus3D Face Application. Similarly, in the research conducted by Michelinakis et al. (2023) [<xref rid="pone.0322358.ref047" ref-type="bibr">47</xref>], the Einscan Pro HD scanner demonstrated a mean accuracy value of 0.358&#x02009;mm, exhibiting significantly higher accuracy for the complete face and significantly higher trueness for each facial partition compared to other scanners such as the Planmeca Preface and Ray Face Scanner. One of the primary limitations of portable face-scanning systems is motion artifacts induced by involuntary facial movements and prolonged facial acquisition time. Due to the lack of clear control over scanning time in our study design, this factor may have been the main source of error in the results of these scanners.</p><p>The analysis of superimpositions revealed differences in reproducibility across various areas. Approximately 80% of the surface fell into the highly reproducible category, with the nose area scanned by the Planmeca ProFace scanner demonstrating the highest average percentage overlap value, followed by the chin and perioral area. For each of the three comparisons examined, between 80 and 90 percent of the five overlapping areas were within the tolerance limits of reproducibility. These outcomes align with what Pellitteri et al. (2021) [<xref rid="pone.0322358.ref015" ref-type="bibr">15</xref>] found. However, it appears that the percentages of locations within the tolerance range in our study are higher than theirs. The right cheek, at almost 60%, was the area that attained the highest percentage, followed by the chin and the tip of the nose. Pellitteri et al. (2023) [<xref rid="pone.0322358.ref048" ref-type="bibr">48</xref>] presented results that contrasted with previous findings. They demonstrated that the areas overlap analysis between scanners validated the accuracy of all systems, with over 90% of each area analyzed falling into the highly reproducible band. Additionally, the chin was found to be the most accurately recreated, with no variation observed between scanners.</p><p>The literature has reported the use of synthetic face markers to help with appropriate registration between the test and reference data sets [<xref rid="pone.0322358.ref049" ref-type="bibr">49</xref>,<xref rid="pone.0322358.ref050" ref-type="bibr">50</xref>]. On the patient&#x02019;s face, 4.00&#x02009;mm diameter marker stickers were securely placed in various locations for use with the 3D scanners. Unfortunately, as illustrated in the diagrammatic representation of the proposed method. (<xref rid="pone.0322358.g001" ref-type="fig">Fig 1</xref>), the marker sticker on the 3D images obtained by the three different 3D scanners utilized in this study was unclear. It was clearly detectable only in the 3D image obtained from CBCT soft tissue segmentation. According to a previous study, while locating the spherical projections on the textured images could potentially offer a solution, they might not consistently appear smaller and less visible than those on the non-textured 3D images. Additionally, their positions on the textured 3D images may not always align with the original balls [<xref rid="pone.0322358.ref047" ref-type="bibr">47</xref>,<xref rid="pone.0322358.ref051" ref-type="bibr">51</xref>]. However, the positions of the measurement points on the 3D image without texture did not always align with those on the textured image, especially when the distortion of the 3D image was significant due to the rendering process of attempting to overlay multiple photographs. This could result in pixel displacement while the surface volume of the image remained unchanged. As a result, the decision was made to refrain from using the marker stickers as facial indicators to aid in mesh registration. In our study, we applied the alignment algorithm and digitized surface area locations using the best-fit algorithm (BF). This method utilizes the iterative closest point (ICP) algorithm to align two meshes by minimizing the discrepancies between their point clouds. The algorithm continuously adjusts the transformation to reduce the error metric [<xref rid="pone.0322358.ref052" ref-type="bibr">52</xref>]. We specifically opted for the best-fit algorithm (BF) as processed directly by the software, without operator-defined alignment to specific sections of the dataset or pre-identified landmarks. This ensured a more standardized and automated approach to alignment, reducing potential human bias in the superimposition process. In the study by Revilla-Leon et al. (2021) [<xref rid="pone.0322358.ref053" ref-type="bibr">53</xref>], an in vitro experiment was conducted to evaluate the accuracy of a facial scanner based on different alignment methods, specifically the reference or section-based best fit (RBF) and landmark-based best fit alignment (LA) techniques. The RBF method aligns datasets by restricting the alignment to operator-identified sections of the dataset, while the LA method requires the operator to manually select common landmarks or points, which are then aligned by the software. Additionally, the study examined the digitized area, both total and localized, of a stereophotogrammetry scanner to assess its impact on alignment accuracy. The study suggested that when creating a virtual patient representation, where multiple scans need to be superimposed, the reference-based best fit (RBF) may be the most suitable alignment method. This recommendation is based on their findings that the RBF algorithm achieved higher trueness, but lower precision compared to the landmark-based best fit alignment technique. Additionally, they observed that the placement of the scanned surface area impacted the accuracy of facial scanning in terms of both trueness and precision. Specifically, it performed better in the center of the face but less accurately when positioned farther laterally. These findings align with our study results, which also demonstrated that the midface region consistently exhibited greater accuracy compared to the lateral areas across all three 3D face scanners used in our research.</p><p>Taking all factors into account, this study demonstrates that all three scanning systems used (laser scanner, dual-structured light, and smartphone) can be regarded as accurate means of obtaining 3D facial models. While statistically significant differences in accuracy among the three face scanners were detected, it remains uncertain whether these differences have clinical significance. All tested scanners had mean entire face trueness values that were within a 1&#x02009;mm range. Deviations smaller than 1.0&#x02009;mm were deemed extremely acceptable in clinical applications, particularly for activities such as facial aesthetic analysis in patient diagnosis and treatment planning. A facial model can be considered suitable in clinical practice if its variation is less than 1.5&#x02009;mm [<xref rid="pone.0322358.ref003" ref-type="bibr">3</xref>,<xref rid="pone.0322358.ref039" ref-type="bibr">39</xref>]. Below this 1.5&#x02009;mm clinical threshold, all the scanners used in the study exhibited deviations in complete face scanning trueness. The current study demonstrates that it is currently feasible to conduct 3D facial scanning in clinical settings using face scanners compatible with smartphones. The main advantages of these scanners are their portability and low cost. However, to minimize the risk of motion artifacts, patients must adhere more closely to instructions compared to other professional devices, requiring additional attention from the clinician. Patients need to remain motionless during the photo-acquisition procedure from various perspectives. However, in orthognathic, plastic, and maxillofacial rehabilitation cases, it is essential to reference soft tissue changes alongside changes in hard tissue and skeletal components post-treatment. Therefore, static face scanner devices capable of quickly capturing images, such as stereophotogrammetry scanners or CBCT imaging units incorporating integrated 3D face scan systems capable of capturing images in a single rotation, provide greater accuracy, particularly in surface areas closer to the facial midline, especially in the nose and perioral regions. This enhanced accuracy is due to their ability to minimize the risk of motion artifacts. There are limitations to the present study. Although the study included patients with skeletal deformities undergoing orthognathic surgery, most of the sample consisted of patients with Class III skeletal deformities. This limitation prevents the assessment of differences in the accuracy of 3D images concerning facial deformities arising from other types of skeletal deformities. According to Zhao et al. (2017) [<xref rid="pone.0322358.ref003" ref-type="bibr">3</xref>], patients with facial deformities exhibit varying degrees of deflection and collapse. Specific areas such as the labiofacial sulcus, oral fissure, and angle of mouth experience an increase in undercut area due to the unusual shape of the facial tissue. This undercut region diminishes the precision of facial scanning and poses challenges for optical scanning. Future research should investigate the effectiveness of different facial scanning modalities in capturing various facial deformities and expressions, including those made during speaking or smiling. Ensuring accuracy when combining extraoral and intraoral data sets is crucial for this purpose. The development of virtual patient models can be facilitated by integrating tomographic data with static and dynamic surface data acquisition sets, which helps streamline the surgical treatment planning procedure.</p></sec><sec sec-type="conclusions" id="sec013"><title>Conclusion</title><list list-type="bullet"><list-item><p>The EM3D scanner application demonstrated the highest overall accuracy (trueness and precision) performance in both the middle face and lower face areas, yet there was no significant difference compared to the Planmeca ProFace scanner.</p></list-item><list-item><p>Both the nasal and perioral units exhibited significantly greater trueness and precision values when calculated using the Planmeca ProFace scanner compared to the other scanners used, as determined by the facial partition separated into localized surface areas.</p></list-item><list-item><p>An overall trueness ranging from 0.70 to 0.85&#x02009;mm and an overall precision ranging from 0.68 to 0.81&#x02009;mm were observed, with deviations less than 1.0&#x02009;mm being considered highly acceptable. Additionally, clinical acceptable scanning accuracy was defined as less than or equal to 1.5&#x02009;mm.</p></list-item><list-item><p>The analysis of superimpositions uncovered variations in reproducibility across different areas. Around 80% of the surface fell into the highly reproducible category, with the nose area scanned by the Planmeca ProFace scanner exhibiting the highest average percentage overlap value, followed by the chin and perioral area.</p></list-item></list></sec><sec id="sec014" sec-type="supplementary-material"><title>Supporting information</title><supplementary-material id="pone.0322358.s001" position="float" content-type="local-data"><label>S1 Table</label><caption><title>Raw data used for the statistical analysis of the Intraclass Correlation Coefficient (ICC).</title><p>The data were obtained from ten randomly selected CBCT soft tissue segmentations. Each segmentation was manually marked for five localized surface areas, and the process was repeated twice by the same examiner, ensuring a minimum interval of seven days between each marking session.</p><p>(XLSX)</p></caption><media xlink:href="pone.0322358.s001.xlsx"/></supplementary-material><supplementary-material id="pone.0322358.s002" position="float" content-type="local-data"><label>S2 Table</label><caption><title>Descriptive statistics of the trueness and precision values (mm) obtained from three-dimensional scanners across different areas.</title><p>T: Trueness, P: Precision, PMC: Planmeca Proface, Ein: EnScanH2, APP: EM3D scanner application, Rcheek: Right cheek unit, Lcheek: Left cheek unit, Nose: nose unit, Perioral: Perioral unit, Chin: Mental unit.</p><p>(PDF)</p></caption><media xlink:href="pone.0322358.s002.pdf"/></supplementary-material></sec></body><back><ack><p>The authors would like to acknowledge the Faculty of Dentistry, Mahidol University for providing support in the use of facilities and granting access to the Planmeca ProMax 3D ProFace for data collection from the study participants.</p></ack><ref-list><title>References</title><ref id="pone.0322358.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Spear</surname><given-names>FM</given-names></name>, <name><surname>Kokich</surname><given-names>VG</given-names></name>. <article-title>A multidisciplinary approach to esthetic dentistry</article-title>. <source>Dent Clin North Am</source>. <year>2007</year>;<volume>51</volume>(<issue>2</issue>):<fpage>487</fpage>&#x02013;<lpage>505</lpage>, x&#x02013;xi. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cden.2006.12.007</pub-id>
<pub-id pub-id-type="pmid">17532924</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Jazayeri</surname><given-names>HE</given-names></name>, <name><surname>Kang</surname><given-names>S</given-names></name>, <name><surname>Masri</surname><given-names>RM</given-names></name>, <name><surname>Kuhn</surname><given-names>L</given-names></name>, <name><surname>Fahimipour</surname><given-names>F</given-names></name>, <name><surname>Vanevenhoven</surname><given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Advancements in craniofacial prosthesis fabrication: A narrative review of holistic treatment</article-title>. <source>J Adv Prosthodont</source>. <year>2018</year>;<volume>10</volume>(<issue>6</issue>):<fpage>430</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.4047/jap.2018.10.6.430</pub-id>
<pub-id pub-id-type="pmid">30584472</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>Y-J</given-names></name>, <name><surname>Xiong</surname><given-names>Y-X</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name>. <article-title>Three-dimensional accuracy of facial scan for facial deformities in clinics: a new evaluation method for facial scanner accuracy</article-title>. <source>PLoS One</source>. <year>2017</year>;<volume>12</volume>(<issue>1</issue>):e0169402. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0169402</pub-id>
<pub-id pub-id-type="pmid">28056044</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Berssenbr&#x000fc;gge</surname><given-names>P</given-names></name>, <name><surname>Berlin</surname><given-names>NF</given-names></name>, <name><surname>Kebeck</surname><given-names>G</given-names></name>, <name><surname>Runte</surname><given-names>C</given-names></name>, <name><surname>Jung</surname><given-names>S</given-names></name>, <name><surname>Kleinheinz</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>2D and 3D analysis methods of facial asymmetry in comparison</article-title>. <source>J Craniomaxillofac Surg</source>. <year>2014</year>;<volume>42</volume>(<issue>6</issue>):e327&#x02013;<lpage>34</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jcms.2014.01.028</pub-id>
<pub-id pub-id-type="pmid">24507934</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Toma</surname><given-names>AM</given-names></name>, <name><surname>Zhurov</surname><given-names>A</given-names></name>, <name><surname>Playle</surname><given-names>R</given-names></name>, <name><surname>Ong</surname><given-names>E</given-names></name>, <name><surname>Richmond</surname><given-names>S</given-names></name>. <article-title>Reproducibility of facial soft tissue landmarks on 3D laser-scanned facial images</article-title>. <source>Orthod Craniofac Res</source>. <year>2009</year>;<volume>12</volume>(<issue>1</issue>):<fpage>33</fpage>&#x02013;<lpage>42</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/j.1601-6343.2008.01435.x</pub-id>
<pub-id pub-id-type="pmid">19154273</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Hajeer</surname><given-names>MY</given-names></name>, <name><surname>Millett</surname><given-names>DT</given-names></name>, <name><surname>Ayoub</surname><given-names>AF</given-names></name>, <name><surname>Siebert</surname><given-names>JP</given-names></name>. <article-title>Current products and practices: Applications of 3D imaging in orthodontics: part I</article-title>. <source>J Orthod</source>. <year>2004</year>;<volume>31</volume>(<issue>1</issue>):<fpage>62</fpage>&#x02013;<lpage>70</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1179/146531204225011346</pub-id>
<pub-id pub-id-type="pmid">15071154</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Millett</surname><given-names>DT</given-names></name>, <name><surname>Siebert</surname><given-names>JP</given-names></name>. <article-title>Three-dimensional imaging in orthognathic surgery: the clinical application of a new method</article-title>. <source>Int J Adult Orthodon Orthognath Surg</source>. <year>2002</year>;<volume>17</volume>(<issue>4</issue>):<fpage>318</fpage>&#x02013;<lpage>30</lpage>.<pub-id pub-id-type="pmid">12593004</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Liebregts</surname><given-names>JHF</given-names></name>, <name><surname>Timmermans</surname><given-names>M</given-names></name>, <name><surname>De Koning</surname><given-names>MJJ</given-names></name>, <name><surname>Berg&#x000e9;</surname><given-names>SJ</given-names></name>, <name><surname>Maal</surname><given-names>TJJ</given-names></name>. <article-title>Three-dimensional facial simulation in bilateral sagittal split osteotomy: a validation study of 100 patients</article-title>. <source>J Oral Maxillofac Surg</source>. <year>2015</year>;<volume>73</volume>(<issue>5</issue>):<fpage>961</fpage>&#x02013;<lpage>70</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.joms.2014.11.006</pub-id>
<pub-id pub-id-type="pmid">25795178</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Chang</surname><given-names>Y-J</given-names></name>, <name><surname>Ruellas</surname><given-names>ACO</given-names></name>, <name><surname>Yatabe</surname><given-names>MS</given-names></name>, <name><surname>Westgate</surname><given-names>PM</given-names></name>, <name><surname>Cevidanes</surname><given-names>LHS</given-names></name>, <name><surname>Huja</surname><given-names>SS</given-names></name>. <article-title>Soft tissue changes measured with three-dimensional software provides new insights for surgical predictions</article-title>. <source>J Oral Maxillofac Surg</source>. <year>2017</year>;<volume>75</volume>(<issue>10</issue>):<fpage>2191</fpage>&#x02013;<lpage>201</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.joms.2017.05.010</pub-id>
<pub-id pub-id-type="pmid">28623681</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>De Riu</surname><given-names>G</given-names></name>, <name><surname>Virdis</surname><given-names>PI</given-names></name>, <name><surname>Meloni</surname><given-names>SM</given-names></name>, <name><surname>Baj</surname><given-names>A</given-names></name>, <name><surname>Vaira</surname><given-names>LA</given-names></name>. <article-title>Accuracy of computer-assisted orthognathic surgery</article-title>. <source>J Craniomaxillofac Surg</source>. <year>2018</year>;<volume>46</volume>(<issue>2</issue>):<fpage>293</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">29275075</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Fink</surname><given-names>M</given-names></name>, <name><surname>Medelnik</surname><given-names>J</given-names></name>, <name><surname>Strobel</surname><given-names>K</given-names></name>, <name><surname>Hirschfelder</surname><given-names>U</given-names></name>, <name><surname>Hofmann</surname><given-names>E</given-names></name>. <article-title>Metric precision via soft-tissue landmarks in three-dimensional structured-light scans of human faces</article-title>. <source>J Orofac Orthop</source>. <year>2014</year>;<volume>75</volume>(<issue>2</issue>):<fpage>133</fpage>&#x02013;<lpage>43</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00056-013-0201-9</pub-id>
<pub-id pub-id-type="pmid">24577017</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>SS</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>He</surname><given-names>Y</given-names></name>. <article-title>Three-dimensional facial stereography and its application in orthognathic surgery</article-title>. <source>J Oral Maxillofac Surg</source>. <year>2019</year>; [Epub ahead of print].</mixed-citation></ref><ref id="pone.0322358.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Gibelli</surname><given-names>D</given-names></name>, <name><surname>Pucciarelli</surname><given-names>V</given-names></name>, <name><surname>Caplova</surname><given-names>Z</given-names></name>, <name><surname>Cappella</surname><given-names>A</given-names></name>, <name><surname>Dolci</surname><given-names>C</given-names></name>, <name><surname>Cattaneo</surname><given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Validation of a low-cost laser scanner device for the assessment of three-dimensional facial anatomy in living subjects</article-title>. <source>J Craniomaxillofac Surg</source>. <year>2018</year>;<volume>46</volume>(<issue>9</issue>):<fpage>1493</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jcms.2018.06.009</pub-id>
<pub-id pub-id-type="pmid">30196857</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Blasi</surname><given-names>A</given-names></name>, <name><surname>Nucera</surname><given-names>R</given-names></name>, <name><surname>Ronsivalle</surname><given-names>V</given-names></name>, <name><surname>Candida</surname><given-names>E</given-names></name>, <name><surname>Grippaudo</surname><given-names>C</given-names></name>. <article-title>Asymmetry index for the photogrammetric assessment of facial asymmetry</article-title>. <source>Am J Orthod Dentofacial Orthop</source>. <year>2022</year>;<volume>162</volume>(<issue>3</issue>):<fpage>394</fpage>&#x02013;<lpage>402</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ajodo.2021.04.030</pub-id>
<pub-id pub-id-type="pmid">35562291</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Pellitteri</surname><given-names>F</given-names></name>, <name><surname>Brucculeri</surname><given-names>L</given-names></name>, <name><surname>Spedicato</surname><given-names>GA</given-names></name>, <name><surname>Siciliani</surname><given-names>G</given-names></name>, <name><surname>Lombardo</surname><given-names>L</given-names></name>. <article-title>Comparison of the accuracy of digital face scans obtained by two different scanners</article-title>. <source>Angle Orthod</source>. <year>2021</year>;<volume>91</volume>(<issue>5</issue>):<fpage>641</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2319/092720-823.1</pub-id>
<pub-id pub-id-type="pmid">33826690</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Karatas</surname><given-names>OH</given-names></name>, <name><surname>Toy</surname><given-names>E</given-names></name>. <article-title>Three-dimensional imaging techniques: a literature review</article-title>. <source>Eur J Dent</source>. <year>2014</year>;<volume>8</volume>(<issue>1</issue>):<fpage>132</fpage>&#x02013;<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.4103/1305-7456.126269</pub-id>
<pub-id pub-id-type="pmid">24966761</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Alves</surname><given-names>PVM</given-names></name>, <name><surname>Zhao</surname><given-names>L</given-names></name>, <name><surname>Patel</surname><given-names>PK</given-names></name>, <name><surname>Bolognese</surname><given-names>AM</given-names></name>. <article-title>Three-dimensional facial surface analysis of patients with skeletal malocclusion</article-title>. <source>J Craniofac Surg</source>. <year>2009</year>;<volume>20</volume>(<issue>2</issue>):<fpage>290</fpage>&#x02013;<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1097/SCS.0b013e3181992165</pub-id>
<pub-id pub-id-type="pmid">19218859</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Khambay</surname><given-names>B</given-names></name>, <name><surname>Nairn</surname><given-names>N</given-names></name>, <name><surname>Bell</surname><given-names>A</given-names></name>, <name><surname>Miller</surname><given-names>J</given-names></name>, <name><surname>Bowman</surname><given-names>A</given-names></name>, <name><surname>Ayoub</surname><given-names>AF</given-names></name>. <article-title>Validation and reproducibility of a high-resolution three-dimensional facial imaging system</article-title>. <source>Br J Oral Maxillofac Surg</source>. <year>2008</year>;<volume>46</volume>(<issue>1</issue>):<fpage>27</fpage>&#x02013;<lpage>32</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.bjoms.2007.04.017</pub-id>
<pub-id pub-id-type="pmid">17561318</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Nord</surname><given-names>F</given-names></name>, <name><surname>Ferjencik</surname><given-names>R</given-names></name>, <name><surname>Seifert</surname><given-names>B</given-names></name>, <name><surname>Lanzer</surname><given-names>M</given-names></name>, <name><surname>Gander</surname><given-names>T</given-names></name>, <name><surname>Matthews</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>The 3dMD photogrammetric photo system in cranio-maxillofacial surgery: Validation of interexaminer variations and perceptions</article-title>. <source>J Craniomaxillofac Surg</source>. <year>2015</year>;<volume>43</volume>(<issue>9</issue>):<fpage>1798</fpage>&#x02013;<lpage>803</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jcms.2015.08.017</pub-id>
<pub-id pub-id-type="pmid">26421470</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Wellens</surname><given-names>HLL</given-names></name>, <name><surname>Hoskens</surname><given-names>H</given-names></name>, <name><surname>Claes</surname><given-names>P</given-names></name>, <name><surname>Kuijpers-Jagtman</surname><given-names>AM</given-names></name>, <name><surname>Ortega-Castrill&#x000f3;n</surname><given-names>A</given-names></name>. <article-title>Three-dimensional facial capture using a custom-built photogrammetry setup: design, performance, and cost</article-title>. <source>Am J Orthod Dentofacial Orthop</source>. <year>2020</year>;<volume>158</volume>(<issue>2</issue>):<fpage>286</fpage>&#x02013;<lpage>99</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ajodo.2020.01.016</pub-id>
<pub-id pub-id-type="pmid">32746977</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Gwilliam</surname><given-names>JR</given-names></name>, <name><surname>Cunningham</surname><given-names>SJ</given-names></name>, <name><surname>Hutton</surname><given-names>T</given-names></name>. <article-title>Reproducibility of soft tissue landmarks on three-dimensional facial scans</article-title>. <source>Eur J Orthod</source>. <year>2006</year>;<volume>28</volume>(<issue>5</issue>):<fpage>408</fpage>&#x02013;<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/ejo/cjl024</pub-id>
<pub-id pub-id-type="pmid">16901962</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Kovacs</surname><given-names>L</given-names></name>, <name><surname>Zimmermann</surname><given-names>A</given-names></name>, <name><surname>Brockmann</surname><given-names>G</given-names></name>, <name><surname>Baurecht</surname><given-names>H</given-names></name>, <name><surname>Schwenzer-Zimmerer</surname><given-names>K</given-names></name>, <name><surname>Papadopulos</surname><given-names>NA</given-names></name>, <etal>et al</etal>. <article-title>Accuracy and precision of the three-dimensional assessment of the facial surface using a 3-D laser scanner</article-title>. <source>IEEE Trans Med Imaging</source>. <year>2006</year>;<volume>25</volume>(<issue>6</issue>):<fpage>742</fpage>&#x02013;<lpage>54</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tmi.2006.873624</pub-id>
<pub-id pub-id-type="pmid">16768239</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Bakirman</surname><given-names>T</given-names></name>, <name><surname>Gumusay</surname><given-names>MU</given-names></name>, <name><surname>Reis</surname><given-names>HC</given-names></name>, <name><surname>Selbesoglu</surname><given-names>MO</given-names></name>, <name><surname>Yosmaoglu</surname><given-names>S</given-names></name>, <name><surname>Yaras</surname><given-names>MC</given-names></name>, <etal>et al</etal>. <article-title>Comparison of low cost 3D structured light scanners for face modeling</article-title>. <source>Appl Opt</source>. <year>2017</year>;<volume>56</volume>(<issue>4</issue>):<fpage>985</fpage>&#x02013;<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1364/AO.56.000985</pub-id>
<pub-id pub-id-type="pmid">28158103</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Ma</surname><given-names>L</given-names></name>, <name><surname>Xu</surname><given-names>T</given-names></name>, <name><surname>Lin</surname><given-names>J</given-names></name>. <article-title>Validation of a three-dimensional facial scanning system based on structured light techniques</article-title>. <source>Comput Methods Programs Biomed</source>. <year>2009</year>;<volume>94</volume>(<issue>3</issue>):<fpage>290</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cmpb.2009.01.010</pub-id>
<pub-id pub-id-type="pmid">19303659</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Elbashti</surname><given-names>M</given-names></name>, <name><surname>Kano</surname><given-names>S</given-names></name>, <name><surname>Cheng</surname><given-names>A</given-names></name>, <name><surname>Amita</surname><given-names>S</given-names></name>, <name><surname>Hattori</surname><given-names>M</given-names></name>, <name><surname>Takahashi</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Smartphone application as a low-cost alternative for digitizing facial defects: Is it accurate enough for clinical application?</article-title>
<source>Int J Prosthodont</source>. <year>2019</year>;<volume>32</volume>(<issue>6</issue>):<fpage>541</fpage>&#x02013;<lpage>3</lpage>.<pub-id pub-id-type="pmid">31664272</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Piccirilli</surname><given-names>M</given-names></name>, <name><surname>Doretto</surname><given-names>G</given-names></name>, <name><surname>Ross</surname><given-names>A</given-names></name>, <name><surname>Adjeroh</surname><given-names>D</given-names></name>. <article-title>A mobile structured light system for 3D face acquisition</article-title>. <source>IEEE Sensors J</source>. <year>2016</year>;<volume>16</volume>(<issue>7</issue>):<fpage>1854</fpage>&#x02013;<lpage>5</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/jsen.2015.2511064</pub-id></mixed-citation></ref><ref id="pone.0322358.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Piedra-Casc&#x000f3;n</surname><given-names>W</given-names></name>, <name><surname>Meyer</surname><given-names>MJ</given-names></name>, <name><surname>Methani</surname><given-names>MM</given-names></name>, <name><surname>Revilla-Le&#x000f3;n</surname><given-names>M</given-names></name>. <article-title>Accuracy (trueness and precision) of a dual-structured light facial scanner and interexaminer reliability</article-title>. <source>J Prosthet Dent</source>. <year>2020</year>;<volume>124</volume>(<issue>5</issue>):<fpage>567</fpage>&#x02013;<lpage>74</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.prosdent.2019.10.010</pub-id>
<pub-id pub-id-type="pmid">31918895</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Amornvit</surname><given-names>P</given-names></name>, <name><surname>Sanohkan</surname><given-names>S</given-names></name>. <article-title>The accuracy of digital face scans obtained from 3D scanners: an in vitro study</article-title>. <source>Int J Environ Res Public Health</source>. <year>2019</year>;<volume>16</volume>(<issue>24</issue>):<fpage>5061</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/ijerph16245061</pub-id>
<pub-id pub-id-type="pmid">31842255</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Alfaro-Santaf&#x000e9;</surname><given-names>J</given-names></name>, <name><surname>G&#x000f3;mez-Bernal</surname><given-names>A</given-names></name>, <name><surname>Lanuza-Cerz&#x000f3;cimo</surname><given-names>C</given-names></name>, <name><surname>Alfaro-Santaf&#x000e9;</surname><given-names>JV</given-names></name>, <name><surname>P&#x000e9;rez-Morcillo</surname><given-names>A</given-names></name>, <name><surname>Almenar-Arasanz</surname><given-names>AJ</given-names></name>. <article-title>Three-axis measurements with a novel system for 3D plantar foot scanning: iPhone X</article-title>. <source>Footwear Science</source>. <year>2020</year>;<volume>12</volume>(<issue>2</issue>):<fpage>123</fpage>&#x02013;<lpage>31</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/19424280.2020.1734867</pub-id></mixed-citation></ref><ref id="pone.0322358.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Jia</surname><given-names>T</given-names></name>, <name><surname>Zhou</surname><given-names>Z</given-names></name>, <name><surname>Gao</surname><given-names>H</given-names></name>. <article-title>Depth measurement based on infrared coded structured light</article-title>. <source>J Sens</source>. <year>2014</year>;<volume>2014</volume>:<fpage>1</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1155/2014/852621</pub-id></mixed-citation></ref><ref id="pone.0322358.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Knoops</surname><given-names>PGM</given-names></name>, <name><surname>Beaumont</surname><given-names>CAA</given-names></name>, <name><surname>Borghi</surname><given-names>A</given-names></name>, <name><surname>Rodriguez-Florez</surname><given-names>N</given-names></name>, <name><surname>Breakey</surname><given-names>RWF</given-names></name>, <name><surname>Rodgers</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Comparison of three-dimensional scanner systems for craniomaxillofacial imaging</article-title>. <source>J Plast Reconstr Aesthet Surg</source>. <year>2017</year>;<volume>70</volume>(<issue>4</issue>):<fpage>441</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.bjps.2016.12.015</pub-id>
<pub-id pub-id-type="pmid">28161205</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref032"><label>32</label><mixed-citation publication-type="book"><collab>International Organization for Standardization.</collab> ISO 5725-1:2023. <source>Accuracy (trueness and precision) of measurement methods and results - Part 1: General principles and definitions</source>. <publisher-loc>Geneva</publisher-loc>: <publisher-name>ISO</publisher-name>; <year>2023</year>.</mixed-citation></ref><ref id="pone.0322358.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Aung</surname><given-names>SC</given-names></name>, <name><surname>Ngim</surname><given-names>RC</given-names></name>, <name><surname>Lee</surname><given-names>ST</given-names></name>. <article-title>Evaluation of the laser scanner as a surface measuring tool and its accuracy compared with direct facial anthropometric measurements</article-title>. <source>Br J Plast Surg</source>. <year>1995</year>;<volume>48</volume>(<issue>8</issue>):<fpage>551</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/0007-1226(95)90043-8</pub-id>
<pub-id pub-id-type="pmid">8548155</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>L&#x000fc;bbers</surname><given-names>H-T</given-names></name>, <name><surname>Medinger</surname><given-names>L</given-names></name>, <name><surname>Kruse</surname><given-names>A</given-names></name>, <name><surname>Gr&#x000e4;tz</surname><given-names>KW</given-names></name>, <name><surname>Matthews</surname><given-names>F</given-names></name>. <article-title>Precision and accuracy of the 3dMD photogrammetric system in craniomaxillofacial application</article-title>. <source>J Craniofac Surg</source>. <year>2010</year>;<volume>21</volume>(<issue>3</issue>):<fpage>763</fpage>&#x02013;<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1097/SCS.0b013e3181d841f7</pub-id>
<pub-id pub-id-type="pmid">20485043</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Lincoln</surname><given-names>KP</given-names></name>, <name><surname>Kiat-Amnuay</surname><given-names>S</given-names></name>, <name><surname>Whitley</surname><given-names>D</given-names></name>, <name><surname>Powers</surname><given-names>JM</given-names></name>, <name><surname>Lemon</surname><given-names>JC</given-names></name>. <article-title>Comparative accuracy of facial models fabricated using traditional and 3D imaging techniques</article-title>. <source>J Prosthodont Complex Restor</source>. <year>2016</year>;<fpage>1</fpage>&#x02013;<lpage>13</lpage>.</mixed-citation></ref><ref id="pone.0322358.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Weinberg</surname><given-names>SM</given-names></name>, <name><surname>Naidoo</surname><given-names>S</given-names></name>, <name><surname>Govier</surname><given-names>DP</given-names></name>, <name><surname>Martin</surname><given-names>RA</given-names></name>, <name><surname>Kane</surname><given-names>AA</given-names></name>, <name><surname>Marazita</surname><given-names>ML</given-names></name>. <article-title>Anthropometric precision and accuracy of digital three-dimensional photogrammetry: comparing the Genex and 3dMD imaging systems with one another and with direct anthropometry</article-title>. <source>J Craniofac Surg</source>. <year>2006</year>;<volume>17</volume>(<issue>3</issue>):<fpage>477</fpage>&#x02013;<lpage>83</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1097/00001665-200605000-00015</pub-id>
<pub-id pub-id-type="pmid">16770184</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Antonacci</surname><given-names>D</given-names></name>, <name><surname>Piancino</surname><given-names>MG</given-names></name>, <name><surname>Garagiola</surname><given-names>U</given-names></name>, <name><surname>Debernardi</surname><given-names>C</given-names></name>, <name><surname>Perillo</surname><given-names>L</given-names></name>, <name><surname>Cugliari</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Facial scanning technologies in the era of digital workflow: a systematic review and network meta-analysis</article-title>. <source>J Prosthodont Res</source>. <year>2022</year>;JPR_D_22_00107.</mixed-citation></ref><ref id="pone.0322358.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Secher</surname><given-names>JJ</given-names></name>, <name><surname>Darvann</surname><given-names>TA</given-names></name>, <name><surname>Pinholt</surname><given-names>EM</given-names></name>. <article-title>Accuracy and reproducibility of the DAVID SLS-2 scanner in three-dimensional facial imaging</article-title>. <source>J Craniomaxillofac Surg</source>. <year>2017</year>;<volume>45</volume>(<issue>10</issue>):<fpage>1662</fpage>&#x02013;<lpage>70</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jcms.2017.07.006</pub-id>
<pub-id pub-id-type="pmid">28847623</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Ye</surname><given-names>H</given-names></name>, <name><surname>Lv</surname><given-names>L</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>. <article-title>Evaluation of the accuracy, reliability, and reproducibility of two different 3D face-scanning systems</article-title>. <source>Int J Prosthodont</source>. <year>2016</year>;<volume>29</volume>(<issue>3</issue>):<fpage>213</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.11607/ijp.4397</pub-id>
<pub-id pub-id-type="pmid">27148978</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>C</given-names></name>, <name><surname>Artopoulos</surname><given-names>A</given-names></name>. <article-title>Validation of a low-cost portable 3-dimensional face scanner</article-title>. <source>Imaging Sci Dent</source>. <year>2019</year>;<volume>49</volume>(<issue>1</issue>):<fpage>35</fpage>&#x02013;<lpage>43</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5624/isd.2019.49.1.35</pub-id>
<pub-id pub-id-type="pmid">30941286</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref041"><label>41</label><mixed-citation publication-type="journal"><name><surname>Koban</surname><given-names>KC</given-names></name>, <name><surname>Perko</surname><given-names>P</given-names></name>, <name><surname>Etzel</surname><given-names>L</given-names></name>, <name><surname>Li</surname><given-names>Z</given-names></name>, <name><surname>Schenck</surname><given-names>TL</given-names></name>, <name><surname>Giunta</surname><given-names>RE</given-names></name>. <article-title>Validation of two handheld devices against a non-portable three-dimensional surface scanner and assessment of potential use for intraoperative facial imaging</article-title>. <source>J Plast Reconstr Aesthet Surg</source>. <year>2020</year>;<volume>73</volume>(<issue>1</issue>):<fpage>141</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.bjps.2019.07.008</pub-id>
<pub-id pub-id-type="pmid">31519501</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Ross</surname><given-names>MT</given-names></name>, <name><surname>Cruz</surname><given-names>R</given-names></name>, <name><surname>Brooks-Richards</surname><given-names>TL</given-names></name>, <name><surname>Hafner</surname><given-names>LM</given-names></name>, <name><surname>Powell</surname><given-names>SK</given-names></name>, <name><surname>Woodruff</surname><given-names>MA</given-names></name>. <article-title>Comparison of three-dimensional surface scanning techniques for capturing the external ear</article-title>. <source>Virtual Phys Prototyping</source>. <year>2018</year>;<volume>13</volume>(<issue>4</issue>):<fpage>255</fpage>&#x02013;<lpage>65</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/17452759.2018.1493803</pub-id></mixed-citation></ref><ref id="pone.0322358.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Mai</surname><given-names>H-N</given-names></name>, <name><surname>Lee</surname><given-names>D-H</given-names></name>. <article-title>Accuracy of mobile device-compatible 3D scanners for facial digitization: systematic review and meta-analysis</article-title>. <source>J Med Internet Res</source>. <year>2020</year>;<volume>22</volume>(<issue>10</issue>):e22228. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/22228</pub-id>
<pub-id pub-id-type="pmid">33095178</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>K&#x000fc;hlman</surname><given-names>DC</given-names></name>, <name><surname>Almuzian</surname><given-names>M</given-names></name>, <name><surname>Coppini</surname><given-names>C</given-names></name>, <name><surname>Alzoubi</surname><given-names>EE</given-names></name>. <article-title>Accuracy (trueness and precision) of four tablet-based applications for three-dimensional facial scanning: an in-vitro study</article-title>. <source>J Dent</source>. <year>2023</year>;<volume>135</volume>:<fpage>104533</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jdent.2023.104533</pub-id>
<pub-id pub-id-type="pmid">37149254</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref045"><label>45</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>C</given-names></name>, <name><surname>Cai</surname><given-names>R</given-names></name>, <name><surname>Yao</surname><given-names>Y</given-names></name>, <name><surname>Zhao</surname><given-names>Z</given-names></name>, <name><surname>Liao</surname><given-names>W</given-names></name>. <article-title>Accuracy of 3-dimensional stereophotogrammetry: comparison of the 3dMD and Bellus3D facial scanning systems with one another and with direct anthropometry</article-title>. <source>Am J Orthod Dentofacial Orthop</source>. <year>2021</year>;<volume>160</volume>(<issue>6</issue>):<fpage>862</fpage>&#x02013;<lpage>71</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ajodo.2021.04.020</pub-id>
<pub-id pub-id-type="pmid">34814981</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Cascos</surname><given-names>R</given-names></name>, <name><surname>Ortiz Del Amo</surname><given-names>L</given-names></name>, <name><surname>&#x000c1;lvarez-Guzm&#x000e1;n</surname><given-names>F</given-names></name>, <name><surname>Antonaya-Mart&#x000ed;n</surname><given-names>JL</given-names></name>, <name><surname>Celem&#x000ed;n-Vi&#x000f1;uela</surname><given-names>A</given-names></name>, <name><surname>G&#x000f3;mez-Costa</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Accuracy between 2D photography and dual-structured light 3D facial scanner for facial anthropometry: a clinical study</article-title>. <source>J Clin Med</source>. <year>2023</year>;<volume>12</volume>(<issue>9</issue>):<fpage>3090</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/jcm12093090</pub-id>
<pub-id pub-id-type="pmid">37176531</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Michelinakis</surname><given-names>G</given-names></name>, <name><surname>Apostolakis</surname><given-names>D</given-names></name>, <name><surname>Velidakis</surname><given-names>E</given-names></name>. <article-title>An in vitro comparison of accuracy between three different face scanning modalities</article-title>. <source>Eur J Prosthodont Restor Dent</source>. <year>2023</year>;[Epub ahead of print].</mixed-citation></ref><ref id="pone.0322358.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Pellitteri</surname><given-names>F</given-names></name>, <name><surname>Scisciola</surname><given-names>F</given-names></name>, <name><surname>Cremonini</surname><given-names>F</given-names></name>, <name><surname>Baciliero</surname><given-names>M</given-names></name>, <name><surname>Lombardo</surname><given-names>L</given-names></name>. <article-title>Accuracy of 3D facial scans: a comparison of three different scanning system in an in vivo study</article-title>. <source>Prog Orthod</source>. <year>2023</year>;<volume>24</volume>(<issue>1</issue>):<fpage>44</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s40510-023-00496-x</pub-id>
<pub-id pub-id-type="pmid">38143253</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Franco de S&#x000e1; Gomes</surname><given-names>C</given-names></name>, <name><surname>Libdy</surname><given-names>MR</given-names></name>, <name><surname>Normando</surname><given-names>D</given-names></name>. <article-title>Scan time, reliability and accuracy of craniofacial measurements using a 3D light scanner</article-title>. <source>J Oral Biol Craniofac Res</source>. <year>2019</year>;<volume>9</volume>(<issue>4</issue>):<fpage>331</fpage>&#x02013;<lpage>5</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jobcr.2019.07.001</pub-id>
<pub-id pub-id-type="pmid">31388482</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Mai</surname><given-names>H-N</given-names></name>, <name><surname>Lee</surname><given-names>D-H</given-names></name>. <article-title>The effect of perioral scan and artificial skin markers on the accuracy of virtual dentofacial integration: stereophotogrammetry versus smartphone three-dimensional face-scanning</article-title>. <source>Int J Environ Res Public Health</source>. <year>2020</year>;<volume>18</volume>(<issue>1</issue>):<fpage>229</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/ijerph18010229</pub-id>
<pub-id pub-id-type="pmid">33396780</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Tsuchida</surname><given-names>Y</given-names></name>, <name><surname>Shiozawa</surname><given-names>M</given-names></name>, <name><surname>Handa</surname><given-names>K</given-names></name>, <name><surname>Takahashi</surname><given-names>H</given-names></name>, <name><surname>Nikawa</surname><given-names>H</given-names></name>. <article-title>Comparison of the accuracy of different handheld-type scanners in three-dimensional facial image recognition</article-title>. <source>J Prosthodont Res</source>. <year>2023</year>;<volume>67</volume>(<issue>2</issue>):<fpage>222</fpage>&#x02013;<lpage>30</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2186/jpr.JPR_D_22_00001</pub-id>
<pub-id pub-id-type="pmid">35768278</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Mora</surname><given-names>H</given-names></name>, <name><surname>Mora-Pascual</surname><given-names>JM</given-names></name>, <name><surname>Garc&#x000ed;a-Garc&#x000ed;a</surname><given-names>A</given-names></name>, <name><surname>Mart&#x000ed;nez-Gonz&#x000e1;lez</surname><given-names>P</given-names></name>. <article-title>Computational analysis of distance operators for the iterative closest point algorithm</article-title>. <source>PLoS One</source>. <year>2016</year>;<volume>11</volume>(<issue>10</issue>):e0164694. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0164694</pub-id>
<pub-id pub-id-type="pmid">27768714</pub-id>
</mixed-citation></ref><ref id="pone.0322358.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Revilla-Le&#x000f3;n</surname><given-names>M</given-names></name>, <name><surname>P&#x000e9;rez-Barquero</surname><given-names>JA</given-names></name>, <name><surname>Barmak</surname><given-names>BA</given-names></name>, <name><surname>Agust&#x000ed;n-Panadero</surname><given-names>R</given-names></name>, <name><surname>Fern&#x000e1;ndez-Estevan</surname><given-names>L</given-names></name>, <name><surname>Att</surname><given-names>W</given-names></name>. <article-title>Facial scanning accuracy depending on the alignment algorithm and digitized surface area location: an in vitro study</article-title>. <source>J Dent</source>. <year>2021</year>;<volume>110</volume>:<fpage>103680</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jdent.2021.103680</pub-id>
<pub-id pub-id-type="pmid">33901605</pub-id>
</mixed-citation></ref></ref-list></back><sub-article article-type="author-comment" id="pone.0322358.r001" specific-use="rebutted-decision-letter-unavailable"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0322358.r001</article-id><title-group><article-title>Author response to Decision Letter 0</article-title></title-group><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">30 Oct 2024</named-content>
</p></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0322358.r002" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0322358.r002</article-id><title-group><article-title>Decision Letter 0</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Abdullah</surname><given-names>Johari Yap</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2025 Johari Yap Abdullah</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Johari Yap Abdullah</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0322358" id="rel-obj002" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">21 Jan 2025</named-content>
</p><p>PONE-D-24-47635THE ACCURACY OF THREE-DIMENSIONAL FACIAL SCAN OBTAINED FROM</p><p>THREE DIFFERENT 3D SCANNERS.PLOS ONE</p><p>Dear Dr. Raocharernporn ,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#x02019;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by Mar 07 2025 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#x000a0;<email>plosone@plos.org</email> . When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:</p><p><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list>
</p><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link> . Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols</ext-link> .</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Johari Yap Abdullah, B.S. &#x00026; I.T, GradDip ICT, M.Sc, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>
<bold>Journal requirements:</bold>
</p><p>1. When submitting your revision, we need you to address these additional requirements.</p><p>Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at&#x000a0;</p><p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and&#x000a0;</p><p>
<ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
</p><p>2. We note that Figures 1 and S1 includes an image of participant in the study.&#x000a0;</p><p>As per the PLOS ONE policy (<ext-link xlink:href="http://journals.plos.org/plosone/s/submission-guidelines#loc-human-subjects-research)" ext-link-type="uri">http://journals.plos.org/plosone/s/submission-guidelines#loc-human-subjects-research</ext-link>) on papers that include identifying, or potentially identifying, information, the individual(s) or parent(s)/guardian(s) must be informed of the terms of the PLOS open-access (CC-BY) license and provide specific permission for publication of these details under the terms of this license. Please download the Consent Form for Publication in a PLOS Journal (<ext-link xlink:href="http://journals.plos.org/plosone/s/file?id=8ce6/plos-consent-form-english.pdf)." ext-link-type="uri">http://journals.plos.org/plosone/s/file?id=8ce6/plos-consent-form-english.pdf</ext-link>). The signed consent form should not be submitted with the manuscript, but should be securely filed in the individual's case notes. Please amend the methods section and ethics statement of the manuscript to explicitly state that the patient/participant has provided consent for publication: &#x0201c;The individual in this manuscript has given written informed consent (as outlined in PLOS consent form) to publish these case details&#x0201d;.&#x000a0;</p><p>If you are unable to obtain consent from the subject of the photograph, you will need to remove the figure and any other textual identifying information or case descriptions for this individual.</p><p>3. Your ethics statement should only appear in the Methods section of your manuscript. If your ethics statement is written in any section besides the Methods, please delete it from any other section.&#x000a0;</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<bold>Comments to the Author</bold>
</p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p><p>Reviewer #1:&#x000a0;Partly</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>2. Has the statistical analysis been performed appropriately and rigorously? </p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.</p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>5. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p><p><bold>Reviewer #1:&#x000a0;</bold> This study compared the accuracy, precision, and reproducibility of three 3D facial scanning systems: Planmeca Proface (laser scanner), EinScan H2 (structured light scanner), and EM3D Scanner (smartphone app). Thirty subjects with skeletal deformities were scanned, and results were compared to CBCT-derived facial surfaces. The EM3D Scanner outperformed the EinScan H2 in accuracy, particularly for the overall face, while the Planmeca Proface showed high accuracy in the nasal and perioral regions. Overall, most scans were reproducible, with deviations under 1 mm, making the EM3D Scanner and Planmeca Proface suitable for clinical use.</p><p>The article seems to be well presented, but some shortcomings can be identified.</p><p>Comments to the Author:</p><p>&#x02022; Citing references in the text of the manuscript does not meet the journal's requirements.</p><p>&#x02022; Then describing &#x0201c;experimental instruments&#x0201d;, you need to indicate what iPhone/iPad model you used with EM3D Scanner app directly in corresponding section</p><p>&#x02022; There is no data provided about the scanned surfaces in STL format: number of edges, vertices. It is important then comparing scans of different scanners.</p><p>&#x02022; I think, it is no reason to present RMS calculation formula if it was calculated by Geomagic X, not by you</p><p>&#x02022; Intraexaminer reliability was assessed only with CBCT segmentation. 3D scanning quality is more dependent on the operator &#x02013; why not to assess this iterexaminer reliability?</p><p>&#x02022; Statistical analysis description could be more precise, clearer describing what analysis was used for what data (maybe separating by new sections).</p><p>&#x02022; There are two same tables: Table 4 on pages 18 and 19.</p><p>&#x02022; What are the meanings of superscripts a,b in Tables 4 to 6?</p><p>&#x02022; Graphical representation of acquired/calculated data would be very useful &#x02013; frequently it is more informative to the reader than just tables with numbers.</p><p>&#x02022; Question about &#x0201c;marker stickers&#x0201d; &#x02013; we can see on figures, what they are visible on reference 3D surfaces, but not on scanners surfaces (as you mention on page 30). From the images presented we can see that they are elevated or recessed and so they have impact on the data statistics. Could you comment on this?</p><p>&#x02022; Language of the manuscript should be clearer, more concise and with no errors &#x02013; moderate English language editing is needed.</p><p>&#x02022; On page 13: &#x0201c;Two groups were generated, namely, the best-fit algorithm, which automatically determined the best-fit alignment by means of pre-established reference points.&#x0201d; &#x02013; it is not clear about &#x0201c;two groups&#x0201d;.</p><p>&#x02022; On page 14: &#x0201c;Furthermore, the following percentage of overlapping surfaces within the tolerance ranges was determined by the software: &#x0003c;&#x02026;&#x0003e;&#x0201d; &#x02013; then authors present the ranges of distances for reproducibility assessment, but from the sentence you expect &#x0201c;percentages&#x0201d;.</p><p>&#x02022; &#x0201c;grater trueness&#x0201d; on page 24 should be changed to &#x0201c;grater trueness value&#x0201d;. Also, please clarify on page 29 &#x0201c;higher trueness compared&#x0201d;.</p><p>&#x02022; &#x0201c;The PLOS Data policy requires authors to make all data underlying the findings described in their manuscript fully available without restriction &#x0003c;...&#x0003e;&#x0201d;. The full data used in the manuscript is not available directly &#x02013; only &#x0201c;upon reasonable request&#x0201d;.</p><p><bold>Reviewer #2:&#x000a0;</bold> The study compares the scanning accuracy of three different facial scanning devices using 30 subjects and holds clinical significance. However, there are several issues that require discussion with the authors:</p><p>1. Please supplement information on whether the scanning data were collected in a closed environment and whether the light source intensity was consistent during the scanning process for each device.</p><p>2. There is an error in the description of the results section: "the Einscan H2 obtained&#x02026;0.85 &#x000b1; 0.8 mm" should be corrected.</p><p>3. Table 4 appears duplicate in the manuscript.</p><p>4. The experimental results of this study indicate variations in scanning accuracy across different facial regions. How can the authors demonstrate that these differences in scanning accuracy are not caused by micro-movements of facial muscles?</p><p>5. Although the authors have mentioned various mesh data registration methods in the discussion, they have not clearly explained why the best-fit registration method was chosen. In fact, this registration method is not the most ideal, and the literature has mentioned registration methods based on the extraoral scan body (ESB). Please provide a comparison of these methods.</p><p>**********</p><p>6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link> ). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link> .</p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#x000a0;<ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link> . PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#x000a0;<email>figures@plos.org</email> . Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0322358.r003"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0322358.r003</article-id><title-group><article-title>Author response to Decision Letter 1</article-title></title-group><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0322358" id="rel-obj003" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">13 Feb 2025</named-content>
</p><p>We have made every effort to address all the comments and suggestions provided by both the Editor and Reviewers. These revisions are detailed in the attached file titled "Response to Reviewers," organized by each specific point raised.</p><p>If there are any remaining issues or misunderstandings regarding certain points that require further clarification or correction, please feel free to contact us, and we will promptly make the necessary adjustments.</p><p>We sincerely appreciate your consideration and acceptance of our research.</p><supplementary-material id="pone.0322358.s004" position="float" content-type="local-data"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers.docx</named-content></p></caption><media xlink:href="pone.0322358.s004.docx"/></supplementary-material></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0322358.r004" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0322358.r004</article-id><title-group><article-title>Decision Letter 1</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Abdullah</surname><given-names>Johari Yap</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2025 Johari Yap Abdullah</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Johari Yap Abdullah</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0322358" id="rel-obj004" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">27 Feb 2025</named-content>
</p><p>PONE-D-24-47635R1THE ACCURACY OF THREE-DIMENSIONAL FACIAL SCAN OBTAINED FROM THREE DIFFERENT 3D SCANNERS.PLOS ONE</p><p>Dear Dr. Raocharernporn ,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#x02019;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by Apr 13 2025 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#x000a0;<email>plosone@plos.org</email> . When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:</p><p><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list>
</p><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link> . Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols</ext-link> .</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Johari Yap Abdullah, B.S. &#x00026; I.T, GradDip ICT, M.Sc, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal Requirements:</p><p>Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article&#x02019;s retracted status in the References list and also include a citation and full reference for the retraction notice.</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<bold>Comments to the Author</bold>
</p><p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#x0201c;Comments to the Author&#x0201d; section, enter your conflict of interest statement in the &#x0201c;Confidential to Editor&#x0201d; section, and submit your "Accept" recommendation.</p><p>Reviewer #1:&#x000a0;All comments have been addressed</p><p>Reviewer #2:&#x000a0;All comments have been addressed</p><p>**********</p><p>2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p><p>Reviewer #1:&#x000a0;(No Response)</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>3. Has the statistical analysis been performed appropriately and rigorously? </p><p>Reviewer #1:&#x000a0;(No Response)</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>4. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.</p><p>Reviewer #1:&#x000a0;(No Response)</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p>6. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p><p>Reviewer #1:&#x000a0;I think the English still needs editing.</p><p>Also check formatting then you are citing publications, as example: "sensitivity sensors. [22,25]" -&#x0003e; sensitivity sensors [22,25]." - see examples of previously published articles.</p><p>Reviewer #2:&#x000a0;(No Response)</p><p>**********</p><p>7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link> ). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link> .</p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#x000a0;<ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link> . PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#x000a0;<email>figures@plos.org</email> . Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0322358.r005"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0322358.r005</article-id><title-group><article-title>Author response to Decision Letter 2</article-title></title-group><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0322358" id="rel-obj005" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>2</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">4 Mar 2025</named-content>
</p><p>We extend our sincere gratitude to Reviewer #1 for dedicating their time to thoroughly reviewing our research and offering insightful suggestions to enhance the quality of the manuscript.</p><p>We have thoroughly reviewed and corrected the grammar and language in the manuscript to ensure clarity and accuracy. Additionally, we have revised and improved the formatting of cited publications in accordance with your recommendations.</p><supplementary-material id="pone.0322358.s005" position="float" content-type="local-data"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers (minor revision).docx</named-content></p></caption><media xlink:href="pone.0322358.s005.docx"/></supplementary-material></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0322358.r006" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0322358.r006</article-id><title-group><article-title>Decision Letter 2</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Abdullah</surname><given-names>Johari Yap</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2025 Johari Yap Abdullah</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Johari Yap Abdullah</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0322358" id="rel-obj006" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>2</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">21 Mar 2025</named-content>
</p><p>THE ACCURACY OF THREE-DIMENSIONAL FACIAL SCAN OBTAINED FROM</p><p>THREE DIFFERENT 3D SCANNERS.</p><p>PONE-D-24-47635R2</p><p>Dear Dr. Raocharernporn ,</p><p>We&#x02019;re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p><p>Within one week, you&#x02019;ll receive an e-mail detailing the required amendments. When these have been addressed, you&#x02019;ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p><p>An invoice will be generated when your article is formally accepted. Please note, if your institution has a publishing partnership with PLOS and your article meets the relevant criteria, all or part of your publication costs will be covered. Please make sure your user information is up-to-date by logging into Editorial Manager at <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">Editorial Manager&#x000ae;</ext-link> &#x000a0;and clicking the &#x02018;Update My Information' link at the top of the page. If you have any questions relating to publication charges, please contact our Author Billing department directly at authorbilling@plos.org.</p><p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they&#x02019;ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.</p><p>Kind regards,</p><p>Johari Yap Abdullah, B.S. &#x00026; I.T, GradDip ICT, M.Sc, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Additional Editor Comments (optional):</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<bold>Comments to the Author</bold>
</p><p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#x0201c;Comments to the Author&#x0201d; section, enter your conflict of interest statement in the &#x0201c;Confidential to Editor&#x0201d; section, and submit your "Accept" recommendation.</p><p>Reviewer #1:&#x000a0;All comments have been addressed</p><p>**********</p><p>2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p><p>Reviewer #1:&#x000a0;Yes</p><p>**********</p><p>3. Has the statistical analysis been performed appropriately and rigorously? </p><p>Reviewer #1:&#x000a0;Yes</p><p>**********</p><p>4. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.</p><p>Reviewer #1:&#x000a0;Yes</p><p>**********</p><p>5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p><p>Reviewer #1:&#x000a0;Yes</p><p>**********</p><p>6. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p><p>Reviewer #1:&#x000a0;(No Response)</p><p>**********</p><p>7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link> ). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link> .</p><p>Reviewer #1:&#x000a0;No</p><p>**********</p></body></sub-article><sub-article article-type="editor-report" id="pone.0322358.r007" specific-use="acceptance-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0322358.r007</article-id><title-group><article-title>Acceptance letter</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Abdullah</surname><given-names>Johari Yap</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2025 Johari Yap Abdullah</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Johari Yap Abdullah</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0322358" id="rel-obj007" related-article-type="reviewed-article"/></front-stub><body><p>PONE-D-24-47635R2</p><p>PLOS ONE</p><p>Dear Dr. Raocharernporn ,</p><p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now being handed over to our production team.</p><p>At this stage, our production department will prepare your paper for publication. This includes ensuring the following:</p><p>* All references, tables, and figures are properly cited</p><p>* All relevant supporting information is included in the manuscript submission,</p><p>* There are no issues that prevent the paper from being properly typeset</p><p>You will receive further&#x000a0;instructions from the production team, including instructions on how to review your proof when it&#x000a0;is ready. Please keep in mind that we are working through a large volume of accepted articles, so please give us a few days to review your paper and let you know the next and final steps.</p><p>Lastly, if your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact onepress@plos.org.</p><p>If we can help with anything else, please email us at customercare@plos.org.</p><p>Thank you for submitting your work to PLOS ONE and supporting open access.</p><p>Kind regards,</p><p>PLOS ONE Editorial Office Staff</p><p>on behalf of</p><p>Dr. Johari Yap Abdullah</p><p>Academic Editor</p><p>PLOS ONE</p></body></sub-article></article>