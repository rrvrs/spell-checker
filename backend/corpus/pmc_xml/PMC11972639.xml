<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Med Oral Patol Oral Cir Bucal</journal-id><journal-id journal-id-type="iso-abbrev">Med Oral Patol Oral Cir Bucal</journal-id><journal-id journal-id-type="publisher-id">Medicina Oral S.L.</journal-id><journal-title-group><journal-title>Medicina Oral, Patolog&#x000ed;a Oral y Cirug&#x000ed;a Bucal</journal-title></journal-title-group><issn pub-type="ppub">1698-4447</issn><issn pub-type="epub">1698-6946</issn><publisher><publisher-name>Medicina Oral S.L.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39864088</article-id><article-id pub-id-type="pmc">PMC11972639</article-id>
<article-id pub-id-type="publisher-id">26824</article-id><article-id pub-id-type="doi">10.4317/medoral.26824</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject><subj-group><subject>Oral Cancer and Potentially malignant disorders</subject></subj-group></subj-group></article-categories><title-group><article-title>Accuracy of ChatGPT 3.5, 4.0, 4o and Gemini in diagnosing oral potentially malignant lesions based on clinical case reports and image recognition</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Pradhan</surname><given-names>Pragya</given-names></name><xref rid="A1" ref-type="aff">1</xref></contrib></contrib-group><aff id="A1"><label>1</label>MDS, Public Health Dentistry, Department of Dentistry, District Hospital, Madhya Pradesh, India</aff><author-notes><corresp> 15, Trauma Centre, District Hospital Neemuch
Madhya Pradesh - 458441, India
, E-mail: <email>pragya.pradhan@yahoo.co.in</email></corresp></author-notes><pub-date pub-type="ppub"><month>3</month><year>2025</year></pub-date><pub-date pub-type="epub"><day>26</day><month>1</month><year>2025</year></pub-date><volume>30</volume><issue>2</issue><fpage>e224</fpage><lpage>e231</lpage><history><date date-type="accepted"><day>30</day><month>12</month><year>2024</year></date><date date-type="received"><day>23</day><month>7</month><year>2024</year></date></history><permissions><copyright-statement>Copyright: &#x000a9; 2025 Medicina Oral S.L.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/2.5/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><sec><title>Background </title><p> The accurate and timely diagnosis of oral potentially malignant lesions (OPMLs) is crucial for effective management and prevention of oral cancer. Recent advancements in artificial intelligence technologies indicates its potential to assist in clinical decision-making. Hence, this study was carried out with the aim to evaluate and compare the diagnostic accuracy of ChatGPT 3.5, 4.0, 4o and Gemini in identifying OPMLs.</p></sec><sec><title>Material and Methods </title><p> The analysis was carried out using 42 case reports from PubMed, Scopus and Google Scholar and images from two datasets, corresponding to different OPMLs. The reports were inputted separately for text description-based diagnosis in GPT 3.5, 4.0, 4o and Gemini, and for image recognition-based diagnosis in GPT 4o and Gemini. Two subject-matter experts independently reviewed the reports and offered their evaluations.</p></sec><sec><title>Results </title><p> For text-based diagnosis, among LLMs, GPT 4o got the maximum number of correct responses (27/42), followed by GPT 4.0 (20/42), GPT 3.5 (18/42) and Gemini (15/42). In identifying OPMLs based on image, GPT 4o demonstrated better performance than Gemini. There was fair to moderate agreement found between Large Language Models (LLMs) and subject experts. None of the LLMs matched the accuracy of the subject experts in identifying the correct number of lesions.</p></sec><sec><title>Conclusions </title><p> The results point towards cautious optimism with respect to commonly used LLMs in diagnosing OPMLs. While their potential in diagnostic applications is undeniable, their integration should be approached judiciously.</p><p><bold> Key words:</bold>Oral premalignant lesions, oral diagnosis, natural language processing, mouth neoplasm, computer-assisted diagnosis.</p></sec></abstract></article-meta></front><body><sec><title>Introduction</title><p>When the renowned mathematician and computer scientist Alan Turing posed the question, "Can machines think?", it marked the beginning of Artificial Intelligence (AI) as a field dedicated to understanding human-like intelligence and attempting to replicate it. In November 2022, the field of AI achieved a milestone with the launch of Chat Generative Pre-Trained Transformer (ChatGPT) by OpenAI. OpenAI is an American AI research organization primarily focused on building generative models using deep learning technology. Shortly after, Google launched Bard in March 2023, which was later transitioned to Gemini in December 2023. Both, ChatGPT and Gemini, are essentially chatbot technology with the ability to process natural human language and generate coherent and contextually suiTable response. The models are pre-trained on large amount of textual data which is then used for targeted applications such as text classification and question-answering. In the pre-training phase, models are trained on language modelling task, which involves predicting the next word in a text sequence based on the previous words in the sequence (<xref rid="B1" ref-type="bibr">1</xref>).</p><p>The efforts to integrate Natural Language Processing (NLP) with healthcare is not new and has seen an increase in research over the past 20 years (<xref rid="B2" ref-type="bibr">2</xref>). NLP techniques have been shown to manage medical information overload, while also assisting in medical decision making by examining the similarities and differences within vast amounts of text data. Yet, the launch of ChatGPT, a result of NLP advancements, managed to catch the eyes of the world due to its browser based, user-friendly interface, which facilitates easy interaction with the language-based learning model, regardless of technical expertise (<xref rid="B3" ref-type="bibr">3</xref>). Its multifaceted role in healthcare practise and research includes, but is not limited to, gathering, analysing and interpretating data, writing and editing scientific literature, as an aid in medical teaching, patient education, streamlining clinical workflow, and assisting in diagnosis and treatment planning (<xref rid="B4" ref-type="bibr">4</xref>). The advantages associated with the tasks includes accessibility, efficiency, improved communication, language assistance and reduced cost (<xref rid="B5" ref-type="bibr">5</xref>). However, its handling have concerns in the scientific community regarding limited knowledge, risk of bias, plagiarism, lack of originality and ethical issues (<xref rid="B5" ref-type="bibr">5</xref>). In addition, ChatGPT lacks critical thinking and reasoning, hence, often produces incorrect information with factual inconsistencies, a phenomenon known as hallucination. With the possible advantages and disadvantages, the various uses of ChatGPT are currently under scientific scrutiny and lacks a general consensus (<xref rid="B6" ref-type="bibr">6</xref>).</p><p>Artificial intelligence encompasses a variety of technologies, including machine learning. The most advanced form of machine learning is deep learning, which utilizes multiple layers of variables to predict outcomes. Clinical decisions are often guided by the clinician&#x02019;s expertise; however, the constant expansion of study material and emergence of complex cases calls for improved diagnostics. In healthcare, deep learning is commonly applied to enhance diagnostic accuracy and support precision medicine. Large Language Models (LLMs) like ChatGPT and Gemini, which are based on deep learning, has demonstrated its utility as a supplementary tool for clinical decision-making in both straightforward cases and complex clinical vignettes (<xref rid="B7" ref-type="bibr">7</xref>). A major concern worldwide is the increase in incidence of oral cancer. Multiple factors including prognosis, morbidity and mortality associated with oral cancer hinges upon its early diagnosis at the pre-malignancy stage of the lesion (<xref rid="B8" ref-type="bibr">8</xref>). These lesions carry a malignancy risk, with transformation rates varying between 13% and 90% (<xref rid="B9" ref-type="bibr">9</xref>). A significant challenge associated with prompt detection is diagnostically challenging nature of Oral Potentially malignant Lesions (OPMLs) and our limited understanding to distinguish high-risk OPMLs from low-risk lesions (<xref rid="B10" ref-type="bibr">10</xref>). Moreover, a definitive diagnosis of OPMLs requires biopsy, which some practitioners might be hesitant to undertake due to methodological obscurity, lack of training and limited knowledge of OPMLs (<xref rid="B11" ref-type="bibr">11</xref>,<xref rid="B12" ref-type="bibr">12</xref>). Various OPMLs also present with overlapping clinical features (<xref rid="B9" ref-type="bibr">9</xref>). Additionally, the prospect of a biopsy may provoke anxiety and discomfort among patients (<xref rid="B13" ref-type="bibr">13</xref>). Therefore, it is imperative to explore the potential of ChatGPT as an adjunct in clinical decision-making. Previous studies have reported inconsistencies in ChatGPT&#x02019;s response with general guidelines and consensus regarding knowledge, diagnosis and risk factors associated with OPMLs (<xref rid="B14" ref-type="bibr">14</xref>). Nonetheless, ChatGPT has shown to be an effective resource for providing patients with information on the early identification of oral cancer (<xref rid="B15" ref-type="bibr">15</xref>). The author observed a gap in literature regarding assessing the accuracy of LLMs such as ChatGPT and Gemini in diagnosing OPMLs based on clinical case reports. Hence, this study was performed with the aim to assess the accuracy of ChatGPT 3.5, 4.0, 4 Omni (4o) and Gemini in diagnosing OPMLs based on Clinical Case Reports. In addition, ChatGPT 4o and Gemini is also evaluated on its diagnostic abilities based on image recognition.</p></sec><sec><title>Material and Methods</title><p>- Search Strategy</p><p>A list of Oral Potentially Malignant Lesions was prepared following the classification by Warnakulasuriya S <italic>et al</italic>. (<xref rid="B16" ref-type="bibr">16</xref>). A comprehensive search was carried out in PubMed, Scopus and Google Scholar for published reports of cases corresponding to the classification. The reports were screened for their relevance to the classification and included only if they met the following conditions: they contained a detailed patient history, symptoms, examination findings, and a confirmed diagnosis through standard procedures; they provided a clinical description of the lesion that matched the images available in the database; they were primarily open access to ensure fair use in research, though subscription-based articles were included when highly relevant; and they were written in English. Additionally, reports were selected to represent a diverse range of demographics and geographic locations. A total of 42 case reports were selected for final analysis, which included 34 OPMLs and 8 Oral Squamous Cell Carcinoma (OSCC) case reports to allow for direct comparison between malignant and premalignant stages. Of the 34 OPMLs reports, there were 4 cases each of Oral Leukoplakia, case reports of variants of Oral Lichenoid Lesions (OLL) and Oral Lupus Erythematosus (OLE) among others. The four variants of Oral Lichen Planus (OLP) were included based on their most common occurrence.</p><p>- Image Recognition Case Reports</p><p>In addition to testing the abilities of GPT 3.5, 4.0, 4o and Gemini based on text recognition, the recently launched GPT 4o and Gemini were also assessed for their abilities to diagnose cases based on a combination of text and image. Publicly available collection of OPMLs photos (https://opmdcare.com/atlas-photos/) and OSCC photos (https://oralcancerfoundation.org/dental/oral-cancer-images/) were accessed in June 2024. The images were selected corresponding to the case reports. Additionally, images for following conditions, namely, Papular OLP, Oral Lichenoid Drug Reaction, Discoid Lupus Erythematosus, Systemic Lupus Erythematosus, Dyskeratosis Congenita, OSCC of Gingiva, and Verrucous Carcinoma were sourced from open access case reports.</p><p>- Reports Preparation</p><p>The case reports were anatomized and only the history section was included for input in different LLMs. The case description included information on the patient&#x02019;s demographics, chief complaint, history of presenting illness, any medical/dental/drug history, personal history such as tobacco usage, description of clinical lesion, any associated symptoms and histopathological findings. The case reports used for image analysis were parsed to match with the lesion characteristics and its location in the image. The reports were entered into ChatGPT and Gemini text box with the additional prompt: &#x0201c;Based on the above description, what is the most likely diagnosis?&#x0201d; For image recognition cases, the case reports were followed by the prompt &#x0201c;Based on the above image and case description, what is the most likely diagnosis?&#x0201d;</p><p>In order to overcome the memory retention bias and also the possible reinforcement learning from human feedback (RLHF) capabilities demonstrated by LLMs, each question was processed in a new chat session. During the course of this study, OpenAI launched memory feature in ChatGPT, which allowed GPT to remember information. However, this feature was turned off to prevent any additional learning by GPT. The case reports and images were also submitted to two Subject Experts (SEs) for their evaluation. The accuracy of the provisional diagnosis was calculated by categorizing the responses into &#x02018;correct&#x02019;, &#x02018;partially correct', and &#x02018;incorrect. The study did not require ethical approval as per the local Institutional Review Board (IRB), but it still adhered to ethical considerations relevant to the handling of data and use of secondary information.</p><p>- Statistical Analysis</p><p>The data was entered into Microsoft Excel and analysed using SPSS Version 25 (IBM Corp., Armonk, New York, United States). Categorical data was analysed by Friedman&#x02019;s Test to detect differences in rankings across multiple groups. It was followed with pairwise comparison by Dunn&#x02019;s Post-hoc adjusted for Bonferroni correction for multiple tests. The data was also assessed for interrater agreement measured by Cohen&#x02019;s kappa (&#x003ba;).</p></sec><sec><title>Results</title><p>Fig. <xref rid="F1" ref-type="fig">1</xref> shows the provisional diagnoses from four LLMs and two SEs, using a heatmap based on text descriptions from case reports.</p><p>
<fig position="float" id="F1"><label>Figure 1</label><caption><p>Provisional diagnosis by ChatGPT 3.5, 4.0, 4o, Gemini, Subject Expert 1 and 2 based on text description of case reports.</p></caption><graphic xlink:href="medoral-30-e224-g001" position="float"/></fig>
</p><p>The frequency distribution of responses indicates that GPT 4o aligns most closely with the subject experts in accurately identifying OPMLs, followed by GPT 4.0 and GPT 3.5. Google&#x02019;s Gemini recorded the fewest correct diagnoses. It also recorded the highest number of incorrect diagnoses along with GPT 3.5. Furthermore, Gemini's responses demonstrated a statistically significant difference from those of subject experts 1 &#x00026; 2 (<italic>p</italic>&#x0003c;0.05). There was also some overlap between GPT 3.5 and 4o in terms of partially correct responses. Both subject experts had a similar number of incorrect responses. (Fig. <xref rid="F2" ref-type="fig">2</xref>).</p><p>
<fig position="float" id="F2"><label>Figure 2</label><caption><p>Distribution of responses by ChatGPT 3.5, 4.0, 4o, Gemini, Subject Expert 1 and 2 to text description of case reports.</p></caption><graphic xlink:href="medoral-30-e224-g002" position="float"/></fig>
</p><p>Fig. <xref rid="F3" ref-type="fig">3</xref> shows scenarios involving image recognition in which GPT 4o accurately identified 28 out of 42 cases (66.6%), while Gemini correctly identified 19 out of 42 cases (45.2%). GPT 4o made incorrect recognitions in 6 out of 42 cases (14.2%), compared to Gemini, which incorrectly identified 14 out of 42 cases (33.3%). (Fig. <xref rid="F4" ref-type="fig">4</xref>) Multiple group response comparison revealed statistically significant differences in response between Gemini and Subject Expert 1 and 2 (<italic>p</italic>&#x0003c;0.05).</p><p>The data was further analysed to evaluate the agreement between the LLMs and human experts by calculating Cohen&#x02019;s kappa (&#x003ba;). The results indicated a substantial agreement between GPT 4o and SE2 (&#x003ba; = 0.659) and moderate agreement between GPT 4o and SE1 (&#x003ba; = 0.543) and GPT 4.0 and SE1 (&#x003ba; = 0.468). The results also showed fair agreement between GPT 3.5 and SE1 (&#x003ba; = 0.365) and SE2 (&#x003ba; = 0.333) and between GPT 4.0 and SE2 (&#x003ba; = 0.350). There was a fair level of agreement between Gemini and SE1 (&#x003ba; = 0.326) and a moderate level of agreement between Gemini and SE2 (&#x003ba; = 0.413). For image recognition, there was moderate agreement between GPT 4o and SE2 (&#x003ba; = 0.514), while there was fair agreement between GPT 4o and SE1 (&#x003ba; = 0.396), Gemini and SE 1 (&#x003ba; = 0.265) and SE2 (&#x003ba; = 0.245). All the kappa values were statistically significant at <italic>p</italic>&#x0003c;0.05. (<xref rid="T1" ref-type="table">Table 1</xref>).</p><p>
<fig position="float" id="F3"><label>Figure 3</label><caption><p>Provisional diagnosis by ChatGPT 4o, Gemini, Subject Expert 1 and 2 based on text description and image recognition.</p></caption><graphic xlink:href="medoral-30-e224-g003" position="float"/></fig>
</p><p>
<fig position="float" id="F4"><label>Figure 4</label><caption><p>Distribution of responses by ChatGPT 4o, Gemini, Subject Expert 1 and 2 to text description and image recognition of case reports.</p></caption><graphic xlink:href="medoral-30-e224-g004" position="float"/></fig>
</p></sec><sec><title>Discussion</title><p>A widely prevalent form of contemporary artificial intelligence is deep learning, which uses multi-layered deep neural networks to simulate the complex decision-making capabilities of the human brain. The core architecture of Conversational AI is based on the Transformer model which facilitated the development of advanced Large Language Models (LLMs) such as OpenAI&#x02019;s ChatGPT 3.5, 4.0 and 4o as well as Google&#x02019;s Gemini. Since their launch, AI chatbots have advanced substantially, evolving from simple scripts to complex conversational systems. Recent studies have shown that ChatGPT exhibited significant accuracy and remarkable competency in the Medical Licensing Exams of countries such as USA, Peru, Saudi Arabia and Germany (<xref rid="B17" ref-type="bibr">17</xref>). In addition to medical knowledge enquiries, LLMs have shown high diagnostic accuracy in predicting medical scenarios. However, it is not without reliability concerns. Even though arriving at a diagnosis is a complex process and requires analysing vast amount of patient&#x02019;s history, medical history and laboratory test results, ChatGPT has demonstrated high accuracy in diagnosing both basic and complex cases requiring specialized knowledge (<xref rid="B7" ref-type="bibr">7</xref>).</p><p>In the present study, various models of LLMs were compared in diagnosing OPMLs based on clinical case reports and image recognition. Using only the text description, Subject Expert 1 and Subject Expert 2 achieved 73.8% (31/42) and 71.4% (30/42) correct responses, respectively, while ChatGPT 4o correctly identified 64.2% (27/42) of the lesions. This was followed by ChatGPT 4.0 which got 47.6% (20/42) responses correct and ChatGPT 3.5 which correctly identified 42.8% (18/42) of the cases. Among LLMs, Gemini got 35.7% (15/42) correct responses. Furthermore, improvement in accuracy of both GPT 4o and Gemini was observed when images were also inputted along with case description. GPT 4o correctly identified 66.6% (28/42) of the cases whereas Gemini had 45.2% (19/42) correct responses. Improvement in recognizing cases of Proliferative Verrucous Leukoplakia (PVL), Palatal Keratosis with Reverse Smoking and OSCC of tongue was found with GPT 4o. While Gemini showed some improvements in correctly identifying Non-Homogenous Leukoplakia, Erythroplakia and OSCC of Gingiva when provided with an image. The inclusion of images provided critical visual information that enhanced accuracy. In text-only descriptions, GPT 4o&#x02019;s diagnoses, although incorrect, were closer to the differential diagnosis compared to other models (<xref rid="B18" ref-type="bibr">18</xref>).</p><p>The categorization of responses was not dichotomous; instead, it included a third category of 'partially correct.' This approach allowed for a more nuanced evaluation of the performance of LLMs by including those diagnoses that captured essential elements of the correct response but may have missed certain details. In the present study, responses were categorized as partially correct if the lesions were not accurately identified along with their subtypes or if they were identified as OSCC, considering Verrucous Carcinoma is a low-grade variant of OSCC (<xref rid="B19" ref-type="bibr">19</xref>). Interestingly, based on text description, both GPT 3.5 and GPT 4o recorded partially correct responses for 16.6% (7/42) of cases, whereas GPT 4.0 had 28.5% (12/42) and Gemini had 23.8% (10/42) of responses classified as partially correct. These responses predominantly involved cases of Oral Lichen Planus and Oral Lichenoid Lesion, where the models accurately identified the lesion but failed to specify its subtypes. This could be because the variants are often intermingled with respect to their characteristic features and presenting symptoms (<xref rid="B20" ref-type="bibr">20</xref>). Compared to the LLM models, the SEs accurately identified the lesions and their subtypes, only partially misidentifying variants of OLP from text descriptions. However, when presented with images, the SEs corrected their diagnoses, while both GPT 4o and Gemini either partially identified the lesion or got the diagnosis incorrect.</p><p>LLMs like GPT and its variants are designed using intricate architectures that process vast amounts of data through Non-Supervised Pre-Training. The high number of parameters that they are trained on (GPT 3 with 175 billion, GPT 4 with significantly more, Gemini; Not known) contributes to the model's ability to understand the pattern better (<xref rid="B21" ref-type="bibr">21</xref>). While GPT 3.5 operates on a fixed dataset with a training cut-off in 2021, both ChatGPT 4.0 and 4o include data up to December 2023. In contrast, Gemini has the capability to access real-time internet data. In the present study, 76.1% (32/42) case reports were pre 2021 and 23.8% (10/42) were published after 2021. Among these, 38 case reports were accessed through open access sources, and four required subscription access. It is noteworthy that Gemini and GPT 3.5 had the highest number of incorrect diagnoses, followed by GPT-4.0, and GPT-4o. The progression from GPT-3.5 to GPT-4o includes improvements in the underlying algorithms, leading to a better understanding of medical information, which is evident in the results. In contrast, Gemini&#x02019;s access to real-time internet data can introduce a high amount of unverified or conflicting information, thereby increasing the likelihood of incorrect diagnoses. Similar findings were reported in a study by Shukla R. <italic>et al</italic>. (<xref rid="B22" ref-type="bibr">22</xref>) on neuro-ophthalmology cases. It is also important to point that none of the LLMs correctly identified OPMLs part of systemic dysfunction such as Discoid Lupus Erythematosus. Additionally, although all LLMs correctly diagnosed Homogeneous Leukoplakia, only GPT 4.0 and GPT 4o accurately identified cases of Non-Homogeneous Leukoplakia.</p><p>The expansion of AI into healthcare has garnered a range of responses from medical professionals. Concerns include inadequate knowledge of AI and fear of replacement and displacement. There is also reluctance to incorporate AI into clinical practice, coupled with skepticism about the system's quality and effectiveness in diagnostic processes (<xref rid="B23" ref-type="bibr">23</xref>). However, attitudes are not uniformly negative. Many professionals have expressed positive views toward AI's potential, particularly in diagnostic specialties. Pathologists, for example, advocate for AI's role in crafting personalized treatment plans (<xref rid="B24" ref-type="bibr">24</xref>). In oral diagnostics, various models of AI have demonstrated efficiency in identifying OPMLs and OSCCs. Furthermore, LLMs such as ChatGPT are being considered to play an important role in risk prediction model of OPMD/OSCC. A study done by Islam A <italic>et al</italic>. (<xref rid="B25" ref-type="bibr">25</xref>) reported high sensitivity of GPT 3.5 response to oral pathology queries, and presented substantial agreement with the experts. In our study, however, we predominantly found fair to moderate agreement between the SEs and LLMs on their responses. Diagnosing OPMLs and OSCCs can be challenging requiring clinicians to undergo extensive training over many years to accurately identify and manage these conditions. Therefore, despite the sophistication of LLMs, it may not demonstrate the originality, creativity, and critical thinking necessary for diagnosing these conditions (<xref rid="B6" ref-type="bibr">6</xref>). This perspective is further reinforced by patients consistently expressing a strong preference for retaining human oversight in medical decisions (<xref rid="B26" ref-type="bibr">26</xref>).</p><p>AI-assisted diagnostics face significant challenges, which includes a lack of standardization, ethical dilemmas, biases, legal concerns, and the scarcity of publicly available databases for training. Other issues, such as interpretability and adaptability, also play crucial roles. Additionally, LLMs may have cost, readability, and accessibility related constraints (<xref rid="B27" ref-type="bibr">27</xref>). Many of these limitations overlap. AI models are developed using various methodologies and datasets, resulting in variance in quality and comprehensiveness based on the source. It can sometimes intensify human biases leading to underdiagnosis for population groups, such as females, black patients, and patients of lower socioeconomic status (<xref rid="B28" ref-type="bibr">28</xref>). A limited number of publicly accessible database for image analysis of OPMDs and OSCCs presents another challenge. In a study by N. Sengupta <italic>et al</italic>. (<xref rid="B29" ref-type="bibr">29</xref>) the authors found only one image database for oral cancer. In the present study, although all the images were sourced either from publicly accessible databases or from open access articles, there were only minor improvements in diagnosis through image recognition by GPT 4o and Gemini. In fact, in one of the misdiagnosed cases, Gemini provided the reference link for the source of the image. This outcome raises questions about the adequacy of the training data used for these models, especially when it comes to image recognition. AI-assisted clinical decision making also brings to light several ethical considerations, including the issues of accountability, transparency on AI functioning, securing informed consent for data use, and protecting patient&#x02019;s privacy (<xref rid="B30" ref-type="bibr">30</xref>).</p><p>This study is not without its limitations. One of them is the limited sample size, consisting of 42 case reports, with 2 cases corresponding to each OPML. This limited selection was due to the inadequate number of publicly available image database for OPMLs to correspond to the case reports. Additionally, the study compared only the popular LLMs for their diagnostic abilities. LLMs such as Claude and Perplexity, may offer diverse performance based on the variation in their training data. Including a wider variety of LLMs with larger sample size in future research could provide a more comprehensive understanding of their diagnostic potential.</p></sec><sec><title>Conclusions</title><p>The results of the present study points towards cautious optimism regarding AI-assisted diagnosis of OPMLs. The analysis found that among LLMs, GPT 4o identified the highest number of lesions correctly followed by GPT 4.0, GPT 3.5 and Gemini. In diagnosing OPMLs through image recognition, GPT 4o outperformed Gemini with the greatest number of correct responses. However, it is worth mentioning that Gemini provides the option of image analysis in its free version, whereas it is a paid service included in ChatGPT 4o. This can have significant impact in terms of affordability and accessibility. Gemini, GPT 4o and GPT 4.0 also provided a range of differential diagnosis along with their responses. Despite these advances, all LLMs fell short of matching the diagnostic precision of subject experts. Nevertheless, including partially correct responses as a factor enhances the perceived diagnostic capabilities of LLMs. When taking assistance of conversational AI-bots, clinicians should be aware of its limitations in correctly identifying the subtypes of various OPMLs and should anticipate receiving general responses rather than specific insights. Its application can be particularly useful in remote settings with limited manpower and resources. ChatGPT and Gemini can be used to analyse patient&#x02019;s history, risk factors, and clinical presentation of OPMLs and aid in clinical decision-making process. The findings of the present study further reinforce the need of human supervision for AI-assisted diagnosis. Clinical decision-making involves numerous factors, at the core of which is human engagement, which cannot be replaced by Artificial Intelligence.</p></sec></body><back><ack><title>Acknowledgement</title><p>The author would like to extend her gratitude to Shubham Sharma, Dr Varsha AC, and Dr Aiman Haider for providing valuable insights and support for this study.
</p></ack><sec><title>Funding</title><p>This research was conducted without any financial support from external funding agencies.</p></sec><sec sec-type="COI-statement"><title>Conflict of interest</title><p>The authors declare no conflict of interest, financial or otherwise.</p></sec><notes><title>Institutional Review Board Statement</title><p>This study did not involve human or animal subjects, nor did it include use of personal or sensitive data.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>Derived data supporting the findings of this study are available from the Correspondence on request.</p></notes><notes><title>Author Contributions</title><p>Pragya Pradhan: Conceptualization, Data Curation, Formal Analysis, Investigation, Methodology, Software, Visualization, Writing - original draft, Writing - review and editing.</p></notes><ref-list><ref id="B1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nazir</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name></person-group><article-title>A comprehensive survey of ChatGPT: Advancements, applications, prospects, and challenges</article-title><source>Meta-Radiology</source><year>2023</year><volume>1</volume><fpage>100022</fpage><pub-id pub-id-type="pmid">37901715</pub-id>
</element-citation></ref><ref id="B2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Deng</surname><given-names>H</given-names></name><name><surname>Liu</surname><given-names>B</given-names></name><name><surname>Hu</surname><given-names>A</given-names></name><name><surname>Liang</surname><given-names>J</given-names></name><name><surname>Fan</surname><given-names>L</given-names></name></person-group><article-title>Systematic evaluation of research progress on natural language processing in medicine over the past 20 years: Bibliometric study on pubmed</article-title><source>J Med Internet Res</source><year>2020</year><volume>22</volume><fpage>e16816</fpage><pub-id pub-id-type="pmid">32012074</pub-id>
</element-citation></ref><ref id="B3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Dada</surname><given-names>A</given-names></name><name><surname>Puladi</surname><given-names>B</given-names></name><name><surname>Kleesiek</surname><given-names>J</given-names></name><name><surname>Egger</surname><given-names>J</given-names></name></person-group><article-title>ChatGPT in healthcare: A taxonomy and systematic review</article-title><source>Comput Methods Programs Biomed</source><year>2024</year><volume>245</volume><fpage>108013</fpage><pub-id pub-id-type="pmid">38262126</pub-id>
</element-citation></ref><ref id="B4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dave</surname><given-names>T</given-names></name><name><surname>Athaluri</surname><given-names>SA</given-names></name><name><surname>Singh</surname><given-names>S</given-names></name></person-group><article-title>ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations</article-title><source>Front Artif Intell</source><year>2023</year><volume>6</volume><fpage>1169595</fpage><pub-id pub-id-type="pmid">37215063</pub-id>
</element-citation></ref><ref id="B5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montazeri</surname><given-names>M</given-names></name><name><surname>Galavi</surname><given-names>Z</given-names></name><name><surname>Ahmadian</surname><given-names>L</given-names></name></person-group><article-title>What are the applications of ChatGPT in healthcare: Gain or loss?</article-title><source>Heal Sci Reports</source><year>2024</year><volume>7</volume><fpage>e1878</fpage><pub-id pub-id-type="pmid">38361810</pub-id>
</element-citation></ref><ref id="B6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garg</surname><given-names>RK</given-names></name><name><surname>Urs</surname><given-names>VL</given-names></name><name><surname>Agarwal</surname><given-names>AA</given-names></name><name><surname>Chaudhary</surname><given-names>SK</given-names></name><name><surname>Paliwal</surname><given-names>V</given-names></name><name><surname>Kar</surname><given-names>SK</given-names></name></person-group><article-title>Exploring the role of ChatGPT in patient care (diagnosis and treatment) and medical research: A systematic review</article-title><source>Heal Promot Perspect</source><year>2023</year><volume>13</volume><fpage>183</fpage><lpage>91</lpage><pub-id pub-id-type="pmid">37808939</pub-id>
</element-citation></ref><ref id="B7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirosawa</surname><given-names>T</given-names></name><name><surname>Kawamura</surname><given-names>R</given-names></name><name><surname>Harada</surname><given-names>Y</given-names></name><name><surname>Mizuta</surname><given-names>K</given-names></name><name><surname>Tokumasu</surname><given-names>K</given-names></name><name><surname>Kaji</surname><given-names>Y</given-names></name></person-group><article-title>ChatGPT-Generated Differential Diagnosis Lists for Complex Case-Derived Clinical Vignettes: Diagnostic Accuracy Evaluation</article-title><source>JMIR Med Informatics</source><year>2023</year><volume>11</volume><fpage>e48808</fpage><pub-id pub-id-type="pmid">37812468</pub-id>
</element-citation></ref><ref id="B8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Messadi D</surname><given-names>V</given-names></name></person-group><article-title>Diagnostic aids for detection of oral precancerous conditions</article-title><source>Int J Oral Sci</source><year>2013</year><volume>5</volume><fpage>59</fpage><lpage>65</lpage><pub-id pub-id-type="pmid">23743617</pub-id>
</element-citation></ref><ref id="B9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yardimci</surname><given-names>G</given-names></name><name><surname>Kutlubay</surname><given-names>Z</given-names></name><name><surname>Engin</surname><given-names>B</given-names></name><name><surname>Tuzun</surname><given-names>Y</given-names></name></person-group><article-title>Precancerous lesions of oral mucosa</article-title><source>World J Clin Cases</source><year>2014</year><volume>2</volume><fpage>866</fpage><lpage>72</lpage><pub-id pub-id-type="pmid">25516862</pub-id>
</element-citation></ref><ref id="B10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steele</surname><given-names>TO</given-names></name><name><surname>Meyers</surname><given-names>A</given-names></name></person-group><article-title>Early detection of premalignant lesions and oral cancer</article-title><source>Otolaryngol Clin North Am</source><year>2011</year><volume>44</volume><fpage>221</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">21093631</pub-id>
</element-citation></ref><ref id="B11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diamanti</surname><given-names>N</given-names></name><name><surname>Duxbury</surname><given-names>AJ</given-names></name><name><surname>Ariyaratnam</surname><given-names>S</given-names></name><name><surname>Macfarlane</surname><given-names>TV</given-names></name></person-group><article-title>Attitudes to biopsy procedures in general dental practice</article-title><source>Br Dent J</source><year>2002</year><volume>192</volume><fpage>588</fpage><lpage>92</lpage><pub-id pub-id-type="pmid">12075959</pub-id>
</element-citation></ref><ref id="B12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tarakji</surname><given-names>B</given-names></name></person-group><article-title>Dentists' Perception of Oral Potentially Malignant Disorders</article-title><source>Int Dent J</source><year>2022</year><volume>72</volume><fpage>414</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">35227496</pub-id>
</element-citation></ref><ref id="B13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khong</surname><given-names>B</given-names></name><name><surname>Ferlito</surname><given-names>S</given-names></name><name><surname>Quek</surname><given-names>S</given-names></name><name><surname>Conte</surname><given-names>G</given-names></name><name><surname>Ingrassia</surname><given-names>A</given-names></name><name><surname>Lechien</surname><given-names>JR</given-names></name></person-group><article-title>Past, Present, and Future Diagnostic Methods for the Early Noninvasive Detection of Oral Premalignant Lesions: A State of the Art and Systematic Review</article-title><source>Ear, Nose Throat J</source><year>2024</year><volume>0</volume><fpage>1455613241245204</fpage><pub-id pub-id-type="pmid">38695398</pub-id>
</element-citation></ref><ref id="B14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diniz-Freitas</surname><given-names>M</given-names></name><name><surname>Rivas-Mundi&#x000f1;a</surname><given-names>B</given-names></name><name><surname>Garc&#x000ed;a-Iglesias</surname><given-names>JR</given-names></name><name><surname>Garc&#x000ed;a-Mato</surname><given-names>E</given-names></name><name><surname>Diz-Dios</surname><given-names>P</given-names></name></person-group><article-title>How ChatGPT performs in Oral Medicine: The case of oral potentially malignant disorders</article-title><source>Oral Dis</source><year>2023</year><volume>30</volume><fpage>1912</fpage><lpage>8</lpage><pub-id pub-id-type="pmid">37794649</pub-id>
</element-citation></ref><ref id="B15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassona</surname><given-names>Y</given-names></name><name><surname>Alqaisi</surname><given-names>D</given-names></name><name><surname>AL-Haddad</surname><given-names>A</given-names></name><name><surname>Georgakopoulou</surname><given-names>EA</given-names></name><name><surname>Malamos</surname><given-names>D</given-names></name><name><surname>Alrashdan</surname><given-names>MS</given-names></name></person-group><article-title>How good is ChatGPT at answering patients' questions related to early detection of oral (mouth) cancer?</article-title><source>Oral Surg Oral Med Oral Pathol Oral Radiol</source><year>2024</year><volume>138</volume><fpage>269</fpage><lpage>78</lpage><pub-id pub-id-type="pmid">38714483</pub-id>
</element-citation></ref><ref id="B16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warnakulasuriya</surname><given-names>S</given-names></name><name><surname>Kujan</surname><given-names>O</given-names></name><name><surname>Aguirre-Urizar</surname><given-names>JM</given-names></name><name><surname>Bagan J</surname><given-names>V</given-names></name></person-group><article-title>, Gonz&#x000e1;lez-Moles M&#x000c1;, Kerr AR, et al. Oral potentially malignant disorders: A consensus report from an international seminar on nomenclature and classification, convened by the WHO Collaborating Centre for Oral Cancer</article-title><source>Oral Dis</source><year>2021</year><volume>27</volume><fpage>1862</fpage><lpage>80</lpage><pub-id pub-id-type="pmid">33128420</pub-id>
</element-citation></ref><ref id="B17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Okuhara</surname><given-names>T</given-names></name><name><surname>Chang</surname><given-names>XY</given-names></name><name><surname>Shirabe</surname><given-names>R</given-names></name><name><surname>Nishiie</surname><given-names>Y</given-names></name><name><surname>Okada</surname><given-names>H</given-names></name></person-group><article-title>Performance of ChatGPT Across Different Versions in Medical Licensing Examinations Worldwide: Systematic Review and Meta-Analysis</article-title><source>J Med Internet Res</source><year>2024</year><volume>26</volume><fpage>e60807</fpage><pub-id pub-id-type="pmid">39052324</pub-id>
</element-citation></ref><ref id="B18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname><given-names>M</given-names></name><name><surname>Sinha</surname><given-names>R</given-names></name><name><surname>Sen</surname><given-names>S</given-names></name><name><surname>Jha</surname><given-names>H</given-names></name><name><surname>Deb</surname><given-names>D</given-names></name></person-group><article-title>Proliferative verrucus leukoplakia: A case series</article-title><source>J Fam Med Prim Care</source><year>2022</year><volume>11</volume><fpage>3352</fpage><lpage>5</lpage><pub-id pub-id-type="pmid">36119284</pub-id>
</element-citation></ref><ref id="B19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kristofelc</surname><given-names>N</given-names></name><name><surname>Zidar</surname><given-names>N</given-names></name><name><surname>Strojan</surname><given-names>P</given-names></name></person-group><article-title>Oral verrucous carcinoma: A diagnostic and therapeutic challenge</article-title><source>Radiol Oncol</source><year>2023</year><volume>57</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">36942907</pub-id>
</element-citation></ref><ref id="B20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shavit</surname><given-names>E</given-names></name><name><surname>Klieb</surname><given-names>H</given-names></name><name><surname>Shear</surname><given-names>NH</given-names></name></person-group><article-title>Oral lichen planus: A novel staging and algorithmic approach and all that is essential to know</article-title><source>F1000Research</source><year>2020</year><volume>9</volume><fpage>F1000 Faculty Rev</fpage><lpage>206</lpage><pub-id pub-id-type="pmid">32226613</pub-id>
</element-citation></ref><ref id="B21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Angelis</surname><given-names>L</given-names></name><name><surname>Baglivo</surname><given-names>F</given-names></name><name><surname>Arzilli</surname><given-names>G</given-names></name><name><surname>Privitera</surname><given-names>GP</given-names></name><name><surname>Ferragina</surname><given-names>P</given-names></name><name><surname>Tozzi</surname><given-names>AE</given-names></name></person-group><article-title>ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health</article-title><source>Front Public Heal</source><year>2023</year><volume>11</volume><fpage>1166120</fpage><pub-id pub-id-type="pmid">37181697</pub-id>
</element-citation></ref><ref id="B22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shukla</surname><given-names>R</given-names></name><name><surname>Mishra</surname><given-names>AK</given-names></name><name><surname>Banerjee</surname><given-names>N</given-names></name><name><surname>Verma</surname><given-names>A</given-names></name></person-group><article-title>The Comparison of ChatGPT 3.5, Microsoft Bing, and Google Gemini for Diagnosing Cases of Neuro-Ophthalmology</article-title><source>Cureus</source><year>2024</year><volume>16</volume><fpage>e58232</fpage><pub-id pub-id-type="pmid">38745784</pub-id>
</element-citation></ref><ref id="B23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdullah</surname><given-names>R</given-names></name><name><surname>Fakieh</surname><given-names>B</given-names></name></person-group><article-title>Health care employees' perceptions of the use of artificial intelligence applications: Survey study</article-title><source>J Med Internet Res</source><year>2020</year><volume>22</volume><fpage>e17620</fpage><pub-id pub-id-type="pmid">32406857</pub-id>
</element-citation></ref><ref id="B24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al-Medfa</surname><given-names>MK</given-names></name><name><surname>Al-Ansari</surname><given-names>AMS</given-names></name><name><surname>Darwish</surname><given-names>AH</given-names></name><name><surname>Qreeballa</surname><given-names>TA</given-names></name><name><surname>Jahrami</surname><given-names>H</given-names></name></person-group><article-title>Physicians' attitudes and knowledge toward artificial intelligence in medicine: Benefits and drawbacks</article-title><source>Heliyon</source><year>2023</year><volume>9</volume><fpage>e14744</fpage><pub-id pub-id-type="pmid">37035387</pub-id>
</element-citation></ref><ref id="B25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Islam</surname><given-names>A</given-names></name><name><surname>Banerjee</surname><given-names>A</given-names></name><name><surname>Wati</surname><given-names>SM</given-names></name><name><surname>Banerjee</surname><given-names>S</given-names></name><name><surname>Shrivastava</surname><given-names>D</given-names></name><name><surname>Srivastava</surname><given-names>KC</given-names></name></person-group><article-title>Utilizing Artificial Intelligence Application for Diagnosis of Oral Lesions and Assisting Young Oral Histopathologist in Deriving Diagnosis from Provided Features - A Pilot study</article-title><source>J Pharm Bioallied Sci</source><year>2024</year><volume>16</volume><fpage>S1136</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">38882904</pub-id>
</element-citation></ref><ref id="B26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritsch</surname><given-names>SJ</given-names></name><name><surname>Blankenheim</surname><given-names>A</given-names></name><name><surname>Wahl</surname><given-names>A</given-names></name><name><surname>Hetfeld</surname><given-names>P</given-names></name><name><surname>Maassen</surname><given-names>O</given-names></name><name><surname>Deffge</surname><given-names>S</given-names></name></person-group><article-title>Attitudes and perception of artificial intelligence in healthcare: A cross-sectional survey among patients</article-title><source>Digit Heal</source><year>2022</year><volume>8</volume><fpage>20552076221116772</fpage><pub-id pub-id-type="pmid">35983102</pub-id>
</element-citation></ref><ref id="B27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wubineh</surname><given-names>BZ</given-names></name><name><surname>Deriba</surname><given-names>FG</given-names></name><name><surname>Woldeyohannis</surname><given-names>MM</given-names></name></person-group><article-title>Exploring the opportunities and challenges of implementing artificial intelligence in healthcare: A systematic literature review</article-title><source>Urol Oncol Semin Orig Investig</source><year>2024</year><volume>42</volume><fpage>48</fpage><lpage>56</lpage><pub-id pub-id-type="pmid">38101991</pub-id>
</element-citation></ref><ref id="B28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seyyed-Kalantari</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>McDermott</surname><given-names>MBA</given-names></name><name><surname>Chen</surname><given-names>IY</given-names></name><name><surname>Ghassemi</surname><given-names>M</given-names></name></person-group><article-title>Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations</article-title><source>Nat Med</source><year>2021</year><volume>27</volume><fpage>2176</fpage><lpage>82</lpage><pub-id pub-id-type="pmid">34893776</pub-id>
</element-citation></ref><ref id="B29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengupta</surname><given-names>N</given-names></name><name><surname>Sarode</surname><given-names>SC</given-names></name><name><surname>Sarode</surname><given-names>GS</given-names></name><name><surname>Ghone</surname><given-names>U</given-names></name></person-group><article-title>Scarcity of publicly available oral cancer image datasets for machine learning research</article-title><source>Oral Oncol</source><year>2022</year><volume>126</volume><fpage>105737</fpage><pub-id pub-id-type="pmid">35114612</pub-id>
</element-citation></ref><ref id="B30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davenport</surname><given-names>T</given-names></name><name><surname>Kalakota</surname><given-names>R</given-names></name></person-group><article-title>The potential for artificial intelligence in healthcare</article-title><source>Futur Healthc J</source><year>2019</year><volume>6</volume><fpage>94</fpage><lpage>8</lpage><pub-id pub-id-type="pmid">31363513</pub-id>
</element-citation></ref></ref-list></back><floats-group><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Interrater agreement between the Subject Experts and ChatGPT 3.5, 4.0, 4o and Gemini.</p></caption><table frame="border" rules="all" width="100%"><thead><tr><th rowspan="2" colspan="1">AI Model - Subject Expert</th><th colspan="2" rowspan="1">Cohen's Kappa</th></tr><tr><th rowspan="1" colspan="1">Text Description</th><th rowspan="1" colspan="1">Text + Image Identification</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">ChatGPT 3.5 - SE1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.365*</td><td align="center" valign="middle" rowspan="1" colspan="1">NA</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">ChatGPT 3.5 - SE2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.333*</td><td align="center" valign="middle" rowspan="1" colspan="1">NA</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">ChatGPT 4.0- SE1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.468*</td><td align="center" valign="middle" rowspan="1" colspan="1">NA</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">ChatGPT 4.0 - SE2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.350*</td><td align="center" valign="middle" rowspan="1" colspan="1">NA</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">ChatGPT 4o - SE1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.502*</td><td align="center" valign="middle" rowspan="1" colspan="1">0.396*</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">ChatGPT 4o - SE2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.659*</td><td align="center" valign="middle" rowspan="1" colspan="1">0.514*</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Gemini - SE1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.326*</td><td align="center" valign="middle" rowspan="1" colspan="1">0.265*</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Gemini - SE2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.413*</td><td align="center" valign="middle" rowspan="1" colspan="1">0.245*</td></tr></tbody></table><table-wrap-foot><fn><p>LLM - Large Language Model; SE - Subject Expert; NA - Not Applicable *Statistically significant at p&#x0003c;0.05.
</p></fn></table-wrap-foot></table-wrap></floats-group></article>