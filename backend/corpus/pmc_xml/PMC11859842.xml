<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006379</article-id><article-id pub-id-type="pmc">PMC11859842</article-id><article-id pub-id-type="doi">10.3390/s25041150</article-id><article-id pub-id-type="publisher-id">sensors-25-01150</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Multimodal Deep Learning Approach to Intraoperative Nociception Monitoring: Integrating Electroencephalogram, Photoplethysmography, and Electrocardiogram</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0000-5284-8845</contrib-id><name><surname>Abdel Deen</surname><given-names>Omar M. T.</given-names></name><xref rid="af1-sensors-25-01150" ref-type="aff">1</xref><xref rid="af2-sensors-25-01150" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6849-8453</contrib-id><name><surname>Fan</surname><given-names>Shou-Zen</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af2-sensors-25-01150" ref-type="aff">2</xref><xref rid="af3-sensors-25-01150" ref-type="aff">3</xref><xref rid="c1-sensors-25-01150" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Shieh</surname><given-names>Jiann-Shing</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="af1-sensors-25-01150" ref-type="aff">1</xref><xref rid="af2-sensors-25-01150" ref-type="aff">2</xref><xref rid="c1-sensors-25-01150" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Cusid&#x000f3;</surname><given-names>Jordi</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01150"><label>1</label>Department of Mechanical Engineering, Yuan Ze University, Taoyuan 320, Taiwan; <email>omartalab40@gmail.com</email></aff><aff id="af2-sensors-25-01150"><label>2</label>Department of Anesthesiology, En Chu Kong Hospital, New Taipei City 237, Taiwan</aff><aff id="af3-sensors-25-01150"><label>3</label>College of Medicine, National Taiwan University, Taipei 100, Taiwan</aff><author-notes><corresp id="c1-sensors-25-01150"><label>*</label>Correspondence: <email>szf2515@ntu.edu.tw</email> (S.-Z.F.); <email>jsshieh@saturn.yzu.edu.tw</email> (J.-S.S.)</corresp></author-notes><pub-date pub-type="epub"><day>13</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1150</elocation-id><history><date date-type="received"><day>24</day><month>1</month><year>2025</year></date><date date-type="rev-recd"><day>08</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>10</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Monitoring nociception under general anesthesia remains challenging due to the complexity of pain pathways and the limitations of single-parameter methods. In this study, we introduce a multimodal approach that integrates electroencephalogram (EEG), photoplethysmography (PPG), and electrocardiogram (ECG) signals to predict nociception. We collected data from patients undergoing general anesthesia at two hospitals and developed and compared two deep learning models: a Multilayer Perceptron (MLP) and a Long Short-Term Memory (LSTM) network. Both models were trained on expert anesthesiologists&#x02019; assessments of nociception. We evaluated normalization strategies for offline and online usage and found that Min&#x02013;Max normalization was most effective for our dataset. Our results demonstrate that the MLP model accurately captured nociceptive changes in response to painful surgical stimuli, whereas the LSTM model provided smoother predictions but with lower sensitivity to rapid changes. These findings underscore the potential of multimodal, deep learning-based solutions to improve real-time nociception monitoring in diverse clinical settings.</p></abstract><kwd-group><kwd>nociception prediction</kwd><kwd>multimodal monitoring</kwd><kwd>machine learning</kwd><kwd>EEG</kwd><kwd>PPG</kwd><kwd>ECG</kwd><kwd>anesthesia</kwd><kwd>LSTM</kwd><kwd>MLP</kwd></kwd-group><funding-group><award-group><funding-source>National Science Foundation of Taiwan</funding-source><award-id>NSC-113-2314-B-385-001</award-id></award-group><funding-statement>This work was supported by the National Science Foundation of Taiwan (NSC-113-2314-B-385-001).</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01150"><title>1. Introduction</title><p>Pain and nociception are often confused, but they are distinct. Pain is a conscious, subjective experience [<xref rid="B1-sensors-25-01150" ref-type="bibr">1</xref>]. Under general anesthesia, however, &#x0201c;pain&#x0201d; is more accurately referred to as &#x0201c;nociception&#x0201d;, which reflects the physiological response to noxious stimuli in the absence of conscious perception. In the last two decades, significant progress has been made in developing methods to monitor nociception during anesthesia, particularly through algorithms that assess the nociception&#x02013;antinociception (NAN) balance based on hemodynamic (e.g., ECG, PPG) and neural (e.g., EEG) signals.</p><p>An increase in the sympathetic tone might be perceived as a reaction to painful stimuli [<xref rid="B2-sensors-25-01150" ref-type="bibr">2</xref>], while conversely, an increase in the parasympathetic tone might be related to analgesia. The Surgical Pleth Index (SPI) is derived from PPG signals and used to monitor NAN; it uses a combination of normalized heartbeat intervals (HBI<sub>Norm</sub>) and plethysmography amplitude (PPGA<sub>Norm</sub>) [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>]. SPI is effective for nociception monitoring; however, since it is based on autonomic nervous system (ANS) activity, it might be confounded by other factors such as arrhythmia or antihypertensive drugs [<xref rid="B4-sensors-25-01150" ref-type="bibr">4</xref>].</p><p>The analgesia nociception index (ANI), another measure used to monitor NAN, is derived from high-frequency heartbeat intervals [<xref rid="B5-sensors-25-01150" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-01150" ref-type="bibr">6</xref>]. The ANI is based on parasympathetic reactions and reflects noxious stimulations; however, it is also prone to arrhythmia and affected by parasympathetic reactions not related to pain. Moreover, the ANI was found to have a large inter-individual variability [<xref rid="B4-sensors-25-01150" ref-type="bibr">4</xref>].</p><p>In general anesthesia, EEG signals are used to predict the consciousness level; however, some studies show that EEG-derived indexes (e.g., BIS, SE, and RE) increased significantly in painful stimulus events [<xref rid="B7-sensors-25-01150" ref-type="bibr">7</xref>,<xref rid="B8-sensors-25-01150" ref-type="bibr">8</xref>,<xref rid="B9-sensors-25-01150" ref-type="bibr">9</xref>], and thus, it might be helpful to provide information about nociception. qNOX is another index that is derived from EEG signals [<xref rid="B10-sensors-25-01150" ref-type="bibr">10</xref>]. It was developed using an Adaptive Neuro Fuzzy Inference System (ANFIS) by fitting different EEG frequency bands into a reference scale to predict noxious stimuli responses. Other methods have used single or a combination of parameters to monitor nociception [<xref rid="B11-sensors-25-01150" ref-type="bibr">11</xref>,<xref rid="B12-sensors-25-01150" ref-type="bibr">12</xref>].</p><p>Pain/nociception is a subjective experience [<xref rid="B13-sensors-25-01150" ref-type="bibr">13</xref>]. Even with the absence of a clinical response, brain and spinal activities persist [<xref rid="B14-sensors-25-01150" ref-type="bibr">14</xref>]. Pain perception starts when nociceptors sense painful stimuli. Nociceptors send pain signals through the spinal cord to the brainstem, where the first stage of processing takes place. These signals then move upward to the Thalamus, which serves as a central relay station for sensory information. Further processing and relay occur in higher brain regions, including the frontal cortex, specifically the somatosensory cortex and anterior cingulate cortex [<xref rid="B15-sensors-25-01150" ref-type="bibr">15</xref>].</p><p>EEG bands were reported to react to several kinds of painful stimuli. It was found that EEG patterns are altered by noxious procedures in children, with local anesthesia mitigating this response [<xref rid="B16-sensors-25-01150" ref-type="bibr">16</xref>]. Additionally, under sevoflurane anesthesia, the neuromuscular block affects BIS and EEG responses to noxious electrical stimulation, suggesting genuine arousal differences [<xref rid="B17-sensors-25-01150" ref-type="bibr">17</xref>]. Clinical observations during tracheal intubation highlight alpha power changes as a sensitive indicator of cerebral activity modulation [<xref rid="B18-sensors-25-01150" ref-type="bibr">18</xref>]. Moreover, noxious stimulation affects cortical electrical activity levels, as shown by EEG parameters [<xref rid="B19-sensors-25-01150" ref-type="bibr">19</xref>].</p><p>The model selection process is challenging. Different models and methods were used in previous studies. For instance, SPI uses a linear model [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>], while qNOX was developed using an ANFIS model [<xref rid="B10-sensors-25-01150" ref-type="bibr">10</xref>], and the nociception level index was developed using random forest and linear regression models [<xref rid="B11-sensors-25-01150" ref-type="bibr">11</xref>]. Long Short-Term Memory Neural Network (LSTM) models [<xref rid="B20-sensors-25-01150" ref-type="bibr">20</xref>] are known for their ability to retain important information over a long period; therefore, they have the advantage of using previous knowledge to make predictions efficiently. On the other hand, Multilayer Perceptron (MLP) models do not need previous knowledge [<xref rid="B21-sensors-25-01150" ref-type="bibr">21</xref>], and yet they can predict nonlinear relationships and find hidden patterns within the data [<xref rid="B22-sensors-25-01150" ref-type="bibr">22</xref>].</p><p>While previous methods for nociception monitoring have demonstrated utility, the limitations of single-source approaches, particularly those reliant solely on the autonomic nervous system (ANS), prompt consideration of multimodal methods. ANS-based models, although informative, may be susceptible to non-nociceptive factors, potentially compromising the accuracy of nociception assessments. Moreover, the use of EEG data in isolation may not provide a comprehensive understanding of nociceptive states. In contrast, multimodal monitoring could offer the advantage of encompassing a broad spectrum of biomedical and clinical information. By integrating multiple physiological signals, such as EEG, PPG, and ECG, multimodal models have the capacity to capture diverse aspects of pain processing. Based on these considerations, we aim to address this challenge by implementing a multimodal approach utilizing EEG, PPG, and ECG signals to predict nociception during general anesthesia by integrating these three signals into one model. This study uses expert anesthesiologists&#x02019; nociception assessments (NOAs) based on clinical signs noted carefully during surgeries.</p></sec><sec id="sec2-sensors-25-01150"><title>2. Materials and Methods</title><sec id="sec2dot1-sensors-25-01150"><title>2.1. Data Collection</title><p>This work received approval from the institutional review board of the National Taiwan University Hospital (NTUH), and informed consent was obtained from all participants involved in this study. ECG, EEG, and PPG signals were collected using a Philips IntelliVue MP60 physiological signal monitor (Koninklijke Philips N.V, Amsterdam, The Netherlands), and the data were stored on a personal computer for further analysis. This study initially enrolled 142 patients from NTUH scheduled for general anesthesia surgery with inhalation anesthesia, during which propofol and fentanyl were administered. Another dataset from ECKH (<italic toggle="yes">n</italic> = 10) was included in the analysis when it became available, the signals were collected using CARESCAPE B650 monitor (GE Healthcare Finland Oy, Helsinki, Finland); the anesthesia method was also inhalation anesthesia. Due to missing signal data in the NTUH dataset, the final analysis included 90 patients from NTUH and 10 patients from ECKH. The patients&#x02019; demographic data are listed in <xref rid="sensors-25-01150-t001" ref-type="table">Table 1</xref>.</p><p>Currently, no universally accepted gold standard for nociception exists, making assessment more challenging. The NOAs were scored based on each patient&#x02019;s anesthesia record. The assessments were later digitized and stored in text files. After the surgeries were finished, each expert anesthesiologist (five in total) was appointed to assess the pain based on the information contained in the anesthesia record (e.g., HR, BP, anesthetic gas concentration, opioid dosages, etc.), and events, such as the eyelash reflex and laryngeal mask airway, were noted. As each anesthesiologist assessed pain individually, we synchronized the pain assessment data collected from multiple doctors and aligned them with the corresponding ECG, PPG, and EEG signals for analysis. Despite potential variations in assessment start times in a few cases, we matched data durations by comparing each patient&#x02019;s assessment times and excluding offsets. The synchronization algorithm identified the latest start time (L) and the earliest end time (U) across all assessments, defining the analysis time interval [L, U]. Data points outside this interval were removed, ensuring only synchronized data were retained. Similar procedures were applied to align ECG, PPG, and EEG signals with synchronized pain score data. This process ensured consistency and the alignment of data across assessments.</p><p>Our study used different parameters extracted from each signal. The ECG signals were used to extract the high-frequency waveform of heartbeats (RRHF) and its spectral power (RRHF<sub>PS</sub>). The photoplethysmographic pulse wave amplitude (PPGA) and the area under the curve of PPG signals (PPG<sub>AUC</sub>) were also extracted. Additionally, EEG signals were used to calculate the spectral power for each frequency band (i.e., delta, theta, alpha, beta, and gamma). The proposed model in this study is described in the flowchart shown in <xref rid="sensors-25-01150-f001" ref-type="fig">Figure 1</xref>. All processing steps were conducted using MATLAB (version R2022b, MathWorks Inc., Natick, MA, USA) with the Signal Processing Toolbox.</p></sec><sec id="sec2dot2-sensors-25-01150"><title>2.2. Signal Processing and Feature Extraction</title><p>First, RR series were extracted from ECG (512 Hz) using Pan&#x02013;Tompkin&#x02019;s algorithm [<xref rid="B23-sensors-25-01150" ref-type="bibr">23</xref>]. Then, we applied wavelet decomposition to the raw data and reconstructed only the RRHF in the range of 0.15&#x02013;0.5 Hz, which is related to parasympathetic activity. Moreover, we calculated the power spectrum for the RRHF series over 64 s segments with a Kaiser window of 16 s. The PPG signals with a 128 Hz sampling frequency were filtered as needed. We used a Chebyshev II fifth-order filter with a cutoff of 0.5&#x02013;8 Hz. For peak detection, we used the automatic multiscale-based peak detection algorithm [<xref rid="B24-sensors-25-01150" ref-type="bibr">24</xref>,<xref rid="B25-sensors-25-01150" ref-type="bibr">25</xref>]. The long-term trend of PPGA was more important than the instant value changes; therefore, we applied a moving average filter of a 16 s window on the raw data. The PPG<sub>AUC</sub> was calculated for each 64 s window. <xref rid="sensors-25-01150-f002" ref-type="fig">Figure 2</xref> shows a bandpass-filtered ECG window with its corresponding R peaks detected, and <xref rid="sensors-25-01150-f003" ref-type="fig">Figure 3</xref> shows a PPG 64 s window before and after filtering.</p><p>EEG (128 Hz) was bandpass filtered between 0.5 and 48 Hz to keep the signal of interest that covered all the EEG bands. Then, the power spectrum was calculated by thresholding over each band&#x02019;s frequency limits. An example of the raw EEG and its 5 bands are shown in <xref rid="sensors-25-01150-f004" ref-type="fig">Figure 4</xref>.</p><p>The EEG signal was first divided into 64 s segments with a 5 s time step; then, for each segment, the power was calculated using a Kaiser window of 16 s with no overlapping. <xref rid="sensors-25-01150-f005" ref-type="fig">Figure 5</xref> shows the procedure for data windowing. The resulting power array was then averaged to obtain one value for each 64 s window. Although this is not standard, the used limits were as follows:<list list-type="bullet"><list-item><p>Delta: 0.5&#x02013;3.5.</p></list-item><list-item><p>Theta: 4&#x02013;7.5.</p></list-item><list-item><p>Alpha: 8&#x02013;12.</p></list-item><list-item><p>Beta: 13&#x02013;30.</p></list-item><list-item><p>Gamma: 30.5&#x02013;48.</p></list-item></list></p></sec><sec id="sec2dot3-sensors-25-01150"><title>2.3. Normalization</title><p>Initially, the histogram normalization described in [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>] was used with a few adjustments. First, the standard deviation for the group dataset was not fixed; instead, it was the actual measure of the dataset. Second, the original distribution parameters were not combined; however, the transformation was calculated based on two distributions. The first transformation was based on the group dataset&#x02019;s cumulative distribution function (cdf), and the second transformation was based on an accumulated individual dataset. At the beginning of the surgery, the weight for the group transformation was 100%. As more data became available, the weight for group data was reduced linearly until 10 min of the individual data was accumulated. The weight after that was fixed at 0.7 for individuals and 0.3 for groups. The transformations were calculated as:<disp-formula id="FD1-sensors-25-01150"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where</p><list list-type="bullet"><list-item><p><italic toggle="yes">X<sub>norm</sub></italic> is the normalized value of <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></list-item><list-item><p><inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the cumulative probability of <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the individual dataset (from the beginning of the surgery until the current value).</p></list-item><list-item><p><inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the cumulative probability of <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the group dataset.</p></list-item><list-item><p><inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the weight for the individual dataset, adjusted based on <italic toggle="yes">t</italic>, which is the window number. <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> starts at 0 and smoothly adjusts to 0.7 over the segments.</p></list-item></list><p>The histogram normalization is modeled in <xref rid="sensors-25-01150-f006" ref-type="fig">Figure 6</xref>.</p><p>When the data were normalized using histogram normalization, we noticed that the correlation between the normalized features and the pain assessment might be affected. Moreover, the variability in the original features was negatively affected in some cases; therefore, we decided to use Min&#x02013;Max and z-score normalizations. The implementation was similar to histogram normalization, where the data were separated into group and individual datasets and the weights changed linearly based on the collected individual data from 100% to 30% for the group dataset. The z-score was previously utilized for online data normalization [<xref rid="B11-sensors-25-01150" ref-type="bibr">11</xref>], and the equation in our study is as follows:<disp-formula id="FD2-sensors-25-01150"><label>(2)</label><mml:math id="mm9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where</p><list list-type="bullet"><list-item><p><italic toggle="yes">X<sub>norm</sub></italic> is the normalized value of <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></list-item><list-item><p><inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the collected data from the beginning of the surgery to the current time.</p></list-item><list-item><p><inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the group dataset.</p></list-item></list><p>For Min&#x02013;Max normalization, we followed a similar procedure as implemented in [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>,<xref rid="B11-sensors-25-01150" ref-type="bibr">11</xref>]; the used equation is:<disp-formula id="FD3-sensors-25-01150"><label>(3)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mspace linebreak="newline"/><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where</p><list list-type="bullet"><list-item><p><italic toggle="yes">X<sub>norm</sub></italic> is the normalized value of <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></list-item><list-item><p><inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the collected data from the beginning of the surgery to the current time.</p></list-item><list-item><p><inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the group dataset.</p></list-item></list><p>To compare the three methods, the residuals and correlation between the original parameters and their transformed values were compared. As the data were available offline, we assumed that a perfect normalization would be achieved by normalizing the data while minimizing both intra- and inter-patient variability. Therefore, the normalization of the offline data to obtain a perfect normalization was fixed with a weight of 0.7 for the individual data, as we already had the data, and with a weight of 0.3 for the group data. The obtained values were then compared to the online implementation of the normalization. The comparison was performed by calculating the MAE and correlation between the normalized data. The best method was selected based on a metric score; the correlation and MAE were normalized and given a percentage based on their values. As both MAE and correlation were equally important, the score was calculated as follows:<disp-formula id="FD4-sensors-25-01150"><label>(4)</label><mml:math id="mm17" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>%</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec2dot4-sensors-25-01150"><title>2.4. Deep Learning Training</title><p>The models&#x02019; parameters were selected after applying an optimizable approach. The used models were MLP and LSTM. The models hyperparameters are listed in <xref rid="sensors-25-01150-t002" ref-type="table">Table 2</xref>. The input parameters for the model were the five spectral power variables extracted from EEG signals, the spectral power of RRHF series, and the PPGA and PPG<sub>AUC</sub> series. We first assumed that the model did not need to be complex; however, to cover every possibility, we set the number of hidden layers to be between 2 and 10. The learning rate was selected between 0.1 and 0.0001, and the batch size was random between 64 and 512. The selected optimal parameters are described in <xref rid="sensors-25-01150-t002" ref-type="table">Table 2</xref>. <xref rid="sensors-25-01150-f007" ref-type="fig">Figure 7</xref> and <xref rid="sensors-25-01150-f008" ref-type="fig">Figure 8</xref> show the models&#x02019; architecture.</p></sec><sec id="sec2dot5-sensors-25-01150"><title>2.5. Statistical Analysis</title><p>Three tests were applied to measure the agreement between each doctor&#x02019;s assessment. Analysis of variance (ANOVA) with a 0.05 significance level was used to test the similarity in the distributions and variance. To ensure consistency and agreement between the experts&#x02019; assessments, we applied the Bland&#x02013;Altman test [<xref rid="B26-sensors-25-01150" ref-type="bibr">26</xref>] and intraclass correlation (ICC) [<xref rid="B27-sensors-25-01150" ref-type="bibr">27</xref>] with a 0.05 significance level. The ICC test was performed on individual assessments and on the whole data. The correlation coefficients and <italic toggle="yes">t</italic>-tests were calculated for pain assessments and the parameters used in this study. The used models were evaluated using the mean squared error (MSE) and R<sup>2</sup> on the training and validation datasets. The test (10 patients) dataset was evaluated using the mean absolute error (MAE) and correlation analysis. For the ECKH data of 10 patients, we compared the differences of the mean at three different surgical stages: Intubation (t<sub>1</sub>), Incision (t<sub>2</sub>), and Extubation (t<sub>3</sub>). The receiver operating characteristic curve (ROC) was used to evaluate the models&#x02019; output in predicting nociception at the defined events for each patient individually (ECKH, <italic toggle="yes">n</italic> = 10).</p></sec></sec><sec sec-type="results" id="sec3-sensors-25-01150"><title>3. Results</title><sec id="sec3dot1-sensors-25-01150"><title>3.1. NOA</title><p>The pain assessments from each doctor were processed carefully. As five anesthesiologists provided the assessments, we first used the ANOVA test. Doctor D provided the lowest assessment, and it was significantly different than the other four doctors [<xref rid="B28-sensors-25-01150" ref-type="bibr">28</xref>]. Therefore, we only used assessments from Doctors A, B, C, and E. Moreover, we applied Bland&#x02013;Altman and ICC [<xref rid="B29-sensors-25-01150" ref-type="bibr">29</xref>] tests. When the pain assessments from all four doctors were pulled together, the ICC was 0.73 with a confidence interval of [0.69 0.75]. The ICC was also applied to each patient&#x02019;s assessments individually. <xref rid="sensors-25-01150-f009" ref-type="fig">Figure 9</xref> shows a histogram of the ICC values among the patients, and <xref rid="sensors-25-01150-f010" ref-type="fig">Figure 10</xref> shows the ANOVA test results. The agreement between the doctors&#x02019; assessments was evaluated using Bland&#x02013;Altman analysis and pairwise comparisons, with the results shown in <xref rid="sensors-25-01150-t003" ref-type="table">Table 3</xref> and <xref rid="sensors-25-01150-f011" ref-type="fig">Figure 11</xref>. The analysis results were consistent across the doctors in terms of agreement, where all data fell within the 95% limits of agreement (LoA). The lowest bias (&#x02212;0.7) was observed between Doctors B and C, indicating minimal differences in their assessments. The highest difference was found between Doctors C and E (bias = 6.25) and Doctors B and E (bias = 5.55). The standard deviation of the differences ranged from 7.4 to 9.1.</p></sec><sec id="sec3dot2-sensors-25-01150"><title>3.2. Parameter Correlations</title><p>After we matched the NOA for the four doctors, the average was taken for further analysis. The Pearson correlation coefficient between the parameters and the average assessment were calculated for each patient individually. The results were pulled together and are shown in <xref rid="sensors-25-01150-f012" ref-type="fig">Figure 12</xref>. PPG<sub>AUC</sub> had the highest individual positive correlation (0.85) and mean (0.46). The PPGA correlation had a mean value of &#x02212;0.32; it was mostly negative, with the highest value of &#x02212;0.82. The power calculations for EEG bands correlated negatively in most cases except for gamma, which had a close mean value (0.40) to PPG<sub>AUC</sub>. RRHF<sub>PS</sub> had the lowest correlation along with the beta band (&#x02212;0.003 and &#x02212;0.004 mean values, respectively).</p><p><xref rid="sensors-25-01150-f013" ref-type="fig">Figure 13</xref> shows an example of the used parameters, where the curves show a good positive or negative correlation with the pain assessment. The correlation analysis for the same subject is shown in <xref rid="sensors-25-01150-f014" ref-type="fig">Figure 14</xref>.</p></sec><sec id="sec3dot3-sensors-25-01150"><title>3.3. Parameter Normalization</title><p>The normalization methods resulted in different MAE and correlation values. The lowest MAE was found for Min&#x02013;Max normalization, and the highest correlation was found for histogram normalization. The results are shown in <xref rid="sensors-25-01150-f015" ref-type="fig">Figure 15</xref>. An example of normalization is shown in <xref rid="sensors-25-01150-f016" ref-type="fig">Figure 16</xref>. For this case, the lowest MAE (0.08) was associated with Min&#x02013;Max normalization, and the highest correlation was 0.95 for z-score normalization.</p></sec><sec id="sec3dot4-sensors-25-01150"><title>3.4. Pain/Nociception Models</title><p>Initially, we had 90 patients&#x02019; datasets. When more datasets from another hospital (ECKH-2023 datasets) became available, we decided to assess the model from a medical and engineering perspective. For NTUH (2015), the pain assessments were based on anesthetic records. However, these records were not easily available to us at the moment of this study; therefore, we were unable to assess the 10 patient test datasets from a medical perspective. Thus, the NTUH data were evaluated using MSE and R<sup>2</sup> on the training and validation datasets and correlation analysis and MAE on the test dataset. For ECKH, the needed information, such as painful stimuli events, was available; therefore, medical analysis was possible.</p><sec id="sec3dot4dot1-sensors-25-01150"><title>3.4.1. MLP Model</title><p>The MLP losses were 0.008 and 0.007 on training and validation, respectively. The R<sup>2</sup> was 0.82 on training and 0.80 on validation. For the test dataset (NTUH), the mean values for correlation and MAE were 0.78 and 5.1, respectively. <xref rid="sensors-25-01150-f017" ref-type="fig">Figure 17</xref> shows the curves for training and validation, and <xref rid="sensors-25-01150-f018" ref-type="fig">Figure 18</xref> shows the distribution of the correlation and MAE values for the test datasets.</p><p>For the 10 patients&#x02019; datasets from ECKH, the mean value before and after the three defined events was calculated. The mean values after t<sub>1</sub> increased from 48 to 57. While at t<sub>2</sub>, the mean value increased the least, from 41 to 50, and at t<sub>3</sub>, the mean value increased the most, from 48 to 62. <xref rid="sensors-25-01150-f019" ref-type="fig">Figure 19</xref> shows the changes in the mean values before and after each event (upper plot) and the difference in the mean NOA at each event (lower plot). The upper plot shows how the mean values before and after each event varied across the 10 patients. The lower plot demonstrates the differences in the mean NOA at each event between the patients. The highest difference was found at t<sub>3</sub>, with a value of 13, and the lowest was at t<sub>2</sub>, with a value of 8. The difference in the NOA means at t<sub>1</sub> was also clearly noticed, with a value of 9.</p><p>An example of the predicted pain/nociception from the two models is shown in <xref rid="sensors-25-01150-f020" ref-type="fig">Figure 20</xref> (NTUH dataset).</p></sec><sec id="sec3dot4dot2-sensors-25-01150"><title>3.4.2. LSTM Model</title><p>The training and validation losses for the LSTM model were 0.012 and 0.011, respectively. The R<sup>2</sup> was 0.87 and 0.81 on the training and validation, respectively. The mean value of the correlation and MAE were 0.85 and 3.6, respectively. <xref rid="sensors-25-01150-f021" ref-type="fig">Figure 21</xref> shows the trends of the training and validation. <xref rid="sensors-25-01150-f022" ref-type="fig">Figure 22</xref> shows the correlation and MAE values for each patient. The results were consistent, except for patient 3, who had a high MAE of 7.8.</p><p>For the 10 patients&#x02019; datasets from ECKH, the mean values before and after the three defined events increased less than the MLP model. The mean values before and after t<sub>1</sub> were 53 and 55, respectively, and it was the lowest. The mean values before and after t<sub>2</sub> were 47 and 51, respectively, and at t<sub>3</sub>, the values were 51 and 55 before and after, respectively. <xref rid="sensors-25-01150-f023" ref-type="fig">Figure 23</xref> shows the changes in the mean values before and after each event (upper plot) and the difference in the mean NOA at each event (lower plot). The upper plot shows how the mean values before and after each event varied across the 10 patients. The lower plot demonstrates the differences in the mean NOA at each event between the patients. The highest difference was found at t<sub>2</sub> and t<sub>3</sub>, with a value of 4, and the lowest was at t<sub>1</sub>, with a value of 2.5.</p><p><xref rid="sensors-25-01150-f024" ref-type="fig">Figure 24</xref> shows an example of the models&#x02019; predictions on the ECKH dataset.</p><p>The ROC curve results are shown in <xref rid="sensors-25-01150-f025" ref-type="fig">Figure 25</xref>. The results were obtained by classifying NOAs based on the events. The figure shows that the MLP model outperformed the LSTM model in predicting noxious stimuli. The mean value for MLP AUC was 0.90; the highest was 0.95, and the lowest was 0.82. The LSTM demonstrated low to moderate reactivity; the mean AUC value was 0.68, whereas the lowest and highest values were 0.44 and 0.82, respectively.</p></sec></sec></sec><sec sec-type="discussion" id="sec4-sensors-25-01150"><title>4. Discussion</title><p>Many indexes were developed specifically to monitor the nociception&#x02013;antinociception balance during general anesthesia [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>,<xref rid="B5-sensors-25-01150" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-01150" ref-type="bibr">6</xref>,<xref rid="B10-sensors-25-01150" ref-type="bibr">10</xref>,<xref rid="B11-sensors-25-01150" ref-type="bibr">11</xref>,<xref rid="B12-sensors-25-01150" ref-type="bibr">12</xref>,<xref rid="B30-sensors-25-01150" ref-type="bibr">30</xref>], and all were based on different parameters or a combination of those parameters (e.g., PPGA, HBI, EEG features). All of them have proven utility and were able to react to painful stimuli events. Single-source indexes were reported to react to other factors that do not relate to nociception [<xref rid="B4-sensors-25-01150" ref-type="bibr">4</xref>]. On the other hand, we believe that single-source indexes might ignore other information that could be helpful to assess NAN. Therefore, in our study, we developed two models to predict nociception in various stages of surgery. First, the ANOVA test was used to check the distributions and variance in the assessments among the doctors. Doctor D showed disagreement with the others; therefore, the related assessments were excluded. To further prove that the other doctors&#x02019; assessments were consistent and reliable, we applied ICC and Bland&#x02013;Altman tests on the assessments. The ICC was applied to the data when pulled together and individually. In both cases, the results proved the reliability between the assessment, as shown in <xref rid="sensors-25-01150-f009" ref-type="fig">Figure 9</xref> (0.73 on the whole data). The Bland&#x02013;Altman test also showed that 95% of the data was in the upper and lower limits of agreement (<xref rid="sensors-25-01150-t003" ref-type="table">Table 3</xref> and <xref rid="sensors-25-01150-f011" ref-type="fig">Figure 11</xref>); therefore, the assessments were used in further analysis. The parameter selection was based on the clinical parameters that were previously used to assess NAN [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>,<xref rid="B5-sensors-25-01150" ref-type="bibr">5</xref>,<xref rid="B10-sensors-25-01150" ref-type="bibr">10</xref>,<xref rid="B11-sensors-25-01150" ref-type="bibr">11</xref>]. PPGA and HBI were used for SPI development in a single-source model [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>] and in a multimodal approach [<xref rid="B11-sensors-25-01150" ref-type="bibr">11</xref>], while EEG parameters were used in other methods [<xref rid="B7-sensors-25-01150" ref-type="bibr">7</xref>,<xref rid="B8-sensors-25-01150" ref-type="bibr">8</xref>,<xref rid="B10-sensors-25-01150" ref-type="bibr">10</xref>,<xref rid="B31-sensors-25-01150" ref-type="bibr">31</xref>]. A correlation analysis was applied to the selected parameters with the pain assessments, and the results proved the validity of our pain assessments. The SPI was calculated using the equation (SPI = 100 &#x02212; (0.7 &#x000d7; PPGA + 0.3 &#x000d7; HBI), where PPGA has the most contribution. This equation implies a negative correlation between nociception and PPGA or HBI, which was the case in our analysis, where PPGA correlated negatively with the assessments and the values were distributed in the range of &#x02212;(0.2&#x02013;0.82), as shown in <xref rid="sensors-25-01150-f012" ref-type="fig">Figure 12</xref>. This agrees with the correlation analysis performed in [<xref rid="B3-sensors-25-01150" ref-type="bibr">3</xref>] with pain stimulus intensity. The EEG parameters also showed an agreement with the results in [<xref rid="B32-sensors-25-01150" ref-type="bibr">32</xref>,<xref rid="B33-sensors-25-01150" ref-type="bibr">33</xref>], where the alpha band was reported to drop in the presence of painful stimuli. Other studies showed that the delta [<xref rid="B34-sensors-25-01150" ref-type="bibr">34</xref>] and beta bands [<xref rid="B35-sensors-25-01150" ref-type="bibr">35</xref>] increased with painful stimuli, and in our case, this was noted in many cases.</p><p>Inter- and intra-patient variability needs to be addressed carefully. Previously, methods such as histogram normalization and z-score normalization were adapted for online usage. In our study, both methods were effective; however, we noticed that some parameters&#x02019; properties were affected after applying those techniques. Therefore, we adapted another normalization method (i.e., Min&#x02013;Max normalization) for our use. The comparison between the three methods showed that for our data, the Min&#x02013;Max method is the most effective in retaining the original parameter properties while reducing both inter- and intra-patient variability.</p><p>In our study, both models used information from many sources, and both were based on experts&#x02019; assessments of pain. The models were evaluated in two groups: the first group was used to evaluate the models&#x02019; performances with the pain assessments (NTUH), and the second group was used to evaluate the models&#x02019; performances in the operation room (ECKH). On the NTUH datasets, the MLP model had a higher MAE and lower correlation compared to the LSTM model (<xref rid="sensors-25-01150-f018" ref-type="fig">Figure 18</xref> and <xref rid="sensors-25-01150-f022" ref-type="fig">Figure 22</xref>). When the predictions were visualized, however, we noticed that both models had predictions that generalized well around the pain assessments, with values from the LSTM model being lower and smoother. This difference was clear, and the LSTM predictions were not conclusive whether the current predicted value was related to nociception or not. On the other hand, the MLP predictions were more precise about the current state, whether it was related to nociception or not. This was proven in the prediction from the ECKH datasets. The predicted values before and after surgical events were compared. For the MLP model (<xref rid="sensors-25-01150-f019" ref-type="fig">Figure 19</xref>), the mean value after t<sub>1</sub> and t<sub>3</sub> increased the most, and it was more spread out after t3 (52&#x02013;69). The mean value of the difference before and after each event provided evidence that the MLP model was able to predict nociception at painful stimuli events, where it was 9 and 12 at t<sub>1</sub> and t<sub>3</sub>, respectively. While smaller than t<sub>1</sub> and t<sub>3</sub>, the increase after t<sub>2</sub> was still noticed; this was also proven in the difference before and after t<sub>2</sub>, where the mean value was 8. On the other hand, for the LSTM model (<xref rid="sensors-25-01150-f023" ref-type="fig">Figure 23</xref>), the mean values of the predicted nociception before and after each event were not large enough to distinguish between different levels of nociception. The largest increase in the predicted value was noticed after t2 and t3, where the difference between the means before and after the two events was also small (4).</p><p>The obtained results in <xref rid="sensors-25-01150-f019" ref-type="fig">Figure 19</xref> and <xref rid="sensors-25-01150-f023" ref-type="fig">Figure 23</xref> provide insights into the models&#x02019; behaviors at the defined events. In particular, the difference in the NOA mean at each event describes the ability of the model to distinguish a noxious stimulus. This was further proven by applying ROC on the defined events (<xref rid="sensors-25-01150-f025" ref-type="fig">Figure 25</xref>). The MLP model demonstrated more accurate predictions, achieving a mean AUC of 0.90 (range 0.82&#x02013;0.95). Hence, this indicates a distinctive assessment of nociception at various stages of surgery. In contrast, the LSTM model provided more variable performance, with a mean AUC value of 0.68 (range 0.44&#x02013;0.82). Considering the metrics used in our study, there is a clear gap in the performance of the two models that was noticed when evaluating the ECKH dataset. This could be related to different factors, including the complexity of LSTM models. Our iterative approach in training the LSTM model did not improve the results. The selection for LSTM was based on the fact that it considers previous knowledge, which could be beneficial in some cases. In our case, however, this might have been one of the limitations to our model. Moreover, we hypothesize that the significant difference in the models&#x02019; performances could be related to the fact that MLP models could capture hidden patterns and complex relationships accurately.</p><p>Delta arousal (power increase) and alpha dropout (power decrease) are related to noxious stimuli. In <xref rid="sensors-25-01150-f026" ref-type="fig">Figure 26</xref>, we show how every single parameter reacted during surgery against MLP and LSTM predictions. At t<sub>1</sub>, MLP predictions increased, which corresponded to delta arousal and alpha dropout. At t<sub>2</sub>, less reactive behavior was noticed from alpha and delta; similarly, PPGA smoothly decreased, and changes were not noticed in PPG<sub>AUC</sub>. Although MLP predictions reacted to these features, resulting in higher predictions, the LSTM model was unable to react to these changes. At t<sub>3</sub>, small changes in delta and alpha and a slow decrease in PPGA were noticed. Unlike the LSTM model, the MLP model was able to react to these changes. These results highlight the need for multiple parameter approaches. A model utilizing one parameter might ignore other information. An increase in PPGA is related to analgesia. As seen in the figure between t<sub>1</sub> and t<sub>2</sub>, PPGA increased in this time segment; this increase could be related to other factors. In the absence of other parameters, a model would predict this value as a decrease in nociception; however, in our case, the usage of multiple parameters provided sufficient data to the MLP model, which identified this as a noxious stimulus.</p><p>Our study aimed to enhance nociception monitoring in general anesthesia by developing a multimodal framework that integrates multiple physiological parameters, offering more comprehensive information for nociception assessment. We applied a comparative analysis of two models (MLP and LSTM) for nociception prediction, demonstrating their relevant strengths and limitations in different clinical settings. Our evaluation across two hospitals further supports the generalizability of these findings and the ability of our MLP model to be used in different clinical settings and patient populations. Our analysis for the used signals demonstrated the capability of EEG signals as an important source for pain assessment, which was further validated with the models&#x02019; results. Additionally, utilizing Min&#x02013;Max normalization for online and offline usage provided better results than histogram and z-score normalization. This was found when the correlation analysis was applied to the pain assessments with the used parameters. Initially, the raw parameters correlated to pain assessments; however, histogram normalization affected these results negatively. Exploring other methods used in the literature, such as the z-score, led to using another common normalization method (i.e., Min&#x02013;Max normalization).</p><p>Our analysis for model development focused on traditional regression metrics (MSE, MAE, and R<sup>2</sup>), given the continuous nature of our datasets. For model validations, a statistical comparison in the mean difference between events was utilized, and the models&#x02019; abilities to differentiate nociceptive events were tested using ROC curves. However, we acknowledge the importance of including performance metrics such as F1, precision, and recall. These metrics could be adopted in the future with larger datasets and various anesthesia settings.</p><p>Our previous studies about pain/nociception did not achieve this performance. We used SPI [<xref rid="B29-sensors-25-01150" ref-type="bibr">29</xref>] and ANI [<xref rid="B28-sensors-25-01150" ref-type="bibr">28</xref>] features to predict pain scores using LSTM and MLP models. The best model [<xref rid="B29-sensors-25-01150" ref-type="bibr">29</xref>] had a correlation of 0.63 and an MAE of 3.42; however, despite this difference in performance, the predictions did not generalize well to the pain assessments, which was due to insufficient information provided to the model. Hence, we solved this in our present study, and the results improved.</p><p>The types of surgeries and anesthesia administration methods could have an effect on the way the model predicts nociception. Our datasets were a combination of inhaled anesthesia and, in a few cases, TCI anesthesia. In both cases, propofol was used intravenously. Therefore, the findings in this study are more related to inhaled anesthesia. The MLP model was more useful in distinguishing the nociceptive reactions at different surgical events. However, this was noticed only when the models were evaluated on ECKH datasets. Considering the size of the dataset (10 patients), the size of the test dataset might not be enough to prove this. Therefore, future studies are needed to validate this result.</p></sec><sec sec-type="conclusions" id="sec5-sensors-25-01150"><title>5. Conclusions</title><p>We developed two multimodal models for nociception prediction in general anesthesia. The models use physiological parameters from various sources rather than relying solely on one signal&#x02019;s information. The developed models were correlated with an expert assessment of pain that was based on clinical information related to nociception and surgical stimulation events. Our investigation of normalization techniques revealed that Min&#x02013;Max normalization was optimal for both online and offline applications, preserving essential parameter characteristics. The models were evaluated across two hospitals with varying results. In the first group, both models demonstrated effective nociception prediction, with the LSTM model providing smoother predictions. In the second group, while LSTM models are typically powerful for sequence data problems, this advantage did not translate to better performance in our specific application. The MLP model successfully differentiated between nociception levels at various events, while the LSTM model&#x02019;s predictions were less definitive. Our results are promising; however, further studies are needed to validate these findings in different anesthesia settings and a larger patient population.</p></sec></body><back><ack><title>Acknowledgments</title><p>We acknowledge all patients and their surgeons for their contribution to this study.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, O.M.T.A.D. and S.-Z.F.; methodology, J.-S.S. and O.M.T.A.D.; software, O.M.T.A.D. and J.-S.S.; validation, S.-Z.F. and J.-S.S.; formal analysis, S.-Z.F. and J.-S.S.; investigation, O.M.T.A.D.; resources, J.-S.S. and S.-Z.F.; supervision, S.-Z.F. and J.-S.S.; project administration, O.M.T.A.D.; funding acquisition, S.-Z.F. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>This study was conducted in accordance with the Declaration of Helsinki and approved by the institutional IRB Board (NTUH IRB: 201302078RINC and ECK IRB: ECKIRB1111208).</p></notes><notes><title>Informed Consent Statement</title><p>Informed consent was obtained from all subjects involved in this study (or their legal guardians).</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>Data presented in the paper are available on request from the corresponding authors S.-Z.F. and J.-S.S.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01150"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Loeser</surname><given-names>J.D.</given-names></name>
<name><surname>Treede</surname><given-names>R.D.</given-names></name>
</person-group><article-title>The Kyoto protocol of IASP Basic Pain Terminology</article-title><source>Pain</source><year>2008</year><volume>137</volume><fpage>473</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1016/j.pain.2008.04.025</pub-id><pub-id pub-id-type="pmid">18583048</pub-id>
</element-citation></ref><ref id="B2-sensors-25-01150"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Schlereth</surname><given-names>T.</given-names></name>
<name><surname>Birklein</surname><given-names>F.</given-names></name>
</person-group><article-title>The sympathetic nervous system and pain</article-title><source>Neuromol. Med.</source><year>2008</year><volume>10</volume><fpage>141</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1007/s12017-007-8018-6</pub-id><pub-id pub-id-type="pmid">17990126</pub-id>
</element-citation></ref><ref id="B3-sensors-25-01150"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Huiku</surname><given-names>M.</given-names></name>
<name><surname>Uutela</surname><given-names>K.</given-names></name>
<name><surname>van Gils</surname><given-names>M.</given-names></name>
<name><surname>Korhonen</surname><given-names>I.</given-names></name>
<name><surname>Kymalainen</surname><given-names>M.</given-names></name>
<name><surname>Merilainen</surname><given-names>P.</given-names></name>
<name><surname>Paloheimo</surname><given-names>M.</given-names></name>
<name><surname>Rantanen</surname><given-names>M.</given-names></name>
<name><surname>Takala</surname><given-names>P.</given-names></name>
<name><surname>Viertio-Oja</surname><given-names>H.</given-names></name>
<etal/>
</person-group><article-title>Assessment of surgical stress during general anaesthesia</article-title><source>Br. J. Anaesth.</source><year>2007</year><volume>98</volume><fpage>447</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1093/bja/aem004</pub-id><pub-id pub-id-type="pmid">17329347</pub-id>
</element-citation></ref><ref id="B4-sensors-25-01150"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Gruenewald</surname><given-names>M.</given-names></name>
<name><surname>Ilies</surname><given-names>C.</given-names></name>
</person-group><article-title>Monitoring the nociception-anti-nociception balance</article-title><source>Best Pract. Res. Clin. Anaesthesiol.</source><year>2013</year><volume>27</volume><fpage>235</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1016/j.bpa.2013.06.007</pub-id><pub-id pub-id-type="pmid">24012235</pub-id>
</element-citation></ref><ref id="B5-sensors-25-01150"><label>5.</label><element-citation publication-type="patent"><person-group person-group-type="author">
<name><surname>Logier</surname><given-names>R.</given-names></name>
<name><surname>Jeanne</surname><given-names>M.</given-names></name>
<name><surname>Tavernier</surname><given-names>B.</given-names></name>
</person-group><article-title>Method and Device for Assessing Pain in Human Being</article-title><source>European Patent</source><patent>N 04370029.3</patent><day>20</day><month>September</month><year>2004</year></element-citation></ref><ref id="B6-sensors-25-01150"><label>6.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Jeanne</surname><given-names>M.</given-names></name>
<name><surname>Logier</surname><given-names>R.</given-names></name>
<name><surname>De Jonckheere</surname><given-names>J.</given-names></name>
<name><surname>Tavernier</surname><given-names>B.</given-names></name>
</person-group><article-title>Validation of a graphic measurement of heart rate variability to assess analgesia/nociception balance during general anesthesia</article-title><source>Proceedings of the 31st Annual International Conference of the IEEE EMBS</source><conf-loc>Minneapolis, MN, USA</conf-loc><conf-date>2&#x02013;6 September 2009</conf-date><volume>Volume 2009</volume><fpage>1840</fpage><lpage>1843</lpage><pub-id pub-id-type="doi">10.1109/IEMBS.2009.5332598</pub-id></element-citation></ref><ref id="B7-sensors-25-01150"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wheeler</surname><given-names>P.</given-names></name>
<name><surname>Hoffman</surname><given-names>W.E.</given-names></name>
<name><surname>Baughman</surname><given-names>V.L.</given-names></name>
<name><surname>Koenig</surname><given-names>H.</given-names></name>
</person-group><article-title>Response entropy increases during painful stimulation</article-title><source>J. Neurosurg. Anesthesiol.</source><year>2005</year><volume>17</volume><fpage>86</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1097/01.ana.0000151408.62650.b5</pub-id><pub-id pub-id-type="pmid">15840994</pub-id>
</element-citation></ref><ref id="B8-sensors-25-01150"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Coleman</surname><given-names>R.M.</given-names></name>
<name><surname>Tousignant-Laflamme</surname><given-names>Y.</given-names></name>
<name><surname>Ouellet</surname><given-names>P.</given-names></name>
<name><surname>Parenteau-Goudreault</surname><given-names>&#x000c9;.</given-names></name>
<name><surname>Cogan</surname><given-names>J.</given-names></name>
<name><surname>Bourgault</surname><given-names>P.</given-names></name>
</person-group><article-title>The Use of the Bispectral Index in the Detection of Pain in Mechanically Ventilated Adults in the Intensive Care Unit: A Review of the Literature</article-title><source>Pain Res. Manag.</source><year>2015</year><volume>20</volume><fpage>e33</fpage><lpage>e37</lpage><pub-id pub-id-type="doi">10.1155/2015/981419</pub-id><pub-id pub-id-type="pmid">25050877</pub-id>
</element-citation></ref><ref id="B9-sensors-25-01150"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Garcia</surname><given-names>P.S.</given-names></name>
<name><surname>Kreuzer</surname><given-names>M.</given-names></name>
<name><surname>Hight</surname><given-names>D.</given-names></name>
<name><surname>Sleigh</surname><given-names>J.W.</given-names></name>
</person-group><article-title>Effects of noxious stimulation on the electroencephalogram during general anaesthesia: A narrative review and approach to analgesic titration</article-title><source>Br. J. Anaesth.</source><year>2021</year><volume>126</volume><fpage>445</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1016/j.bja.2020.10.036</pub-id><pub-id pub-id-type="pmid">33461725</pub-id>
</element-citation></ref><ref id="B10-sensors-25-01150"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jensen</surname><given-names>E.W.</given-names></name>
<name><surname>Valencia</surname><given-names>J.F.</given-names></name>
<name><surname>Lopez</surname><given-names>A.</given-names></name>
<name><surname>Anglada</surname><given-names>T.</given-names></name>
<name><surname>Agusti</surname><given-names>M.</given-names></name>
<name><surname>Ramos</surname><given-names>Y.</given-names></name>
<name><surname>Serra</surname><given-names>R.</given-names></name>
<name><surname>Jospin</surname><given-names>M.</given-names></name>
<name><surname>Pineda</surname><given-names>P.</given-names></name>
<name><surname>Gambus</surname><given-names>P.</given-names></name>
</person-group><article-title>Monitoring hypnotic effect and nociception with two EEG-derived indices, qCON and qNOX, during general anaesthesia</article-title><source>Acta Anaesthesiol. Scand.</source><year>2014</year><volume>58</volume><fpage>933</fpage><lpage>941</lpage><pub-id pub-id-type="doi">10.1111/aas.12359</pub-id><pub-id pub-id-type="pmid">24995461</pub-id>
</element-citation></ref><ref id="B11-sensors-25-01150"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ben-Israel</surname><given-names>N.</given-names></name>
<name><surname>Kliger</surname><given-names>M.</given-names></name>
<name><surname>Zuckerman</surname><given-names>G.</given-names></name>
<name><surname>Katz</surname><given-names>Y.</given-names></name>
<name><surname>Edry</surname><given-names>R.</given-names></name>
</person-group><article-title>Monitoring the nociception level: A multi-parameter approach</article-title><source>J. Clin. Monit. Comput.</source><year>2013</year><volume>27</volume><fpage>659</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1007/s10877-013-9487-9</pub-id><pub-id pub-id-type="pmid">23835792</pub-id>
</element-citation></ref><ref id="B12-sensors-25-01150"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Rantanen</surname><given-names>M.</given-names></name>
<name><surname>Yli-Hankala</surname><given-names>A.</given-names></name>
<name><surname>van Gils</surname><given-names>M.</given-names></name>
<name><surname>Ypparila-Wolters</surname><given-names>H.</given-names></name>
<name><surname>Takala</surname><given-names>P.</given-names></name>
<name><surname>Huiku</surname><given-names>M.</given-names></name>
<name><surname>Kymalainen</surname><given-names>M.</given-names></name>
<name><surname>Seitsonen</surname><given-names>E.</given-names></name>
<name><surname>Korhonen</surname><given-names>I.</given-names></name>
</person-group><article-title>Novel multiparameter approach for measurement of nociception at skin incision during general anaesthesia</article-title><source>Br. J. Anaesth.</source><year>2006</year><volume>96</volume><fpage>367</fpage><lpage>376</lpage><pub-id pub-id-type="doi">10.1093/bja/ael005</pub-id><pub-id pub-id-type="pmid">16431883</pub-id>
</element-citation></ref><ref id="B13-sensors-25-01150"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Baliki</surname><given-names>M.N.</given-names></name>
<name><surname>Apkarian</surname><given-names>A.V.</given-names></name>
</person-group><article-title>Nociception, Pain, Negative Moods, and Behavior Selection</article-title><source>Neuron</source><year>2015</year><volume>87</volume><fpage>474</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.005</pub-id><pub-id pub-id-type="pmid">26247858</pub-id>
</element-citation></ref><ref id="B14-sensors-25-01150"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lichtner</surname><given-names>G.</given-names></name>
<name><surname>Auksztulewicz</surname><given-names>R.</given-names></name>
<name><surname>Velten</surname><given-names>H.</given-names></name>
<name><surname>Mavrodis</surname><given-names>D.</given-names></name>
<name><surname>Scheel</surname><given-names>M.</given-names></name>
<name><surname>Blankenburg</surname><given-names>F.</given-names></name>
<name><surname>von Dincklage</surname><given-names>F.</given-names></name>
</person-group><article-title>Nociceptive activation in spinal cord and brain persists during deep general anaesthesia</article-title><source>Br. J. Anaesth.</source><year>2018</year><volume>121</volume><fpage>291</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1016/j.bja.2018.03.031</pub-id><pub-id pub-id-type="pmid">29935584</pub-id>
</element-citation></ref><ref id="B15-sensors-25-01150"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Garland</surname><given-names>E.L.</given-names></name>
</person-group><article-title>Pain processing in the human nervous system: A selective review of nociceptive and biobehavioral pathways</article-title><source>Prim. Care</source><year>2012</year><volume>39</volume><fpage>561</fpage><lpage>571</lpage><pub-id pub-id-type="doi">10.1016/j.pop.2012.06.013</pub-id><pub-id pub-id-type="pmid">22958566</pub-id>
</element-citation></ref><ref id="B16-sensors-25-01150"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hartley</surname><given-names>C.</given-names></name>
<name><surname>Poorun</surname><given-names>R.</given-names></name>
<name><surname>Goksan</surname><given-names>S.</given-names></name>
<name><surname>Worley</surname><given-names>A.</given-names></name>
<name><surname>Boyd</surname><given-names>S.</given-names></name>
<name><surname>Rogers</surname><given-names>R.</given-names></name>
<name><surname>Ali</surname><given-names>T.</given-names></name>
<name><surname>Slater</surname><given-names>R.</given-names></name>
</person-group><article-title>Noxious stimulation in children receiving general anaesthesia evokes an increase in delta frequency brain activity</article-title><source>Pain</source><year>2014</year><volume>155</volume><fpage>2368</fpage><lpage>2376</lpage><pub-id pub-id-type="doi">10.1016/j.pain.2014.09.006</pub-id><pub-id pub-id-type="pmid">25218826</pub-id>
</element-citation></ref><ref id="B17-sensors-25-01150"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ekman</surname><given-names>A.</given-names></name>
<name><surname>Flink</surname><given-names>R.</given-names></name>
<name><surname>Sundman</surname><given-names>E.</given-names></name>
<name><surname>Eriksson</surname><given-names>L.I.</given-names></name>
<name><surname>Brudin</surname><given-names>L.</given-names></name>
<name><surname>Sandin</surname><given-names>R.</given-names></name>
</person-group><article-title>Neuromuscular block and the electroencephalogram during sevoflurane anaesthesia</article-title><source>Neuroreport</source><year>2007</year><volume>18</volume><fpage>1817</fpage><lpage>1820</lpage><pub-id pub-id-type="doi">10.1097/WNR.0b013e3282f13e11</pub-id><pub-id pub-id-type="pmid">18090318</pub-id>
</element-citation></ref><ref id="B18-sensors-25-01150"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kox</surname><given-names>W.J.</given-names></name>
<name><surname>von Heymann</surname><given-names>C.</given-names></name>
<name><surname>Heinze</surname><given-names>J.</given-names></name>
<name><surname>Prichep</surname><given-names>L.S.</given-names></name>
<name><surname>John</surname><given-names>E.R.</given-names></name>
<name><surname>Rundshagen</surname><given-names>I.</given-names></name>
</person-group><article-title>Electroencephalographic mapping during routine clinical practice: Cortical arousal during tracheal intubation?</article-title><source>Anesth. Analg.</source><year>2006</year><volume>102</volume><fpage>825</fpage><lpage>831</lpage><pub-id pub-id-type="doi">10.1213/01.ane.0000197776.26307.fa</pub-id><pub-id pub-id-type="pmid">16492836</pub-id>
</element-citation></ref><ref id="B19-sensors-25-01150"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ropcke</surname><given-names>H.</given-names></name>
<name><surname>Rehberg</surname><given-names>B.</given-names></name>
<name><surname>Koenen-Bergmann</surname><given-names>M.</given-names></name>
<name><surname>Bouillon</surname><given-names>T.</given-names></name>
<name><surname>Bruhn</surname><given-names>J.</given-names></name>
<name><surname>Hoeft</surname><given-names>A.</given-names></name>
</person-group><article-title>Surgical stimulation shifts EEG concentration-response relationship of desflurane</article-title><source>Anesthesiology</source><year>2001</year><volume>94</volume><fpage>390</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1097/00000542-200103000-00006</pub-id><pub-id pub-id-type="pmid">11374596</pub-id>
</element-citation></ref><ref id="B20-sensors-25-01150"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hochreiter</surname><given-names>S.</given-names></name>
<name><surname>Schmidhuber</surname><given-names>J.</given-names></name>
</person-group><article-title>Long short-term memory</article-title><source>Neural Comput.</source><year>1997</year><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="pmid">9377276</pub-id>
</element-citation></ref><ref id="B21-sensors-25-01150"><label>21.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Park</surname><given-names>Y.-S.</given-names></name>
<name><surname>Lek</surname><given-names>S.</given-names></name>
</person-group><article-title>Artificial neural networks: Multilayer perceptron for ecological modeling</article-title><source>Developments in Environmental Modelling</source><publisher-name>Elsevier</publisher-name><publisher-loc>Amsterdam, The Netherlands</publisher-loc><year>2016</year><volume>Volume 28</volume><fpage>123</fpage><lpage>140</lpage></element-citation></ref><ref id="B22-sensors-25-01150"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pedregosa</surname><given-names>F.</given-names></name>
<name><surname>Varoquaux</surname><given-names>G.</given-names></name>
<name><surname>Gramfort</surname><given-names>A.</given-names></name>
<name><surname>Michel</surname><given-names>V.</given-names></name>
<name><surname>Thirion</surname><given-names>B.</given-names></name>
<name><surname>Grisel</surname><given-names>O.</given-names></name>
<name><surname>Blondel</surname><given-names>M.</given-names></name>
<name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
<name><surname>Weiss</surname><given-names>R.</given-names></name>
<name><surname>Dubourg</surname><given-names>V.</given-names></name>
</person-group><article-title>Scikit-learn: Machine learning in Python</article-title><source>J. Mach. Learn. Res.</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="B23-sensors-25-01150"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pan</surname><given-names>J.</given-names></name>
<name><surname>Tompkins</surname><given-names>W.J.</given-names></name>
</person-group><article-title>A real-time QRS detection algorithm</article-title><source>IEEE Trans. Biomed. Eng.</source><year>1985</year><volume>32</volume><fpage>230</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1109/TBME.1985.325532</pub-id><pub-id pub-id-type="pmid">3997178</pub-id>
</element-citation></ref><ref id="B24-sensors-25-01150"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Scholkmann</surname><given-names>F.</given-names></name>
<name><surname>Boss</surname><given-names>J.</given-names></name>
<name><surname>Wolf</surname><given-names>M.</given-names></name>
</person-group><article-title>An efficient algorithm for automatic peak detection in noisy periodic and quasi-periodic signals</article-title><source>Algorithms</source><year>2012</year><volume>5</volume><fpage>588</fpage><lpage>603</lpage><pub-id pub-id-type="doi">10.3390/a5040588</pub-id></element-citation></ref><ref id="B25-sensors-25-01150"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Charlton</surname><given-names>P.H.</given-names></name>
<name><surname>Kotzen</surname><given-names>K.</given-names></name>
<name><surname>Mejia-Mejia</surname><given-names>E.</given-names></name>
<name><surname>Aston</surname><given-names>P.J.</given-names></name>
<name><surname>Budidha</surname><given-names>K.</given-names></name>
<name><surname>Mant</surname><given-names>J.</given-names></name>
<name><surname>Pettit</surname><given-names>C.</given-names></name>
<name><surname>Behar</surname><given-names>J.A.</given-names></name>
<name><surname>Kyriacou</surname><given-names>P.A.</given-names></name>
</person-group><article-title>Detecting beats in the photoplethysmogram: Benchmarking open-source algorithms</article-title><source>Physiol. Meas.</source><year>2022</year><volume>43</volume><fpage>085007</fpage><pub-id pub-id-type="doi">10.1088/1361-6579/ac826d</pub-id><pub-id pub-id-type="pmid">35853440</pub-id>
</element-citation></ref><ref id="B26-sensors-25-01150"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bland</surname><given-names>J.M.</given-names></name>
<name><surname>Altman</surname><given-names>D.G.</given-names></name>
</person-group><article-title>Measuring agreement in method comparison studies</article-title><source>Stat. Methods Med. Res.</source><year>1999</year><volume>8</volume><fpage>135</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1177/096228029900800204</pub-id><pub-id pub-id-type="pmid">10501650</pub-id>
</element-citation></ref><ref id="B27-sensors-25-01150"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cicchetti</surname><given-names>D.V.</given-names></name>
</person-group><article-title>Guidelines, criteria, and rules of thumb for evaluating normed and standardized assessment instruments in psychology</article-title><source>Psychol. Assess.</source><year>1994</year><volume>6</volume><fpage>284</fpage><pub-id pub-id-type="doi">10.1037/1040-3590.6.4.284</pub-id></element-citation></ref><ref id="B28-sensors-25-01150"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jean</surname><given-names>W.-H.</given-names></name>
<name><surname>Sutikno</surname><given-names>P.</given-names></name>
<name><surname>Fan</surname><given-names>S.-Z.</given-names></name>
<name><surname>Abbod</surname><given-names>M.F.</given-names></name>
<name><surname>Shieh</surname><given-names>J.-S.</given-names></name>
</person-group><article-title>Comparison of Deep Learning Algorithms in Predicting Expert Assessments of Pain Scores during Surgical Operations Using Analgesia Nociception Index</article-title><source>Sensors</source><year>2022</year><volume>22</volume><elocation-id>5496</elocation-id><pub-id pub-id-type="doi">10.3390/s22155496</pub-id><pub-id pub-id-type="pmid">35897999</pub-id>
</element-citation></ref><ref id="B29-sensors-25-01150"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Abdel Deen</surname><given-names>O.M.T.</given-names></name>
<name><surname>Jean</surname><given-names>W.-H.</given-names></name>
<name><surname>Fan</surname><given-names>S.-Z.</given-names></name>
<name><surname>Abbod</surname><given-names>M.F.</given-names></name>
<name><surname>Shieh</surname><given-names>J.-S.</given-names></name>
</person-group><article-title>Pain scores estimation using surgical pleth index and long short-term memory neural networks</article-title><source>Artif. Life Robot.</source><year>2023</year><volume>28</volume><fpage>600</fpage><lpage>608</lpage><pub-id pub-id-type="doi">10.1007/s10015-023-00880-0</pub-id></element-citation></ref><ref id="B30-sensors-25-01150"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Melia</surname><given-names>U.</given-names></name>
<name><surname>Gabarron</surname><given-names>E.</given-names></name>
<name><surname>Agust&#x000ed;</surname><given-names>M.</given-names></name>
<name><surname>Souto</surname><given-names>N.</given-names></name>
<name><surname>Pineda</surname><given-names>P.</given-names></name>
<name><surname>Fontanet</surname><given-names>J.</given-names></name>
<name><surname>Vallverdu</surname><given-names>M.</given-names></name>
<name><surname>Jensen</surname><given-names>E.W.</given-names></name>
<name><surname>Gambus</surname><given-names>P.</given-names></name>
</person-group><article-title>Comparison of the qCON and qNOX indices for the assessment of unconsciousness level and noxious stimulation response during surgery</article-title><source>J. Clin. Monit. Comput.</source><year>2017</year><volume>31</volume><fpage>1273</fpage><lpage>1281</lpage><pub-id pub-id-type="doi">10.1007/s10877-016-9948-z</pub-id><pub-id pub-id-type="pmid">27766525</pub-id>
</element-citation></ref><ref id="B31-sensors-25-01150"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Anders</surname><given-names>M.</given-names></name>
<name><surname>Anders</surname><given-names>B.</given-names></name>
<name><surname>Dreismickenbecker</surname><given-names>E.</given-names></name>
<name><surname>Hight</surname><given-names>D.</given-names></name>
<name><surname>Kreuzer</surname><given-names>M.</given-names></name>
<name><surname>Walter</surname><given-names>C.</given-names></name>
<name><surname>Zinn</surname><given-names>S.</given-names></name>
</person-group><article-title>EEG responses to standardised noxious stimulation during clinical anaesthesia: A pilot study</article-title><source>BJA Open</source><year>2023</year><volume>5</volume><fpage>100118</fpage><pub-id pub-id-type="doi">10.1016/j.bjao.2022.100118</pub-id><pub-id pub-id-type="pmid">37587999</pub-id>
</element-citation></ref><ref id="B32-sensors-25-01150"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hight</surname><given-names>D.F.</given-names></name>
<name><surname>Gaskell</surname><given-names>A.L.</given-names></name>
<name><surname>Kreuzer</surname><given-names>M.</given-names></name>
<name><surname>Voss</surname><given-names>L.J.</given-names></name>
<name><surname>Garc&#x000ed;a</surname><given-names>P.S.</given-names></name>
<name><surname>Sleigh</surname><given-names>J.W.</given-names></name>
</person-group><article-title>Transient electroencephalographic alpha power loss during maintenance of general anaesthesia</article-title><source>Br. J. Anaesth.</source><year>2019</year><volume>122</volume><fpage>635</fpage><lpage>642</lpage><pub-id pub-id-type="doi">10.1016/j.bja.2018.11.029</pub-id><pub-id pub-id-type="pmid">30915994</pub-id>
</element-citation></ref><ref id="B33-sensors-25-01150"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hagihira</surname><given-names>S.</given-names></name>
<name><surname>Takashina</surname><given-names>M.</given-names></name>
<name><surname>Mori</surname><given-names>T.</given-names></name>
<name><surname>Ueyama</surname><given-names>H.</given-names></name>
<name><surname>Mashimo</surname><given-names>T.</given-names></name>
</person-group><article-title>Electroencephalographic bicoherence is sensitive to noxious stimuli during isoflurane or sevoflurane anesthesia</article-title><source>J. Am. Soc. Anesthesiol.</source><year>2004</year><volume>100</volume><fpage>818</fpage><lpage>825</lpage><pub-id pub-id-type="doi">10.1097/00000542-200404000-00011</pub-id></element-citation></ref><ref id="B34-sensors-25-01150"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kochs</surname><given-names>E.</given-names></name>
<name><surname>Bischoff</surname><given-names>P.</given-names></name>
<name><surname>Pichlmeier</surname><given-names>U.</given-names></name>
<name><surname>Schulte am Esch</surname><given-names>J.</given-names></name>
</person-group><article-title>Surgical stimulation induces changes in brain electrical activity during isoflurane/nitrous oxide anesthesia. A topographic electroencephalographic analysis</article-title><source>Anesthesiology</source><year>1994</year><volume>80</volume><fpage>1026</fpage><lpage>1034</lpage><pub-id pub-id-type="doi">10.1097/00000542-199405000-00012</pub-id><pub-id pub-id-type="pmid">8017642</pub-id>
</element-citation></ref><ref id="B35-sensors-25-01150"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Rundshagen</surname><given-names>I.</given-names></name>
<name><surname>Schr&#x000f6;der</surname><given-names>T.</given-names></name>
<name><surname>Heinze</surname><given-names>J.</given-names></name>
<name><surname>Prichep</surname><given-names>L.</given-names></name>
<name><surname>John</surname><given-names>E.</given-names></name>
<name><surname>Kox</surname><given-names>W.</given-names></name>
</person-group><article-title>Topographic electroencephalography: Endotracheal intubation during anaesthesia with propofol/fentanyl</article-title><source>Anasthesiol. Intensivmed. Notfallmedizin Schmerzther. AINS</source><year>2005</year><volume>40</volume><fpage>633</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1055/s-2005-870464</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01150-f001"><label>Figure 1</label><caption><p>Flowchart of the methods used in this study. This flowchart briefly lists the methods used in this study.</p></caption><graphic xlink:href="sensors-25-01150-g001" position="float"/></fig><fig position="float" id="sensors-25-01150-f002"><label>Figure 2</label><caption><p>A 16 s ECG signal before (<bold>upper plot</bold>) and after (<bold>lower plot</bold>) filtering. The RR is calculated as the duration between each 2 successive R peaks.</p></caption><graphic xlink:href="sensors-25-01150-g002" position="float"/></fig><fig position="float" id="sensors-25-01150-f003"><label>Figure 3</label><caption><p>Raw PPG signal before (<bold>upper plot</bold>) and after (<bold>lower plot</bold>) filtering. The figure shows how the filter scheme enhanced some of the corrupted waveforms.</p></caption><graphic xlink:href="sensors-25-01150-g003" position="float"/></fig><fig position="float" id="sensors-25-01150-f004"><label>Figure 4</label><caption><p>Raw EEG signal and its extracted bands. The frequency range used for each band is described below. The figure shows an example of each EEG band with different color. The waveforms are labeled with their corresponding band from top to bottom (Raw EEG, Delta band, Theta band, Alpha band, Beta band, and Gamma band).</p></caption><graphic xlink:href="sensors-25-01150-g004" position="float"/></fig><fig position="float" id="sensors-25-01150-f005"><label>Figure 5</label><caption><p>Data segmentation. (<bold>a</bold>) All signals were divided into 64 s windows. The windows overlapped with 59 s. After the first window is processed, the next window contains 59 s samples from the previous window and new 5 s samples. (<bold>b</bold>) For power calculations, the EEG and RRHF 64 s windows were divided into four segments of 16 s durations.</p></caption><graphic xlink:href="sensors-25-01150-g005a" position="float"/><graphic xlink:href="sensors-25-01150-g005b" position="float"/></fig><fig position="float" id="sensors-25-01150-f006"><label>Figure 6</label><caption><p>Histogram-based normalization. The <bold>upper plots</bold> show the dataset&#x02019;s distribution, and the <bold>lower plots</bold> show the cdf. The equation in the figure shows the weights assigned to each transformation.</p></caption><graphic xlink:href="sensors-25-01150-g006" position="float"/></fig><fig position="float" id="sensors-25-01150-f007"><label>Figure 7</label><caption><p>Details of the used LSTM model. The input parameters consist of 8 features, with a time step of 5 points. The data were originally processed in segments of 64 s with 59 s overlapping, which means that to predict one value, the model needs to wait first for 64 s to be processed before the prediction is made, and after the first window, it only waited for 5 s. PS refers to the power spectral estimation.</p></caption><graphic xlink:href="sensors-25-01150-g007" position="float"/></fig><fig position="float" id="sensors-25-01150-f008"><label>Figure 8</label><caption><p>Details of the used neural network model. The input parameters here are one input per five seconds. After the first 64 s segment is available, it results in one prediction, and the segment is then updated by the next available 5 s data.</p></caption><graphic xlink:href="sensors-25-01150-g008" position="float"/></fig><fig position="float" id="sensors-25-01150-f009"><label>Figure 9</label><caption><p>ICC test results. The figure shows the ICC results across each patient individually; the bar values (<italic toggle="yes">y</italic>-axis) represent the counts. The ICC result was in the corresponding range (<italic toggle="yes">x</italic>-axis).</p></caption><graphic xlink:href="sensors-25-01150-g009" position="float"/></fig><fig position="float" id="sensors-25-01150-f010"><label>Figure 10</label><caption><p>ANOVA test results. The mean value and interval plots for each doctor are shown in the figure.</p></caption><graphic xlink:href="sensors-25-01150-g010" position="float"/></fig><fig position="float" id="sensors-25-01150-f011"><label>Figure 11</label><caption><p>Agreement on a pairwise basis between each doctor&#x02019;s assessment. The black dots represent the difference between each paired data points (<italic toggle="yes">y</italic>-axis) against their mean (<italic toggle="yes">x</italic>-axis). The blue horizontal lines represent the bias (mean difference), while the red dashed lines indicate the 95% limits of agreement (&#x000b1;1.96 SD). The green dotted lines represent zero bias (ideal).</p></caption><graphic xlink:href="sensors-25-01150-g011" position="float"/></fig><fig position="float" id="sensors-25-01150-f012"><label>Figure 12</label><caption><p>Correlation coefficients between parameters and pain assessments. The plot shows the distribution of the correlation coefficients for the 90 patients. The median is shown in the box (the red vertical line). The high and low quartiles are shown, and the outliers are marked with black open circles.</p></caption><graphic xlink:href="sensors-25-01150-g012" position="float"/></fig><fig position="float" id="sensors-25-01150-f013"><label>Figure 13</label><caption><p>An example of the parameters used in this study. The <italic toggle="yes">x</italic>-axis is the sample index, and the <italic toggle="yes">y</italic>-axis is the parameter value. The EEG bands and RRHF are in (dB) power spectral. Waveforms are represented using different colors from top to bottom (PPG<sub>AUC</sub>, PPGA, RRHF, Gamma, Beta, Alpha, Theta, and Delta).</p></caption><graphic xlink:href="sensors-25-01150-g013" position="float"/></fig><fig position="float" id="sensors-25-01150-f014"><label>Figure 14</label><caption><p>An example of the correlation analysis for one patient. The correlation coefficients are shown in different bar colors, and the <italic toggle="yes">t</italic>-test values with a significance level of 0.05 are in black bars. The plot shows PPGA with the highest correlation value (&#x02212;0.73).</p></caption><graphic xlink:href="sensors-25-01150-g014" position="float"/></fig><fig position="float" id="sensors-25-01150-f015"><label>Figure 15</label><caption><p>Performance comparison between normalization methods against the raw parameters. The <bold>upper plot</bold> is the score based on the normalized MAE and correlation, and the <bold>lower plot</bold> shows the normalized metrics. The figure shows Min&#x02013;Max normalization with the lowest MAE and histogram normalization with the highest correlation. The overall score shows the Min&#x02013;Max normalization with the best score, and, therefore, it was used in our algorithm. The raw parameter was normalized as if all data were already available. Therefore, the weights w<sub>1</sub> and w<sub>2</sub> were fixed at 0.7 for the individual (accumulated) dataset and 0.3 for the group dataset.</p></caption><graphic xlink:href="sensors-25-01150-g015" position="float"/></fig><fig position="float" id="sensors-25-01150-f016"><label>Figure 16</label><caption><p>Example of the online and offline normalization for one patient (PPG<sub>AUC</sub>). The figure shows how histogram normalization either maximized or minimized the parameter value in online implementation, whereas Min&#x02013;Max and z-score maintained results closer to the offline implementation.</p></caption><graphic xlink:href="sensors-25-01150-g016" position="float"/></fig><fig position="float" id="sensors-25-01150-f017"><label>Figure 17</label><caption><p>Training and validation loss for the MLP model. The training and validation loss curves are shown as a solid and a dashed line, respectively.</p></caption><graphic xlink:href="sensors-25-01150-g017" position="float"/></fig><fig position="float" id="sensors-25-01150-f018"><label>Figure 18</label><caption><p>Correlation analysis and error results (MLP). The <bold>upper plot</bold> shows the distribution of the correlation values across the test dataset (NTUH) with the pain assessments, and the <bold>lower plot</bold> shows the MAE results.</p></caption><graphic xlink:href="sensors-25-01150-g018" position="float"/></fig><fig position="float" id="sensors-25-01150-f019"><label>Figure 19</label><caption><p>Nociception reactions at different events during surgery. These values were obtained by the MLP model. The <bold>upper plot</bold> shows the distributions before and after the event for the 10 patients together. The <italic toggle="yes">x</italic>-axis is the time at which a surgical stimulus happened, and the <italic toggle="yes">y</italic>-axis is the distribution of the values during the time before and after (the whiskers) the event. The mean value for each event is shown by the closed circle. The <bold>lower plot</bold> shows the difference in means before and after the events. The error bars represent the standard error, and the closed circles are for the difference in means. The <italic toggle="yes">p</italic>-value for all events was <italic toggle="yes">p</italic> &#x0003c; 0.01 using the Mann&#x02013;Whitney test. The difference in means (SEs) were 9 (3), 8 (2.7), and 14 (4).</p></caption><graphic xlink:href="sensors-25-01150-g019" position="float"/></fig><fig position="float" id="sensors-25-01150-f020"><label>Figure 20</label><caption><p>An example of the predicted nociception from the NTUH test dataset. The figure shows how both predictions implied a strong positive correlation and low error with pain assessment.</p></caption><graphic xlink:href="sensors-25-01150-g020" position="float"/></fig><fig position="float" id="sensors-25-01150-f021"><label>Figure 21</label><caption><p>Training and validation loss for the LSTM model. The training and validation loss curves are shown as a solid and a dashed line, respectively.</p></caption><graphic xlink:href="sensors-25-01150-g021" position="float"/></fig><fig position="float" id="sensors-25-01150-f022"><label>Figure 22</label><caption><p>Correlation analysis and error results. The <bold>upper plot</bold> shows the distribution of the correlation values across the test dataset (NTUH) with the pain assessments, and the <bold>lower plot</bold> shows the MAE results.</p></caption><graphic xlink:href="sensors-25-01150-g022" position="float"/></fig><fig position="float" id="sensors-25-01150-f023"><label>Figure 23</label><caption><p>Nociception reactions at different events during surgery (LSTM model). The <bold>upper plot</bold> shows the distributions of the mean values before and after the event for the ten patients together. The <italic toggle="yes">x</italic>-axis is the time at which a surgical stimulus happened, and the <italic toggle="yes">y</italic>-axis is the distribution of the values during the time before and after (the whiskers) the event. The mean value for each event is shown by the closed circle. The <bold>lower plot</bold> shows the difference in the means before and after the events. The error bars represent the standard error, and the closed circles represent the difference in means. The <italic toggle="yes">p</italic>-value for all events was <italic toggle="yes">p</italic> &#x0003c; 0.01 using the Mann&#x02013;Whitney test. The differences in the means (SEs) were 2.5 (5.9), 4 (2), and 4 (3).</p></caption><graphic xlink:href="sensors-25-01150-g023" position="float"/></fig><fig position="float" id="sensors-25-01150-f024"><label>Figure 24</label><caption><p>Example of MLP and LSTM predictions from ECKH. The 3 defined events are marked with vertical dashed lines. The figure shows how the MLP predictions reacted better at all events than LSTM.</p></caption><graphic xlink:href="sensors-25-01150-g024" position="float"/></fig><fig position="float" id="sensors-25-01150-f025"><label>Figure 25</label><caption><p>Receiver operating curve (ROC) results. The ROC illustrates the ability of the two models to distinguish noxious stimuli at t<sub>1</sub>, t<sub>2</sub>, and t<sub>3</sub>. The subfigures from (<bold>a</bold>&#x02013;<bold>j</bold>) correspond to individual patients, ordered sequentially, where each subfigure presents the ROC curve for the respective patient. The black dashed line in each ROC plot represents the performance of a non-discriminatory or random classifier. The results show MLP with more reactivity and ability to differentiate noxious stimuli, where the mean value for the area under the curve (AUC) across the 10 patients was 0.90.</p></caption><graphic xlink:href="sensors-25-01150-g025a" position="float"/><graphic xlink:href="sensors-25-01150-g025b" position="float"/></fig><fig position="float" id="sensors-25-01150-f026"><label>Figure 26</label><caption><p>An example of parameter trends against LSTM and MLP predictions. The figure illustrates how each model behaved differently according to the parameters&#x02019; changes, with the MLP model demonstrating better reactivity.</p></caption><graphic xlink:href="sensors-25-01150-g026" position="float"/></fig><table-wrap position="float" id="sensors-25-01150-t001"><object-id pub-id-type="pii">sensors-25-01150-t001_Table 1</object-id><label>Table 1</label><caption><p>Patient demographic. Fentanyl and propofol were administered intravenously.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">NTUH</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">ECKH</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Range</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mean &#x000b1; SD</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Range</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mean &#x000b1; SD</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Age (yr)</td><td align="center" valign="middle" rowspan="1" colspan="1">22&#x02013;78</td><td align="center" valign="middle" rowspan="1" colspan="1">48 &#x000b1; 12</td><td align="center" valign="middle" rowspan="1" colspan="1">40&#x02013;67</td><td align="center" valign="middle" rowspan="1" colspan="1">57 &#x000b1; 10</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Weight (kg)</td><td align="center" valign="middle" rowspan="1" colspan="1">40&#x02013;160</td><td align="center" valign="middle" rowspan="1" colspan="1">59 &#x000b1; 14</td><td align="center" valign="middle" rowspan="1" colspan="1">41&#x02013;93</td><td align="center" valign="middle" rowspan="1" colspan="1">68 &#x000b1; 18</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Height (cm)</td><td align="center" valign="middle" rowspan="1" colspan="1">138&#x02013;185</td><td align="center" valign="middle" rowspan="1" colspan="1">157 &#x000b1; 7</td><td align="center" valign="middle" rowspan="1" colspan="1">150&#x02013;189</td><td align="center" valign="middle" rowspan="1" colspan="1">166 &#x000b1; 15</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Fentanyl IV (&#x000b5;g)</td><td align="center" valign="middle" rowspan="1" colspan="1">50&#x02013;205</td><td align="center" valign="middle" rowspan="1" colspan="1">117 &#x000b1; 42</td><td align="center" valign="middle" rowspan="1" colspan="1">50&#x02013;100</td><td align="center" valign="middle" rowspan="1" colspan="1">80 &#x000b1; 27</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Propofol IV (mg)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50&#x02013;250</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">124 &#x000b1; 30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90&#x02013;200</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">122 &#x000b1; 45</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01150-t002"><object-id pub-id-type="pii">sensors-25-01150-t002_Table 2</object-id><label>Table 2</label><caption><p>Models&#x02019; specifications. The activation within the hidden layers were, by default, sigmoid for the LSTM model and ReLU for MLP.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Hidden Layers</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Neurons</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Batch Size</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Epochs</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Learning Rate</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Optimizer</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Activation (Output)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">MLP</td><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">50/30</td><td align="center" valign="middle" rowspan="1" colspan="1">125</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">Adam</td><td align="center" valign="middle" rowspan="1" colspan="1">ReLU</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LSTM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100/200</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">256</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Adam</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ReLU</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01150-t003"><object-id pub-id-type="pii">sensors-25-01150-t003_Table 3</object-id><label>Table 3</label><caption><p>Bland&#x02013;Altman test results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Group1</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Group2</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">SD</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Bias</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Agreement (%)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">A</td><td align="center" valign="middle" rowspan="1" colspan="1">B</td><td align="center" valign="middle" rowspan="1" colspan="1">7.40</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02212;1.22</td><td align="center" valign="middle" rowspan="1" colspan="1">95.00</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">A</td><td align="center" valign="middle" rowspan="1" colspan="1">C</td><td align="center" valign="middle" rowspan="1" colspan="1">9.11</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02212;1.92</td><td align="center" valign="middle" rowspan="1" colspan="1">96.00</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">A</td><td align="center" valign="middle" rowspan="1" colspan="1">E</td><td align="center" valign="middle" rowspan="1" colspan="1">8.52</td><td align="center" valign="middle" rowspan="1" colspan="1">4.32</td><td align="center" valign="middle" rowspan="1" colspan="1">95.00</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">B</td><td align="center" valign="middle" rowspan="1" colspan="1">C</td><td align="center" valign="middle" rowspan="1" colspan="1">8.55</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x02212;0.7</td><td align="center" valign="middle" rowspan="1" colspan="1">95.00</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">B</td><td align="center" valign="middle" rowspan="1" colspan="1">E</td><td align="center" valign="middle" rowspan="1" colspan="1">7.70</td><td align="center" valign="middle" rowspan="1" colspan="1">5.55</td><td align="center" valign="middle" rowspan="1" colspan="1">95.01</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">C</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">E</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8.01</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">95.00</td></tr></tbody></table></table-wrap></floats-group></article>