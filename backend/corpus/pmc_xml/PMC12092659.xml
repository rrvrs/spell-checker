<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">BJC Rep</journal-id><journal-id journal-id-type="iso-abbrev">BJC Rep</journal-id><journal-title-group><journal-title>BJC Reports</journal-title></journal-title-group><issn pub-type="epub">2731-9377</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40394100</article-id><article-id pub-id-type="pmc">PMC12092659</article-id>
<article-id pub-id-type="publisher-id">147</article-id><article-id pub-id-type="doi">10.1038/s44276-025-00147-0</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Deep learning-based interpretable prediction of recurrence of diffuse large B-cell lymphoma</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Naji</surname><given-names>Hussein</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Hahn</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Pisula</surname><given-names>Juan I.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Ugliano</surname><given-names>Stefano</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Simon</surname><given-names>Adrian</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>B&#x000fc;ttner</surname><given-names>Reinhard</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Bozek</surname><given-names>Katarzyna</given-names></name><address><email>k.bozek@uni-koeln.de</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00rcxh774</institution-id><institution-id institution-id-type="GRID">grid.6190.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 8580 3777</institution-id><institution>Institute for Biomedical Informatics, Faculty of Medicine and University Hospital Cologne, </institution><institution>University of Cologne, </institution></institution-wrap>Cologne, Germany </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00rcxh774</institution-id><institution-id institution-id-type="GRID">grid.6190.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 8580 3777</institution-id><institution>Center for Molecular Medicine Cologne (CMMC), Faculty of Medicine and University Hospital Cologne, </institution><institution>University of Cologne, </institution></institution-wrap>Cologne, Germany </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05mxhda18</institution-id><institution-id institution-id-type="GRID">grid.411097.a</institution-id><institution-id institution-id-type="ISNI">0000 0000 8852 305X</institution-id><institution>Institute of Pathology, </institution><institution>University Hospital Cologne, </institution></institution-wrap>Cologne, Germany </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00rcxh774</institution-id><institution-id institution-id-type="GRID">grid.6190.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 8580 3777</institution-id><institution>Cologne Excellence Cluster on Cellular Stress Responses in Aging-Associated Diseases (CECAD), </institution><institution>University of Cologne, </institution></institution-wrap>Cologne, Germany </aff></contrib-group><pub-date pub-type="epub"><day>20</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>20</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>3</volume><elocation-id>34</elocation-id><history><date date-type="received"><day>17</day><month>6</month><year>2024</year></date><date date-type="rev-recd"><day>28</day><month>3</month><year>2025</year></date><date date-type="accepted"><day>21</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">The heterogeneous and aggressive nature of diffuse large B-cell lymphoma (DLBCL) presents significant treatment challenges as up to 50% of patients experience recurrence of disease after chemotherapy. Upfront detection of recurring patients could offer alternative treatments. Deep learning has shown potential in predicting recurrence of various cancer types but suffers from lack of interpretability. Particularly in prediction of recurrence, an understanding of the model&#x02019;s decision could eventually result in novel treatments.</p></sec><sec><title>Methods</title><p id="Par2">We developed a deep learning-based pipeline to predict recurrence of DLBCL based on histological images of a publicly available cohort. We utilized attention-based classification to highlight areas within the images that were of high relevance for the model&#x02019;s classification. Subsequently, we segmented the nuclei within these areas, calculated morphological features, and statistically analyzed them to find differences between recurred and non-recurred patients.</p></sec><sec><title>Results</title><p id="Par3">We achieved an f1 score of 0.88 indicating that our model can distinguish non-recurred from recurred patients. Additionally, we found that features that are the most predictive of recurrence include large and irregularly shaped tumor cell nuclei.</p></sec><sec><title>Discussion</title><p id="Par4">Our work underlines the value of histological images in predicting treatment outcomes and enhances our understanding of complex biological processes in aggressive, heterogeneous cancers like DLBCL.</p></sec></abstract><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium f&#x000fc;r Bildung und Forschung</institution></institution-wrap></funding-source><award-id>01ZX1917B</award-id><award-id>01ZX1917B</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100014690</institution-id><institution>Ministerium f&#x000fc;r Kultur und Wissenschaft des Landes Nordrhein-Westfalen</institution></institution-wrap></funding-source><award-id>311-8.03.03.02-147635</award-id><award-id>311-8.03.03.02-147635</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>325931972</award-id><award-id>325931972</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par5">Diffuse large B-cell lymphoma (DLBCL) represents the most prevalent form of non-Hodgkin&#x02019;s lymphoma (NHL) in adults, accounting for 30&#x02013;40% of all NHL cases. It originates from B-lymphocytes and is characterized by its remarkable diversity in terms of morphology, biology, and clinical outcomes. Despite treatment strategies that include high-dose chemotherapy coupled with autologous stem cell transplantation, achieving long-term remission remains challenging. Approximately half of all patients experience a recurrence, following initial therapy. Due to its aggressiveness, recurred patients have a critically low survival probability [<xref ref-type="bibr" rid="CR1">1</xref>]. Thus, there is a pressing need for a reliable upfront detection of those patients that will not benefit from standard frontline regimens.</p><p id="Par6">In the recent past, deep learning has made remarkable progress in predicting recurrence of various cancer types (including bladder [<xref ref-type="bibr" rid="CR2">2</xref>], breast [<xref ref-type="bibr" rid="CR3">3</xref>&#x02013;<xref ref-type="bibr" rid="CR6">6</xref>], colorectal [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>], hepatocellular carcinoma [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>], lung [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>], and prostate cancer [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR14">14</xref>]) based on histological images.</p><p id="Par7">Previous studies have used deep learning models (mostly variations of ResNet architectures [<xref ref-type="bibr" rid="CR15">15</xref>]) to predict recurrence based on images as well as clinical features such as tumor grade, stage, age, etc. [<xref ref-type="bibr" rid="CR2">2</xref>&#x02013;<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR11">11</xref>]. While offering good performance, these models did not provide insights into the determinants of the patient outcomes.</p><p id="Par8">Explainability of recurrence prediction models is of tremendous medical importance. Identifying which image regions are predictive of specific clinical outcomes could potentially lead to discovery of novel visual biomarkers as well as to a better understanding of the underlying resistance mechanisms. Several recent studies have included interpretability analyses using multiple instance learning (MIL) [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>] or gradCAM heatmaps [<xref ref-type="bibr" rid="CR6">6</xref>] to highlight image patches that were important for the model&#x02019;s decision. Although these methods allowed for qualitative insights into the relevant image regions, they did not perform an in-depth quantitative analysis of those regions.</p><p id="Par9">There is relatively little research on the image-based prediction of DLBCL patient outcomes. Up to 2019, the primary prognostic features were clinical features, gene expression markers, and genetic abnormalities [<xref ref-type="bibr" rid="CR16">16</xref>]. Wang et al. [<xref ref-type="bibr" rid="CR17">17</xref>], Fan et al. [<xref ref-type="bibr" rid="CR18">18</xref>], and Xing et al. [<xref ref-type="bibr" rid="CR19">19</xref>] used traditional machine learning algorithms (such as random forest support vector machine, regression, gaussian mixture model clustering) to predict recurrence in patients with DLBCL using clinical features. Shankar et al. [<xref ref-type="bibr" rid="CR20">20</xref>] introduced LymphoML, an interpretable deep learning method that identifies morphological features that are predictive of lymphoma subtypes. Their model points to concrete single-cell-based morphological features that are distinctive for different lymphoma subtypes, such as minor axis length and nuclei area. However, how these features could be leveraged to predict recurrence in DLBCL patients is an open question.</p><p id="Par10">In this work, we address the challenge of prediction of recurrence after first-line treatment in DLBCL and interpretation of the prediction model. We developed a deep learning-based prediction pipeline based on tissue microarrays (TMAs) stained with hematoxylin and eosin (H&#x00026;E). We extracted the model&#x02019;s high attention areas of the core images, applied nuclei segmentation on these areas, and determined single-cell morphological features which are distinct for recurred and non-recurred patients. While the causes of DLBCL relapse are still unknown, here, we point to cell morphology features which might be determinant for patient response to treatment.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Patient cohort and dataset</title><p id="Par11">Our dataset is based on a publicly available dataset of the Stanford Cancer Institute [<xref ref-type="bibr" rid="CR21">21</xref>]. Of the 42 TMAs in the original dataset, prepared with six different stains, we are using the seven TMAs stained with hematoxylin and eosin (H&#x00026;E). After discarding cores with low quality and incomplete patient information, our dataset contained 167 patients with 306 cores (1&#x02013;2 cores per patient) from the seven H&#x00026;E-stained TMAs. The TMA slides were scanned at 40&#x000d7; magnification (0.25&#x02009;&#x003bc;m per pixel) on an Aperio AT2 scanner (Leica Biosystems, Nussloch, Germany). Each TMA has a thickness of 4&#x02009;&#x003bc;m and includes a formalin-fixed, paraffin-embedded (FFPE) section of tumors arranged in a grid. Each core within the TMAs has a diameter of 0.6&#x02009;mm [<xref ref-type="bibr" rid="CR21">21</xref>]. The clinical data shows that 47 patients of the cohort did suffer from a recurrence, whereas 120 patients stayed recurrence-free.</p></sec><sec id="Sec4"><title>Pipeline</title><p id="Par12">We developed a pipeline (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>) that starts with a preprocessing step (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1a</xref>) in which the cores are cut into non-overlapping patches of size 256&#x02009;&#x000d7;&#x02009;256 pixels. For each patch of a core, a low-dimensional feature representation is determined using a ResNet50 model pretrained on ImageNet. This results in a 1024-dimensional feature vector which is then further compressed to a 512-dimensional vector (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1b</xref>) through linear transformation of a fully connected layer. To predict recurrence from the images, we use CLAM (clustering-constrained attention multiple instance learning) [<xref ref-type="bibr" rid="CR22">22</xref>]. CLAM leverages attention-based learning to localize image regions that are of significant diagnostic importance. That is, the model uses an attention-based pooling function to aggregate patch-level features into sample-level representations to classify a sample into &#x02018;recurrence&#x02019; or &#x02018;non-recurrence&#x02019;. The classification decision depends on the attention score that is assigned to each patch and indicates its importance to the sample-level representation for the respective class (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1c</xref>) [<xref ref-type="bibr" rid="CR22">22</xref>].<fig id="Fig1"><label>Fig. 1</label><caption><title>Deep learning pipeline.</title><p><bold>a</bold> H&#x00026;E-stained core images were segmented and cut into non-overlapping patches of size 256 &#x000d7;256 pixels. <bold>b</bold> Features were extracted from all patches of a core image using a ResNet50 encoder. The final feature vectors had a size of 1024. <bold>c</bold> CLAM model to classify the cores into &#x02018;recurrence&#x02019; or &#x02018;non-recurrence&#x02019;. The model assignes attention scores to each patch of a core image, with blue frames indicating low attention patches and red frames indicating high attention patches. <bold>d</bold> Segmentation of the nuclei of the top 20 patches (based on the attention score) of each class using a pre-trained modified HoVer-Net architecture [<xref ref-type="bibr" rid="CR24">24</xref>]. <bold>e</bold> We calculate morphological features from the segmented cell nuclei and statistically analyze them to find significant differences between recurred and non-recurred patients.</p></caption><graphic xlink:href="44276_2025_147_Fig1_HTML" id="d33e381"/></fig></p><p id="Par13">For training the classification model, we used 60% of patients for training, 20% for validation and 20% for final testing. We further applied a cross validation with 4 iterations to further validate our model&#x02019;s performance. Hence, we express the performance as the mean of all iterations. Out of the correctly classified cores (true positives), we utilized the top 20 patches with the highest attention scores for further analysis (for both groups, respectively). We segmented the nuclei within each patch using a modified version of HoVer-Net [<xref ref-type="bibr" rid="CR23">23</xref>], that has specifically been trained on H&#x00026;E-stained DLBCL whole slide images (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1d</xref>) [<xref ref-type="bibr" rid="CR24">24</xref>]. We excluded cut-off nuclei at the patch margins, quantified morphological features of the remaining segmented nuclei, and applied statistical analysis to identify differences between the features of recurred and non-recurred patients (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1e</xref>). We quantified the following shape- and size-based nuclei features:<list list-type="order"><list-item><p id="Par14">area: area of the nucleus.</p></list-item><list-item><p id="Par15">major axis length: length of the major axis of the ellipse that has the same second central moment as the nucleus.</p></list-item><list-item><p id="Par16">minor axis length: length of the minor axis of the ellipse that has the same second central moment as the nucleus.</p></list-item><list-item><p id="Par17">roughness: variance in the length of a vector that is centered at the centroid of a nucleus as it rotates along with each boundary point. The higher the value, the higher the degree of nucleus shape irregularity [<xref ref-type="bibr" rid="CR25">25</xref>].</p></list-item></list></p></sec></sec><sec id="Sec5" sec-type="results"><title>Results</title><sec id="Sec6"><title>Relapse prediction</title><p id="Par18">Our model achieves a classification accuracy of 0.79, a precision of 0.79, a recall of 0.98 and an f1-score of 0.88. A confusion matrix is shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. Despite the class imbalance of the dataset with approximately 28% of patients that experience recurrence, the errors are equally distributed among the two patient groups.<fig id="Fig2"><label>Fig. 2</label><caption><title>Confusion matrix of the recurrence prediction on the hold-out test set (<italic>n</italic>&#x02009;=&#x02009;32).</title><p>The matrix was normalized and shows the average performance across all cross validation folds.</p></caption><graphic xlink:href="44276_2025_147_Fig2_HTML" id="d33e440"/></fig></p><p id="Par19">Feature encoder and model hyperparameters were chosen based on performance. We have tested several models for comparison, shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. Each model was trained for a maximum of 200 epochs with early stopping enabled after 50 epochs. Instance clustering was performed using eight patches with the CLAM method. Using a higher number of patches was not possible due to the patch extraction of CLAM, which extracted eight patches for some cores available. Class weighting was enabled to balance the dataset. As a patient can have two cores in the dataset, DLBCL is predicted to recur for a patient if DLBCL is predicted to recur for at least one core.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Prediction accuracy depending on hyperparameter values and feature encoders.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Learning rate</th><th>Weight decay</th><th>Metrics</th><th>ResNet</th><th>UNI</th><th>CONCH</th><th>CTrans-Path</th><th>Prov-GigaPath</th></tr></thead><tbody><tr><td rowspan="4">0.0001</td><td rowspan="4">0.00001</td><td>Accuracy</td><td>0.7879</td><td>0.7500</td><td>0.7500</td><td>0.7273</td><td>0.7424</td></tr><tr><td>B. Acc.</td><td>0.5531</td><td>0.6626</td><td>0.5776</td><td>0.6147</td><td>0.5883</td></tr><tr><td>AUC</td><td>0.5524</td><td>0.6146</td><td>0.6546</td><td>0.5775</td><td>0.6149</td></tr><tr><td>F1-score</td><td>0.8768</td><td>0.8370</td><td>0.8481</td><td>0.8252</td><td>0.8378</td></tr><tr><td rowspan="4">0.0001</td><td rowspan="4">0.0001</td><td>Accuracy</td><td><bold>0.7879</bold></td><td>0.7348</td><td>0.7348</td><td>0.7197</td><td>0.7197</td></tr><tr><td>B. Acc.</td><td><bold>0.5979</bold></td><td>0.6130</td><td>0.5732</td><td>0.5998</td><td>0.6246</td></tr><tr><td>AUC</td><td><bold>0.5994</bold></td><td>0.6304</td><td>0.6681</td><td>0.5627</td><td>0.682</td></tr><tr><td>F1-score</td><td><bold>0.8728</bold></td><td>0.8328</td><td>0.8367</td><td>0.8189</td><td>0.8199</td></tr><tr><td rowspan="4">0.00001</td><td rowspan="4">0.00001</td><td>Accuracy</td><td>0.7576</td><td>0.7348</td><td>0.6818</td><td>0.6894</td><td>0.7121</td></tr><tr><td>B. Acc.</td><td>0.5106</td><td>0.6343</td><td>0.5458</td><td>0.6243</td><td>0.5986</td></tr><tr><td>AUC</td><td>0.5024</td><td>0.7172</td><td>0.559</td><td>0.5956</td><td>0.6549</td></tr><tr><td>F1-score</td><td>0.8602</td><td>0.8291</td><td>0.7962</td><td>0.7844</td><td>0.8153</td></tr><tr><td rowspan="4">0.00001</td><td rowspan="4">0.0001</td><td>Accuracy</td><td>0.7576</td><td>0.7045</td><td>0.6970</td><td>0.6894</td><td>0.7273</td></tr><tr><td>B. Acc.</td><td>0.5000</td><td>0.5819</td><td>0.5829</td><td>0.6243</td><td>0.6165</td></tr><tr><td>AUC</td><td>0.5074</td><td>0.6650</td><td>0.5889</td><td>0.6193</td><td>0.6619</td></tr><tr><td>F1-score</td><td>0.8614</td><td>0.8112</td><td>0.8039</td><td>0.7844</td><td>0.8251</td></tr></tbody></table><table-wrap-foot><p>The different cores per patient were first transformed into feature vectors using a ResNet-50 trained on ImageNet and different feature encoders trained on H&#x00026;E-stained images: UNI by Chen et al. [<xref ref-type="bibr" rid="CR29">29</xref>], CONCH by Lu et al. [<xref ref-type="bibr" rid="CR30">30</xref>], CTransPath by Wang et al. [<xref ref-type="bibr" rid="CR28">28</xref>] and Prov-GigaPath by Xu et al. [<xref ref-type="bibr" rid="CR31">31</xref>]. The length of the feature vectors varies across the different feature encoders. The pretrained Resnet-50 and UNI generate 1024-dimensional features, CONCH produces features of size 512, CTransPath of size 768 and Prov-GigaPath outputs features of length 1536. B. Acc. stands for balanced accuracy. The results of our model are marked in bold.</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec7"><title>Statistical analysis</title><p id="Par20">We identified nuclei area, major and minor axis length, and roughness as nuclei features that differ between the patients that have recurred and those that have not (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>). In the high-attention image areas for recurred patients, the nuclei area, major and minor axis length, and roughness are higher, with a difference of 10.8&#x02009;&#x000b5;m<sup>2</sup> (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.0001, <italic>t</italic>-test), 230&#x02009;nm (<italic>p</italic>&#x02009;=&#x02009;0.0036, <italic>t</italic>-test), 321&#x02009;nm (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.0001, <italic>t</italic>-test), and 706&#x02009;nm (<italic>p</italic>&#x02009;=&#x02009;0.0002, <italic>t</italic>-test), respectively.<fig id="Fig3"><label>Fig. 3</label><caption><title>Distribution and boxplots of the determined morphological features for recurred (<italic>n</italic>&#x02009;=&#x02009;18, with an average of 63 nuclei per patient) and non-recurred (<italic>n</italic>&#x02009;=&#x02009;20, with an average of 65 nuclei per patient) patients.</title><p>We calculated the features &#x02018;area&#x02019;, &#x02018;major axis length&#x02019;, &#x02018;minor axis length&#x02019;, and &#x02018;roughness&#x02019;. The <italic>p</italic> values indicate the t-test results to highlight statistically significant differences between the features of recurred and non-recurred patients.</p></caption><graphic xlink:href="44276_2025_147_Fig3_HTML" id="d33e779"/></fig></p><p id="Par21">Figure&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> shows examples of tissue areas from recurrence and non-recurrence patients in which we visualize differences in these morphological features. The elevated values of the nuclei area and roughness parameters suggest that patients who relapsed have bigger nuclei and more nuclei with irregular-shaped cells.<fig id="Fig4"><label>Fig. 4</label><caption><title>Heatmap visualization of feature values.</title><p>For the top two patches of recurred and non-recurred patients, we visualize the strengths of the features &#x02018;area&#x02019;, &#x02018;minor axis length&#x02019;, and &#x02018;roughness&#x02019;. The darker the color of a cell the higher its respective feature value.</p></caption><graphic xlink:href="44276_2025_147_Fig4_HTML" id="d33e792"/></fig></p></sec><sec id="Sec8"><title>Survival prediction</title><p id="Par22">We next inspected whether the visual features identified by our predictive model are predictive of patient survival. To this end, we used the overall survival and the follow-up status from the clinical data of the patients to visualize the survival curves with a Kaplan&#x02013;Meier plot.</p><p id="Par23">Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> indicates that patients predicted to recur have lower survival probabilities. Additionally, the survival curve of patients predicted as recurring closely matches the curve of patients that actually experienced recurrence based on the clinical follow up data.<fig id="Fig5"><label>Fig. 5</label><caption><title>Kaplan&#x02013;Meier plot for overall survival.</title><p>The plot shows the overall survival probability of recurred and non-recurred patients (true and predicted) over time. The variable <italic>p</italic> indicates the t-test-based <italic>p</italic>-value for true recurrence and non-recurrence and <italic>p</italic><sub>pred</sub> the <italic>p</italic> value for predicted recurrence and non-recurrence.</p></caption><graphic xlink:href="44276_2025_147_Fig5_HTML" id="d33e823"/></fig></p></sec></sec><sec id="Sec9" sec-type="discussion"><title>Discussion</title><p id="Par24">Deep learning presents tremendous opportunities for medically relevant prediction tasks, such as recurrence or survival. Additionally, attention-based mechanisms provide insights into the prediction process of the model by enabling quantitative analyses of the tumor morphology and microenvironment features that were crucial to the model&#x02019;s decision.</p><p id="Par25">In this work, we perform image-based prediction of recurrence of DLBCL. We show, that, despite limited dataset size and class imbalance, our model is able to distinguish recurred from non-recurred patients, indicating that H&#x00026;E-stained images contain meaningful information for such prediction tasks. Our statistical analysis further suggests that the model&#x02019;s prediction decision can be explained by morphological characteristics of the cell nuclei within the high-attention areas of the images. Namely, the model focuses on areas where nuclei of recurred patients tend to be bigger and more irregular in shape as the nuclei of non-recurred patients (Figs.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref>). These features indicate a higher degree of nuclear pleomorphism, which has previously been shown as related to tumor aggressiveness [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>]. Lastly, our model is indirectly predicting patient survival as well (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>).</p><p id="Par26">A major limitation of this study is the small size of the dataset and lack of an external validation cohort. To the best of our knowledge the used dataset is the only available one which contains the patient recurrence information. Our cross-validation test however suggests that the information on the disease progression might indeed be encoded in the patient diagnostic images. This finding should be further verified as more DLBCL patient data becomes publicly available in the future.</p><p id="Par27">In addition to the feature extractor pre-trained on ImageNet, we also used the Transformer-based feature extractor CTransPath [<xref ref-type="bibr" rid="CR28">28</xref>] &#x02013; a model that has been pretrained on histological images. We found, however, that the model pre-trained on ImageNet yielded better results.</p><p id="Par28">One limitation of our work is the lack of validation on an independent cohort from a different clinical center. To our knowledge, there is however no other publicly available DLBCL histology image data with reported patient clinical outcomes. We aimed to mitigate the model by training and testing the model in several cross-validation iterations.</p><p id="Par29">Our study highlights the importance and high information content of histological images for prediction of treatment outcome. In combination with the ability to make our model biologically interpretable, it allows for descriptive, quantitative, and thorough distinction between recurred and non-recurred patients offering the potential for better diagnostics and better understanding of the complexity of fundamental biological processes in aggressive, heterogeneous cancer types, such as DLBCL.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>These authors contributed equally: Hussein Naji, Paul Hahn.</p></fn></fn-group><ack><title>Acknowledgements</title><p>This work was part of the Collaborative Research Center 1310 &#x0201c;Predictability in evolution&#x0201d; project C03. SU was supported by the Federal Ministry of Education and Research (BMBF)[grant number 01ZX1917B]; HN by the Ministry for Culture and Science (MKW) of the State of North Rhine-Westphalia [grant number 311-8.03.03.02-147635].</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>HN and PH performed data analysis, paper writing and software development. JIP and SU contributed to software development and data analysis. AS contributed to data analysis. RB and KB designed the study. KB also wrote the paper.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>This work was part of the Collaborative Research Center 1310 &#x0201c;Predictability in evolution&#x0201d; project C03. SU was supported by the Federal Ministry of Education and Research (BMBF) [grant number 01ZX1917B]; HN by the Ministry for Culture and Science (MKW) of the State of North Rhine-Westphalia [grant number 311-8.03.03.02-147635]. Open Access funding enabled and organized by Projekt DEAL.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>All data supporting the results reported in this article can be found here: <ext-link ext-link-type="uri" xlink:href="https://github.com/stanfordmlgroup/DLBCL-Morph">https://github.com/stanfordmlgroup/DLBCL-Morph</ext-link>.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par30">The authors declare no competing interests.</p></notes><notes id="FPar2"><title>Ethics approval and consent to participate</title><p id="Par31">All methods were performed in accordance with the relevant guidelines and regulations.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Susanibar-Adaniya</surname><given-names>S</given-names></name><name><surname>Barta</surname><given-names>SK</given-names></name></person-group><article-title>2021 Update on Diffuse large B cell lymphoma: a review of current data and potential applications on risk stratification and management</article-title><source>Am J Hematol</source><year>2021</year><volume>96</volume><fpage>617</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1002/ajh.26151</pub-id><pub-id pub-id-type="pmid">33661537</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Susanibar-Adaniya S, Barta SK. 2021 Update on Diffuse large B cell lymphoma: a review of current data and potential applications on risk stratification and management. Am J Hematol. 2021;96:617&#x02013;29.<pub-id pub-id-type="pmid">33661537</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Lucas</surname><given-names>M</given-names></name><name><surname>Jansen</surname><given-names>I</given-names></name><name><surname>van Leeuwen</surname><given-names>TG</given-names></name><name><surname>Oddens</surname><given-names>JR</given-names></name><name><surname>de Bruin</surname><given-names>DM</given-names></name><name><surname>Marquering</surname><given-names>HA</given-names></name></person-group><article-title>Deep learning&#x02013;based recurrence prediction in patients with non&#x02013;muscle-invasive bladder cancer</article-title><source>Eur Urol Focus</source><year>2022</year><volume>8</volume><fpage>165</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.euf.2020.12.008</pub-id><pub-id pub-id-type="pmid">33358370</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Lucas M, Jansen I, van Leeuwen TG, Oddens JR, de Bruin DM, Marquering HA. Deep learning&#x02013;based recurrence prediction in patients with non&#x02013;muscle-invasive bladder cancer. Eur Urol Focus. 2022;8:165&#x02013;72.<pub-id pub-id-type="pmid">33358370</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname></name></person-group><article-title>Prediction of HER2-positive breast cancer recurrence and metastasis risk from histopathological images and clinical information via multimodal deep learning</article-title><source>Computational Struct Biotechnol J</source><year>2022</year><volume>20</volume><fpage>333</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/j.csbj.2021.12.028</pub-id></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Yang. Prediction of HER2-positive breast cancer recurrence and metastasis risk from histopathological images and clinical information via multimodal deep learning. Computational Struct Biotechnol J. 2022;20:333&#x02013;42.</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>FM</given-names></name><name><surname>Dolezal</surname><given-names>J</given-names></name><name><surname>Kochanny</surname><given-names>S</given-names></name><name><surname>Khramtsova</surname><given-names>G</given-names></name><name><surname>Vickery</surname><given-names>J</given-names></name><name><surname>Srisuwananukorn</surname><given-names>A</given-names></name><etal/></person-group><article-title>Integration of clinical features and deep learning on pathology for the prediction of breast cancer recurrence assays and risk of recurrence</article-title><source>npj Breast Cancer</source><year>2023</year><volume>9</volume><fpage>25</fpage><pub-id pub-id-type="doi">10.1038/s41523-023-00530-5</pub-id><pub-id pub-id-type="pmid">37059742</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Howard FM, Dolezal J, Kochanny S, Khramtsova G, Vickery J, Srisuwananukorn A, et al. Integration of clinical features and deep learning on pathology for the prediction of breast cancer recurrence assays and risk of recurrence. npj Breast Cancer. 2023;9:25.<pub-id pub-id-type="pmid">37059742</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>Y</given-names></name><name><surname>Olsson</surname><given-names>LT</given-names></name><name><surname>Hoadley</surname><given-names>KA</given-names></name><name><surname>Calhoun</surname><given-names>BC</given-names></name><name><surname>Marron</surname><given-names>JS</given-names></name><name><surname>Geradts</surname><given-names>J</given-names></name><etal/></person-group><article-title>Predicting early breast cancer recurrence from histopathological images in the Carolina Breast Cancer Study</article-title><source>npj Breast Cancer</source><year>2023</year><volume>9</volume><fpage>92</fpage><pub-id pub-id-type="doi">10.1038/s41523-023-00597-0</pub-id><pub-id pub-id-type="pmid">37952058</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Shi Y, Olsson LT, Hoadley KA, Calhoun BC, Marron JS, Geradts J, et al. Predicting early breast cancer recurrence from histopathological images in the Carolina Breast Cancer Study. npj Breast Cancer. 2023;9:92.<pub-id pub-id-type="pmid">37952058</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>Z</given-names></name><name><surname>Niazi</surname><given-names>MKK</given-names></name><name><surname>Tavolara</surname><given-names>TE</given-names></name><name><surname>Niu</surname><given-names>S</given-names></name><name><surname>Tozbikian</surname><given-names>GH</given-names></name><name><surname>Wesolowski</surname><given-names>R</given-names></name><etal/></person-group><article-title>BCR-Net: a deep learning framework to predict breast cancer recurrence from histopathology images</article-title><source>PLoS ONE</source><year>2023</year><volume>18</volume><fpage>e0283562</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0283562</pub-id><pub-id pub-id-type="pmid">37014891</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Su Z, Niazi MKK, Tavolara TE, Niu S, Tozbikian GH, Wesolowski R, et al. BCR-Net: a deep learning framework to predict breast cancer recurrence from histopathology images. PLoS ONE. 2023;18:e0283562.<pub-id pub-id-type="pmid">37014891</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Foersch</surname><given-names>S</given-names></name><name><surname>Glasner</surname><given-names>C</given-names></name><name><surname>Woerl</surname><given-names>AC</given-names></name><name><surname>Eckstein</surname><given-names>M</given-names></name><name><surname>Wagner</surname><given-names>DC</given-names></name><name><surname>Schulz</surname><given-names>S</given-names></name><etal/></person-group><article-title>Multistain deep learning for prediction of prognosis and therapy response in colorectal cancer</article-title><source>Nat Med</source><year>2023</year><volume>29</volume><fpage>430</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/s41591-022-02134-1</pub-id><pub-id pub-id-type="pmid">36624314</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Foersch S, Glasner C, Woerl AC, Eckstein M, Wagner DC, Schulz S, et al. Multistain deep learning for prediction of prognosis and therapy response in colorectal cancer. Nat Med. 2023;29:430&#x02013;9.<pub-id pub-id-type="pmid">36624314</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>H</given-names></name><name><surname>Weng</surname><given-names>Z</given-names></name><name><surname>Sun</surname><given-names>K</given-names></name><name><surname>Shen</surname><given-names>J</given-names></name><name><surname>Lin</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><etal/></person-group><article-title>Predicting 5-year recurrence risk in colorectal cancer: development and validation of a histology-based deep learning approach</article-title><source>Br J Cancer</source><year>2024</year><volume>130</volume><fpage>951</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1038/s41416-024-02573-2</pub-id><pub-id pub-id-type="pmid">38245662</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Xiao H, Weng Z, Sun K, Shen J, Lin J, Chen S, et al. Predicting 5-year recurrence risk in colorectal cancer: development and validation of a histology-based deep learning approach. Br J Cancer. 2024;130:951&#x02013;60.<pub-id pub-id-type="pmid">38245662</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Yamashita</surname><given-names>R</given-names></name><name><surname>Long</surname><given-names>J</given-names></name><name><surname>Saleem</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>DL</given-names></name><name><surname>Shen</surname><given-names>J</given-names></name></person-group><article-title>Deep learning predicts postsurgical recurrence of hepatocellular carcinoma from digital histopathologic images</article-title><source>Sci Rep</source><year>2021</year><volume>11</volume><fpage>2047</fpage><pub-id pub-id-type="doi">10.1038/s41598-021-81506-y</pub-id><pub-id pub-id-type="pmid">33479370</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Yamashita R, Long J, Saleem A, Rubin DL, Shen J. Deep learning predicts postsurgical recurrence of hepatocellular carcinoma from digital histopathologic images. Sci Rep. 2021;11:2047.<pub-id pub-id-type="pmid">33479370</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Qu</surname><given-names>WF</given-names></name><name><surname>Tian</surname><given-names>MX</given-names></name><name><surname>Qiu</surname><given-names>JT</given-names></name><name><surname>Guo</surname><given-names>YC</given-names></name><name><surname>Tao</surname><given-names>CY</given-names></name><name><surname>Liu</surname><given-names>WR</given-names></name><etal/></person-group><article-title>Exploring pathological signatures for predicting the recurrence of early-stage hepatocellular carcinoma based on deep learning</article-title><source>Front Oncol</source><year>2022</year><volume>12</volume><fpage>968202</fpage><pub-id pub-id-type="doi">10.3389/fonc.2022.968202</pub-id><pub-id pub-id-type="pmid">36059627</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Qu WF, Tian MX, Qiu JT, Guo YC, Tao CY, Liu WR, et al. Exploring pathological signatures for predicting the recurrence of early-stage hepatocellular carcinoma based on deep learning. Front Oncol. 2022;12:968202.<pub-id pub-id-type="pmid">36059627</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Cai</surname><given-names>Y</given-names></name><name><surname>Liang</surname><given-names>Y</given-names></name><name><surname>Mo</surname><given-names>X</given-names></name><etal/></person-group><article-title>DeepLRHE: a deep convolutional neural network framework to evaluate the risk of lung cancer recurrence and metastasis from histopathology images</article-title><source>Front Genet.</source><year>2020</year><volume>11</volume><fpage>768</fpage><pub-id pub-id-type="doi">10.3389/fgene.2020.00768</pub-id><pub-id pub-id-type="pmid">33193560</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Wu Z, Wang L, Li C, Cai Y, Liang Y, Mo X, et al. DeepLRHE: a deep convolutional neural network framework to evaluate the risk of lung cancer recurrence and metastasis from histopathology images. Front Genet. 2020;11:768.<pub-id pub-id-type="pmid">33193560</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Akram</surname><given-names>F</given-names></name><name><surname>Wolf</surname><given-names>JL</given-names></name><name><surname>Trandafir</surname><given-names>TE</given-names></name><name><surname>Dingemans</surname><given-names>AC</given-names></name><name><surname>Stubbs</surname><given-names>AP</given-names></name><name><surname>von der Th&#x000fc;sen</surname><given-names>JH</given-names></name></person-group><article-title>Artificial intelligence-based recurrence prediction outperforms classical histopathological methods in pulmonary adenocarcinoma biopsies</article-title><source>Lung Cancer</source><year>2023</year><volume>186</volume><fpage>107413</fpage><pub-id pub-id-type="doi">10.1016/j.lungcan.2023.107413</pub-id><pub-id pub-id-type="pmid">37939498</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Akram F, Wolf JL, Trandafir TE, Dingemans AC, Stubbs AP, von der Th&#x000fc;sen JH. Artificial intelligence-based recurrence prediction outperforms classical histopathological methods in pulmonary adenocarcinoma biopsies. Lung Cancer. 2023;186:107413.<pub-id pub-id-type="pmid">37939498</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Dietrich</surname><given-names>E</given-names></name><name><surname>Fuhlert</surname><given-names>P</given-names></name><name><surname>Ernst</surname><given-names>A</given-names></name><name><surname>Sauter</surname><given-names>G</given-names></name><name><surname>Lennartz</surname><given-names>M</given-names></name><name><surname>Stiehl</surname><given-names>HS</given-names></name><etal/></person-group><article-title>Towards explainable end-to-end prostate cancer relapse prediction from H&#x00026;E images combining self-attention multiple instance learning with a recurrent neural network</article-title><source>Proc Mach Learn Res</source><year>2021</year><volume>158</volume><fpage>38</fpage><lpage>53</lpage></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Dietrich E, Fuhlert P, Ernst A, Sauter G, Lennartz M, Stiehl HS, et al. Towards explainable end-to-end prostate cancer relapse prediction from H&#x00026;E images combining self-attention multiple instance learning with a recurrent neural network. Proc Mach Learn Res. 2021;158:38&#x02013;53.</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Eminaga, O, Saad, F, Tian, Z, Wolffgang, U, Karakiewicz, PI, Ouellet, V et al. Artificial intelligence helps to predict recurrence and mortality for prostate cancer using histology images. Preprint. 2023, 10.1101/2023.07.27.550781.</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In: IEEE conference on computer vision and pattern recognition. Las Vegas 2016:770&#x02013;8. 10.1109/CVPR.2016.90.</mixed-citation></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Harkins</surname><given-names>RA</given-names></name><name><surname>Chang</surname><given-names>A</given-names></name><name><surname>Patel</surname><given-names>SP</given-names></name><name><surname>Lee</surname><given-names>MJ</given-names></name><name><surname>Goldstein</surname><given-names>JS</given-names></name><name><surname>Merdan</surname><given-names>S</given-names></name><etal/></person-group><article-title>Remaining challenges in predicting patient outcomes for diffuse large B-cell lymphoma</article-title><source>Expert Rev Hematol</source><year>2019</year><volume>12</volume><fpage>959</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1080/17474086.2019.1660159</pub-id><pub-id pub-id-type="pmid">31513757</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Harkins RA, Chang A, Patel SP, Lee MJ, Goldstein JS, Merdan S, et al. Remaining challenges in predicting patient outcomes for diffuse large B-cell lymphoma. Expert Rev Hematol. 2019;12:959&#x02013;73.<pub-id pub-id-type="pmid">31513757</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Luo</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Ren</surname><given-names>X</given-names></name><etal/></person-group><article-title>Classifying 2-year recurrence in patients with dlbcl using clinical variables with imbalanced data and machine learning methods</article-title><source>Comput Methods Prog Biomed</source><year>2020</year><volume>196</volume><fpage>105567</fpage><pub-id pub-id-type="doi">10.1016/j.cmpb.2020.105567</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Wang L, Zhao Z, Luo Y, Yu H, Wu S, Ren X, et al. Classifying 2-year recurrence in patients with dlbcl using clinical variables with imbalanced data and machine learning methods. Comput Methods Prog Biomed. 2020;196:105567.</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Zheng</surname><given-names>C</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><etal/></person-group><article-title>Probability calibration-based prediction of recurrence rate in patients with diffuse large B-cell lymphoma</article-title><source>BioData Min</source><year>2021</year><volume>14</volume><fpage>38</fpage><pub-id pub-id-type="doi">10.1186/s13040-021-00272-9</pub-id><pub-id pub-id-type="pmid">34389029</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Fan S, Zhao Z, Zhang Y, Yu H, Zheng C, Huang X, et al. Probability calibration-based prediction of recurrence rate in patients with diffuse large B-cell lymphoma. BioData Min. 2021;14:38.<pub-id pub-id-type="pmid">34389029</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Predict DLBCL patients&#x02019; recurrence within two years with Gaussian mixture model cluster oversampling and multi-kernel learning</article-title><source>Comput Methods Prog Biomed</source><year>2022</year><volume>226</volume><fpage>107103</fpage><pub-id pub-id-type="doi">10.1016/j.cmpb.2022.107103</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Xing M, Zhang Y, Yu H, Yang Z, Li X, Li Q, et al. Predict DLBCL patients&#x02019; recurrence within two years with Gaussian mixture model cluster oversampling and multi-kernel learning. Comput Methods Prog Biomed. 2022;226:107103.</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Shankar</surname><given-names>V</given-names></name><name><surname>Yang</surname><given-names>X</given-names></name><name><surname>Krishna</surname><given-names>V</given-names></name><name><surname>Tan</surname><given-names>BT</given-names></name><name><surname>Silva</surname><given-names>O</given-names></name><name><surname>Rojansky</surname><given-names>R</given-names></name><etal/></person-group><article-title>LymphoML: an interpretable artificial intelligence-based method dentifies morphologic features that correlate with lymphoma subtype</article-title><source>Proc Mach Learn Res</source><year>2023</year><volume>225</volume><fpage>528</fpage><lpage>58</lpage></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Shankar V, Yang X, Krishna V, Tan BT, Silva O, Rojansky R, et al. LymphoML: an interpretable artificial intelligence-based method dentifies morphologic features that correlate with lymphoma subtype. Proc Mach Learn Res. 2023;225:528&#x02013;58.</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Vrabac</surname><given-names>D</given-names></name><name><surname>Smit</surname><given-names>A</given-names></name><name><surname>Rojansky</surname><given-names>R</given-names></name><name><surname>Natkunam</surname><given-names>Y</given-names></name><name><surname>Advani</surname><given-names>RH</given-names></name><name><surname>Ng</surname><given-names>AY</given-names></name><etal/></person-group><article-title>DLBCL-Morph: Morphological features computed using deep learning for an annotated digital DLBCL image set</article-title><source>Sci Data</source><year>2021</year><volume>8</volume><fpage>135</fpage><pub-id pub-id-type="doi">10.1038/s41597-021-00915-w</pub-id><pub-id pub-id-type="pmid">34017010</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Vrabac D, Smit A, Rojansky R, Natkunam Y, Advani RH, Ng AY, et al. DLBCL-Morph: Morphological features computed using deep learning for an annotated digital DLBCL image set. Sci Data. 2021;8:135.<pub-id pub-id-type="pmid">34017010</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>MY</given-names></name><name><surname>Williamson</surname><given-names>DFK</given-names></name><name><surname>Chen</surname><given-names>TY</given-names></name><name><surname>Chen</surname><given-names>RJ</given-names></name><name><surname>Barbieri</surname><given-names>M</given-names></name><name><surname>Mahmood</surname><given-names>F</given-names></name></person-group><article-title>Data-efficient and weakly supervised computational pathology on whole-slide images</article-title><source>Nat Biomed Eng</source><year>2021</year><volume>5</volume><fpage>555</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/s41551-020-00682-w</pub-id><pub-id pub-id-type="pmid">33649564</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Lu MY, Williamson DFK, Chen TY, Chen RJ, Barbieri M, Mahmood F. Data-efficient and weakly supervised computational pathology on whole-slide images. Nat Biomed Eng. 2021;5:555&#x02013;70.<pub-id pub-id-type="pmid">33649564</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Graham</surname><given-names>S</given-names></name><name><surname>Vu</surname><given-names>QD</given-names></name><name><surname>Raza</surname><given-names>SEA</given-names></name><name><surname>Azam</surname><given-names>A</given-names></name><name><surname>Tsang</surname><given-names>YW</given-names></name><name><surname>Kwak</surname><given-names>JT</given-names></name><etal/></person-group><article-title>Hover-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images</article-title><source>Med Image Anal</source><year>2019</year><volume>58</volume><fpage>101563</fpage><pub-id pub-id-type="doi">10.1016/j.media.2019.101563</pub-id><pub-id pub-id-type="pmid">31561183</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Graham S, Vu QD, Raza SEA, Azam A, Tsang YW, Kwak JT, et al. Hover-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images. Med Image Anal. 2019;58:101563.<pub-id pub-id-type="pmid">31561183</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Naji</surname><given-names>H</given-names></name><name><surname>Sancere</surname><given-names>L</given-names></name><name><surname>Simon</surname><given-names>A</given-names></name><name><surname>B&#x000fc;ttner</surname><given-names>R</given-names></name><name><surname>Eich</surname><given-names>ML</given-names></name><name><surname>Lohneis</surname><given-names>P</given-names></name><etal/></person-group><article-title>HoLy-Net: Segmentation of histological images of diffuse large B-cell lymphoma</article-title><source>Comput Biol Med</source><year>2024</year><volume>170</volume><fpage>107978</fpage><pub-id pub-id-type="doi">10.1016/j.compbiomed.2024.107978</pub-id><pub-id pub-id-type="pmid">38237235</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Naji H, Sancere L, Simon A, B&#x000fc;ttner R, Eich ML, Lohneis P, et al. HoLy-Net: Segmentation of histological images of diffuse large B-cell lymphoma. Comput Biol Med. 2024;170:107978.<pub-id pub-id-type="pmid">38237235</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Phillip</surname><given-names>JM</given-names></name><name><surname>Han</surname><given-names>KS</given-names></name><name><surname>Chen</surname><given-names>WC</given-names></name><name><surname>Wirtz</surname><given-names>D</given-names></name><name><surname>Wu</surname><given-names>PH</given-names></name></person-group><article-title>A robust unsupervised machine-learning method to quantify the morphological heterogeneity of cells and nuclei</article-title><source>Nat Protoc</source><year>2021</year><volume>16</volume><fpage>754</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1038/s41596-020-00432-x</pub-id><pub-id pub-id-type="pmid">33424024</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Phillip JM, Han KS, Chen WC, Wirtz D, Wu PH. A robust unsupervised machine-learning method to quantify the morphological heterogeneity of cells and nuclei. Nat Protoc. 2021;16:754&#x02013;74.<pub-id pub-id-type="pmid">33424024</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Rashid</surname><given-names>F</given-names></name><name><surname>Haque</surname><given-names>AU</given-names></name></person-group><article-title>Frequencies of different nuclear morphological features in prostate adenocarcinoma</article-title><source>Ann Diagnostic Pathol</source><year>2011</year><volume>15</volume><fpage>414</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.anndiagpath.2011.06.002</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Rashid F, Haque AU. Frequencies of different nuclear morphological features in prostate adenocarcinoma. Ann Diagnostic Pathol. 2011;15:414&#x02013;21.</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>EG</given-names></name></person-group><article-title>Nuclear morphology and the biology of cancer cells</article-title><source>Acta Cytologica</source><year>2020</year><volume>64</volume><fpage>511</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1159/000508780</pub-id><pub-id pub-id-type="pmid">32570234</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">Fischer EG. Nuclear morphology and the biology of cancer cells. Acta Cytologica. 2020;64:511&#x02013;9.<pub-id pub-id-type="pmid">32570234</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Yang</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name><etal/></person-group><article-title>Transformer-based unsupervised contrastive learning for histopathological image classification</article-title><source>Med Image Anal</source><year>2022</year><volume>81</volume><fpage>102559</fpage><pub-id pub-id-type="doi">10.1016/j.media.2022.102559</pub-id><pub-id pub-id-type="pmid">35952419</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">Wang X, Yang S, Zhang J, Wang M, Zhang J, Yang W, et al. Transformer-based unsupervised contrastive learning for histopathological image classification. Med Image Anal. 2022;81:102559.<pub-id pub-id-type="pmid">35952419</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>RJ</given-names></name><name><surname>Ding</surname><given-names>T</given-names></name><name><surname>Lu</surname><given-names>MY</given-names></name><name><surname>Williamson</surname><given-names>DFK</given-names></name><name><surname>Jaume</surname><given-names>G</given-names></name><name><surname>Song</surname><given-names>AH</given-names></name><etal/></person-group><article-title>Towards a general-purpose foundation model for computational pathology</article-title><source>Nat Med</source><year>2024</year><volume>30</volume><fpage>850</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/s41591-024-02857-3</pub-id><pub-id pub-id-type="pmid">38504018</pub-id>
</element-citation><mixed-citation id="mc-CR29" publication-type="journal">Chen RJ, Ding T, Lu MY, Williamson DFK, Jaume G, Song AH, et al. Towards a general-purpose foundation model for computational pathology. Nat Med. 2024;30:850&#x02013;62.<pub-id pub-id-type="pmid">38504018</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>MY</given-names></name><name><surname>Chen</surname><given-names>B</given-names></name><name><surname>Williamson</surname><given-names>DF</given-names></name><name><surname>Chen</surname><given-names>RJ</given-names></name><name><surname>Liang</surname><given-names>I</given-names></name><name><surname>Ding</surname><given-names>T</given-names></name><etal/></person-group><article-title>A visual-language foundation model for computational pathology</article-title><source>Nat Med</source><year>2024</year><volume>30</volume><fpage>863</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1038/s41591-024-02856-4</pub-id><pub-id pub-id-type="pmid">38504017</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Lu MY, Chen B, Williamson DF, Chen RJ, Liang I, Ding T, et al. A visual-language foundation model for computational pathology. Nat Med. 2024;30:863&#x02013;74.<pub-id pub-id-type="pmid">38504017</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Usuyama</surname><given-names>N</given-names></name><name><surname>Bagga</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Rao</surname><given-names>R</given-names></name><name><surname>Naumann</surname><given-names>T</given-names></name><etal/></person-group><article-title>A whole-slide foundation model for digital pathology from real-world data</article-title><source>Nature</source><year>2024</year><volume>630</volume><fpage>181</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/s41586-024-07441-w</pub-id><pub-id pub-id-type="pmid">38778098</pub-id>
</element-citation><mixed-citation id="mc-CR31" publication-type="journal">Xu H, Usuyama N, Bagga J, Zhang S, Rao R, Naumann T, et al. A whole-slide foundation model for digital pathology from real-world data. Nature. 2024;630:181&#x02013;8.<pub-id pub-id-type="pmid">38778098</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>