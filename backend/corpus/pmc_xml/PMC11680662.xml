<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Psychon Bull Rev</journal-id><journal-id journal-id-type="iso-abbrev">Psychon Bull Rev</journal-id><journal-title-group><journal-title>Psychonomic Bulletin &#x00026; Review</journal-title></journal-title-group><issn pub-type="ppub">1069-9384</issn><issn pub-type="epub">1531-5320</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>New York</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38689188</article-id><article-id pub-id-type="pmc">PMC11680662</article-id>
<article-id pub-id-type="publisher-id">2511</article-id><article-id pub-id-type="doi">10.3758/s13423-024-02511-6</article-id><article-categories><subj-group subj-group-type="heading"><subject>Brief Report</subject></subj-group></article-categories><title-group><article-title>Neural representation of phonological wordform in temporal cortex</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sorensen</surname><given-names>David O.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Avcu</surname><given-names>Enes</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Lynch</surname><given-names>Skyla</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Ahlfors</surname><given-names>Seppo P.</given-names></name><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Gow</surname><given-names>David W.</given-names></name><address><email>dgow@mgh.harvard.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff5">5</xref><xref ref-type="aff" rid="Aff6">6</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03vek6s52</institution-id><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution>Division of Medical Sciences, Harvard Medical School, </institution></institution-wrap>Cambridge, MA USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03vek6s52</institution-id><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution>Department of Neurology, </institution><institution>Massachusetts General Hospital, Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/002pd6e78</institution-id><institution-id institution-id-type="GRID">grid.32224.35</institution-id><institution-id institution-id-type="ISNI">0000 0004 0386 9924</institution-id><institution>Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, </institution></institution-wrap>Charlestown, MA USA </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/002pd6e78</institution-id><institution-id institution-id-type="GRID">grid.32224.35</institution-id><institution-id institution-id-type="ISNI">0000 0004 0386 9924</institution-id><institution>Department of Radiology, </institution><institution>Massachusetts General Hospital, Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/023qmza96</institution-id><institution-id institution-id-type="GRID">grid.419433.8</institution-id><institution-id institution-id-type="ISNI">0000 0000 8935 1851</institution-id><institution>Department of Psychology, </institution><institution>Salem State University, </institution></institution-wrap>Salem, MA USA </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/002pd6e78</institution-id><institution-id institution-id-type="GRID">grid.32224.35</institution-id><institution-id institution-id-type="ISNI">0000 0004 0386 9924</institution-id><institution>Neurodynamics and Neural Decoding Group, Massachusetts General Hospital, </institution></institution-wrap>65 Landsdowne Street, rm 219, Cambridge, MA 02139 USA </aff></contrib-group><pub-date pub-type="epub"><day>30</day><month>4</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>30</day><month>4</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2024</year></pub-date><volume>31</volume><issue>6</issue><fpage>2659</fpage><lpage>2671</lpage><history><date date-type="accepted"><day>8</day><month>4</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">While the neural bases of the earliest stages of speech categorization have been widely explored using neural decoding methods, there is still a lack of consensus on questions as basic as how wordforms are represented and in what way this word-level representation influences downstream processing in the brain. Isolating and localizing the neural representations of wordform is challenging because spoken words activate a variety of representations (e.g., segmental, semantic, articulatory) in addition to form-based representations. We addressed these challenges through a novel integrated neural decoding and effective connectivity design using region of interest (ROI)-based, source-reconstructed magnetoencephalography/electroencephalography (MEG/EEG) data collected during a lexical decision task. To identify wordform representations, we trained classifiers on words and nonwords from different phonological neighborhoods and then tested the classifiers' ability to discriminate between untrained target words that overlapped phonologically with the trained items. Training with word neighbors supported significantly better decoding than training with nonword neighbors in the period immediately following target presentation. Decoding regions included mostly right hemisphere regions in the posterior temporal lobe implicated in phonetic and lexical representation. Additionally, neighbors that aligned with target word beginnings (critical for word recognition) supported decoding, but equivalent phonological overlap with word codas did not, suggesting lexical mediation. Effective connectivity analyses showed a rich pattern of interaction between ROIs that support decoding based on training with lexical neighbors, especially driven by right posterior middle temporal gyrus. Collectively, these results evidence functional representation of wordforms in temporal lobes isolated from phonemic or semantic representations.</p><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.3758/s13423-024-02511-6.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Phonology</kwd><kwd>Neural decoding</kwd><kwd>Neural representation</kwd><kwd>Spoken word</kwd><kwd>Recognition</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>R01DC015455</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Psychonomic Society, Inc. 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Neural decoding analyses of activity in the posterior temporal gyri have provided important insight into the nature of neural sensitivity to segmental features in spoken language (Bhaya-Grossman &#x00026; Chang, <xref ref-type="bibr" rid="CR10">2022</xref>; Mesgarani et al., <xref ref-type="bibr" rid="CR69">2014</xref>; Oganian &#x00026; Chang, <xref ref-type="bibr" rid="CR76">2019</xref>; Yi et al., <xref ref-type="bibr" rid="CR95">2019</xref>). In contrast, it is less clear how neural activity reflects any aspects of specifically lexical knowledge (Poeppel &#x00026; Idsardi, <xref ref-type="bibr" rid="CR82">2022</xref>). The goal of the present study is to isolate and localize neural representations of wordform &#x02013; activity indexing sound patterns that differentiate individual words and mediate the mappings between acoustic-phonetic input and word-specific semantic, syntactic, and articulatory information.</p><p id="Par3">Wordforms play a central role in lexically mediated language-dependent processes ranging from phonetic interpretation, word learning, lexical segmentation, and perceptual learning to sentence processing and rehearsal processes in working memory (Bresnan, <xref ref-type="bibr" rid="CR13">2001</xref>; Ganong, <xref ref-type="bibr" rid="CR22">1980</xref>; Gathercole et al., <xref ref-type="bibr" rid="CR25">1999</xref>; Merriman et al., <xref ref-type="bibr" rid="CR68">1989</xref>; Norris et al., <xref ref-type="bibr" rid="CR75">2003</xref>). However, questions as basic as how time is represented (Gwilliams et al., <xref ref-type="bibr" rid="CR41">2022</xref>; Hannagan et al., <xref ref-type="bibr" rid="CR43">2013</xref>), whether wordform representations are episodic or idealized (Pierrehumbert, <xref ref-type="bibr" rid="CR81">2016</xref>), morphologically decomposable or holistic (Pelletier, <xref ref-type="bibr" rid="CR79">2012</xref>), or fully specified versus underspecified (Lahiri &#x00026; Marslen-Wilson, <xref ref-type="bibr" rid="CR55">1991</xref>) remain topics of vigorous debate. It is even unclear whether words and nonwords have overlapping representation above the segmental level. Nonword processing is strongly affected by form similarity to known words (Bailey &#x00026; Hahn, <xref ref-type="bibr" rid="CR7">2001</xref>; Frisch et al., <xref ref-type="bibr" rid="CR21">2000</xref>; Gathercole, <xref ref-type="bibr" rid="CR24">1995</xref>). This could be a byproduct of word recognition processes, or a partial function of distributed word-level representations that can also capture overlapping nonword form patterns. Understanding the basis of these similarity effects would clarify the interpretation of results that depend on word-nonword contrasts.</p><p id="Par4">Many studies have examined sensitivity to lexical wordform properties, including cohort size (Gaskell &#x00026; Marslen-Wilson, <xref ref-type="bibr" rid="CR23">2002</xref>; Kocagoncu et al., <xref ref-type="bibr" rid="CR50">2017</xref>; Marslen-Wilson &#x00026; Welsh, <xref ref-type="bibr" rid="CR65">1978</xref>; McClelland &#x00026; Elman, <xref ref-type="bibr" rid="CR66">1986</xref>; Zhuang et al., <xref ref-type="bibr" rid="CR96">2014</xref>), phonological neighborhood density (Landauer &#x00026; Streeter, <xref ref-type="bibr" rid="CR56">1973</xref>; Luce &#x00026; Large, <xref ref-type="bibr" rid="CR60">2001</xref>; Luce &#x00026; Pisoni, <xref ref-type="bibr" rid="CR61">1998</xref>; Peramunage et al., <xref ref-type="bibr" rid="CR80">2011</xref>), and lexical competitor environment (Prabhakaran et al., <xref ref-type="bibr" rid="CR83">2006</xref>). These lexical and sublexical effects are considered to play a crucial role in understanding the functional architecture of spoken word recognition and phonotactic constraints that shape wordform representation (Albright, <xref ref-type="bibr" rid="CR2">2009</xref>; Hayes &#x00026; Wilson, <xref ref-type="bibr" rid="CR46">2008</xref>; Magnuson et al., <xref ref-type="bibr" rid="CR62">2003</xref>; Samuel &#x00026; Pitt, <xref ref-type="bibr" rid="CR86">2003</xref>). An even larger literature has explored BOLD imaging contrasts between words and nonwords (see reviews by Binder et al., <xref ref-type="bibr" rid="CR11">2009</xref>; Davis &#x00026; Gaskell, <xref ref-type="bibr" rid="CR18">2009</xref>). Several models (Gow, <xref ref-type="bibr" rid="CR28">2012</xref>; Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>) have synthesized this research, hypothesizing that the bilateral posterior middle temporal gyrus and perhaps the bilateral supramarginal gyrus mediate the mapping between acoustic-phonetic and higher-level representations. While this work coarsely localizes the likely site containing such mediating wordform representations, it does not isolate individual wordforms, which would be an important first step towards characterizing their representation.</p><p id="Par5">Isolating wordforms poses significant challenges. The phonological patterning of wordforms is confounded with the patterning of the phonemes that make up words, making it difficult to discriminate between lexical and segmental representation. This problem is compounded by evidence for the influence of lexical factors on phoneme processing and representation in the brain (Gow et al., <xref ref-type="bibr" rid="CR34">2021</xref>; Gow et al., <xref ref-type="bibr" rid="CR36">2008</xref>; Gwilliams et al., <xref ref-type="bibr" rid="CR41">2022</xref>; Leonard et al., <xref ref-type="bibr" rid="CR58">2016</xref>; Myers, <xref ref-type="bibr" rid="CR72">2007</xref>). Moreover, auditory words may evoke activation of semantic, articulatory, syntactic, and episodic representations in addition to stored representations of phonological wordform. Finally, evidence that both spoken words and phonotactically legal nonwords briefly activate multiple lexical candidates (Tanenhaus et al., <xref ref-type="bibr" rid="CR91">1995</xref>; Zhuang et al., <xref ref-type="bibr" rid="CR96">2014</xref>; Zwitserlood, <xref ref-type="bibr" rid="CR97">1989</xref>) suggests the need to separate the activation of a target word from that of its temporarily coactivated lexical candidates with overlapping phonology.</p><p id="Par6">Neural decoding techniques provide powerful means for investigating the information content of neural signals (Haynes &#x00026; Rees, <xref ref-type="bibr" rid="CR47">2006</xref>; Kriegeskorte &#x00026; Diedrichsen, <xref ref-type="bibr" rid="CR51">2019</xref>; Kriegeskorte &#x00026; Kievit, <xref ref-type="bibr" rid="CR52">2013</xref>). Several studies have used decoding to reconstruct latent information from human brain activity and to understand the relationship between neural representations and cognitive content (Anderson et al., <xref ref-type="bibr" rid="CR4">2019</xref>; Choi et al., <xref ref-type="bibr" rid="CR15">2021</xref>; Naselaris et al., <xref ref-type="bibr" rid="CR73">2009</xref>). The opportunities afforded by these methods have been tempered in part by a tendency to equate decodability with encoding or representation. Decoding analyses reveal the availability of information in neural activity to support a given classification but do not discriminate between latent information and functional representation &#x02013; which must both capture contrast and influence downstream processing. In addition, functional representation should be localized in a neurally plausible brain region (e.g., an area independently identified as a lexical interface or wordform area). Following Dennett (<xref ref-type="bibr" rid="CR19">1987</xref>) and Kriegeskorte and Diedrichsen (<xref ref-type="bibr" rid="CR51">2019</xref>), we suggest that the concept of representation only becomes useful to theory if it can be demonstrated that a representation is plausibly localized and influences downstream processing. Several strategies have been proposed for demonstrating that putative neural representations affect downstream processing. Grootswagers et al. (<xref ref-type="bibr" rid="CR39">2018</xref>) probed the relationship between neural activity and behavioral response time in tasks hypothesized to depend on those representations. While promising, this approach may be challenging to implement because it requires the identification of a task in which responses directly tap a specific representation, and reaction times are not significantly affected by post-representation metalinguistic processing demands. Goddard and colleagues (Goddard et al., <xref ref-type="bibr" rid="CR26">2016</xref>) used Granger causation analyses to explore downstream neural dependencies. Gow et al. (<xref ref-type="bibr" rid="CR29">2023</xref>) used a variant of Goddard et al.&#x02019;s strategy in which the same signals that were used to decode contrasting patterns of syllable repetition in individual brain regions using support vector machine analyses were shown to drive moment-by-moment decoding accuracy in other successful decoding regions using a Kalman filter implementation of Granger causation. The implicated regions were posterior temporal areas independently implicated in the processing of spoken words. Gow et al. (<xref ref-type="bibr" rid="CR29">2023</xref>) suggested that these results demonstrate the propagation of representations of syllable repetitions.</p><p id="Par7">In this study, we used a transfer-learning neural decoding and integrated effective connectivity approach, based on region of interest (ROI)-oriented source-reconstructed MEG/EEG activity, to identify and examine wordform representations. We isolated wordform representations by training classifiers to discriminate between activity evoked by sets of words and nonwords with overlapping phonology, for example<italic>, pick</italic> and <italic>pid</italic> (neighbors of <italic>pig</italic>) versus <italic>tote</italic> and <italic>tobe</italic> (neighbors of <italic>toad</italic>). We then tested the classifiers' ability to discriminate between untrained hub words, for example, <italic>pig</italic> versus <italic>toad</italic>. We reasoned that classifiers trained on activity prior to word recognition or nonword rejection would rely on the segmental overlap between neighbors and hub words, but that classification after word recognition would reflect similarity in global activation patterns associated with the consolidated representation of lexical neighbors. Because neighbors were defined by form similarity rather than semantic similarity, we reasoned that transfer performance would specifically depend on overlap in form representation between hub words and their neighbors. The inclusion of phonologically overlapping nonwords further allowed us to discriminate between lexically mediated classification (which should only occur for words) and sublexical influences (common to both words and nonwords). By comparing the alignment of overlap between neighbors and hub words (initial CV vs. final VC), we were further able to examine the role of word onsets and offsets in decoding. Word onsets play an out-sized role in spoken word recognition (see, e.g., Marslen-Wilson &#x00026; Tyler, <xref ref-type="bibr" rid="CR64">1980</xref>), and so evidence of a decoding advantage for training sets that share an initial CV would be consistent with the claim that decoding taps lexical representation rather than simple phonological overlap. Finally, to determine whether decoded patterns had causal influences on downstream processing, we used the implementation of Granger causality analysis developed in Gow et al. (<xref ref-type="bibr" rid="CR29">2023</xref>) to determine whether within-ROI activation patterns that support decoding in one area influenced decoding performance in downstream processing areas.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Participants</title><p id="Par8">Twenty subjects (14 female) between the ages of 21 to 43 years (mean 29.5, SD = 7.1 years) participated. All were native speakers of American English and had no auditory, motor, or uncorrected visual impairments that could interfere with the task. Human participation was approved by the Human Subjects Review Board, and all procedures were conducted in compliance with the principles for ethical research established by the Declaration of Helsinki.</p></sec><sec id="Sec4"><title>Stimuli</title><p id="Par9">The stimuli consisted of spoken CVC words and nonwords. To limit the potential influence of gross low-level acoustic properties on classification, only stop consonants were used (/b,d,g,p,t,k/). Six words (<italic>pig, toad, cab, bike, dupe, gut</italic>) were chosen as hub words. These were each used to define a set of phonological neighbors. For each hub, we created three word and three nonword neighbors by changing only one phoneme, with the position of the changed phoneme counterbalanced across the three positions. Consonant changes involved either the voice or place feature. Changed vowels were selected to be in close proximity to the hub vowel in F1/F2 space, but this requirement was applied less strictly in order to generate word and nonword tokens. The full set of words and nonwords is included in the Online Supplementary Material (OSM; Table <xref rid="MOESM1" ref-type="media">S1</xref>). The stimuli were recorded by two speakers, one male and one female. All final consonants were fully released, which provided a cue to item offset. After normalizing the duration to 350 ms and the intensity to 70 dB SPL, a Praat script was used to make additional versions of each token by scaling formant values and mean F0 to create eight discriminable virtual talkers with different vocal tract sizes (Darwin et al., <xref ref-type="bibr" rid="CR17">2003</xref>). This allowed us to both introduce spectral variability within the training set and increase the power of the design.</p></sec><sec id="Sec5"><title>Procedure</title><p id="Par10">Simultaneous MEG and EEG data were recorded while the subjects completed a lexical decision task using these stimuli. As the subjects listened to the recorded stimuli, the task was to determine whether or not the token they heard was a valid English word and signal their judgment via a left-handed keypress on a response pad. The subjects were asked to respond as accurately as possible. Stimuli were presented in 16 blocks, with two non-consecutive blocks assigned to each virtual talker. Within a block, each of the hub words was presented twice and each neighbor once, for a total of 48 trials. Trials were presented in a pseudo-randomized order, with the constraint that the second presentation of a hub word could not directly follow the first presentation. Stimulus presentation was controlled via PsychToolbox for Matlab (Kleiner et al., <xref ref-type="bibr" rid="CR49">2007</xref>).</p><p id="Par11">The MEG/EEG data were collected using a Vectorview system (MEGIN, Finland) with 306 MEG channels, a 70-channel EEG cap, and vertical and horizontal electrooculograms. The EEG data were referenced to a nose electrode during the recording. All data were low-pass filtered at 330 Hz and sampled at 1,000 Hz. Prior to the testing, the locations of anatomical landmarks (nasion, and left and right preauricular points), four head-position indicator (HPI) coils, the EEG electrodes, and over 100 additional surface points on the scalp were digitized using a FASTRAK 3D digitizer (Polhemus, Colchester, VT). The head position with respect to the MEG sensor array was measured at the start of each block via the HPI coils and was tracked continuously during task performance. In a separate session, T1-weighted structural MRIs were collected from each subject on a 3T Siemens TIM Trio scanner using an MPRAGE sequence.</p></sec><sec id="Sec6"><title>Behavioral analysis</title><p id="Par12">Behavioral accuracy was analyzed using the lme4 (Bates &#x00026; Bolker, <xref ref-type="bibr" rid="CR8">2012</xref>) and lmerTest (Kuznetsova et al., <xref ref-type="bibr" rid="CR54">2017</xref>) packages in R (R Core Team, <xref ref-type="bibr" rid="CR84">2023</xref>) to perform a logistic mixed-effects analysis of the relationship between accuracy and lexical class (two levels: Words vs. Nonwords). We ran the full model with word condition as the reference level. Lexical class was treated as a fixed effect. We used random intercepts and slopes for lexical class by participants and random intercepts for lexical class by items. We reported the model estimation of the change in accuracy rate (in log odds) from the reference category for each fixed effect (b), standard error of the estimate (SE), Wald z test statistic (z), and the associated p values.</p></sec><sec id="Sec7"><title>MEG/EEG preprocessing and source reconstruction</title><p id="Par13">MEG/EEG data were processed offline using MNE-C (Gramfort et al., <xref ref-type="bibr" rid="CR37">2014</xref>) via the Granger Processing Stream software (Gow &#x00026; Caplan, <xref ref-type="bibr" rid="CR30">2012</xref>). Eyeblinks were identified manually, and a set of signal space projectors corresponding to eyeblinks and empty room noise were removed from the MEG data. Epochs from -100 to 1,000 ms time-locked to the onset of the auditory stimuli were extracted after low-pass filtering the data at 50 Hz. Epochs with high magnetometer (&#x0003e;&#x000a0;100 pT) or gradiometer (&#x0003e;&#x000a0;300 pT/cm) values were rejected. The remaining epochs were averaged across all trials with a correct response for each subject.</p><p id="Par14">All decoding and effective connectivity analyses were based on MEG/EEG source estimates for a set of ROIs. Source estimation enables the interpretation of the results in terms of brain regions, and also allows connectivity analyses between regions, reducing confounds due to the spatial spread of signals over several MEG and EEG sensors (Schoffelen &#x00026; Gross, <xref ref-type="bibr" rid="CR87">2009</xref>). Minimum Norm Estimates (MNEs) were calculated for each individual subject to reconstruct event-related electrical activity in the brain (H&#x000e4;m&#x000e4;l&#x000e4;inen &#x00026; Ilmoniemi, <xref ref-type="bibr" rid="CR42">1994</xref>). The MEG/EEG source space consisted of ~10,000 current dipoles located on the cortical surfaces reconstructed from the structural MRIs using Freesurfer (<ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu/">http://surfer.nmr.mgh.harvard.edu/</ext-link>). For the MEG/EEG forward model, a three-compartment (Leahy et al., <xref ref-type="bibr" rid="CR57">1998</xref>) boundary element model was used, with the skull and scalp boundaries obtained from the MRIs. The MRI and MEG/EEG data were co-registered using information from the digitizer and the HPI coils. The MNE inverse operator was constructed with free source orientation for the dipoles. Source estimates were obtained by multiplying the MEG/EEG sensor data with the inverse operator. The source estimates for each individual subject were then brought into a common space obtained by spherical morphing of the MRI data using Freesurfer (Fischl et al., <xref ref-type="bibr" rid="CR20">1999</xref>) and averaged to create the group average source reconstruction that was used to perform ROI generation. For the ROI source waveforms used in the decoding and effective connectivity analyses, we calculated noise-normalized MNE time courses for each ROI using dynamic statistical parametric mapping (dSPM).</p><p id="Par15">ROIs were generated from the grand average evoked response using procedures previously described by Gow and Caplan (<xref ref-type="bibr" rid="CR30">2012</xref>) designed to identify ROIs that meet the assumptions of Granger Causality analysis. Briefly, a set of potential centroid locations was generated consisting of the source space dipoles on the cortical surfaces with the highest activation in the time window from 100 to 500 ms after stimulus onset. From those centroids, neighboring dipoles were included into a growing ROI and distant dipoles were excluded from the final set of ROIs based on metrics of similarity, redundancy, and spatial weight. Because our decoding analyses rely on subdividing ROIs, it is beneficial to produce larger ROIs; we thus loosened our empirically determined similarity and redundancy constraints relative to previous studies (Gow &#x00026; Nied (<xref ref-type="bibr" rid="CR31">2014</xref>); see OSM Fig. <xref rid="MOESM1" ref-type="media">1</xref> for an example ROI set created using previous parameters). This adjustment may increase the rate of type II errors through the inclusion of otherwise redundant signals but would not increase the likelihood of false-positive results in Granger analyses. This process resulted in a total of 39 ROIs, which were then transformed to each individual subject's source space.</p><p id="Par16">For decoding analyses, individual ROIs were split into eight approximately equal-sized subdivisions. dSPM source time courses were calculated for each subdivision by averaging the source time courses of all the source dipoles within the subdivision. The mean value over the 100-ms pre-stimulus baseline period was subtracted, and the data were vector normalized across subdivisions for each timepoint in each epoch.</p><p id="Par17">Source-space analyses of MEG and EEG significantly strengthen the interpretation of connectivity measures, compared with sensors-space analyses (Haufe et al., <xref ref-type="bibr" rid="CR45">2013</xref>). However, there will inevitably be some crosstalk between the estimated ROI source waveforms (Liu et al., <xref ref-type="bibr" rid="CR59">1998</xref>). Crosstalk can potentially lead to false-positive effects when a true effect in one ROI is falsely seen also in another ROI, or false-negative effects when the sensitivity to a true effect in one ROI is diminished due to the influence of crosstalk signal from another ROI without the effect. To minimize crosstalk effects, several steps were undertaken. First, we recorded simultaneous MEG and EEG, which can provide better spatial resolution than either method by itself (Sharon et al., <xref ref-type="bibr" rid="CR89">2007</xref>). Second, our data-driven algorithm for determining the ROIs was designed to maximize dissimilarity between the ROI source waveforms (Gow &#x00026; Caplan, <xref ref-type="bibr" rid="CR30">2012</xref>). Third, effective connectivity analyses are based on prediction of future time points and thus less sensitive to the strictly spatial effects of crosstalk than zero-lag correlation-based connectivity measures (Nolte et al., <xref ref-type="bibr" rid="CR74">2004</xref>). Our previous studies of Granger causality among a relatively large number of ROIs (up to 68) have provided consistent results on speech and language-related processing (Avcu et al., <xref ref-type="bibr" rid="CR5">2023</xref>; Gow et al., <xref ref-type="bibr" rid="CR36">2008</xref>, <xref ref-type="bibr" rid="CR29">2023</xref>). Also, notably Michalareas et al. (<xref ref-type="bibr" rid="CR70">2016</xref>) successfully analyzed effective connectivity among 26 human visual cortical areas using 275-channel MEG.</p></sec><sec id="Sec8"><title>Neural decoding</title><p id="Par18">Neural decoding analyses with a transfer learning design were conducted to evaluate phonological neighborhood representations using support vector machine (SVM) classifiers (Beach et al., <xref ref-type="bibr" rid="CR9">2021</xref>). The SVM classifiers were trained to discriminate neighborhoods using only trials in which the neighbors were presented, then tested on their performance to discriminate the corresponding hub words in a transfer learning design. Pairwise classification was done at each time point within the epoch for all neighborhood pairs.</p><p id="Par19">To increase the robustness of the ROI source waveforms as input to the SVM, bins of eight trials were randomly selected and averaged within each condition. The random bin assignment was repeated 100 times for each condition. Single timepoints from these bin averages were used as the input to the SVM, and the average classification accuracy across the 100 bin assignments was used as the measure of decoding accuracy for each time point. Performance of these classifiers was then averaged across all pairwise neighborhood contrasts. For statistical analysis, the decoding accuracy data were submitted to cluster-based permutation tests at the group level. Clusters were defined as consecutive time points of above chance performance (alpha = 0.05; chance performance = 50% for pairwise classification). The observed accuracy data for each subject were then randomly flipped with respect to chance accuracy (Beach et al., <xref ref-type="bibr" rid="CR9">2021</xref>) across 1,000 permutations, and the largest cluster within each permutation was taken to form a distribution of cluster sizes. The cluster statistic was Bonferroni-adjusted (for 39 ROIs) with <italic>p</italic> &#x0003c; 0.00128 needed to reach significance with a corrected alpha of 0.05.</p><p id="Par20">Our primary decoding analyses contrasted the transfer discrimination of pairs of hub words based on training by exclusively word or nonword neighbors (Cheng et al., <xref ref-type="bibr" rid="CR14">2014</xref>). The purpose was to determine the degree to which decoding relied on stored representations of known words as opposed to sublexical overlap present in both neighboring words and nonwords. In addition, to further isolate the effects of sublexical overlap, we compared the decoding of hub word contrasts as a function of positional overlap between the neighbors and hub words. All nonwords in the study partially overlapped with real words, and any decoding based on nonword training could be due to this overlap. Given evidence for the relative importance of onsets in spoken word recognition (Marslen-Wilson &#x00026; Tyler, <xref ref-type="bibr" rid="CR64">1980</xref>), we hypothesized that overlap between the initial CV- of words and nonwords in the training set and hub words (e.g., the neighbors <italic>pick</italic>, <italic>pid</italic>, and the hub word <italic>pig</italic>) would produce better decoding than overlap involving the final -VC of training words (e.g., <italic>big</italic>, <italic>tig</italic>, and <italic>pig</italic>). To compare between conditions, a second set of cluster permutation tests was performed with an additional constraint: timepoints had to both be above chance (uncorrected alpha &#x0003c; 0.05) and different than the comparator condition (uncorrected alpha &#x0003c; 0.05) to be included in clusters. Permutations randomly flipped the relationship of observed data with respect to both the chance accuracy and zero difference between conditions null values. Clusters with Bonferroni-adjusted (for 39 ROIs) <italic>p</italic> &#x0003c; 0.00128 were counted as significantly different between conditions (alpha = 0.05).</p></sec><sec id="Sec9"><title>Effective connectivity analyses</title><p id="Par21">Effective connectivity analyses follow our previously published Granger causality analysis approach (Gow &#x00026; Caplan, <xref ref-type="bibr" rid="CR30">2012</xref>), with modifications to integrate the results of the decoding analysis as described in Gow et al. (<xref ref-type="bibr" rid="CR29">2023</xref>). The goal of the modified Granger causality analyses was to identify whether the activation time courses in ROIs that supported decoding could predict (or "Granger cause") the SVM classifier accuracy time courses in other ROIs. The integration involved substituting the single source waveform activation time course for each ROI (normally used in our Granger analyses) with data relevant to the decoding analyses. When evaluating the influence of a given ROI on others, the single activation time course for that ROI was substituted by the eight subdivision dSPM time courses used in the decoding analysis. When evaluating how other ROIs influenced a given ROI, the single activation time course for that ROI was substituted by the within-subject neural decoding accuracy time course averaged across all pairwise conditions from the decoding analysis based on word neighbors as the training set. All 39 ROIs were included in the predictive models, but only relationships between ROIs that showed significant transfer decoding for words were analyzed.</p><p id="Par22">Representations, formally defined, require that the activity not only decode but also be related to a functional outcome (Dennett, <xref ref-type="bibr" rid="CR19">1987</xref>; Kriegeskorte &#x00026; Diedrichsen, <xref ref-type="bibr" rid="CR51">2019</xref>). Our analysis thus focused on influences between regions that supported word-based transfer decoding to see how these activations reinforce each other when words were presented. Specifically, we examined the ability of the estimated activation time courses in a decoding ROI to predict the decoding accuracy in the other decoding ROIs. We selected the window of analysis to 250&#x02013;550 ms, following latencies used for the lexically conditioned N400 ERP (Kutas &#x00026; Federmeier, <xref ref-type="bibr" rid="CR53">2011</xref>). The strength of Granger causality, as quantified by the number of time points with a significant Granger Causality index, was compared in the single word condition to a control pair of ROIs (Milde et al., <xref ref-type="bibr" rid="CR71">2010</xref>) that did not exhibit transfer decoding in our analyses or have plausible processing relationship in this paradigm , L-cMFG1 and R-LOC1, using binomial tests.</p></sec></sec><sec id="Sec10"><title>Results</title><sec id="Sec11"><title>Behavioral results</title><p id="Par23">Overall mean behavioral accuracy on the lexical decision was 90% (SD = 2.8%). Accuracy was higher for words (92%; <italic>SD </italic>= 4.4%) than for nonwords (86%; SD = 6.3%). This difference was statistically significant (<italic>b</italic> = 1.18, <italic>SE</italic> = 0.46, <italic>z</italic> =2.58, <italic>p</italic> =.01).</p></sec><sec id="Sec12"><title>Regions of interest</title><p id="Par24">A set of 39 ROIs associated with overall task-related activation was identified through our process of grouping contiguous cortical source locations associated with activation peaks that share similar temporal activation patterns (Fig. <xref rid="Fig1" ref-type="fig">1</xref>, Table <xref rid="MOESM1" ref-type="media">S2</xref> (OSM)). These ROIs were used for neural decoding and effective connectivity analyses.<fig id="Fig1"><label>Fig. 1</label><caption><p>Regions of interest (ROIs) visualized over an inflated averaged cortical surface. Lateral (<bold>top</bold>) and medial (<bold>bottom</bold>) views of the left and right hemisphere are shown. ROI names are generated based on the location of the centroid vertex for each ROI in the Desikian-Killiany atlas parcellation of the average subject brain. For further description of the ROIs, see Table <xref rid="MOESM1" ref-type="media">S2</xref> (Online Supplementary Material)</p></caption><graphic xlink:href="13423_2024_2511_Fig1_HTML" id="MO1"/></fig></p></sec><sec id="Sec13"><title>Neural decoding: Lexicality effects</title><p id="Par25">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows results of the transfer decoding analysis in which SVM classifiers were trained using exclusively either word or nonword neighbors and then tested on their ability to classify the corresponding hub words. Within the entire 1,100-ms epoch window, significant clusters of decoding time points were found in five of the 39 ROIs (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A): L-STG<sub>1</sub>, R-STG<sub>2</sub>, R-MTG<sub>2</sub>, R-ITG<sub>3</sub>, and R-postCG<sub>5</sub>. With the exception of R-postCG<sub>5</sub>, which shows a brief earlier period of decoding, all decoding begins after the point (~ 225 ms) at which Gwilliams et al. (<xref ref-type="bibr" rid="CR41">2022</xref>) identify the earliest decoding of the third phoneme of words in connected speech. All five of these produced successful transfer decoding of hub words when trained with word neighbors. When trained with nonword neighbors, only L-STG<sub>1</sub> produced successful transfer decoding and only prior to stimulus offset. This timing falls after the potential decodability of the phoneme that makes training items nonwords, but possibly before all phonemic information is integrated in lexical representations. Overall, training with word neighbors resulted in better decoding across more ROIs than training with nonword neighbors.<fig id="Fig2"><label>Fig. 2</label><caption><p>Bonferonni-corrected significant (corrected alpha = 0.05) transfer decoding clusters after training with word or nonword neighbors. (<bold>A</bold>) Clusters of significant above chance transfer decoding accuracy for words-only (blue solid) or nonwords-only (red dotted) conditions. (<bold>B</bold>) Clusters of transfer decoding accuracy which is above chance and significantly differs between training conditions. Better transfer decoding for words-only condition indicated by blue solid bars; no clusters of better transfer decoding for nonwords-only condition were observed. The vertical dotted line in both panels indicates the offset of the auditory stimuli</p></caption><graphic xlink:href="13423_2024_2511_Fig2_HTML" id="MO2"/></fig></p><p id="Par26">Differences between conditions were observed in a total of six ROIs (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). All significant differences showed better decoding when trained with words than with nonwords. Prior to stimulus offset, two ROIs showed a difference between training conditions: L-ParaHip<sub>1</sub> and R-postCG<sub>2</sub>. Four ROIs showed a difference during the post-offset period between 400 and 600 ms: L-MTG<sub>1</sub>, R-STG<sub>1</sub>, R-STG<sub>2</sub>, and R-ITG<sub>3</sub>. These differences are consistent with a lexically mediated effect.</p></sec><sec id="Sec14"><title>Neural decoding: Positional effects</title><p id="Par27">We also examined the role of onset overlap between neighbors in the training set and hub word decoding. We hypothesized that neighbors that share a common CV onset with hub words would support more accurate hub word decoding than neighbors that share the same amount of overlap at their VC offsets. Within the entire epoch window, significant clusters of decoding time points were found in six of the 39 ROIs (Fig. <xref rid="MOESM1" ref-type="media">S3</xref>A (OSM)) when classifiers were trained by neighbors that shared initial CV- sequences: L-STG<sub>1</sub>, R-STG<sub>1</sub>, R-STG<sub>2</sub>, R-STG<sub>3</sub>, R-postCG<sub>5</sub> and R-preCG<sub>2</sub>. No ROIs produced successful transfer decoding when trained only by neighbors that shared final -VC sequences. Significant differences were found prior to stimulus offset for 13 ROIs (Fig. <xref rid="MOESM1" ref-type="media">S3</xref>B (OSM)), with better decoding observed for initial CV- overlap in L-STG<sub>1</sub>, L-MTG<sub>2</sub>, L-ParsOrb<sub>1</sub>, R-STG<sub>1</sub>, R-STG<sub>2</sub>, R-STG<sub>3</sub>, R-MTG<sub>2</sub>, R-MTG<sub>4</sub>, R-ITG<sub>1</sub>, R-postCG<sub>4</sub>, R-postCG<sub>5</sub>, R-preCG<sub>2</sub>, and R-ParsOrb<sub>1</sub>. L-STG<sub>1</sub> also supported better decoding for final -VC overlap over initial CV- overlap, but this was late in the epoch after the period typically associated with automatic spoken word recognition (Kutas &#x00026; Federmeier, <xref ref-type="bibr" rid="CR53">2011</xref>). As predicted, we found better decoding was achieved using training neighbors with initial than with final overlap. Across both analyses, decoding supported by initial CV overlap generally occurred before stimulus offset. We believe this is due to the inclusion of nonwords in the training sets that failed to support lexical representation after they became inconsistent with lexical candidates.</p></sec><sec id="Sec15"><title>Effective connectivity analyses</title><p id="Par28">To determine whether local patterns of neural activity influence downstream neural processing, we examined whether the event-related neural activity in any one of our decoding ROIs significantly influenced the decoding accuracy in the others within the 250- to 550-ms window associated with lexical processing indexed by the N400 component (Kutas &#x00026; Federmeier, <xref ref-type="bibr" rid="CR53">2011</xref>). We focused on interactions among the five ROIs (L-STG<sub>1</sub>, R-STG<sub>2</sub>, R-MTG<sub>2</sub>, R-ITG<sub>3</sub>, and R-postCG<sub>5</sub>) that successfully discriminated hub words after training with real word neighbors of those hubs. FDR-corrected tests revealed 13 significant interactions (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). These included reciprocal connections between R-MTG<sub>2</sub> and L-STG<sub>1</sub>, R-STG<sub>2</sub> and R-postCG<sub>5</sub>, as well as between L-STG<sub>1</sub> and R-ITG<sub>3</sub>.We hypothesize that reciprocal relationships reflect a resonance dynamic that develops parity between representations, for example aligning wordform representations hypothesized to occur in posterior middle temporal gyrus/inferior temporal gyrus (MTG/ITG) (Gow, <xref ref-type="bibr" rid="CR28">2012</xref>; Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>) with lower level segmental representations associated with superior temporal gyrus (STG) (Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>; Mesgarani et al., <xref ref-type="bibr" rid="CR69">2014</xref>).<fig id="Fig3"><label>Fig. 3</label><caption><p>Effective connectivity analysis of transfer decoding regions of interest (ROIs). Effective connectivity between the five ROIs that supported reliable transfer decoding of hub words after training with word neighbors in the interval of 250&#x02013;550 ms after the onset of the word. Lighter arrows indicate significant one-way directed Granger causation between ROIs. Darker green arrows indicate significant reciprocal connectivity. Significance is based on FDR-corrected binomial testing with an alpha of 0.05</p></caption><graphic xlink:href="13423_2024_2511_Fig3_HTML" id="MO3"/></fig></p></sec></sec><sec id="Sec16"><title>Discussion</title><p id="Par29">We undertook this study to isolate wordform representations and examine their neural basis. Wordforms were isolated from segmental overlap in time and from semantic overlap in feature space using phonological neighborhoods. We found significant decoding after training with either word or nonword neighbors prior to stimulus offset, consistent with incremental acoustic-phonetic processing before the presentation of the stimulus was complete. Indeed, when training was based on phonological overlap of the initial consonant, the same ROIs were able to decode, suggesting phonological overlap alone was sufficient to produce decoding in the word and/or nonword conditions early in the epoch. In contrast, post-stimulus offset decoding occurred mainly after training with word neighbors, suggesting lexical sensitivity in the wordform representation. This post-offset regime aligned with the well-characterized event-related potential evidence of lexical processing, including the N400 (Kutas &#x00026; Federmeier, <xref ref-type="bibr" rid="CR53">2011</xref>). Additionally, phonological overlap alone did not produce transfer decoding in the immediate post-offset period, strengthening the case for lexical sensitivity. The lexically sensitive decoding occurred in a bilateral network of mostly temporal lobe regions. The effective connectivity analysis showed that the word-evoked activity in these regions preferentially influenced decoding accuracy in other decoding regions, with one region in right posterior middle temporal gyrus, R-MTG<sub>2</sub>, showing direct reciprocal influences on all but one of its fellow decoding regions (R-ITG<sub>3</sub>), and indirect influences on that area (mediated by interactions with R-STG<sub>2</sub>). Independent evidence that the bilateral posterior middle temporal gyrus is involved in lexical processing (see reviews by Gow, <xref ref-type="bibr" rid="CR28">2012</xref>, and Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>) attests to the plausibility of this region as a site for wordform representation. To sum up, our results revealed a bilateral network of temporal lobe areas that were sensitive to both the phonology and lexicality of word-like stimuli and also affected downstream processing.</p><p id="Par30">We achieved these results despite implementing a difficult decoding design. Rather than a leave-n-out cross-validation approach common to many decoding studies (Guggenmos et al., <xref ref-type="bibr" rid="CR40">2018</xref>; Hastie et al., <xref ref-type="bibr" rid="CR44">2009</xref>), we tested the classifiers in a transfer learning design with stimuli from multiple talkers. The SVMs were trained on one set of words or nonwords and tested on an untrained set of phonologically similar words, based on the assumption that phonologically similar words have overlapping patterns of distributed neural representation. Additionally, our ROI-based approach restricted the signals that the SVM could rely upon to classify epochs. We made these design choices to address qualities necessary to establish a representation. As formally defined by Dennett (<xref ref-type="bibr" rid="CR19">1987</xref>) and Kriegeskorte and Diedrichsen (<xref ref-type="bibr" rid="CR51">2019</xref>), for a signal to be a representation it must index the stimulus feature, affect downstream processing, and have a plausible localization. Our integrated approach allowed us to evaluate all three criteria: the decoding analyses tested for feature sensitivity; the effective connectivity analyses examined downstream effects; and the ROI-based approach addressed the location.</p><p id="Par31">Most of the ROIs that decoded hub words based on training with words were in bilateral temporal lobe regions previously implicated a variety of spoken languages functions. Posterior middle temporal regions that decoded for words (combining results from the single condition and differences between condition analyses) include L-MTG<sub>1</sub> and R-MTG<sub>2</sub>, located in regions that have been implicated in wordform representation. Posterior MTG and adjacent areas have been specifically implicated in wordform representations that mediate the mapping between sound and meaning (Gow, <xref ref-type="bibr" rid="CR28">2012</xref>; Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>). Imaging studies have shown that activation in these posterior temporal regions is influenced by wordform properties such as word frequency, lexical neighborhood size, lexical enhancement/suppression, phonological similarity, and word-level structural properties (Biran &#x00026; Friedmann, <xref ref-type="bibr" rid="CR12">2005</xref>; Gow et al., <xref ref-type="bibr" rid="CR29">2023</xref>; Graves et al., <xref ref-type="bibr" rid="CR38">2007</xref>; Prabhakaran et al., <xref ref-type="bibr" rid="CR83">2006</xref>; Righi et al., <xref ref-type="bibr" rid="CR85">2009</xref>). In addition, damage to posterior temporal regions has been shown to produce deficits in lexico-semantic processing (Axer et al., <xref ref-type="bibr" rid="CR6">2001</xref>; Coslett et al., <xref ref-type="bibr" rid="CR16">1987</xref>; Goldstein, <xref ref-type="bibr" rid="CR27">1948</xref>; Wernicke, <xref ref-type="bibr" rid="CR94">1970</xref>).</p><p id="Par32">R-ITG<sub>3</sub> is an anterior temporal ROI sensitive to wordform, located in a region that has been associated with word retrieval (Abrahams et al., <xref ref-type="bibr" rid="CR1">2003</xref>), attention to semantic relations (McDermott et al., <xref ref-type="bibr" rid="CR67">2003</xref>), and representing the semantic similarity among concepts (Patterson et al., <xref ref-type="bibr" rid="CR78">2007</xref>). Superior temporal ROIs included L-STG<sub>1</sub> and R-STG<sub>1,2,</sub>, in regions that have been shown to be sensitive to the processing and representation of the sound structure of language (Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>; Mesgarani et al., <xref ref-type="bibr" rid="CR69">2014</xref>). Effective connectivity studies of phonotactic repair in phoneme categorization judgments (Gow &#x00026; Nied, <xref ref-type="bibr" rid="CR31">2014</xref>), phonological acceptability judgments (Avcu et al., <xref ref-type="bibr" rid="CR5">2023</xref>), and phonotactic frequency effects on lexical decision (Gow &#x00026; Olson, <xref ref-type="bibr" rid="CR32">2015</xref>, <xref ref-type="bibr" rid="CR33">2016</xref>; Gow &#x00026; Segawa, <xref ref-type="bibr" rid="CR35">2009</xref>; Gow et al., <xref ref-type="bibr" rid="CR36">2008</xref>) suggest the possibility of "referred lexical sensitivity" arising from resonance between acoustic-phonetic representation in superior temporal regions and lexical representation in middle temporal regions and supramarginal gyrus.</p><p id="Par33">Outside of the temporal lobe, a ventral sensorimotor ROI, R-postCG<sub>5</sub>, showed decoding for words after stimulus presentation. This specific ROI aligns with a segment of the sensorimotor cortex involved in oral movements (Pardo et al., <xref ref-type="bibr" rid="CR77">1997</xref>), sensitive to the frequency of articulatory patterns (Treutler &#x00026; S&#x000f6;r&#x000f6;s, <xref ref-type="bibr" rid="CR93">2021</xref>) and associated with the perception of spoken language (Schomers &#x00026; Pulverm&#x000fc;ller, <xref ref-type="bibr" rid="CR88">2016</xref>; Tremblay &#x00026; Small, <xref ref-type="bibr" rid="CR92">2011</xref>).</p><p id="Par34">The positional analysis (Figs. <xref rid="MOESM1" ref-type="media">S3</xref> and <xref rid="MOESM1" ref-type="media">S4</xref> (OSM)) showed that word-initial overlap between training and test items supported decoding by more ROIs than did word-final overlap. This aligns with behavioral results that have shown that spoken word recognition relies more heavily on word onsets than offsets (Allopenna et al., <xref ref-type="bibr" rid="CR3">1998</xref>; Marslen-Wilson &#x00026; Tyler, <xref ref-type="bibr" rid="CR64">1980</xref>; Marslen-Wilson, <xref ref-type="bibr" rid="CR63">1987</xref>). Despite this onset-bias, more ROIs decoded in the word analysis than in the onset analysis specifically in the post-offset period, suggesting that overlap at each position contributed to classification performance in the word condition. While phonological representations appear to persist for up to hundreds of milliseconds after presentation (Gwilliams et al., <xref ref-type="bibr" rid="CR41">2022</xref>), we did not observe transfer decoding based on phonological overlap after stimulus presentation. This implies that the neural activation patterns reflected parallel activation of stored words with overlapping phonology. Evidence for overlapping neural representation of phonologically similar words suggests a neural basis for lexically mediated "gang effects" supporting a variety of speech and spoken word recognition effects where less activated lexical candidates provide cumulative top-down support based on phonological overlap with input representations. This interpretation is consistent with the claims of the TRACE model (McClelland &#x00026; Elman, <xref ref-type="bibr" rid="CR66">1986</xref>), in which cohort size, length of the target word, and phonetic saliency can modulate the intensity of gang effects and their role in onset effects, phonotactic repair, and categorical speech perception (Hannagan et al., <xref ref-type="bibr" rid="CR43">2013</xref>).</p><p id="Par35">The results of our integrated effective connectivity analyses strengthen the argument for functional representation of decodable properties. The results show a dense pattern of interaction between decoding regions with activity that supports decoding of hub word contrasts based on training with their word neighbors influencing decoding accuracy in other ROIs. Significantly, most interactions are reciprocal and involve an ROI in lexically implicated right posterior middle temporal gyrus, R-MTG<sub>2</sub> (Gow, <xref ref-type="bibr" rid="CR28">2012</xref>; Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>). The reciprocal effective connectivity between this region and bilateral posterior STG (L-STG<sub>1</sub> and R-STG<sub>2</sub>) is consistent with prior findings showing that behavioral evidence for lexical influences on speech perception coincides with increased Granger influences by posterior MTG on posterior STG (Gow &#x00026; Nied, <xref ref-type="bibr" rid="CR31">2014</xref>; Gow &#x00026; Olson; Gow &#x00026; Olson, <xref ref-type="bibr" rid="CR32">2015</xref>; Gow et al., <xref ref-type="bibr" rid="CR34">2021</xref>). Whereas damage to posterior MTG is associated with lexical deficits, damage to posterior STG is not associated with specifically lexical deficits (Gow, <xref ref-type="bibr" rid="CR28">2012</xref>; Hickok &#x00026; Poeppel, <xref ref-type="bibr" rid="CR48">2007</xref>). This implies that decoding of lexical neighbors by posterior STG reflects segmental representations (Gwilliams et al., <xref ref-type="bibr" rid="CR41">2022</xref>; Mesgarani et al., <xref ref-type="bibr" rid="CR69">2014</xref>) that are enhanced by resonance with word level representations in posterior MTG. These representations may be further stabilized by reciprocal connections over a larger network of wordform-informed representations of articulation in inferior postcentral gyrus (R-postCG<sub>5</sub>) and representations integrating sensory, motor and linguistic representations in R-ITG<sub>3</sub>, a portion of anterior inferior temporal cortex with MNI coordinates consistent with the anterior temporal pole (Patterson et al., <xref ref-type="bibr" rid="CR78">2007</xref>; Small et al., <xref ref-type="bibr" rid="CR90">1997</xref>). These effective connectivity patterns demonstrate the propagation of wordform representation through a distributed network of regions involved in spoken word recognition.</p><p id="Par36">Taken together, our results provide evidence of a functional neural representation of wordform in the right temporal cortex, with contributions from left STG. The convergence of decoding and effective connectivity results with an existing experimental literature implicating this region in form-based lexical processes satisfies the requirements for demonstrating representation identified by Dennett (<xref ref-type="bibr" rid="CR19">1987</xref>) and Kriegeskorte and Diedrichsen (<xref ref-type="bibr" rid="CR51">2019</xref>). This approach provides a potential template for future experimental exploration of neural representation. While the current results provide a limited window into the content of representations of wordform, the finding that representations evoked by phonologically similar words involve sufficiently similar patterns of neural activity to support transfer decoding demonstrates that wordform representations systematically encode aspects of phonological structure rather than simply individuating words or the mapping to syntactic or semantic information. We suggest that future work exploring the content of these representations may shed light on the role that lexical representation plays in listeners&#x02019; ability to discriminate phonemic minimal pairs, while still being able to recognize words despite systematic phonemic disruption resulting from phenomena including lawful phonological processes (e.g., assimilation), reduced speech, or dialectal variation.</p></sec><sec id="Sec17" sec-type="supplementary-material"><title>Supplementary Information</title><p>Below is the link to the electronic supplementary material.<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="13423_2024_2511_MOESM1_ESM.docx"><caption><p>Supplementary file1 (DOCX 595 KB)</p></caption></media></supplementary-material></p></sec></body><back><fn-group><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p><bold>Open Practices Statement</bold></p><p>The data and materials for this experiment are available on request to gow@helix.mgh.harvard.edu pending permanent posting at the Harvard Dataverse (<ext-link ext-link-type="uri" xlink:href="https://dataverse.harvard.edu/">https://dataverse.harvard.edu/</ext-link>). This experiment was not preregistered.</p></fn></fn-group><ack><title>Acknowledgements</title><p>This work was supported by National Institute on Deafness and Other Communication Disorders (NIDCD) grant R01DC015455 (P.I. D.G.), and the NIH grants P41EB030006 and S10OD030469. We thank Adriana Schoenhaut and Olivia Newman for their help during data collection. We also thank Dimitrios Pantazis for sharing code used to implement the SVM analyses, and the Harvard Statistical Consulting Service for advice about our statistical analyses. </p></ack><notes notes-type="data-availability"><title>Data Availability</title><p>The authors confirm that the data supporting the findings of this study are available within the article [and/or] its&#x000a0;supplementary materials through the Harvard Dataverse (Gow, David, 2024, "Replication Data for Gang EffectsStudy", 10.7910/DVN/8FOV1J, Harvard Dataverse, V1). Code and documentation for our Granger&#x000a0;Processing Stream (GPS) is available at <ext-link ext-link-type="uri" xlink:href="https://www.nmr.mgh.harvard.edu/software/gps">https://www.nmr.mgh.harvard.edu/software/gps</ext-link>. GPS relies on Freesurfersoftware for MRI analysis and automatic cortical parcellation (<ext-link ext-link-type="uri" xlink:href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</ext-link>) and MNE&#x000a0;software for reconstruction of minimum norm estimates of source activity based on combined MRI, MEG and EEG&#x000a0;data (<ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/mne/">https://pypi.org/project/mne/</ext-link>). Support vector machine code can be found at&#x000a0;(<ext-link ext-link-type="uri" xlink:href="https://www.csie.ntu.edu.tw/~cjlin/libsvm">www.csie.ntu.edu.tw/~cjlin/libsvm</ext-link>).</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><mixed-citation publication-type="other">Abrahams, S., Goldstein, L. H., Simmons, A., Brammer, M. J., Williams, S. C., Giampietro, V. P., ..., Leigh, P. N. (2003). Functional magnetic resonance imaging of verbal fluency and confrontation naming using compressed image acquisition to permit overt responses. <italic>Hum Brain Mapp</italic>, <italic>20</italic>(1), 29-40. 10.1002/hbm.10126</mixed-citation></ref><ref id="CR2"><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Albright</surname><given-names>A</given-names></name></person-group><article-title>Feature-based generalization as a source of gradient acceptability</article-title><source>Phonology</source><year>2009</year><volume>26</volume><issue>1</issue><fpage>9</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1017/S0952675709001705</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Albright, A. (2009). Feature-based generalization as a source of gradient acceptability. <italic>Phonology,</italic><italic>26</italic>(1), 9&#x02013;41. 10.1017/S0952675709001705</mixed-citation></citation-alternatives></ref><ref id="CR3"><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Allopenna</surname><given-names>PD</given-names></name><name><surname>Magnuson</surname><given-names>JS</given-names></name><name><surname>Tanenhaus</surname><given-names>MK</given-names></name></person-group><article-title>Tracking the time course of spoken word recognition using eye movements: Evidence for continuous mapping models</article-title><source>Journal of Memory and Language</source><year>1998</year><volume>38</volume><issue>4</issue><fpage>419</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1006/jmla.1997.2558</pub-id></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Allopenna, P. D., Magnuson, J. S., &#x00026; Tanenhaus, M. K. (1998). Tracking the time course of spoken word recognition using eye movements: Evidence for continuous mapping models. <italic>Journal of Memory and Language,</italic><italic>38</italic>(4), 419&#x02013;439. 10.1006/jmla.1997.2558</mixed-citation></citation-alternatives></ref><ref id="CR4"><mixed-citation publication-type="other">Anderson, A. J., Binder, J. R., Fernandino, L., Humphries, C. J., Conant, L. L., Raizada, R. D., ..., &#x00026; Lalor, E. C. (2019). An integrated neural decoder of linguistic and experiential meaning. <italic>Journal of Neuroscience</italic>, <italic>39</italic>(45), 8969-8987. 10.1523/JNEUROSCI.2575-18.2019</mixed-citation></ref><ref id="CR5"><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Avcu</surname><given-names>E</given-names></name><name><surname>Newman</surname><given-names>O</given-names></name><name><surname>Ahlfors</surname><given-names>SP</given-names></name><name><surname>Gow</surname><given-names>DW</given-names><suffix>Jr</suffix></name></person-group><article-title>Neural evidence suggests phonological acceptability judgments reflect similarity, not constraint evaluation</article-title><source>Cognition</source><year>2023</year><volume>230</volume><fpage>105322</fpage><pub-id pub-id-type="doi">10.1016/j.cognition.2022.105322</pub-id><pub-id pub-id-type="pmid">36370613</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Avcu, E., Newman, O., Ahlfors, S. P., &#x00026; Gow, D. W., Jr. (2023). Neural evidence suggests phonological acceptability judgments reflect similarity, not constraint evaluation. <italic>Cognition,</italic><italic>230</italic>, 105322. 10.1016/j.cognition.2022.105322<pub-id pub-id-type="pmid">36370613</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Axer</surname><given-names>H</given-names></name><name><surname>Keyserlingk</surname><given-names>AGV</given-names></name><name><surname>Berks</surname><given-names>G</given-names></name><name><surname>Keyserlingk</surname><given-names>DGV</given-names></name></person-group><article-title>Supra-and infrasylvian conduction aphasia</article-title><source>Brain and Language</source><year>2001</year><volume>76</volume><issue>3</issue><fpage>317</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1006/brln.2000.2425</pub-id><pub-id pub-id-type="pmid">11247647</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Axer, H., Keyserlingk, A. G. V., Berks, G., &#x00026; Keyserlingk, D. G. V. (2001). Supra-and infrasylvian conduction aphasia. <italic>Brain and Language,</italic><italic>76</italic>(3), 317&#x02013;331. 10.1006/brln.2000.2425<pub-id pub-id-type="pmid">11247647</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Bailey</surname><given-names>TM</given-names></name><name><surname>Hahn</surname><given-names>U</given-names></name></person-group><article-title>Determinants of wordlikeness: Phonotactics or lexical neighborhoods?</article-title><source>Journal of Memory and Language</source><year>2001</year><volume>44</volume><issue>4</issue><fpage>568</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1006/jmla.2000.2756</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Bailey, T. M., &#x00026; Hahn, U. (2001). Determinants of wordlikeness: Phonotactics or lexical neighborhoods? <italic>Journal of Memory and Language,</italic><italic>44</italic>(4), 568&#x02013;591. 10.1006/jmla.2000.2756</mixed-citation></citation-alternatives></ref><ref id="CR8"><mixed-citation publication-type="other">Bates, D., Bolker, B. (2012) lme4. 0: Linear mixed-effects models using S4 classes. R package version 09999&#x02013;1/r1692 2012. <ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/package=lme4">http://CRAN.R-project.org/package=lme4</ext-link></mixed-citation></ref><ref id="CR9"><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Beach</surname><given-names>SD</given-names></name><name><surname>Ozernov-Palchik</surname><given-names>O</given-names></name><name><surname>May</surname><given-names>SC</given-names></name><name><surname>Centanni</surname><given-names>TM</given-names></name><name><surname>Gabrieli</surname><given-names>JD</given-names></name><name><surname>Pantazis</surname><given-names>D</given-names></name></person-group><article-title>Neural decoding reveals concurrent phonemic and subphonemic representations of speech across tasks</article-title><source>Neurobiology of Language</source><year>2021</year><volume>2</volume><issue>2</issue><fpage>254</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1162/nol_a_00034</pub-id><pub-id pub-id-type="pmid">34396148</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Beach, S. D., Ozernov-Palchik, O., May, S. C., Centanni, T. M., Gabrieli, J. D., &#x00026; Pantazis, D. (2021). Neural decoding reveals concurrent phonemic and subphonemic representations of speech across tasks. <italic>Neurobiology of Language,</italic><italic>2</italic>(2), 254&#x02013;279. 10.1162/nol_a_00034<pub-id pub-id-type="pmid">34396148</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Bhaya-Grossman</surname><given-names>I</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name></person-group><article-title>Speech computations of the human superior temporal gyrus</article-title><source>Annual Review of Psychology</source><year>2022</year><volume>73</volume><fpage>79</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-022321-035256</pub-id><pub-id pub-id-type="pmid">34672685</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Bhaya-Grossman, I., &#x00026; Chang, E. F. (2022). Speech computations of the human superior temporal gyrus. <italic>Annual Review of Psychology,</italic><italic>73</italic>, 79&#x02013;102. 10.1146/annurev-psych-022321-035256<pub-id pub-id-type="pmid">34672685</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name><name><surname>Graves</surname><given-names>WW</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name></person-group><article-title>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies</article-title><source>Cerebral Cortex</source><year>2009</year><volume>19</volume><issue>12</issue><fpage>2767</fpage><lpage>2796</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp055</pub-id><pub-id pub-id-type="pmid">19329570</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Binder, J. R., Desai, R. H., Graves, W. W., &#x00026; Conant, L. L. (2009). Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. <italic>Cerebral Cortex,</italic><italic>19</italic>(12), 2767&#x02013;2796. 10.1093/cercor/bhp055<pub-id pub-id-type="pmid">19329570</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><mixed-citation publication-type="other">Biran, M., &#x00026; Friedmann, N. (2005). From phonological paraphasias to the structure of the phonological output lexicon. <italic>Language and Cognitive Processes</italic>, <italic>20</italic>(4). 10.1080/01690960400005813</mixed-citation></ref><ref id="CR13"><citation-alternatives><element-citation id="ec-CR13" publication-type="book"><person-group person-group-type="author"><name><surname>Bresnan</surname><given-names>J</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Baltin</surname><given-names>Mark</given-names></name><name><surname>Collins</surname><given-names>Chris</given-names></name></person-group><article-title>Explaining morphosyntactic competition</article-title><source>Handbook of Contemporary Syntactic Theory</source><year>2001</year><publisher-name>Blackwell</publisher-name><fpage>1</fpage><lpage>44</lpage></element-citation><mixed-citation id="mc-CR13" publication-type="book">Bresnan, J. (2001). Explaining morphosyntactic competition. In Mark Baltin &#x00026; Chris Collins (Eds.), <italic>Handbook of Contemporary Syntactic Theory</italic> (pp. 1&#x02013;44). Blackwell.</mixed-citation></citation-alternatives></ref><ref id="CR14"><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>X</given-names></name><name><surname>Schafer</surname><given-names>G</given-names></name><name><surname>Riddell</surname><given-names>PM</given-names></name></person-group><article-title>Immediate Auditory Repetition of Words and Nonwords: An ERP Study of Lexical and Sublexical Processing</article-title><source>PLoS One</source><year>2014</year><volume>9</volume><issue>3</issue><fpage>e91988</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0091988</pub-id><pub-id pub-id-type="pmid">24642662</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Cheng, X., Schafer, G., &#x00026; Riddell, P. M. (2014). Immediate Auditory Repetition of Words and Nonwords: An ERP Study of Lexical and Sublexical Processing. <italic>PLoS One,</italic><italic>9</italic>(3), e91988. 10.1371/journal.pone.0091988<pub-id pub-id-type="pmid">24642662</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>HS</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Lyu</surname><given-names>B</given-names></name><name><surname>Randall</surname><given-names>B</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name></person-group><article-title>Decoding the real-time neurobiological properties of incremental semantic interpretation</article-title><source>Cerebral Cortex</source><year>2021</year><volume>31</volume><issue>1</issue><fpage>233</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhaa222</pub-id><pub-id pub-id-type="pmid">32869058</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Choi, H. S., Marslen-Wilson, W. D., Lyu, B., Randall, B., &#x00026; Tyler, L. K. (2021). Decoding the real-time neurobiological properties of incremental semantic interpretation. <italic>Cerebral Cortex,</italic><italic>31</italic>(1), 233&#x02013;247. 10.1093/cercor/bhaa222<pub-id pub-id-type="pmid">32869058</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Coslett</surname><given-names>HB</given-names></name><name><surname>Roeltgen</surname><given-names>DP</given-names></name><name><surname>Gonzalez Rothi</surname><given-names>L</given-names></name><name><surname>Heilman</surname><given-names>KM</given-names></name></person-group><article-title>Transcortical sensory aphasia: evidence for subtypes</article-title><source>Brain and Language</source><year>1987</year><volume>32</volume><issue>2</issue><fpage>362</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1016/0093-934X(87)90133-7</pub-id><pub-id pub-id-type="pmid">3690258</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Coslett, H. B., Roeltgen, D. P., Gonzalez Rothi, L., &#x00026; Heilman, K. M. (1987). Transcortical sensory aphasia: evidence for subtypes. <italic>Brain and Language,</italic><italic>32</italic>(2), 362&#x02013;378. 10.1016/0093-934X(87)90133-7<pub-id pub-id-type="pmid">3690258</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Darwin</surname><given-names>CJ</given-names></name><name><surname>Brungart</surname><given-names>DS</given-names></name><name><surname>Simpson</surname><given-names>BD</given-names></name></person-group><article-title>Effects of fundamental frequency and vocal-tract length changes on attention to one of two simultaneous talkers</article-title><source>The Journal of the Acoustical Society of America</source><year>2003</year><volume>114</volume><issue>5</issue><fpage>2913</fpage><lpage>2922</lpage><pub-id pub-id-type="doi">10.1121/1.1616924</pub-id><pub-id pub-id-type="pmid">14650025</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Darwin, C. J., Brungart, D. S., &#x00026; Simpson, B. D. (2003). Effects of fundamental frequency and vocal-tract length changes on attention to one of two simultaneous talkers. <italic>The Journal of the Acoustical Society of America,</italic><italic>114</italic>(5), 2913&#x02013;2922. 10.1121/1.1616924<pub-id pub-id-type="pmid">14650025</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>MH</given-names></name><name><surname>Gaskell</surname><given-names>MG</given-names></name></person-group><article-title>A complementary systems account of word learning: neural and behavioural evidence</article-title><source>Philosophical Transactions of the Royal Society of London Series B, Biological Sciences</source><year>2009</year><volume>364</volume><issue>1536</issue><fpage>3773</fpage><lpage>3800</lpage><pub-id pub-id-type="doi">10.1098/rstb.2009.0111</pub-id><pub-id pub-id-type="pmid">19933145</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Davis, M. H., &#x00026; Gaskell, M. G. (2009). A complementary systems account of word learning: neural and behavioural evidence. <italic>Philosophical Transactions of the Royal Society of London Series B, Biological Sciences,</italic><italic>364</italic>(1536), 3773&#x02013;3800. 10.1098/rstb.2009.0111<pub-id pub-id-type="pmid">19933145</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><citation-alternatives><element-citation id="ec-CR19" publication-type="book"><person-group person-group-type="author"><name><surname>Dennett</surname><given-names>DC</given-names></name></person-group><source>The intentional stance</source><year>1987</year><publisher-name>The MIT Press</publisher-name></element-citation><mixed-citation id="mc-CR19" publication-type="book">Dennett, D. C. (1987). <italic>The intentional stance</italic>. The MIT Press.</mixed-citation></citation-alternatives></ref><ref id="CR20"><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Tootell</surname><given-names>RBH</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><article-title>High resolution intersubject averaging and a coordinate system for the cortical surface</article-title><source>Human Brain Mapping</source><year>1999</year><volume>8</volume><issue>4</issue><fpage>272</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1002/(sici)1097-0193(1999)8:4</pub-id><pub-id pub-id-type="pmid">10619420</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Fischl, B., Sereno, M. I., Tootell, R. B. H., &#x00026; Dale, A. M. (1999). High resolution intersubject averaging and a coordinate system for the cortical surface. <italic>Human Brain Mapping,</italic><italic>8</italic>(4), 272&#x02013;284. 10.1002/(sici)1097-0193(1999)8:4<pub-id pub-id-type="pmid">10619420</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Frisch</surname><given-names>S</given-names></name><name><surname>Large</surname><given-names>N</given-names></name><name><surname>Pisoni</surname><given-names>D</given-names></name></person-group><article-title>Perception of wordlikeness: Effects of segment probability and length on the processing of nonwords</article-title><source>Journal of Memory and Language</source><year>2000</year><volume>42</volume><issue>4</issue><fpage>481</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1006/jmla.1999.2692</pub-id><pub-id pub-id-type="pmid">21738287</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Frisch, S., Large, N., &#x00026; Pisoni, D. (2000). Perception of wordlikeness: Effects of segment probability and length on the processing of nonwords. <italic>Journal of Memory and Language,</italic><italic>42</italic>(4), 481&#x02013;496. 10.1006/jmla.1999.2692<pub-id pub-id-type="pmid">21738287</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Ganong</surname><given-names>WF</given-names><suffix>3rd</suffix></name></person-group><article-title>Phonetic categorization in auditory word perception</article-title><source>Journal of Experimental Psychology: Human Perception and Performormance</source><year>1980</year><volume>6</volume><issue>1</issue><fpage>110</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.6.1.110</pub-id></element-citation><mixed-citation id="mc-CR22" publication-type="journal">Ganong, W. F., 3rd. (1980). Phonetic categorization in auditory word perception. <italic>Journal of Experimental Psychology: Human Perception and Performormance,</italic><italic>6</italic>(1), 110&#x02013;125. 10.1037/0096-1523.6.1.110</mixed-citation></citation-alternatives></ref><ref id="CR23"><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Gaskell</surname><given-names>MG</given-names></name><name><surname>Marslen-Wilson</surname><given-names>W</given-names></name></person-group><article-title>Representation and competition in the perception of spoken words</article-title><source>Cognitive Psychology</source><year>2002</year><volume>45</volume><issue>2</issue><fpage>220</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1016/S0010-0285(02)00003-8</pub-id><pub-id pub-id-type="pmid">12528902</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Gaskell, M. G., &#x00026; Marslen-Wilson, W. (2002). Representation and competition in the perception of spoken words. <italic>Cognitive Psychology,</italic><italic>45</italic>(2), 220&#x02013;266. 10.1016/S0010-0285(02)00003-8<pub-id pub-id-type="pmid">12528902</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Gathercole</surname><given-names>SE</given-names></name></person-group><article-title>Is nonword repetition a test of phonological memory or long-term knowledge? It all depends on the nonwords</article-title><source>Memory &#x00026; Cognition</source><year>1995</year><volume>23</volume><issue>1</issue><fpage>83</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.3758/BF03210559</pub-id><pub-id pub-id-type="pmid">7885268</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Gathercole, S. E. (1995). Is nonword repetition a test of phonological memory or long-term knowledge? It all depends on the nonwords. <italic>Memory &#x00026; Cognition,</italic><italic>23</italic>(1), 83&#x02013;94.<pub-id pub-id-type="pmid">7885268</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Gathercole</surname><given-names>SE</given-names></name><name><surname>Frankish</surname><given-names>CR</given-names></name><name><surname>Pickering</surname><given-names>SJ</given-names></name><name><surname>Peaker</surname><given-names>S</given-names></name></person-group><article-title>Phonotactic influences on short-term memory</article-title><source>Journal of Experimental Psychology: Learning Memory and Cognition</source><year>1999</year><volume>25</volume><issue>1</issue><fpage>84</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.25.1.84</pub-id><pub-id pub-id-type="pmid">9949710</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Gathercole, S. E., Frankish, C. R., Pickering, S. J., &#x00026; Peaker, S. (1999). Phonotactic influences on short-term memory. <italic>Journal of Experimental Psychology: Learning Memory and Cognition,</italic><italic>25</italic>(1), 84&#x02013;95. 10.1037/0278-7393.25.1.84<pub-id pub-id-type="pmid">9949710</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Goddard</surname><given-names>E</given-names></name><name><surname>Carlson</surname><given-names>TA</given-names></name><name><surname>Dermody</surname><given-names>N</given-names></name><name><surname>Woolgar</surname><given-names>A</given-names></name></person-group><article-title>Representational dynamics of object recognition: Feedforward and feedback information flows</article-title><source>Neuroimage</source><year>2016</year><volume>128</volume><fpage>385</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.01.006</pub-id><pub-id pub-id-type="pmid">26806290</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Goddard, E., Carlson, T. A., Dermody, N., &#x00026; Woolgar, A. (2016). Representational dynamics of object recognition: Feedforward and feedback information flows. <italic>Neuroimage,</italic><italic>128</italic>, 385&#x02013;397. 10.1016/j.neuroimage.2016.01.006<pub-id pub-id-type="pmid">26806290</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><citation-alternatives><element-citation id="ec-CR27" publication-type="book"><person-group person-group-type="author"><name><surname>Goldstein</surname><given-names>K</given-names></name></person-group><source>Language and language disturbances; aphasic symptom complexes and their significance for medicine and theory of language</source><year>1948</year><publisher-name>Grune &#x00026; Stratton</publisher-name></element-citation><mixed-citation id="mc-CR27" publication-type="book">Goldstein, K. (1948). <italic>Language and language disturbances; aphasic symptom complexes and their significance for medicine and theory of language</italic>. Grune &#x00026; Stratton.</mixed-citation></citation-alternatives></ref><ref id="CR28"><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name></person-group><article-title>The cortical organization of lexical knowledge: A dual lexicon model of spoken language processing</article-title><source>Brain and Language</source><year>2012</year><volume>121</volume><issue>3</issue><fpage>273</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2012.03.005</pub-id><pub-id pub-id-type="pmid">22498237</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">Gow, D. W. (2012). The cortical organization of lexical knowledge: A dual lexicon model of spoken language processing. <italic>Brain and Language,</italic><italic>121</italic>(3), 273&#x02013;288. 10.1016/j.bandl.2012.03.005<pub-id pub-id-type="pmid">22498237</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><mixed-citation publication-type="other">Gow, D. W., Avcu, E., Schoenhaut, A., Sorensen, D. O., &#x00026; Ahlfors, S. P. (2023). Abstract representations in temporal cortex support generative linguistic processing. Language. <italic>Cognition and Neuroscience, 38</italic>(6), 765&#x02013;778. 10.1080/23273798.2022.2157029</mixed-citation></ref><ref id="CR30"><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name><name><surname>Caplan</surname><given-names>DN</given-names></name></person-group><article-title>New levels of language processing complexity and organization revealed by granger causation</article-title><source>Frontiers in Psychology</source><year>2012</year><volume>3</volume><fpage>506</fpage><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00506</pub-id><pub-id pub-id-type="pmid">23293611</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Gow, D. W., &#x00026; Caplan, D. N. (2012). New levels of language processing complexity and organization revealed by granger causation. <italic>Frontiers in Psychology,</italic><italic>3</italic>, 506. 10.3389/fpsyg.2012.00506<pub-id pub-id-type="pmid">23293611</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name><name><surname>Nied</surname><given-names>A</given-names></name></person-group><article-title>Rules from words: Phonotactic biases in speech perception</article-title><source>PloS One</source><year>2014</year><volume>9</volume><issue>1</issue><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0086212</pub-id></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Gow, D. W., &#x00026; Nied, A. (2014). Rules from words: Phonotactic biases in speech perception. <italic>PloS One,</italic><italic>9</italic>(1), 1&#x02013;12. 10.1371/journal.pone.0086212</mixed-citation></citation-alternatives></ref><ref id="CR32"><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name><name><surname>Olson</surname><given-names>BB</given-names></name></person-group><article-title>Lexical mediation of phonotactic frequency effects on spoken word recognition: A Granger causality analysis of MRI-constrained MEG/EEG data</article-title><source>Journal of Memory and Language</source><year>2015</year><volume>82</volume><fpage>41</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2015.03.004</pub-id><pub-id pub-id-type="pmid">25883413</pub-id>
</element-citation><mixed-citation id="mc-CR32" publication-type="journal">Gow, D. W., &#x00026; Olson, B. B. (2015). Lexical mediation of phonotactic frequency effects on spoken word recognition: A Granger causality analysis of MRI-constrained MEG/EEG data. <italic>Journal of Memory and Language,</italic><italic>82</italic>, 41&#x02013;55. 10.1016/j.jml.2015.03.004<pub-id pub-id-type="pmid">25883413</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR33"><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name><name><surname>Olson</surname><given-names>BB</given-names></name></person-group><article-title>Sentential influences on acoustic-phonetic processing: A Granger causality analysis of multimodal imaging data</article-title><source>Language Cognition and Neuroscience</source><year>2016</year><volume>31</volume><issue>7</issue><fpage>841</fpage><lpage>855</lpage><pub-id pub-id-type="doi">10.1080/23273798.2015.1029498</pub-id><pub-id pub-id-type="pmid">27595118</pub-id>
</element-citation><mixed-citation id="mc-CR33" publication-type="journal">Gow, D. W., &#x00026; Olson, B. B. (2016). Sentential influences on acoustic-phonetic processing: A Granger causality analysis of multimodal imaging data. <italic>Language Cognition and Neuroscience,</italic><italic>31</italic>(7), 841&#x02013;855. 10.1080/23273798.2015.1029498<pub-id pub-id-type="pmid">27595118</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR34"><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name><name><surname>Schoenhaut</surname><given-names>A</given-names></name><name><surname>Avcu</surname><given-names>E</given-names></name><name><surname>Ahlfors</surname><given-names>S</given-names></name></person-group><article-title>Behavioral and neurodynamic effects of word learning on phonotactic repair</article-title><source>Frontiers in Psychology</source><year>2021</year><volume>12</volume><fpage>590155</fpage><pub-id pub-id-type="doi">10.3389/fpsyg.2021.590155</pub-id><pub-id pub-id-type="pmid">33776832</pub-id>
</element-citation><mixed-citation id="mc-CR34" publication-type="journal">Gow, D. W., Schoenhaut, A., Avcu, E., &#x00026; Ahlfors, S. (2021). Behavioral and neurodynamic effects of word learning on phonotactic repair. <italic>Frontiers in Psychology,</italic><italic>12</italic>, 590155. 10.3389/fpsyg.2021.590155<pub-id pub-id-type="pmid">33776832</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR35"><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name><name><surname>Segawa</surname><given-names>JA</given-names></name></person-group><article-title>Articulatory mediation of speech perception: a causal analysis of multi-modal imaging data</article-title><source>Cognition</source><year>2009</year><volume>110</volume><issue>2</issue><fpage>222</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2008.11.011</pub-id><pub-id pub-id-type="pmid">19110238</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Gow, D. W., &#x00026; Segawa, J. A. (2009). Articulatory mediation of speech perception: a causal analysis of multi-modal imaging data. <italic>Cognition,</italic><italic>110</italic>(2), 222&#x02013;236. 10.1016/j.cognition.2008.11.011<pub-id pub-id-type="pmid">19110238</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name><name><surname>Segawa</surname><given-names>JA</given-names></name><name><surname>Ahlfors</surname><given-names>SP</given-names></name><name><surname>Lin</surname><given-names>F-H</given-names></name></person-group><article-title>Lexical influences on speech perception: A Granger causality analysis of MEG and EEG source estimates</article-title><source>NeuroImage</source><year>2008</year><volume>43</volume><issue>3</issue><fpage>614</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.07.027</pub-id><pub-id pub-id-type="pmid">18703146</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal">Gow, D. W., Segawa, J. A., Ahlfors, S. P., &#x00026; Lin, F.-H. (2008). Lexical influences on speech perception: A Granger causality analysis of MEG and EEG source estimates. <italic>NeuroImage,</italic><italic>43</italic>(3), 614&#x02013;623. 10.1016/j.neuroimage.2008.07.027<pub-id pub-id-type="pmid">18703146</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><mixed-citation publication-type="other">Gramfort, A., Luessi, M., Larson, E., Engemann, D. A., Strohmeier, D., Brodbeck, C., ..., &#x00026; Hamalainen, M. S. (2014). MNE software for processing MEG and EEG data. <italic>Neuroimage</italic>, <italic>86</italic>, 446-460. 10.1016/j.neuroimage.2013.10.027</mixed-citation></ref><ref id="CR38"><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>WW</given-names></name><name><surname>Grabowski</surname><given-names>TJ</given-names></name><name><surname>Mehta</surname><given-names>S</given-names></name><name><surname>Gordon</surname><given-names>JK</given-names></name></person-group><article-title>A neural signature of phonological access: distinguishing the effects of word frequency from familiarity and length in overt picture naming</article-title><source>Journal of Cognitive Neuroscience</source><year>2007</year><volume>19</volume><issue>4</issue><fpage>617</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1162/jocn.2007.19.4.617</pub-id><pub-id pub-id-type="pmid">17381253</pub-id>
</element-citation><mixed-citation id="mc-CR38" publication-type="journal">Graves, W. W., Grabowski, T. J., Mehta, S., &#x00026; Gordon, J. K. (2007). A neural signature of phonological access: distinguishing the effects of word frequency from familiarity and length in overt picture naming. <italic>Journal of Cognitive Neuroscience,</italic><italic>19</italic>(4), 617&#x02013;631. 10.1162/jocn.2007.19.4.617<pub-id pub-id-type="pmid">17381253</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR39"><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name><surname>Grootswagers</surname><given-names>T</given-names></name><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Carlson</surname><given-names>TA</given-names></name></person-group><article-title>Finding decodable information that can be read out in behaviour</article-title><source>NeuroImage</source><year>2018</year><volume>179</volume><fpage>252</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.06.022</pub-id><pub-id pub-id-type="pmid">29886145</pub-id>
</element-citation><mixed-citation id="mc-CR39" publication-type="journal">Grootswagers, T., Cichy, R. M., &#x00026; Carlson, T. A. (2018). Finding decodable information that can be read out in behaviour. <italic>NeuroImage,</italic><italic>179</italic>, 252&#x02013;262. 10.1016/j.neuroimage.2018.06.022<pub-id pub-id-type="pmid">29886145</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR40"><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name><surname>Guggenmos</surname><given-names>M</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name><name><surname>Cichy</surname><given-names>RM</given-names></name></person-group><article-title>Multivariate pattern analysis for MEG: A comparison of dissimilarity measures</article-title><source>Neuroimage</source><year>2018</year><volume>173</volume><fpage>434</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.02.044</pub-id><pub-id pub-id-type="pmid">29499313</pub-id>
</element-citation><mixed-citation id="mc-CR40" publication-type="journal">Guggenmos, M., Sterzer, P., &#x00026; Cichy, R. M. (2018). Multivariate pattern analysis for MEG: A comparison of dissimilarity measures. <italic>Neuroimage,</italic><italic>173</italic>, 434&#x02013;447. 10.1016/j.neuroimage.2018.02.044<pub-id pub-id-type="pmid">29499313</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR41"><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name><surname>Gwilliams</surname><given-names>L</given-names></name><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Marantz</surname><given-names>A</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>Neural dynamics of phoneme sequences reveal position-invariant code for content and order</article-title><source>Nature Communications</source><year>2022</year><volume>13</volume><issue>1</issue><fpage>6606</fpage><pub-id pub-id-type="doi">10.1038/s41467-022-34326-1</pub-id><pub-id pub-id-type="pmid">36329058</pub-id>
</element-citation><mixed-citation id="mc-CR41" publication-type="journal">Gwilliams, L., King, J. R., Marantz, A., &#x00026; Poeppel, D. (2022). Neural dynamics of phoneme sequences reveal position-invariant code for content and order. <italic>Nature Communications,</italic><italic>13</italic>(1), 6606. 10.1038/s41467-022-34326-1<pub-id pub-id-type="pmid">36329058</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR42"><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>H&#x000e4;m&#x000e4;l&#x000e4;inen</surname><given-names>MS</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name></person-group><article-title>Interpreting magnetic fields of the brain: minimum norm estimates</article-title><source>Medical &#x00026; Biological Engineering &#x00026; Computing</source><year>1994</year><volume>32</volume><fpage>35</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1007/BF02512476</pub-id><pub-id pub-id-type="pmid">8182960</pub-id>
</element-citation><mixed-citation id="mc-CR42" publication-type="journal">H&#x000e4;m&#x000e4;l&#x000e4;inen, M. S., &#x00026; Ilmoniemi, R. J. (1994). Interpreting magnetic fields of the brain: minimum norm estimates. <italic>Medical &#x00026; Biological Engineering &#x00026; Computing,</italic><italic>32</italic>, 35&#x02013;42.<pub-id pub-id-type="pmid">8182960</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR43"><mixed-citation publication-type="other">Hannagan, T., Magnuson, J. S., &#x00026; Grainger, J. (2013). Spoken word recognition without a TRACE. <italic>Frontiers in Psychology</italic>,<italic> 4</italic>. 10.3389/fpsyg.2013.00563</mixed-citation></ref><ref id="CR44"><citation-alternatives><element-citation id="ec-CR44" publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>JH</given-names></name></person-group><source>The elements of statistical learning: data mining, inference, and prediction</source><year>2009</year><edition>2</edition><publisher-name>Springer</publisher-name></element-citation><mixed-citation id="mc-CR44" publication-type="book">Hastie, T., Tibshirani, R., &#x00026; Friedman, J. H. (2009). <italic>The elements of statistical learning: data mining, inference, and prediction</italic> (2nd ed.). Springer.</mixed-citation></citation-alternatives></ref><ref id="CR45"><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Nikulin</surname><given-names>VV</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K-R</given-names></name><name><surname>Nolte</surname><given-names>G</given-names></name></person-group><article-title>A critical assessment of connectivity measures for EEG data: a simulation study</article-title><source>Neuroimage</source><year>2013</year><volume>64</volume><fpage>120</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.09.036</pub-id><pub-id pub-id-type="pmid">23006806</pub-id>
</element-citation><mixed-citation id="mc-CR45" publication-type="journal">Haufe, S., Nikulin, V. V., M&#x000fc;ller, K.-R., &#x00026; Nolte, G. (2013). A critical assessment of connectivity measures for EEG data: a simulation study. <italic>Neuroimage,</italic><italic>64</italic>, 120&#x02013;133. 10.1016/j.neuroimage.2012.09.036<pub-id pub-id-type="pmid">23006806</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR46"><citation-alternatives><element-citation id="ec-CR46" publication-type="journal"><person-group person-group-type="author"><name><surname>Hayes</surname><given-names>B</given-names></name><name><surname>Wilson</surname><given-names>C</given-names></name></person-group><article-title>A maximum entropy model of phonotactics and phonotactic learning</article-title><source>Linguistic Inquiry</source><year>2008</year><volume>39</volume><issue>3</issue><fpage>379</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1162/ling.2008.39.3.379</pub-id></element-citation><mixed-citation id="mc-CR46" publication-type="journal">Hayes, B., &#x00026; Wilson, C. (2008). A maximum entropy model of phonotactics and phonotactic learning. <italic>Linguistic Inquiry,</italic><italic>39</italic>(3), 379&#x02013;440. 10.1162/ling.2008.39.3.379</mixed-citation></citation-alternatives></ref><ref id="CR47"><citation-alternatives><element-citation id="ec-CR47" publication-type="journal"><person-group person-group-type="author"><name><surname>Haynes</surname><given-names>J-D</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><article-title>Decoding mental states from brain activity in humans</article-title><source>Nature Reviews Neuroscience</source><year>2006</year><volume>7</volume><issue>7</issue><fpage>523</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1038/nrn1931</pub-id><pub-id pub-id-type="pmid">16791142</pub-id>
</element-citation><mixed-citation id="mc-CR47" publication-type="journal">Haynes, J.-D., &#x00026; Rees, G. (2006). Decoding mental states from brain activity in humans. <italic>Nature Reviews Neuroscience,</italic><italic>7</italic>(7), 523&#x02013;534. 10.1038/nrn1931<pub-id pub-id-type="pmid">16791142</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR48"><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name><surname>Hickok</surname><given-names>G</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>The cortical organization of speech processing</article-title><source>Nature Reviews Neuroscience</source><year>2007</year><volume>8</volume><issue>5</issue><fpage>393</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1038/nrn2113</pub-id><pub-id pub-id-type="pmid">17431404</pub-id>
</element-citation><mixed-citation id="mc-CR48" publication-type="journal">Hickok, G., &#x00026; Poeppel, D. (2007). The cortical organization of speech processing. <italic>Nature Reviews Neuroscience,</italic><italic>8</italic>(5), 393&#x02013;402. 10.1038/nrn2113<pub-id pub-id-type="pmid">17431404</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR49"><mixed-citation publication-type="other">Kleiner, M., Brainard, D., Pelli, D., Ingling, A., Murray, R., &#x00026; Broussard, C. (2007). What's new in psychtoolbox-3. <italic>Perception, 36</italic>(14), 1&#x02013;16. 10.1177/03010066070360S101</mixed-citation></ref><ref id="CR50"><citation-alternatives><element-citation id="ec-CR50" publication-type="journal"><person-group person-group-type="author"><name><surname>Kocagoncu</surname><given-names>E</given-names></name><name><surname>Clarke</surname><given-names>A</given-names></name><name><surname>Devereux</surname><given-names>BJ</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name></person-group><article-title>Decoding the cortical dynamics of sound-meaning mapping</article-title><source>Journal of Neuroscience</source><year>2017</year><volume>37</volume><issue>5</issue><fpage>1312</fpage><lpage>1319</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2858-16.2016</pub-id><pub-id pub-id-type="pmid">28028201</pub-id>
</element-citation><mixed-citation id="mc-CR50" publication-type="journal">Kocagoncu, E., Clarke, A., Devereux, B. J., &#x00026; Tyler, L. K. (2017). Decoding the cortical dynamics of sound-meaning mapping. <italic>Journal of Neuroscience,</italic><italic>37</italic>(5), 1312&#x02013;1319. 10.1523/JNEUROSCI.2858-16.2016<pub-id pub-id-type="pmid">28028201</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR51"><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><article-title>Peeling the onion of brain representations</article-title><source>Annual Review of Neuroscience</source><year>2019</year><volume>42</volume><fpage>407</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-061906</pub-id><pub-id pub-id-type="pmid">31283895</pub-id>
</element-citation><mixed-citation id="mc-CR51" publication-type="journal">Kriegeskorte, N., &#x00026; Diedrichsen, J. (2019). Peeling the onion of brain representations. <italic>Annual Review of Neuroscience,</italic><italic>42</italic>, 407&#x02013;432. 10.1146/annurev-neuro-080317-061906<pub-id pub-id-type="pmid">31283895</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR52"><citation-alternatives><element-citation id="ec-CR52" publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Kievit</surname><given-names>RA</given-names></name></person-group><article-title>Representational geometry: integrating cognition, computation, and the brain</article-title><source>Trends in Cognitive Sciences</source><year>2013</year><volume>17</volume><issue>8</issue><fpage>401</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.007</pub-id><pub-id pub-id-type="pmid">23876494</pub-id>
</element-citation><mixed-citation id="mc-CR52" publication-type="journal">Kriegeskorte, N., &#x00026; Kievit, R. A. (2013). Representational geometry: integrating cognition, computation, and the brain. <italic>Trends in Cognitive Sciences,</italic><italic>17</italic>(8), 401&#x02013;412. 10.1016/j.tics.2013.06.007<pub-id pub-id-type="pmid">23876494</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR53"><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name><surname>Kutas</surname><given-names>M</given-names></name><name><surname>Federmeier</surname><given-names>KD</given-names></name></person-group><article-title>Thirty years and counting: finding meaning in the N400 component of the event-related brain potential (ERP)</article-title><source>Annual Review of Psychology</source><year>2011</year><volume>62</volume><fpage>621</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.093008.131123</pub-id><pub-id pub-id-type="pmid">20809790</pub-id>
</element-citation><mixed-citation id="mc-CR53" publication-type="journal">Kutas, M., &#x00026; Federmeier, K. D. (2011). Thirty years and counting: finding meaning in the N400 component of the event-related brain potential (ERP). <italic>Annual Review of Psychology,</italic><italic>62</italic>, 621&#x02013;647. 10.1146/annurev.psych.093008.131123<pub-id pub-id-type="pmid">20809790</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR54"><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name><surname>Kuznetsova</surname><given-names>A</given-names></name><name><surname>Brockhoff</surname><given-names>PB</given-names></name><name><surname>Christensen</surname><given-names>RH</given-names></name></person-group><article-title>lmerTest package: tests in linear mixed effects models</article-title><source>Journal of Statistical Software</source><year>2017</year><volume>82</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.18637/jss.v082.i13</pub-id></element-citation><mixed-citation id="mc-CR54" publication-type="journal">Kuznetsova, A., Brockhoff, P. B., &#x00026; Christensen, R. H. (2017). lmerTest package: tests in linear mixed effects models. <italic>Journal of Statistical Software,</italic><italic>82</italic>, 1&#x02013;26. 10.18637/jss.v082.i13</mixed-citation></citation-alternatives></ref><ref id="CR55"><citation-alternatives><element-citation id="ec-CR55" publication-type="journal"><person-group person-group-type="author"><name><surname>Lahiri</surname><given-names>A</given-names></name><name><surname>Marslen-Wilson</surname><given-names>W</given-names></name></person-group><article-title>The mental representation of lexical form: A phonological approach to the recognition lexicon</article-title><source>Cognition</source><year>1991</year><volume>38</volume><issue>3</issue><fpage>245</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(91)90008-R</pub-id><pub-id pub-id-type="pmid">2060271</pub-id>
</element-citation><mixed-citation id="mc-CR55" publication-type="journal">Lahiri, A., &#x00026; Marslen-Wilson, W. (1991). The mental representation of lexical form: A phonological approach to the recognition lexicon. <italic>Cognition,</italic><italic>38</italic>(3), 245&#x02013;294. 10.1016/0010-0277(91)90008-R<pub-id pub-id-type="pmid">2060271</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR56"><citation-alternatives><element-citation id="ec-CR56" publication-type="journal"><person-group person-group-type="author"><name><surname>Landauer</surname><given-names>TK</given-names></name><name><surname>Streeter</surname><given-names>LA</given-names></name></person-group><article-title>Structural differences between common and rare words: Failure of equivalence assumptions for theories of word recognition</article-title><source>Journal of Verbal Learning and Verbal Behavior</source><year>1973</year><volume>12</volume><issue>2</issue><fpage>119</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1016/S0022-5371(73)80001-5</pub-id></element-citation><mixed-citation id="mc-CR56" publication-type="journal">Landauer, T. K., &#x00026; Streeter, L. A. (1973). Structural differences between common and rare words: Failure of equivalence assumptions for theories of word recognition. <italic>Journal of Verbal Learning and Verbal Behavior,</italic><italic>12</italic>(2), 119&#x02013;131. 10.1016/S0022-5371(73)80001-5</mixed-citation></citation-alternatives></ref><ref id="CR57"><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name><surname>Leahy</surname><given-names>RM</given-names></name><name><surname>Mosher</surname><given-names>JC</given-names></name><name><surname>Spencer</surname><given-names>ME</given-names></name><name><surname>Huang</surname><given-names>MX</given-names></name><name><surname>Lewine</surname><given-names>JD</given-names></name></person-group><article-title>A study of dipole localization accuracy for MEG and EEG using a human skull phantom</article-title><source>Electroencephalography and Clinical Neurophysiology</source><year>1998</year><volume>107</volume><issue>2</issue><fpage>159</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1016/S0013-4694(98)00057-1</pub-id><pub-id pub-id-type="pmid">9751287</pub-id>
</element-citation><mixed-citation id="mc-CR57" publication-type="journal">Leahy, R. M., Mosher, J. C., Spencer, M. E., Huang, M. X., &#x00026; Lewine, J. D. (1998). A study of dipole localization accuracy for MEG and EEG using a human skull phantom. <italic>Electroencephalography and Clinical Neurophysiology,</italic><italic>107</italic>(2), 159&#x02013;173. 10.1016/S0013-4694(98)00057-1<pub-id pub-id-type="pmid">9751287</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR58"><mixed-citation publication-type="other">Leonard, M. K., Baud, M. O., Sjerps, M. J., &#x00026; Chang, E. F. (2016). Perceptual restoration of masked speech in human cortex. <italic>Nature Communications</italic>,<italic> 7</italic>(13619). 10.1038/ncomms13619</mixed-citation></ref><ref id="CR59"><citation-alternatives><element-citation id="ec-CR59" publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>AK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><article-title>Spatiotemporal imaging of human brain activity using functional MRI constrained magnetoencephalography data: Monte Carlo simulations</article-title><source>Proceedings of the National Academy of Science USA</source><year>1998</year><volume>95</volume><issue>15</issue><fpage>8945</fpage><lpage>8950</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.15.8945</pub-id></element-citation><mixed-citation id="mc-CR59" publication-type="journal">Liu, A. K., Belliveau, J. W., &#x00026; Dale, A. M. (1998). Spatiotemporal imaging of human brain activity using functional MRI constrained magnetoencephalography data: Monte Carlo simulations. <italic>Proceedings of the National Academy of Science USA,</italic><italic>95</italic>(15), 8945&#x02013;8950. 10.1073/pnas.95.15.8945</mixed-citation></citation-alternatives></ref><ref id="CR60"><citation-alternatives><element-citation id="ec-CR60" publication-type="journal"><person-group person-group-type="author"><name><surname>Luce</surname><given-names>PA</given-names></name><name><surname>Large</surname><given-names>N</given-names></name></person-group><article-title>Phonotactics, density, and entropy in spoken word recognition</article-title><source>Language and Cognitive Processes</source><year>2001</year><volume>16</volume><issue>5</issue><fpage>565</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1080/01690960143000137</pub-id></element-citation><mixed-citation id="mc-CR60" publication-type="journal">Luce, P. A., &#x00026; Large, N. (2001). Phonotactics, density, and entropy in spoken word recognition. <italic>Language and Cognitive Processes,</italic><italic>16</italic>(5), 565&#x02013;581. 10.1080/01690960143000137</mixed-citation></citation-alternatives></ref><ref id="CR61"><citation-alternatives><element-citation id="ec-CR61" publication-type="journal"><person-group person-group-type="author"><name><surname>Luce</surname><given-names>PA</given-names></name><name><surname>Pisoni</surname><given-names>DB</given-names></name></person-group><article-title>Recognizing spoken words: the neighborhood activation model</article-title><source>Ear and Hearing</source><year>1998</year><volume>19</volume><issue>1</issue><fpage>1</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1097/00003446-199802000-00001</pub-id><pub-id pub-id-type="pmid">9504270</pub-id>
</element-citation><mixed-citation id="mc-CR61" publication-type="journal">Luce, P. A., &#x00026; Pisoni, D. B. (1998). Recognizing spoken words: the neighborhood activation model. <italic>Ear and Hearing,</italic><italic>19</italic>(1), 1&#x02013;36. 10.1097/00003446-199802000-00001<pub-id pub-id-type="pmid">9504270</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR62"><citation-alternatives><element-citation id="ec-CR62" publication-type="journal"><person-group person-group-type="author"><name><surname>Magnuson</surname><given-names>JS</given-names></name><name><surname>McMurray</surname><given-names>B</given-names></name><name><surname>Tanenhaus</surname><given-names>MK</given-names></name><name><surname>Aslin</surname><given-names>RS</given-names></name></person-group><article-title>Lexical effects on compensation for coarticulation: a tale of two systems?</article-title><source>Cognitive Science</source><year>2003</year><volume>27</volume><issue>5</issue><fpage>801</fpage><lpage>805</lpage><pub-id pub-id-type="doi">10.1016/s0364-0213(03)00067-3</pub-id></element-citation><mixed-citation id="mc-CR62" publication-type="journal">Magnuson, J. S., McMurray, B., Tanenhaus, M. K., &#x00026; Aslin, R. S. (2003). Lexical effects on compensation for coarticulation: a tale of two systems? <italic>Cognitive Science,</italic><italic>27</italic>(5), 801&#x02013;805. 10.1016/s0364-0213(03)00067-3</mixed-citation></citation-alternatives></ref><ref id="CR63"><citation-alternatives><element-citation id="ec-CR63" publication-type="journal"><person-group person-group-type="author"><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name></person-group><article-title>Functional parallelism in spoken word-recognition</article-title><source>Cognition</source><year>1987</year><volume>25</volume><issue>1&#x02013;2</issue><fpage>71</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(87)90005-9</pub-id><pub-id pub-id-type="pmid">3581730</pub-id>
</element-citation><mixed-citation id="mc-CR63" publication-type="journal">Marslen-Wilson, W. D. (1987). Functional parallelism in spoken word-recognition. <italic>Cognition,</italic><italic>25</italic>(1&#x02013;2), 71&#x02013;102. 10.1016/0010-0277(87)90005-9<pub-id pub-id-type="pmid">3581730</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR64"><citation-alternatives><element-citation id="ec-CR64" publication-type="journal"><person-group person-group-type="author"><name><surname>Marslen-Wilson</surname><given-names>W</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name></person-group><article-title>The temporal structure of spoken language understanding</article-title><source>Cognition</source><year>1980</year><volume>8</volume><issue>1</issue><fpage>1</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(80)90015-3</pub-id><pub-id pub-id-type="pmid">7363578</pub-id>
</element-citation><mixed-citation id="mc-CR64" publication-type="journal">Marslen-Wilson, W., &#x00026; Tyler, L. K. (1980). The temporal structure of spoken language understanding. <italic>Cognition,</italic><italic>8</italic>(1), 1&#x02013;71. 10.1016/0010-0277(80)90015-3<pub-id pub-id-type="pmid">7363578</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR65"><citation-alternatives><element-citation id="ec-CR65" publication-type="journal"><person-group person-group-type="author"><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Welsh</surname><given-names>A</given-names></name></person-group><article-title>Processing interactions and lexical access during word recognition in continuous speech</article-title><source>Cognitive Psychology</source><year>1978</year><volume>10</volume><issue>1</issue><fpage>29</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(78)90018-X</pub-id></element-citation><mixed-citation id="mc-CR65" publication-type="journal">Marslen-Wilson, W. D., &#x00026; Welsh, A. (1978). Processing interactions and lexical access during word recognition in continuous speech. <italic>Cognitive Psychology,</italic><italic>10</italic>(1), 29&#x02013;63. 10.1016/0010-0285(78)90018-X</mixed-citation></citation-alternatives></ref><ref id="CR66"><citation-alternatives><element-citation id="ec-CR66" publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Elman</surname><given-names>JL</given-names></name></person-group><article-title>The TRACE model of speech perception</article-title><source>Cognitive Psychology</source><year>1986</year><volume>18</volume><issue>1</issue><fpage>1</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(86)90015-0</pub-id><pub-id pub-id-type="pmid">3753912</pub-id>
</element-citation><mixed-citation id="mc-CR66" publication-type="journal">McClelland, J. L., &#x00026; Elman, J. L. (1986). The TRACE model of speech perception. <italic>Cognitive Psychology,</italic><italic>18</italic>(1), 1&#x02013;86. 10.1016/0010-0285(86)90015-0<pub-id pub-id-type="pmid">3753912</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR67"><citation-alternatives><element-citation id="ec-CR67" publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>KB</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name><name><surname>Watson</surname><given-names>JM</given-names></name><name><surname>Ojemann</surname><given-names>JG</given-names></name></person-group><article-title>A procedure for identifying regions preferentially activated by attention to semantic and phonological relations using functional magnetic resonance imaging</article-title><source>Neuropsychologia</source><year>2003</year><volume>41</volume><issue>3</issue><fpage>293</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1016/s0028-3932(02)00162-8</pub-id><pub-id pub-id-type="pmid">12457755</pub-id>
</element-citation><mixed-citation id="mc-CR67" publication-type="journal">McDermott, K. B., Petersen, S. E., Watson, J. M., &#x00026; Ojemann, J. G. (2003). A procedure for identifying regions preferentially activated by attention to semantic and phonological relations using functional magnetic resonance imaging. <italic>Neuropsychologia,</italic><italic>41</italic>(3), 293&#x02013;303. 10.1016/s0028-3932(02)00162-8<pub-id pub-id-type="pmid">12457755</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR68"><mixed-citation publication-type="other">Merriman, W. E., Bowman, L. L., &#x00026; MacWhinney, B. (1989). The mutual exclusivity bias in children's word learning. <italic>Monographs of the Society for Research in Child Development</italic>, i-129. 10.2307/1166130</mixed-citation></ref><ref id="CR69"><citation-alternatives><element-citation id="ec-CR69" publication-type="journal"><person-group person-group-type="author"><name><surname>Mesgarani</surname><given-names>N</given-names></name><name><surname>Cheung</surname><given-names>C</given-names></name><name><surname>Johnson</surname><given-names>K</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name></person-group><article-title>Phonetic feature encoding in human superior temporal gyrus</article-title><source>Science</source><year>2014</year><volume>343</volume><issue>6174</issue><fpage>1006</fpage><lpage>1010</lpage><pub-id pub-id-type="doi">10.1126/science.1245994</pub-id><pub-id pub-id-type="pmid">24482117</pub-id>
</element-citation><mixed-citation id="mc-CR69" publication-type="journal">Mesgarani, N., Cheung, C., Johnson, K., &#x00026; Chang, E. F. (2014). Phonetic feature encoding in human superior temporal gyrus. <italic>Science,</italic><italic>343</italic>(6174), 1006&#x02013;1010. 10.1126/science.1245994<pub-id pub-id-type="pmid">24482117</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR70"><citation-alternatives><element-citation id="ec-CR70" publication-type="journal"><person-group person-group-type="author"><name><surname>Michalareas</surname><given-names>G</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Van Pelt</surname><given-names>S</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><article-title>Alpha-beta and gamma rhythms subserve feedback and feedforward influences among human visual cortical areas</article-title><source>Neuron</source><year>2016</year><volume>89</volume><issue>2</issue><fpage>384</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.018</pub-id><pub-id pub-id-type="pmid">26777277</pub-id>
</element-citation><mixed-citation id="mc-CR70" publication-type="journal">Michalareas, G., Vezoli, J., Van Pelt, S., Schoffelen, J.-M., Kennedy, H., &#x00026; Fries, P. (2016). Alpha-beta and gamma rhythms subserve feedback and feedforward influences among human visual cortical areas. <italic>Neuron,</italic><italic>89</italic>(2), 384&#x02013;397. 10.1016/j.neuron.2015.12.018<pub-id pub-id-type="pmid">26777277</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR71"><citation-alternatives><element-citation id="ec-CR71" publication-type="journal"><person-group person-group-type="author"><name><surname>Milde</surname><given-names>T</given-names></name><name><surname>Leistritz</surname><given-names>L</given-names></name><name><surname>Astolfi</surname><given-names>L</given-names></name><name><surname>Miltner</surname><given-names>WH</given-names></name><name><surname>Weiss</surname><given-names>T</given-names></name><name><surname>Babiloni</surname><given-names>F</given-names></name><name><surname>Witte</surname><given-names>H</given-names></name></person-group><article-title>A new Kalman filter approach for the estimation of high-dimensional time-variant multivariate AR models and its application in analysis of laser-evoked brain potentials</article-title><source>NeuroImage</source><year>2010</year><volume>50</volume><issue>3</issue><fpage>960</fpage><lpage>969</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.110</pub-id><pub-id pub-id-type="pmid">20060483</pub-id>
</element-citation><mixed-citation id="mc-CR71" publication-type="journal">Milde, T., Leistritz, L., Astolfi, L., Miltner, W. H., Weiss, T., Babiloni, F., &#x00026; Witte, H. (2010). A new Kalman filter approach for the estimation of high-dimensional time-variant multivariate AR models and its application in analysis of laser-evoked brain potentials. <italic>NeuroImage,</italic><italic>50</italic>(3), 960&#x02013;969. 10.1016/j.neuroimage.2009.12.110<pub-id pub-id-type="pmid">20060483</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR72"><citation-alternatives><element-citation id="ec-CR72" publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname><given-names>EB</given-names></name></person-group><article-title>Dissociable effects of phonetic competition and category typicality in a phonetic categorization task: an fMRI investigation</article-title><source>Neuropsychologia</source><year>2007</year><volume>45</volume><issue>7</issue><fpage>1463</fpage><lpage>1473</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.11.005</pub-id><pub-id pub-id-type="pmid">17178420</pub-id>
</element-citation><mixed-citation id="mc-CR72" publication-type="journal">Myers, E. B. (2007). Dissociable effects of phonetic competition and category typicality in a phonetic categorization task: an fMRI investigation. <italic>Neuropsychologia,</italic><italic>45</italic>(7), 1463&#x02013;1473. 10.1016/j.neuropsychologia.2006.11.005<pub-id pub-id-type="pmid">17178420</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR73"><citation-alternatives><element-citation id="ec-CR73" publication-type="journal"><person-group person-group-type="author"><name><surname>Naselaris</surname><given-names>T</given-names></name><name><surname>Prenger</surname><given-names>RJ</given-names></name><name><surname>Kay</surname><given-names>KN</given-names></name><name><surname>Oliver</surname><given-names>M</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><article-title>Bayesian reconstruction of natural images from human brain activity</article-title><source>Neuron</source><year>2009</year><volume>63</volume><issue>6</issue><fpage>902</fpage><lpage>915</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.006</pub-id><pub-id pub-id-type="pmid">19778517</pub-id>
</element-citation><mixed-citation id="mc-CR73" publication-type="journal">Naselaris, T., Prenger, R. J., Kay, K. N., Oliver, M., &#x00026; Gallant, J. L. (2009). Bayesian reconstruction of natural images from human brain activity. <italic>Neuron,</italic><italic>63</italic>(6), 902&#x02013;915. 10.1016/j.neuron.2009.09.006<pub-id pub-id-type="pmid">19778517</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR74"><citation-alternatives><element-citation id="ec-CR74" publication-type="journal"><person-group person-group-type="author"><name><surname>Nolte</surname><given-names>G</given-names></name><name><surname>Bai</surname><given-names>O</given-names></name><name><surname>Wheaton</surname><given-names>L</given-names></name><name><surname>Mari</surname><given-names>Z</given-names></name><name><surname>Vorbach</surname><given-names>S</given-names></name><name><surname>Hallett</surname><given-names>M</given-names></name></person-group><article-title>Identifying true brain interaction from EEG data using the imaginary part of coherency</article-title><source>Clinical Neurophysiology</source><year>2004</year><volume>115</volume><issue>10</issue><fpage>2292</fpage><lpage>2307</lpage><pub-id pub-id-type="doi">10.1016/j.clinph.2004.04.029</pub-id><pub-id pub-id-type="pmid">15351371</pub-id>
</element-citation><mixed-citation id="mc-CR74" publication-type="journal">Nolte, G., Bai, O., Wheaton, L., Mari, Z., Vorbach, S., &#x00026; Hallett, M. (2004). Identifying true brain interaction from EEG data using the imaginary part of coherency. <italic>Clinical Neurophysiology,</italic><italic>115</italic>(10), 2292&#x02013;2307. 10.1016/j.clinph.2004.04.029<pub-id pub-id-type="pmid">15351371</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR75"><citation-alternatives><element-citation id="ec-CR75" publication-type="journal"><person-group person-group-type="author"><name><surname>Norris</surname><given-names>D</given-names></name><name><surname>McQueen</surname><given-names>JM</given-names></name><name><surname>Cutler</surname><given-names>A</given-names></name></person-group><article-title>Perceptual learning in speech</article-title><source>Cognitive Psychology</source><year>2003</year><volume>47</volume><issue>2</issue><fpage>204</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1016/S0010-0285(03)00006-9</pub-id><pub-id pub-id-type="pmid">12948518</pub-id>
</element-citation><mixed-citation id="mc-CR75" publication-type="journal">Norris, D., McQueen, J. M., &#x00026; Cutler, A. (2003). Perceptual learning in speech. <italic>Cognitive Psychology,</italic><italic>47</italic>(2), 204&#x02013;238. 10.1016/S0010-0285(03)00006-9<pub-id pub-id-type="pmid">12948518</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR76"><mixed-citation publication-type="other">Organian, Y., &#x00026; Chang, E. F. (2019). A speech envelope landmark for syllable encoding in human superior temporal gyrus. <italic>Science Advances</italic> (eaay6279). 10.1126/sciadv.aay6279</mixed-citation></ref><ref id="CR77"><citation-alternatives><element-citation id="ec-CR77" publication-type="journal"><person-group person-group-type="author"><name><surname>Pardo</surname><given-names>JV</given-names></name><name><surname>Wood</surname><given-names>TD</given-names></name><name><surname>Costello</surname><given-names>PA</given-names></name><name><surname>Pardo</surname><given-names>PJ</given-names></name><name><surname>Lee</surname><given-names>JT</given-names></name></person-group><article-title>PET study of the localization and laterality of lingual somatosensory processing in humans</article-title><source>Neuroscience Letters</source><year>1997</year><volume>234</volume><issue>1</issue><fpage>23</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1016/s0304-3940(97)00650-2</pub-id><pub-id pub-id-type="pmid">9347937</pub-id>
</element-citation><mixed-citation id="mc-CR77" publication-type="journal">Pardo, J. V., Wood, T. D., Costello, P. A., Pardo, P. J., &#x00026; Lee, J. T. (1997). PET study of the localization and laterality of lingual somatosensory processing in humans. <italic>Neuroscience Letters,</italic><italic>234</italic>(1), 23&#x02013;26. 10.1016/s0304-3940(97)00650-2<pub-id pub-id-type="pmid">9347937</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR78"><citation-alternatives><element-citation id="ec-CR78" publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Nestor</surname><given-names>PJ</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Where do you know what you know? The representation of semantic knowledge in the human brain [Review]</article-title><source>Nature Reviews. Neuroscience</source><year>2007</year><volume>8</volume><issue>12</issue><fpage>976</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1038/nrn2277</pub-id><pub-id pub-id-type="pmid">18026167</pub-id>
</element-citation><mixed-citation id="mc-CR78" publication-type="journal">Patterson, K., Nestor, P. J., &#x00026; Rogers, T. T. (2007). Where do you know what you know? The representation of semantic knowledge in the human brain [Review]. <italic>Nature Reviews. Neuroscience,</italic><italic>8</italic>(12), 976&#x02013;987. 10.1038/nrn2277<pub-id pub-id-type="pmid">18026167</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR79"><citation-alternatives><element-citation id="ec-CR79" publication-type="book"><person-group person-group-type="author"><name><surname>Pelletier</surname><given-names>FJ</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Werning</surname><given-names>M</given-names></name><name><surname>Hinzen</surname><given-names>W</given-names></name><name><surname>Machery</surname><given-names>E</given-names></name></person-group><article-title>Holism And Compositionality</article-title><source>The Oxford handbook of compositionality</source><year>2012</year><publisher-name>Oxford University Press</publisher-name><fpage>149</fpage><lpage>174</lpage></element-citation><mixed-citation id="mc-CR79" publication-type="book">Pelletier, F. J. (2012). Holism And Compositionality. In M. Werning, W. Hinzen, &#x00026; E. Machery (Eds.), <italic>The Oxford handbook of compositionality</italic> (pp. 149&#x02013;174). Oxford University Press.</mixed-citation></citation-alternatives></ref><ref id="CR80"><citation-alternatives><element-citation id="ec-CR80" publication-type="journal"><person-group person-group-type="author"><name><surname>Peramunage</surname><given-names>D</given-names></name><name><surname>Blumstein</surname><given-names>SE</given-names></name><name><surname>Myers</surname><given-names>EB</given-names></name><name><surname>Goldrick</surname><given-names>M</given-names></name><name><surname>Baese-Berk</surname><given-names>M</given-names></name></person-group><article-title>Phonological neighborhood effects in spoken word production: an fMRI study</article-title><source>Journal of Cognitive Neuroscience</source><year>2011</year><volume>23</volume><issue>3</issue><fpage>593</fpage><lpage>603</lpage><pub-id pub-id-type="doi">10.1162/jocn.2010.21489</pub-id><pub-id pub-id-type="pmid">20350185</pub-id>
</element-citation><mixed-citation id="mc-CR80" publication-type="journal">Peramunage, D., Blumstein, S. E., Myers, E. B., Goldrick, M., &#x00026; Baese-Berk, M. (2011). Phonological neighborhood effects in spoken word production: an fMRI study. <italic>Journal of Cognitive Neuroscience,</italic><italic>23</italic>(3), 593&#x02013;603. 10.1162/jocn.2010.21489<pub-id pub-id-type="pmid">20350185</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR81"><citation-alternatives><element-citation id="ec-CR81" publication-type="journal"><person-group person-group-type="author"><name><surname>Pierrehumbert</surname><given-names>JB</given-names></name></person-group><article-title>Phonological representation: Beyond abstract versus episodic</article-title><source>Annual Review of Linguistics</source><year>2016</year><volume>2</volume><fpage>33</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1146/annurev-linguistics-030514-125050</pub-id></element-citation><mixed-citation id="mc-CR81" publication-type="journal">Pierrehumbert, J. B. (2016). Phonological representation: Beyond abstract versus episodic. <italic>Annual Review of Linguistics,</italic><italic>2</italic>, 33&#x02013;52. 10.1146/annurev-linguistics-030514-125050</mixed-citation></citation-alternatives></ref><ref id="CR82"><mixed-citation publication-type="other">Poeppel, D., &#x00026; Idsardi, W. (2022). We don&#x02019;t know how the brain stores anything, let alone words. <italic>Trends in Cognitive Sciences, 26</italic>(12)<italic>, </italic>1054&#x02013;1055<italic>. </italic>10.1016/j.tics.2022.08.010</mixed-citation></ref><ref id="CR83"><citation-alternatives><element-citation id="ec-CR83" publication-type="journal"><person-group person-group-type="author"><name><surname>Prabhakaran</surname><given-names>R</given-names></name><name><surname>Blumstein</surname><given-names>SE</given-names></name><name><surname>Myers</surname><given-names>EB</given-names></name><name><surname>Hutchison</surname><given-names>E</given-names></name><name><surname>Britton</surname><given-names>B</given-names></name></person-group><article-title>An event-related fMRI investigation of phonological&#x02013;lexical competition</article-title><source>Neuropsychologia</source><year>2006</year><volume>44</volume><issue>12</issue><fpage>2209</fpage><lpage>2221</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.05.025</pub-id><pub-id pub-id-type="pmid">16842827</pub-id>
</element-citation><mixed-citation id="mc-CR83" publication-type="journal">Prabhakaran, R., Blumstein, S. E., Myers, E. B., Hutchison, E., &#x00026; Britton, B. (2006). An event-related fMRI investigation of phonological&#x02013;lexical competition. <italic>Neuropsychologia,</italic><italic>44</italic>(12), 2209&#x02013;2221. 10.1016/j.neuropsychologia.2006.05.025<pub-id pub-id-type="pmid">16842827</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR84"><mixed-citation publication-type="other">R Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link></mixed-citation></ref><ref id="CR85"><citation-alternatives><element-citation id="ec-CR85" publication-type="journal"><person-group person-group-type="author"><name><surname>Righi</surname><given-names>G</given-names></name><name><surname>Blumstein</surname><given-names>SE</given-names></name><name><surname>Mertus</surname><given-names>J</given-names></name><name><surname>Worden</surname><given-names>MS</given-names></name></person-group><article-title>Neural systems underlying lexical competition: An eye tracking and fMRI study</article-title><source>Journal of Cognitive Neuroscience</source><year>2009</year><volume>22</volume><issue>2</issue><fpage>213</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21200</pub-id></element-citation><mixed-citation id="mc-CR85" publication-type="journal">Righi, G., Blumstein, S. E., Mertus, J., &#x00026; Worden, M. S. (2009). Neural systems underlying lexical competition: An eye tracking and fMRI study. <italic>Journal of Cognitive Neuroscience,</italic><italic>22</italic>(2), 213&#x02013;224. 10.1162/jocn.2009.21200</mixed-citation></citation-alternatives></ref><ref id="CR86"><citation-alternatives><element-citation id="ec-CR86" publication-type="journal"><person-group person-group-type="author"><name><surname>Samuel</surname><given-names>AG</given-names></name><name><surname>Pitt</surname><given-names>MA</given-names></name></person-group><article-title>Lexical activation (and other factors) can mediate compensation for coarticulation</article-title><source>Journal of Memory and Language</source><year>2003</year><volume>48</volume><issue>2</issue><fpage>416</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/S0749-596X(02)00514-4</pub-id></element-citation><mixed-citation id="mc-CR86" publication-type="journal">Samuel, A. G., &#x00026; Pitt, M. A. (2003). Lexical activation (and other factors) can mediate compensation for coarticulation. <italic>Journal of Memory and Language,</italic><italic>48</italic>(2), 416&#x02013;434. 10.1016/S0749-596X(02)00514-4</mixed-citation></citation-alternatives></ref><ref id="CR87"><citation-alternatives><element-citation id="ec-CR87" publication-type="journal"><person-group person-group-type="author"><name><surname>Schoffelen</surname><given-names>JM</given-names></name><name><surname>Gross</surname><given-names>J</given-names></name></person-group><article-title>Source connectivity analysis with MEG and EEG [Review]</article-title><source>Human Brain Mapping</source><year>2009</year><volume>30</volume><issue>6</issue><fpage>1857</fpage><lpage>1865</lpage><pub-id pub-id-type="doi">10.1002/hbm.20745</pub-id><pub-id pub-id-type="pmid">19235884</pub-id>
</element-citation><mixed-citation id="mc-CR87" publication-type="journal">Schoffelen, J. M., &#x00026; Gross, J. (2009). Source connectivity analysis with MEG and EEG [Review]. <italic>Human Brain Mapping,</italic><italic>30</italic>(6), 1857&#x02013;1865. 10.1002/hbm.20745<pub-id pub-id-type="pmid">19235884</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR88"><citation-alternatives><element-citation id="ec-CR88" publication-type="journal"><person-group person-group-type="author"><name><surname>Schomers</surname><given-names>MR</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Is the sensorimotor cortex relevant for speech perception and understanding? An integrative review</article-title><source>Frontiers in Human Neuroscience</source><year>2016</year><volume>10</volume><fpage>435</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2016.00435</pub-id><pub-id pub-id-type="pmid">27708566</pub-id>
</element-citation><mixed-citation id="mc-CR88" publication-type="journal">Schomers, M. R., &#x00026; Pulverm&#x000fc;ller, F. (2016). Is the sensorimotor cortex relevant for speech perception and understanding? An integrative review. <italic>Frontiers in Human Neuroscience,</italic><italic>10</italic>, 435. 10.3389/fnhum.2016.00435<pub-id pub-id-type="pmid">27708566</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR89"><citation-alternatives><element-citation id="ec-CR89" publication-type="journal"><person-group person-group-type="author"><name><surname>Sharon</surname><given-names>D</given-names></name><name><surname>H&#x000e4;m&#x000e4;l&#x000e4;inen</surname><given-names>MS</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name></person-group><article-title>The advantage of combining MEG and EEG: comparison to fMRI in focally stimulated visual cortex</article-title><source>NeuroImage</source><year>2007</year><volume>36</volume><issue>4</issue><fpage>1225</fpage><lpage>1235</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.03.066</pub-id><pub-id pub-id-type="pmid">17532230</pub-id>
</element-citation><mixed-citation id="mc-CR89" publication-type="journal">Sharon, D., H&#x000e4;m&#x000e4;l&#x000e4;inen, M. S., Tootell, R. B., Halgren, E., &#x00026; Belliveau, J. W. (2007). The advantage of combining MEG and EEG: comparison to fMRI in focally stimulated visual cortex. <italic>NeuroImage,</italic><italic>36</italic>(4), 1225&#x02013;1235. 10.1016/j.neuroimage.2007.03.066<pub-id pub-id-type="pmid">17532230</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR90"><citation-alternatives><element-citation id="ec-CR90" publication-type="journal"><person-group person-group-type="author"><name><surname>Small</surname><given-names>DM</given-names></name><name><surname>Jones-Gotman</surname><given-names>M</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name><name><surname>Evans</surname><given-names>AC</given-names></name></person-group><article-title>A role for the right anterior temporal lobe in taste quality recognition</article-title><source>Journal of Neuroscience</source><year>1997</year><volume>17</volume><issue>13</issue><fpage>5136</fpage><lpage>5142</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-13-05136.1997</pub-id><pub-id pub-id-type="pmid">9185551</pub-id>
</element-citation><mixed-citation id="mc-CR90" publication-type="journal">Small, D. M., Jones-Gotman, M., Zatorre, R. J., Petrides, M., &#x00026; Evans, A. C. (1997). A role for the right anterior temporal lobe in taste quality recognition. <italic>Journal of Neuroscience,</italic><italic>17</italic>(13), 5136&#x02013;5142. 10.1523/JNEUROSCI.17-13-05136.1997<pub-id pub-id-type="pmid">9185551</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR91"><citation-alternatives><element-citation id="ec-CR91" publication-type="journal"><person-group person-group-type="author"><name><surname>Tanenhaus</surname><given-names>MK</given-names></name><name><surname>Spivey-Knowlton</surname><given-names>MJ</given-names></name><name><surname>Eberhard</surname><given-names>KM</given-names></name><name><surname>Sedivy</surname><given-names>JC</given-names></name></person-group><article-title>Integration of visual and linguistic information in spoken language comprehension</article-title><source>Science</source><year>1995</year><volume>268</volume><issue>5217</issue><fpage>1632</fpage><lpage>1634</lpage><pub-id pub-id-type="doi">10.1126/science.777786</pub-id><pub-id pub-id-type="pmid">7777863</pub-id>
</element-citation><mixed-citation id="mc-CR91" publication-type="journal">Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K. M., &#x00026; Sedivy, J. C. (1995). Integration of visual and linguistic information in spoken language comprehension. <italic>Science,</italic><italic>268</italic>(5217), 1632&#x02013;1634. 10.1126/science.777786<pub-id pub-id-type="pmid">7777863</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR92"><citation-alternatives><element-citation id="ec-CR92" publication-type="journal"><person-group person-group-type="author"><name><surname>Tremblay</surname><given-names>P</given-names></name><name><surname>Small</surname><given-names>SL</given-names></name></person-group><article-title>From language comprehension to action understanding and back again</article-title><source>Cerebral Cortex</source><year>2011</year><volume>21</volume><issue>5</issue><fpage>1166</fpage><lpage>1177</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq189</pub-id><pub-id pub-id-type="pmid">20940222</pub-id>
</element-citation><mixed-citation id="mc-CR92" publication-type="journal">Tremblay, P., &#x00026; Small, S. L. (2011). From language comprehension to action understanding and back again. <italic>Cerebral Cortex,</italic><italic>21</italic>(5), 1166&#x02013;1177. 10.1093/cercor/bhq189<pub-id pub-id-type="pmid">20940222</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR93"><citation-alternatives><element-citation id="ec-CR93" publication-type="journal"><person-group person-group-type="author"><name><surname>Treutler</surname><given-names>M</given-names></name><name><surname>S&#x000f6;r&#x000f6;s</surname><given-names>P</given-names></name></person-group><article-title>Functional MRI of native and non-native speech sound production in sequential German-English bilinguals</article-title><source>Frontiers in Human Neuroscience</source><year>2021</year><volume>15</volume><fpage>683277</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2021.683277</pub-id><pub-id pub-id-type="pmid">34349632</pub-id>
</element-citation><mixed-citation id="mc-CR93" publication-type="journal">Treutler, M., &#x00026; S&#x000f6;r&#x000f6;s, P. (2021). Functional MRI of native and non-native speech sound production in sequential German-English bilinguals. <italic>Frontiers in Human Neuroscience,</italic><italic>15</italic>, 683277. 10.3389/fnhum.2021.683277<pub-id pub-id-type="pmid">34349632</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR94"><citation-alternatives><element-citation id="ec-CR94" publication-type="journal"><person-group person-group-type="author"><name><surname>Wernicke</surname><given-names>C</given-names></name></person-group><article-title>The symptom complex of aphasia: A psychological study on an anatomical basis</article-title><source>Archives of Neurology</source><year>1970</year><volume>22</volume><issue>3</issue><fpage>280</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1001/archneur.1970.00480210090013</pub-id></element-citation><mixed-citation id="mc-CR94" publication-type="journal">Wernicke, C. (1970). The symptom complex of aphasia: A psychological study on an anatomical basis. <italic>Archives of Neurology,</italic><italic>22</italic>(3), 280&#x02013;282. 10.1001/archneur.1970.00480210090013</mixed-citation></citation-alternatives></ref><ref id="CR95"><citation-alternatives><element-citation id="ec-CR95" publication-type="journal"><person-group person-group-type="author"><name><surname>Yi</surname><given-names>HG</given-names></name><name><surname>Leonard</surname><given-names>MK</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name></person-group><article-title>The encoding of speech sounds in the superior temporal gyrus</article-title><source>Neuron</source><year>2019</year><volume>102</volume><issue>6</issue><fpage>1096</fpage><lpage>1110</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.04.023</pub-id><pub-id pub-id-type="pmid">31220442</pub-id>
</element-citation><mixed-citation id="mc-CR95" publication-type="journal">Yi, H. G., Leonard, M. K., &#x00026; Chang, E. F. (2019). The encoding of speech sounds in the superior temporal gyrus. <italic>Neuron,</italic><italic>102</italic>(6), 1096&#x02013;1110. 10.1016/j.neuron.2019.04.023<pub-id pub-id-type="pmid">31220442</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR96"><citation-alternatives><element-citation id="ec-CR96" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhuang</surname><given-names>J</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name><name><surname>Randall</surname><given-names>B</given-names></name><name><surname>Stamatakis</surname><given-names>EA</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name></person-group><article-title>Optimally efficient neural systems for processing spoken language</article-title><source>Cerebral Cortex</source><year>2014</year><volume>24</volume><issue>4</issue><fpage>908</fpage><lpage>918</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs366</pub-id><pub-id pub-id-type="pmid">23250955</pub-id>
</element-citation><mixed-citation id="mc-CR96" publication-type="journal">Zhuang, J., Tyler, L. K., Randall, B., Stamatakis, E. A., &#x00026; Marslen-Wilson, W. D. (2014). Optimally efficient neural systems for processing spoken language. <italic>Cerebral Cortex,</italic><italic>24</italic>(4), 908&#x02013;918. 10.1093/cercor/bhs366<pub-id pub-id-type="pmid">23250955</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR97"><citation-alternatives><element-citation id="ec-CR97" publication-type="journal"><person-group person-group-type="author"><name><surname>Zwitserlood</surname><given-names>P</given-names></name></person-group><article-title>The locus of the effects of sentential-semantic context in spoken-word processing</article-title><source>Cognition</source><year>1989</year><volume>32</volume><issue>1</issue><fpage>25</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(89)90013-9</pub-id><pub-id pub-id-type="pmid">2752705</pub-id>
</element-citation><mixed-citation id="mc-CR97" publication-type="journal">Zwitserlood, P. (1989). The locus of the effects of sentential-semantic context in spoken-word processing. <italic>Cognition,</italic><italic>32</italic>(1), 25&#x02013;64. 10.1016/0010-0277(89)90013-9<pub-id pub-id-type="pmid">2752705</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>