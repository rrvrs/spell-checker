<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Psychon Bull Rev</journal-id><journal-id journal-id-type="iso-abbrev">Psychon Bull Rev</journal-id><journal-title-group><journal-title>Psychonomic Bulletin &#x00026; Review</journal-title></journal-title-group><issn pub-type="ppub">1069-9384</issn><issn pub-type="epub">1531-5320</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>New York</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38587754</article-id><article-id pub-id-type="pmc">PMC11680606</article-id>
<article-id pub-id-type="publisher-id">2493</article-id><article-id pub-id-type="doi">10.3758/s13423-024-02493-5</article-id><article-categories><subj-group subj-group-type="heading"><subject>Brief Report</subject></subj-group></article-categories><title-group><article-title>Attention and feature binding in the temporal domain</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Zivony</surname><given-names>Alon</given-names></name><address><email>a.zivony@sheffield.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Eimer</surname><given-names>Martin</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05krs5044</institution-id><institution-id institution-id-type="GRID">grid.11835.3e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9262</institution-id><institution>Department of Psychology, </institution><institution>University of Sheffield, </institution></institution-wrap>Sheffield, UK </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04cw6st05</institution-id><institution-id institution-id-type="GRID">grid.4464.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 2161 2573</institution-id><institution>Department of Psychological Sciences, Birkbeck College, </institution><institution>University of London, </institution></institution-wrap>London, UK </aff></contrib-group><pub-date pub-type="epub"><day>8</day><month>4</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>8</day><month>4</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2024</year></pub-date><volume>31</volume><issue>6</issue><fpage>2599</fpage><lpage>2610</lpage><history><date date-type="accepted"><day>12</day><month>3</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Previous studies have shown that illusory conjunction can emerge for both spatially and temporally proximal objects. However, the mechanisms involved in binding in the temporal domain are not yet fully understood. In the current study, we investigated the role of attentional processes in correct and incorrect temporal binding, and specifically how feature binding is affected by the speed of attentional engagement. In two experiments, participants searched for a target in a rapid serial visual presentation stream and reported its colour and alphanumeric identity. Temporal binding errors were frequent. Critically, when participants reported the identity of a distractor instead of a target, they were also more likely to report the colour of this distractor. This association was observed both within and between individuals. These findings suggest that attentional engagement facilitates the binding of temporally co-occurring features. We discuss these results within a &#x02018;diachronic&#x02019; framework of selective attention, and also consider other factors that contribute to temporal binding errors.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Attention</kwd><kwd>Binding</kwd><kwd>Attentional episodes</kwd><kwd>Temporal attention</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id>896192</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000269</institution-id><institution>Economic and Social Research Council</institution></institution-wrap></funding-source><award-id>ES/V002708/1</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Psychonomic Society, Inc. 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Perceiving objects as cohesive wholes rather than an assortment of disparate features (colour, shape) is essential to everyday functioning. Yet, how these features become bound together has not been resolved despite decades of research. Through the years, different accounts of feature binding have been put forward, most of which emphasized spatial attention as a key factor in binding (Kovacs &#x00026; Harris, <xref ref-type="bibr" rid="CR11">2019</xref>; Treisman &#x00026; Gelade, <xref ref-type="bibr" rid="CR20">1980</xref>; Wolfe &#x00026; Cave, <xref ref-type="bibr" rid="CR25">1999</xref>). While the role of space in binding has been thoroughly investigated, the role of time has received much less attention. This is unfortunate since real-world visual inputs change over time and objects need to be individuated from preceding and following objects at the same location. Also, because different features are processed at different speeds (Wolfe, <xref ref-type="bibr" rid="CR24">2014</xref>), even spatially attended features at the same location will not necessarily be processed simultaneously, resulting in a <italic>temporal</italic> binding problem (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR28">2022a</xref>). Similar to the phenomenon of &#x02018;illusory conjunctions&#x02019; in the spatial domain (Treisman &#x00026; Schmidt, <xref ref-type="bibr" rid="CR21">1982</xref>), the temporal binding problem can be demonstrated with temporal binding errors. When searching for a target among rapidly changing stimuli, features from successive objects are often incorrectly perceived as conjoined, resulting in distractor intrusion errors. For example, if participants have to detect a red digit among grey digits, they will often report seeing a temporally adjacent distractor as the red digit (e.g., Botella et al., <xref ref-type="bibr" rid="CR6">2001</xref>; Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR27">2021</xref>).</p><p id="Par3">Only a few theoretical accounts of temporal binding have been put forward so far. These accounts all assume that features are sampled independently, and for binding to take place, individual features must gain access to working memory (WM). However, the role of attention for temporal binding remains disputed. According to one view (Botella et al., <xref ref-type="bibr" rid="CR6">2001</xref>), correct temporal binding strongly depends on an all-or-none attentional selection process. When selection occurs at the right moment, correct binding is guaranteed. In contrast, a failure of attentional selection results in both &#x0201c;fortunate conjunctions&#x0201d; (i.e., correct reports) as well as various binding errors, determined by feature salience and proximity to the target. This postulated two-stage mechanism can explain a wide range of results in distractor intrusions studies, such as differences in the pattern of intrusions when participants report colours versus identities (Botella et al., <xref ref-type="bibr" rid="CR5">1992</xref>). However, we have previously shown that intrusions are not associated with complete failures of attentional selection, but rather with delays in the deployment of spatial attention (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR27">2021</xref>, <xref ref-type="bibr" rid="CR30">2023</xref>). An alternative account of binding was proposed by Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>), who suggest that spatiotemporal attention plays no role in spatial or temporal feature binding. Instead, features of spatially or temporally distributed objects are sampled separately, and binding depends on which features are selected for encoding, based on probabilistic distributions. Because features are sampled independently, and their binding is not mediated by spatiotemporal attention, binding errors should show no bias towards reporting spatially or temporally co-occurring features. Reporting a feature in one dimension (identity) does not determine whether the reported feature in a different dimension (colour) belongs to the same or a different object. Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>) found support for this prediction both for spatial attention with visual search tasks and for temporal attention with rapid serial visual presentation (RSVP) tasks, where participants had to report both the colour and the identity of a target (see Botella et al., <xref ref-type="bibr" rid="CR5">1992</xref>, for a similar task). In their RSVP task, they reported only a &#x0201c;negligible&#x0201d; (p. 1173) co-variance between the temporal positions of the reported features, suggesting that their temporal co-occurrence did not affect binding.</p><p id="Par4">The conclusion that attention does not affect feature binding in space and time (Vul &#x00026; Rich, <xref ref-type="bibr" rid="CR22">2010</xref>) is provocative, as it challenges a core assumption of current models of binding (e.g., Wolfe &#x00026; Cave, <xref ref-type="bibr" rid="CR25">1999</xref>; Treisman, <xref ref-type="bibr" rid="CR19">2014</xref>). It therefore certainly deserves further critical evaluation. Here, we present two experiments that re-examined whether temporal co-occurrence affects binding, and by proxy, re-evaluate the role of attention in temporal binding. These experiments were motivated by a group of theories (Bowman &#x00026; Wyble, <xref ref-type="bibr" rid="CR7">2007</xref>; Olivers &#x00026; Meeter <xref ref-type="bibr" rid="CR14">2008</xref>; Shih, <xref ref-type="bibr" rid="CR17">2008</xref>; Sperling &#x00026; Weichselgartner, <xref ref-type="bibr" rid="CR18">1995</xref>; Reeves &#x00026; Sperling, <xref ref-type="bibr" rid="CR16">1986</xref>; Wyble et al., <xref ref-type="bibr" rid="CR26">2011</xref>) that we recently labelled as &#x02018;diachronic&#x02019; accounts of temporal selectivity (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR28">2022a</xref>). Diachronic accounts of attention &#x02013; while different in many respects &#x02013; all emphasize the gradual emergence of attentional selectivity across time. Specifically, they all share the assumption that perception is strongly modulated during transient periods (~150&#x02013;250 ms) of attentional amplification. These &#x0201c;attentional episodes&#x0201d; (Wyble et al., <xref ref-type="bibr" rid="CR26">2011</xref>) are triggered once a potentially relevant event is detected, and then indiscriminately modulates the perception of all the features that appear in the same location, thereby increasing the likelihood that they will be encoded. Because the processing of multiple objects is likely to be enhanced during the attentional episode, a distractor feature may be encoded instead of the corresponding target feature, resulting in an intrusion error. However, and in direct contrast to the proposal by Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>), the distinct time course of amplification during an attentional episode should result in a dependency in the reports of features from the same object. Because amplification is indiscriminate, when two features appear at the same time, their processing should benefit to a&#x000a0;similar extent from the amount of amplification received at that point in time. Moreover, since the onset of the attentional episode is not fixed, but rather varies from trial to trial (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR27">2021</xref>), which features receive maximal attentional enhancement changes from trial to trial. Therefore, participants should be biased towards reporting the target&#x02019;s feature (or the features of the object preceding the target) when the attentional episode is triggered early, and they should be biased towards reporting the features of the following object(s) when the attentional episode is triggered late. Thus, diachronic accounts predict that there should be a bias towards encoding and reporting features from the same object in RSVP tasks.</p><p id="Par5">Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>) may have failed to observe such a dependency because several aspects of their experimental design and analysis could have reduced the likelihood to observe such an effect. In the current Experiment <xref rid="Sec2" ref-type="sec">1</xref>, we employed their general design, but changed some key features that may have obscured evidence for object-based feature binding (see below). Importantly, Vul and Rich examined co-variation in position of reported features across all trials and all participants (i.e., each trial was a datapoint). This analysis ignores individual differences in binding that may be linked to known individual differences in temporal selectivity (Martens et al., <xref ref-type="bibr" rid="CR12">2006</xref>). It is possible that some participants showed object-based feature binding, but this may have been obscured by the data from other participants who did not. Therefore, the current study included additional analyses that take such individual differences into account. We predicted that with this analysis a robust dependency will emerge between reports of co-occurring features.</p></sec><sec id="Sec2"><title>Experiment 1</title><sec id="Sec3"><title>Method</title><p id="Par6">In their experiment, Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>) asked participants to report a target&#x02019;s identity and colour in two sequential responses. This may have weakened evidence of the importance of co-occurrence because participants could not match the stimuli in the response screen based on familiarity or a full match with a memorized object. Furthermore, their response screens included the target and two preceding and following distractors, but no unrelated items, so that guess rates could not be quantified. In Experiment <xref rid="Sec2" ref-type="sec">1</xref>, all target/distractor colour and identity combinations were presented in the same response screen, and these screens also included a &#x0201c;foil&#x0201d; object that was not present in the RSVP stream (Fig. <xref rid="Fig1" ref-type="fig">1</xref>B). Thus, response choices could be based on full matches and/or familiarity, and the probability of guesses could be assessed.<fig id="Fig1"><label>Fig. 1</label><caption><p>Illustration of the experimental paradigm used in Experiment <xref rid="Sec2" ref-type="sec">1</xref>. Participants had to find a target character inside a circle (<bold>A</bold>), embedded in a rapid serial visual presentation (RSVP) stream of grey digits and letters, and report its colour and identity (<bold>B</bold>). The response screen always included the identities and colours of the target, the pre-target (-1) distractor, post-target (+1) distractor, as well as one identity (e.g., &#x0201c;2&#x0201d;) and one colour (e.g., blue) that did not appear in the RSVP</p></caption><graphic xlink:href="13423_2024_2493_Fig1_HTML" id="MO1"/></fig></p><sec id="Sec4"><title>Ethics</title><p id="Par7">All methods used in this and the next experiment were approved by the institution&#x02019;s departmental ethical guidelines committee at Birkbeck, University of London.</p></sec><sec id="Sec5"><title>Sample size selection</title><p id="Par8">We based our sample size on Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>), even though we could not use their report to conduct a formal power analysis. They reported that with 14 participants and 100 trials per condition (i.e., 1,400 observations), they observed a negligibly small but significant correlation between reports of identity and of colour in their RSVP task (100-ms condition). To increase power, we increased the number of participants to 20 and increased the number of observations by 2.4 (to a total of 4,800 observations). This ensured that the current study has enough power to detect even smaller effects than the ones observed in Vul and Rich.</p></sec><sec id="Sec6"><title>Participants</title><p id="Par9">After the exclusion of a single participant from the dataset (see below), the sample included 20 (16 women) volunteers (<italic>M</italic><sub><italic>age</italic></sub> = 27.7, <italic>SD</italic> = 7.1 years) who participated for &#x000a3;5 or course credits. All reported normal or corrected-to-normal visual acuity and normal colour vision. Participants were given the option to report gender identities other than woman or man. In this experiment and all subsequent experiments, these options were not selected. No other demographic information was collected.</p></sec><sec id="Sec7"><title>Apparatus</title><p id="Par10">The experiment was conducted using participants&#x02019; individual computers, who accessed and downloaded the experiment via E-Prime Go cloud service. Subjects were asked to sit approximately 60 cm from the screen (approximately an arm&#x02019;s length), in a quiet and distraction-free environment, and complete the task in one sitting within 35 min. Manual responses were given via standard keyboard and mouse.</p></sec><sec id="Sec8"><title>Stimuli, procedure and design</title><p id="Par11">All stimuli sizes were calculated in visual angles based on the participants&#x02019; self-reported monitor size (monitor sizes ranged from 12 in. to 17 in.) and an assumed distance of 60 cm from the screen. If participants did not know their monitor size, they were directed to a website that calculates it for them (<ext-link ext-link-type="uri" xlink:href="http://www.piliapp.com/actual-size/credit-card/">www.piliapp.com/actual-size/credit-card/</ext-link>).</p><p id="Par12">Participants had to report as accurately as possible the identity of an alphanumeric character that appeared inside a (0.8&#x000b0; radius) circle cue (the selection feature). These targets were presented unpredictably in an RSVP stream that appeared in the centre of the screen. Manual responses were executed without time pressure at the end of each trial. The sequence of events is illustrated in Fig. <xref rid="Fig1" ref-type="fig">1</xref>A. Each trial began with the presentation of a fixation display (a grey 0.2&#x000b0; &#x000d7; 0.2&#x000b0; &#x0201c;+&#x0201d; sign at the centre of the screen). Then, after 500 ms, the RSVP stream appeared.</p><p id="Par13">The target digit appeared with equal probability and unpredictably in the sixth, eighth, tenth or 12th frame within the RSVP stream, and was followed by two additional distractors. Therefore, the length of the RSVP was between eight and 14 frames. Alphanumeric characters were all 1.3&#x000b0; in height. The selection cue had a radius of&#x000a0;0.8&#x000b0; and line width of 4 pixels. All characters in the RSVP streams were grey and were randomly selected without replacement from a 24-letter set (all English alphabet letters, excluding I and O) and a set of eight digits (2&#x02013;9), with the restriction that letters and digits appeared equally often in the RSVP. All characters were drawn in &#x02018;Consolas&#x02019; font. The letters and digits were drawn in one of six possible colours: green (RGB values: 0,90,0), blue (50,100,255), orange (255,175,200), yellow (255,255,0), magenta (160,75,160) and red (255,0,0). On every trial, one colour did not appear in the RSVP stream. The colour on each frame was randomly drawn from the remaining five colours with the following restrictions: colours could not repeat until all five colours appeared and could not appear on two frames in a row. Finally, the colours of the distractor that preceded and the two distractors that followed the target (-1, +1, and +2 positions) were always different from one another and different from the target&#x02019;s colour.</p><p id="Par14">Each frame appeared for 50 ms, followed by an interstimulus interval (ISI) of 50 ms. E-prime Go can collect data about exact presentation times, which varied across different computers. Participants were excluded if their monitor&#x02019;s refresh rate could not produce these stimulus durations or ISI durations (e.g., if their monitor refresh rate was 50 Hz, they were not included in the sample; see Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR29">2022b</xref>, for a similar procedure). After the exclusion of a single participant, each frame appeared on average for 49.80 ms (<italic>SD</italic> = 0.45 ms), followed by an ISI of 49.86 ms (<italic>SD</italic> = 0.76 ms).</p><p id="Par15">The response screen (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>B) included a 4 &#x000d7; 4 grid. Columns were based on different colours. They included, in random order, the colour of the target, the colour of the pre-target (-1) distractor, the colour of the post-target (+1) distractor, and the colour that did not appear in the RSVP on that trial. Rows were based on different identities. They included the identities of the target, pre-target (-1), post-target (+1), and another digit or letter that did not appear in the RSVP stream. From left to right, digits were presented first (sorted based on size) and letters later (sorted based on alphabet order). Thus, the locations on the grid were uncorrelated with the order in which the colours or identities appeared in the stream. The centre-to-centre distance between characters was 3.0&#x000b0; both horizontally and vertically. Participants used the mouse to select one of the characters, by pressing on an area within an invisible 0.8&#x000b0; &#x000d7; 1.0&#x000b0; rectangle around a character. Once pressed, a (0.8&#x000b0; radius) circle appeared for 200 ms around the selected character to provide participants with visual feedback that their response was registered. Following feedback, a blank screen appeared for 800 ms before a new trial started. The experiment included ten practice trials followed by 240 experimental trials, divided into 60-trial blocks.</p></sec><sec id="Sec9"><title>Analysis</title><p id="Par16">For any given trial, we coded which features participants reported based on their temporal position relative to the target (a position index). That is, reporting a target feature yields a position index value of 0 and reporting the distractor immediately following or preceding the target yields a value of +1 and -1, respectively. Our first analysis was meant to replicate Vul and Rich&#x02019;s results. Therefore, we conducted a Spearman Rho&#x02019;s correlation analysis on the position of the reported colour (-1, 0, or +1) and the position of the reported identity (-1, 0, or +1), taking into account all trials except for trials with foil reports. This analysis does not take into account individual differences, which might be an important source of statistical error. Therefore, our second and third analyses used a within-subject design.</p><p id="Par17">Our second analysis compared the likelihood of making different types of errors (Dowd &#x00026; Golomb, <xref ref-type="bibr" rid="CR8">2019</xref>).<xref ref-type="fn" rid="Fn1">1</xref> If co-occurring features are processed independently, reporting of one of the distractor&#x02019;s features should not be correlated with reporting its other features. For example, report of the -1 identity should be equally likely to be accompanied with report of the -1 colour (correlated intrusion) or of the +1 colour (uncorrelated intrusion). In contrast, if there is a dependency between co-occurring features, correlated intrusions should be substantially more frequent than uncorrelated intrusions.</p><p id="Par18">A drawback of this analysis is that it excludes a large proportion of trials (i.e., trials where target features were reported). Therefore, we also examined the dependency between identity reports and colour reports with two additional&#x000a0;methods. First, we quantified the average reported feature for each participant as a function of the feature&#x02019;s position relative to the target &#x02013; an average position index (API; see also Botella et al., <xref ref-type="bibr" rid="CR6">2001</xref>). For each participant, we calculated the average position of colour reported (colour API) as a function of the reported identity (-1, 0, or +1). Then, colour APIs were compared using a repeated-measures ANOVA with the reported identity as the independent variable.<xref ref-type="fn" rid="Fn2">2</xref> Following our previous findings showing that report of distractor identities depends on the onset of the attentional episode (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR27">2021</xref>), we predicted that colour APIs would change as a factor of the reported identity: they should be higher on trials where participants report the identity of the +1 distractor than the target or the -1 distractor. In contrast, a lack of dependency between the two measures should result in similar colour API regardless of the reported identity. A significant main effect was followed by Bonferroni-corrected comparisons that examined the differences in colour API between each pair of reported identities (pre-target vs. target, target vs. post-target).</p><p id="Par19">Finally, another way to examine the dependency between temporally co-occurring features is to use an individual differences approach. If the timing of attentional episodes plays a role in binding and varies reliably between different individuals, then some individuals should have a high-identity API and high-colour API, whereas others should have relatively low API on both measures. In contrast, if the timing of attentional episodes does not play a role in binding and/or does not reliably vary between participants, then participants with a high-identity API should be equally likely to show a low-colour API. To examine this, we calculated the average colour API and identity API for each participant and then calculated the Pearson correlation between the two measures.</p></sec></sec><sec id="Sec10"><title>Results</title><p id="Par20">Participants mostly reported the target accurately (48.2%; Fig. <xref rid="Fig2" ref-type="fig">2</xref>A centre) or else reported a combination of one of the target&#x02019;s features and one of the distractor&#x02019;s features (32.9%; Fig. <xref rid="Fig2" ref-type="fig">2</xref>A, sum of datapoints perpendicular to centre). The likelihood to report the foil was very low, <italic>M</italic> = 2.4% and <italic>M</italic> = 4.0%, for identity and colour reports, respectively. On average, participants were less accurate in identifying the target&#x02019;s identity than the target&#x02019;s colour, <italic>M</italic> = 61.8% versus <italic>M</italic> = 70.5%, <italic>t</italic>(19) = 3.48, <italic>p</italic> = .002, <italic>d</italic><sub><italic>z</italic></sub> = 1.23. The full distribution of reported features (except for foil reports) is presented in Fig. <xref rid="Fig1" ref-type="fig">1</xref>A. As predicted, the first analysis yielded a small yet significant positive correlation between the position of the reported colour and identity, <italic>&#x003c1;</italic>(4690) = .13, <italic>p</italic> &#x0003c; .001 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A).<fig id="Fig2"><label>Fig. 2</label><caption><p>Results from Experiment <xref rid="Sec2" ref-type="sec">1</xref>. (<bold>A</bold>) Frequency table&#x000a0;denoting the report frequency of each of the possible conjunctions (reported colour and reported identity), except for foil reports. (<bold>B</bold>) Report likelihood of reporting a combination of distractor features from two different distractors (uncorrelated intrusion) versus the likelihood of reporting two distractor features from the same distractor (correlated intrusions). (<bold>C</bold>) Average reported position in the colour dimension (average position index, API) as a function of the reported identity. In panels B and C, the black line reflects the average across all participants (error bars reflect one standard error) and grey lines reflect individual participants</p></caption><graphic xlink:href="13423_2024_2493_Fig2_HTML" id="MO2"/></fig></p><sec id="Sec11"><title>Within-participants dependency</title><p id="Par21">Participants were almost twice more likely to make correlated intrusion errors (reports of both features from the same distractor; Fig. <xref rid="Fig2" ref-type="fig">2</xref>A, bottom-left and top-right corners) than uncorrelated intrusion errors (reports of features from different distractors; Fig. <xref rid="Fig2" ref-type="fig">2</xref>A, bottom-right and top-left corners), <italic>M</italic> = 8.4% versus <italic>M</italic> = 4.3%. This observation was confirmed by a direct comparison of these two types of errors, <italic>t</italic>(19) = 5.24, <italic>p</italic> &#x0003c; .001, <italic>d</italic><sub><italic>z</italic></sub> = 1.17 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). Moreover, colour API gradually rose as a function of the position of the reported identity (Fig. <xref rid="Fig2" ref-type="fig">2</xref>C): colour API was lowest when participants reported the pre-target identity (<italic>M</italic> = -0.10), higher for target reports (<italic>M</italic> = -0.001), and highest for post-target reports (<italic>M</italic> = 0.13). The third analysis confirmed this observation, <italic>F</italic>(2,40) = 24.86, <italic>p</italic> &#x0003c; .001, <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\eta }_{p}^{2}$$\end{document}</tex-math><mml:math id="M2"><mml:msubsup><mml:mi>&#x003b7;</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13423_2024_2493_Article_IEq1.gif"/></alternatives></inline-formula>= .55. The follow-up analysis indicated that differences between colour API on each pair of reported identities was significant, <italic>t</italic>(19) = 2.96, <italic>p</italic> = .008, <italic>d</italic><sub><italic>z</italic></sub> = 0.90, and <italic>t</italic>(19) = 4.06, <italic>p</italic> &#x0003c; .001, <italic>d</italic><sub><italic>z</italic></sub> = 1.24.</p></sec><sec id="Sec12"><title>Between-participants dependency</title><p id="Par22">The fourth analysis revealed a significant positive correlation between average colour APIs and average identity APIs, <italic>r</italic>(18) = .58, <italic>p</italic> = .007 (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A).<fig id="Fig3"><label>Fig. 3</label><caption><p>Scatterplot of average reported colour position (colour average position index, API) and average identity position (identity API) in Experiment <xref rid="Sec2" ref-type="sec">1</xref> (<bold>A</bold>) and Experiment <xref rid="Sec14" ref-type="sec">2</xref> (<bold>B</bold>). Data in Experiment <xref rid="Sec14" ref-type="sec">2</xref> is separated as function of the task (first-colour vs. first-digit). Each dot reflects one participant. The dotted line reflects the linear regression line fitted based on the data</p></caption><graphic xlink:href="13423_2024_2493_Fig3_HTML" id="MO3"/></fig></p></sec></sec><sec id="Sec13"><title>Discussion</title><p id="Par23">The results of Experiment <xref rid="Sec2" ref-type="sec">1</xref> demonstrated that temporally co-occurring features are more likely to be encoded together, as reports of an object&#x02019;s identity were associated with a higher likelihood of reporting the same object&#x02019;s colour. Importantly, participants who had a high API on one feature also had a high API on the other. Once these individual differences were accounted for, the effect sizes demonstrating co-dependence of feature reports were far from negligible. At the same time, binding errors still occurred on a substantial number of trials. We return to this point in the <italic>General discussion</italic>. Another finding was that colour reports were more accurate than identity reports. This is compatible with the notion that colour is processed faster than semantic identity (Treisman, <xref ref-type="bibr" rid="CR19">2014</xref>; Wolfe, <xref ref-type="bibr" rid="CR24">2014</xref>), and that this difference affects feature binding.</p><p id="Par24">However, two issues potentially limit these conclusions. First, stimulus set size differed between dimensions, as there were 32 possible letters and only six possible colours, which may have contributed to the observed asymmetry between these dimensions. More importantly, the shape selection feature in Experiment <xref rid="Sec2" ref-type="sec">1</xref> was not part of the reported object itself. Thus, the observed dependency between co-occurring features may have resulted from the additional temporal demands of shifting attention from the selection cue to the object inside the stream. Experiment <xref rid="Sec14" ref-type="sec">2</xref> was designed to address these issues.</p></sec></sec><sec id="Sec14"><title>Experiment 2</title><sec id="Sec15"><title>Method</title><p id="Par25">In Experiment <xref rid="Sec14" ref-type="sec">2</xref>, target set size was limited to four possible colours and four possible identities. Importantly, instead of searching for a shape cue, participants were instructed to report either the first coloured item after a series of grey distractors or the first digit following a series of distractor letters. Thus, the selection feature was now always a part of the reported object. As before, the question was whether reliable evidence for the preferential binding of temporally co-occurring features would be obtained under these circumstances.</p><sec id="Sec16"><title>Sample size selection</title><p id="Par26">We conducted a power analysis to calculate the required sample to replicate the main result (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B) in Experiment <xref rid="Sec2" ref-type="sec">1</xref> with 80% power. To do this, we entered the effect size of the one-way ANOVA (<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\eta }_{p}^{2}$$\end{document}</tex-math><mml:math id="M4"><mml:msubsup><mml:mi>&#x003b7;</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13423_2024_2493_Article_IEq2.gif"/></alternatives></inline-formula>=.55) to G*Power (Faul et al., <xref ref-type="bibr" rid="CR9">2013</xref>). This analysis revealed that a sample of a mere seven participants would suffice to replicate this effect. To allow for a better comparison between the two experiments, we once again recruited 20 participants.</p></sec><sec id="Sec17"><title>Apparatus</title><p id="Par27">Unlike Experiment <xref rid="Sec2" ref-type="sec">1</xref>, this experiment was conducted in the lab and not in participants&#x02019; homes. Stimuli were presented on a 24-in. BenQ LED monitor (120 Hz; 1,920 &#x000d7; 1,080 screen resolution) attached to a SilverStone PC, with participant viewing distance at approximately 80 cm. Manual responses were registered via a standard mouse.</p></sec><sec id="Sec18"><title>Stimuli, procedure and design</title><p id="Par28">The stimuli, procedure and design were the same as Experiment <xref rid="Sec2" ref-type="sec">1</xref> except for the following changes. For every participant, the set of potential target stimuli was comprised of a combination of four possible digits in four possible colours. The set of four digits was selected at random at the beginning of the experiment from the set used in Experiment <xref rid="Sec2" ref-type="sec">1</xref> and remained the same throughout the experiment. Participants were notified that the target will always be one of these digits. The four colours were orange (CIE colour coordinates: .476/.462), green (.247/.402), blue (.199/.253) and magenta (.333/.165), and were matched in luminance (38.8&#x02013;40.3&#x0202f;cd/m<sup>2</sup>).</p><p id="Par29">The experiment included two tasks. In the <italic>first-digit</italic> task (Fig. <xref rid="Fig4" ref-type="fig">4</xref>A), participants had to detect the first digit in the RSVP, whereas in the <italic>first-colour</italic> task (Fig. <xref rid="Fig4" ref-type="fig">4</xref>B), they had to detect the first coloured item in the RSVP. The two tasks had the following in common: the target was always a coloured digit, and participants had to report both its identity and colour. The target was always followed by two frames of differently coloured digits. The response screen always included nine options, sorted in a 3 &#x000d7; 3 array (Fig. <xref rid="Fig4" ref-type="fig">4</xref>C). These included the target digit, the post-target (+1) digit, and a foil digit that did not appear near the target (i.e., not in the -1 or +2 positions), and these items were presented in the target&#x02019;s colour, the post-target colour, and a foil colour.<fig id="Fig4"><label>Fig. 4</label><caption><p>Illustration of the experimental paradigm used in Experiment <xref rid="Sec14" ref-type="sec">2</xref>. Participants had to find the first digit in a stream of differently coloured letters (<bold>A</bold>) or the first coloured item (<bold>B</bold>) among a stream of grey coloured digits and letters, and report its colour and identity. The response screen (<bold>C</bold>) always included the identities and colours of the target, the post-target (+1) distractor, as well as a foil colour (e.g., green) and a foil digit (e.g., &#x0201c;4&#x0201d;) that did not appear near the target</p></caption><graphic xlink:href="13423_2024_2493_Fig4_HTML" id="MO4"/></fig></p><p id="Par30">The main difference between the tasks was the RSVP frames that preceded the target. In the first-digit task, the target was preceded by differently coloured letters. The letter identities were selected randomly without replacement from the set used in Experiment <xref rid="Sec2" ref-type="sec">1</xref>. Half of these letters were grey, whereas the others were coloured randomly in one of four possible colours. The sole restrictions were that the same colour could not repeat twice on two consecutive frames, and that the distractor immediately preceding the target could be either grey or match the +2 distractor (i.e., it did not share the target&#x02019;s colour, the post-target colour, or the foil&#x02019;s colour).</p><p id="Par31">In contrast, in the first-colour task, the target was preceded by grey digits and letters. The letter identities (50% of distractors) were selected randomly without replacement, whereas the digit identities were randomly selected with replacement from the set of four possible digits. The sole restrictions were that the same colour could not repeat twice on two consecutive frames, and that the distractor immediately preceding the target could only be a letter or match the +2 distractor (i.e., it did not share the target&#x02019;s identity, the post-target identity, or the foil&#x02019;s identity). Taken together, the difference between the two tasks was in what information participants could use to search for the target. Even though the target was always a coloured digit, participants could only utilize the target&#x02019;s alphanumeric category in the first-digit task (since many distractors were coloured) and could only utilize the target&#x02019;s colour in the first-colour task (since many distractors were digits).</p><p id="Par32">Participants completed eight blocks of 60 trials (i.e., a total of 480 trials), divided into two halves based on the task. The order in which the tasks was presented was counterbalanced between subjects. Before the experiment began participants received instructions and were given ten practice trials. At the halfway point, they received instructions regarding the new task and were given five practice trials.</p></sec><sec id="Sec19"><title>Analysis</title><p id="Par33">We once again examined the dependency between identity reports and colour reports, and conducted this analysis separately for both tasks. To do so, we excluded trials where participants selected the foil in either reporting dimensions. Like Experiment <xref rid="Sec2" ref-type="sec">1</xref>, we first conducted a Spearman Rho&#x02019;s correlation analysis on the position of the reported colour (0 or +1) and the position of the reported identity (0 or +1). In this experiment, the -1 distractor was not reportable, and therefore we could not compare between correlated and uncorrelated intrusions. For the second analysis, we once again examined the average colour API as a function of identity report (target vs. post-target). We entered these APIs as a dependent variable in a two-way repeated-measures ANOVA with task (first-digit vs. first-colour) and reported identity (target vs. post-target, i.e., 0 vs. +1). Finally, like Experiment <xref rid="Sec2" ref-type="sec">1</xref>, we examined the correlation between average identity API and average colour API using a Pearson correlation.</p></sec></sec><sec id="Sec20"><title>Results</title><p id="Par34">Performance was generally poorer in the first-digit task than the first-colour task. This can be seen from the accuracy level in reports of both identity (<italic>M</italic> = 39.2% vs. <italic>M</italic> = 50.4%; Fig. <xref rid="Fig5" ref-type="fig">5</xref>A, sum of left columns) and colour (<italic>M</italic> = 44.3% vs. <italic>M</italic> = 60.6%; Fig. <xref rid="Fig5" ref-type="fig">5</xref>A, sum of bottom rows), both <italic>p</italic>s &#x0003c; .01. Similarly, foil identities and foil colours were more likely to be reported in the first-digit task than in the first-colour task (<italic>M</italic> = 13.9% vs. <italic>M</italic> = 10.4% and <italic>M</italic> = 15.5% vs. <italic>M</italic> = 7.4%, respectively), both <italic>p</italic>s &#x0003c; .05. In both tasks, correct reports were most common, followed by incorrect bindings of colour and identity, and reports of the post-target distractor (Fig. <xref rid="Fig5" ref-type="fig">5</xref>A). The first analysis revealed a significant correlation between the positions of reported colours and identities for both the first-digit and the first-colour tasks, <italic>&#x003c1;</italic>(3677) = .29, <italic>p</italic> &#x0003c; .001 and <italic>&#x003c1;</italic>(4164) = .30, <italic>p</italic> &#x0003c; .001, respectively.<fig id="Fig5"><label>Fig. 5</label><caption><p>Results from Experiment <xref rid="Sec14" ref-type="sec">2</xref> as function of the task (first-colour vs. first-digit, reported in the upper and lower row respectively). (<bold>A</bold>) Frequency tables denoting the report frequency of each of the possible conjunctions (reported colour and reported identity), excluding foil reports. (<bold>B</bold>) Average reported position in the colour dimension (average position index, API) as function of the reported identity. The black line reflects the average across all participants (error bars reflect one standard error) and grey lines reflect individual participants</p></caption><graphic xlink:href="13423_2024_2493_Fig5_HTML" id="MO5"/></fig></p><sec id="Sec21"><title>Within-participants dependency</title><p id="Par35">The second analysis revealed that APIs were higher in the first-digit task than in the first-colour task (<italic>M</italic> = 0.44 vs. <italic>M</italic> = 0.32), <italic>F</italic>(1,19) = 27.39, <italic>p</italic> &#x0003c; .001, <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\eta }_{p}^{2}$$\end{document}</tex-math><mml:math id="M6"><mml:msubsup><mml:mi>&#x003b7;</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13423_2024_2493_Article_IEq3.gif"/></alternatives></inline-formula>= .59. Importantly, colour APIs were also higher on trials where participants reported the +1 distractor identity (<italic>M</italic> = 0.55 vs. <italic>M</italic> = 0.34), <italic>F</italic>(1,19)=37.66, <italic>p</italic>&#x0003c;.001, <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\eta }_{p}^{2}$$\end{document}</tex-math><mml:math id="M8"><mml:msubsup><mml:mi>&#x003b7;</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math><inline-graphic xlink:href="13423_2024_2493_Article_IEq4.gif"/></alternatives></inline-formula>=.67 (Fig. <xref rid="Fig5" ref-type="fig">5</xref>B). The interaction between the two factors was not significant, <italic>F</italic>&#x0003c;1.</p></sec><sec id="Sec22"><title>Between-participants dependency</title><p id="Par36">The correlation between identity API and colour API was significant for both the first-colour and the first-digit tasks, <italic>r</italic>(18) = .88, <italic>p</italic> &#x0003c; .001 and <italic>r</italic>(18) = .89, <italic>p</italic> &#x0003c; .001 (Fig. <xref rid="Fig3" ref-type="fig">3</xref>B).</p></sec></sec><sec id="Sec23"><title>Discussion</title><p id="Par37">The results of Experiment <xref rid="Sec14" ref-type="sec">2</xref> closely replicated those of Experiment <xref rid="Sec2" ref-type="sec">1</xref>,<xref ref-type="fn" rid="Fn3">3</xref> even though selection cues&#x000a0;and response feature belonged to the same object. This demonstrates that the dependency between co-occurring features observed in Experiment <xref rid="Sec2" ref-type="sec">1</xref> was not a result of the need to realign the focus of attention between two different objects. Interestingly, the nature of the selection cue did not systematically affect reports. For example, when participants were searching for the first digit, they still reported the post-target digit identity on 41.7% of the trials, which suggests that the selection feature does not automatically receive priority in encoding. This is in line with our own recent diachronic account (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR28">2022a</xref>), which does not assume that selection features have a special status in encoding. Furthermore, the findings from Experiment <xref rid="Sec2" ref-type="sec">1</xref> were replicated even though target set sizes were equalized for colour and identity. Thus, the asymmetry between identity and colour reports likely reflect differences in processing speed (Wolfe, <xref ref-type="bibr" rid="CR24">2014</xref>).</p></sec></sec><sec id="Sec24"><title>General discussion</title><p id="Par38">Binding is a fundamental process that allows objects to be perceived as coherent events, rather than disparate features. Although it is generally believed that attention plays a crucial role in binding (Kovacs &#x00026; Harris, <xref ref-type="bibr" rid="CR11">2019</xref>; Treisman &#x00026; Schmidt, <xref ref-type="bibr" rid="CR21">1982</xref>), findings by Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>) have suggested that this is not the case, for binding both in space and in time. In the two experiments presented here, we re-assessed their provocative conclusion for the case of feature binding in the temporal domain. We used procedures similar to Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>), with some modifications to the methods and analysis.</p><p id="Par39">Participants had to detect a target and report both its colour and identity. Results consistently showed that the co-occurrence of features increased the probability of their binding into a single object. When participants erroneously reported the identity of a distractor, they were also more likely to report the same distractor&#x02019;s colour. This association was substantially strengthened when individual differences and trial-by-trial variability were accounted for. Together with our previous observation that intrusion errors are associated with a delayed onset of the attentional episode (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR27">2021</xref>), these findings show that the timing of attentional engagement affects all features presented in that point in space and time. When engagement is fast, there is a high likelihood that the processing of all target features will be sufficiently enhanced to be encoded together (Fig. <xref rid="Fig6" ref-type="fig">6</xref>A). When engagement is slow, features from the distractor object following the target will be encoded instead (Fig. <xref rid="Fig6" ref-type="fig">6</xref>B). This conclusion is further supported by the observation that intrusions were strongly affected by the type of selection cue being employed. In Experiment <xref rid="Sec14" ref-type="sec">2</xref>, intrusions were lower in the first-colour task than in the first-digit task, plausibly because colours were detected more quickly, making the colour-defined target less vulnerable to masking. Likewise, the probability of post-target intrusions in Experiment <xref rid="Sec2" ref-type="sec">1</xref> was lower than in Experiment <xref rid="Sec14" ref-type="sec">2</xref>, plausibly because, on average, the onset selection cue was detected more rapidly. Interestingly, dependency between co-occurring features was also lower in Experiment <xref rid="Sec2" ref-type="sec">1</xref>. It is possible that when attentional cues are highly salient, attentional episodes are not just triggered faster but are also less variable in their timing, thereby limiting the potential for detecting shared variance between features. Given the other differences between the two experiments (see footnote 3), this possibility remains speculative, but points to potential new avenues of research about the relationship between the timing of attention and feature binding. In any case, in contrast to the probabilistic independent feature sampling account proposed by Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>), we conclude that attentional mechanisms, and in particular the temporal dynamics of spatial attention, have a direct impact on the process of combining features from different dimension. They do so by making it more likely that co-occurring features will be perceived to belong to the same object.<fig id="Fig6"><label>Fig. 6</label><caption><p>Illustration of factors that determine temporal feature binding in the diachronic account on hypothetical trials. In this example, the selection feature is a circle, the target is a red &#x0201c;F&#x0201d;, and the post-target distractor is a green &#x0201c;8&#x0201d;. The x-axis in each panel represents time in milliseconds from the moment signals from the target reach the visual cortex. Evidence about each feature (colour and identity) is accumulated separately and continuously modulated by spatially-specific attentional enhancement. In addition, sensory representations mutually inhibit one another. Once the target is detected, it triggers an attentional episode. When this attentional episode is triggered early (<bold>A</bold>), it is more likely that both the target&#x02019;s features will be sufficiently strong to cross the encoding threshold and be encoded. When the attentional episode is substantially delayed (<bold>B</bold>), there is a higher likelihood that both of the post-target&#x02019;s features will be encoded instead. However, high perceptual noise in one feature (<bold>C</bold>) or different rates of evidence accumulation due to different processing speed (<bold>D</bold>) can result in temporal misbinding where the perceived object is comprised of two features from two different objects</p></caption><graphic xlink:href="13423_2024_2493_Fig6_HTML" id="MO6"/></fig></p><p id="Par40">While co-occurrence plays an important role in temporal binding, it is not always sufficient to guarantee correct binding. In the current study, participants often reported the target colour or identity alongside the identity or colour of a temporally proximal distractor. This shows that while attentional factors facilitate the dependence between co-occurring features, other factors can result in the independent encoding of features from different objects. In our diachronic account (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR28">2022a</xref>), perception is described as a process of evidence accumulation that is modulated by attention, particularly during attentional episodes. As a result, some features (usually those that benefitted from attentional modulation) reach the threshold required for encoding. However, evidence accumulation is also affected by attention-unrelated factors. One of these relates to feature-specific variations in perceptual noise (Ashby &#x00026; Lee, <xref ref-type="bibr" rid="CR3">1993</xref>), which can affect evidence accumulation, allowing for features from other objects to &#x0201c;win the race&#x0201d; for encoding (Fig. <xref rid="Fig6" ref-type="fig">6</xref>C). This view is compatible with the finding that averaging responses across individual trials resulted in much larger effect sizes, as averaging reduces the effect of perceptual noise and better reflects the central tendency of the real effect for each participant.</p><p id="Par41">Binding errors can also occur when different features are processed at different speeds. In this case, the feature that is processed more slowly is more vulnerable to intrusions, resulting in more errors on this dimension (Fig. <xref rid="Fig6" ref-type="fig">6</xref>D). In the current experiments, this was illustrated by the asymmetry between colour and identity reports. In both experiments, target colour/distractor identity reports were more frequent than target identity/distractor colour reports (Experiment <xref rid="Sec2" ref-type="sec">1</xref>: <italic>M</italic> = 21.1% vs. <italic>M</italic> = 11.8%; Experiment <xref rid="Sec14" ref-type="sec">2</xref> first-colour task: <italic>M</italic> = 18.8% vs. <italic>M</italic> = 8.6%; Experiment <xref rid="Sec14" ref-type="sec">2</xref> first-digit task: <italic>M</italic> = 15.7% vs. <italic>M</italic> = 10.6%, all <italic>p</italic>s &#x0003c; .001). Finally, while fast attentional engagement is likely to result in correct reports and delayed engagement in reports of the post-target distractor object, intermediate speeds of attentional engagement could result in an encoding of multiple features from different objects (Vul et al., <xref ref-type="bibr" rid="CR23">2009</xref>), at the expense of precise temporal information (Aky&#x000fc;rek &#x00026; Wolff, <xref ref-type="bibr" rid="CR1">2016</xref>; Aky&#x000fc;rek et al., <xref ref-type="bibr" rid="CR2">2012</xref>). In such cases, perceptual decisions may indeed follow a probabilistic distribution, as suggested by Vul and Rich (<xref ref-type="bibr" rid="CR22">2010</xref>), and these should be associated with substantially reduced confidence (Recht et al., <xref ref-type="bibr" rid="CR15">2019</xref>) relative to trials where only a single object is encoded.</p><p id="Par42">In contrast to most previous work on the role of attention in object binding, which were focused on spatial factors (e.g., Treisman &#x00026; Schmidt, <xref ref-type="bibr" rid="CR21">1982</xref>), the current study investigated temporal binding. It is important to note that attention is likely to operate differently in these two dimensions, due to the way that space and time are processed in the visual system. Because the visual cortex is retinotopically organised, interference from equidistant distractors will be similar regardless of their spatial position relative to the target (Klein et al., <xref ref-type="bibr" rid="CR10">2023</xref>). In contrast, time perception is an inferred property based on processing of multiple events (e.g., Block &#x00026; Gruber, <xref ref-type="bibr" rid="CR4">2014</xref>), and the effects of temporal proximity on binding are asymmetrical, with generally larger interference by stimuli that follow the target relative to preceding objects (e.g., Botella et al., <xref ref-type="bibr" rid="CR6">2001</xref>; Klein et al., <xref ref-type="bibr" rid="CR10">2023</xref>). This asymmetry is easily explained by the diachronic account, as attentional episodes are only triggered once sufficient evidence for the presence of a potential target has accumulated. By that time, representations of previous stimuli may already have faded or been overridden by the target object. This implies that manipulations that delay attentional engagement should result in more post-target distractor intrusions, while manipulations that speed up engagement should result in better accuracy but no increase of pre-target intrusions (as has indeed been found; Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR30">2023</xref>).</p><p id="Par43">Given these differences, prior observations regarding binding in space do not necessarily apply to the role of attention in temporal binding. This underlines the need for additional research in this field, which needs to address several unanswered questions. For example, the robust individual differences observed here go beyond previous studies (e.g., Martens et al., <xref ref-type="bibr" rid="CR12">2006</xref>) to reveal undocumented variability in the speed of attentional engagement. This variability may produce important differences in real-world behaviour that depends on temporal selectivity, such as driving or reading. It also presents a challenge to models of temporal selectivity that view such differences as statistical noise. Finally, the current investigation highlights the importance of a diachronic perspective (e.g., Reeves &#x00026; Sperling, <xref ref-type="bibr" rid="CR16">1986</xref>; Wyble et al., <xref ref-type="bibr" rid="CR26">2011</xref>). Standard models of attention view attentional selection as a temporally discrete all-or-none process that neatly divides processing to a &#x0201c;pre-attentive&#x0201d; stage and an &#x0201c;attentive&#x0201d; stage (Neisser, <xref ref-type="bibr" rid="CR13">1967</xref>). The diachronic view eliminates this division (Zivony &#x00026; Eimer, <xref ref-type="bibr" rid="CR28">2022a</xref>), as it describes selective attention as emerging from multiple processes that modulate visual perception gradually and continuously in real time. Such a perspective is critical to understanding temporal binding errors, which cannot be adequately accounted for with standard attention accounts. Further research into temporal binding can thus benefit cognitive research more generally as this line of inquiry can challenge long-held assumptions about the functional and temporal organisation of attentional mechanisms in vision.</p></sec></body><back><fn-group><fn id="Fn1"><label>1</label><p id="Par44">We thank Julie Golomb for suggesting this analysis.</p></fn><fn id="Fn2"><label>2</label><p id="Par45">In both experiments, all effects reported below were also reliable when identity APIs were entered as the dependent variable with colour report as the independent variable.</p></fn><fn id="Fn3"><label>3</label><p id="Par46">We note that both the trial-by-trial and between-participants correlations were substantially larger in Experiment <xref rid="Sec14" ref-type="sec">2</xref> than the equivalent correlations in Experiment <xref rid="Sec2" ref-type="sec">1</xref> (<italic>r</italic> = .29-30 vs. <italic>r</italic> = .13 and <italic>r</italic> = .88-89 vs. <italic>r</italic> = .58, respectively). Among the possible reasons for this discrepancy are the reduced set size for target colours and identities, the change in task instructions, the increase in the number of trials, the fact that pre-target distractors were always response-irrelevant, or the fact that this experiment was run in the lab rather than online. Any of these factors may have increased reliability of Experiment <xref rid="Sec14" ref-type="sec">2</xref> and/or strengthened the dependency between co-occurring features relative to Experiment <xref rid="Sec2" ref-type="sec">1</xref>.</p></fn><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p><bold>Open practices statement</bold></p><p>The data for both experiments are posted at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.24250975">https://doi.org/10.6084/m9.figshare.24250975</ext-link>.</p></fn></fn-group><ack><title>Acknowledgements</title><p>Both authors (A.Z. and M.E.) were responsible for the conceptualization, experiment design, and writing. A.Z. programmed the experiments, collected the data, conducted the statistical analyses, and wrote the original draft. For the purpose of open access, the authors have applied a creative commons attribution (CC BY) licence to any author-accepted manuscript version arising. This project has received funding from the European Union&#x02019;s Horizon 2020 research and innovation programme under Grant Agreement No. 896192 to Alon Zivony and from ESRC Grant No. ES/V002708/1 to Martin Eimer.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Aky&#x000fc;rek</surname><given-names>EG</given-names></name><name><surname>Wolff</surname><given-names>MJ</given-names></name></person-group><article-title>Extended temporal integration in rapid serial visual presentation: Attentional control at Lag 1 and beyond</article-title><source>Acta Psychologica</source><year>2016</year><volume>168</volume><fpage>50</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.actpsy.2016.04.009</pub-id><pub-id pub-id-type="pmid">27155801</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Aky&#x000fc;rek, E. G., &#x00026; Wolff, M. J. (2016). Extended temporal integration in rapid serial visual presentation: Attentional control at Lag 1 and beyond. <italic>Acta Psychologica,</italic><italic>168</italic>, 50&#x02013;64.<pub-id pub-id-type="pmid">27155801</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Aky&#x000fc;rek</surname><given-names>EG</given-names></name><name><surname>Eshuis</surname><given-names>SA</given-names></name><name><surname>Nieuwenstein</surname><given-names>MR</given-names></name><name><surname>Saija</surname><given-names>JD</given-names></name><name><surname>Ba&#x0015f;kent</surname><given-names>D</given-names></name><name><surname>Hommel</surname><given-names>B</given-names></name></person-group><article-title>Temporal target integration underlies performance at Lag 1 in the attentional blink</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2012</year><volume>38</volume><issue>6</issue><fpage>1448</fpage><lpage>1464</lpage><pub-id pub-id-type="pmid">22428668</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Aky&#x000fc;rek, E. G., Eshuis, S. A., Nieuwenstein, M. R., Saija, J. D., Ba&#x0015f;kent, D., &#x00026; Hommel, B. (2012). Temporal target integration underlies performance at Lag 1 in the attentional blink. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>38</italic>(6), 1448&#x02013;1464.<pub-id pub-id-type="pmid">22428668</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><mixed-citation publication-type="other">Ashby, F. G., &#x00026; Lee, W. W. (1993). Perceptual variability as a fundamental axiom of perceptual science. In <italic>Advances in psychology</italic> (Vol. 99, pp. 369&#x02013;399). North-Holland.</mixed-citation></ref><ref id="CR4"><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Block</surname><given-names>RA</given-names></name><name><surname>Gruber</surname><given-names>RP</given-names></name></person-group><article-title>Time perception, attention, and memory: A selective review</article-title><source>Acta Psychologica</source><year>2014</year><volume>149</volume><fpage>129</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/j.actpsy.2013.11.003</pub-id><pub-id pub-id-type="pmid">24365036</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Block, R. A., &#x00026; Gruber, R. P. (2014). Time perception, attention, and memory: A selective review. <italic>Acta Psychologica,</italic><italic>149</italic>, 129&#x02013;133.<pub-id pub-id-type="pmid">24365036</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Botella</surname><given-names>J</given-names></name><name><surname>Garcia</surname><given-names>ML</given-names></name><name><surname>Barriopedro</surname><given-names>M</given-names></name></person-group><article-title>Intrusion patterns in rapid serial visual presentation tasks with two response dimensions</article-title><source>Perception &#x00026; Psychophysics</source><year>1992</year><volume>52</volume><fpage>547</fpage><lpage>552</lpage><pub-id pub-id-type="doi">10.3758/BF03206716</pub-id><pub-id pub-id-type="pmid">1437487</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Botella, J., Garcia, M. L., &#x00026; Barriopedro, M. (1992). Intrusion patterns in rapid serial visual presentation tasks with two response dimensions. <italic>Perception &#x00026; Psychophysics,</italic><italic>52</italic>, 547&#x02013;552.<pub-id pub-id-type="pmid">1437487</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Botella</surname><given-names>J</given-names></name><name><surname>Suero</surname><given-names>M</given-names></name><name><surname>Barriopedro</surname><given-names>MI</given-names></name></person-group><article-title>A model of the formation of illusory conjunctions in the time domain</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><year>2001</year><volume>27</volume><fpage>1452</fpage><lpage>1467</lpage><pub-id pub-id-type="pmid">11766936</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Botella, J., Suero, M., &#x00026; Barriopedro, M. I. (2001). A model of the formation of illusory conjunctions in the time domain. <italic>Journal of Experimental Psychology: Human Perception and Performance,</italic><italic>27</italic>, 1452&#x02013;1467.<pub-id pub-id-type="pmid">11766936</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>H</given-names></name><name><surname>Wyble</surname><given-names>B</given-names></name></person-group><article-title>The simultaneous type, serial token model of temporal attention and working memory</article-title><source>Psychological review</source><year>2007</year><volume>114</volume><issue>1</issue><fpage>38</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.1.38</pub-id><pub-id pub-id-type="pmid">17227181</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Bowman, H., &#x00026; Wyble, B. (2007). The simultaneous type, serial token model of temporal attention and working memory. <italic>Psychological review,</italic><italic>114</italic>(1), 38&#x02013;70.<pub-id pub-id-type="pmid">17227181</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Dowd</surname><given-names>EW</given-names></name><name><surname>Golomb</surname><given-names>JD</given-names></name></person-group><article-title>Object-feature binding survives dynamic shifts of spatial attention</article-title><source>Psychological science</source><year>2019</year><volume>30</volume><issue>3</issue><fpage>343</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1177/0956797618818481</pub-id><pub-id pub-id-type="pmid">30694718</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Dowd, E. W., &#x00026; Golomb, J. D. (2019). Object-feature binding survives dynamic shifts of spatial attention. <italic>Psychological science,</italic><italic>30</italic>(3), 343&#x02013;361.<pub-id pub-id-type="pmid">30694718</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><mixed-citation publication-type="other">Faul, F., Erdfelder, E., Buchner, A., &#x00026; Lang, A. G. (2013). <italic>G*Power (Version 3.1.7) [Computer software]</italic>. University of Kiel.</mixed-citation></ref><ref id="CR10"><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>RM</given-names></name><name><surname>Ishigami</surname><given-names>Y</given-names></name><name><surname>Murray</surname><given-names>NE</given-names></name></person-group><article-title>Slippage of the attentional beam when searching in space and in time</article-title><source>Cognition</source><year>2023</year><volume>241</volume><fpage>105610</fpage><pub-id pub-id-type="doi">10.1016/j.cognition.2023.105610</pub-id><pub-id pub-id-type="pmid">37778283</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Klein, R. M., Ishigami, Y., &#x00026; Murray, N. E. (2023). Slippage of the attentional beam when searching in space and in time. <italic>Cognition,</italic><italic>241</italic>, 105610.<pub-id pub-id-type="pmid">37778283</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Kovacs</surname><given-names>O</given-names></name><name><surname>Harris</surname><given-names>IM</given-names></name></person-group><article-title>The role of location in visual feature binding</article-title><source>Attention, Perception, &#x00026; Psychophysics</source><year>2019</year><volume>81</volume><fpage>1551</fpage><lpage>1563</lpage><pub-id pub-id-type="doi">10.3758/s13414-018-01638-8</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Kovacs, O., &#x00026; Harris, I. M. (2019). The role of location in visual feature binding. <italic>Attention, Perception, &#x00026; Psychophysics,</italic><italic>81</italic>, 1551&#x02013;1563.</mixed-citation></citation-alternatives></ref><ref id="CR12"><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Martens</surname><given-names>S</given-names></name><name><surname>Munneke</surname><given-names>J</given-names></name><name><surname>Smid</surname><given-names>H</given-names></name><name><surname>Johnson</surname><given-names>A</given-names></name></person-group><article-title>Quick minds don't blink: Electrophysiological correlates of individual differences in attentional selection</article-title><source>Journal of cognitive neuroscience</source><year>2006</year><volume>18</volume><issue>9</issue><fpage>1423</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1162/jocn.2006.18.9.1423</pub-id><pub-id pub-id-type="pmid">16989545</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Martens, S., Munneke, J., Smid, H., &#x00026; Johnson, A. (2006). Quick minds don&#x02019;t blink: Electrophysiological correlates of individual differences in attentional selection. <italic>Journal of cognitive neuroscience,</italic><italic>18</italic>(9), 1423&#x02013;1438.<pub-id pub-id-type="pmid">16989545</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><citation-alternatives><element-citation id="ec-CR13" publication-type="book"><person-group person-group-type="author"><name><surname>Neisser</surname><given-names>U</given-names></name></person-group><source>Cognitive psychology</source><year>1967</year><publisher-name>Appleton-Century-Crofts</publisher-name></element-citation><mixed-citation id="mc-CR13" publication-type="book">Neisser, U. (1967). <italic>Cognitive psychology</italic>. Appleton-Century-Crofts.</mixed-citation></citation-alternatives></ref><ref id="CR14"><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Olivers</surname><given-names>CN</given-names></name><name><surname>Meeter</surname><given-names>M</given-names></name></person-group><article-title>A boost and bounce theory of temporal attention</article-title><source>Psychological review</source><year>2008</year><volume>115</volume><issue>4</issue><fpage>836</fpage><lpage>863</lpage><pub-id pub-id-type="doi">10.1037/a0013395</pub-id><pub-id pub-id-type="pmid">18954206</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Olivers, C. N., &#x00026; Meeter, M. (2008). A boost and bounce theory of temporal attention. <italic>Psychological review,</italic><italic>115</italic>(4), 836&#x02013;863.<pub-id pub-id-type="pmid">18954206</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Recht</surname><given-names>S</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name></person-group><article-title>Temporal attention causes systematic biases in visual confidence</article-title><source>Scientific reports</source><year>2019</year><volume>9</volume><issue>1</issue><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/s41598-019-48063-x</pub-id><pub-id pub-id-type="pmid">30626917</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Recht, S., Mamassian, P., &#x00026; de Gardelle, V. (2019). Temporal attention causes systematic biases in visual confidence. <italic>Scientific reports,</italic><italic>9</italic>(1), 1&#x02013;9.<pub-id pub-id-type="pmid">30626917</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Reeves</surname><given-names>A</given-names></name><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><article-title>Attention gating in short-term visual memory</article-title><source>Psychological Review</source><year>1986</year><volume>93</volume><issue>2</issue><fpage>180</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.93.2.180</pub-id><pub-id pub-id-type="pmid">3714927</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Reeves, A., &#x00026; Sperling, G. (1986). Attention gating in short-term visual memory. <italic>Psychological Review,</italic><italic>93</italic>(2), 180&#x02013;206.<pub-id pub-id-type="pmid">3714927</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Shih</surname><given-names>SI</given-names></name></person-group><article-title>The attention cascade model and attentional blink</article-title><source>Cognitive Psychology</source><year>2008</year><volume>56</volume><issue>3</issue><fpage>210</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2007.06.001</pub-id><pub-id pub-id-type="pmid">17624321</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Shih, S. I. (2008). The attention cascade model and attentional blink. <italic>Cognitive Psychology,</italic><italic>56</italic>(3), 210&#x02013;236.<pub-id pub-id-type="pmid">17624321</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Sperling</surname><given-names>G</given-names></name><name><surname>Weichselgartner</surname><given-names>E</given-names></name></person-group><article-title>Episodic theory of the dynamics of spatial attention</article-title><source>Psychological Review</source><year>1995</year><volume>102</volume><issue>3</issue><fpage>503</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.503</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Sperling, G., &#x00026; Weichselgartner, E. (1995). Episodic theory of the dynamics of spatial attention. <italic>Psychological Review,</italic><italic>102</italic>(3), 503&#x02013;32.</mixed-citation></citation-alternatives></ref><ref id="CR19"><mixed-citation publication-type="other">Treisman, A. (2014). The psychological reality of levels of processing. <italic>Levels of processing in human memory</italic>, 301&#x02013;330.</mixed-citation></ref><ref id="CR20"><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>AM</given-names></name><name><surname>Gelade</surname><given-names>G</given-names></name></person-group><article-title>A feature-integration theory of attention</article-title><source>Cognitive psychology</source><year>1980</year><volume>12</volume><issue>1</issue><fpage>97</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(80)90005-5</pub-id><pub-id pub-id-type="pmid">7351125</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Treisman, A. M., &#x00026; Gelade, G. (1980). A feature-integration theory of attention. <italic>Cognitive psychology,</italic><italic>12</italic>(1), 97&#x02013;136.<pub-id pub-id-type="pmid">7351125</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>A</given-names></name><name><surname>Schmidt</surname><given-names>H</given-names></name></person-group><article-title>Illusory conjunctions in the perception of objects</article-title><source>Cognitive psychology</source><year>1982</year><volume>14</volume><issue>1</issue><fpage>107</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/0010-0285(82)90006-8</pub-id><pub-id pub-id-type="pmid">7053925</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Treisman, A., &#x00026; Schmidt, H. (1982). Illusory conjunctions in the perception of objects. <italic>Cognitive psychology,</italic><italic>14</italic>(1), 107&#x02013;141.<pub-id pub-id-type="pmid">7053925</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Vul</surname><given-names>E</given-names></name><name><surname>Rich</surname><given-names>AN</given-names></name></person-group><article-title>Independent sampling of features enables conscious perception of bound objects</article-title><source>Psychological Science</source><year>2010</year><volume>21</volume><issue>8</issue><fpage>1168</fpage><lpage>1175</lpage><pub-id pub-id-type="doi">10.1177/0956797610377341</pub-id><pub-id pub-id-type="pmid">20631320</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Vul, E., &#x00026; Rich, A. N. (2010). Independent sampling of features enables conscious perception of bound objects. <italic>Psychological Science,</italic><italic>21</italic>(8), 1168&#x02013;1175.<pub-id pub-id-type="pmid">20631320</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Vul</surname><given-names>E</given-names></name><name><surname>Hanus</surname><given-names>D</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>Attention as inference: Selection is probabilistic; responses are all-or-none samples</article-title><source>Journal of Experimental Psychology: General</source><year>2009</year><volume>138</volume><fpage>546</fpage><lpage>560</lpage><pub-id pub-id-type="doi">10.1037/a0017352</pub-id><pub-id pub-id-type="pmid">19883136</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Vul, E., Hanus, D., &#x00026; Kanwisher, N. (2009). Attention as inference: Selection is probabilistic; responses are all-or-none samples. <italic>Journal of Experimental Psychology: General,</italic><italic>138</italic>, 546&#x02013;560.<pub-id pub-id-type="pmid">19883136</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><mixed-citation publication-type="other">Wolfe, J. M. (2014). Approaches to visual search: Feature integration theory and guided search. <italic>The Oxford handbook of attention</italic>, <italic>11</italic>, 35&#x02013;44.</mixed-citation></ref><ref id="CR25"><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname><given-names>JM</given-names></name><name><surname>Cave</surname><given-names>KR</given-names></name></person-group><article-title>The psychophysical evidence for a binding problem in human vision</article-title><source>Neuron</source><year>1999</year><volume>24</volume><issue>1</issue><fpage>11</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80818-1</pub-id><pub-id pub-id-type="pmid">10677023</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Wolfe, J. M., &#x00026; Cave, K. R. (1999). The psychophysical evidence for a binding problem in human vision. <italic>Neuron,</italic><italic>24</italic>(1), 11&#x02013;17.<pub-id pub-id-type="pmid">10677023</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Wyble</surname><given-names>B</given-names></name><name><surname>Potter</surname><given-names>MC</given-names></name><name><surname>Bowman</surname><given-names>H</given-names></name><name><surname>Nieuwenstein</surname><given-names>M</given-names></name></person-group><article-title>Attentional episodes in visual perception</article-title><source>Journal of Experimental Psychology: General</source><year>2011</year><volume>140</volume><issue>3</issue><fpage>488</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1037/a0023612</pub-id><pub-id pub-id-type="pmid">21604913</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Wyble, B., Potter, M. C., Bowman, H., &#x00026; Nieuwenstein, M. (2011). Attentional episodes in visual perception. <italic>Journal of Experimental Psychology: General,</italic><italic>140</italic>(3), 488&#x02013;505.<pub-id pub-id-type="pmid">21604913</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Zivony</surname><given-names>A</given-names></name><name><surname>Eimer</surname><given-names>M</given-names></name></person-group><article-title>Distractor intrusions are the result of delayed attentional engagement: A new temporal variability account of attentional selectivity in dynamic visual tasks</article-title><source>Journal of Experimental Psychology: General</source><year>2021</year><volume>150</volume><issue>1</issue><fpage>23</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1037/xge0000789</pub-id><pub-id pub-id-type="pmid">32700923</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">Zivony, A., &#x00026; Eimer, M. (2021). Distractor intrusions are the result of delayed attentional engagement: A new temporal variability account of attentional selectivity in dynamic visual tasks. <italic>Journal of Experimental Psychology: General,</italic><italic>150</italic>(1), 23&#x02013;41.<pub-id pub-id-type="pmid">32700923</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Zivony</surname><given-names>A</given-names></name><name><surname>Eimer</surname><given-names>M</given-names></name></person-group><article-title>The diachronic account of attentional selectivity</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2022</year><volume>29</volume><issue>4</issue><fpage>1118</fpage><lpage>1142</lpage><pub-id pub-id-type="doi">10.3758/s13423-021-02023-7</pub-id><pub-id pub-id-type="pmid">34918282</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">Zivony, A., &#x00026; Eimer, M. (2022a). The diachronic account of attentional selectivity. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>29</italic>(4), 1118&#x02013;1142.<pub-id pub-id-type="pmid">34918282</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name><surname>Zivony</surname><given-names>A</given-names></name><name><surname>Eimer</surname><given-names>M</given-names></name></person-group><article-title>Expectation-based blindness: Predictions about object categories gate awareness of focally attended objects</article-title><source>Psychonomic Bulletin &#x00026; Review</source><year>2022</year><volume>29</volume><fpage>1879</fpage><lpage>1889</lpage><pub-id pub-id-type="doi">10.3758/s13423-022-02116-x</pub-id><pub-id pub-id-type="pmid">35581491</pub-id>
</element-citation><mixed-citation id="mc-CR29" publication-type="journal">Zivony, A., &#x00026; Eimer, M. (2022b). Expectation-based blindness: Predictions about object categories gate awareness of focally attended objects. <italic>Psychonomic Bulletin &#x00026; Review,</italic><italic>29</italic>, 1879&#x02013;1889.<pub-id pub-id-type="pmid">35581491</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR30"><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Zivony</surname><given-names>A</given-names></name><name><surname>Eimer</surname><given-names>M</given-names></name></person-group><article-title>The temporal dynamics of selective attention are reflected by distractor intrusions</article-title><source>Scientific Reports</source><year>2023</year><volume>13</volume><issue>408</issue><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="pmid">36593249</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Zivony, A., &#x00026; Eimer, M. (2023). The temporal dynamics of selective attention are reflected by distractor intrusions. <italic>Scientific Reports,</italic><italic>13</italic>(408), 1&#x02013;11.<pub-id pub-id-type="pmid">36593249</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>