<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">World J Urol</journal-id><journal-id journal-id-type="iso-abbrev">World J Urol</journal-id><journal-title-group><journal-title>World Journal of Urology</journal-title></journal-title-group><issn pub-type="ppub">0724-4983</issn><issn pub-type="epub">1433-8726</issn><publisher><publisher-name>Springer Berlin Heidelberg</publisher-name><publisher-loc>Berlin/Heidelberg</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39729119</article-id><article-id pub-id-type="pmc">PMC11680670</article-id>
<article-id pub-id-type="publisher-id">5399</article-id><article-id pub-id-type="doi">10.1007/s00345-024-05399-y</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Physician vs. AI-generated messages in urology: evaluation of accuracy, completeness, and preference by patients and physicians</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6334-3540</contrib-id><name><surname>Robinson</surname><given-names>Eric J.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Qiu</surname><given-names>Chunyuan</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Sands</surname><given-names>Stuart</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Khan</surname><given-names>Mohammad</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Vora</surname><given-names>Shivang</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Oshima</surname><given-names>Kenichiro</given-names></name><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Nguyen</surname><given-names>Khang</given-names></name><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><name><surname>DiFronzo</surname><given-names>L. Andrew</given-names></name><xref ref-type="aff" rid="Aff8">8</xref></contrib><contrib contrib-type="author"><name><surname>Rhew</surname><given-names>David</given-names></name><xref ref-type="aff" rid="Aff9">9</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Feng</surname><given-names>Mark I.</given-names></name><address><email>mark.i.feng@kp.org</email></address><xref ref-type="aff" rid="Aff10">10</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t60zh31</institution-id><institution-id institution-id-type="GRID">grid.280062.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9957 7758</institution-id><institution>Department of Urology, Los Angeles Medical Center, </institution><institution>Kaiser Permanente, </institution></institution-wrap>Los Angeles, CA USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t60zh31</institution-id><institution-id institution-id-type="GRID">grid.280062.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9957 7758</institution-id><institution>Department of Anesthesiology, Baldwin Park Medical Center, </institution><institution>Kaiser Permanente, </institution></institution-wrap>Baldwin Park, CA USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t60zh31</institution-id><institution-id institution-id-type="GRID">grid.280062.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9957 7758</institution-id><institution>Kaiser Permanente, </institution></institution-wrap>Pleasanton, CA USA </aff><aff id="Aff4"><label>4</label>Microsoft Health &#x00026; Life Sciences, Irvine, CA USA </aff><aff id="Aff5"><label>5</label>Microsoft Health &#x00026; Life Sciences, Dallas, TX USA </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t60zh31</institution-id><institution-id institution-id-type="GRID">grid.280062.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9957 7758</institution-id><institution>Kaiser Permanente, </institution></institution-wrap>Oakland, CA USA </aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t60zh31</institution-id><institution-id institution-id-type="GRID">grid.280062.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9957 7758</institution-id><institution>Department of Family Medicine, </institution><institution>Kaiser Permanente, </institution></institution-wrap>Pasadena, CA USA </aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t60zh31</institution-id><institution-id institution-id-type="GRID">grid.280062.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9957 7758</institution-id><institution>Kaiser Permanente, </institution></institution-wrap>Pasadena, CA USA </aff><aff id="Aff9"><label>9</label>Microsoft Health &#x00026; Life Sciences, Redmond, WA USA </aff><aff id="Aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00t60zh31</institution-id><institution-id institution-id-type="GRID">grid.280062.e</institution-id><institution-id institution-id-type="ISNI">0000 0000 9957 7758</institution-id><institution>Department of Urology, Baldwin Park Medical Center, </institution><institution>Kaiser Permanente, </institution></institution-wrap>1011 Baldwin Park Blvd., Baldwin Park, CA 91706 USA </aff></contrib-group><pub-date pub-type="epub"><day>27</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>27</day><month>12</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2025</year></pub-date><volume>43</volume><issue>1</issue><elocation-id>48</elocation-id><history><date date-type="received"><day>8</day><month>10</month><year>2024</year></date><date date-type="accepted"><day>27</day><month>11</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Purpose</title><p id="Par1">To evaluate the accuracy, comprehensiveness, empathetic tone, and patient preference for AI and urologist responses to patient messages concerning common BPH questions across phases of care.</p></sec><sec><title>Methods</title><p id="Par2">Cross-sectional study evaluating responses to 20 BPH-related questions generated by 2 AI chatbots and 4 urologists in a simulated clinical messaging environment without direct patient interaction. Accuracy, completeness, and empathetic tone of responses assessed by experts using Likert scales, and preferences and perceptions of authorship (chatbot vs. human) rated by non-medical evaluators.</p></sec><sec><title>Results</title><p id="Par3">Five non-medical volunteers independently evaluated, ranked, and inferred the source for 120 responses (<italic>n</italic>&#x02009;=&#x02009;600 total). For volunteer evaluations, the mean (SD) score of chatbots, 3.0 (1.4) (moderately empathetic) was significantly higher than urologists, 2.1 (1.1) (slightly empathetic) (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001); mean (SD) and preference ranking for chatbots, 2.6 (1.6), was significantly higher than urologist ranking, 3.9 (1.6) (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Two subject matter experts (SMEs) independently evaluated 120 responses each (answers to 20 questions from 4 urologist and 2 chatbots, <italic>n</italic>&#x02009;=&#x02009;240 total). For SME evaluations, mean (SD) accuracy score for chatbots was 4.5 (1.1) (nearly all correct) and not significantly different than urologists, 4.6 (1.2). The mean (SD) completeness score for chatbots was 2.4 (0.8) (comprehensive), significantly higher than urologists, 1.6 (0.6) (adequate) (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p></sec><sec><title>Conclusion</title><p id="Par4">Answers to patient BPH messages generated by chatbots were evaluated by experts as equally accurate and more complete than urologist answers. Non-medical volunteers preferred chatbot-generated messages and considered them more empathetic compared to answers generated by urologists.</p></sec><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1007/s00345-024-05399-y.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Artificial intelligence (AI)</kwd><kwd>Large language models (LLMs)</kwd><kwd>Benign prostatic hyperplasia (BPH)</kwd><kwd>Patient communication</kwd><kwd>Patient messages</kwd><kwd>Sandbox</kwd><kwd>ChatGPT</kwd><kwd>Chatbot</kwd><kwd>Care experience</kwd><kwd>Physician experience</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer-Verlag GmbH Germany, part of Springer Nature 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par5">There is growing integration of artificial intelligence (AI) into healthcare, particularly with Large Language Models (LLMs). LLMs leverage self-supervised learning to acquire knowledge from extensive unannotated datasets [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Chatbots, implementations of LLMs defined as an AI software capable of engaging in conversational exchanges, are increasingly considered as tools for improving physician-patient communication [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]. A clinically applicable chatbot can serve physicians and patients through real-time actionable information exchanges and delivering on physician objectives for quality and personalized care.</p><p id="Par6">ChatGPT, a widely popular chatbot with broad training on internet sources including medical books and articles, has demonstrated an ability to discuss and answer medical questions with a high degree of complexity and clarity [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>]. The availability and usability of ChatGPT make it a popular consult for patients seeking information on healthcare symptomatology and treatment, and patients are trending toward using chatbots more than online search engines [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. However, in clinical practice, the use of individualized data outside of a hospital&#x02019;s technical ecosystem creates ethical and legal liabilities as LLMs store and train on input data, exposing personal health information (PHI) to systems outside of a healthcare institution&#x02019;s control [<xref ref-type="bibr" rid="CR9">9</xref>]. Integration with any outside system is a security risk, and effective handling of PHI requires development of systems with structural integrity from data storage to access controls.</p><p id="Par7">A &#x0201c;sandbox&#x0201d; environment is a secure testing space used in developing healthcare technology that replicates a healthcare software ecosystem isolated from patient data. Use of sandboxes eliminates the risk of data breaches while allowing robust testing of new technologies. In our study, we established a sandbox environment at a large, integrated health system to ensure secure testing, selecting Benign Prostatic Hyperplasia (BPH) as an initial test topic.</p><p id="Par8">BPH is a common urologic condition well suited for chatbot testing due to its high prevalence and large message volume. Primarily affecting males over 50, BPH involves a relatively focused demographic that serves as an effective test group to study chatbot effectiveness in clinical communications. Due to appropriate precaution surrounding PHI, existing studies assessing the ability of chatbots to answer medical topics have used questions drawn from social media, FAQs on clinic websites, education guidelines, or generated by physicians [<xref ref-type="bibr" rid="CR5">5</xref>&#x02013;<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR10">10</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>]. This approach limits the full range of a chatbot&#x02019;s ability to respond to open-ended, personalized and patient-specific questions. To our knowledge, the use of chatbots in perioperative settings along a patient&#x02019;s entire surgical journey, from preoperative evaluation and consent to postoperative follow up and recovery expectations, has not been studied.</p><p id="Par9">By leveraging a sandbox environment, our study uses the most common real-world patient questions as selected by a nursing messaging management team responsible for triaging hundreds of questions per week. This study&#x02019;s selected questions are open-ended, covering topics across the spectrum of care for a common urologic condition, emulating the complexity and ambiguity that clinicians and patients encounter during the regular course of clinical care. Our study evaluates answers from four board-certified urologists and two chatbots for accuracy, comprehensiveness, tone, and patient preference. By evaluating chatbot performance on a range of common clinical questions, this study provides early evidence for the reliability of chatbots in a real-world clinical setting to generate accurate and complete information in an empathetic manner.</p></sec><sec id="Sec2"><title>Methods</title><p id="Par10">This cross-sectional study was exempt from Institutional Review Board review as no PHI were used. This study adhered to the guidelines set forth by the STROBE statement for observational research reporting [<xref ref-type="bibr" rid="CR14">14</xref>]. Informed consent was not obtained by respondents but was implied by participation in survey response. Respondents and evaluators were not compensated.</p><p id="Par11">Twenty common BPH-related patient questions from phone or EHR-messaging were pooled, anonymized, and compiled by clinic nursing message management team (Supplemental Table 1). A standardized answer key for each of the twenty questions was independently generated by three urologists with subject matter expertise in treating large-volume BPH to serve as a rubric for evaluating accuracy and completeness.</p><p id="Par12">Answers for each question were generated by four urologists and two chatbots. The four urologists were provided a document with the questions and instructed to provide the &#x0201c;best answer possible&#x0201d; as a simulation of answering patient messages. The two chatbots, Kaiser Permanente GPT (KPGPT), a snapshot version of ChatGPT 4.0 LLM (gpt-4-0613), and SurgiChat, the same snapshot of ChatGPT 4.0 with additional Retrieval-Augmented Generation (RAG) based on BPH literature and implemented within a sandbox environment [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>]. RAG redirects LLM processing to retrieve relevant information from authoritative, pre-determined knowledge sources. The sandbox was an environment disconnected from the healthcare institution resources and databases to prevent inclusion of PHI/PII sensitive information, and processing was performed at pre-approved regional data centers restricted to institutional IP addresses.</p><p id="Par13">The chatbots were provided each question individually in a new chat session with the prompt <italic>&#x0201c;Be specific and incorporate any applicable applied sources of information&#x0201d;</italic>.</p><p id="Par14">Answers from urologists and chatbots were organized by question and presented in random order to participants. Some chatbot responses qualified answers as non-professional, for example &#x0201c;Consult a healthcare provider to determine the best course of action.&#x0201d; Such qualifications were truncated from the response during answer compilation to maintain blindness to the answer source. The document was distributed to two urologists with subject matter expertise in BPH (SMEs) and five non-medical volunteers pre-screened to be male, 50 years or older, and with at least a high-school level of education. Volunteers aged 56&#x02013;82 (median 72), three received previous BPH treatment, four had a master&#x02019;s degree and one associate degree, and four were Caucasian, one was Asian. The SMEs and non-medical volunteers were informed they would be participating in evaluating physician and chatbot answers to common patient questions but were not informed of the identity or number of physicians or chatbots providing answers.</p><p id="Par15">The SMEs were asked to grade each question based on their medical expertise and in accordance with the expert-generated answer key for accuracy, completeness, and tone using Likert scales. Accuracy was graded on a 6-point Likert scale (1, completely incorrect; 2, more incorrect than correct; 3, approximately equal correct and incorrect; 4, more correct than incorrect; 5, nearly all correct; 6, completely correct). Completeness was graded on a 3-point Likert scale (1, incomplete; 2, adequate [addresses all aspects of the question and provides the minimum amount of information to be considered complete]; 3, comprehensive). Feature/tone was graded on a 5-point Likert scale (1, not empathetic; 2, slightly empathetic; 3, moderately empathetic; 4, empathetic; 5, very empathetic).</p><p id="Par16">The non-medical volunteers were asked to grade each answer for feature/tone using the same Likert scale, to rank each answer within each question 1&#x02013;6 in terms of their preference for receiving a message (1 the answer they would most prefer to receive, and 6 as the answer they would least prefer to receive), and label the answer as generated by human or chatbot.</p><sec id="Sec3"><title>Statistical analysis</title><p id="Par17">Score results were listed descriptively and were compared between groups using the Pearson&#x02019;s Chi-squared test for evaluating response source and Wilcoxon rank sum test or the Kruskal-Wallis test for Likert scales and preference ranking. A 2-sided <italic>P&#x02009;&#x0003c;</italic>&#x02009;0.05 was considered statistically significant. Interrater agreement between subject matter experts was graded using the weighted &#x003ba; statistic across all scores for eval (R package &#x0201c;irr&#x0201d;; R, version 4.3.1 [The R Project for Statistical Computing]).</p></sec></sec><sec id="Sec4" sec-type="results"><title>Results</title><sec id="Sec5"><title>Subject matter expert analysis</title><p id="Par18">SMEs each evaluated 120 answers from 4 urologists and 2 chatbots responding to 20 questions each including 7 questions on BPH evaluation, 7 questions on BPH operations, and 6 questions on post-operative recovery, for a total of 240 evaluations (160 from urologists, 80 from chatbots) (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). The median scores across all questions were as follows: urologists had a median accuracy of 5.0 (IQR, 4.0&#x02013;5.0), completeness of 2.0 (IQR, 1.0&#x02013;2.0), and a feature/tone of 2.0 (IQR, 2.0&#x02013;3.0); chatbots had a median accuracy of 5.0 (IQR, 4.0&#x02013;6.0), completeness of 3.0 (IQR, 2.0&#x02013;3.0), and feature/tone of 3.0 (IQR, 2.0&#x02013;4.0). Comparatively, chatbot and urologist responses showed no significant difference in accuracy (mean [SD], 4.5 [1.1] vs. 4.6 [1.2], <italic>p</italic>&#x02009;=&#x02009;0.2), but chatbots scored higher in completeness (mean [SD], 2.4 [0.8] vs. 1.6 [0.6], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and feature/tone (mean [SD], 3.2 [1.3] vs. 2.4 [1.0], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Interrater agreement was moderate for accuracy (weighted &#x003ba;&#x02009;=&#x02009;0.18; <italic>P</italic>&#x02009;&#x0003c;&#x02009;0.05) and completeness (weighted &#x003ba;&#x02009;=&#x02009;0.34; <italic>P</italic>&#x02009;&#x0003c;&#x02009;0.001), but low for feature/tone (weighted &#x003ba;&#x02009;=&#x02009;0.04; <italic>P</italic>&#x02009;=&#x02009;0.32).</p><p id="Par19">
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Subject matter expert evaluations</p></caption><graphic position="anchor" xlink:href="345_2024_5399_Tab1_HTML" id="d33e442"/></table-wrap>
</p><p id="Par20">For pre-operative evaluation, chatbots outperformed urologists in accuracy (mean [SD], 5.2 [0.9] vs. 4.4 [1.2], <italic>p</italic>&#x02009;=&#x02009;0.001), completeness (mean [SD], 2.6 [0.6] vs. 1.6 [0.6], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), and feature/tone (mean [SD], 2.9 [1.4] vs. 2.1 [1.0], <italic>p</italic>&#x02009;=&#x02009;0.008) [Supplemental Table 1]. For operative experience, there was no significant difference in accuracy (mean [SD], 4.2 [1.4] vs. 4.8 [1.0], <italic>p</italic>&#x02009;=&#x02009;0.07) or feature/tone (mean [SD], 3.2 [1.2] vs. 2.7 [1.1], <italic>p</italic>&#x02009;=&#x02009;0.14) between chatbots and urologists, but chatbots were significantly better in completeness (mean [SD], 2.4 [0.8] vs. 1.6 [0.6], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). For post-operative experience, no significant difference was found in accuracy (mean [SD], 4.2 [1.1] vs. 4.2 [1.0], <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.9); however, chatbots scored significantly higher in completeness (mean [SD], 2.0 [0.9] vs. 1.5 [0.6], <italic>p</italic>&#x02009;=&#x02009;0.007) and feature/tone (mean [SD], 3.5 [1.2] vs. 2.3 [0.8], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001)</p></sec><sec id="Sec6"><title>Non-medical volunteer analysis</title><p id="Par21">Non-medical volunteers evaluated 120 responses from 4 urologists and 2 chatbots. Volunteer accuracy in identifying the source was 59% (95% CI: 55.3 &#x02212;&#x02009;61.7%), while the expected accuracy of random guessing was 67%. They were not significantly different in identifying chatbot and urologist answers (54% vs. 61%, <italic>p</italic>&#x02009;=&#x02009;0.089). Median scores for chatbots&#x02019; features and tone were higher than for urologists (3.0 [IQR 2.0&#x02013;4.0] vs. 2.0 [IQR 1.0&#x02013;3.0]), as were preference rankings (2.0 [IQR 1.0&#x02013;4.0] vs. 4.0 [IQR 3.0&#x02013;5.0]). Mean scores confirmed these results (feature/tone: 3.0 [1.4] vs. 2.1 [1.1], preference: 2.6 [1.6] vs. 3.9 [1.6], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001 for both) (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). Scores within categories&#x02014;evaluation, operative, and post-operative experiences&#x02014;also favored chatbots, with statistical significance (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.005). Responses that volunteers labeled as human scored higher in feature/tone than those labeled as chatbot (2.7 [1.1] vs. 2.1 [1.4], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), also with a higher preference ranking (3.3 [1.6] vs. 3.8 [1.8], <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) (Supplemental Table 3).</p><p id="Par22">
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Non-medical volunteer evaluations</p></caption><graphic position="anchor" xlink:href="345_2024_5399_Tab2_HTML" id="d33e505"/></table-wrap>
</p></sec></sec><sec id="Sec7" sec-type="discussion"><title>Discussion</title><p id="Par23">In this cross-sectional study, we observed that purpose-trained chatbots and general-purpose chatbots are equally effective in answering patient BPH questions as their expert urologist counterparts. Both chatbots scored better than expert urologists and are preferred by non-medical volunteers when comparing accuracy, completeness, empathy, and readability. Interestingly, non-medical volunteers mistook Chatbot answers for human generated. Furthermore, our purpose-trained chatbot was not better than the general-purpose chatbot in all tested categories.</p><p id="Par24">This study suggests when blinded to authorship, chatbot responses to common BPH questions compared to urologist responses were equally accurate, more complete, more empathetic, and overall preferred by non-medical volunteers. Conversely, this study suggests a negative association with the chatbot label, finding volunteers inferred chatbot authorship for communication they found less desirable and less empathetic.</p><p id="Par25">The use of generative AI in healthcare is growing rapidly, enhancing performance and adoption of the new technology. Our study&#x02019;s finding that chatbot responses are accurate and complete aligns with prior research in surgical fields that chatbots provide well-structured, comprehensive, and accurate answers to patient medical questions [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>]. Chatbot responses in our study maintained high accuracy and coherence with the standardized answer key, with 59% of answers rated a 5/6 or 6/6 accuracy level compared to 53% of urologists. The 9% of chatbot responses with 2/6 accuracy is comparable to the 7% of urologist answers rated 2/6 or lower, and is consistent with ChatGPT accuracy in other studies of general medical messaging [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR19">19</xref>].</p><p id="Par26">Physicians spend significant time on EHR tasks and patient inquiries, and administrative burden is a primary pain point among urologists, with recent research showing chatbots have potential to reduce administrative burnout by answering patient questions [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. Typing long answers is time consuming, and it would take 7&#x02013;8&#x000a0;min to type the median ChatGPT response of 300 words at an average typing speed (40 words per minute) [<xref ref-type="bibr" rid="CR21">21</xref>]. This may account for the discrepancy in comprehensiveness scores where 55% of chatbot responses were &#x0201c;comprehensive&#x0201d; compared to 5% of urologist responses, and 18% of chatbot responses compared to 53% of urologist responses were &#x0201c;incomplete.&#x0201d; The difference in answer length may account for the difference in completeness, as longer chatbot answers involved defining acronyms and providing broader context with detail outside of the specific question, while urologist answers were more specific and direct.</p><p id="Par27">Given higher empathy evaluations, chatbot implementation offers an opportunity to foster connection with patients through active messaging, a factor associated with improved patient outcomes and satisfaction, without tradeoff for increased feelings of burnout [<xref ref-type="bibr" rid="CR22">22</xref>&#x02013;<xref ref-type="bibr" rid="CR24">24</xref>]. Our volunteers associated more empathetic and preferable messages with human authorship, though the preferred messages were often authored by chatbots. This preference aligns with other studies that patients, especially at lower education levels, view AI messages negatively and express higher trust in physicians than AI-generated information [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR25">25</xref>]. Urologists are aware of these perceptions, and a 2024 survey of 456 urologists identified negative patient perception as a primary concern of AI-generated information [<xref ref-type="bibr" rid="CR26">26</xref>]. The concerns around perception and accuracy emphasize the role of urologists as gatekeepers and collaborators in the optimal integration of AI, and the ideal implementation is an active area of research that will individually depend on institutional and regional requirements.</p><p id="Par28">Human processing of messages serves as a guardrail for identifying urgent patient symptoms (e.g. severe hematuria, early sepsis), and the ability of an isolated chatbot to handle such symptoms must be tested, as well as the responsibilities of human oversight in a chatbot-integrated system. Further research and testing of chatbot interactions may cover broader areas of urology, particularly questions with less publicly available information, or areas of higher sensitivity such as erectile dysfunction, or sexually transmitted diseases. ChatGPT has internal guardrails to avoid discussing sensitive or sexual topics, and its consistency in handling sexually explicit questions needs testing. Testing is also required for questions that are irregularly structured (grammatically incorrect, contain multiple incomplete sentences, separate questions or references).</p><sec id="Sec8"><title>Limitations</title><p id="Par29">The participants were limited to five non-medical evaluators with above-average education. Further assessment of patients and chatbot messaging should expand the demographic base to include conditions that affect broader ages, genders, non-English speakers, varying levels of education, and types of urologic conditions. Our study did not assess factors that may influence perception of feature &#x00026; tone or preference, such as patient sentiment or anxiety toward a specific question. There is a positive association between word count with the answer metrics evaluated in this study, but the direct impact of word count was not examined in this study and could be investigated in future research. There was low interrater agreement between SMEs, which may skew the accuracy and completeness findings. Additionally, this study covers a small sample of question prompts that do not perfectly model human speech or text patterns; the questions were limited to a single area of urology that generally pertains to a single gender, contained one or two closely related questions within each prompt, and were written with perfect grammar and spelling. Finally, the summary measures used for evaluation were not validated or pilot tested.</p></sec></sec><sec id="Sec9" sec-type="conclusion"><title>Conclusion</title><p id="Par30">Chatbot responses to common BPH questions when compared to urologist responses were equally accurate, more complete, more empathetic, and overall preferred by patient volunteers when blinded to the authorship. This study highlights the potential for integration of AI-written messaging into urology office communications. Further studies are needed on the negative perceptions of patient toward AI generated answers.</p></sec><sec id="Sec874" sec-type="supplementary-material"><title>Electronic supplementary material</title><p>Below is the link to the electronic supplementary material.</p><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="345_2024_5399_MOESM1_ESM.docx"><caption><p>Supplementary Material 1</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>The study authors would like to acknowledge Dr. Ramzi Jabaji and Dr. Ashish Parekh for their contribution of subject matter expertise and significant time reviewing questionnaire data. We also acknowledge the Kaiser Permanente urologists for their time and expertise providing answers to the sample patient questions.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>E.R., C.Q., and M.F. wrote and reviewed the main manuscript text, developed study methodology, conducted the study investigation, performed formal analysis, and managed data curation. E.R. prepared figures and tables. S.S., M.K., S.V., and K.O. were involved in software design and implementation. K.N., A.D., D.R., and M.F., were involved in project administration. All authors reviewed the manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>None.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>Data that support the findings of this study are available online in an anonymized format at <ext-link ext-link-type="uri" xlink:href="https://github.com/EricRob/surgichat/blob/main/compiled_evaluations.csv">https://github.com/EricRob/surgichat/blob/main/compiled_evaluations.csv</ext-link>.</p></notes><notes><title>Declarations</title><notes id="FPar3" notes-type="COI-statement"><title>Competing interests</title><p id="Par31">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>SH</given-names></name><name><surname>Tae</surname><given-names>JH</given-names></name><name><surname>Chang</surname><given-names>IH</given-names></name><etal/></person-group><article-title>Changes in patient perceptions regarding ChatGPT-written explanations on lifestyle modifications for preventing urolithiasis recurrence</article-title><source>Digit Health Jan-Dec</source><year>2023</year><volume>9</volume><fpage>20552076231203940</fpage><pub-id pub-id-type="doi">10.1177/20552076231203940</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Kim SH, Tae JH, Chang IH et al (2023) Changes in patient perceptions regarding ChatGPT-written explanations on lifestyle modifications for preventing urolithiasis recurrence. Digit Health Jan-Dec 9:20552076231203940. 10.1177/20552076231203940</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">OpenAI, Achiam J, Adler S, GPT-4 Technical Report (2023).:arXiv:2303.08774. 10.48550/arXiv.2303.08774 Accessed March 01, 2023. <ext-link ext-link-type="uri" xlink:href="https://ui.adsabs.harvard.edu/abs/2023arXiv230308774O">https://ui.adsabs.harvard.edu/abs/2023arXiv230308774O</ext-link></mixed-citation></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>P</given-names></name><name><surname>Bubeck</surname><given-names>S</given-names></name><name><surname>Petro</surname><given-names>J</given-names></name><name><surname>Benefits</surname></name></person-group><article-title>Limits, and risks of GPT-4 as an AI Chatbot for Medicine</article-title><source>N Engl J Med Mar</source><year>2023</year><volume>30</volume><issue>13</issue><fpage>1233</fpage><lpage>1239</lpage><pub-id pub-id-type="doi">10.1056/NEJMsr2214184</pub-id></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Lee P, Bubeck S, Petro J, Benefits (2023) Limits, and risks of GPT-4 as an AI Chatbot for Medicine. N Engl J Med Mar 30(13):1233&#x02013;1239. 10.1056/NEJMsr2214184</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>G</given-names></name><name><surname>Smith</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>S</given-names></name></person-group><article-title>The AI will see you now: feasibility and acceptability of a conversational AI Medical Interviewing System</article-title><source>JMIR Form Res Jun</source><year>2022</year><volume>27</volume><issue>6</issue><fpage>e37028</fpage><pub-id pub-id-type="doi">10.2196/37028</pub-id></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Hong G, Smith M, Lin S (2022) The AI will see you now: feasibility and acceptability of a conversational AI Medical Interviewing System. JMIR Form Res Jun 27(6):e37028. 10.2196/37028</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Shah NH, Entwistle D, Pfeffer MA (2023) Creation and adoption of large Language models in Medicine. JAMA 330(9). 10.1001/jama.2023.14217</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Goodman RS, Patrinely JR, Stone CA et al (2023) Accuracy and reliability of chatbot responses to physician questions. JAMA Netw Open 6(10). 10.1001/jamanetworkopen.2023.36483</mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>R</given-names></name><name><surname>Eppler</surname><given-names>M</given-names></name><name><surname>Ayo-Ajibola</surname><given-names>O</given-names></name><etal/></person-group><article-title>Evaluating the effectiveness of Artificial intelligence&#x02013;powered large Language models Application in disseminating Appropriate and Readable Health Information in Urology</article-title><source>J Urol</source><year>2023</year><volume>210</volume><issue>4</issue><fpage>688</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1097/ju.0000000000003615</pub-id><pub-id pub-id-type="pmid">37428117</pub-id>
</element-citation><mixed-citation id="mc-CR7" publication-type="journal">Davis R, Eppler M, Ayo-Ajibola O et al (2023) Evaluating the effectiveness of Artificial intelligence&#x02013;powered large Language models Application in disseminating Appropriate and Readable Health Information in Urology. J Urol 210(4):688&#x02013;694. 10.1097/ju.0000000000003615<pub-id pub-id-type="pmid">37428117</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Checcucci</surname><given-names>E</given-names></name><name><surname>Rodler</surname><given-names>S</given-names></name><name><surname>Piazza</surname><given-names>P</given-names></name><name><surname>Porpiglia</surname><given-names>F</given-names></name><name><surname>Cacciamani</surname><given-names>GE</given-names></name></person-group><article-title>Transitioning from Dr. Google to Dr. ChatGPT: the advent of artificial intelligence chatbots</article-title><source>Translational Androl Urol</source><year>2024</year><volume>13</volume><issue>6</issue><fpage>1067</fpage><lpage>1070</lpage><pub-id pub-id-type="doi">10.21037/tau-23-629</pub-id></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Checcucci E, Rodler S, Piazza P, Porpiglia F, Cacciamani GE (2024) Transitioning from Dr. Google to Dr. ChatGPT: the advent of artificial intelligence chatbots. Translational Androl Urol 13(6):1067&#x02013;1070. 10.21037/tau-23-629</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Rezaeikhonakdar</surname><given-names>D</given-names></name></person-group><article-title>AI Chatbots and challenges of HIPAA Compliance for AI developers and vendors</article-title><source>J Law Med Ethics</source><year>2023</year><volume>51</volume><issue>4</issue><fpage>988</fpage><lpage>995</lpage><pub-id pub-id-type="doi">10.1017/jme.2024.15</pub-id><pub-id pub-id-type="pmid">38477276</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Rezaeikhonakdar D (2023) AI Chatbots and challenges of HIPAA Compliance for AI developers and vendors. J Law Med Ethics 51(4):988&#x02013;995. 10.1017/jme.2024.15<pub-id pub-id-type="pmid">38477276</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>L</given-names></name><name><surname>Mou</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>R</given-names></name></person-group><article-title>Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge?</article-title><source>J Transl Med Apr</source><year>2023</year><volume>19</volume><issue>1</issue><fpage>269</fpage><pub-id pub-id-type="doi">10.1186/s12967-023-04123-5</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Zhu L, Mou W, Chen R (2023) Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge? J Transl Med Apr 19(1):269. 10.1186/s12967-023-04123-5</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Mika</surname><given-names>AP</given-names></name><name><surname>Martin</surname><given-names>JR</given-names></name><name><surname>Engstrom</surname><given-names>SM</given-names></name><name><surname>Polkowski</surname><given-names>GG</given-names></name><name><surname>Wilson</surname><given-names>JM</given-names></name></person-group><article-title>Assessing ChatGPT responses to common patient questions regarding total hip arthroplasty</article-title><source>J Bone Joint Surg Am Oct</source><year>2023</year><volume>4</volume><issue>19</issue><fpage>1519</fpage><lpage>1526</lpage><pub-id pub-id-type="doi">10.2106/JBJS.23.00209</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Mika AP, Martin JR, Engstrom SM, Polkowski GG, Wilson JM (2023) Assessing ChatGPT responses to common patient questions regarding total hip arthroplasty. J Bone Joint Surg Am Oct 4(19):1519&#x02013;1526. 10.2106/JBJS.23.00209</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Ellis</surname><given-names>J</given-names></name><name><surname>Hamer</surname><given-names>MK</given-names></name><name><surname>Akerson</surname><given-names>M</given-names></name><etal/></person-group><article-title>Patient perceptions of Chatbot Supervision in Health Care settings</article-title><source>JAMA Netw Open Apr</source><year>2024</year><volume>1</volume><issue>4</issue><fpage>e248833</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.8833</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Ellis J, Hamer MK, Akerson M et al (2024) Patient perceptions of Chatbot Supervision in Health Care settings. JAMA Netw Open Apr 1(4):e248833. 10.1001/jamanetworkopen.2024.8833</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Cil G, Dogan K (2024) The efficacy of artificial intelligence in urology: a detailed analysis of kidney stone-related queries. World J Urol 42(1). 10.1007/s00345-024-04847-z</mixed-citation></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Ghaferi</surname><given-names>AA</given-names></name><name><surname>Schwartz</surname><given-names>TA</given-names></name><name><surname>Pawlik</surname><given-names>TM</given-names></name></person-group><article-title>STROBE reporting guidelines for Observational studies</article-title><source>JAMA Surg</source><year>2021</year><volume>156</volume><issue>6</issue><fpage>577</fpage><lpage>578</lpage><pub-id pub-id-type="doi">10.1001/jamasurg.2021.0528</pub-id><pub-id pub-id-type="pmid">33825815</pub-id>
</element-citation><mixed-citation id="mc-CR14" publication-type="journal">Ghaferi AA, Schwartz TA, Pawlik TM (2021) STROBE reporting guidelines for Observational studies. JAMA Surg 156(6):577&#x02013;578. 10.1001/jamasurg.2021.0528<pub-id pub-id-type="pmid">33825815</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">OpenAI, GPT-4. <ext-link ext-link-type="uri" xlink:href="https://openai.com/index/gpt-4-research/">https://openai.com/index/gpt-4-research/</ext-link></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Services AW RAG (Retrieval-Augmented Generation). <ext-link ext-link-type="uri" xlink:href="https://aws.amazon.com/what-is/retrieval-augmented-generation/">https://aws.amazon.com/what-is/retrieval-augmented-generation/</ext-link></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Gajjar AA, Kumar RP, Paliwoda ED et al (2024) Usefulness and accuracy of Artificial Intelligence Chatbot responses to patient questions for neurosurgical procedures. Neurosurg Feb 14. 10.1227/neu.0000000000002856</mixed-citation></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>I</given-names></name><name><surname>Cox</surname><given-names>A</given-names></name><name><surname>Xie</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Evaluating Chatbot Efficacy for answering frequently asked questions in plastic surgery: a ChatGPT Case Study focused on breast augmentation</article-title><source>Aesthet Surg J Sep</source><year>2023</year><volume>14</volume><issue>10</issue><fpage>1126</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1093/asj/sjad140</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Seth I, Cox A, Xie Y et al (2023) Evaluating Chatbot Efficacy for answering frequently asked questions in plastic surgery: a ChatGPT Case Study focused on breast augmentation. Aesthet Surg J Sep 14(10):1126&#x02013;1135. 10.1093/asj/sjad140</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Cacciamani</surname><given-names>GE</given-names></name><name><surname>Bassi</surname><given-names>S</given-names></name><name><surname>Sebben</surname><given-names>M</given-names></name><etal/></person-group><article-title>Consulting Dr. Google for prostate Cancer Treatment options: a contemporary Worldwide Trend Analysis</article-title><source>Eur Urol Oncol</source><year>2020</year><volume>3</volume><issue>4</issue><fpage>481</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1016/j.euo.2019.07.002</pub-id><pub-id pub-id-type="pmid">31375427</pub-id>
</element-citation><mixed-citation id="mc-CR19" publication-type="journal">Cacciamani GE, Bassi S, Sebben M et al (2020) Consulting Dr. Google for prostate Cancer Treatment options: a contemporary Worldwide Trend Analysis. Eur Urol Oncol 3(4):481&#x02013;488. 10.1016/j.euo.2019.07.002<pub-id pub-id-type="pmid">31375427</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Garcia P, Ma SP, Shah S et al (2024) Artificial intelligence&#x02013;generated draft replies to patient inbox messages. JAMA Netw Open 7(3). 10.1001/jamanetworkopen.2024.3201</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Professionals ASoA Average Words Per Minute Typing: How Fast Is Fast Enough? <ext-link ext-link-type="uri" xlink:href="https://www.asaporg.com/efficiency-skills/average-words-per-minute-typing-how-fast-is-fast-enough">https://www.asaporg.com/efficiency-skills/average-words-per-minute-typing-how-fast-is-fast-enough</ext-link></mixed-citation></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>AM</given-names></name><name><surname>Brimhall</surname><given-names>AS</given-names></name><name><surname>Johnson</surname><given-names>ET</given-names></name><etal/></person-group><article-title>A systematic review of the effectiveness of patient education through patient portals</article-title><source>JAMIA Open Apr</source><year>2023</year><volume>6</volume><issue>1</issue><fpage>ooac085</fpage><pub-id pub-id-type="doi">10.1093/jamiaopen/ooac085</pub-id></element-citation><mixed-citation id="mc-CR22" publication-type="journal">Johnson AM, Brimhall AS, Johnson ET et al (2023) A systematic review of the effectiveness of patient education through patient portals. JAMIA Open Apr 6(1):ooac085. 10.1093/jamiaopen/ooac085</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Rotenstein</surname><given-names>LS</given-names></name><name><surname>Holmgren</surname><given-names>AJ</given-names></name><name><surname>Healey</surname><given-names>MJ</given-names></name><etal/></person-group><article-title>Association between Electronic Health Record Time and Quality of Care Metrics in Primary Care</article-title><source>JAMA Netw Open Oct</source><year>2022</year><volume>3</volume><issue>10</issue><fpage>e2237086</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2022.37086</pub-id></element-citation><mixed-citation id="mc-CR23" publication-type="journal">Rotenstein LS, Holmgren AJ, Healey MJ et al (2022) Association between Electronic Health Record Time and Quality of Care Metrics in Primary Care. JAMA Netw Open Oct 3(10):e2237086. 10.1001/jamanetworkopen.2022.37086</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Rotenstein</surname><given-names>LS</given-names></name><name><surname>Melnick</surname><given-names>ER</given-names></name><name><surname>Jeffery</surname><given-names>M</given-names></name><etal/></person-group><article-title>Association of Primary Care Physicians&#x02019; electronic inbox activity patterns with patients&#x02019; likelihood to recommend the physician</article-title><source>J Gen Intern Med</source><year>2023</year><volume>39</volume><issue>1</issue><fpage>150</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1007/s11606-023-08417-8</pub-id><pub-id pub-id-type="pmid">37731135</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Rotenstein LS, Melnick ER, Jeffery M et al (2023) Association of Primary Care Physicians&#x02019; electronic inbox activity patterns with patients&#x02019; likelihood to recommend the physician. J Gen Intern Med 39(1):150&#x02013;152. 10.1007/s11606-023-08417-8<pub-id pub-id-type="pmid">37731135</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Rodler</surname><given-names>S</given-names></name><name><surname>Kopliku</surname><given-names>R</given-names></name><name><surname>Ulrich</surname><given-names>D</given-names></name><etal/></person-group><article-title>Patients&#x02019; trust in Artificial intelligence&#x02013;based decision-making for localized prostate Cancer: results from a prospective trial</article-title><source>Eur Urol Focus Published Online</source><year>2023</year><pub-id pub-id-type="doi">10.1016/j.euf.2023.10.020</pub-id></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Rodler S, Kopliku R, Ulrich D et al (2023) Patients&#x02019; trust in Artificial intelligence&#x02013;based decision-making for localized prostate Cancer: results from a prospective trial. Eur Urol Focus Published Online. 10.1016/j.euf.2023.10.020</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Eppler</surname><given-names>M</given-names></name><name><surname>Ganjavi</surname><given-names>C</given-names></name><name><surname>Ramacciotti</surname><given-names>LS</given-names></name><etal/></person-group><article-title>Awareness and use of ChatGPT and large Language models: a prospective cross-sectional global survey in Urology</article-title><source>Eur Urol</source><year>2024</year><volume>85</volume><issue>2</issue><fpage>146</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1016/j.eururo.2023.10.014</pub-id><pub-id pub-id-type="pmid">37926642</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal">Eppler M, Ganjavi C, Ramacciotti LS et al (2024) Awareness and use of ChatGPT and large Language models: a prospective cross-sectional global survey in Urology. Eur Urol 85(2):146&#x02013;153. 10.1016/j.eururo.2023.10.014<pub-id pub-id-type="pmid">37926642</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>