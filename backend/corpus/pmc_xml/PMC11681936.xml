<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39585721</article-id><article-id pub-id-type="pmc">PMC11681936</article-id>
<article-id pub-id-type="doi">10.1093/bioinformatics/btae708</article-id><article-id pub-id-type="publisher-id">btae708</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject><subj-group subj-group-type="category-toc-heading"><subject>Structural Bioinformatics</subject></subj-group></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI01060</subject></subj-group></article-categories><title-group><article-title>TPepPro: a deep learning model for predicting peptide&#x02013;protein interactions</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Jin</surname><given-names>Xiaohong</given-names></name><aff>
<institution>School of Electronic Information, Guangxi University for Nationalities</institution>, Nanning 530000, <country country="CN">China</country></aff><xref rid="btae708-FM1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Zimeng</given-names></name><aff>
<institution>Division of Applied Oral Sciences and Community Dental Care, Faculty of Dentistry, The University of Hong Kong</institution>, Hong Kong SAR, <country country="CN">China</country></aff><xref rid="btae708-FM1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><name><surname>Yu</surname><given-names>Dan</given-names></name><aff>
<institution>Division of Applied Oral Sciences and Community Dental Care, Faculty of Dentistry, The University of Hong Kong</institution>, Hong Kong SAR, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><name><surname>Jiang</surname><given-names>Qianhui</given-names></name><aff>
<institution>Division of Applied Oral Sciences and Community Dental Care, Faculty of Dentistry, The University of Hong Kong</institution>, Hong Kong SAR, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Zhuobin</given-names></name><aff>
<institution>School of Pharmaceutical Sciences (Shenzhen), Shenzhen Campus of Sun Yat-sen University</institution>, Shenzhen, Guangdong 518107, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><name><surname>Yan</surname><given-names>Bin</given-names></name><aff>
<institution>Division of Applied Oral Sciences and Community Dental Care, Faculty of Dentistry, The University of Hong Kong</institution>, Hong Kong SAR, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8327-8846</contrib-id><name><surname>Qin</surname><given-names>Jing</given-names></name><aff>
<institution>School of Pharmaceutical Sciences (Shenzhen), Shenzhen Campus of Sun Yat-sen University</institution>, Shenzhen, Guangdong 518107, <country country="CN">China</country></aff></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Liu</surname><given-names>Yong</given-names></name><aff>
<institution>School of Artificial Intelligence, Guangxi University for Nationalities</institution>, Nanning 530000, <country country="CN">China</country></aff><xref rid="btae708-cor1" ref-type="corresp"/><!--junwen@hku.hk--></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4432-4707</contrib-id><name><surname>Wang</surname><given-names>Junwen</given-names></name><aff>
<institution>Division of Applied Oral Sciences and Community Dental Care, Faculty of Dentistry, The University of Hong Kong</institution>, Hong Kong SAR, <country country="CN">China</country></aff><aff>
<institution>State Key Laboratory of Pharmaceutical Biotechnology, The University of Hong Kong</institution>, Hong Kong SAR, <country country="CN">China</country></aff><aff>
<institution>HKU Shenzhen Hospital</institution>, Shenzhen 518000, <country country="CN">China</country></aff><xref rid="btae708-cor1" ref-type="corresp"/><!--junwen@hku.hk--></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Elofsson</surname><given-names>Arne</given-names></name><role>Associate Editor</role></contrib></contrib-group><author-notes><corresp id="btae708-cor1">Corresponding authors.&#x000a0;Division of Applied Oral Sciences and Community Dental Care, Faculty of Dentistry, The University of Hong Kong, 34 Hospital Road, Hong Kong SAR, China.&#x000a0;E-mail: <email>junwen@hku.hk</email> (J.W.);&#x000a0;School of Electronic Information, Guangxi University for Nationalities, University East Road 188, Nanning 530006, China.&#x000a0;E-mail: <email>liuhyonge@gxmzu.edu.cn</email> (Y.L.)</corresp><fn id="btae708-FM1"><p>Xiaohong Jin and Zimeng Chen Equal contribution.</p></fn></author-notes><pub-date pub-type="collection"><month>1</month><year>2025</year></pub-date><pub-date pub-type="epub" iso-8601-date="2024-11-25"><day>25</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>25</day><month>11</month><year>2024</year></pub-date><volume>41</volume><issue>1</issue><elocation-id>btae708</elocation-id><history><date date-type="received"><day>29</day><month>5</month><year>2024</year></date><date date-type="rev-recd"><day>23</day><month>10</month><year>2024</year></date><date date-type="editorial-decision"><day>13</day><month>11</month><year>2024</year></date><date date-type="accepted"><day>24</day><month>11</month><year>2024</year></date><date date-type="corrected-typeset"><day>28</day><month>12</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024. Published by Oxford University Press.</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="btae708.pdf"/><abstract><title>Abstract</title><sec id="s1"><title>Motivation</title><p>Peptides and their derivatives hold potential as therapeutic agents. The rising interest in developing peptide drugs is evidenced by increasing approval rates by the FDA of USA. To identify the most potential peptides, study on peptide-protein interactions (PepPIs) presents a very important approach but poses considerable technical challenges. In experimental aspects, the transient nature of PepPIs and the high flexibility of peptides contribute to elevated costs and inefficiency. Traditional docking and molecular dynamics simulation methods require substantial computational resources, and the predictive accuracy of their results remain unsatisfactory.</p></sec><sec id="s2"><title>Results</title><p>To address this gap, we proposed TPepPro, a Transformer-based model for PepPI prediction. We trained TPepPro on a dataset of 19,187 pairs of peptide-protein complexes with both sequential and structural features. TPepPro utilizes a strategy that combines local protein sequence feature extraction with global protein structure feature extraction. Moreover, TPepPro optimizes the architecture of structural featuring neural network in BN-ReLU arrangement, which notably reduced the amount of computing resources required for PepPIs prediction. According to comparison analysis, the accuracy reached 0.855 in TPepPro, achieving an 8.1% improvement compared to the second-best model TAGPPI. TPepPro achieved an AUC of 0.922, surpassing the second-best model TAGPPI with 0.844. Moreover, the newly developed TPepPro identify certain PepPIs that can be validated according to previous experimental evidence, thus indicating the efficiency of TPepPro to detect high potential PepPIs that would be helpful for amino acid drug applications.</p></sec><sec id="s3"><title>Availability and implementation</title><p>The source code of TPepPro is available at <ext-link xlink:href="https://github.com/wanglabhku/TPepPro" ext-link-type="uri">https://github.com/wanglabhku/TPepPro</ext-link>.</p></sec></abstract><abstract abstract-type="graphical"><title>Graphical abstract</title><p>
<fig position="float" id="btae708-F10"><label>Graphical abstract</label><graphic xlink:href="btae708f10" position="float"/></fig>
</p></abstract><funding-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Hong Kong General Research Fund</institution></institution-wrap>
</funding-source><award-id>C7015-23G</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>University of Hong Kong</institution><institution-id institution-id-type="DOI">10.13039/501100003803</institution-id></institution-wrap>
</funding-source></award-group></funding-group><counts><page-count count="12"/></counts></article-meta></front><body><sec><title>1 Introduction</title><p>Peptide-protein interactions (PepPIs) refer to interactions between proteins and peptide molecules that are ubiquitous in living organisms and involved in many biological processes. The specificity and biological activity of peptides make them a good starting point for new treatments. Identifying accurate PepPIs is critical to the invention of such treatments, but determining PepPIs experimentally is often time-consuming and expensive. Predicting whether they have interactions is of great significance for the development of peptide drugs. To address this problem, numerous computational methods have been developed to predict the relationship between proteins and peptides (<xref rid="btae708-B5" ref-type="bibr">Cunningham <italic toggle="yes">et al.</italic> 2020</xref>).</p><p>Recently, rapidly developing deep learning techniques have provided viable solutions for modelling protein-ligands or protein&#x02013;protein interactions (PPIs) with better accuracy while requiring fewer computational resources (<xref rid="btae708-B28" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae708-B40" ref-type="bibr">Tang <italic toggle="yes">et al.</italic> 2023</xref>, <xref rid="btae708-B48" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2023a</xref>). However, the advancement in machine learning has not yet significantly impacted PepPI research. To date, <italic toggle="yes">in silico</italic> research targeting peptides has primarily focused on peptide-protein docking or molecular dynamic simulations (<xref rid="btae708-B20" ref-type="bibr">Keeble <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae708-B24" ref-type="bibr">Lee <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae708-B19" ref-type="bibr">Johansson-&#x000c5;khe <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae708-B39" ref-type="bibr">Sunny and Jayaraj 2022</xref>). Predictions based on conventional docking have been reported to fail biologically activity tests (<xref rid="btae708-B4" ref-type="bibr">Cole <italic toggle="yes">et al.</italic> 2005</xref>, <xref rid="btae708-B32" ref-type="bibr">Ram&#x000ed;rez and Caballero 2016</xref>). Previous studies have utilized machine learning methods that widely applied in vision tasks to construct PepPI models, such as Convolutional Neural Network (CNN) (<xref rid="btae708-B1" ref-type="bibr">Ballester and Mitchell 2010</xref>, <xref rid="btae708-B51" ref-type="bibr">Yin <italic toggle="yes">et al.</italic> 2023</xref>). However, in terms of PepPIs, features include not only structural but also sequential.</p><p>Fortunately, artificial intelligence models have experienced rapidly updated in recent years (<xref rid="btae708-B37" ref-type="bibr">Sinha <italic toggle="yes">et al.</italic> 2023</xref>, <xref rid="btae708-B49" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2023b</xref>, <xref rid="btae708-B27" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2024</xref>). The advantage of Transformer in amino acid sequence analysis is its ability to capture long-distance dependencies and to effectively handle long sequence data. Meanwhile, through the self-attention mechanism, it can automatically learn the important features in the sequences and improve the prediction performance. Here, we employ a transformer-based model with enhanced capability to comprehend contextual information in protein sequences and to construct more accurate and reliable PepPI prediction models. Moreover, in our study, we paid special attention to whether the prediction results could be experimentally validated. Despite the need for further experimental confirmation, we still find experimental evidence beyond the scope of the training and testing sets to confirm the effectiveness of the TPepPro model in practical applications.</p><p>Although there are growing interests in making peptide drugs and increasing number of approved peptide therapies, only a handful of work has been proposed to utilize machine learning or deep learning-based methods to model PepPIs. Hence, there is a pressing need for more advanced machine learning or deep learning-based models with superior efficiency for discovering PepPIs, specifically tailored for predicting PepPIs. In this study, we propose a novel model named TPepPro, that combines features extracted from both local protein sequences and global protein structures. The TPepPro system optimizes the architecture of structural featuring neural network with BN-ReLU (Batch Normalization&#x02014;Rectified Linear Unit). We applied a 5-fold cross-validation to evaluate the performance of TPepPro as compared with other models, including PIPR (<xref rid="btae708-B3" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2019</xref>), SCNN (<xref rid="btae708-B45" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2019</xref>), and TAGPPI (<xref rid="btae708-B38" ref-type="bibr">Song <italic toggle="yes">et al.</italic> 2022</xref>). Our findings show an enhanced prediction accuracy of 0.855, a notable improvement over TAGPPI, the second-best model which achieved 0.774, and an increase of 8.1%. More importantly, the TPepPro method can identify PepPIs, consistent with those validated in previous experiments. Therefore, these findings demonstrate the superior ability of our method to discover potential PepPIs that would be helpful for amino acid drug applications.</p></sec><sec><title>2 Materials and methods</title><sec><title>2.1 Workflow of TPepPro</title><p>The TPepPro model proposed in this study uses an end-to-end deep learning method. There are four modules in TPepPro (<xref rid="btae708-F1" ref-type="fig">Fig.&#x000a0;1</xref>): (i) Data pre-processing: Protein sequences are processed by ProtTrans, which is based on the Transformer architecture. This model has proven to be an excellent model on encoding the syntax and semantics of protein sequences (<xref rid="btae708-B8" ref-type="bibr">Elnaggar et al. 2022</xref>). The highest performance model of ProtTrans, ProtT5_XL_half_UniRef50-enc, is utilized in this pipeline. Structural features are encoded as contact map. (ii) Extracting local features of protein sequences using TextCNN (<xref rid="btae708-B22" ref-type="bibr">Kim 2014</xref>). (iii) Extracting protein structural features using TAGCN (<xref rid="btae708-B7" ref-type="bibr">Du <italic toggle="yes">et al.</italic> 2018</xref>). Compared with the original GCN, TAGCN is chosen for its better performance and accuracy as it uses a set of filters that are specific for each node. (iv) Prediction Model. In the training module, the Batch Normalization layer was placed prior to the ReLU layer (<xref rid="btae708-B18" ref-type="bibr">Ioffe and Szegedy 2015</xref>). This is because the BN layer can make the mean of the input values to be 0 and the variance to be 1, alleviating the problem of vanishing gradient of the ReLU function to a certain extent. This setting helps to keep the gradient passing efficiently while training the neural network, and to improve the performance (<xref rid="btae708-B9" ref-type="bibr">Garbin <italic toggle="yes">et al.</italic> 2020</xref>).</p><fig position="float" id="btae708-F1"><label>Figure 1.</label><caption><p>Architecture of TPepPro. (1) Data preprocessing: The amino acid sequences corresponding to proteins and peptides are encoded as vectors of size <italic toggle="yes">L</italic>&#x02009;&#x000d7;&#x02009;1024. Here, <italic toggle="yes">L</italic> represents the length of the protein/peptide amino acid sequence, and 1024 denotes that each amino acid is encoded into a vector of 1024 dimensions. Additionally, distances between residues in the PDB-format protein and peptide structure files are calculated to obtain the contact map files of proteins and peptides. (2) TextCNN module is utilized to extract local sequence features of proteins and peptides. (3) Extraction of protein and peptide structural features: The TAGCN module is used to extract structural features through the contact map files of proteins and peptides. (4) Prediction module: Finally, the local sequence features and structural features of the given protein-peptide pairs obtained from the above steps are fused before being input into the prediction module. The generated prediction results undergo a sigmoid activation function for nonlinear transformation, resulting in an output between 0 and 1. Based on a set threshold, here set as 0.5, the presence of interaction in the input peptide-protein pairs is determined. Pairs with output results greater than or equal to 0.5 are considered to have interaction; pairs with output results less than 0.5 are deemed to have no interaction.</p></caption><graphic xlink:href="btae708f1" position="float"/></fig></sec><sec><title>2.2 Data collection</title><p>Five datasets are utilized in this study (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>), comprising: (i) The protein-peptide complex dataset Propedia v2.3 (<xref rid="btae708-B30" ref-type="bibr">Martins <italic toggle="yes">et al.</italic> 2023</xref>); (2) The human protein dataset DIP (<xref rid="btae708-B54" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic> 2022</xref>); (3) The yeast protein dataset (<xref rid="btae708-B36" ref-type="bibr">Salwinski <italic toggle="yes">et al.</italic> 2004</xref>); (4) The neocoronavirus-human protein dataset (<xref rid="btae708-B50" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>). (v) The HIV-human protein dataset (<xref rid="btae708-B50" ref-type="bibr">Yang <italic toggle="yes">et al.</italic> 2021</xref>). The protein-peptide complex dataset from Propedia v2.3 serves as the primary dataset in this research.</p></sec><sec><title>2.3 Data pre-processing</title><p>Developed by DeepMind Google, ProtTrans uses the self-attention mechanism optimized for understanding the syntax and semantics of protein sequences (<xref rid="btae708-B8" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2022</xref>). ProtT5-XL-UniRef50 is chosen here for representing proteins with vectors as it was the best performance among ProtTrans models. To speed this step up, the model&#x02019;s half-precision mode is turned on, namely, ProtT5-XL-half-UniRef50-enc. It was verified by Elnaggar <italic toggle="yes">et al.</italic> that this modification does not compromise the performance.</p><p>As shown in <xref rid="btae708-F2" ref-type="fig">Fig.&#x000a0;2</xref>, we firstly tokenize and encode the input protein sequences. The encoded vectors are piped into ProtT5-XL-half-UniRef50-enc model, creating context-aware embeddings for each token. The vector representation of the protein is therefore obtained with the output being <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>X</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. <italic toggle="yes">L</italic> represents the number of amino acids of the input protein.</p><fig position="float" id="btae708-F2"><label>Figure 2.</label><caption><p>Protein amino acid embedding generation diagram. Protein sequences are first subjected to tokenization and positional encoding, followed by generating context-aware embeddings for each amino acid using the ProtT5-XL-half-UniRef50-enc model, resulting in vector representations of the proteins.</p></caption><graphic xlink:href="btae708f2" position="float"/></fig></sec><sec><title>2.4 Strategy of extracting local feature of protein sequence</title><p>This research adopts a TextCNN module for extracting local sequence features of proteins (<xref rid="btae708-B54" ref-type="bibr">Zhao <italic toggle="yes">et al.</italic> 2022</xref>). The module consists of three CNN layers and three max pooling layers. This structure is designed to achieve effective feature extraction and classification of protein sequences through the combination of CNNs and max pooling layers, while ensuring computational efficiency and robustness at the same time. Detailed extraction process is described below:</p><p>Firstly, ProtT5-XL-half-UniRef50-enc model is used to encode protein sequences into vector representations, denoted as <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>X</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Next, to ensure a fixed output vector size for the TextCNN module, the maximum length of the protein sequence <italic toggle="yes">L</italic> is set to be 1200. When a protein sequence is less than 1200 in length, a zero-padding approach would be applied to complement the sequence to fit 1200. Therefore, the formatted vector as <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>X</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1200</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is adopted as further input of TextCNN.</p><p>The first convolutional layer of TextCNN has 128 output channels and a convolutional kernel size of 3. The output feature map has a size of 1198&#x02009;&#x000d7;&#x02009;128. This feature map was then fed into a maximum pooling layer with a step size of 3, resulting in another feature map of the protein with a size of 399&#x02009;&#x000d7;&#x02009;128. The processes mentioned above are repeated twice. Eventually, local feature vectors of size <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> will be output from TextCNN module as the protein sequence features.</p></sec><sec><title>2.5 Extracting protein structure features</title><p>Protein structural features are extracted through the construction of a protein&#x02019;s contact graph. First, a contact graph file of the protein is constructed based on its structure file (PDB file). Bio.PDB, a module in the BioPython package, is used to process protein structure files in PDB format and calculate distances between residues (<xref rid="btae708-B12" ref-type="bibr">Hamelryck and Manderick 2003</xref>). The contact graph is square shaped with dimensions <italic toggle="yes">L</italic>&#x02009;&#x000d7;&#x02009;<italic toggle="yes">L</italic>. From this contact graph, we derive the Adjacency Matrix <italic toggle="yes">A</italic> and the Node Feature Matrix <italic toggle="yes">X</italic>. The adjacency matrix, denoted as <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi>A</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, represents connections between nodes. A value of 0 indicates no connection between two nodes, while a value of 1 indicates the presence of a connection. The node feature matrix, represented as <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>X</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, consists of feature vectors of 1024 dimensions for each node.</p><p>Subsequently, the obtained adjacency matrix <italic toggle="yes">A</italic> and the node feature matrix <italic toggle="yes">X</italic> are input into the TAGCN layer, a variant of GCN. Traditional GCN sets <italic toggle="yes">K</italic>&#x02009;=&#x02009;1 after approximating filters with Chebyshev polynomials, while TAGCN employs <italic toggle="yes">K</italic> filters to extract local features of varying sizes, with <italic toggle="yes">K</italic> serving as a hyperparameter. <italic toggle="yes">K</italic> varies among filters, ranging from 1 to <italic toggle="yes">K</italic>, akin to GoogleNet&#x02019;s filters. The convolution process of TAGCN is demonstrated as follows:</p><p>Here, the graph convolution on the first hidden layer is demonstrated as an example, with the resulting pattern applicable to any other hidden layers. In this demonstration, it is assumed that <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> features are mapped to each node. Subsequently, the adjacency matrix underwent self-looping and normalization:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>-</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>-</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>
<inline-formula id="IE9">
<mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math>
</inline-formula> denote the form of <italic toggle="yes">f</italic>th graph filter. The convolution of a graph is the product of a matrix and a vector, namely, <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. Therefore, the output feature map after the <italic toggle="yes">f</italic>th map filter is:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>In form (2): <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> represents the graph filter polynomial coefficients. <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the learnable bias. <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> means all elements of the <italic toggle="yes">N</italic>-dimensional vector are 1.</p><p>According to the CNN architecture, an additional nonlinear operation would be employed after the convolution operation for each graph.
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Afterwards, the protein structural features extracted by TAGCN are fed into the maximum pooling layer and the linear layer containing 128 neurons. This process ensures a fixed number of outputs from the feature extraction module. Finally, for a pair of protein spatial maps <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">G</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and<inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">G</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, we extract its structural feature vectors as <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and<inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, respectively.</p><p>The convolution process of TAGCN at <italic toggle="yes">K</italic>&#x02009;=&#x02009;3 (<xref rid="btae708-F3" ref-type="fig">Fig.&#x000a0;3</xref>) is illustrated below. The feature map of each vertex is assumed to contain one feature. Similarly, CNN, multiple channels are formed from the features extracted by multiple filters in each convolutional layer. Features extracted in filter ranging from 1 to 3 are denoted as<inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mi mathvariant="normal">&#x000a0;</mml:mi><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Features extracted by the three filters represent the relationship between the vertices and their neighbors in different spatial ranges. The new features of the green vertices in the graph are obtained by linearly combining them. New features of the vertex are denoted as <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p><fig position="float" id="btae708-F3"><label>Figure 3.</label><caption><p>Topology-Adaptive Graph Convolutional Network (TAGCN) convolution process with K=3.The central amino acid node aggregates features from neighboring nodes within three hop distances (K=1,2,3), enabling the capture of both local and extended structural information.</p></caption><graphic xlink:href="btae708f3" position="float"/></fig></sec><sec><title>2.6 Prediction module</title><p>The local sequence features (<inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) and structural features (<inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) of the proteins obtained from the above steps are fused in the prediction module, based on the formulas:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula><disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>The fused features are connected and fed into the MLP layer, which is stacked of three linear layers (FC layer). The first two FC layers are followed by the BN function and ReLU activation function. Whereas the prediction results generated by the last FC layer are nonlinearly transformed by the Sigmoid activation function, obtaining an output that lies between 0 and 1. A judgment of whether the input protein pair interacts or not is then obtained based on the set threshold. Here the threshold is set to 0.5. Namely, an output prediction scores greater than or equal to 0.5 indicates that the input protein pairs are interacting, and vice versa.</p></sec><sec><title>2.7 Evaluation metrics</title><p>Five-fold cross-validation is used to evaluate binary prediction from seven criteria, namely accuracy (ACC), precision (Prec), recall (Recall), specificity (Spec), F1-score (F1), Area Under Curve (AUC), and the area under PRC curve (The area under the precision-recall curve, AUPRC).
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mi mathvariant="normal">ACC</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext><mml:mi>+</mml:mi><mml:mtext>TN</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mi>+</mml:mi><mml:mtext>FN</mml:mtext><mml:mi>+</mml:mi><mml:mtext>FP</mml:mtext><mml:mi>+</mml:mi><mml:mtext>TN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mtext>Prec</mml:mtext><mml:mi>=</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mi>+</mml:mi><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mtext>Recall</mml:mtext><mml:mi>=</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mi>+</mml:mi><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mi mathvariant="normal">Spec</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>TN</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TN</mml:mtext><mml:mi>+</mml:mi><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E10"><label>(10)</label><mml:math id="M10" display="block" overflow="scroll"><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn><mml:mi>=</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>*</mml:mi><mml:mtext>Prec</mml:mtext><mml:mi>*</mml:mi><mml:mtext>Recall</mml:mtext></mml:mrow><mml:mrow><mml:mtext>Prec</mml:mtext><mml:mi>+</mml:mi><mml:mtext>Recall</mml:mtext></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>In the above formula: TP (True Positive) represents that the prediction is positive, and the prediction is correct; TN (True Negative) means that the prediction is negative, and the prediction is correct. FP (False Positive) means that the prediction is positive, but the prediction is incorrect; FN (False Negative) indicates that the prediction is negative, but the prediction is incorrect.
<disp-formula id="E11"><label>(11)</label><mml:math id="M11" display="block" overflow="scroll"><mml:mi mathvariant="normal">FPR</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">FP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">TN</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="E12"><label>(12)</label><mml:math id="M12" display="block" overflow="scroll"><mml:mi mathvariant="normal">TPR</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">TP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">FN</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>AUC is the area enclosed by the ROC curve and the <italic toggle="yes">x</italic>-axis, the ROC curve <italic toggle="yes">x</italic>-axis is FPR (False Positive Rate), and the <italic toggle="yes">y</italic> axis is TPR (True Positive Rate).</p><p>AUPRC is the area enclosed by the PRC curve and the <italic toggle="yes">x</italic>-axis, the PRC curve <italic toggle="yes">x</italic>-axis is the recall (Recall), and the <italic toggle="yes">y</italic>-axis is the precision (Prec).</p></sec><sec><title>2.8 Interpretability analysis</title><p>The interpretable analysis of the significant global features of protein structure extracted by TAGCN involves the following process: First, we load the amino acid sequences of the proteins, along with their contact maps and encoded vector representations. Next, we generate an adjacency matrix based on the contact map and create a graph data structure, incorporating the protein-encoded vectors as node features. These data are then input into the TAGCN model. The input graph data undergoes processing through the TAGConv layers, where graph convolution operations update the node features, followed by a forward propagation to obtain the output features processed by the TAGCN model. Finally, these output features are passed through an attention mechanism module to derive the corresponding attention scores, which are then combined to calculate the node importance scores.</p><p>To interpret analysis of the crucial local features of protein sequences extracted by TextCNN, we utilized visualizations of the activation maps of the convolutional kernels. These maps provide effective means to understand how TextCNN captures features from the input data. In the context of TextCNN, the activation maps illustrate the activation values generated as the convolutional kernels slide over the protein sequences. These activation values reflect the degree of matching between the kernels and the local features at different positions within the input sequence.</p></sec><sec><title>2.9 Model training</title><p>TPepPro takes the protein/peptide sequence features and predicts contact maps as input. We used the dgl libraries of Python 3.7, PyTorch 1.5.1, and CUDA 10.1 to implement TAGCN (<xref rid="btae708-B7" ref-type="bibr">Du <italic toggle="yes">et al.</italic> 2018</xref>). At the same time, the experiment took advantage of the powerful computing of the GPU, namely NVIDIA Quadro RTX, 24GB memory. The TPepPro model was trained on 50 epochs on the protein-peptide complex dataset using Adam optimizer, with a learning rate and batch size of 0.001 and 32, respectively. To avoid overfitting, BN technology is used during training. Other parameters took the default values provided by PyTorch (<xref rid="btae708-B52" ref-type="bibr">Zhai <italic toggle="yes">et al.</italic> 2023</xref>).</p></sec></sec><sec><title>3 Results</title><p>The TPepPro model is composed of an investigation into the effects of sequence encoding methods, graph CNN methods, and the architecture of the neural network. Comparative analyses are conducted between the TPepPro model and other state-of-the-art methods. The performance of the TPepPro model on different datasets is examined using ROC curves and PR curves. Finally, case studies of high-confidence results are provided with experimental evidence.</p><sec><title>3.1 Dataset</title><p>The protein-peptide complex dataset is from Propedia database (<ext-link xlink:href="http://bioinfo.dcc.ufmg.br/propedia2/index.php/download" ext-link-type="uri">http://bioinfo.dcc.ufmg.br/propedia2/index.php/download</ext-link>). The latest version v2.3 contains 49&#x000a0;300 protein-peptide complexes. We treated protein-peptide complexes as positive protein-peptide samples, and negative interactions are constructed by randomly pairing protein-peptide pairs and not present in positive dataset. There may be inconsistencies between the number of amino acids in the contact diagram generated from their corresponding structure files and the number of amino acids in the embedding generated from their original amino acid sequences. This discrepancy arises from variations in the representation of the protein structure and the raw amino acid sequence, potentially impacting the analysis and interpretation of the data. At this time, the amino acid embedding of the protein cannot correspond to the amino acids in the contact map, and the amino acid vertices in the diagram generated by the contact diagram cannot obtain the corresponding amino acid expression, so that the subsequent extraction of protein structure features cannot be carried out. Therefore, we only selected proteins and peptides whose amino acid numbers in the contact chart matched their original amino acid numbers. As shown in <xref rid="btae708-T1" ref-type="table">Table&#x000a0;1</xref>, there were 9594 pairs of positive peptide-protein complex samples and 9593 pairs of negative samples, including 14&#x000a0;374 types of valid proteins and 9594 valid peptides.</p><table-wrap position="float" id="btae708-T1"><label>Table 1.</label><caption><p>Dataset statistics.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Name</th><th rowspan="1" colspan="1">Total number of samples</th><th rowspan="1" colspan="1">Types of protein</th><th rowspan="1" colspan="1">Types of peptide</th><th rowspan="1" colspan="1">Positive samples</th><th rowspan="1" colspan="1">Negative samples</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Protein-peptide dataset</td><td rowspan="1" colspan="1">19&#x000a0;187</td><td rowspan="1" colspan="1">14&#x000a0;374</td><td rowspan="1" colspan="1">9594</td><td rowspan="1" colspan="1">9594</td><td rowspan="1" colspan="1">9593</td></tr></tbody></table></table-wrap></sec><sec><title>3.2 Evaluation on sequence coding strategy</title><p>To verify the robustness of the sequence coding method used in this study, a set of comparative tests was designed. The comparison of the ProtT5_XL_half_UniRef50-enc coding method with SeqVec (<xref rid="btae708-B14" ref-type="bibr">Heinzinger <italic toggle="yes">et al.</italic> 2019</xref>), ProtXLNet, and ProtBert-BFD (<xref rid="btae708-B8" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> 2022</xref>). To ensure the reliability of this experiment, the sequence coding strategy was controlled as the sole variable. The model architecture used in this experiment is TPepPro. Our data experiments compared the dataset consists of protein-peptide complex that sourced from Propedia v2.3. As shown in <xref rid="btae708-F4" ref-type="fig">Fig.&#x000a0;4</xref>, model ProtT5_XL_half_UniRef50-enc we used here ranked the first in all evaluate parameter. The robustness of ProtT5_XL_half_UniRef50-enc coding method has been justified.</p><fig position="float" id="btae708-F4"><label>Figure 4.</label><caption><p>Evaluation of different sequence coding methods. The horizontal axis represents statistical parameters of model accuracy. Colors represent different models. The vertical axis values represent scores obtained by different models for evaluation.</p></caption><graphic xlink:href="btae708f4" position="float"/></fig></sec><sec><title>3.3 Evaluation on structural featuring strategy</title><p>To showcase the advantages of the graph CNN employed in this study for extracting protein structural features, we conducted a series of comparative experiments. The other graph CNNs used for this purpose include GAT (<xref rid="btae708-B43" ref-type="bibr">Veli&#x0010d;kovi&#x00107; <italic toggle="yes">et al.</italic> 2018</xref>), APPNP (<xref rid="btae708-B10" ref-type="bibr">Gasteiger <italic toggle="yes">et al.</italic> 2022</xref>), and GATV2 (<xref rid="btae708-B2" ref-type="bibr">Brody <italic toggle="yes">et al.</italic> 2022</xref>), alongside the TAGCN (<xref rid="btae708-B7" ref-type="bibr">Du <italic toggle="yes">et al.</italic> 2018</xref>) utilized in this research (where the graph CNN for protein structural feature extraction is a single layer).</p><p>Utilizing the same dataset (protein-peptide complex), we employed TPepPro for predictive modeling and facilitated direct comparative analysis. As shown in <xref rid="btae708-F5" ref-type="fig">Fig.&#x000a0;5</xref>, the prediction accuracy achieved by GAT for extracting protein structural features is 0.841, while that of APPNP stands at 0.826, and for GATV2 it is 0.844. Our TPepPro method yields the highest prediction accuracy of 0.855, highlighting its efficacy in extracting protein structural features.</p><fig position="float" id="btae708-F5"><label>Figure 5.</label><caption><p>Evaluation of different methods for extracting protein structural features. The figure legend is the same as <xref rid="btae708-F4" ref-type="fig">Fig.&#x000a0;4</xref>.</p></caption><graphic xlink:href="btae708f5" position="float"/></fig></sec><sec><title>3.4 Optimizing architecture of structural featuring neural network</title><p>In this study, the BN function and ReLU were used to reduce the overfitting of the model. Therefore, in this section, comparative experiments were conducted to compare with other functions: ReLU-Dropout, ReLU-BN, and BN_ReLU. The results, as depicted in <xref rid="btae708-F6" ref-type="fig">Fig.&#x000a0;6</xref>, show that the BN-ReLU combination achieved the best performance.</p><fig position="float" id="btae708-F6"><label>Figure 6.</label><caption><p>The combination of the Dropout/BN function and the ReLU function is used to evaluate the model performance sequentially.</p></caption><graphic xlink:href="btae708f6" position="float"/></fig></sec><sec><title>3.5 Comparison with state-of-the-art methods</title><p>The baseline method was outperformed by the TPepPro model in binary interaction prediction. TPepPro focuses primarily on the binary classification of whether query peptide and the receptor protein interact with each other or not. In this study, the classification performance of TPepPro was compared with other state-of-the-art baseline methods, including the TAGPPI model based on deep learning using local sequence features and structural features of proteins for predicting PPIs (<xref rid="btae708-B38" ref-type="bibr">Song <italic toggle="yes">et al.</italic> 2022</xref>) the PIPR model based on deep learning for PPI prediction, and a Siamese Convolutional Neural Network (SCNN) model that excludes GRUs from PIPR (<xref rid="btae708-B3" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2019</xref>). All prediction methods were evaluated on a benchmark dataset, with the four models assessed on the protein-peptide complex dataset (<xref rid="btae708-B25" ref-type="bibr">Lei <italic toggle="yes">et al.</italic> 2021</xref>). As indicated in <xref rid="btae708-T2" ref-type="table">Table&#x000a0;2</xref>, the TPepPro model achieved higher accuracy and AUC values for predicting PepPIs compared to the TAGPPI model (<xref rid="btae708-B38" ref-type="bibr">Song <italic toggle="yes">et al.</italic> 2022</xref>).</p><table-wrap position="float" id="btae708-T2"><label>Table 2.</label><caption><p>Comparison of TPepPro model with three other models on protein-peptide complex datasets.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Model</th><th rowspan="1" colspan="1">Accuracy</th><th rowspan="1" colspan="1">Precision</th><th rowspan="1" colspan="1">Recall</th><th rowspan="1" colspan="1">Specificity</th><th rowspan="1" colspan="1">F1-score</th><th rowspan="1" colspan="1">AUC</th><th rowspan="1" colspan="1">AUPRC</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">PIPR</td><td rowspan="1" colspan="1">0.755</td><td rowspan="1" colspan="1">0.741</td><td rowspan="1" colspan="1">0.785</td><td rowspan="1" colspan="1">0.771</td><td rowspan="1" colspan="1">0.762</td><td rowspan="1" colspan="1">0.816</td><td rowspan="1" colspan="1">0.785</td></tr><tr><td rowspan="1" colspan="1">SCNN</td><td rowspan="1" colspan="1">0.729</td><td rowspan="1" colspan="1">0.722</td><td rowspan="1" colspan="1">0.745</td><td rowspan="1" colspan="1">0.737</td><td rowspan="1" colspan="1">0.734</td><td rowspan="1" colspan="1">0.790</td><td rowspan="1" colspan="1">0.753</td></tr><tr><td rowspan="1" colspan="1">TAGPPI</td><td rowspan="1" colspan="1">0.774</td><td rowspan="1" colspan="1">0.751</td><td rowspan="1" colspan="1">0.824</td><td rowspan="1" colspan="1">0.724</td><td rowspan="1" colspan="1">0.785</td><td rowspan="1" colspan="1">0.844</td><td rowspan="1" colspan="1">0.819</td></tr><tr><td rowspan="1" colspan="1">TPepPro (ours)</td><td rowspan="1" colspan="1">
<bold>0.855</bold>
</td><td rowspan="1" colspan="1">
<bold>0.836</bold>
</td><td rowspan="1" colspan="1">
<bold>0.884</bold>
</td><td rowspan="1" colspan="1">
<bold>0.827</bold>
</td><td rowspan="1" colspan="1">
<bold>0.859</bold>
</td><td rowspan="1" colspan="1">
<bold>0.922</bold>
</td><td rowspan="1" colspan="1">
<bold>0.909</bold>
</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p>Note: Bold font indicates the best result in the column.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>3.6 ROC curve and PR curve of various datasets with different methods</title><p>We compared the performance of four models, PIPR, SCNN, TAGPPI, and TPepPro. In multiple datasets, encompassing protein-peptide complex, human, yeast, HIV-human protein, and SARS-CoV-2-human protein datasets. Five-fold cross-validation was executed on each dataset, and the predictions from the five test sets generated for each model were aggregated. Subsequently, ROC (Receiver Operating Characteristic) curves and P-R (Precision-Recall) curves were generated for each dataset. To better illustrate the improvement in the performance of TPepPro by comparing it with other methods, the five datasets were divided into two groups to represent two different situations (<xref rid="btae708-F7" ref-type="fig">Fig.&#x000a0;7</xref>). The first situation is exemplified by the yeast dataset, where existing models already perform well, with a mean AUC of 0.990 among the three existing models. TPepPro still ranks highly with an AUC of 0.994. Similar results were observed in the human Protein dataset and the HIV-human dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). The other situation involves datasets where existing models perform unsatisfactorily in predicting PepPIs yet show great improvement with TPepPro. These datasets include the Propedia protein-peptide complex and the SARS-CoV-2-human protein datasets (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>). From the ROC and PR curves, we found superior overall performance of TPepPro model exhibits in prediction across all five datasets as compared to the other three models.</p><fig position="float" id="btae708-F7"><label>Figure 7.</label><caption><p>ROC curves and P-R curves of datasets. Curves of yeast dataset represent datasets that already have good performance in other methods. Curves protein-peptide complex dataset represents the pattern of datasets that do not have satisfying performance in other methods, yet greatly improved by TPepPro.</p></caption><graphic xlink:href="btae708f7" position="float"/></fig></sec><sec><title>3.7 Evaluation TPepPro performance on multiple datasets</title><p>To validate the applicability of TPepPro in other datasets, we conducted additional evaluations using human, yeast, and virus-human protein datasets. Such evaluations help us gain a more comprehensive understanding of TPepPro performance and its applicability cross different organisms. For evaluation of different models on these diverse datasets, we can more accurately evaluate their capabilities and accuracy, thereby facilitating its better application in real-world scenarios.</p><p>
<xref rid="btae708-T3 btae708-T4 btae708-T5 btae708-T6" ref-type="table">Tables&#x000a0;3&#x02013;6</xref> correspond to the experimental testing of TPepPro and other methods using human proteins, yeast, HIV-human proteins, and SARS-CoV-2-human protein datasets, respectively. From the experimental results, we conclude that TPepPro not only performs better on the protein-peptide complex dataset but also exhibits significantly better prediction performance compared to other models. This pattern is repeated on all five datasets. This indicates that TPepPro can achieve excellent prediction from multiple datasets, and further displays its reliability.</p><table-wrap position="float" id="btae708-T3"><label>Table 3.</label><caption><p>Comparison of TPepPro with three other models on human datasets.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Model</th><th rowspan="1" colspan="1">Accuracy</th><th rowspan="1" colspan="1">Precision</th><th rowspan="1" colspan="1">Recall</th><th rowspan="1" colspan="1">Specificity</th><th rowspan="1" colspan="1">F1-score</th><th rowspan="1" colspan="1">AUC</th><th rowspan="1" colspan="1">AUPRC</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">PIPR</td><td rowspan="1" colspan="1">0.849</td><td rowspan="1" colspan="1">0.860</td><td rowspan="1" colspan="1">0.833</td><td rowspan="1" colspan="1">0.839</td><td rowspan="1" colspan="1">0.847</td><td rowspan="1" colspan="1">0.941</td><td rowspan="1" colspan="1">0.933</td></tr><tr><td rowspan="1" colspan="1">SCNN</td><td rowspan="1" colspan="1">0.937</td><td rowspan="1" colspan="1">0.927</td><td rowspan="1" colspan="1">0.948</td><td rowspan="1" colspan="1">
<bold>0.947</bold>
</td><td rowspan="1" colspan="1">0.937</td><td rowspan="1" colspan="1">0.983</td><td rowspan="1" colspan="1">0.981</td></tr><tr><td rowspan="1" colspan="1">TAGPPI</td><td rowspan="1" colspan="1">0.937</td><td rowspan="1" colspan="1">0.923</td><td rowspan="1" colspan="1">
<bold>0.953</bold>
</td><td rowspan="1" colspan="1">0.920</td><td rowspan="1" colspan="1">0.938</td><td rowspan="1" colspan="1">0.980</td><td rowspan="1" colspan="1">0.978</td></tr><tr><td rowspan="1" colspan="1">TPepPro (ours)</td><td rowspan="1" colspan="1">
<bold>0.947</bold>
</td><td rowspan="1" colspan="1">
<bold>0.943</bold>
</td><td rowspan="1" colspan="1">
<bold>0.953</bold>
</td><td rowspan="1" colspan="1">0.941</td><td rowspan="1" colspan="1">
<bold>0.948</bold>
</td><td rowspan="1" colspan="1">
<bold>0.988</bold>
</td><td rowspan="1" colspan="1">
<bold>0.989</bold>
</td></tr></tbody></table><table-wrap-foot><fn id="tblfn2"><p>Note: Bold font indicates the best result in the column.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="btae708-T4"><label>Table 4</label><caption><p>Comparison of TPepPro with three other models on yeast datasets.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Model</th><th rowspan="1" colspan="1">Accuracy</th><th rowspan="1" colspan="1">Precision</th><th rowspan="1" colspan="1">Recall</th><th rowspan="1" colspan="1">Specificity</th><th rowspan="1" colspan="1">F1-score</th><th rowspan="1" colspan="1">AUC</th><th rowspan="1" colspan="1">AUPRC</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">PIPR</td><td rowspan="1" colspan="1">0.966</td><td rowspan="1" colspan="1">0.960</td><td rowspan="1" colspan="1">0.973</td><td rowspan="1" colspan="1">0.973</td><td rowspan="1" colspan="1">0.966</td><td rowspan="1" colspan="1">0.988</td><td rowspan="1" colspan="1">0.986</td></tr><tr><td rowspan="1" colspan="1">SCNN</td><td rowspan="1" colspan="1">0.958</td><td rowspan="1" colspan="1">0.963</td><td rowspan="1" colspan="1">0.952</td><td rowspan="1" colspan="1">0.952</td><td rowspan="1" colspan="1">0.957</td><td rowspan="1" colspan="1">0.988</td><td rowspan="1" colspan="1">0.986</td></tr><tr><td rowspan="1" colspan="1">TAGPPI</td><td rowspan="1" colspan="1">0.971</td><td rowspan="1" colspan="1">0.973</td><td rowspan="1" colspan="1">0.968</td><td rowspan="1" colspan="1">0.973</td><td rowspan="1" colspan="1">0.970</td><td rowspan="1" colspan="1">0.993</td><td rowspan="1" colspan="1">0.994</td></tr><tr><td rowspan="1" colspan="1">TPepPro (ours)</td><td rowspan="1" colspan="1">
<bold>0.979</bold>
</td><td rowspan="1" colspan="1">
<bold>0.981</bold>
</td><td rowspan="1" colspan="1">
<bold>0.978</bold>
</td><td rowspan="1" colspan="1">
<bold>0.981</bold>
</td><td rowspan="1" colspan="1">
<bold>0.979</bold>
</td><td rowspan="1" colspan="1">
<bold>0.994</bold>
</td><td rowspan="1" colspan="1">
<bold>0.994</bold>
</td></tr></tbody></table><table-wrap-foot><fn id="tblfn3"><p>Note: Bold font indicates the best result in the column.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="btae708-T5"><label>Table 5.</label><caption><p>Comparison of TPepPro with three other models on HIV-human protein datasets.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Model</th><th rowspan="1" colspan="1">Accuracy</th><th rowspan="1" colspan="1">Precision</th><th rowspan="1" colspan="1">Recall</th><th rowspan="1" colspan="1">Specificity</th><th rowspan="1" colspan="1">F1-score</th><th rowspan="1" colspan="1">AUC</th><th rowspan="1" colspan="1">AUPRC</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">PIPR</td><td rowspan="1" colspan="1">0.867</td><td rowspan="1" colspan="1">0.863</td><td rowspan="1" colspan="1">0.872</td><td rowspan="1" colspan="1">0.871</td><td rowspan="1" colspan="1">0.867</td><td rowspan="1" colspan="1">0.906</td><td rowspan="1" colspan="1">0.899</td></tr><tr><td rowspan="1" colspan="1">SCNN</td><td rowspan="1" colspan="1">0.875</td><td rowspan="1" colspan="1">0.886</td><td rowspan="1" colspan="1">0.861</td><td rowspan="1" colspan="1">0.865</td><td rowspan="1" colspan="1">0.873</td><td rowspan="1" colspan="1">0.933</td><td rowspan="1" colspan="1">0.935</td></tr><tr><td rowspan="1" colspan="1">TAGPPI</td><td rowspan="1" colspan="1">0.877</td><td rowspan="1" colspan="1">0.878</td><td rowspan="1" colspan="1">0.877</td><td rowspan="1" colspan="1">0.877</td><td rowspan="1" colspan="1">0.877</td><td rowspan="1" colspan="1">0.944</td><td rowspan="1" colspan="1">0.945</td></tr><tr><td rowspan="1" colspan="1">TPepPro (ours)</td><td rowspan="1" colspan="1">
<bold>0.891</bold>
</td><td rowspan="1" colspan="1">
<bold>0.886</bold>
</td><td rowspan="1" colspan="1">
<bold>0.897</bold>
</td><td rowspan="1" colspan="1">
<bold>0.884</bold>
</td><td rowspan="1" colspan="1">
<bold>0.891</bold>
</td><td rowspan="1" colspan="1">
<bold>0.956</bold>
</td><td rowspan="1" colspan="1">
<bold>0.954</bold>
</td></tr></tbody></table><table-wrap-foot><fn id="tblfn4"><p>Note: Bold font indicates the best result in the column.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="btae708-T6"><label>Table 6.</label><caption><p>Comparison of TPepPro with three other models on SARS-CoV-2-human protein datasets.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Model</th><th rowspan="1" colspan="1">Accuracy</th><th rowspan="1" colspan="1">Precision</th><th rowspan="1" colspan="1">Recall</th><th rowspan="1" colspan="1">Specificity</th><th rowspan="1" colspan="1">F1-score</th><th rowspan="1" colspan="1">AUC</th><th rowspan="1" colspan="1">AUPRC</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">PIPR</td><td rowspan="1" colspan="1">0.663</td><td rowspan="1" colspan="1">0.662</td><td rowspan="1" colspan="1">0.667</td><td rowspan="1" colspan="1">0.665</td><td rowspan="1" colspan="1">0.664</td><td rowspan="1" colspan="1">0.679</td><td rowspan="1" colspan="1">0.649</td></tr><tr><td rowspan="1" colspan="1">SCNN</td><td rowspan="1" colspan="1">0.671</td><td rowspan="1" colspan="1">0.666</td><td rowspan="1" colspan="1">0.683</td><td rowspan="1" colspan="1">0.675</td><td rowspan="1" colspan="1">0.674</td><td rowspan="1" colspan="1">0.717</td><td rowspan="1" colspan="1">0.685</td></tr><tr><td rowspan="1" colspan="1">TAGPPI</td><td rowspan="1" colspan="1">0.703</td><td rowspan="1" colspan="1">0.692</td><td rowspan="1" colspan="1">0.738</td><td rowspan="1" colspan="1">0.667</td><td rowspan="1" colspan="1">0.713</td><td rowspan="1" colspan="1">0.776</td><td rowspan="1" colspan="1">0.742</td></tr><tr><td rowspan="1" colspan="1">TPepPro (ours)</td><td rowspan="1" colspan="1">
<bold>0.747</bold>
</td><td rowspan="1" colspan="1">
<bold>0.733</bold>
</td><td rowspan="1" colspan="1">
<bold>0.807</bold>
</td><td rowspan="1" colspan="1">
<bold>0.687</bold>
</td><td rowspan="1" colspan="1">
<bold>0.759</bold>
</td><td rowspan="1" colspan="1">
<bold>0.833</bold>
</td><td rowspan="1" colspan="1">
<bold>0.821</bold>
</td></tr></tbody></table><table-wrap-foot><fn id="tblfn5"><p>Note: Bold font indicates the best result in the column.</p></fn></table-wrap-foot></table-wrap><p>In addition, the AUCs obtained from the five datasets differ from those in the ROC curves. This is because the TAGPPI and TPepPro models calculate the AUCs separately for each fold using the predicted fold, and then sums these AUCs. Their average is treated as the final AUC value. However, the AUCs calculated for ROC curves are obtained by combining the predictions of the five testing sets before computation. In contrast, the AUCs in the tables from the PIPR and SCNN models are the same as those obtained in the ROC curves because their AUCs also use the same approaches, i.e. combined predictions of the five sets before evaluation.</p><p>Furthermore, four times of 5-fold cross-validations have been performed to increase the reliability of the tests. The results from each round of the validation are remarkably similar cross each fold. Moreover, the mean value of each evaluation parameter is very close to each other as well (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref>). This data indicates the stability and reliability of the TPepPro model.</p></sec><sec><title>3.8 Interpretability analysis</title><p>The protein structures extracted using TAGCN were analyzed for interpretability of key global features. Taking peptides 3eyu_Q, 1a1m_C, and protein P62861 as an example. The node importance scores of each protein or peptide are shown in <xref rid="btae708-F8" ref-type="fig">Fig.&#x000a0;8</xref>. The first amino acid E and the last amino acid A in 3eyu_Q, the first amino acid T in 1a1m_C and the seventh amino acid A in Protein P62861 show its importance in their respective sequences. This result represents a high potential for these amino acid sites that are likely to become peptide-protein binding sites.</p><fig position="float" id="btae708-F8"><label>Figure 8.</label><caption><p>Heatmap of residue importance scores for global features of protein structures extracted by TAGCN.</p></caption><graphic xlink:href="btae708f8" position="float"/></fig><p>The TextCNN module extracts protein local sequence features from high-dimensional protein global features that have been encoded by the attention based ProtTrans model. Therefore, TextCNN lacks a direct attention mechanism to retrieve specific positions of the input sequences for interpretability analysis of protein local sequence features extracted by TextCNN. Therefore, the importance scores corresponding to specific amino acids cannot be derived. Here, we visualize the input vectors after passing through the first convolutional layer instead. This is because the data representations in post-first convolution establish a more intuitive connection with the original input data. Using the P0DTC2 and P62861 proteins as examples, the top 20 absolute values of activation values correspond to the activation maps shown in <xref rid="btae708-F9" ref-type="fig">Fig.&#x000a0;9</xref>. The darker the color and the further left the position in the ranking, the higher the absolute value of the Activation Value. The red bars indicate positions with high Activation Values, suggesting a greater potential for these sites to serve as binding sites for PepPIs. Conversely, the more purple the color and the further left the ranking of the bars, the smaller the Activation Value, indicating that these positions are relatively conserved and less likely to become interaction binding sites.</p><fig position="float" id="btae708-F9"><label>Figure 9.</label><caption><p>Activation map of local features of protein sequences extracted by TextCNN of protein P0DTC2 and P62861.</p></caption><graphic xlink:href="btae708f9" position="float"/></fig></sec><sec><title>3.9 TPepPro can find valid new interactions</title><p>From the predictions, we found 1662 pairs of new PepPIs that are not present in the input dataset before (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>). The output of the TPepPro model contains two confidence values, which respectively refer the extent to which the model supports the presence (positive confidence value) or absence (negative confidence value) of interactions between sample pairs. Sixty-nine of them were found to have a positive confidence value greater than or equal to 0.99999, and more than 43% belong to humans. <italic toggle="yes">Homo sapiens</italic> was chosen as the organism for case studies for both peptide and protein, as we aim to find biologically meaningful evidence. However, the pairs involving to different species, including interactions between humans and various viruses or bacteria, are also present in the predictions and are worthy of investigation.</p><p>To validate the efficacy of the model and assess the practical biological relevance of the predicted outcomes, extensive research was conducted on the predicted results. Utilizing our custom-built package named TPepPro-filter for screening, 11 pairs of newly discovered high-confidence PepPIs were extracted. Their original label in the database was 0 (no interaction) and the predicted label was 1 (interaction exits). They all belong to <italic toggle="yes">H.sapiens</italic> with a confidence level greater than or equal to 0.99999 (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>). Docking for each pair was carried out by ClusPro 2.0 to predict the interaction structure (<xref rid="btae708-B23" ref-type="bibr">Kozakov <italic toggle="yes">et al.</italic> 2017</xref>). All those 11 pairs were predicted to exhibit interaction. Docking results can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material S4</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>.</p><p>The dataset used in this study is Propedia v2.3, which collected published PepPIs from the Protein Data Bank on 15 November 2022. Therefore, the so-called new interactions here include those not recorded in Propedia, as well as truly novel interactions. Two cases of the former were found through extensive database searching and literature research. The two pairs of interactions were validated with experimental evidence (<xref rid="btae708-T7" ref-type="table">Table&#x000a0;7</xref>). At the same time, both pairs are ranked the highest positive confidence value among all human samples.</p><table-wrap position="float" id="btae708-T7"><label>Table 7.</label><caption><p>Predicted new interactions which have experimental evidence.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="center" span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Receptor</th><th rowspan="1" colspan="1">Peptide</th><th rowspan="1" colspan="1">Class_label</th><th rowspan="1" colspan="1">Confidence_positive</th><th rowspan="1" colspan="1">Predicted_label</th><th rowspan="1" colspan="1">Receptor Gene</th><th rowspan="1" colspan="1">Peptide Gene</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">6v13_B</td><td rowspan="1" colspan="1">4ov5_L</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">0.999999404</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">HLA-DRB1</td><td rowspan="1" colspan="1">HLA-A</td></tr><tr><td rowspan="1" colspan="1">3r85_B</td><td rowspan="1" colspan="1">7m5c_B</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">0.999998212</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">BCL2L</td><td rowspan="1" colspan="1">BAK</td></tr></tbody></table></table-wrap><p>The first pair of interaction 6v13_B (PDB ID of HLA-DRB1) and 4ov5_L (HLA-A) was proved by Affinity Capture-Mass Spectrometry experiment, which originated from a pre-published dataset from Steve Huttlin <italic toggle="yes">et al.</italic> at Harvard Medical School (<xref rid="btae708-B17" ref-type="bibr">Huttlin <italic toggle="yes">et al.</italic> 2015</xref>). The second pair of experimentally confirmed interactions was between 3r85_B (BCL2L1) and 7m5c_B (BAK), which was more extensively reported. According to the database BioGRID 4.4 (<xref rid="btae708-B31" ref-type="bibr">Oughtred <italic toggle="yes">et al.</italic> 2021</xref>), there were 6 high-throughput and 10 low-throughput experimental evidences of the interaction between BCL2L1 and BAK (<xref rid="btae708-B11" ref-type="bibr">Griffiths <italic toggle="yes">et al.</italic> 1999</xref>, <xref rid="btae708-B6" ref-type="bibr">Degterev <italic toggle="yes">et al.</italic> 2001</xref>, <xref rid="btae708-B53" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2002</xref>, <xref rid="btae708-B46" ref-type="bibr">Whitfield <italic toggle="yes">et al.</italic> 2003</xref>, <xref rid="btae708-B34" ref-type="bibr">Rual <italic toggle="yes">et al.</italic> 2005</xref>, <xref rid="btae708-B47" ref-type="bibr">Willis <italic toggle="yes">et al.</italic> 2005</xref>, <xref rid="btae708-B44" ref-type="bibr">Venkatesan <italic toggle="yes">et al.</italic> 2009</xref>, <xref rid="btae708-B35" ref-type="bibr">Rudner <italic toggle="yes">et al.</italic> 2011</xref>, <xref rid="btae708-B41" ref-type="bibr">Trepte <italic toggle="yes">et al.</italic> 2015</xref>, <xref rid="btae708-B42" ref-type="bibr">Trepte <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae708-B13" ref-type="bibr">He <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae708-B29" ref-type="bibr">Luck <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae708-B16" ref-type="bibr">Huttlin <italic toggle="yes">et al.</italic> 2021</xref>, <xref rid="btae708-B26" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2021</xref>). Detailed experiments include Affinity Capture-Luminescence, Affinity Capture-Mass Spectrometry, Affinity Capture Western Blotting, Fluorescence Resonance Energy Transfer, PepPIs, Reconstituted Complex Assay, and Two-Hybrid Assay. Moreover, evidence of BCL2L2-BAK interaction was found as well, including two high-throughput experimental test using Two-Hybrid Assay (<xref rid="btae708-B15" ref-type="bibr">Holmgreen <italic toggle="yes">et al.</italic> 1999</xref>, <xref rid="btae708-B21" ref-type="bibr">Kim <italic toggle="yes">et al.</italic> 2014</xref>) and two high-throughput experiment using Affinity Capture-Western (<xref rid="btae708-B33" ref-type="bibr">Rolland <italic toggle="yes">et al.</italic> 2014</xref>, <xref rid="btae708-B29" ref-type="bibr">Luck <italic toggle="yes">et al.</italic> 2020</xref>).</p><p>The two validated pairs provide evidence to support the effectiveness of our predictive model. The remaining nine pairs have all passed the docking test, demonstrating a wide range/scope of potential interactions that have yet to be experimentally detected. Interestingly, four pairs in the results showed no interaction in the initial dataset (original label was 0), yet TPepPro predicted their existence with 100% confidence (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref> Sheet2). It is worth noting that the first pair involves human protein and peptide from <italic toggle="yes">Saccharomyces cerevisiae</italic>, and the fourth pair involves T4 bacteriophage and human. Therefore, the two pairs of novel interactions predicted by TPepPro hold the potential for further biological validation.</p></sec></sec><sec><title>4 Discussion and conclusion</title><p>A Transformer-based module was utilized in TPepPro for data preprocessing. Convolutional structures were employed to simultaneously extract features from amino acid sequences and contact maps describing the spatial structure of proteins. Additionally, an overfitting prevention method, Batch Normalization, was applied in the prediction part of the model for PepPIs prediction. It was proved that the performance could be improved by replacing the Dropout function with BN. The model architecture in TPepPro improves the accuracy by 8.1% in predicting PepPIs, as compared with the second-best model TAGPPI.</p><p>It is noticed that although machine learning techniques possess powerful computational capabilities, the authenticity of <italic toggle="yes">in silico</italic> prediction has been under considerable debate. Identification of potential PepPIs is inherently complex and challenging. In our study, TPepPro model displays its effectiveness in discovery of novel PepPIs that have been experimentally validated. A total of 17 experimental evidence were reported to support the accuracy of TPepPro system. Therefore, TPepPro not only outperforms previously published models in terms of accuracy, AUC, and other statistical metrices, but it also demonstrates experimental feasibility.</p><p>The interpretability analysis of the key global features extracted by TAGCN reveals amino acids with strong feature importance, such as first amino acid E in 3eyu_Q. This finding is significant for predicting peptide-protein binding sites. Similar feature importance is also observed in the local sequence features of TextCNN. Unfortunately, the dimensionality reduction performed by the convolutional layers hampers the mapping back to the original amino acid sequences. However, mapping the activation values back to the original amino acids would provide substantial biological insights. Ultimately, the models we explore will relate back to biological questions regarding active and contact sites between peptides and proteins. Identifying amino acids with the highest potential to become binding sites, along with relatively conserved amino acid positions, will be meaningful for studying protein-protein, protein-peptide, and peptide-peptide interactions. Therefore, in the future, we will develop methods for extracting local sequence features of proteins that can be traced back to amino acids. We aim to conduct a detailed interpretability analysis of both local features of protein sequences and global features of protein structures.</p><p>Furthermore, the PepPI model can be applied in drug research. Researchers have implemented the pre-trained TPepPro model on drug-target datasets. The resulting drug-target interaction prediction model will possess the capability to uncover novel interactions, to predict binding affinities, and to identify potential drug candidates with high specificity. By leveraging these capabilities, we can enhance the efficiency of drug discovery processes and pave the way for targeted therapies.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data"><label>btae708_Supplementary_Data</label><media xlink:href="btae708_supplementary_data.zip"/></supplementary-material></sec></body><back><sec><title>Supplementary data</title><p>
<xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p><p>Conflict of interest: The authors declare no competing interests.</p></sec><sec><title>Funding</title><p>The study was funded by collaborative research fund of Hong Kong General Research Fund (C7015-23G), seed fundings for collaborative research (2207101590) and basic research (2201101499) from the University of Hong Kong, and startup funds [207051059, 6010309] from Faculty of Dentistry, the University of Hong Kong to J.W.</p></sec><sec sec-type="data-availability"><title>Data availability</title><p>Source code of model TPepPro is available at: <ext-link xlink:href="https://github.com/wanglabhku/TPepPro" ext-link-type="uri">https://github.com/wanglabhku/TPepPro</ext-link>. A package to manipulate TPepPro output files is available at <ext-link xlink:href="https://github.com/wanglabhku/TPepProfilter" ext-link-type="uri">https://github.com/wanglabhku/TPepPro filter</ext-link>. The TPepPro-filter package allows users to filter results based on specific confidence thresholds and desired combinations of species. The datasets used in this research were sourced from a peptide-protein interactions database located at: <ext-link xlink:href="http://bioinfo.dcc.ufmg.br/propedia2/index.php/download" ext-link-type="uri">http://bioinfo.dcc.ufmg.br/propedia2/index.php/download</ext-link>.</p></sec><ref-list id="ref1"><title>References</title><ref id="btae708-B1"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ballester</surname>
<given-names>PJ</given-names>
</string-name>, <string-name><surname>Mitchell</surname><given-names>JBO.</given-names></string-name></person-group>
<article-title>A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking</article-title>. <source>Bioinformatics</source><year>2010</year>;<volume>26</volume>:<fpage>1169</fpage>&#x02013;<lpage>75</lpage>.<pub-id pub-id-type="pmid">20236947</pub-id>
</mixed-citation></ref><ref id="btae708-B2"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Brody</surname>
<given-names>S, Alon U, Yahav E.</given-names>
</string-name>
</person-group> How attentive are graph attention networks? arXiv, <pub-id pub-id-type="doi">10.48550/arXiv.2105.14491,</pub-id> 2022, preprint: not peer reviewed.</mixed-citation></ref><ref id="btae708-B3"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Chen</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Ju</surname><given-names>CJ-T</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>G</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Multifaceted protein-protein interaction prediction based on Siamese residual RCNN</article-title>. <source>Bioinformatics</source><year>2019</year>;<volume>35</volume>:<fpage>i305</fpage>&#x02013;<lpage>14</lpage>.<pub-id pub-id-type="pmid">31510705</pub-id>
</mixed-citation></ref><ref id="btae708-B4"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Cole</surname>
<given-names>JC</given-names>
</string-name>, <string-name><surname>Murray</surname><given-names>CW</given-names></string-name>, <string-name><surname>Nissink</surname><given-names>JWM</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Comparing protein-ligand docking programs is difficult</article-title>. <source>Proteins</source><year>2005</year>;<volume>60</volume>:<fpage>325</fpage>&#x02013;<lpage>32</lpage>.<pub-id pub-id-type="pmid">15937897</pub-id>
</mixed-citation></ref><ref id="btae708-B5"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Cunningham</surname>
<given-names>JM</given-names>
</string-name>, <string-name><surname>Koytiger</surname><given-names>G</given-names></string-name>, <string-name><surname>Sorger</surname><given-names>PK</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Biophysical prediction of protein&#x02013;peptide interactions and signaling networks using machine learning</article-title>. <source>Nat Methods</source><year>2020</year>;<volume>17</volume>:<fpage>175</fpage>&#x02013;<lpage>83</lpage>.<pub-id pub-id-type="pmid">31907444</pub-id>
</mixed-citation></ref><ref id="btae708-B6"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Degterev</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Lugovskoy</surname><given-names>A</given-names></string-name>, <string-name><surname>Cardone</surname><given-names>M</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Identification of small-molecule inhibitors of interaction between the BH3 domain and Bcl-xL</article-title>. <source>Nat Cell Biol</source><year>2001</year>;<volume>3</volume>:<fpage>173</fpage>&#x02013;<lpage>82</lpage>.<pub-id pub-id-type="pmid">11175750</pub-id>
</mixed-citation></ref><ref id="btae708-B7"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Du</surname>
<given-names>J, Zhang S, Wu G</given-names>
</string-name>
</person-group>
<etal>et al</etal> Topology adaptive graph convolutional networks. arXiv, <pub-id pub-id-type="doi">10.48550/arXiv.1710.10370,</pub-id> 2018, preprint: not peer reviewed.</mixed-citation></ref><ref id="btae708-B8"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Elnaggar</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Heinzinger</surname><given-names>M</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>ProtTrans: toward understanding the language of life through self-supervised learning</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source><year>2022</year>;<volume>44</volume>:<fpage>7112</fpage>&#x02013;<lpage>27</lpage>.<pub-id pub-id-type="pmid">34232869</pub-id>
</mixed-citation></ref><ref id="btae708-B9"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Garbin</surname>
<given-names>C</given-names>
</string-name>, <string-name><surname>Zhu</surname><given-names>X</given-names></string-name>, <string-name><surname>Marques</surname><given-names>O</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Dropout vs. batch normalization: an empirical study of their impact to deep learning</article-title>. <source>Multimed Tools Appl</source><year>2020</year>;<volume>79</volume>:<fpage>12777</fpage>&#x02013;<lpage>815</lpage>.</mixed-citation></ref><ref id="btae708-B10"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Gasteiger</surname>
<given-names>J, Bojchevski A, G&#x000fc;nnemann S.</given-names>
</string-name>
</person-group> Predict then propagate: graph neural networks meet personalized PageRank. arXiv, <pub-id pub-id-type="doi">10.48550/arXiv.1810.05997,</pub-id> 2022, preprint: not peer reviewed.</mixed-citation></ref><ref id="btae708-B11"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Griffiths</surname>
<given-names>GJ</given-names>
</string-name>, <string-name><surname>Dubrez</surname><given-names>L</given-names></string-name>, <string-name><surname>Morgan</surname><given-names>CP</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Cell damage-induced conformational changes of the pro-apoptotic protein bank in vivo precede the onset of apoptosis</article-title>. <source>J Cell Biol</source><year>1999</year>;<volume>144</volume>:<fpage>903</fpage>&#x02013;<lpage>14</lpage>.<pub-id pub-id-type="pmid">10085290</pub-id>
</mixed-citation></ref><ref id="btae708-B12"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hamelryck</surname>
<given-names>T</given-names>
</string-name>, <string-name><surname>Manderick</surname><given-names>B.</given-names></string-name></person-group>
<article-title>PDB file parser and structure class implemented in python</article-title>. <source>Bioinformatics</source><year>2003</year>;<volume>19</volume>:<fpage>2308</fpage>&#x02013;<lpage>10</lpage>.<pub-id pub-id-type="pmid">14630660</pub-id>
</mixed-citation></ref><ref id="btae708-B13"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>He</surname>
<given-names>Y</given-names>
</string-name>, <string-name><surname>Li</surname><given-names>W</given-names></string-name>, <string-name><surname>Lv</surname><given-names>D</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Inhibition of USP7 activity selectively eliminates senescent cells in part via restoration of p53 activity</article-title>. <source>Aging Cell</source><year>2020</year>;<volume>19</volume>:<fpage>e13117</fpage>.<pub-id pub-id-type="pmid">32064756</pub-id>
</mixed-citation></ref><ref id="btae708-B14"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Heinzinger</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Elnaggar</surname><given-names>A</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Modeling aspects of the language of life through transfer-learning protein sequences</article-title>. <source>BMC Bioinformatics</source><year>2019</year>;<volume>20</volume>:<fpage>723</fpage>.<pub-id pub-id-type="pmid">31847804</pub-id>
</mixed-citation></ref><ref id="btae708-B15"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Holmgreen</surname>
<given-names>SP</given-names>
</string-name>, <string-name><surname>Huang</surname><given-names>DC</given-names></string-name>, <string-name><surname>Adams</surname><given-names>JM</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Survival activity of Bcl-2 homologs Bcl-w and A1 only partially correlates with their ability to bind pro-apoptotic family members</article-title>. <source>Cell Death Differ</source><year>1999</year>;<volume>6</volume>:<fpage>525</fpage>&#x02013;<lpage>32</lpage>.<pub-id pub-id-type="pmid">10381646</pub-id>
</mixed-citation></ref><ref id="btae708-B16"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Huttlin</surname>
<given-names>EL</given-names>
</string-name>, <string-name><surname>Bruckner</surname><given-names>RJ</given-names></string-name>, <string-name><surname>Navarrete-Perea</surname><given-names>J</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Dual proteome-scale networks reveal cell-specific remodeling of the human interactome</article-title>. <source>Cell</source><year>2021</year>;<volume>184</volume>:<fpage>3022</fpage>&#x02013;<lpage>40.e28</lpage>.<pub-id pub-id-type="pmid">33961781</pub-id>
</mixed-citation></ref><ref id="btae708-B17"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Huttlin</surname>
<given-names>EL</given-names>
</string-name>, <string-name><surname>Ting</surname><given-names>L</given-names></string-name>, <string-name><surname>Bruckner</surname><given-names>RJ</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>The BioPlex network: a systematic exploration of the human interactome</article-title>. <source>Cell</source><year>2015</year>;<volume>162</volume>:<fpage>425</fpage>&#x02013;<lpage>40</lpage>.<pub-id pub-id-type="pmid">26186194</pub-id>
</mixed-citation></ref><ref id="btae708-B18"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Ioffe</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Szegedy</surname><given-names>C.</given-names></string-name></person-group> Batch normalization: accelerating deep network training by reducing internal covariate shift. arXiv, <pub-id pub-id-type="doi">10.48550/arXiv.1502.03167,</pub-id> 2015, preprint: not peer reviewed..</mixed-citation></ref><ref id="btae708-B19"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Johansson-&#x000c5;khe</surname>
<given-names>I</given-names>
</string-name>, <string-name><surname>Mirabello</surname><given-names>C</given-names></string-name>, <string-name><surname>Wallner</surname><given-names>B</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>InterPep2: global peptide-protein docking using interaction surface templates</article-title>. <source>Bioinformatics</source><year>2020</year>;<volume>36</volume>:<fpage>2458</fpage>&#x02013;<lpage>65</lpage>.<pub-id pub-id-type="pmid">31917413</pub-id>
</mixed-citation></ref><ref id="btae708-B20"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Keeble</surname>
<given-names>AH</given-names>
</string-name>, <string-name><surname>Turkki</surname><given-names>P</given-names></string-name>, <string-name><surname>Stokes</surname><given-names>S</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Approaching infinite affinity through engineering of peptide-protein interaction</article-title>. <source>Proc Natl Acad Sci USA</source><year>2019</year>;<volume>116</volume>:<fpage>26523</fpage>&#x02013;<lpage>33</lpage>.<pub-id pub-id-type="pmid">31822621</pub-id>
</mixed-citation></ref><ref id="btae708-B21"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Kim</surname>
<given-names>EM</given-names>
</string-name>, <string-name><surname>Park</surname><given-names>JK</given-names></string-name>, <string-name><surname>Hwang</surname><given-names>S-G</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Nuclear and cytoplasmic p53 suppress cell invasion by inhibiting respiratory complex-I activity via Bcl-2 family proteins</article-title>. <source>Oncotarget</source><year>2014</year>;<volume>5</volume>:<fpage>8452</fpage>&#x02013;<lpage>65</lpage>.<pub-id pub-id-type="pmid">25115399</pub-id>
</mixed-citation></ref><ref id="btae708-B22"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Kim</surname>
<given-names>Y.</given-names>
</string-name>
</person-group> Convolutional neural networks for sentence classification. In: <italic toggle="yes">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</italic>, <year>2014</year>, 1746&#x02013;51. <ext-link xlink:href="https://aclanthology.org/D14-1181" ext-link-type="uri">https://aclanthology.org/D14-1181</ext-link></mixed-citation></ref><ref id="btae708-B23"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Kozakov</surname>
<given-names>D</given-names>
</string-name>, <string-name><surname>Hall</surname><given-names>DR</given-names></string-name>, <string-name><surname>Xia</surname><given-names>B</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>The ClusPro web server for protein-protein docking</article-title>. <source>Nat Protoc</source><year>2017</year>;<volume>12</volume>:<fpage>255</fpage>&#x02013;<lpage>78</lpage>.<pub-id pub-id-type="pmid">28079879</pub-id>
</mixed-citation></ref><ref id="btae708-B24"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lee</surname>
<given-names>AC-L</given-names>
</string-name>, <string-name><surname>Harris</surname><given-names>JL</given-names></string-name>, <string-name><surname>Khanna</surname><given-names>KK</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>A comprehensive review on current advances in peptide drug development and design</article-title>. <source>Int J Mol Sci</source><year>2019</year>;<volume>20</volume>:<fpage>2383</fpage>.<pub-id pub-id-type="pmid">31091705</pub-id>
</mixed-citation></ref><ref id="btae708-B25"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lei</surname>
<given-names>Y</given-names>
</string-name>, <string-name><surname>Li</surname><given-names>S</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Z</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>A deep-learning framework for multi-level peptide&#x02013;protein interaction prediction</article-title>. <source>Nat Commun</source><year>2021</year>;<volume>12</volume>:<fpage>5465</fpage>.<pub-id pub-id-type="pmid">34526500</pub-id>
</mixed-citation></ref><ref id="btae708-B26"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname>
<given-names>W</given-names>
</string-name>, <string-name><surname>Ma</surname><given-names>Y</given-names></string-name>, <string-name><surname>He</surname><given-names>L</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Protease-activated receptor 2 stabilizes Bcl-xL and regulates EGFR-targeted therapy response in colorectal cancer</article-title>. <source>Cancer Lett</source><year>2021</year>;<volume>517</volume>:<fpage>14</fpage>&#x02013;<lpage>23</lpage>.<pub-id pub-id-type="pmid">34098062</pub-id>
</mixed-citation></ref><ref id="btae708-B27"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname>
<given-names>Z</given-names>
</string-name>, <string-name><surname>Huang</surname><given-names>R</given-names></string-name>, <string-name><surname>Xia</surname><given-names>M</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Fingerprinting interactions between proteins and ligands for facilitating machine learning in drug discovery</article-title>. <source>Biomolecules</source><year>2024</year>;<volume>14</volume>:<fpage>72</fpage>.<pub-id pub-id-type="pmid">38254672</pub-id>
</mixed-citation></ref><ref id="btae708-B28"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Liu</surname><given-names>C</given-names></string-name>, <string-name><surname>Deng</surname><given-names>L.</given-names></string-name></person-group>
<article-title>Machine learning approaches for protein&#x02212;protein interaction hot spot prediction: progress and comparative assessment</article-title>. <source>Molecules</source><year>2018</year>;<volume>23</volume>:<fpage>2535</fpage>.<pub-id pub-id-type="pmid">30287797</pub-id>
</mixed-citation></ref><ref id="btae708-B29"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Luck</surname>
<given-names>K</given-names>
</string-name>, <string-name><surname>Kim</surname><given-names>D-K</given-names></string-name>, <string-name><surname>Lambourne</surname><given-names>L</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>A reference map of the human binary protein interactome</article-title>. <source>Nature</source><year>2020</year>;<volume>580</volume>:<fpage>402</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">32296183</pub-id>
</mixed-citation></ref><ref id="btae708-B30"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Martins</surname>
<given-names>P</given-names>
</string-name>, <string-name><surname>Mariano</surname><given-names>D</given-names></string-name>, <string-name><surname>Carvalho</surname><given-names>FC</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Propedia v2.3: a novel representation approach for the peptide-protein interaction database using graph-based structural signatures</article-title>. <source>Front Bioinform</source><year>2023</year>;<volume>3</volume>:<fpage>1103103</fpage>.<pub-id pub-id-type="pmid">36875148</pub-id>
</mixed-citation></ref><ref id="btae708-B31"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Oughtred</surname>
<given-names>R</given-names>
</string-name>, <string-name><surname>Rust</surname><given-names>J</given-names></string-name>, <string-name><surname>Chang</surname><given-names>C</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>The BioGRID database: a comprehensive biomedical resource of curated protein, genetic, and chemical interactions</article-title>. <source>Protein Sci</source><year>2021</year>;<volume>30</volume>:<fpage>187</fpage>&#x02013;<lpage>200</lpage>.<pub-id pub-id-type="pmid">33070389</pub-id>
</mixed-citation></ref><ref id="btae708-B32"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ram&#x000ed;rez</surname>
<given-names>D</given-names>
</string-name>, <string-name><surname>Caballero</surname><given-names>J.</given-names></string-name></person-group>
<article-title>Is it reliable to use common molecular docking methods for comparing the binding affinities of enantiomer pairs for their protein target?</article-title>
<source>Int J Mol Sci</source>
<year>2016</year>;<volume>17</volume>:<fpage>525</fpage>.<pub-id pub-id-type="pmid">27104528</pub-id>
</mixed-citation></ref><ref id="btae708-B33"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Rolland</surname>
<given-names>T</given-names>
</string-name>, <string-name><surname>Ta&#x0015f;an</surname><given-names>M</given-names></string-name>, <string-name><surname>Charloteaux</surname><given-names>B</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>A proteome-scale map of the human interactome network</article-title>. <source>Cell</source><year>2014</year>;<volume>159</volume>:<fpage>1212</fpage>&#x02013;<lpage>26</lpage>.<pub-id pub-id-type="pmid">25416956</pub-id>
</mixed-citation></ref><ref id="btae708-B34"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Rual</surname>
<given-names>J-F</given-names>
</string-name>, <string-name><surname>Venkatesan</surname><given-names>K</given-names></string-name>, <string-name><surname>Hao</surname><given-names>T</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Towards a proteome-scale map of the human protein-protein interaction network</article-title>. <source>Nature</source><year>2005</year>;<volume>437</volume>:<fpage>1173</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">16189514</pub-id>
</mixed-citation></ref><ref id="btae708-B35"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Rudner</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Elsaesser</surname><given-names>SJ</given-names></string-name>, <string-name><surname>Jendrossek</surname><given-names>V</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Anti-apoptotic Bcl-2 fails to form efficient complexes with pro-apoptotic Bak to protect from Celecoxib-induced apoptosis</article-title>. <source>Biochem Pharmacol</source><year>2011</year>;<volume>81</volume>:<fpage>32</fpage>&#x02013;<lpage>42</lpage>.<pub-id pub-id-type="pmid">20836993</pub-id>
</mixed-citation></ref><ref id="btae708-B36"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Salwinski</surname>
<given-names>L</given-names>
</string-name>, <string-name><surname>Miller</surname><given-names>CS</given-names></string-name>, <string-name><surname>Smith</surname><given-names>AJ</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>The database of interacting proteins: 2004 update</article-title>. <source>Nucleic Acids Res</source><year>2004</year>;<volume>32</volume>:<fpage>D449</fpage>&#x02013;<lpage>51</lpage>.<pub-id pub-id-type="pmid">14681454</pub-id>
</mixed-citation></ref><ref id="btae708-B37"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Sinha</surname>
<given-names>K</given-names>
</string-name>, <string-name><surname>Ghosh</surname><given-names>N</given-names></string-name>, <string-name><surname>Sil</surname><given-names>PC</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>A review on the recent applications of deep learning in predictive drug toxicological studies</article-title>. <source>Chem Res Toxicol</source><year>2023</year>;<volume>36</volume>:<fpage>1174</fpage>&#x02013;<lpage>205</lpage>.<pub-id pub-id-type="pmid">37561655</pub-id>
</mixed-citation></ref><ref id="btae708-B38"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Song</surname>
<given-names>B</given-names>
</string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name>, <string-name><surname>Luo</surname><given-names>X</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Learning spatial structures of proteins improves protein-protein interaction prediction</article-title>. <source>Brief Bioinform</source><year>2022</year>;<volume>23</volume>:<fpage>bbab558</fpage>.<pub-id pub-id-type="pmid">35018418</pub-id>
</mixed-citation></ref><ref id="btae708-B39"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Sunny</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Jayaraj</surname><given-names>PB.</given-names></string-name></person-group>
<article-title>Protein-protein docking: past, present, and future</article-title>. <source>Protein J</source><year>2022</year>;<volume>41</volume>:<fpage>1</fpage>&#x02013;<lpage>26</lpage>.<pub-id pub-id-type="pmid">34787783</pub-id>
</mixed-citation></ref><ref id="btae708-B40"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Tang</surname>
<given-names>T</given-names>
</string-name>, <string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Machine learning on protein-protein interaction prediction: models, challenges and trends</article-title>. <source>Brief Bioinform</source><year>2023</year>;<volume>24</volume>:bbad076.</mixed-citation></ref><ref id="btae708-B41"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Trepte</surname>
<given-names>P</given-names>
</string-name>, <string-name><surname>Buntru</surname><given-names>A</given-names></string-name>, <string-name><surname>Klockmeier</surname><given-names>K</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>DULIP: a dual luminescence-based co-immunoprecipitation assay for interactome mapping in mammalian cells</article-title>. <source>J Mol Biol</source><year>2015</year>;<volume>427</volume>:<fpage>3375</fpage>&#x02013;<lpage>88</lpage>.<pub-id pub-id-type="pmid">26264872</pub-id>
</mixed-citation></ref><ref id="btae708-B42"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Trepte</surname>
<given-names>P, Kruse S, Kostova S</given-names>
</string-name>
</person-group>
<etal>et al</etal>
<article-title>LuTHy: a double-readout bioluminescence-based two-hybrid technology for quantitative mapping of protein-protein interactions in mammalian cells</article-title>. <source>Mol Syst Biol</source><year>2018</year>;<volume>14</volume>:e8071.</mixed-citation></ref><ref id="btae708-B43"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Veli&#x0010d;kovi&#x00107;</surname>
<given-names>P, Cucurull G, Casanova A</given-names>
</string-name>
</person-group>
<etal>et al. </etal>Graph attention networks. arXiv, <pub-id pub-id-type="doi">10.48550/arXiv.1710.10903,</pub-id> 2018, preprint: not peer reviewed.</mixed-citation></ref><ref id="btae708-B44"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Venkatesan</surname>
<given-names>K</given-names>
</string-name>, <string-name><surname>Rual</surname><given-names>J-F</given-names></string-name>, <string-name><surname>Vazquez</surname><given-names>A</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>An empirical framework for binary interactome mapping</article-title>. <source>Nat Methods</source><year>2009</year>;<volume>6</volume>:<fpage>83</fpage>&#x02013;<lpage>90</lpage>.<pub-id pub-id-type="pmid">19060904</pub-id>
</mixed-citation></ref><ref id="btae708-B45"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname>
<given-names>T, Xiong J, Xu X</given-names>
</string-name>
</person-group>
<etal>et al</etal> SCNN: a general distribution based statistical convolutional neural network with application to video object detection. In: <italic toggle="yes">Proceedings of the AAAI Conference on Artificial Intelligence, 33 (No. 1: AAAI-19, IAAI-19, EAAI-20)</italic>, <year>2019</year>, <fpage>5321</fpage>&#x02013;<lpage>8</lpage>.</mixed-citation></ref><ref id="btae708-B46"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Whitfield</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Harada</surname><given-names>K</given-names></string-name>, <string-name><surname>Bardelle</surname><given-names>C</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>High-throughput methods to detect dimerization of Bcl-2 family proteins</article-title>. <source>Anal Biochem</source><year>2003</year>;<volume>322</volume>:<fpage>170</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">14596824</pub-id>
</mixed-citation></ref><ref id="btae708-B47"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Willis</surname>
<given-names>SN</given-names>
</string-name>, <string-name><surname>Chen</surname><given-names>L</given-names></string-name>, <string-name><surname>Dewson</surname><given-names>G</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Proapoptotic Bak is sequestered by Mcl-1 and Bcl-xL, but not Bcl-2, until displaced by BH3-only proteins</article-title>. <source>Genes Dev</source><year>2005</year>;<volume>19</volume>:<fpage>1294</fpage>&#x02013;<lpage>305</lpage>.<pub-id pub-id-type="pmid">15901672</pub-id>
</mixed-citation></ref><ref id="btae708-B48"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yang</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Jude</surname><given-names>KM</given-names></string-name>, <string-name><surname>Lai</surname><given-names>B</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Deploying synthetic coevolution and machine learning to engineer protein-protein interactions</article-title>. <source>Science</source><year>2023a</year>;<volume>381</volume>:<fpage>eadh1720</fpage>.<pub-id pub-id-type="pmid">37499032</pub-id>
</mixed-citation></ref><ref id="btae708-B49"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yang</surname>
<given-names>C, Xu X, Xiang C.</given-names>
</string-name>
</person-group>
<article-title>Current computational methods for protein-peptide complex structure prediction</article-title>. <source>Curr Med Chem</source><year>2023b</year>;<volume>31</volume>:<fpage>4058</fpage>&#x02013;<lpage>78</lpage>.</mixed-citation></ref><ref id="btae708-B50"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yang</surname>
<given-names>X</given-names>
</string-name>, <string-name><surname>Yang</surname><given-names>S</given-names></string-name>, <string-name><surname>Lian</surname><given-names>X</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Transfer learning via multi-scale convolutional neural layers for human-virus protein-protein interaction prediction</article-title>. <source>Bioinformatics</source><year>2021</year>;<volume>37</volume>:<fpage>4771</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">34273146</pub-id>
</mixed-citation></ref><ref id="btae708-B51"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yin</surname>
<given-names>S, Mi X</given-names>
</string-name>, <string-name><surname>Shukla</surname><given-names>D</given-names></string-name></person-group>. Leveraging machine learning models for peptide-protein interaction prediction. RSC Chem Biol 2024;<volume>5</volume>:<fpage>401</fpage>&#x02013;<lpage>17</lpage>. <ext-link xlink:href="https://pubs.rsc.org/en/content/articlelanding/2024/cb/d3cb00208j" ext-link-type="uri">https://pubs.rsc.org/en/content/articlelanding/2024/cb/d3cb00208j</ext-link>.</mixed-citation></ref><ref id="btae708-B52"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhai</surname>
<given-names>H</given-names>
</string-name>, <string-name><surname>Hou</surname><given-names>H</given-names></string-name>, <string-name><surname>Luo</surname><given-names>J</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>DGDTA: dynamic graph attention network for predicting drug&#x02013;target binding affinity</article-title>. <source>BMC Bioinformatics</source><year>2023</year>;<volume>24</volume>:<fpage>367</fpage>.<pub-id pub-id-type="pmid">37777712</pub-id>
</mixed-citation></ref><ref id="btae708-B53"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname>
<given-names>H</given-names>
</string-name>, <string-name><surname>Nimmer</surname><given-names>P</given-names></string-name>, <string-name><surname>Rosenberg</surname><given-names>SH</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Development of a high-throughput fluorescence polarization assay for Bcl-xL</article-title>. <source>Anal Biochem</source><year>2002</year>;<volume>307</volume>:<fpage>70</fpage>&#x02013;<lpage>5</lpage>.<pub-id pub-id-type="pmid">12137781</pub-id>
</mixed-citation></ref><ref id="btae708-B54"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname>
<given-names>N</given-names>
</string-name>, <string-name><surname>Zhuo</surname><given-names>M</given-names></string-name>, <string-name><surname>Tian</surname><given-names>K</given-names></string-name></person-group>
<etal>et al</etal>
<article-title>Protein&#x02013;protein interaction and non-interaction predictions using gene sequence natural vector</article-title>. <source>Commun Biol</source><year>2022</year>;<volume>5</volume>:<fpage>652</fpage>.<pub-id pub-id-type="pmid">35780196</pub-id>
</mixed-citation></ref></ref-list></back></article>