<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006255</article-id><article-id pub-id-type="pmc">PMC11859358</article-id><article-id pub-id-type="doi">10.3390/s25041026</article-id><article-id pub-id-type="publisher-id">sensors-25-01026</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>SSM-Net: Enhancing Compressed Sensing Image Reconstruction with Mamba Architecture and Fast Iterative Shrinking Threshold Algorithm Optimization</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gao</surname><given-names>Xianwei</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Bi</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role></contrib><contrib contrib-type="author"><name><surname>Yao</surname><given-names>Xiang</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role></contrib><contrib contrib-type="author"><name><surname>Yuan</surname><given-names>Ye</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="c1-sensors-25-01026" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Angrisani</surname><given-names>Leopoldo</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01026">Beijing Electronic Science and Technology Institute, Beijing 100070, China; <email>gaoxianwei@besti.edu.cn</email> (X.G.); <email>20232940@mail.besti.edu.cn</email> (B.C.); <email>20233910@mail.besti.edu.cn</email> (X.Y.)</aff><author-notes><corresp id="c1-sensors-25-01026"><label>*</label>Correspondence: <email>yuanye@besti.edu.cn</email></corresp></author-notes><pub-date pub-type="epub"><day>09</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1026</elocation-id><history><date date-type="received"><day>05</day><month>1</month><year>2025</year></date><date date-type="rev-recd"><day>05</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>07</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Compressed sensing (CS) is a powerful technique that can reduce data size while maintaining high reconstruction quality, which makes it particularly valuable in high-dimensional image applications. However, many existing methods have difficulty balancing reconstruction accuracy, computational efficiency, and fast convergence. To address these challenges, this paper proposes SSM-Net, a novel framework that combines the state-space modeling (SSM) of the Mamba architecture with the fast iterative shrinking threshold algorithm (FISTA). The Mamba-based SSM module can effectively capture local and global dependencies with linear computational complexity and significantly reduces the computation time compared to Transformer-based methods. In addition, the momentum update inspired by FISTA improves the convergence speed during deep iterative reconstruction. SSM-Net features a lightweight sampling module for efficient data compression, an initial reconstruction module for fast approximation, and a deep reconstruction module for iterative refinement. Extensive experiments on various benchmark datasets show that SSM-Net achieves state-of-the-art reconstruction performance while reducing both training and inference reconstruction time, making SSM-Net a scalable and practical solution for real-time applications of compressed sensing.</p></abstract><kwd-group><kwd>compressive sensing</kwd><kwd>image reconstruction</kwd><kwd>Mamba</kwd><kwd>state-space modeling</kwd><kwd>FISTA</kwd></kwd-group><funding-group><award-group><funding-source>the Fundamental Research Funds for the Central Universities</funding-source><award-id>3282023009</award-id></award-group><funding-statement>This research was supported by &#x0201c;the Fundamental Research Funds for the Central Universities&#x0201d; (Grant Number: 3282023009).</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01026"><title>1. Introduction</title><p>Compressed sensing (CS) has gained prominence in signal processing due to its ability to reconstruct high-dimensional signals from significantly fewer measurements&#x000a0;[<xref rid="B1-sensors-25-01026" ref-type="bibr">1</xref>]. This technique proves especially effective in scenarios where resources for data acquisition, such as bandwidth and storage, are constrained&#x000a0;[<xref rid="B2-sensors-25-01026" ref-type="bibr">2</xref>,<xref rid="B3-sensors-25-01026" ref-type="bibr">3</xref>,<xref rid="B4-sensors-25-01026" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-01026" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-01026" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-01026" ref-type="bibr">7</xref>]. By exploiting the inherent sparsity or compressibility of signals, CS offers a structured approach to signal recovery applicable across various fields, including medical imaging, telecommunications, and industrial automation.</p><p>CS works in two main steps. First, during the sampling phase, a high-dimensional signal <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is projected into a lower-dimensional measurement <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>m</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#x0226a;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) using a sensing matrix <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:mo>&#x003a6;</mml:mo></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD1-sensors-25-01026"><label>(1)</label><mml:math id="mm5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x003a6;</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">&#x003b7;</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">&#x003b7;</mml:mi></mml:mrow></mml:math></inline-formula> represents noise. In the second step, the goal is to recover <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:math></inline-formula> by solving an optimization problem that balances the accuracy of the data and the sparsity of the signal:<disp-formula id="FD2-sensors-25-01026"><label>(2)</label><mml:math id="mm8" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mi mathvariant="bold">x</mml:mi></mml:munder><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msubsup><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mo>&#x003a6;</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msub><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:mo>&#x003a8;</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> Here, <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mo>&#x003a8;</mml:mo></mml:mrow></mml:math></inline-formula> represents the transform basis, and <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mi>&#x003bb;</mml:mi></mml:mrow></mml:math></inline-formula> controls the trade-off between the reconstruction accuracy and sparsity.</p><p>Researchers have developed numerous algorithms to solve this problem. Methods like Orthogonal Matching Pursuit (OMP)&#x000a0;[<xref rid="B8-sensors-25-01026" ref-type="bibr">8</xref>] and the Iterative Shrinkage-Thresholding Algorithm (ISTA)&#x000a0;[<xref rid="B9-sensors-25-01026" ref-type="bibr">9</xref>] address the optimization efficiently in many cases. However, computational limitations and reduced accuracy at low sampling rates remain persistent challenges. Algorithms such as the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA)&#x000a0;[<xref rid="B10-sensors-25-01026" ref-type="bibr">10</xref>] incorporate momentum-based updates to improve convergence speed, significantly enhancing scalability in large-scale settings.</p><p>The integration of deep learning with CS has introduced new possibilities. Hybrid frameworks combine traditional optimization methods with neural network-based models to achieve better performance. ISTA-Net&#x000a0;[<xref rid="B11-sensors-25-01026" ref-type="bibr">11</xref>], for example, adapts ISTA into a trainable neural network, while ADMM-CSNet&#x000a0;[<xref rid="B12-sensors-25-01026" ref-type="bibr">12</xref>] integrates alternating direction method of multipliers (ADMM) with deep learning for faster and more accurate results. Transformer-based approaches like TransCS&#x000a0;[<xref rid="B13-sensors-25-01026" ref-type="bibr">13</xref>] utilize attention mechanisms to capture global dependencies effectively. Additionally, architectures based on generative adversarial networks (GANs)&#x000a0;[<xref rid="B14-sensors-25-01026" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-01026" ref-type="bibr">15</xref>] have been employed to enhance image resolution and recover fine details.</p><p>Despite these advancements, computational complexity and trade-offs between speed and accuracy present ongoing difficulties. Transformer-based models, though capable of modeling global features, exhibit quadratic complexity in self-attention mechanisms, limiting their use in real-time applications. Lightweight designs, such as CSNet&#x000a0;[<xref rid="B16-sensors-25-01026" ref-type="bibr">16</xref>], improve processing speed but often compromise reconstruction quality.</p><p>Alternative approaches have emerged to address these shortcomings. The Mamba architecture introduces a selective state-space model that captures local and global dependencies efficiently. Unlike Transformers, which rely on self-attention mechanisms with quadratic complexity <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">O</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, Mamba achieves linear complexity <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">O</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> through a more computationally efficient design. This approach reduces processing overhead and enhances scalability, making it well suited for high-dimensional image data.</p><p>Inspired by Mamba&#x02019;s efficient dependency modeling, this work combines its state-space modeling with the momentum-based optimization of FISTA. The resulting framework achieves faster convergence, improved accuracy, and enhanced adaptability across various reconstruction scenarios.</p><p>This study makes the following contributions:<list list-type="bullet"><list-item><p>A novel compressive sensing framework is proposed, integrating Mamba&#x02019;s state-space modeling and FISTA&#x02019;s optimization. This design removes the dependence on manually defined hyperparameters such as sensing matrices.</p></list-item><list-item><p>Improvements in computational efficiency and reconstruction accuracy are demonstrated, with reduced training and inference times.</p></list-item><list-item><p>Extensive evaluations across multiple datasets highlight the framework&#x02019;s adaptability and robustness under varying sampling rates and noise levels.</p></list-item></list></p><p>The paper proceeds as follows: <xref rid="sec2-sensors-25-01026" ref-type="sec">Section 2</xref> examines related works in CS and hybrid frameworks. <xref rid="sec3-sensors-25-01026" ref-type="sec">Section 3</xref> describes the proposed framework in detail. <xref rid="sec4-sensors-25-01026" ref-type="sec">Section 4</xref> presents experimental results and comparisons. <xref rid="sec5-sensors-25-01026" ref-type="sec">Section 5</xref> concludes with an outlook on future research.</p></sec><sec id="sec2-sensors-25-01026"><title>2. Related Work</title><sec id="sec2dot1-sensors-25-01026"><title>2.1. FISTA</title><p>FISTA is an advanced algorithm for solving large-scale optimization problems, particularly in compressive sensing applications. It builds on the traditional Iterative Shrinkage-Thresholding Algorithm (ISTA) by adding momentum-based acceleration, while keeping the simplicity of first-order methods.</p><p>The algorithm solves optimization problems of the following form:<disp-formula id="FD3-sensors-25-01026"><label>(3)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mi mathvariant="bold">x</mml:mi></mml:munder><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a smooth convex function with a continuous gradient, and <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a convex but possibly non-smooth regularization term. In compressive sensing, this becomes<disp-formula id="FD4-sensors-25-01026"><label>(4)</label><mml:math id="mm16" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mi mathvariant="bold">x</mml:mi></mml:munder><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msubsup><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:mo>&#x003a6;</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msub><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mo>&#x003a6;</mml:mo></mml:mrow></mml:math></inline-formula> is the measurement matrix, <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></inline-formula> represents the compressed measurements, and <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:mi>&#x003bb;</mml:mi></mml:mrow></mml:math></inline-formula> controls how sparse the solution is.</p><p>The key innovation of FISTA is its momentum-based acceleration. In each iteration, the algorithm keeps track of an auxiliary sequence that adds momentum from previous iterations, leading to the following update rules:<disp-formula id="FD5-sensors-25-01026"><label>(5)</label><mml:math id="mm20" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:msubsup><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD6-sensors-25-01026"><label>(6)</label><mml:math id="mm21" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Next, the algorithm performs a step called a &#x0201c;proximal gradient step&#x0201d; to adjust the solution:<disp-formula id="FD7-sensors-25-01026"><label>(7)</label><mml:math id="mm22" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mspace width="4.pt"/><mml:mi>min</mml:mi></mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:munder><mml:mfenced separators="" open="{" close="}"><mml:mi>&#x003bb;</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mrow><mml:mo stretchy="false">&#x02225;</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>L</mml:mi></mml:mfrac></mml:mstyle><mml:mo>&#x02207;</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msubsup><mml:mo stretchy="false">&#x02225;</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">L</italic> is the Lipschitz constant of <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#x02207;</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. For the common <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x02113;</mml:mo><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> regularization used in compressive sensing, this step simplifies to a soft-thresholding operation:<disp-formula id="FD8-sensors-25-01026"><label>(8)</label><mml:math id="mm25" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>soft</mml:mi><mml:mrow><mml:mi>&#x003bb;</mml:mi><mml:mo>/</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>sign</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mo>{</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mo>/</mml:mo><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This combination of momentum acceleration and proximal steps allows FISTA to converge faster, achieving a rate of <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is much better than ISTA&#x02019;s <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> rate. The faster convergence and the algorithm&#x02019;s efficiency make FISTA especially useful for large-scale compressive sensing tasks, where quick reconstruction is needed.</p></sec><sec id="sec2dot2-sensors-25-01026"><title>2.2. DL-Based CS</title><p>Deep learning has brought substantial advancements to CS by enabling the modeling of complex relationships between measurements and original signals. Methods leveraging deep learning for CS can generally be divided into two categories. The first category combines traditional optimization techniques with neural networks, creating hybrid models that balance interpretability and flexibility. The second category focuses on fully end-to-end architectures, where neural networks directly learn to reconstruct images without relying on prior optimization frameworks.</p><p>In the first category, hybrid methods combine the stability of traditional CS algorithms with the efficiency of deep learning. ISTA-Net&#x000a0;[<xref rid="B11-sensors-25-01026" ref-type="bibr">11</xref>] unfolds the ISTA into a neural network, replacing handcrafted sparsity constraints with learned nonlinear transforms. ADMM-CSNet&#x000a0;[<xref rid="B12-sensors-25-01026" ref-type="bibr">12</xref>] extends the alternating direction method of multipliers (ADMM) by introducing learnable parameters to accelerate convergence and enhance reconstruction accuracy. AMP-Net unfolds the AMP algorithm into a network framework, addressing noise and reducing blocking artifacts. NeumNet&#x000a0;[<xref rid="B17-sensors-25-01026" ref-type="bibr">17</xref>] uses the Neumann series to solve inverse problems efficiently but remains susceptible to block effects. Recent approaches, such as TransCS, incorporate Transformer-based architectures to capture global dependencies across image sub-blocks, while DRCAMP-Net&#x000a0;[<xref rid="B18-sensors-25-01026" ref-type="bibr">18</xref>] combines AMP with residual convolutional layers to expand the receptive field and improve reconstruction performance.</p><p>The second category focuses on purely deep learning-based methods, which leverage convolutional neural networks (CNNs) for end-to-end image reconstruction. ReconNet&#x000a0;[<xref rid="B19-sensors-25-01026" ref-type="bibr">19</xref>] pioneered the use of CNNs for compressive sensing recovery, demonstrating the feasibility of deep learning in this domain. DR2-Net&#x000a0;[<xref rid="B20-sensors-25-01026" ref-type="bibr">20</xref>] improves reconstruction with residual learning blocks, while DPA-Net&#x000a0;[<xref rid="B21-sensors-25-01026" ref-type="bibr">21</xref>] employs a dual-path attention mechanism to separately capture structural and texture details. However, the limited receptive field of CNNs restricts their ability to model global dependencies. To address this, methods like MSCRLNet extend the receptive field using multi-scale and residual learning strategies, effectively combining local feature extraction with global modeling.</p><p>In addition to these methods, hybrid deep unfolding networks, such as DPC-DUN&#x000a0;[<xref rid="B22-sensors-25-01026" ref-type="bibr">22</xref>] and LTwIST&#x000a0;[<xref rid="B23-sensors-25-01026" ref-type="bibr">23</xref>], combine the interpretability of traditional algorithms with the flexibility of deep learning, dynamically optimizing reconstruction paths and eliminating the need for manual parameter tuning.</p><p>While these advancements have significantly enhanced image reconstruction, challenges remain in balancing computational efficiency, reconstruction quality, and the ability to capture both local and global features. Recent methods integrating Transformers with CNNs offer promising solutions, paving the way for frameworks like our proposed SSM-Net (the code can be found in <xref rid="app1-sensors-25-01026" ref-type="app">Supplementary Material</xref>), which further improves the efficiency and accuracy of compressive sensing reconstruction.</p></sec><sec id="sec2dot3-sensors-25-01026"><title>2.3. Mamba</title><p>Mamba is a cutting-edge state-space model (SSM)&#x000a0;[<xref rid="B24-sensors-25-01026" ref-type="bibr">24</xref>] that has demonstrated remarkable efficiency in modeling long-range dependencies in sequential data. Its key innovation lies in replacing the self-attention mechanism, commonly used in Transformers, with a structured state-space representation. This approach reduces the computational complexity of sequence modeling from quadratic to linear, making Mamba particularly well suited for tasks involving large-scale data. The state-space model underlying Mamba can be expressed as<disp-formula id="FD9-sensors-25-01026"><label>(9)</label><mml:math id="mm28" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">h</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="bold">B</mml:mi><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="1.em"/><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the hidden state, <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the input, and <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the output. The matrices <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:math></inline-formula> are learnable parameters. To adapt this continuous formulation for deep learning models, it is discretized using zero-order hold (ZOH) as follows:<disp-formula id="FD10-sensors-25-01026"><label>(10)</label><mml:math id="mm36" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mo>&#x00394;</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>&#x00394;</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mi>d</mml:mi><mml:mi>&#x003c4;</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mo>&#x00394;</mml:mo></mml:mrow></mml:math></inline-formula> is the time step.</p><p>On this basis, Mamba-2&#x000a0;[<xref rid="B25-sensors-25-01026" ref-type="bibr">25</xref>] introduces several architectural improvements that improve both efficiency and performance. Key innovations include a simplified design with parallel parameter generation, an improved state-space dual (SSD) framework for connecting SSM and attention mechanisms, and improved hardware utilization through efficient matrix multiplication operations. The architecture supports larger state sizes (up to 8 times larger than the original Mamba) while maintaining 2&#x02013;8 times faster computation speed. Mamba-2 also includes an additional normalization layer for improved stability and supports tensor parallelism for better scaling.</p><p>The selective information preservation mechanism present in both versions dynamically considers sequence length and input batch size in state computation. Mamba&#x02019;s scanning method is a key step in converting 2D visual data into 1D sequences. Different scanning methods have different advantages in capturing spatial relationships and contextual information. Global scanning processes the entire image at once and can capture global patterns but may ignore details. Multi-directional selective scanning scans the image from multiple directions and can fully capture spatial information but has higher computational complexity. Spiral scanning expands from the center of the image outward and is suitable for tasks that require full coverage of the image, such as medical imaging and remote sensing. Radial scanning expands from the edge of the image to the center and is suitable for tasks that need to capture details in the central area. The scanning operation facilitates efficient computation of state selection, enabling Mamba to compress historical information into a compact and efficient state representation. This architectural efficiency enables Mamba to be successfully adapted to various computer vision tasks, such as the efficient visual backbone of Vision Mamba&#x000a0;[<xref rid="B26-sensors-25-01026" ref-type="bibr">26</xref>] and VMamba; the computationally efficient graph processing of Graph/-Mamba&#x000a0;[<xref rid="B27-sensors-25-01026" ref-type="bibr">27</xref>]; LocalMamba&#x000a0;[<xref rid="B28-sensors-25-01026" ref-type="bibr">28</xref>], which focuses on the extraction of local features, processing local areas of the image through window selective scanning techniques; and EfficientVMamba&#x000a0;[<xref rid="B29-sensors-25-01026" ref-type="bibr">29</xref>], which is a lightweight Mamba architecture that reduces computational costs by introducing Atrous selective scanning techniques. Mamba-ND&#x000a0;[<xref rid="B30-sensors-25-01026" ref-type="bibr">30</xref>] is a multi-dimensional Mamba architecture capable of processing data of arbitrary dimensions. It maintains the linear complexity of SSM by alternating the sequence order, which is suitable for processing high-dimensional data. MambaMixer&#x000a0;[<xref rid="B31-sensors-25-01026" ref-type="bibr">31</xref>] is a hybrid architecture that combines the advantages of Mamba and Transformer. It enhances the efficiency of sequence modeling through dual token and channel selection mechanisms. Mamba-R&#x000a0;[<xref rid="B32-sensors-25-01026" ref-type="bibr">32</xref>] introduces register tokens to enhance the focusing ability of feature maps and reduce artifacts in feature maps. PlainMamba&#x000a0;[<xref rid="B33-sensors-25-01026" ref-type="bibr">33</xref>] is a non-hierarchical Mamba architecture that maintains spatial continuity through continuous 2D scanning. This approach performs well in scenarios that require continuous data processing. Additionally, there are various Mamba-based image segmentation architectures (U-Mamba&#x000a0;[<xref rid="B34-sensors-25-01026" ref-type="bibr">34</xref>], Swin-UMamba&#x000a0;[<xref rid="B35-sensors-25-01026" ref-type="bibr">35</xref>], and Mamba-UNet&#x000a0;[<xref rid="B36-sensors-25-01026" ref-type="bibr">36</xref>]). As an emerging deep learning architecture, Mamba has shown great potential in the field of computer vision through selective state-space models and efficient scanning mechanisms. Its flexible architectural design enables it to adapt to different task requirements, from image classification and video processing to remote sensing and medical image analysis.</p></sec></sec><sec sec-type="methods" id="sec3-sensors-25-01026"><title>3. Methods</title><p>In this section, we present the proposed framework for efficient image reconstruction. The overall system pipeline is illustrated in <xref rid="sensors-25-01026-f001" ref-type="fig">Figure 1</xref>. The framework consists of three primary components: the sampling module, the reconstruction module, and the loss function design. The sampling module compresses high-dimensional image data into compact measurements, which are then used by the reconstruction module to recover the original image. The reconstruction module includes both initial reconstruction and deep reconstruction stages, iteratively refining the output to achieve high-fidelity results. Finally, the loss function ensures the reconstruction accuracy by balancing fidelity, perceptual similarity, and structural consistency.</p><sec id="sec3dot1-sensors-25-01026"><title>3.1. Sampling Module</title><p>The sampling module is designed to efficiently transform high-dimensional image data into compressed measurements while preserving essential structural information. Given an input image <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>H</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">B</italic> represents the batch size and <italic toggle="yes">H</italic>, <italic toggle="yes">W</italic> denote the height and width, respectively, we propose a structured block-wise sampling approach that leverages learnable measurement matrices.</p><p>The foundation of our sampling mechanism is a learnable measurement matrix <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#x003a6;</mml:mo><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x0230a;</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mi>n</mml:mi><mml:mo>&#x0230b;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow></mml:math></inline-formula> being the target compression ratio and <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#x003d5;</mml:mi><mml:mrow><mml:mi>size</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> denoting the dimensionality of each block. The complete sampling process is detailed in Algorithm 1.
<array><tbody><tr><td style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 1</bold> Block-wise Adaptive Sampling Process</td></tr><tr><td style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label><bold>Require:</bold>&#x000a0;
</label><p>Input image <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>H</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label><bold>Ensure:</bold>&#x000a0;
</label><p>Compressed measurements <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;1:</label><p>{Initialize measurement matrix}</p></list-item><list-item><label>&#x000a0;&#x000a0;2:</label><p><inline-formula><mml:math id="mm45" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x02190;</mml:mo><mml:msubsup><mml:mi>&#x003d5;</mml:mi><mml:mrow><mml:mi>size</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;3:</label><p><inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#x02190;</mml:mo><mml:mo>&#x0230a;</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mi>n</mml:mi><mml:mo>&#x0230b;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;4:</label><p><inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mo>&#x003a6;</mml:mo><mml:mi>init</mml:mi></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;5:</label><p><inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>init</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:msubsup><mml:mo>&#x003a6;</mml:mo><mml:mrow><mml:mi>init</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> {Initialize reconstruction matrix}</p></list-item><list-item><label>&#x000a0;&#x000a0;6:</label><p>{Block partitioning}</p></list-item><list-item><label>&#x000a0;&#x000a0;7:</label><p><bold>if</bold>&#x000a0;<inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mspace width="0.277778em"/><mml:mo form="prefix">mod</mml:mo><mml:mspace width="0.277778em"/><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>&#x02260;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mspace width="0.277778em"/><mml:mo form="prefix">mod</mml:mo><mml:mspace width="0.277778em"/><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>&#x02260;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>&#x000a0;<bold>then</bold></p></list-item><list-item><label>&#x000a0;&#x000a0;8:</label><p>&#x000a0;&#x000a0;&#x000a0;Apply padding operator <inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">B</mml:mi></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;9:</label><p><bold>end if</bold></p></list-item><list-item><label>10:</label><p><inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>blocks</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>11:</label><p>{Vectorization}</p></list-item><list-item><label>12:</label><p><inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x02190;</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>blocks</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>13:</label><p>{Measurement computation}</p></list-item><list-item><label>14:</label><p><inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x02190;</mml:mo><mml:mo>&#x003a6;</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>15:</label><p><bold>return</bold>&#x000a0;
<inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></inline-formula></p></list-item></list></td></tr></tbody></array></p><p>The sampling process consists of three key transformations. Initially, we define a block partitioning operator <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">P</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>H</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">N</italic> represents the total number of blocks. This operator decomposes the input image into non-overlapping blocks:<disp-formula id="FD11-sensors-25-01026"><label>(11)</label><mml:math id="mm57" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>blocks</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="script">P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Subsequently, we employ a vectorization operator <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">V</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mo>&#x02192;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:msubsup><mml:mi>&#x003d5;</mml:mi><mml:mrow><mml:mi>size</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> that transforms each block into a vector representation:<disp-formula id="FD12-sensors-25-01026"><label>(12)</label><mml:math id="mm59" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>blocks</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The final transformation computes the compressed measurements through linear&#x000a0;projection:<disp-formula id="FD13-sensors-25-01026"><label>(13)</label><mml:math id="mm60" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">y</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x003a6;</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>A key innovation in our approach is the simultaneous learning of a reconstruction initialization matrix <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, initialized as <inline-formula><mml:math id="mm62" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>init</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#x003a6;</mml:mo><mml:mrow><mml:mi>init</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. This dual learning strategy enables joint optimization of the sampling and initial reconstruction processes, leading to the following objective:<disp-formula id="FD14-sensors-25-01026"><label>(14)</label><mml:math id="mm63" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>&#x003a6;</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Q</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>&#x003a6;</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> represents our reconstruction network.</p><p>To handle inputs of any size, we use a padding operator <inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">B</mml:mi></mml:mrow></mml:math></inline-formula> to adjust the input to the nearest multiple of <inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. After the experiments, we found that <inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> provides the best balance between speed and reconstruction quality. The adaptive sampling matrices and block-based processing help the framework capture important image features, while keeping the computation simple. This sampling module provides a strong foundation for reducing dimensionality efficiently while preserving critical image structures. It prepares the data for the reconstruction process, which is explained in the next section.</p></sec><sec id="sec3dot2-sensors-25-01026"><title>3.2. Reconstruction Module</title><sec id="sec3dot2dot1-sensors-25-01026"><title>3.2.1. Initial Reconstruction</title><p>The image signal is compressed into <inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></inline-formula> through the sampling module, and this <inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></inline-formula> is used as the input to the initial reconstruction, providing the preliminary estimate <inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>init</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. This estimate forms the basis for subsequent refinement and optimization.</p><p>The process begins with a linear operation:<disp-formula id="FD15-sensors-25-01026"><label>(15)</label><mml:math id="mm71" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>init</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mi mathvariant="bold">y</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is initialized as the transpose of the sampling matrix <inline-formula><mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mo>&#x003a6;</mml:mo></mml:mrow></mml:math></inline-formula>. Specifically, <inline-formula><mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>init</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mo>&#x003a6;</mml:mo><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, ensuring that the initial estimate aligns naturally with the compressed data.</p><p>To maintain stability and support effective training, the entries of <inline-formula><mml:math id="mm75" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">Q</mml:mi></mml:mrow></mml:math></inline-formula> are drawn from a normal distribution:<disp-formula id="FD16-sensors-25-01026"><label>(16)</label><mml:math id="mm76" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>init</mml:mi></mml:msub><mml:mo>&#x0223c;</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">m</italic> denotes the dimensionality of the compressed measurements. This initialization strategy promotes stable gradient flow during backpropagation and enables the model to learn meaningful reconstruction patterns.</p><p>When the dimensions of the input image do not align with the block size used in the sampling module, padding is applied to adjust the height (<italic toggle="yes">H</italic>) and width (<italic toggle="yes">W</italic>). The required padding values are determined as follows:<disp-formula id="FD17-sensors-25-01026"><label>(17)</label><mml:math id="mm77" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>h</mml:mi><mml:mi>pad</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>if</mml:mi><mml:mspace width="4.pt"/><mml:mi>H</mml:mi><mml:mspace width="0.277778em"/><mml:mo form="prefix">mod</mml:mo><mml:mspace width="0.277778em"/><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>H</mml:mi><mml:mspace width="0.277778em"/><mml:mo form="prefix">mod</mml:mo><mml:mspace width="0.277778em"/><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>otherwise</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="FD18-sensors-25-01026"><label>(18)</label><mml:math id="mm78" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>w</mml:mi><mml:mi>pad</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>if</mml:mi><mml:mspace width="4.pt"/><mml:mi>W</mml:mi><mml:mspace width="0.277778em"/><mml:mo form="prefix">mod</mml:mo><mml:mspace width="0.277778em"/><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>W</mml:mi><mml:mspace width="0.277778em"/><mml:mo form="prefix">mod</mml:mo><mml:mspace width="0.277778em"/><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>size</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>otherwise</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>This adjustment ensures consistent processing of all image blocks and retains the spatial relationships present in the original image.</p></sec><sec id="sec3dot2dot2-sensors-25-01026"><title>3.2.2. Deep Reconstruction</title><p>The initial reconstruction result <inline-formula><mml:math id="mm79" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>init</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is used as input to the deep reconstruction module, where it is further improved through iterative optimization and advanced feature modeling. This stage combines momentum-based updates inspired by FISTA with multi-directional selective state-space modeling (SSM). Together, these techniques enable efficient and accurate recovery of high-dimensional image data from compressed measurements. The full process is described in Algorithm 2.
<array><tbody><tr><td style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 2</bold> Deep Reconstruction Process</td></tr><tr><td style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label><bold>Require:</bold>&#x000a0;
</label><p>Initial reconstruction <inline-formula><mml:math id="mm80" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>init</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, compressed measurements <inline-formula><mml:math id="mm81" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></inline-formula>, sampling matrix <inline-formula><mml:math id="mm82" overflow="scroll"><mml:mrow><mml:mo>&#x003a6;</mml:mo></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label><bold>Ensure:</bold>&#x000a0;
</label><p>Final reconstructed image <inline-formula><mml:math id="mm83" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;1:</label><p>Initialize <inline-formula><mml:math id="mm84" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>init</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm85" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;2:</label><p><bold>for</bold>&#x000a0;<inline-formula><mml:math id="mm86" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> to <italic toggle="yes">L</italic>&#x000a0;<bold>do</bold></p></list-item><list-item><label>&#x000a0;&#x000a0;3:</label><p>&#x000a0;&#x000a0;&#x000a0;Compute momentum <inline-formula><mml:math id="mm87" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:msubsup><mml:mi>t</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;4:</label><p>&#x000a0;&#x000a0;&#x000a0;Update intermediate state <inline-formula><mml:math id="mm88" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02190;</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;5:</label><p>&#x000a0;&#x000a0;&#x000a0;Apply gradient correction <inline-formula><mml:math id="mm89" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02190;</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:msup><mml:mo>&#x003a6;</mml:mo><mml:mo>&#x022a4;</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x003a6;</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;6:</label><p>&#x000a0;&#x000a0;&#x000a0;Pre-process features <inline-formula><mml:math id="mm90" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02190;</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>pre</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>&#x000a0;&#x000a0;7:</label><p>&#x000a0;&#x000a0;&#x000a0;Apply selective state-space modeling:</p></list-item><list-item><label>&#x000a0;&#x000a0;8:</label><p>&#x000a0;&#x000a0;&#x000a0;<bold>for</bold> each direction <inline-formula><mml:math id="mm91" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>&#x000a0;<bold>do</bold></p></list-item><list-item><label>&#x000a0;&#x000a0;9:</label><p>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;Compute state evolution <inline-formula><mml:math id="mm92" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:mo form="prefix">exp</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x0039b;</mml:mo><mml:msub><mml:mo>&#x00394;</mml:mo><mml:mi>r</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">B</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mo>&#x00394;</mml:mo><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>10:</label><p>&#x000a0;&#x000a0;&#x000a0;<bold>end for</bold></p></list-item><list-item><label>11:</label><p>&#x000a0;&#x000a0;&#x000a0;Aggregate results <inline-formula><mml:math id="mm93" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02190;</mml:mo><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>12:</label><p>&#x000a0;&#x000a0;&#x000a0;Post-process features <inline-formula><mml:math id="mm94" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02190;</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>post</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>13:</label><p><bold>end for</bold></p></list-item><list-item><label>14:</label><p>Reshape final result <inline-formula><mml:math id="mm95" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>15:</label><p><bold>return</bold>&#x000a0;<inline-formula><mml:math id="mm96" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p></list-item></list></td></tr></tbody></array></p><p>In each iteration <italic toggle="yes">l</italic>, the reconstruction follows these steps:</p><p>First, momentum-based acceleration is used to speed up convergence. The intermediate state <inline-formula><mml:math id="mm97" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is updated as follows:<disp-formula id="FD19-sensors-25-01026"><label>(19)</label><mml:math id="mm98" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:msubsup><mml:mi>t</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="FD20-sensors-25-01026"><label>(20)</label><mml:math id="mm99" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mstyle><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm100" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a momentum factor initialized as <inline-formula><mml:math id="mm101" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. This step incorporates information from previous iterations to ensure faster convergence and improved reconstruction quality.</p><p>Next, to maintain consistency with the compressed measurements <inline-formula><mml:math id="mm102" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></inline-formula>, a gradient descent step is applied to <inline-formula><mml:math id="mm103" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD21-sensors-25-01026"><label>(21)</label><mml:math id="mm104" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:msup><mml:mo>&#x003a6;</mml:mo><mml:mo>&#x022a4;</mml:mo></mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mo>&#x003a6;</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm105" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003b7;</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> is a learnable step size parameter. This correction minimizes the data fidelity term, aligning the reconstruction with the measurement constraints.</p><p>Before applying state-space modeling, a pre-processing network <inline-formula><mml:math id="mm106" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>pre</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is employed to enhance local image features:<disp-formula id="FD22-sensors-25-01026"><label>(22)</label><mml:math id="mm107" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>pre</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm108" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>pre</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is implemented as a series of convolutional layers designed to extract fine-grained image details.</p><p>The refined intermediate signal <inline-formula><mml:math id="mm109" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is then processed using a multi-directional selective state-space model. This step captures both local and global dependencies by scanning the input in four directions: horizontal, vertical, main diagonal, and secondary diagonal. For each direction <italic toggle="yes">r</italic>, the modeling is defined as<disp-formula id="FD23-sensors-25-01026"><label>(23)</label><mml:math id="mm110" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#x0039b;</mml:mo><mml:msub><mml:mo>&#x00394;</mml:mo><mml:mi>r</mml:mi></mml:msub></mml:mfenced><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">B</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mo>&#x00394;</mml:mo><mml:mi>r</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="FD24-sensors-25-01026"><label>(24)</label><mml:math id="mm111" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mo>&#x00394;</mml:mo><mml:mi>r</mml:mi></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> Here, <inline-formula><mml:math id="mm112" overflow="scroll"><mml:mrow><mml:mo>&#x0039b;</mml:mo></mml:mrow></mml:math></inline-formula> represents the state evolution matrix, <inline-formula><mml:math id="mm113" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">B</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the input projection matrix, <inline-formula><mml:math id="mm114" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003d5;</mml:mi><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a nonlinear activation function that ensures stability, and <inline-formula><mml:math id="mm115" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x00394;</mml:mo><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the adaptive time step for the <italic toggle="yes">r</italic>-th direction. The outputs from all directions are combined as<disp-formula id="FD25-sensors-25-01026"><label>(25)</label><mml:math id="mm116" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:munderover><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>After state-space modeling, a post-processing network <inline-formula><mml:math id="mm117" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>post</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> refines the reconstructed signal. This refinement is performed using<disp-formula id="FD26-sensors-25-01026"><label>(26)</label><mml:math id="mm118" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>post</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm119" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>post</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is a set of learnable convolutional layers designed to remove residual errors and improve the global structure of the signal.</p><p>Once <italic toggle="yes">L</italic> iterations are complete, the final reconstructed signal <inline-formula><mml:math id="mm120" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is reshaped into its original spatial dimensions:<disp-formula id="FD27-sensors-25-01026"><label>(27)</label><mml:math id="mm121" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm122" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">R</mml:mi><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the reshaping operator.</p><p>This iterative process combines momentum-based optimization, feature extraction, and selective state-space modeling to achieve accurate and high-quality reconstruction. The integration of learnable parameters and adaptive strategies allows the model to handle diverse image structures and varying compression conditions effectively, ensuring both efficiency and accuracy.</p></sec></sec><sec id="sec3dot3-sensors-25-01026"><title>3.3. Loss Function</title><p>To ensure accurate and high-quality reconstruction, we design a loss function that balances pixel-wise fidelity, perceptual quality, and structural consistency.</p><p>The MSE loss ensures pixel-wise accuracy by minimizing the <inline-formula><mml:math id="mm123" overflow="scroll"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm between the reconstructed image <inline-formula><mml:math id="mm124" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the ground truth <inline-formula><mml:math id="mm125" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD28-sensors-25-01026"><label>(28)</label><mml:math id="mm126" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>MSE</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle><mml:msubsup><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">N</italic> is the total number of pixels.</p><p>To improve perceptual quality, the SSIM loss measures structural similarity between <inline-formula><mml:math id="mm127" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm128" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD29-sensors-25-01026"><label>(29)</label><mml:math id="mm129" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>SSIM</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>SSIM</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm130" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>SSIM</mml:mi><mml:mo>(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>,</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> captures luminance, contrast, and structure.</p><p>The edge gradient loss enhances edge preservation by penalizing differences in image gradients:<disp-formula id="FD30-sensors-25-01026"><label>(30)</label><mml:math id="mm131" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>edge</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:msub><mml:mo>&#x02207;</mml:mo><mml:mi>h</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mo>&#x02207;</mml:mo><mml:mi>h</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mo>&#x02207;</mml:mo><mml:mi>v</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>recon</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mo>&#x02207;</mml:mo><mml:mi>v</mml:mi></mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm132" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x02207;</mml:mo><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm133" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x02207;</mml:mo><mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represent horizontal and vertical gradient operators, respectively.</p><p>Finally, the total loss integrates these components, balancing their contributions with weighting factors <inline-formula><mml:math id="mm134" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>SSIM</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm135" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>edge</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD31-sensors-25-01026"><label>(31)</label><mml:math id="mm136" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>total</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>MSE</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>SSIM</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>SSIM</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>edge</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>edge</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This comprehensive loss function ensures faithful reconstruction while preserving structural details and perceptual quality, enabling the model to achieve robust and high-quality results.</p></sec></sec><sec id="sec4-sensors-25-01026"><title>4. Experimental Results</title><sec id="sec4dot1-sensors-25-01026"><title>4.1. Experimental Settings</title><p>The training and evaluation of SSM-Net use a variety of datasets, including satellite imagery, urban environments, natural scenes, and high-resolution images. The primary training process relies on the BSD500 dataset [<xref rid="B37-sensors-25-01026" ref-type="bibr">37</xref>], which consists of 200 training images, 100 validation images, and 200 testing images. From each training image, 200 patches of size <inline-formula><mml:math id="mm137" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>96</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>96</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> pixels are extracted, resulting in a total of 100,000 training samples. Data augmentation methods, such as bidirectional flips, rotations, and scaling, are applied to increase image diversity.</p><p>To evaluate performance, several benchmark datasets are selected, each addressing specific challenges in image reconstruction:</p><p>(1) UCMerced Land Use Dataset: This dataset includes 21 land-use classes, each containing 100 images at a spatial resolution of 0.3 m. The dataset evaluates how well the model processes and distinguishes diverse land cover patterns.</p><p>(2) Urban100 [<xref rid="B38-sensors-25-01026" ref-type="bibr">38</xref>]: This high-resolution dataset focuses on urban architecture and building facades. It tests the model&#x02019;s ability to capture detailed structural features in dense urban environments.</p><p>(3) BSD100 [<xref rid="B39-sensors-25-01026" ref-type="bibr">39</xref>]: A dataset of natural scene images, which features a range of terrain types and vegetation patterns. It provides insight into the model&#x02019;s generalization capabilities across varied natural landscapes.</p><p>(4) Set5 [<xref rid="B40-sensors-25-01026" ref-type="bibr">40</xref>]: This benchmark dataset contains high-resolution images designed to evaluate the reconstruction of fine-scale features. It is particularly useful for scenarios where precise detail recovery is critical.</p><p>Each dataset presents unique challenges, offering insights into the model&#x02019;s behavior under different conditions. These datasets also serve as standardized benchmarks, enabling direct comparisons with existing methods such as ISTA-Net+, Csformer [<xref rid="B41-sensors-25-01026" ref-type="bibr">41</xref>], AMP-Net, CPP-Net [<xref rid="B42-sensors-25-01026" ref-type="bibr">42</xref>], and TransCS. By incorporating diverse structural patterns, textures, and details, the evaluation framework ensures a rigorous assessment of reconstruction performance. The observed results reflect the model&#x02019;s ability to adapt to various image characteristics, confirming its effectiveness in reconstructing high-quality images under challenging conditions.</p><p>All experiments were conducted using PyTorch 1.9.0 on a machine equipped with an Intel<sup>&#x000ae;</sup> Xeon<sup>&#x000ae;</sup> 8336 CPU and a GeForce RTX 4090 GPU. To ensure fair comparison, all competing models were trained using the same BSD500 dataset and evaluated under identical conditions across all test datasets.</p></sec><sec id="sec4dot2-sensors-25-01026"><title>4.2. Comparisons with State-of-the-Art Methods</title><p><xref rid="sensors-25-01026-t001" ref-type="table">Table 1</xref> presents comprehensive quantitative comparisons between SSM-Net and current state-of-the-art methods across four benchmark datasets (UCMerced, Set5, Urban100, and BSD100) at various sampling rates (<inline-formula><mml:math id="mm138" overflow="scroll"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula>). The sampling rate <inline-formula><mml:math id="mm139" overflow="scroll"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula> is defined as the ratio between the number of measurements <italic toggle="yes">M</italic> and the total number of pixels in the image <italic toggle="yes">N</italic>. Specifically, we define the sampling rate as<disp-formula><mml:math id="mm140" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>M</mml:mi><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This sampling rate controls how much of the image is used during the reconstruction process, with lower values of <inline-formula><mml:math id="mm141" overflow="scroll"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula> corresponding to higher levels of compression. The experimental results demonstrate that SSM-Net achieves competitive or superior performance compared to existing approaches.</p><p>On the UCMerced dataset, which consists of satellite remote sensing imagery, SSM-Net demonstrates competitive performance particularly at lower sampling rates. At <inline-formula><mml:math id="mm142" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, our method achieves a PSNR of 25.28 dB and an SSIM of 0.6959, outperforming both CSformer (25.21 dB/0.6957) and TransCS (25.18 dB/0.6950). The advantage is more pronounced at <inline-formula><mml:math id="mm143" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, where SSM-Net achieves 29.53 dB PSNR and 0.8449 SSIM, surpassing TransCS (29.41 dB/0.8412) and CSformer (29.47 dB/0.8437). At <inline-formula><mml:math id="mm144" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, our method achieves the highest PSNR of 34.71 dB among all compared methods, demonstrating its particular effectiveness in medium-rate compression scenarios for remote sensing applications. While the performance shows some limitations at very high sampling rates (<inline-formula><mml:math id="mm145" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), the strong results in the critical low-to-medium sampling rate range highlight SSM-Net&#x02019;s practical value for bandwidth-constrained remote sensing scenarios where efficient compression is most needed.</p><p>For the Set5 dataset, SSM-Net demonstrates superior performance across the full range of sampling rates. At lower rates (<inline-formula><mml:math id="mm146" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm147" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.04</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), our method achieves 23.37 dB and 29.32 dB PSNR, respectively, outperforming TransCS (22.98 dB and 29.02 dB). This advantage is maintained through medium rates (<inline-formula><mml:math id="mm148" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm149" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) with PSNRs of 37.61 dB and 38.74 dB, and extends to higher rates (<inline-formula><mml:math id="mm150" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm151" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) reaching 41.81 dB and 42.72 dB, consistently surpassing both TransCS and CSformer across all compression levels.</p><p>In the Urban100 dataset, which contains complex urban structures, SSM-Net shows balanced performance across different sampling rates. While slightly lower than TransCS at <inline-formula><mml:math id="mm152" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (19.18 dB vs. 19.53 dB), our method demonstrates competitive results at medium rates (<inline-formula><mml:math id="mm153" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm154" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) with PSNRs of 30.78 dB and 31.21 dB, and achieves superior reconstruction at higher rates (<inline-formula><mml:math id="mm155" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm156" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) with values of 33.34 dB and 34.93 dB, respectively, demonstrating particular effectiveness in preserving architectural details.</p><p>On the BSD100 dataset, featuring diverse natural landscapes, SSM-Net exhibits strong performance across sampling rates, with notable advantages at medium to high rates. Starting from <inline-formula><mml:math id="mm157" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> with 27.60 dB PSNR, our method shows progressive improvement through <inline-formula><mml:math id="mm158" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm159" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (31.45 dB and 32.79 dB), culminating in strong high-rate performance at <inline-formula><mml:math id="mm160" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm161" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (34.96 dB and 36.89 dB). This consistent scaling demonstrates our method&#x02019;s effectiveness in handling varied natural textures across different compression levels.</p><p><xref rid="sensors-25-01026-t002" ref-type="table">Table 2</xref> further shows the WS-PSNR and MSSIM comparisons of different image reconstruction methods on the UCMerced, Set5, Urban100, and BSD100 datasets at various sampling rates (<inline-formula><mml:math id="mm162" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.04</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). The results show that SSM-Net can achieve the current state-of-the-art performance on various datasets and sampling rates.</p><p><xref rid="sensors-25-01026-f002" ref-type="fig">Figure 2</xref> demonstrates the reconstruction results for satellite sensing images. As shown in the detailed regions (highlighted by red boxes), SSM-Net achieves superior reconstruction quality with PSNR/SSIM values of 33.41/0.8443 and 33.32/0.9192 for different sampling rates, effectively preserving both global structure and fine details in remote sensing imagery.</p><p><xref rid="sensors-25-01026-f003" ref-type="fig">Figure 3</xref> provides additional visual comparisons for high-resolution images. The results show that SSM-Net better preserves fine textures and sharp edges, achieving PSNR/SSIM values of 31.55/0.8896 and 35.42/0.9753 for different test cases. This visual quality improvement aligns with the quantitative metrics, confirming our method&#x02019;s effectiveness in maintaining both structural integrity and local details.</p><p>These comprehensive results demonstrate that SSM-Net has achieved state-of-the-art performance, consistently matching or exceeding existing methods across different datasets and sampling rates. The balanced performance across various scenarios, particularly in remote sensing applications, validates our approach of combining momentum-based optimization with efficient feature modeling through the Mamba architecture.</p></sec><sec id="sec4dot3-sensors-25-01026"><title>4.3. Noise Robustness Analysis</title><p>We evaluate our method&#x02019;s robustness against measurement noise using the BSD100 dataset. Our experiments introduce Gaussian noise with different variances at various sampling rates (<inline-formula><mml:math id="mm163" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>0.04</mml:mn><mml:mo>,</mml:mo><mml:mn>0.10</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). <xref rid="sensors-25-01026-t003" ref-type="table">Table 3</xref> presents the quantitative comparisons between SSM-Net, AMP-Net, and Csformer under these conditions.</p><p>SSM-Net consistently outperforms the competing methods across all noise levels and sampling rates. At low noise (<inline-formula><mml:math id="mm164" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), our method achieves higher PSNR values than both AMP-Net and Csformer, with improvements of up to 0.95 dB at <inline-formula><mml:math id="mm165" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. This advantage remains evident at higher noise levels (<inline-formula><mml:math id="mm166" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), where SSM-Net maintains better reconstruction quality with PSNR values of 22.74 dB, 24.31 dB, and 26.06 dB at sampling rates of 0.04, 0.10, and 0.25, respectively.</p><p>The visual comparisons in <xref rid="sensors-25-01026-f004" ref-type="fig">Figure 4</xref> further demonstrate our method&#x02019;s superior noise handling capabilities. SSM-Net preserves more image details and produces cleaner reconstructions compared to AMP-Net and Csformer, particularly in challenging cases with both high noise levels and low sampling rates. These results confirm that our approach offers enhanced stability and reconstruction accuracy in noisy conditions.</p></sec><sec id="sec4dot4-sensors-25-01026"><title>4.4. Training Convergence Rate Analysis</title><p>We analyze the training convergence speed by comparing the PSNR and SSIM curves of different methods during the training process, as shown in <xref rid="sensors-25-01026-f005" ref-type="fig">Figure 5</xref>. The curves are obtained by evaluating performance on the validation set during training iterations.</p><p>Our SSM-Net achieves faster convergence compared to TransCS, reaching stable PSNR and SSIM values within approximately 3000 s. In contrast, TransCS requires nearly 5000 iterations to achieve comparable performance levels. While AMP-Net converges slightly faster, reaching stability at around 2000 s, its final reconstruction quality is notably lower than that of SSM-Net. For example, at sampling rate <inline-formula><mml:math id="mm167" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, SSM-Net achieves a <inline-formula><mml:math id="mm168" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1.23</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> dB PSNR improvement over AMP-Net after convergence.</p><p>The rapid convergence of SSM-Net can be attributed to two factors: the momentum-based optimization strategy from FISTA and the efficient feature modeling of the Mamba architecture. Specifically, FISTA optimizes the training process by incorporating momentum, which accelerates convergence by utilizing information from previous gradients. This allows the model to make larger, more accurate updates during training, speeding up the process and improving performance.</p><p>The Mamba architecture, in contrast to the Transformer-based models, improves convergence by modeling both local and global feature dependencies efficiently. Transformers, while highly effective at capturing global relationships, require extensive computational resources due to their self-attention mechanism, which scales quadratically with the image size. Mamba&#x02019;s state-space modeling (SSM) addresses this challenge by representing dependencies in a more compact and efficient manner, reducing computational complexity. By utilizing SSM, Mamba effectively captures long-range dependencies without the heavy computational burden typical of Transformers, leading to faster convergence and better performance in terms of both quality and efficiency.</p><p>The sudden drop observed in the blue curve (representing SSM-Net) around 2000 s is a notable point. This drop can be explained by the dynamic adjustments the model makes during training. It likely occurs due to the optimization algorithm adapting to the more challenging aspects of the data as the training progresses, where certain features or structures in the image require fine-tuning. This brief decrease is followed by rapid recovery, indicating that the model&#x02019;s optimization strategy is robust enough to handle such challenges, and it stabilizes quickly. This behavior highlights the balance between exploration and fine-tuning during training, which is an essential aspect of the learning process.</p><p>Thus, the combination of FISTA&#x02019;s momentum-based optimization and Mamba&#x02019;s state-space modeling contributes significantly to the fast convergence of SSM-Net. The architecture&#x02019;s efficiency in modeling dependencies and its ability to quickly adapt to complex image features ensure that the network converges faster while maintaining high reconstruction quality.</p></sec><sec id="sec4dot5-sensors-25-01026"><title>4.5. Complexity Analysis</title><p>We analyze the computational complexity of SSM-Net compared to existing methods. All experiments use a standard input size of <inline-formula><mml:math id="mm169" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>256</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> pixels and sampling rate <inline-formula><mml:math id="mm170" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>As shown in <xref rid="sensors-25-01026-f006" ref-type="fig">Figure 6</xref>, SSM-Net requires 26.6626 GFLOPs (billion floating-point operations), which falls between lightweight models like CSNet (11.49 GFLOPs) and heavier models like ISTA-Net+ (30.931 GFLOPs). The parameter count of SSM-Net is 1.654 M, similar to that of TransCS (1.489 M). This moderate computational cost enables SSM-Net to achieve superior reconstruction quality while maintaining reasonable efficiency. In terms of energy consumption, SSM-Net requires 68.11 W, which is higher than lightweight models such as CSNet (29.35 W) and CSformer (29.49 W), but still more efficient than models like ISTA-Net+ (79.01 W). Similarly, SSM-Net&#x02019;s memory usage stands at 892.38 MB, which is significantly higher than CSNet&#x02019;s 173.78 MB and CSformer&#x02019;s 347.56 MB, but lower than TransCS (803.60 MB) and ISTA-Net + (220.73 MB). These values highlight the trade-off between higher model performance and the increased computational cost in terms of energy consumption and memory usage.</p><p><xref rid="sensors-25-01026-t004" ref-type="table">Table 4</xref> shows inference time comparisons on an RTX 4090 GPU. SSM-Net consistently processes images in approximately 0.0202 s across different sampling rates. This stable processing time demonstrates better scalability compared to methods like CSformer, which shows increasing inference times from 0.0469 to 0.0486 s at higher sampling rates. While CSNet achieves faster inference (0.0078&#x02013;0.0099 s), it produces lower-quality reconstructions as shown by the PSNR results.</p><p>The efficiency of SSM-Net comes from the linear complexity of Mamba&#x02019;s state-space model and FISTA&#x02019;s momentum-based optimization. These components work together to provide fast convergence without excessive computational demands. The results show that SSM-Net balances computational cost and reconstruction quality effectively, offering strong performance while maintaining practical processing speeds.</p></sec><sec id="sec4dot6-sensors-25-01026"><title>4.6. Ablation Studies</title><p><xref rid="sensors-25-01026-f007" ref-type="fig">Figure 7</xref> and <xref rid="sensors-25-01026-t005" ref-type="table">Table 5</xref> show the results of the ablation study, which evaluates the impact of removing the FISTA algorithm and the Mamba module on image reconstruction quality and computational efficiency. We compare three configurations: SSM-Net (full model), without FISTA, and without Mamba, as well as Mamba replaced with Transformer.</p><p>Removing the FISTA algorithm results in a significant reduction in reconstruction quality. At <inline-formula><mml:math id="mm171" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, the PSNR drops from 30.78 dB (SSM-Net) to 27.85 dB (without FISTA), while the runtime improves slightly to 0.0180 s per image. This demonstrates that FISTA is crucial for enhancing both the quality and convergence of the reconstruction.</p><p>Similarly, removing the Mamba module also significantly degrades the performance. At <inline-formula><mml:math id="mm172" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, the PSNR decreases from 30.78 dB (SSM-Net) to 28.47 dB (without Mamba). The model also suffers from a loss of important global and local feature modeling, which is essential for high-quality reconstruction. The runtime remains competitive at 0.0184 s per image, but this speed comes at the expense of a noticeable loss in PSNR.</p><p>In contrast, the complete SSM-Net model achieves the best balance between reconstruction quality and computational efficiency. At <inline-formula><mml:math id="mm173" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, SSM-Net delivers a PSNR of 30.78 dB, while the runtime is 0.0204 s per image. This shows that the Mamba module plays a key role in improving the reconstruction quality without introducing significant computational overhead.</p><p>Finally, replacing Mamba with Transformer brings the PSNR closer to the performance of SSM-Net, reaching 30.12 dB at <inline-formula><mml:math id="mm174" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, compared to 28.47 dB without Mamba. However, the computational time increases significantly to 0.024 s per image. This indicates that although the Transformer configuration achieves PSNR values near SSM-Net, it incurs a substantial increase in runtime due to the quadratic complexity of attention mechanisms, making it less efficient than SSM-Net.</p><p>The ablation study demonstrates the critical role of both the Mamba module and FISTA in improving the reconstruction quality. Removing the Mamba module reduces the model&#x02019;s ability to capture global and local dependencies, as evidenced by the significant drop in PSNR. This shows that Mamba&#x02019;s capability to model these dependencies is essential for preserving fine image details.</p><p>In contrast, FISTA optimization enhances the reconstruction process by accelerating convergence and refining the image quality. When FISTA is removed, the network&#x02019;s reconstruction is slower, and the model struggles to reach the same level of accuracy. This is reflected in the lower PSNR of &#x0201c;without FISTA&#x0201d; compared to SSM-Net, particularly at higher compression rates, where FISTA&#x02019;s optimization is most beneficial.</p><p>These comparisons clearly demonstrate the benefits of the full SSM-Net model. Removing FISTA or Mamba degrades both the quality and efficiency of the model, while the Transformer-based alternative, although offering PSNR values close to those of SSM-Net, suffers from a substantial increase in runtime. This underscores the importance of Mamba in maintaining high-quality reconstruction with minimal computational cost.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-01026"><title>5. Conclusions</title><p>In this paper, we propose SSM-Net, a new framework for efficient remote sensing image reconstruction based on SSM and deep unfolding techniques. The framework integrates a sampling module for efficient data compression, an initial reconstruction module for fast signal estimation, and a deep reconstruction module that iteratively refines the results. By leveraging FISTA-inspired momentum updates and selective state-space modeling, SSM-Net achieves a balance between reconstruction accuracy, computational efficiency, and fast training convergence.</p><p>Comprehensive experiments on standard benchmark datasets demonstrate that SSM-Net offers competitive performance in terms of PSNR and SSIM while maintaining a lightweight architecture and computational efficiency. Although the training process exploits natural image datasets, the framework exhibits strong generalization potential for remote sensing scenarios. Its modular design ensures adaptability and scalability, making it a practical solution for real-world remote sensing applications where storage and transmission constraints are critical.</p><p>Looking ahead, we aim to further optimize the proposed framework by incorporating ideas from the Mamba-2 model, particularly the selective state-space decoding SSD methodology. The SSD concept introduces more effective ways of modeling spatial dependencies, which can potentially enhance reconstruction accuracy and robustness. Additionally, we plan to explore domain-specific adaptations of SSM-Net by fine-tuning the framework on large-scale remote sensing datasets, including hyperspectral and SAR images. These advancements will further extend the applicability of SSM-Net, paving the way for its deployment in practical remote sensing systems.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><app-group><app id="app1-sensors-25-01026"><title>Supplementary Materials</title><p>The following supporting information can be downloaded at: <uri xlink:href="https://www.mdpi.com/article/10.3390/s25041026/s1">https://www.mdpi.com/article/10.3390/s25041026/s1</uri>.</p><supplementary-material id="sensors-25-01026-s001" position="float" content-type="local-data"><media xlink:href="sensors-25-01026-s001.zip"/></supplementary-material></app></app-group><notes><title>Author Contributions</title><p>Conceptualization, X.G. and Y.Y.; methodology, X.G. and B.C.; software, X.G. and X.Y.; validation, X.G., B.C. and X.Y.; formal analysis, X.G. and X.Y.; data curation, X.G.; writing&#x02014;original draft preparation, X.G. and B.C.; writing&#x02014;review and editing, B.C. and Y.Y.; funding acquisition, Y.Y. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The original contributions presented in this study are included in the article/<xref rid="app1-sensors-25-01026" ref-type="app">Supplementary Material</xref>.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare that they have no conflicts of interest to report regarding the present study.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01026"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Donoho</surname><given-names>D.</given-names></name>
</person-group><article-title>Compressed sensing</article-title><source>IEEE Trans. Inf. Theory</source><year>2006</year><volume>52</volume><fpage>1289</fpage><lpage>1306</lpage><pub-id pub-id-type="doi">10.1109/TIT.2006.871582</pub-id></element-citation></ref><ref id="B2-sensors-25-01026"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hariri</surname><given-names>A.</given-names></name>
<name><surname>Babaie-Zadeh</surname><given-names>M.</given-names></name>
</person-group><article-title>Compressive detection of sparse signals in additive white Gaussian noise without signal reconstruction</article-title><source>Signal Process.</source><year>2017</year><volume>131</volume><fpage>376</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1016/j.sigpro.2016.08.020</pub-id></element-citation></ref><ref id="B3-sensors-25-01026"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Usala</surname><given-names>J.D.</given-names></name>
<name><surname>Maag</surname><given-names>A.</given-names></name>
<name><surname>Nelis</surname><given-names>T.</given-names></name>
<name><surname>Gamez</surname><given-names>G.</given-names></name>
</person-group><article-title>Compressed sensing spectral imaging for plasma optical emission spectroscopy</article-title><source>J. Anal. At. Spectrom.</source><year>2016</year><volume>31</volume><fpage>2198</fpage><lpage>2206</lpage><pub-id pub-id-type="doi">10.1039/C6JA00261G</pub-id></element-citation></ref><ref id="B4-sensors-25-01026"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Bu</surname><given-names>H.</given-names></name>
<name><surname>Tao</surname><given-names>R.</given-names></name>
<name><surname>Bai</surname><given-names>X.</given-names></name>
<name><surname>Zhao</surname><given-names>J.</given-names></name>
</person-group><article-title>A novel SAR imaging algorithm based on compressed sensing</article-title><source>IEEE Geosci. Remote. Sens. Lett.</source><year>2014</year><volume>12</volume><fpage>1003</fpage><lpage>1007</lpage><pub-id pub-id-type="doi">10.1109/LGRS.2014.2372319</pub-id></element-citation></ref><ref id="B5-sensors-25-01026"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Goodsell</surname><given-names>R.M.</given-names></name>
<name><surname>Coutts</surname><given-names>S.</given-names></name>
<name><surname>Oxford</surname><given-names>W.</given-names></name>
<name><surname>Hicks</surname><given-names>H.</given-names></name>
<name><surname>Comont</surname><given-names>D.</given-names></name>
<name><surname>Freckleton</surname><given-names>R.P.</given-names></name>
<name><surname>Childs</surname><given-names>D.Z.</given-names></name>
</person-group><article-title>Black-Grass Monitoring Using Hyperspectral Image Data Is Limited by Between-Site Variability</article-title><source>Remote Sens.</source><year>2024</year><volume>16</volume><elocation-id>4749</elocation-id><pub-id pub-id-type="doi">10.3390/rs16244749</pub-id></element-citation></ref><ref id="B6-sensors-25-01026"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chanda</surname><given-names>M.</given-names></name>
<name><surname>Hossain</surname><given-names>A.K.M.A.</given-names></name>
</person-group><article-title>Application of PlanetScope Imagery for Flood Mapping: A Case Study in South Chickamauga Creek, Chattanooga, Tennessee</article-title><source>Remote Sens.</source><year>2024</year><volume>16</volume><elocation-id>4437</elocation-id><pub-id pub-id-type="doi">10.3390/rs16234437</pub-id></element-citation></ref><ref id="B7-sensors-25-01026"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ren</surname><given-names>D.</given-names></name>
<name><surname>Qiu</surname><given-names>X.</given-names></name>
<name><surname>An</surname><given-names>Z.</given-names></name>
</person-group><article-title>A Multi-Source Data-Driven Analysis of Building Functional Classification and Its Relationship with Population Distribution</article-title><source>Remote Sens.</source><year>2024</year><volume>16</volume><elocation-id>4492</elocation-id><pub-id pub-id-type="doi">10.3390/rs16234492</pub-id></element-citation></ref><ref id="B8-sensors-25-01026"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Tropp</surname><given-names>J.A.</given-names></name>
<name><surname>Gilbert</surname><given-names>A.C.</given-names></name>
</person-group><article-title>Signal recovery from random measurements via orthogonal matching pursuit</article-title><source>IEEE Trans. Inf. Theory</source><year>2007</year><volume>53</volume><fpage>4655</fpage><lpage>4666</lpage><pub-id pub-id-type="doi">10.1109/TIT.2007.909108</pub-id></element-citation></ref><ref id="B9-sensors-25-01026"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Daubechies</surname><given-names>I.</given-names></name>
<name><surname>Defrise</surname><given-names>M.</given-names></name>
<name><surname>De Mol</surname><given-names>C.</given-names></name>
</person-group><article-title>An iterative thresholding algorithm for linear inverse problems with a sparsity constraint</article-title><source>Commun. Pure Appl. Math. J. Issued Courant Inst. Math. Sci.</source><year>2004</year><volume>57</volume><fpage>1413</fpage><lpage>1457</lpage><pub-id pub-id-type="doi">10.1002/cpa.20042</pub-id></element-citation></ref><ref id="B10-sensors-25-01026"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Beck</surname><given-names>A.</given-names></name>
<name><surname>Teboulle</surname><given-names>M.</given-names></name>
</person-group><article-title>A fast iterative shrinkage-thresholding algorithm for linear inverse problems</article-title><source>SIAM J. Imaging Sci.</source><year>2009</year><volume>2</volume><fpage>183</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1137/080716542</pub-id></element-citation></ref><ref id="B11-sensors-25-01026"><label>11.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>J.</given-names></name>
<name><surname>Ghanem</surname><given-names>B.</given-names></name>
</person-group><article-title>ISTA-Net: Interpretable optimization-inspired deep network for image compressive sensing</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City</source><conf-loc>UT, USA</conf-loc><conf-date>18&#x02013;22 June 2018</conf-date><fpage>1828</fpage><lpage>1837</lpage></element-citation></ref><ref id="B12-sensors-25-01026"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yang</surname><given-names>Y.</given-names></name>
<name><surname>Sun</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>H.</given-names></name>
<name><surname>Xu</surname><given-names>Z.</given-names></name>
</person-group><article-title>ADMM-CSNet: A deep learning approach for image compressive sensing</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2018</year><volume>42</volume><fpage>521</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2018.2883941</pub-id><pub-id pub-id-type="pmid">30507495</pub-id>
</element-citation></ref><ref id="B13-sensors-25-01026"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shen</surname><given-names>M.</given-names></name>
<name><surname>Gan</surname><given-names>H.</given-names></name>
<name><surname>Ning</surname><given-names>C.</given-names></name>
<name><surname>Hua</surname><given-names>Y.</given-names></name>
<name><surname>Zhang</surname><given-names>T.</given-names></name>
</person-group><article-title>TransCS: A transformer-based hybrid architecture for image compressed sensing</article-title><source>IEEE Trans. Image Process.</source><year>2022</year><volume>31</volume><fpage>6991</fpage><lpage>7005</lpage><pub-id pub-id-type="doi">10.1109/TIP.2022.3217365</pub-id><pub-id pub-id-type="pmid">36318549</pub-id>
</element-citation></ref><ref id="B14-sensors-25-01026"><label>14.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kabkab</surname><given-names>M.</given-names></name>
<name><surname>Samangouei</surname><given-names>P.</given-names></name>
<name><surname>Chellappa</surname><given-names>R.</given-names></name>
</person-group><article-title>Task-aware compressed sensing with generative adversarial networks</article-title><source>Proceedings of the AAAI Conference on Artificial Intelligence</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>2&#x02013;7 February 2018</conf-date><volume>Volume 32</volume></element-citation></ref><ref id="B15-sensors-25-01026"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Sun</surname><given-names>Y.</given-names></name>
<name><surname>Chen</surname><given-names>J.</given-names></name>
<name><surname>Liu</surname><given-names>Q.</given-names></name>
<name><surname>Liu</surname><given-names>G.</given-names></name>
</person-group><article-title>Learning image compressed sensing with sub-pixel convolutional generative adversarial network</article-title><source>Pattern Recognit.</source><year>2020</year><volume>98</volume><fpage>107051</fpage><pub-id pub-id-type="doi">10.1016/j.patcog.2019.107051</pub-id></element-citation></ref><ref id="B16-sensors-25-01026"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kumar</surname><given-names>A.</given-names></name>
<name><surname>Upadhyay</surname><given-names>N.</given-names></name>
<name><surname>Ghosal</surname><given-names>P.</given-names></name>
<name><surname>Chowdhury</surname><given-names>T.</given-names></name>
<name><surname>Das</surname><given-names>D.</given-names></name>
<name><surname>Mukherjee</surname><given-names>A.</given-names></name>
<name><surname>Nandi</surname><given-names>D.</given-names></name>
</person-group><article-title>CSNet: A new DeepNet framework for ischemic stroke lesion segmentation</article-title><source>Comput. Methods Programs Biomed.</source><year>2020</year><volume>193</volume><elocation-id>105524</elocation-id><pub-id pub-id-type="doi">10.1016/j.cmpb.2020.105524</pub-id><pub-id pub-id-type="pmid">32417618</pub-id>
</element-citation></ref><ref id="B17-sensors-25-01026"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Gilton</surname><given-names>D.</given-names></name>
<name><surname>Ongie</surname><given-names>G.</given-names></name>
<name><surname>Willett</surname><given-names>R.</given-names></name>
</person-group><article-title>Neumann networks for linear inverse problems in imaging</article-title><source>IEEE Trans. Comput. Imaging</source><year>2019</year><volume>6</volume><fpage>328</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1109/TCI.2019.2948732</pub-id></element-citation></ref><ref id="B18-sensors-25-01026"><label>18.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Guo</surname><given-names>Z.</given-names></name>
<name><surname>Zhang</surname><given-names>J.</given-names></name>
</person-group><article-title>Lightweight Dilated Residual Convolution AMP Network for Image Compressed Sensing</article-title><source>Proceedings of the 2023 4th International Conference on Computer Engineering and Application (ICCEA)</source><conf-loc>Hangzhou, China</conf-loc><conf-date>7&#x02013;9 April 2023</conf-date><fpage>747</fpage><lpage>752</lpage></element-citation></ref><ref id="B19-sensors-25-01026"><label>19.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kulkarni</surname><given-names>K.</given-names></name>
<name><surname>Lohit</surname><given-names>S.</given-names></name>
<name><surname>Turaga</surname><given-names>P.</given-names></name>
<name><surname>Kerviche</surname><given-names>R.</given-names></name>
<name><surname>Ashok</surname><given-names>A.</given-names></name>
</person-group><article-title>Reconnet: Non-iterative reconstruction of images from compressively sensed measurements</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>27&#x02013;30 June 2016</conf-date><fpage>449</fpage><lpage>458</lpage></element-citation></ref><ref id="B20-sensors-25-01026"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yao</surname><given-names>H.</given-names></name>
<name><surname>Dai</surname><given-names>F.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Tian</surname><given-names>Q.</given-names></name>
<name><surname>Xu</surname><given-names>C.</given-names></name>
</person-group><article-title>Dr2-net: Deep residual reconstruction network for image compressive sensing</article-title><source>Neurocomputing</source><year>2019</year><volume>359</volume><fpage>483</fpage><lpage>493</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2019.05.006</pub-id></element-citation></ref><ref id="B21-sensors-25-01026"><label>21.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Yu</surname><given-names>F.</given-names></name>
<name><surname>Qian</surname><given-names>Y.</given-names></name>
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Gil-Ureta</surname><given-names>F.</given-names></name>
<name><surname>Jackson</surname><given-names>B.</given-names></name>
<name><surname>Bennett</surname><given-names>E.</given-names></name>
<name><surname>Zhang</surname><given-names>H.</given-names></name>
</person-group><article-title>Dpa-net: Structured 3d abstraction from sparse views via differentiable primitive assembly</article-title><source>European Conference on Computer Vision</source><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2025</year><fpage>454</fpage><lpage>471</lpage></element-citation></ref><ref id="B22-sensors-25-01026"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Song</surname><given-names>J.</given-names></name>
<name><surname>Chen</surname><given-names>B.</given-names></name>
<name><surname>Zhang</surname><given-names>J.</given-names></name>
</person-group><article-title>Dynamic path-controllable deep unfolding network for compressive sensing</article-title><source>IEEE Trans. Image Process.</source><year>2023</year><volume>32</volume><fpage>2202</fpage><lpage>2214</lpage><pub-id pub-id-type="doi">10.1109/TIP.2023.3263100</pub-id><pub-id pub-id-type="pmid">37037236</pub-id>
</element-citation></ref><ref id="B23-sensors-25-01026"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Gan</surname><given-names>H.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
<name><surname>He</surname><given-names>L.</given-names></name>
<name><surname>Liu</surname><given-names>J.</given-names></name>
</person-group><article-title>Learned two-step iterative shrinkage thresholding algorithm for deep compressive sensing</article-title><source>IEEE Trans. Circuits Syst. Video Technol.</source><year>2023</year><volume>34</volume><fpage>3943</fpage><lpage>3956</lpage><pub-id pub-id-type="doi">10.1109/TCSVT.2023.3325340</pub-id></element-citation></ref><ref id="B24-sensors-25-01026"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Gu</surname><given-names>A.</given-names></name>
<name><surname>Dao</surname><given-names>T.</given-names></name>
</person-group><article-title>Mamba: Linear-time sequence modeling with selective state spaces</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type="arxiv">2312.00752</pub-id></element-citation></ref><ref id="B25-sensors-25-01026"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dao</surname><given-names>T.</given-names></name>
<name><surname>Gu</surname><given-names>A.</given-names></name>
</person-group><article-title>Transformers are SSMs: Generalized models and efficient algorithms through structured state space duality</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2405.21060</pub-id></element-citation></ref><ref id="B26-sensors-25-01026"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhu</surname><given-names>L.</given-names></name>
<name><surname>Liao</surname><given-names>B.</given-names></name>
<name><surname>Zhang</surname><given-names>Q.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
<name><surname>Liu</surname><given-names>W.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
</person-group><article-title>Vision mamba: Efficient visual representation learning with bidirectional state space model</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2401.09417</pub-id></element-citation></ref><ref id="B27-sensors-25-01026"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>C.</given-names></name>
<name><surname>Tsepa</surname><given-names>O.</given-names></name>
<name><surname>Ma</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>B.</given-names></name>
</person-group><article-title>Graph-mamba: Towards long-range graph sequence modeling with selective state spaces</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2402.00789</pub-id></element-citation></ref><ref id="B28-sensors-25-01026"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>T.</given-names></name>
<name><surname>Pei</surname><given-names>X.</given-names></name>
<name><surname>You</surname><given-names>S.</given-names></name>
<name><surname>Wang</surname><given-names>F.</given-names></name>
<name><surname>Qian</surname><given-names>C.</given-names></name>
<name><surname>Xu</surname><given-names>C.</given-names></name>
</person-group><article-title>Localmamba: Visual state space model with windowed selective scan</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2403.09338</pub-id></element-citation></ref><ref id="B29-sensors-25-01026"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pei</surname><given-names>X.</given-names></name>
<name><surname>Huang</surname><given-names>T.</given-names></name>
<name><surname>Xu</surname><given-names>C.</given-names></name>
</person-group><article-title>Efficientvmamba: Atrous selective scan for light weight visual mamba</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2403.09977</pub-id></element-citation></ref><ref id="B30-sensors-25-01026"><label>30.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>S.</given-names></name>
<name><surname>Singh</surname><given-names>H.</given-names></name>
<name><surname>Grover</surname><given-names>A.</given-names></name>
</person-group><article-title>Mamba-nd: Selective state space modeling for multi-dimensional data</article-title><source>European Conference on Computer Vision</source><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2025</year><fpage>75</fpage><lpage>92</lpage></element-citation></ref><ref id="B31-sensors-25-01026"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Behrouz</surname><given-names>A.</given-names></name>
<name><surname>Santacatterina</surname><given-names>M.</given-names></name>
<name><surname>Zabih</surname><given-names>R.</given-names></name>
</person-group><article-title>Mambamixer: Efficient selective state space models with dual token and channel selection</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2403.19888</pub-id></element-citation></ref><ref id="B32-sensors-25-01026"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>F.</given-names></name>
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Ren</surname><given-names>S.</given-names></name>
<name><surname>Wei</surname><given-names>G.</given-names></name>
<name><surname>Mei</surname><given-names>J.</given-names></name>
<name><surname>Shao</surname><given-names>W.</given-names></name>
<name><surname>Zhou</surname><given-names>Y.</given-names></name>
<name><surname>Yuille</surname><given-names>A.</given-names></name>
<name><surname>Xie</surname><given-names>C.</given-names></name>
</person-group><article-title>Mamba-r: Vision mamba also needs registers</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2405.14858</pub-id></element-citation></ref><ref id="B33-sensors-25-01026"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Yang</surname><given-names>C.</given-names></name>
<name><surname>Chen</surname><given-names>Z.</given-names></name>
<name><surname>Espinosa</surname><given-names>M.</given-names></name>
<name><surname>Ericsson</surname><given-names>L.</given-names></name>
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Liu</surname><given-names>J.</given-names></name>
<name><surname>Crowley</surname><given-names>E.J.</given-names></name>
</person-group><article-title>Plainmamba: Improving non-hierarchical mamba in visual recognition</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2403.17695</pub-id></element-citation></ref><ref id="B34-sensors-25-01026"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ma</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>F.</given-names></name>
<name><surname>Wang</surname><given-names>B.</given-names></name>
</person-group><article-title>U-mamba: Enhancing long-range dependency for biomedical image segmentation</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2401.04722</pub-id></element-citation></ref><ref id="B35-sensors-25-01026"><label>35.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>J.</given-names></name>
<name><surname>Yang</surname><given-names>H.</given-names></name>
<name><surname>Zhou</surname><given-names>H.Y.</given-names></name>
<name><surname>Xi</surname><given-names>Y.</given-names></name>
<name><surname>Yu</surname><given-names>L.</given-names></name>
<name><surname>Li</surname><given-names>C.</given-names></name>
<name><surname>Liang</surname><given-names>Y.</given-names></name>
<name><surname>Shi</surname><given-names>G.</given-names></name>
<name><surname>Yu</surname><given-names>Y.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
<etal/>
</person-group><article-title>Swin-umamba: Mamba-based unet with imagenet-based pretraining</article-title><source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2024</year><fpage>615</fpage><lpage>625</lpage></element-citation></ref><ref id="B36-sensors-25-01026"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Zheng</surname><given-names>J.Q.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Cui</surname><given-names>G.</given-names></name>
<name><surname>Li</surname><given-names>L.</given-names></name>
</person-group><article-title>Mamba-unet: Unet-like pure visual mamba for medical image segmentation</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2402.05079</pub-id></element-citation></ref><ref id="B37-sensors-25-01026"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Arbelaez</surname><given-names>P.</given-names></name>
<name><surname>Maire</surname><given-names>M.</given-names></name>
<name><surname>Fowlkes</surname><given-names>C.</given-names></name>
<name><surname>Malik</surname><given-names>J.</given-names></name>
</person-group><article-title>Contour detection and hierarchical image segmentation</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2010</year><volume>33</volume><fpage>898</fpage><lpage>916</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2010.161</pub-id></element-citation></ref><ref id="B38-sensors-25-01026"><label>38.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>J.B.</given-names></name>
<name><surname>Singh</surname><given-names>A.</given-names></name>
<name><surname>Ahuja</surname><given-names>N.</given-names></name>
</person-group><article-title>Single image super-resolution from transformed self-exemplars</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-loc>Boston, MA, USA</conf-loc><conf-date>7&#x02013;12 June 2015</conf-date><fpage>5197</fpage><lpage>5206</lpage></element-citation></ref><ref id="B39-sensors-25-01026"><label>39.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Martin</surname><given-names>D.</given-names></name>
<name><surname>Fowlkes</surname><given-names>C.</given-names></name>
<name><surname>Tal</surname><given-names>D.</given-names></name>
<name><surname>Malik</surname><given-names>J.</given-names></name>
</person-group><article-title>A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</article-title><source>Proceedings of the Eighth IEEE International Conference on Computer Vision, ICCV 2001</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>7&#x02013;14 July 2001</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>Piscataway, NJ, USA</publisher-loc><year>2001</year><volume>Volume 2</volume><fpage>416</fpage><lpage>423</lpage></element-citation></ref><ref id="B40-sensors-25-01026"><label>40.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Bevilacqua</surname><given-names>M.</given-names></name>
<name><surname>Roumy</surname><given-names>A.</given-names></name>
<name><surname>Guillemot</surname><given-names>C.</given-names></name>
<name><surname>Alberi-Morel</surname><given-names>M.L.</given-names></name>
</person-group><article-title>Low-complexity single-image super-resolution based on nonnegative neighbor embedding</article-title><source>Proceedings of the 23rd British Machine Vision Conference (BMVC)</source><conf-loc>Surrey, UK</conf-loc><conf-date>3&#x02013;7 September 2012</conf-date></element-citation></ref><ref id="B41-sensors-25-01026"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ye</surname><given-names>D.</given-names></name>
<name><surname>Ni</surname><given-names>Z.</given-names></name>
<name><surname>Wang</surname><given-names>H.</given-names></name>
<name><surname>Zhang</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>S.</given-names></name>
<name><surname>Kwong</surname><given-names>S.</given-names></name>
</person-group><article-title>CSformer: Bridging convolution and transformer for compressive sensing</article-title><source>IEEE Trans. Image Process.</source><year>2023</year><volume>32</volume><fpage>2827</fpage><lpage>2842</lpage><pub-id pub-id-type="doi">10.1109/TIP.2023.3274988</pub-id><pub-id pub-id-type="pmid">37186533</pub-id>
</element-citation></ref><ref id="B42-sensors-25-01026"><label>42.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Guo</surname><given-names>Z.</given-names></name>
<name><surname>Gan</surname><given-names>H.</given-names></name>
</person-group><article-title>CPP-Net: Embracing Multi-Scale Feature Fusion into Deep Unfolding CP-PPA Network for Compressive Sensing</article-title><source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</source><conf-loc>Seattle, WA, USA</conf-loc><conf-date>16&#x02013;22 June 2024</conf-date><fpage>25086</fpage><lpage>25095</lpage></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01026-f001"><label>Figure 1</label><caption><p>System model.</p></caption><graphic xlink:href="sensors-25-01026-g001" position="float"/></fig><fig position="float" id="sensors-25-01026-f002"><label>Figure 2</label><caption><p>Reconstruction results for satellite sensing images using SSM-Net and other methods. Sampling rates <inline-formula><mml:math id="mm175" overflow="scroll"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula> are 0.04 for the first row and 0.1 for the second row. Please zoom in for better comparison.</p></caption><graphic xlink:href="sensors-25-01026-g002" position="float"/></fig><fig position="float" id="sensors-25-01026-f003"><label>Figure 3</label><caption><p>Reconstruction results for high-resolution images using SSM-Net and other methods. Sampling rates <inline-formula><mml:math id="mm176" overflow="scroll"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula> are 0.04 for the first row and 0.25 for the second row. Please zoom in for better comparison.</p></caption><graphic xlink:href="sensors-25-01026-g003" position="float"/></fig><fig position="float" id="sensors-25-01026-f004"><label>Figure 4</label><caption><p>Noise robustness comparison. Visual analysis of different CS methods on images from the BSD100 dataset at sampling rates <inline-formula><mml:math id="mm177" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mn>0.04</mml:mn><mml:mo>,</mml:mo><mml:mn>0.10</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Gaussian noise with variances <inline-formula><mml:math id="mm178" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.002</mml:mn><mml:mo>,</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> was introduced. Note the effectiveness in recovering the images.</p></caption><graphic xlink:href="sensors-25-01026-g004" position="float"/></fig><fig position="float" id="sensors-25-01026-f005"><label>Figure 5</label><caption><p>PSNR and SSIM changes in models trained in different ways as training time increases.</p></caption><graphic xlink:href="sensors-25-01026-g005" position="float"/></fig><fig position="float" id="sensors-25-01026-f006"><label>Figure 6</label><caption><p>Comparison of GFLOPs, parameters, memory consumption, and energy consumption for a <inline-formula><mml:math id="mm179" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>256</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> pixel image with <inline-formula><mml:math id="mm180" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></caption><graphic xlink:href="sensors-25-01026-g006" position="float"/></fig><fig position="float" id="sensors-25-01026-f007"><label>Figure 7</label><caption><p>Effectiveness of Mamba and FISTA in SSM-Net reconstruction.</p></caption><graphic xlink:href="sensors-25-01026-g007" position="float"/></fig><table-wrap position="float" id="sensors-25-01026-t001"><object-id pub-id-type="pii">sensors-25-01026-t001_Table 1</object-id><label>Table 1</label><caption><p>PSNR (dB) and SSIM comparisons of different methods on datasets Urban100, BSD100, and Set5 at multiple sampling rates (<inline-formula><mml:math id="mm181" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.04</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mn>0.3</mml:mn><mml:mo>,</mml:mo><mml:mn>0.4</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). The highest value is marked in red, and the second highest value is marked in blue.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Datasets</th><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Methods</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.01</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.04</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.10</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.25</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.30</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.40</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.50</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th></tr></thead><tbody><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">UCMerced</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">17.82</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4127</td><td align="center" valign="middle" rowspan="1" colspan="1">21.65</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5892</td><td align="center" valign="middle" rowspan="1" colspan="1">25.44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7165</td><td align="center" valign="middle" rowspan="1" colspan="1">29.78</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8825</td><td align="center" valign="middle" rowspan="1" colspan="1">31.04</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9061</td><td align="center" valign="middle" rowspan="1" colspan="1">33.32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9373</td><td align="center" valign="middle" rowspan="1" colspan="1">35.36</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9571</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">18.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4438</td><td align="center" valign="middle" rowspan="1" colspan="1">22.69</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6173</td><td align="center" valign="middle" rowspan="1" colspan="1">26.17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7789</td><td align="center" valign="middle" rowspan="1" colspan="1">30.76</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9033</td><td align="center" valign="middle" rowspan="1" colspan="1">32.52</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9278</td><td align="center" valign="middle" rowspan="1" colspan="1">34.83</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9462</td><td align="center" valign="middle" rowspan="1" colspan="1">36.47</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9627</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">19.12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4567</td><td align="center" valign="middle" rowspan="1" colspan="1">23.74</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6513</td><td align="center" valign="middle" rowspan="1" colspan="1">27.90</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7959</td><td align="center" valign="middle" rowspan="1" colspan="1">32.55</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9174</td><td align="center" valign="middle" rowspan="1" colspan="1">33.44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9317</td><td align="center" valign="middle" rowspan="1" colspan="1">35.26</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9521</td><td align="center" valign="middle" rowspan="1" colspan="1">37.65</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9702</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>21.76</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.4836</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">25.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6950</td><td align="center" valign="middle" rowspan="1" colspan="1">29.41</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8412</td><td align="center" valign="middle" rowspan="1" colspan="1">34.03</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9303</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>36.12</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9527</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>38.45</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9692</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>40.56</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9785</bold>
</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">21.52</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.4793</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">25.21</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6957</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">29.47</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.8437</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">34.57</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9387</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">35.97</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9513</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">38.21</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9675</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">40.23</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9771</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">21.40</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4783</td><td align="center" valign="middle" rowspan="1" colspan="1">25.14</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6908</td><td align="center" valign="middle" rowspan="1" colspan="1">29.46</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8427</td><td align="center" valign="middle" rowspan="1" colspan="1">34.23</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9328</td><td align="center" valign="middle" rowspan="1" colspan="1">35.55</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9498</td><td align="center" valign="middle" rowspan="1" colspan="1">37.11</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9629</td><td align="center" valign="middle" rowspan="1" colspan="1">39.31</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9758</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21.38</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.4705</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>25.28</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.6959</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>29.53</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.8449</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>34.71</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9398</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">35.89</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9511</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">36.12</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9568</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">37.33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9613</td></tr><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Set5</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">20.25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5608</td><td align="center" valign="middle" rowspan="1" colspan="1">23.42</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6287</td><td align="center" valign="middle" rowspan="1" colspan="1">28.47</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8309</td><td align="center" valign="middle" rowspan="1" colspan="1">34.02</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9188</td><td align="center" valign="middle" rowspan="1" colspan="1">35.38</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9397</td><td align="center" valign="middle" rowspan="1" colspan="1">37.44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9573</td><td align="center" valign="middle" rowspan="1" colspan="1">39.25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9689</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">20.15</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5447</td><td align="center" valign="middle" rowspan="1" colspan="1">27.12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7988</td><td align="center" valign="middle" rowspan="1" colspan="1">31.07</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8925</td><td align="center" valign="middle" rowspan="1" colspan="1">35.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9473</td><td align="center" valign="middle" rowspan="1" colspan="1">37.25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9473</td><td align="center" valign="middle" rowspan="1" colspan="1">38.91</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9611</td><td align="center" valign="middle" rowspan="1" colspan="1">40.74</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9691</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">20.45</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5563</td><td align="center" valign="middle" rowspan="1" colspan="1">27.25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8065</td><td align="center" valign="middle" rowspan="1" colspan="1">31.43</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8977</td><td align="center" valign="middle" rowspan="1" colspan="1">36.25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9514</td><td align="center" valign="middle" rowspan="1" colspan="1">37.82</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9583</td><td align="center" valign="middle" rowspan="1" colspan="1">39.55</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9694</td><td align="center" valign="middle" rowspan="1" colspan="1">41.48</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9756</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">22.98</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6287</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">29.02</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.8317</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">32.74</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9235</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">37.26</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9625</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">38.53</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9693</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">41.40</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9773</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">42.42</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9846</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">21.84</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5892</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">29.27</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8239</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">33.04</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9243</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">37.04</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9583</td><td align="center" valign="middle" rowspan="1" colspan="1">38.44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9614</td><td align="center" valign="middle" rowspan="1" colspan="1">40.62</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9723</td><td align="center" valign="middle" rowspan="1" colspan="1">42.37</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9793</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">22.63</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6214</td><td align="center" valign="middle" rowspan="1" colspan="1">29.19</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8259</td><td align="center" valign="middle" rowspan="1" colspan="1">32.64</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9240</td><td align="center" valign="middle" rowspan="1" colspan="1">37.12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9592</td><td align="center" valign="middle" rowspan="1" colspan="1">38.24</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9598</td><td align="center" valign="middle" rowspan="1" colspan="1">40.90</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9746</td><td align="center" valign="middle" rowspan="1" colspan="1">42.25</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9769</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>23.37</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.6311</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>29.32</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.8377</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>33.17</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9250</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>37.61</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9647</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>38.74</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9712</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>41.81</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9796</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>42.72</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9849</bold>
</named-content>
</td></tr><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Urban100</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">15.23</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4127</td><td align="center" valign="middle" rowspan="1" colspan="1">19.65</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5351</td><td align="center" valign="middle" rowspan="1" colspan="1">23.44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7165</td><td align="center" valign="middle" rowspan="1" colspan="1">28.78</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8825</td><td align="center" valign="middle" rowspan="1" colspan="1">30.04</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9061</td><td align="center" valign="middle" rowspan="1" colspan="1">32.32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9373</td><td align="center" valign="middle" rowspan="1" colspan="1">34.36</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9571</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">15.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4438</td><td align="center" valign="middle" rowspan="1" colspan="1">19.69</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5973</td><td align="center" valign="middle" rowspan="1" colspan="1">23.17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7789</td><td align="center" valign="middle" rowspan="1" colspan="1">28.76</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9033</td><td align="center" valign="middle" rowspan="1" colspan="1">29.52</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9278</td><td align="center" valign="middle" rowspan="1" colspan="1">32.83</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9462</td><td align="center" valign="middle" rowspan="1" colspan="1">33.47</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9627</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">16.12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4567</td><td align="center" valign="middle" rowspan="1" colspan="1">20.74</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6013</td><td align="center" valign="middle" rowspan="1" colspan="1">23.90</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7859</td><td align="center" valign="middle" rowspan="1" colspan="1">29.55</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9174</td><td align="center" valign="middle" rowspan="1" colspan="1">30.44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9317</td><td align="center" valign="middle" rowspan="1" colspan="1">33.26</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9521</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">34.65</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9702</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>19.53</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.5104</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">22.30</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.6938</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>25.87</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.8334</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">30.46</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9215</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>31.47</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9446</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>33.49</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9621</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">34.58</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9711</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">18.92</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4893</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>22.57</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6781</td><td align="center" valign="middle" rowspan="1" colspan="1">25.27</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8213</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">30.57</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9287</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">31.07</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9313</td><td align="center" valign="middle" rowspan="1" colspan="1">33.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9575</td><td align="center" valign="middle" rowspan="1" colspan="1">34.23</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9721</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">18.83</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4856</td><td align="center" valign="middle" rowspan="1" colspan="1">22.19</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6759</td><td align="center" valign="middle" rowspan="1" colspan="1">25.32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8255</td><td align="center" valign="middle" rowspan="1" colspan="1">30.22</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9269</td><td align="center" valign="middle" rowspan="1" colspan="1">31.17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9358</td><td align="center" valign="middle" rowspan="1" colspan="1">33.16</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9549</td><td align="center" valign="middle" rowspan="1" colspan="1">34.60</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9699</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">19.18</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.4992</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21.79</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6857</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">25.43</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.8293</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>30.78</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9398</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">31.21</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9372</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">33.34</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9583</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>34.93</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9725</bold>
</named-content>
</td></tr><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">BSD100</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">17.45</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4234</td><td align="center" valign="middle" rowspan="1" colspan="1">22.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5397</td><td align="center" valign="middle" rowspan="1" colspan="1">24.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6837</td><td align="center" valign="middle" rowspan="1" colspan="1">28.83</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8379</td><td align="center" valign="middle" rowspan="1" colspan="1">29.92</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8673</td><td align="center" valign="middle" rowspan="1" colspan="1">31.77</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9063</td><td align="center" valign="middle" rowspan="1" colspan="1">33.52</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9357</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">18.23</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4567</td><td align="center" valign="middle" rowspan="1" colspan="1">23.77</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6497</td><td align="center" valign="middle" rowspan="1" colspan="1">26.31</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7714</td><td align="center" valign="middle" rowspan="1" colspan="1">30.04</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8997</td><td align="center" valign="middle" rowspan="1" colspan="1">30.69</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9135</td><td align="center" valign="middle" rowspan="1" colspan="1">32.94</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9299</td><td align="center" valign="middle" rowspan="1" colspan="1">34.96</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9478</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">18.67</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4623</td><td align="center" valign="middle" rowspan="1" colspan="1">24.04</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6537</td><td align="center" valign="middle" rowspan="1" colspan="1">26.16</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7688</td><td align="center" valign="middle" rowspan="1" colspan="1">30.13</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9002</td><td align="center" valign="middle" rowspan="1" colspan="1">30.88</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9142</td><td align="center" valign="middle" rowspan="1" colspan="1">33.24</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9379</td><td align="center" valign="middle" rowspan="1" colspan="1">35.43</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9517</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">22.26</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.4848</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">24.68</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6633</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>27.76</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.7945</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>31.54</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9031</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">32.27</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9215</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">34.52</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9499</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">36.52</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9671</bold>
</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>22.42</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.4892</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">24.96</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.6709</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">26.54</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7749</td><td align="center" valign="middle" rowspan="1" colspan="1">30.75</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9022</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">31.54</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9189</td><td align="center" valign="middle" rowspan="1" colspan="1">34.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9443</td><td align="center" valign="middle" rowspan="1" colspan="1">35.91</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9589</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">22.15</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4836</td><td align="center" valign="middle" rowspan="1" colspan="1">24.78</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6684</td><td align="center" valign="middle" rowspan="1" colspan="1">27.38</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7895</td><td align="center" valign="middle" rowspan="1" colspan="1">30.95</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9012</td><td align="center" valign="middle" rowspan="1" colspan="1">31.97</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9207</td><td align="center" valign="middle" rowspan="1" colspan="1">34.35</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9478</td><td align="center" valign="middle" rowspan="1" colspan="1">36.24</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9584</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21.87</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.4797</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>25.12</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6690</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">27.60</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.7903</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">31.45</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.8910</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>32.79</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9237</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>34.96</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.9522</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>36.89</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9577</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01026-t002"><object-id pub-id-type="pii">sensors-25-01026-t002_Table 2</object-id><label>Table 2</label><caption><p>WS-PSNR (dB) and MSSIM comparisons of different methods on datasets Urban100, BSD100, and Set5 at multiple sampling rates (<inline-formula><mml:math id="mm182" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.04</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). The highest value is marked in red, and the second highest value is marked in blue.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Datasets</th><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Methods</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.01</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.04</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.10</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.25</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">0.50</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WS-PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MSSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WS-PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MSSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WS-PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MSSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WS-PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MSSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WS-PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MSSIM</th></tr></thead><tbody><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">UCMerced</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">16.03</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4457</td><td align="center" valign="middle" rowspan="1" colspan="1">18.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6079</td><td align="center" valign="middle" rowspan="1" colspan="1">21.88</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7351</td><td align="center" valign="middle" rowspan="1" colspan="1">27.69</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8913</td><td align="center" valign="middle" rowspan="1" colspan="1">33.28</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9565</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">17.11</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4998</td><td align="center" valign="middle" rowspan="1" colspan="1">20.12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6354</td><td align="center" valign="middle" rowspan="1" colspan="1">23.98</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7972</td><td align="center" valign="middle" rowspan="1" colspan="1">28.63</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9121</td><td align="center" valign="middle" rowspan="1" colspan="1">34.39</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9611</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">17.37</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5139</td><td align="center" valign="middle" rowspan="1" colspan="1">20.19</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6698</td><td align="center" valign="middle" rowspan="1" colspan="1">24.32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8142</td><td align="center" valign="middle" rowspan="1" colspan="1">30.48</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9259</td><td align="center" valign="middle" rowspan="1" colspan="1">35.57</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9694</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">19.87</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.5321</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7621</td><td align="center" valign="middle" rowspan="1" colspan="1">26.92</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8922</td><td align="center" valign="middle" rowspan="1" colspan="1">31.97</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9487</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">38.41</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9881</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">19.62</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.5308</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">22.54</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.7682</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">27.18</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.8957</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">32.43</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9572</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">38.37</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9868</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">18.48</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5271</td><td align="center" valign="middle" rowspan="1" colspan="1">22.13</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7607</td><td align="center" valign="middle" rowspan="1" colspan="1">27.01</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8937</td><td align="center" valign="middle" rowspan="1" colspan="1">32.05</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9502</td><td align="center" valign="middle" rowspan="1" colspan="1">38.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9849</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18.87</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.5274</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">22.67</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.7690</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">27.26</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.8965</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">32.49</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9590</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">36.31</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9778</td></tr><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Set5</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">16.68</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5791</td><td align="center" valign="middle" rowspan="1" colspan="1">18.85</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6469</td><td align="center" valign="middle" rowspan="1" colspan="1">26.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8487</td><td align="center" valign="middle" rowspan="1" colspan="1">31.95</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9271</td><td align="center" valign="middle" rowspan="1" colspan="1">35.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9579</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">17.59</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5629</td><td align="center" valign="middle" rowspan="1" colspan="1">19.92</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8161</td><td align="center" valign="middle" rowspan="1" colspan="1">29.49</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9108</td><td align="center" valign="middle" rowspan="1" colspan="1">33.81</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9556</td><td align="center" valign="middle" rowspan="1" colspan="1">36.24</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9662</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">17.88</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5746</td><td align="center" valign="middle" rowspan="1" colspan="1">23.68</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8239</td><td align="center" valign="middle" rowspan="1" colspan="1">29.86</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9159</td><td align="center" valign="middle" rowspan="1" colspan="1">34.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9597</td><td align="center" valign="middle" rowspan="1" colspan="1">36.41</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9688</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">19.32</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6552</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">24.97</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.8784</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">30.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9479</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">35.19</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9708</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">37.54</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9745</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">19.12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6542</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">25.08</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8776</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">30.47</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9515</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">34.97</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9666</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">37.91</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9793</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">19.27</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6521</td><td align="center" valign="middle" rowspan="1" colspan="1">24.65</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8749</td><td align="center" valign="middle" rowspan="1" colspan="1">30.07</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9427</td><td align="center" valign="middle" rowspan="1" colspan="1">34.95</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9675</td><td align="center" valign="middle" rowspan="1" colspan="1">37.42</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9762</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">19.96</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.6589</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">25.17</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.8798</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">30.64</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9522</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">34.83</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9728</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">37.70</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9788</named-content>
</td></tr><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Urban100</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">13.65</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4309</td><td align="center" valign="middle" rowspan="1" colspan="1">17.08</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5534</td><td align="center" valign="middle" rowspan="1" colspan="1">20.87</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7348</td><td align="center" valign="middle" rowspan="1" colspan="1">26.71</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8909</td><td align="center" valign="middle" rowspan="1" colspan="1">32.29</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9504</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">14.33</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4611</td><td align="center" valign="middle" rowspan="1" colspan="1">17.12</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6156</td><td align="center" valign="middle" rowspan="1" colspan="1">21.59</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7972</td><td align="center" valign="middle" rowspan="1" colspan="1">26.68</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9117</td><td align="center" valign="middle" rowspan="1" colspan="1">31.40</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9520</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">14.57</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4742</td><td align="center" valign="middle" rowspan="1" colspan="1">18.17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6196</td><td align="center" valign="middle" rowspan="1" colspan="1">22.33</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8429</td><td align="center" valign="middle" rowspan="1" colspan="1">27.48</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9257</td><td align="center" valign="middle" rowspan="1" colspan="1">31.58</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9595</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">16.85</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.5279</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">19.98</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.7618</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">24.29</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.8991</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">28.39</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9298</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">32.16</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9704</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">15.43</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5197</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">19.72</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.7554</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">22.98</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8821</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">28.49</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9370</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">32.51</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9714</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">15.24</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5182</td><td align="center" valign="middle" rowspan="1" colspan="1">19.01</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7532</td><td align="center" valign="middle" rowspan="1" colspan="1">23.02</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8832</td><td align="center" valign="middle" rowspan="1" colspan="1">28.05</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9352</td><td align="center" valign="middle" rowspan="1" colspan="1">31.84</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9689</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">15.89</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.5202</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">19.15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.7544</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">23.11</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.8839</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">27.29</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9377</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">31.78</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9629</td></tr><tr><td rowspan="7" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">BSD100</td><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+ (CVPR2018)</td><td align="center" valign="middle" rowspan="1" colspan="1">15.88</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4417</td><td align="center" valign="middle" rowspan="1" colspan="1">17.64</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5581</td><td align="center" valign="middle" rowspan="1" colspan="1">20.32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7019</td><td align="center" valign="middle" rowspan="1" colspan="1">24.78</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8462</td><td align="center" valign="middle" rowspan="1" colspan="1">30.45</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9449</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet (TIP2019)</td><td align="center" valign="middle" rowspan="1" colspan="1">16.66</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4751</td><td align="center" valign="middle" rowspan="1" colspan="1">20.20</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6680</td><td align="center" valign="middle" rowspan="1" colspan="1">22.74</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7897</td><td align="center" valign="middle" rowspan="1" colspan="1">26.81</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9080</td><td align="center" valign="middle" rowspan="1" colspan="1">31.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9571</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net (TIP2021)</td><td align="center" valign="middle" rowspan="1" colspan="1">17.10</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4806</td><td align="center" valign="middle" rowspan="1" colspan="1">20.42</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6720</td><td align="center" valign="middle" rowspan="1" colspan="1">22.59</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7871</td><td align="center" valign="middle" rowspan="1" colspan="1">27.06</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9085</td><td align="center" valign="middle" rowspan="1" colspan="1">31.36</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9510</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS (TIP2022)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">18.69</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.5642</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">21.11</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7416</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">25.19</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.8572</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">28.23</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9214</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">34.45</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.9699</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer (TIP2023)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">18.85</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.5666</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">21.39</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.7492</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">24.34</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8541</td><td align="center" valign="middle" rowspan="1" colspan="1">27.89</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9199</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">33.84</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.9682</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPP-Net (CVPR2024)</td><td align="center" valign="middle" rowspan="1" colspan="1">18.58</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5607</td><td align="center" valign="middle" rowspan="1" colspan="1">21.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7423</td><td align="center" valign="middle" rowspan="1" colspan="1">24.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.8478</td><td align="center" valign="middle" rowspan="1" colspan="1">27.84</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9185</td><td align="center" valign="middle" rowspan="1" colspan="1">33.17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9677</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net (Ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18.49</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.5621</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">21.47</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.7462</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">24.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.8552</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">27.92</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9182</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32.53</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9583</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01026-t003"><object-id pub-id-type="pii">sensors-25-01026-t003_Table 3</object-id><label>Table 3</label><caption><p>PSNR (dB) and SSIM comparisons on BSD100 with different noise levels <inline-formula><mml:math id="mm183" overflow="scroll"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow></mml:math></inline-formula> and various sampling rates <inline-formula><mml:math id="mm184" overflow="scroll"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">
<inline-formula>
<mml:math id="mm185" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold-italic">&#x003c3;</mml:mi></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">
<inline-formula>
<mml:math id="mm186" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">AMP-Net</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Csformer</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">SSM-Net</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM</th></tr></thead><tbody><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.04</td><td align="center" valign="middle" rowspan="1" colspan="1">23.28</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5475</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">24.12</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.5483</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>24.23</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.5509</bold>
</named-content>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.10</td><td align="center" valign="middle" rowspan="1" colspan="1">25.32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6558</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">26.21</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6722</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>26.38</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.6760</bold>
</named-content>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">27.73</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.7930</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">28.54</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.7932</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>28.75</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.7946</bold>
</named-content>
</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.04</td><td align="center" valign="middle" rowspan="1" colspan="1">22.59</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4879</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">23.41</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.4923</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>23.54</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.4957</bold>
</named-content>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.10</td><td align="center" valign="middle" rowspan="1" colspan="1">24.17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6052</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">25.31</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6198</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>25.44</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.6241</bold>
</named-content>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">27.23</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.7583</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">27.33</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.7512</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>27.46</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.7537</bold>
</named-content>
</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">0.004</td><td align="center" valign="middle" rowspan="1" colspan="1">0.04</td><td align="center" valign="middle" rowspan="1" colspan="1">20.56</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4317</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">22.56</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.4246</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>22.74</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.4262</bold>
</named-content>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.10</td><td align="center" valign="middle" rowspan="1" colspan="1">22.53</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5289</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">24.18</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.5312</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>24.31</bold>
</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.5331</bold>
</named-content>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">25.41</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.6825</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">25.89</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #0000FF">0.6943</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>26.06</bold>
</named-content>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">
<bold>0.6972</bold>
</named-content>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01026-t004"><object-id pub-id-type="pii">sensors-25-01026-t004_Table 4</object-id><label>Table 4</label><caption><p>Time consumption (in seconds) of different methods under various compression rates <inline-formula><mml:math id="mm187" overflow="scroll"><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math></inline-formula> on GPU: RTX 4090.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Methods</th><th colspan="5" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">GPU Time Consumption (s)</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Platform</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><inline-formula><mml:math id="mm188" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> = 0.10
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><inline-formula><mml:math id="mm189" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> = 0.25
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><inline-formula><mml:math id="mm190" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> = 0.30
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><inline-formula><mml:math id="mm191" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> = 0.40
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><inline-formula><mml:math id="mm192" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> = 0.50
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">ISTA-Net+</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0227</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0232</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0238</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0241</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0247</td><td rowspan="6" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">RTX 4090</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSNet</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0078</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0084</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0089</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0095</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0099</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CSformer</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0469</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0471</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0476</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0480</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0486</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AMP-Net</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0165</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0177</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0181</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0189</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0194</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TransCS</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0241</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0245</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0247</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0251</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0257</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0201</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0203</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0202</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0203</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0203</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01026-t005"><object-id pub-id-type="pii">sensors-25-01026-t005_Table 5</object-id><label>Table 5</label><caption><p>Comparisons of PSNR results (dB) and GPU runtime on 4090 for different methods with an input image of pixel size 256 &#x000d7; 256.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Methods</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin" rowspan="1">
<inline-formula>
<mml:math id="mm193" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.10</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin" rowspan="1">
<inline-formula>
<mml:math id="mm194" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin" rowspan="1">
<inline-formula>
<mml:math id="mm195" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003c4;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.30</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR (dB)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GPU Time (s)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR (dB)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GPU Time (s)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PSNR (dB</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GPU Time (s)</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">Without Mamba</td><td align="center" valign="middle" rowspan="1" colspan="1">26.58</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0182</td><td align="center" valign="middle" rowspan="1" colspan="1">28.47</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0184</td><td align="center" valign="middle" rowspan="1" colspan="1">29.84</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0185</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">Without FISTA</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">25.40</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.0175</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">27.85</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.0180</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">29.10</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.0182</named-content>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">Mamba replaced with Transformer</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">28.74</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.0234</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">30.12</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.024</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">31.89</named-content>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<named-content content-type="color: #FF0000">0.025</named-content>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSM-Net</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">29.32</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0201</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30.78</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0204</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32.45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0207</td></tr></tbody></table></table-wrap></floats-group></article>