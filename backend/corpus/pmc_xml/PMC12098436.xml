<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="review-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Pediatr</journal-id><journal-id journal-id-type="iso-abbrev">Front Pediatr</journal-id><journal-id journal-id-type="publisher-id">Front. Pediatr.</journal-id><journal-title-group><journal-title>Frontiers in Pediatrics</journal-title></journal-title-group><issn pub-type="epub">2296-2360</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC12098436</article-id><article-id pub-id-type="doi">10.3389/fped.2025.1558951</article-id><article-categories><subj-group subj-group-type="heading"><subject>Pediatrics</subject><subj-group><subject>Review</subject></subj-group></subj-group></article-categories><title-group><article-title>The significance of an infant's cry: a narrative review of physiological, pathological, and analytical perspectives</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Wang</surname><given-names>Zimai</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="an1" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Cai</surname><given-names>Yurui</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="an1" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Wang</surname><given-names>Xiaojun</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="an1" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author"><name><surname>Wu</surname><given-names>Shiyi</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author"><name><surname>Cao</surname><given-names>Yixin</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Xu</surname><given-names>Fan</given-names></name><xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref><xref rid="cor1" ref-type="corresp">*</xref><uri xlink:href="https://loop.frontiersin.org/people/1093562/overview"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Huang</surname><given-names>Min</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="cor1" ref-type="corresp">*</xref><uri xlink:href="https://loop.frontiersin.org/people/2531406/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff id="aff1"><label><sup>1</sup></label><institution>Department of Physiology, School of Basic Medical Sciences, Chengdu Medical College</institution>, <addr-line>Chengdu</addr-line>, <country>China</country></aff><aff id="aff2"><label><sup>2</sup></label><institution>School of Clinical Medicine, Chengdu Medical College</institution>, <addr-line>Chengdu</addr-line>, <country>China</country></aff><aff id="aff3"><label><sup>3</sup></label><institution>Department of Evidence-based Medicine and Social Medicine, School of Public Health, Chengdu Medical College</institution>, <addr-line>Chengdu</addr-line>, <country>China</country></aff><author-notes><fn fn-type="edited-by"><p><bold>Edited by:</bold> Silvia Orlandi, University of Bologna, Italy</p></fn><fn fn-type="edited-by"><p><bold>Reviewed by:</bold> Yun Cheng Jia, Guizhou Minzu University, China</p><p>Gianpaolo Coro, National Research Council (CNR), Italy</p><p>Andrea Bandini, Sant'Anna School of Advanced Studies, Italy</p></fn><corresp id="cor1"><label>*</label><bold>Correspondence:</bold> Fan Xu <email>xufan@cmc.edu.cn</email> Min Huang <email>huangmin@cmc.edu.cn</email></corresp><fn fn-type="equal" id="an1"><label>
<sup>&#x02020;</sup>
</label><p>These authors have contributed equally to this work</p></fn></author-notes><pub-date pub-type="epub"><day>09</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>13</volume><elocation-id>1558951</elocation-id><history><date date-type="received"><day>11</day><month>1</month><year>2025</year></date><date date-type="accepted"><day>21</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 Wang, Cai, Wang, Wu, Cao, Xu and Huang.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Wang, Cai, Wang, Wu, Cao, Xu and Huang</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License (CC BY)</ext-link>. The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>Infants communicate with the outside world through their cries, which often differ for various reasons. Moreover, the cries of healthy and specific pathological conditions (e.g., neurological damage) can be different. Changes in the physical and mental states can cause crying. Infant cries are characterised by a variety of features, including changes in pitch, tempo, and volume. Crying can serve as a biological indicator of an infant's health and emotions. To facilitate timely treatment, parents and caregivers can effectively understand the state of their infant by observing and identifying the characteristics of their cries. Analysis of the cries of infant with neurological disorders or severe diseases may facilitate early diagnosis of diseases and protect an infant from motor and intellectual impairments. In this article, we discuss the physiological process, causes, analysis, and application of infant cry. The purpose of this article was to fill the gap in the existing literature on the systematic integration of multi-dimensional (physiological, pathological, and psychological) analysis and deep learning applications of infant crying, and to highlight the potential of infant crying as biological indicator and in precision care.</p></abstract><kwd-group><kwd>infant cry</kwd><kwd>feature extraction</kwd><kwd>infant care</kwd><kwd>somatic system disorders</kwd><kwd>neurodevelopmental and neuropsychiatric disorders</kwd></kwd-group><funding-group><funding-statement>The author(s) declare that financial support was received for the research and/or publication of this article. This study was supported by National Key R&#x00026;D Program of China (2023YFE0108400), Sichuan Provincial Key Laboratory of Nursing (HLKF2023(F)-1), Sichuan Provincial Administration of Traditional Chinese Medicine (2023MS100), Sichuan Provincial Key Research Base of Social Sciences, Sichuan Research Centre for Applied Psychology (CSXL-23202), Key Discipline Project at the School of Public Health, Chengdu Medical College (No. 21), School joint funding (23LHPDZYB08), Sichuan applied psychology research centre (CSXL-24215). Also thank the valuable support from the medical sound database from Chengdu Medical College (<ext-link xlink:href="http://ama.cmc.edu.cn" ext-link-type="uri">http://ama.cmc.edu.cn</ext-link>).</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="3"/><equation-count count="2"/><ref-count count="75"/><page-count count="12"/><word-count count="0"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Children and Health</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="background" id="s1"><title>Background</title><p>Crying is a behavioural state in which infants express basic needs and sensations such as hunger and pain (<xref rid="B1" ref-type="bibr">1</xref>). Globally, about 130 million babies are born each year. Taking good care of a newborn is a huge challenge, especially for first-time parents (<xref rid="B2" ref-type="bibr">2</xref>). Simply following the advice of other parents and guidebooks is not enough to solve practical problems. A major issue is the difficulty new parents have in understanding the significance of infant cries. Experienced parents, caregivers, doctors, and nurses understand cries based on their experience (<xref rid="B3" ref-type="bibr">3</xref>). Accurately interpreting infant cries can help parents take better care of their babies. More importantly, the production of a cry requires coordination of multiple systems, and changes in one system may alter the characteristics of crying. As a result, infant cries reflect the degree of coordination of multiple organs and can be used to assess the physical condition of an infant. Therefore, it is necessary to understand the meaning behind an infant's cry.</p><p>However, infant crying is the intertwined result of multiple complex factors, which encompass the infant's age, personality traits, environmental conditions, and prior experiences. These factors interact with each other, collectively shaping the unique and variable characteristics of infant crying. Given the complexity and diversity of crying, conducting in-depth and detailed analysis faces numerous challenges, and existing analytical methods often fail to fully and accurately reveal all the information underlying it.</p><p>In recent years, published papers on infant cry have mostly focused on the in-depth analysis of its acoustic characteristics. However, there is still a lack of a comprehensive summary regarding the timing of infant crying, the physiological mechanisms underlying cry production, and the practical applications of infant crying. This narrative review synthesized evidence on infant cry research from 1968 to 2024. A comprehensive search was conducted across four major biomedical databases: PubMed, Embase, Cochrane Library, and Web of Science. The search terms are shown below: (infant cry OR baby cry OR newborn vocalization OR neonatal vocal behavior) AND (physiological analysis OR pathological indicators OR psychological correlates OR acoustic features OR deep learning OR convolutional neural networks OR biological marker OR infant care). Inclusion criteria encompassed studies investigating cry characteristics, developmental patterns, clinical correlations, or caregiver responses to infant cries. Exclusion criteria removed animal studies.</p><p>This article provides a thorough and detailed elaboration on the timing of infant crying, the physiological processes involved in cry generation, and introduces the current analytical techniques for infant crying as well as their applications in various fields. In terms of applications, this article effectively summarizes the findings in three areas: infant care, somatic system disorders and neurodevelopmental and neuropsychiatric disorders assessment, providing a more comprehensive background for understanding infant crying. This not only helps us to gain a deeper understanding of the intrinsic mechanisms of crying, but also may provide new perspectives and ideas for research in this field, promoting its development to deeper levels and broader areas.</p></sec><sec id="s2"><title>The general physiological process of infant cry</title><p>Complex interactions between many anatomic structures and physiologic mechanisms, that are responsible for the outcome of the infant cry (<xref rid="B4" ref-type="bibr">4</xref>, <xref rid="B5" ref-type="bibr">5</xref>). The nasopharynx, oropharynx, laryngopharynx, and lungs make up the basic human vocal system, The lungs provide airflow for vocalisation through expansion and compression. The most important part of the vocal system is the laryngopharynx, which consists of the pharynx and vocal cords. The vocal cords have two ligamentous folds, and there is a small space between them called the vocal folds (<xref rid="B6" ref-type="bibr">6</xref>). The oropharynx and nasopharynx play the role of resonating cavities in the human vocal system, and the vocal tract is the entire respiratory passage from the vocal folds to the lips. The vibration of the vocal cords emits a &#x0201c;fundamental sound&#x0201d; that is extremely weak, and the sound waves must be resonated by the resonating body in order to expand and beautify the sound (<xref rid="B7" ref-type="bibr">7</xref>). When speaking or making a sound, the airflow exchanged at the vocal folds causes the vocal cords to vibrate, and this vibration eventually resonates through the vocal tract to produce a sound (<xref rid="B8" ref-type="bibr">8</xref>).</p><p>The process of generating a cry is under the coordinated control of several brain regions (mainly the brainstem and limbic system) and requires the respiratory system. The respiratory system produces the airflow to allow vibration of the vocal folds and to make a sound. At the same time, there is resonance in all the other resonance cavities in the human body (<xref rid="B9" ref-type="bibr">9</xref>, <xref rid="B10" ref-type="bibr">10</xref>). Crying is a type of vocalisation and a whole-body movement. As illustrated in <xref rid="F1" ref-type="fig">Figure&#x000a0;1</xref>, the process of crying involves the central nervous system, the respiratory system, the peripheral nervous system, and various muscles. Changes in any component of this system may alter the characteristics of a cry.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p>The process of crying. The production of crying originates from nociceptive or emotional stimuli that activate the amygdala within the limbic system, eliciting a negative emotional response and initiating autonomic stress responses (e.g., accelerated heart rate and respiration) via hypothalamic engagement. The hypothalamus enhances the drive of brainstem respiratory centers (medulla oblongata and pons) through neuroendocrine signaling, inducing the respiratory system (diaphragm and intercostal muscles) to generate high-velocity pulmonary airflow. This airflow traverses the larynx, inducing oscillatory vibrations of the vocal cords, whose vibratory frequency is modulated by motor neurons in the medullary nucleus ambiguus. Concurrently, acoustic resonance within the oropharyngeal and nasopharyngeal cavities amplifies and shapes the sound waves. The neurophysiological integration of these processes culminates in a vocal output characterized by affective features, reflecting the hierarchical coordination of limbic, autonomic, and brainstem motor networks.</p></caption><graphic xlink:href="fped-13-1558951-g001" position="float"/></fig><p>The prenatal period has a significant impact on the development of the vocalization-related systems in newborns, primarily reflected in maternal health (<xref rid="B11" ref-type="bibr">11</xref>), nutritional status, environmental exposures (<xref rid="B12" ref-type="bibr">12</xref>), and psychological state (<xref rid="B13" ref-type="bibr">13</xref>). These aspects collectively influence the structural and functional development of systems critical for infant vocalization. Infant's vocal folds are shorter and thinner, producing sounds at higher frequencies. Adult's vocal folds are longer and thicker, vibrating at lower frequencies, which is why the frequency range of an adult's voice is typically lower (85&#x02005;Hz to 255&#x02005;Hz), whereas the frequency range of an infant's cry is higher (250&#x02005;Hz to 700&#x02005;Hz) (<xref rid="B14" ref-type="bibr">14</xref>). Due to these structural differences, infants produce different sounds compared with adults (<xref rid="B15" ref-type="bibr">15</xref>).</p><p>This difference is not only reflected in the average frequency but also in the range and concentration of the frequency distribution. The frequency range of an adult's voice is broader, covering more low-frequency components, while the frequency of an infant's cry is more concentrated and skewed towards the higher end. This difference has potential implications for sound recognition, speech processing, and acoustic communication. Understanding the fundamental characteristics of infant cries requires an analysis of both their physiological origins and their pathological deviations.</p></sec><sec id="s3"><title>When does an infant cry?</title><p>In the early stages, crying is primarily an expression of physiological needs, and as emotional development progresses, crying gradually becomes a form of emotional expression (<xref rid="B16" ref-type="bibr">16</xref>, <xref rid="B17" ref-type="bibr">17</xref>). Hence, infant cries are important in determining their physical and mental states (<xref rid="B18" ref-type="bibr">18</xref>). Infant crying is defined as a unique behavioural state by which an infant expresses a variety of emotions, physiological needs, and their physical state. Behind the production of an infant's cry is the emotional impact of basic sensations&#x02014;for example, sadness, fear, dread, or anxiety. Mood changes either in the infant itself or changes in the outside world can cause an infant to cry (<xref rid="B3" ref-type="bibr">3</xref>, <xref rid="B19" ref-type="bibr">19</xref>).</p><p>Infants also express their physical needs through crying. When infants feel hunger, pain, restraint (from wearing clothing that is too tight), warm or cold or pressure from a foreign object, they tend to express their discomfort by crying. All the above conditions lead to normal physiological cries, and when the infant's demands are met or their discomfort is resolved, their crying will stop immediately (<xref rid="B20" ref-type="bibr">20</xref>).</p><p>Most importantly, an infant's cry is also an adaptive signal of distress (<xref rid="B21" ref-type="bibr">21</xref>). Crying in infants may be associated with one or more known diseases including infections such as sepsis (<xref rid="B22" ref-type="bibr">22</xref>), fever (<xref rid="B23" ref-type="bibr">23</xref>), deafness (<xref rid="B24" ref-type="bibr">24</xref>), autism (<xref rid="B25" ref-type="bibr">25</xref>),vomiting (<xref rid="B23" ref-type="bibr">23</xref>), meningitis (<xref rid="B23" ref-type="bibr">23</xref>), renal failure (<xref rid="B23" ref-type="bibr">23</xref>), respiratory distress syndrome (RDS) (<xref rid="B26" ref-type="bibr">26</xref>), asphyxia (<xref rid="B23" ref-type="bibr">23</xref>) and jaundice (<xref rid="B27" ref-type="bibr">27</xref>). Early diagnosis of one of these illnesses is critical to ensure timely and effective treatment, so it is important for infant caregivers and parents to understand the needs of infants through their cries. In general, an infant's crying serves as an important signal of their physical and psychological state. By analyzing the frequency and pitch of their cries, it is possible to distinguish between different needs of infants and uncover variations in their physical and emotional responses (<xref rid="B28" ref-type="bibr">28</xref>).</p></sec><sec id="s4"><title>Feature extraction of cry</title><p>The crying signals of infants differ significantly from adult speech. The variations within waveform and spectrogram of infant cries and adult speech are quite distinct, especially in terms of energy, intensity, and frequency. In the context of acoustic signals, energy refers to the total energy of the sound wave over a specified time interval, calculated as the integral of the squared amplitude of the signal. This energy metric, distinct from perceived loudness (which depends on both sound pressure level and frequency sensitivity of the human ear), can serve as an objective indicator for assessing the physiological exertion or duration of a baby's cry, potentially reflecting the degree of distress. Intensity, a measure of sound wave characteristics, is typically closely related to the baby's physical and physiological state. Fundamental frequency (F0), specifically referring to the vibration frequency of the vocal cords, is particularly significant because it provides crucial information on neural or respiratory abnormalities (<xref rid="B29" ref-type="bibr">29</xref>). Due to natural pauses and breathing, infant cry signals exhibit rhythmic and periodic variations. <italic>Chittora</italic> et al. used F_0 contour to find out the unvoiced segments from the infant cry (<xref rid="B30" ref-type="bibr">30</xref>).</p><p>Formants are the frequencies corresponding to prominent amplitude peaks in the sound spectrum, and their occurrence primarily depends on the shape and length of the vocal tract. Each formant corresponds to a specific resonant frequency of the vocal tract. These formants are a direct reflection of the resonant characteristics of the vocal tract during the process of sound production, with the first three typically labeled as F1, F2, and F3. The three formants F1, F2, and F3 are the most critical, as they carry most of the information in the sound, effectively distinguish between different vowels and sound features, and provide valuable information about the shape and length of the vocal tract. They are of great significance for identifying pathological features in infant cries. <italic>Orlandi</italic> et al. used the mean, median, standard deviation, minimum and maximum values of F0 and F1&#x02013;3 to utilize the differences between full-term and preterm infant cries (<xref rid="B31" ref-type="bibr">31</xref>).</p><p>Infant crying is a combination of various forms such as vocalization, silence, coughing, choking, and interruptions, encompassing a diversity of acoustic and prosodic information at different levels. Infant crying research involves data collection, cry signal processing, feature extraction and selection, and classification (<xref rid="B2" ref-type="bibr">2</xref>). Due to the sensitive nature of crying data, it is difficult for researchers to obtain the required data. Signal processing is a necessary step to remove background noise and to segment cries to create a cry database. The quality of audio data is highly dependent on signal pre-processing. This process eliminates irrelevant or unwanted information such as noise and channel distortion (<xref rid="B32" ref-type="bibr">32</xref>). <xref rid="F2" ref-type="fig">Figure&#x000a0;2</xref> provides a detailed summary of the steps involved in the extraction of infant crying.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p>The extraction process of infant crying. (1) Collecting raw audio of infant cries under different physiological states; (2) noise reduction processing, such as employing dual-mode noise reduction technology that combines Adobe Audition&#x000ae; spectral editing with wavelet threshold denoising to effectively eliminate environmental noise; (3) segmentation and annotation: achieving precise segmentation of the expiratory phase based on waveform morphology, frequency characteristics, and duration thresholds, and automatically marking the inspiratory/expiratory cycles through energy envelope detection; (4) parameter calculation and output: such as using MATLAB to extract fundamental frequency, sound intensity and time-domain features, ultimately generating a structured CSV data file with timestamps.</p></caption><graphic xlink:href="fped-13-1558951-g002" position="float"/></fig><p>Feature extraction is the stage where characteristics are derived from audio signals and then input into machine learning algorithms. It is one of the most crucial parts of the machine learning process. Feature extraction in the time domain or frequency domain serves as the fundamental work for cry analysis and processing. Time-domain features, such as zero-crossing rate, amplitude, and energy-based characteristics, are simple and straightforward to calculate. However, time-domain features are not robust enough to cover the variations in infant cry signals, and they are sensitive to background noise (<xref rid="B33" ref-type="bibr">33</xref>). Conversely, frequency-domain features possess strong capabilities to mimic the characteristics of infant cry signals. Combining prosodic features with time-domain or frequency-domain features can capture both physical and physiological information simultaneously.</p><p>Currently, commonly used features like Mel-frequency cepstral coefficient (MFCC) (<xref rid="B33" ref-type="bibr">33</xref>), Linear Prediction Cepstral Coefficients (LPCC) (<xref rid="B34" ref-type="bibr">34</xref>), and Linear Frequency Cepstral Coefficients (LFCC) (<xref rid="B35" ref-type="bibr">35</xref>) have proven to outperform time-domain features (<xref rid="B33" ref-type="bibr">33</xref>). MFCC is widely used in speech recognition as a cepstral representation of an audio signal (<xref rid="B36" ref-type="bibr">36</xref>). It is used by researchers to test proposed methods and is often used for baseline experiments. <italic>Liu</italic> et al. (<xref rid="B37" ref-type="bibr">37</xref>) used MFCC and two other cepstral features, LPCC and Bark Frequency Cepstral Coefficients (BFCC) to categorize the causes of infant crying. The results show that BFCC combined with neural network model can obtain the best recognition rate of 76.47%. The main idea of LPCC is to remove redundancy from the signal and try to predict the next value by linearly combining the previously known coefficients. The LFCC extraction process is like the MFCC extraction process. The difference is that it uses a linear filter -bank instead of the Mel filter-bank (<xref rid="B38" ref-type="bibr">38</xref>). MFCC and LPCC derive from speech recognition, and they aim at describing the phonetic structure of the signal (<xref rid="T1" ref-type="table">Table&#x000a0;1</xref>). However, there are significant differences between infant cries and adult speech or sounds with typical phonetic structures. For this reason, syllabic scale features have indeed proven to be more effective for infant cry detection (<xref rid="B39" ref-type="bibr">39</xref>).</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Comparison of feature extraction methods (MFCC vs. LPCC).</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/></colgroup><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Dimension</th><th valign="top" align="center" rowspan="1" colspan="1">MFCC</th><th valign="top" align="center" rowspan="1" colspan="1">LPCC</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Core Principles</td><td valign="top" align="left" rowspan="1" colspan="1">Based on the auditory characteristics of the human ear, Mel-scale filtering&#x02009;+&#x02009;cepstral analysis</td><td valign="top" align="left" rowspan="1" colspan="1">Based on the vocal tract model, linear predictive analysis&#x02009;+&#x02009;cepstral transformation</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Key steps</td><td valign="top" align="left" rowspan="1" colspan="1">Pre-emphasis&#x02009;&#x02192;&#x02009;Framing&#x02009;&#x02192;&#x02009;FFT&#x02009;&#x02192;&#x02009;Mel Filtering&#x02009;&#x02192;&#x02009;Log Energy&#x02009;&#x02192;&#x02009;DCT</td><td valign="top" align="left" rowspan="1" colspan="1">Pre-emphasis&#x02009;&#x02192;&#x02009;Framing&#x02009;&#x02192;&#x02009;LPC Coefficient Calculation&#x02009;&#x02192;&#x02009;Cepstral Transformation</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Mathematical formulas</td><td valign="top" align="left" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="IM1" overflow="scroll"><mml:msub><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mrow><mml:mo movablelimits="false">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mspace width="0.2em"/><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mspace width="0.2em"/><mml:msub><mml:mi>E</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>cos</mml:mi><mml:mspace width="0.2em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003c0;</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
</inline-formula>
</td><td valign="top" align="left" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="IM2" overflow="scroll"><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">arg</mml:mi></mml:mrow><mml:mspace width=".1em"/><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mspace width=".1em"/><mml:msub><mml:mo movablelimits="false">&#x02211;</mml:mo><mml:mi>n</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:munderover><mml:mrow><mml:mo movablelimits="false">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mspace width="0.2em"/><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math>
</inline-formula>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1"><italic>c<sub>n</sub></italic> represents the n-th MFCC coefficient, <italic>E<sub>k</sub></italic> represents the <italic>k</italic>-th output of the Mel filter bank, and <italic>K</italic> represents the number of Mel filters in the filter bank.</td><td valign="top" align="left" rowspan="1" colspan="1"><italic>a<sub>i</sub></italic> represents the <italic>i</italic>-th LPCC coefficient, <italic>x</italic>(<italic>n</italic>) represents the <italic>n</italic>-th sample of the speech signal, and <italic>p</italic> represents the order of the LPCC coefficients.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Advantages</td><td valign="top" align="left" rowspan="1" colspan="1">Strong noise resistance, in line with auditory perception</td><td valign="top" align="left" rowspan="1" colspan="1">Low computational load, suitable for real-time systems</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Limitations</td><td valign="top" align="left" rowspan="1" colspan="1">Based on the assumption of the Mel scale, high-frequency resolution is low</td><td valign="top" align="left" rowspan="1" colspan="1">Sensitive to noise, assuming source-filter separation</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Typical application scenarios</td><td valign="top" align="left" rowspan="1" colspan="1">speech recognition, voiceprint verification</td><td valign="top" align="left" rowspan="1" colspan="1">Low-resource devices, linear channel modeling</td></tr></tbody></table><table-wrap-foot><fn id="table-fn1"><p>MFCC, mel-frequency cepstral coefficients; LPCC, linear prediction cepstrum coefficients; LPC, linear predictive coding.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s5"><title>Current methods used to classify infant cry</title><p>Methods for classify infant cries have evolved significantly from the initial subjective perception to the objective evaluation of cries using machine learning methods, which have undergone several major breakthroughs. Research on infant cries began as early as the 1960s, based on trained nurses, <italic>Wasz-Hockert</italic> et al. (<xref rid="B40" ref-type="bibr">40</xref>) identified four types of cries: pain, hunger, birth and joy. Early research has confirmed that trained adults could auditorily distinguish between different types of cries. However, training humans to perceive infant cries is more challenging than training machine learning models, as human perception is subjective and prone to bias. In contrast, machine learning models can consistently analyze large datasets and identify subtle patterns that may be missed by human listeners (<xref rid="B2" ref-type="bibr">2</xref>, <xref rid="B41" ref-type="bibr">41</xref>).</p><p>Researchers are beginning to explore the use of machine learning models to analyse and process sound signals. The early days relied heavily on manual feature extraction and simple machine learning algorithms for basic feature extraction and classification of cries. These algorithms learned certain feature patterns in cries from training data and tried to correlate these patterns with specific emotions or need states. These emotional states are usually determined by observing the infant's behavioral and physiological responses, and the need states are usually determined by the experience and observation of parents or caregivers (<xref rid="B3" ref-type="bibr">3</xref>). The establishment of basic facts about the different states usually relies on detailed observation and documentation of the infant's behavior (<xref rid="B22" ref-type="bibr">22</xref>). For example, when an infant cries, caregivers record the infant's behavior, physiological responses (e.g., facial expressions, body movements), and environmental factors (e.g., feeding time, diaper status) (<xref rid="B42" ref-type="bibr">42</xref>). To more accurately determine the underlying facts, a combination of multimodal data, such as video recordings, physiological signals (e.g., heart rate, respiratory rate), and environmental sensor data (<xref rid="B33" ref-type="bibr">33</xref>) These data can provide more comprehensive information to help validate the infant's emotional and need states (<xref rid="B43" ref-type="bibr">43</xref>). The validation process relies on the assessment of pediatricians, psychologists, and nursing specialists to determine and validate the infant's emotional and need states based on their expertise and experience and through consistency checks by multiple experts (<xref rid="B44" ref-type="bibr">44</xref>).</p><p>After the initial establishment of the ground truth, machine learning algorithms can be used to initially categorize the data and then compare the results with the expert assessments to further validate the accuracy of the ground truth (<xref rid="B45" ref-type="bibr">45</xref>). <italic>Mukhopadhyay</italic> et al. (<xref rid="B46" ref-type="bibr">46</xref>) reported that a group of people trained to recognise cries had a maximum classification accuracy of 33.09%, while machine learning algorithms based on spectral and rhythmic features could classify the same set of data with 80.56% accuracy. Thus, different types of cries can be recognised faster and more accurately by machine learning models. It should be noted that multiple studies have already emphasized the influence of the native language on the acoustic features of infant cries. This finding underscores the potential impact of language-specific factors on the ability of machine learning models to recognize infant cries (<xref rid="B47" ref-type="bibr">47</xref>, <xref rid="B48" ref-type="bibr">48</xref>).</p><p>However, due to the complexity and diversity of cry signals, early machine learning algorithms do not have high accuracy and reliability in cry recognition and insufficient ability to process complex features. As the second winter of artificial intelligence (AI) came to an end in the 1990s (<xref rid="B49" ref-type="bibr">49</xref>), early deep learning models (primarily multi-layer neural networks) began gaining traction in infant cry analysis. These deep learning architectures consist of hierarchical layers of artificial neurons that simulate biological neural connectivity. A typical framework comprises: (1) input layers for signal reception, (2) hidden layers with weighted connections and activation functions, and (3) output layers generating classification predictions&#x02014;forming an end-to-end computational pipeline for cry pattern decoding. Since the 2000s, methods used in infant cry research have been mainly related to scale-conjugate gradient neural networks, multilayer perceptron, general regression neural networks, evolutionary neural networks, probabilistic neural networks, neuro-fuzzy networks and time-delay neural networks (<xref rid="B44" ref-type="bibr">44</xref>, <xref rid="B50" ref-type="bibr">50</xref>&#x02013;<xref rid="B53" ref-type="bibr">53</xref>). In the last decade, many traditional machine learning methods, such as support vector machine (SVM), k-nearest neighbour (KNN), Gaussian mixture model (GMM), fuzzy classifier, logistic regression, k-means clustering and random forest, have been applied to classify pathological cries and the causes of cries and to detect cries (<xref rid="T2" ref-type="table">Table&#x000a0;2</xref>).</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Comparison of classification algorithms (CNN vs. SVM vs. KNN).</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/></colgroup><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Dimension</th><th valign="top" align="center" rowspan="1" colspan="1">CNN</th><th valign="top" align="center" rowspan="1" colspan="1">SVM</th><th valign="top" align="center" rowspan="1" colspan="1">KNN</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Model Type</td><td valign="top" align="left" rowspan="1" colspan="1">Deep Learning (Hierarchical Feature Learning)</td><td valign="top" align="left" rowspan="1" colspan="1">Traditional machine learning (maximum margin classification)</td><td valign="top" align="left" rowspan="1" colspan="1">Lazy Learning (Instance-Based)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Core Operations</td><td valign="top" align="left" rowspan="1" colspan="1">Convolution, pooling, backpropagation</td><td valign="top" align="left" rowspan="1" colspan="1">kernel techniques, convex optimization</td><td valign="top" align="left" rowspan="1" colspan="1">Distance calculation, nearest neighbor voting</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Feature Processing</td><td valign="top" align="left" rowspan="1" colspan="1">Automatic learning of multi-level abstract features</td><td valign="top" align="left" rowspan="1" colspan="1">Dependence on manual features&#x02009;+&#x02009;kernel function mapping</td><td valign="top" align="left" rowspan="1" colspan="1">Features need to be manually designed</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Training Complexity</td><td valign="top" align="left" rowspan="1" colspan="1">High (requires GPU acceleration)</td><td valign="top" align="left" rowspan="1" colspan="1">Medium [<italic>O</italic>(<italic>n</italic><sup>2</sup>)&#x02009;&#x0223c;&#x02009;<italic>O</italic>(<italic>n</italic><sup>3</sup>)]</td><td valign="top" align="left" rowspan="1" colspan="1">No explicit training</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Inference speed</td><td valign="top" align="left" rowspan="1" colspan="1">Slow (large parameter volume)</td><td valign="top" align="left" rowspan="1" colspan="1">Fast (only supports vector participation in prediction)</td><td valign="top" align="left" rowspan="1" colspan="1">Extremely slow (requires traversing all samples)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Interpretability</td><td valign="top" align="left" rowspan="1" colspan="1">Low (black box model)</td><td valign="top" align="left" rowspan="1" colspan="1">Support Vector Visualization</td><td valign="top" align="left" rowspan="1" colspan="1">High (dependent on sample distance)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Data requirements</td><td valign="top" align="left" rowspan="1" colspan="1">Large-scale labeled data is required</td><td valign="top" align="left" rowspan="1" colspan="1">Small and medium-sized data</td><td valign="top" align="left" rowspan="1" colspan="1">Small-scale data</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Typical application scenarios</td><td valign="top" align="left" rowspan="1" colspan="1">Image classification and time series signal analysis</td><td valign="top" align="left" rowspan="1" colspan="1">Text classification, high-dimensional sparse data</td><td valign="top" align="left" rowspan="1" colspan="1">Simple classification and rapid prototype validation</td></tr></tbody></table><table-wrap-foot><fn id="table-fn2"><p>CNN, convolutional neural network; SVM, support vector machine; KNN, K-nearest neighbors.</p></fn></table-wrap-foot></table-wrap><p>In recent years, with the continuous development and improvement of deep learning technology, neural network models have been further optimized, resulting in the emergence of deep learning models including convolutional neural networks (CNN), recurrent neural networks (RNN), CNN-RNN, capsule networks, reservoir networks and neuro-fuzzy networks and others (<xref rid="B41" ref-type="bibr">41</xref>, <xref rid="B54" ref-type="bibr">54</xref>&#x02013;<xref rid="B57" ref-type="bibr">57</xref>). Compared to neural network models, deep learning models are more complex, with more parameters and layers. By building a deep neural network structure, the model can learn more abstract and complex feature representations, which can better process sequence data and capture temporal and frequency features in cries, improving the accuracy and robustness of cry recognition, and therefore, the ability in cry recognition and analysis has been significantly improved.</p><p><italic>Wang XM</italic> et al. (<xref rid="B58" ref-type="bibr">58</xref>) proposed a CNN-Transformer-based model for infant crying emotion analysis, demonstrating remarkable enhancements in key performance metrics such as classification accuracy, per-class precision, and training time. <italic>Zayed Y</italic> et al. (<xref rid="B59" ref-type="bibr">59</xref>) presented a medical diagnostic system for infant crying using a combination of different audio domain features and DL algorithms. By combining spectrograms, harmonic ratios (HR) and gammatone frequency cepstral coefficients (GFCCs) and employing a deep learning process, the highest accuracy of 97.50% was achieved. <italic>Hammoud M et al</italic>. (<xref rid="B33" ref-type="bibr">33</xref>) primarily studied methods for classification and recognition of infant cries, and the results showed that using deep learning approaches and feature extraction techniques could effectively classify and recognize infant cries. Moreover, compared to traditional machine learning methods, deep learning methods demonstrated superior performance in terms of classification accuracy.</p><p>However, during the training and using of deep learning models, model errors (derived from data noise, model structure, parameter settings, training algorithms, etc.) may lead to inconsistent or conflicting results in model prediction or classification. <italic>Zhang K</italic> et al. proposed an improved dempster-shafer evidence theory (DST) based on wasserstein distance and deng entropy, the fusion method has a classification accuracy of 90.15%, and improves the recognition accuracy by 5.79% to 11.53% consistent with the latest methods used in baby cry recognition. The method could effectively reduce the conflict of results caused by model errors between deep learning models and improve the accuracy of infant cry recognition (<xref rid="B60" ref-type="bibr">60</xref>).</p><p>Besides, multimodal analysis and deep learning models can be combined with each other and work together in cry research. Multimodal analysis can extract information from multiple sources and types of data. It not only focuses on the sound features of the infant cry itself, but also considers the infant facial expressions, body movements, and possible physiological reactions when crying, which can provide more comprehensive, gain a deeper understanding of the reasons and emotional state behind infant crying (<xref rid="B61" ref-type="bibr">61</xref>). Multimodal analysis provides richer and more comprehensive data inputs to deep learning models, allowing the models to better understand and identify infant cries. <italic>Laguna A</italic> et al. (<xref rid="B61" ref-type="bibr">61</xref>) used multimodal analysis to collect multimodal data [i.e., crying, electroencephalography (EEG), near-infrared spectroscopy (NIRS), facial expressions, and body movements]. According to the five different conditions (i.e., hunger, sleepiness, fussiness, need to burp, and distress) defined different cry types. The study showed the robust DL algorithm named Acoustic MultiStage Interpreter (AMSI) achieved an accuracy rate of 92% in classifying infant cries. Thence, the combination of multimodal analysis and deep learning models provides more accurate tools and methods for infant cry recognition and emotion analysis.</p><p>With the improvement of computing power and the use of deep learning methods, the study of infant crying still faces many challenges. Firstly, the issue of insufficient data and scalability in research limits the further enhancement of model performance. The shared databases have limited sample sizes, and most databases are not publicly available. Current research is mostly based on datasets recorded by individual researchers, making it difficult to conduct cross-study comparisons. Additionally, ethical and legal issues in the data collection process have prevented the acquisition of data on infant crying. Secondly, there are difficulties in data collection and annotation, which is a time-consuming and labor-intensive process requiring professional expertise. To address these issues, it is necessary to combine audio acquisition and processing technologies to improve the accuracy of infant cry data collection, signal processing, and feature extraction. Through training with vast amounts of data, deep learning models can discern subtle differences in cries and more accurately determine the infant's emotions and physiological states.</p></sec><sec id="s6"><title>What can we learn from infant cry</title><p>The central nervous system (CNS) and vagal tone regulate the function of the laryngeal and vocal cord anatomy to produce the acoustic properties of crying, and the acoustic characteristics of infant cries may be affected by CNS pathology (<xref rid="B10" ref-type="bibr">10</xref>, <xref rid="B62" ref-type="bibr">62</xref>). In addition, the cry signals of unhealthy infants have unique characteristics that differ from those of healthy infants because the vocal cords and respiratory system of infants are affected by certain diseases (<xref rid="B32" ref-type="bibr">32</xref>). Therefore, the acoustic study of infant cries is of great significance in the study of infant development. In addition to understanding the daily needs of infants, it is even more important to identify diseases by analysing pathological cry signatures, especially in wards where medical equipment and expertise are lacking (<xref rid="T3" ref-type="table">Table&#x000a0;3</xref>).</p><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>The application of infant crying.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/></colgroup><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Supporting study</th><th valign="top" align="center" rowspan="1" colspan="1">Cry feature</th><th valign="top" align="center" rowspan="1" colspan="1">Application</th><th valign="top" align="center" rowspan="1" colspan="1">Measures</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Yamamoto et al. (<xref rid="B63" ref-type="bibr">63</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">A 32-dimensional fast Fourier transform of sound</td><td valign="top" align="left" rowspan="1" colspan="1">Recognition the needs of the baby</td><td valign="top" align="left" rowspan="1" colspan="1">Accuracy: Discomfortable 30%; Hungry 92.9%; Sleepy 40%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Liang et al. (<xref rid="B44" ref-type="bibr">44</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">MFCC</td><td valign="top" align="left" rowspan="1" colspan="1">Infant emotion recognition</td><td valign="top" align="left" rowspan="1" colspan="1">CNN reached up to 60% accuracy, outperforming LSTM and ANN in almost all measures.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Cabon et al. (<xref rid="B55" ref-type="bibr">55</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">MFCC</td><td valign="top" align="left" rowspan="1" colspan="1">Extraction of Premature Newborns' Spontaneous Cries</td><td valign="top" align="left" rowspan="1" colspan="1">KNN: precision score 92.9%, accuracy above 90.2%;<break/>LR: recall score 94.1%, accuracy above 90.2%;<break/>MLP: precision 92.7%, recall 90.48%, accuracy 94.5%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Farsaie et al. (<xref rid="B56" ref-type="bibr">56</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">MFCC</td><td valign="top" align="left" rowspan="1" colspan="1">Development of a health diagnosis system based on infant crying</td><td valign="top" align="left" rowspan="1" colspan="1">Healthy infant type (SVM-MLP with BML adaptation): FNR 8.84%, FPR 11.49% Sick infant type (PNN classifier with BML adaptation): nervous system disease: FNR 26.4%, FPR 24.6% respiratory system disease: FNR 30.5%, FPR 25.4%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Manigault et al. (<xref rid="B43" ref-type="bibr">43</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Short vocalizations (&#x0003c;500&#x02005;ms)<break/>long vocalizations (&#x02265;500&#x02005;ms)</td><td valign="top" align="left" rowspan="1" colspan="1">The evaluation and diagnosis of neonatal opioid withdrawal syndrome</td><td valign="top" align="left" rowspan="1" colspan="1">AUC 0.90, accuracy 85%, sensitivity 89%, specificity 83%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Donzelli et al. (<xref rid="B67" ref-type="bibr">67</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Duration, F0, F1, F2, F3, CV, PHP, MP, Cry score</td><td valign="top" align="left" rowspan="1" colspan="1">To evaluate the cries of infants affected by severe protein energy malnutrition</td><td valign="top" align="left" rowspan="1" colspan="1">CV f0 lower than controls (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.0001); F1, F2, F3 lower than controls (F1: <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.0001, F2: <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.0005, F3: <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01); MP lower than controls (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.0001).</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Orlandi et al. (<xref rid="B31" ref-type="bibr">31</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Mean and median of F0 median, mean, minimum maximum of F1, median and mean of F2 and F3</td><td valign="top" align="left" rowspan="1" colspan="1">Classification of preterm vs. term infants</td><td valign="top" align="left" rowspan="1" colspan="1">AUC 0.94, Accuracy 87.34%, Sensitivity 87.3%, Specificity 87.4%</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Sheinkopf et al. (<xref rid="B71" ref-type="bibr">71</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">Pitch (F0), Variability of pitch, Phonation, Hyperphonation, Utterance duration, Average energy/amplitude, Variability of energy/amplitude, F1, F2</td><td valign="top" align="left" rowspan="1" colspan="1">Disruptions in cry acoustics may be part of an atypical vocal signature of autism in early life</td><td valign="top" align="left" rowspan="1" colspan="1">At-risk infants produced pain-related cries with higher and more variable F0 than low-risk infants.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">English et al. (<xref rid="B72" ref-type="bibr">72</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">The utterance duration inter-utterance intervals loudness in dB, frication, F0.</td><td valign="top" align="left" rowspan="1" colspan="1">A marker of the neurobehavioral status of newborns.</td><td valign="top" align="left" rowspan="1" colspan="1">ASD infant cries were rated as more distressed, less typical, and reflecting greater pain</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Mahmoudian et al. (<xref rid="B65" ref-type="bibr">65</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">F0, F1, F2, F3, F2/F1, F3/F1, Intensity, Shimmer, Jitter, Voice break, HNR mean, Duration</td><td valign="top" align="left" rowspan="1" colspan="1">The functional mechanisms of the vocal organ in hearing-impaired (HI) and normal hearing (NH) infants.</td><td valign="top" align="left" rowspan="1" colspan="1">HI infants have lower intensity and higher F0 and voice break than NH infants. However, the other differences were not statistically significant.</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Khozaei et al. (<xref rid="B73" ref-type="bibr">73</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">MFCC<break/>Spectral flatness</td><td valign="top" align="left" rowspan="1" colspan="1">Early screening of autism spectrum disorder</td><td valign="top" align="left" rowspan="1" colspan="1">Boys: Sensitivity 85.71%, specificity 100%;<break/>Girls: Sensitivity 71.42%, specificity 100%</td></tr></tbody></table><table-wrap-foot><fn id="table-fn3"><p>MFCC, mel-frequency cepstral coefficients; CNN, convolutional neural network; LSTM, long short term memory; ANN, artificial neural network; KNN, K-nearest neighbours; LR, logistic regression; MLP, multi-layer perceptron; SVM-MLP, support vector machine-multilayer perceptron; BML, boosting mixture learning; FNR, false negative rate; FPR, false positive rate; AUC, area under the curve; PNN, probabilistic neural networks; NAS, neonatal opioid withdrawal syndrome; CI, confidence interval; CV, coefficient of variation; PHP, peak harmonic proportion; MP, melodic pattern.</p></fn></table-wrap-foot></table-wrap><sec id="s6a"><title>Infant care aspects</title><p>Analysis of infant cries may help to identify needs such as hunger, pain and illness, leading to the development of a biological indicator or possibly a mobile app that could help parents monitor their infant's needs. <italic>Yamamoto</italic> et al. (<xref rid="B63" ref-type="bibr">63</xref>) developed a technique for recognising emotions in infants (e.g., uncomfortable, hungry or sleepy). They successfully integrated this method into a robotic baby caregiver. <italic>Liang</italic> et al. (<xref rid="B44" ref-type="bibr">44</xref>) used deep learning algorithms to recognise needs such as hunger/thirst, a diaper change, emotional needs (e.g., touching/cuddling) and pain caused by medical treatment (e.g., injection). Both CNN and long short-term memory (LSTM) models provided good performance in distinguishing between healthy and sick infants, with around 95% accuracy, precision, and recall. A CNN achieved up to 60% accuracy in determining the special needs of infants. These results could be used as metrics for future applications to help parents understand the condition and needs of their infants. <italic>Cabon</italic> et al. (<xref rid="B55" ref-type="bibr">55</xref>) established a method to extract the cries of preterm infants in noisy environments such as a neonatal intensive care unit. <italic>Manigault</italic> et al. (<xref rid="B43" ref-type="bibr">43</xref>) showed that the use of machine learning for cry analysis could improve the assessment, diagnosis and management of neonatal opioid withdrawal syndrome and contribute to standardised care for these infants.</p></sec><sec id="s6b"><title>Somatic system disorders</title><p>Advances in the available machine learning methods have allowed researchers to automatically label normal and pathological cries, and many studies on infant cries for early diagnosis of a variety of diseases have emerged. <italic>Saraswathy</italic> et al. (<xref rid="B63" ref-type="bibr">64</xref>) reviewed 34 papers published between 2003 and 2011 on the classification of normal and pathological call signals. This included recognition of diseases such as murmuring, asphyxia, hypothyroidism, hyperbilirubinemia, and cleft palate. <italic>Farsaie Alaie</italic> et al. (<xref rid="B56" ref-type="bibr">56</xref>) demonstrated that a diagnostic system based on infant cries can distinguish between multiple neonatal diseases. They proposed a novel adaptation method known as boosted mixture learning (BML) and compared it with the traditional Bayesian adaptation method. The experimental results revealed that their proposed BML adaptation method significantly improved the system's performance. <italic>Mahmoudian</italic> et al. (<xref rid="B65" ref-type="bibr">65</xref>) found that by applying acoustic analysis of cries, the intensity, fundamental frequency and breaks of cries could be used as indicators of differentiate between infants with impaired hearing and infants with normal hearing at a very young age (less than 2 months). Early identification of hearing impairment plays an important role in the prevention of speech and language disorders.</p></sec><sec id="s6c"><title>Neurodevelopmental and neuropsychiatric disorders</title><p>Analysis of cries from infants with neurological disorders and severe diseases, which can later lead to motor and intellectual disability, may help to facilitate early detection and timely intervention (<xref rid="B32" ref-type="bibr">32</xref>). Initially, <italic>Lester</italic> et al. (<xref rid="B66" ref-type="bibr">66</xref>) compared the cries of normally developing infants with those of infants who may have suffered CNS damage due to malnutrition. They showed that the cries of malnourished infants were initially longer, higher in pitch, lower in amplitude, more arrhythmic and had a longer latency to the next cry than the cries of well-nourished infants. The similarity between the cries of malnourished infants and brain-injured infants suggests that malnutrition may affect the regulatory functions of the CNS. <italic>Donzelli</italic> et al. (<xref rid="B67" ref-type="bibr">67</xref>) reached similar conclusions in a computer analysis. When <italic>Lester and Dreher</italic> (<xref rid="B68" ref-type="bibr">68</xref>) studied the effects of maternal marijuana use on the newborn cry, they found that heavy use of marijuana affected the neuropsychological integrity of infants, resulting in differences in the cry characteristics. <italic>Lawford</italic> et al. (<xref rid="B69" ref-type="bibr">69</xref>) showed that infants with underlying neuropathology have unique cries characterised by a higher fundamental frequency, dysphonia, and atypical melodies. Assessment of acoustic cry characteristics offers the potential for non-invasive and rapid point-of-care screening for neurologically high-risk infants.</p><p>The characteristics of preterm cries and their differences from those of term infants have also been explored to explain the differences observed in their neurophysiological maturation and the subsequent effects on their language development. The initial studies focused on the analysis of pain-inducing cries. The effect of neurophysiological maturity on pain-inducing cries was first revealed when <italic>Tenold</italic> et al. (<xref rid="B70" ref-type="bibr">70</xref>) found that the spectral variability of cries of term newborns was more complex than that of preterm infants. <italic>Orlandi</italic> et al. (<xref rid="B31" ref-type="bibr">31</xref>) compared the acoustic characteristics of the cries of preterm and term infants. They obtained an optimal feature set, consisting of 10 parameters, that they could use to assess the differences between preterm and term newborns with approximately 87% accuracy. Moreover, the area under the receiver operating characteristic curve reached 0.94. After comparing several machine learning models, they found that K-Nearest Neighbors (KNN) had an accuracy of up to 92.9%.</p><p><italic>Sheinkopf</italic> et al. (<xref rid="B71" ref-type="bibr">71</xref>) studied the differences in acoustic characteristics of infant cries between high-risk infants for autism spectrum disorder (ASD) and low-risk infants. Using specialized software for analysis, they found that the fundamental frequency (F0) of pain-related cries produced by high-risk infants was higher and more variable. Especially for those high-risk infants who were later diagnosed with ASD at 36 months, their F0 values were the highest regardless of the cry type, and their cries were more poorly articulated, making it difficult to produce them in a voiced mode. The study concluded that abnormalities in the acoustic characteristics of cries may be an atypical vocal feature of autism in early infancy. <italic>English</italic> et al. (<xref rid="B72" ref-type="bibr">72</xref>) investigated parental perceptions of cries of 1-month-old infants later diagnosed with autism spectrum disorder (ASD) and non-ASD controls. Across parents, ASD infant cries were rated as more distressed, less typical, and reflecting greater pain. <italic>Khozaei</italic> et al. (<xref rid="B73" ref-type="bibr">73</xref>) developed an ASD screening method based on crying sounds and proposed a new classification approach to identify ASD features. They trained the classifier using data from children aged 18 to 53 months and tested it on ASD and TD children of different genders. The results showed that for boys, the sensitivity, specificity, and precision of the method were 85.71%, 100%, and 92.85%, respectively; for girls, these metrics were 71.42%, 100%, and 85.71%, respectively.</p><p>The relationship between infant cries and their psychological disorders can be explained through the interaction between the central nervous system and vagal tone. Vagal tone reflects the activity level of the parasympathetic nervous system, with high vagal tone typically associated with better emotional regulation, social adaptability, and physiological stability (<xref rid="B74" ref-type="bibr">74</xref>). Infants with higher vagal tone often exhibit more stable crying patterns, while those with lower vagal tone may demonstrate higher fundamental frequency, more irregular, or more intense cries. The central nervous system, particularly the brainstem and limbic system, regulates infants' physiological and emotional responses by modulating the activity of the vagus nerve (<xref rid="B75" ref-type="bibr">75</xref>). In infants with psychological disorders such as autism spectrum disorder, anxiety disorders, or depression, abnormalities may occur in the central nervous system's regulation of the vagus nerve. These abnormalities can lead to decreased vagal tone, which in turn affects the infants' emotional regulation capabilities and crying patterns.</p></sec></sec><sec id="s7"><title>Challenges and perspective</title><p>In this paper, we comprehensively elaborate on the physiological process, causes, analysis, and application of infant crying. It aims to provide detailed information and valuable resources for researchers and medical professionals in this field. Despite significant advancements in infant crying research, there is still room for improvement. Given that the characteristics of infant crying are influenced by multiple factors such as the cause of crying, health status, weight, and age, the collection and analysis of crying data face numerous challenges. Therefore, integrating advanced audio acquisition and processing technologies is crucial for improving the quality of crying data collection, signal purity (especially in terms of background noise removal), and the accuracy of feature recognition. With the training of massive infant crying data, deep learning models can finely distinguish subtle differences in cries, thereby accurately determining infants' emotional fluctuations and physiological conditions.</p><p>Due to the dual pressures of strict ethical review and data scarcity, we did not analyze the cultural, ethnic, or pathological differences in demographic characteristics, nor did we validate the differences in infant crying patterns across different resource environments. Future research should proceed as follows: On the one hand, we will strictly adhere to ethical norms, ensuring that all data collection activities are approved by legitimate and compliant ethical review processes, fully respecting parents' right to informed consent, and strengthening data anonymization and privacy protection. On the other hand, we will actively explore and apply new technologies, such as federated learning and synthetic data, to effectively address the issue of data scarcity, ensuring the rational use of data resources while fully protecting personal privacy, and promoting the continuous deepening and development of research.</p><p>However, the non-specificity of crying characteristics means they cannot be directly used as a gold standard for disease diagnosis, which undoubtedly increases the complexity of differential diagnosis. Considering this, combining crying characteristics with clinical manifestations and facial expression, body movement and physiological signals (such as EEG, NIRS), can serve as an effective supplement to comprehensive pathological assessments of infants. Therefore, multimodal integration based on crying is undoubtedly an important direction for future infant crying research.</p><p>Of course, every technology is a double-edged sword. While the application of computerized tools in infant crying classification has brought many conveniences, researchers also need to be vigilant about their potential interference with normal parent-infant interaction, ensuring that the use of technology does not weaken humanized care and attention.</p></sec></body><back><ack><title>Acknowledgments</title><p>We gratefully acknowledge the contribution of Mr. Liu Fangfang from Southwest Minzu University in creating the schematic illustrations for this study.</p></ack><sec sec-type="author-contributions" id="s8"><title>Author contributions</title><p>ZW: Data curation, Investigation, Writing &#x02013; original draft. YCai: Data curation, Investigation, Writing &#x02013; original draft. XW: Data curation, Investigation, Writing &#x02013; original draft. SW: Data curation, Visualization, Writing &#x02013; original draft. YCao: Data curation, Visualization, Writing &#x02013; original draft. FX: Data curation, Investigation, Writing &#x02013; original draft. MH: Conceptualization, Writing &#x02013; review &#x00026; editing.</p></sec><sec sec-type="COI-statement" id="s10"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type="ai-statement" id="s11"><title>Generative AI statement</title><p>The author(s) declare that no Generative AI was used in the creation of this manuscript.</p></sec><sec sec-type="disclaimer" id="s12"><title>Publisher's note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><ref-list><title>References</title><ref id="B1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Qu</surname><given-names>Y</given-names></name><name><surname>Mu</surname><given-names>D</given-names></name></person-group>. <article-title>Research progress on physiological and pathological factors of infant cry</article-title>. <source>Chin J Child Health Care</source>. (<year>2018</year>) <volume>26</volume>(<issue>8</issue>):<fpage>869</fpage>&#x02013;<lpage>72</lpage>. <pub-id pub-id-type="doi">10.11852/zgetbjzz2018-26-08-16</pub-id></mixed-citation></ref><ref id="B2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>C</given-names></name><name><surname>Mudiyanselage</surname><given-names>TB</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Pan</surname><given-names>Y</given-names></name></person-group>. <article-title>A review of infant cry analysis and classification</article-title>. <source>EURASIP J Audio Speech Music Process</source>. (<year>2021</year>) <volume>2021</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1186/s13636-021-00197-5</pub-id></mixed-citation></ref><ref id="B3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LaGasse</surname><given-names>LL</given-names></name><name><surname>Neal</surname><given-names>AR</given-names></name><name><surname>Lester</surname><given-names>BM</given-names></name></person-group>. <article-title>Assessment of infant cry: acoustic cry analysis and parental perception</article-title>. <source>Ment Retard Dev Disabil Res Rev</source>. (<year>2005</year>) <volume>11</volume>(<issue>1</issue>):<fpage>83</fpage>&#x02013;<lpage>93</lpage>. <pub-id pub-id-type="doi">10.1002/mrdd.20050</pub-id><pub-id pub-id-type="pmid">15856439</pub-id>
</mixed-citation></ref><ref id="B4"><label>4.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z</given-names></name></person-group>. <source>Structure and Function of the Vocal Vocal Organs</source>. Changchun, Jilin Province: <publisher-name>Modern Music</publisher-name> (<year>2020</year>). p. <fpage>159</fpage>&#x02013;<lpage>60</lpage>.</mixed-citation></ref><ref id="B5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>X</given-names></name></person-group>. <article-title>Structure and function of the vocal organs</article-title>. <source>China Sci Technol Inf</source>. (<year>2006</year>) (<issue>06</issue>):<fpage>243</fpage>. <pub-id pub-id-type="doi">10.3969/j.issn.1001-8972.2006.06.155</pub-id></mixed-citation></ref><ref id="B6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paulsen</surname><given-names>F</given-names></name><name><surname>Tillmann</surname><given-names>B</given-names></name></person-group>. <article-title>Structure, function and insertion of the human vocal folds</article-title>. <source>Adv Otorhinolaryngol</source>. (<year>2020</year>) <volume>85</volume>:<fpage>1</fpage>&#x02013;<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1159/000456678</pub-id><pub-id pub-id-type="pmid">33166982</pub-id>
</mixed-citation></ref><ref id="B7"><label>7.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tao</surname><given-names>S</given-names></name></person-group>. <source>The Basic Structure of the Singing Vocal Organs and the Principles of Vocalization</source>. Xi'an City, Shaanxi Province: <publisher-name>The World of Music</publisher-name> (<year>2015</year>). p. <fpage>48</fpage>&#x02013;<lpage>50</lpage>.</mixed-citation></ref><ref id="B8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benninger</surname><given-names>MS</given-names></name></person-group>. <article-title>The professional voice</article-title>. <source>J Laryngol Otol</source>. (<year>2011</year>) <volume>125</volume>(<issue>2</issue>):<fpage>111</fpage>&#x02013;<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1017/S0022215110001970</pub-id><pub-id pub-id-type="pmid">21029501</pub-id>
</mixed-citation></ref><ref id="B9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belyk</surname><given-names>M</given-names></name><name><surname>Brown</surname><given-names>S</given-names></name></person-group>. <article-title>The origins of the vocal brain in humans</article-title>. <source>Neurosci Biobehav Rev</source>. (<year>2017</year>) <volume>77</volume>:<fpage>177</fpage>&#x02013;<lpage>93</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2017.03.014</pub-id><pub-id pub-id-type="pmid">28351755</pub-id>
</mixed-citation></ref><ref id="B10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rautava</surname><given-names>L</given-names></name><name><surname>Lempinen</surname><given-names>A</given-names></name><name><surname>Ojala</surname><given-names>S</given-names></name><name><surname>Parkkola</surname><given-names>R</given-names></name><name><surname>Rikalainen</surname><given-names>H</given-names></name><name><surname>Lapinleimu</surname><given-names>H</given-names></name><etal/></person-group>
<article-title>Acoustic quality of cry in very-low-birth-weight infants at the age of 1 1/2 years</article-title>. <source>Early Hum Dev</source>. (<year>2007</year>) <volume>83</volume>(<issue>1</issue>):<fpage>5</fpage>&#x02013;<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1016/j.earlhumdev.2006.03.004</pub-id><pub-id pub-id-type="pmid">16650947</pub-id>
</mixed-citation></ref><ref id="B11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harding</surname><given-names>R</given-names></name><name><surname>Maritz</surname><given-names>G</given-names></name></person-group>. <article-title>Maternal and fetal origins of lung disease in adulthood</article-title>. <source>Semin Fetal Neonatal Med</source>. (<year>2012</year>) <volume>17</volume>(<issue>2</issue>):<fpage>67</fpage>&#x02013;<lpage>72</lpage>. <pub-id pub-id-type="doi">10.1016/j.siny.2012.01.005</pub-id><pub-id pub-id-type="pmid">22277111</pub-id>
</mixed-citation></ref><ref id="B12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dietert</surname><given-names>RR</given-names></name><name><surname>Dietert</surname><given-names>JM</given-names></name></person-group>. <article-title>Potential for early-life immune insult including developmental immunotoxicity in autism and autism Spectrum disorders: focus on critical windows of immune vulnerability</article-title>. <source>J Toxicol Environ Health B Crit Rev</source>. (<year>2008</year>) <volume>11</volume>(<issue>8</issue>):<fpage>660</fpage>&#x02013;<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1080/10937400802370923</pub-id><pub-id pub-id-type="pmid">18821424</pub-id>
</mixed-citation></ref><ref id="B13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Field</surname><given-names>T</given-names></name><name><surname>Diego</surname><given-names>M</given-names></name><name><surname>Hernandez-Reif</surname><given-names>M</given-names></name></person-group>. <article-title>Prenatal depression effects on the Fetus and newborn: a review</article-title>. <source>Infant Behav Dev</source>. (<year>2006</year>) <volume>29</volume>(<issue>3</issue>):<fpage>445</fpage>&#x02013;<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1016/j.infbeh.2006.03.003</pub-id><pub-id pub-id-type="pmid">17138297</pub-id>
</mixed-citation></ref><ref id="B14"><label>14.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Boersma</surname><given-names>P</given-names></name><name><surname>Weenink</surname><given-names>D</given-names></name></person-group>. <article-title>Praat: Doing Phonetics by Computer</article-title>. (<year>2020</year>). <comment>Available at:</comment>
<ext-link xlink:href="https://www.fon.hum.uva.nl/praat/" ext-link-type="uri">https://www.fon.hum.uva.nl/praat/</ext-link>
<comment>(Accessed August 07, 2020)</comment>.</mixed-citation></ref><ref id="B15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>K</given-names></name><name><surname>Guo</surname><given-names>Z</given-names></name><name><surname>Peng</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>X</given-names></name><name><surname>Su</surname><given-names>C</given-names></name></person-group>. <article-title>Research on infant cry classification algorithm based on acoustic feature extraction</article-title>. <source>Inf Rec Mater</source>. (<year>2021</year>) <volume>22</volume>(<issue>7</issue>):<fpage>131</fpage>&#x02013;<lpage>3</lpage>. <pub-id pub-id-type="doi">10.16009/j.cnki.cn13-1295/tq.2021.07.066</pub-id></mixed-citation></ref><ref id="B16"><label>16.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wasz-Hockert</surname><given-names>O</given-names></name><name><surname>Lind</surname><given-names>J</given-names></name><name><surname>Vuorenkoski</surname><given-names>V</given-names></name><name><surname>Partanen</surname><given-names>T</given-names></name><name><surname>Valanne</surname><given-names>E</given-names></name><name><surname>Illingworth</surname><given-names>R</given-names></name></person-group>. <source>The Infant Cry. A Spectrographic and Auditory Analysis. (Clinics in Developmental Medicine No.29)</source>. London: <publisher-name>Spastics International Medical Publications</publisher-name> (<year>1968</year>).</mixed-citation></ref><ref id="B17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnston</surname><given-names>CC</given-names></name><name><surname>Stevens</surname><given-names>B</given-names></name><name><surname>Craig</surname><given-names>KD</given-names></name><name><surname>Grunau</surname><given-names>RVE</given-names></name></person-group>. <article-title>Developmental changes in pain expression in premature, full-term, two- and four-month-old infants</article-title>. <source>Pain</source>. (<year>1993</year>) <volume>52</volume>(<issue>2</issue>):<fpage>201</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/0304-3959(93)90132-9</pub-id><pub-id pub-id-type="pmid">8455968</pub-id>
</mixed-citation></ref><ref id="B18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name></person-group>. <article-title>Knowledge map analysis of domestic infant cry research field based on citespace</article-title>. <source>Chin J Child Health Care</source>. (<year>2022</year>) <volume>30</volume>(<issue>10</issue>):<fpage>1112</fpage>&#x02013;<lpage>7</lpage>. <pub-id pub-id-type="doi">10.11852/zgetbjzz2022-0103</pub-id></mixed-citation></ref><ref id="B19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z</given-names></name></person-group>. <article-title>Observation and nursing of infant cry</article-title>. <source>J Mod Med Health</source>. (<year>2006</year>)(<issue>22</issue>):<fpage>3517</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.3969/j.issn.1009-5519.2006.22.124</pub-id></mixed-citation></ref><ref id="B20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lind</surname><given-names>J</given-names></name></person-group>. <article-title>The infant cry</article-title>. <source>Proc R Soc Med</source>. (<year>1971</year>) <volume>64</volume>(<issue>5</issue>):<fpage>468</fpage>. <pub-id pub-id-type="doi">10.1177/003591577106400503</pub-id><pub-id pub-id-type="pmid">5576897</pub-id>
</mixed-citation></ref><ref id="B21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carollo</surname><given-names>A</given-names></name><name><surname>Montefalcone</surname><given-names>P</given-names></name><name><surname>Bornstein</surname><given-names>MH</given-names></name><name><surname>Esposito</surname><given-names>G</given-names></name></person-group>. <article-title>A scientometric review of infant cry and caregiver responsiveness: literature trends and research gaps over 60 years of developmental study</article-title>. <source>Children (Basel)</source>. (<year>2023</year>) <volume>10</volume>(<issue>6</issue>). <pub-id pub-id-type="doi">10.3390/children10061042</pub-id><pub-id pub-id-type="pmid">37371273</pub-id>
</mixed-citation></ref><ref id="B22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Micheletti</surname><given-names>M</given-names></name><name><surname>Yao</surname><given-names>X</given-names></name><name><surname>Johnson</surname><given-names>M</given-names></name><name><surname>de Barbaro</surname><given-names>K</given-names></name></person-group>. <article-title>Validating a model to detect infant crying from naturalistic audio</article-title>. <source>Behav Res Methods</source>. (<year>2023</year>) <volume>55</volume>(<issue>6</issue>):<fpage>3187</fpage>&#x02013;<lpage>97</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-022-01961-x</pub-id><pub-id pub-id-type="pmid">36085547</pub-id>
</mixed-citation></ref><ref id="B23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michelsson</surname><given-names>K</given-names></name><name><surname>Michelsson</surname><given-names>O</given-names></name></person-group>. <article-title>Phonation in the newborn, infant cry</article-title>. <source>Int J Pediatr Otorhinolaryngol</source>. (<year>1999</year>) <volume>49</volume>(<issue>Suppl 1</issue>):<fpage>S297</fpage>&#x02013;<lpage>301</lpage>. <pub-id pub-id-type="doi">10.1016/S0165-5876(99)00180-9</pub-id><pub-id pub-id-type="pmid">10577825</pub-id>
</mixed-citation></ref><ref id="B24"><label>24.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Wu</surname><given-names>D</given-names></name><name><surname>Niu</surname><given-names>X</given-names></name></person-group>. <article-title>Research on acoustic feature extraction of crying for early screening of children with autism</article-title>. In: <source>2019 34rd Youth Academic Annual Conference of Chinese Association of Automation (YAC); 2019 Jun 06&#x02013;08</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2019</year>). p. <fpage>290</fpage>&#x02013;<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1109/YAC.2019.8787725</pub-id></mixed-citation></ref><ref id="B25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esposito</surname><given-names>G</given-names></name><name><surname>Nakazawa</surname><given-names>J</given-names></name><name><surname>Venuti</surname><given-names>P</given-names></name><name><surname>Bornstein</surname><given-names>MH</given-names></name></person-group>. <article-title>Componential deconstruction of infant distress vocalizations via tree-based models: a study of cry in autism Spectrum disorder and typical development</article-title>. <source>Res Dev Disabil</source>. (<year>2013</year>) <volume>34</volume>(<issue>9</issue>):<fpage>2717</fpage>&#x02013;<lpage>24</lpage>. <pub-id pub-id-type="doi">10.1016/j.ridd.2013.05.036</pub-id><pub-id pub-id-type="pmid">23774058</pub-id>
</mixed-citation></ref><ref id="B26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salehian Matikolaie</surname><given-names>F</given-names></name><name><surname>Tadj</surname><given-names>C</given-names></name></person-group>. <article-title>On the use of long-term features in a newborn cry diagnostic system</article-title>. <source>Biomed Signal Process Control</source>. (<year>2020</year>) <volume>59</volume>:<fpage>101889</fpage>. <pub-id pub-id-type="doi">10.1016/j.bspc.2020.101889</pub-id></mixed-citation></ref><ref id="B27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rapisardi</surname><given-names>G</given-names></name><name><surname>Vohr</surname><given-names>B</given-names></name><name><surname>Cashore</surname><given-names>W</given-names></name><name><surname>Peucker</surname><given-names>M</given-names></name><name><surname>Lester</surname><given-names>B</given-names></name></person-group>. <article-title>Assessment of infant cry variability in high-risk infants</article-title>. <source>Int J Pediatr Otorhinolaryngol</source>. (<year>1989</year>) <volume>17</volume>(<issue>1</issue>):<fpage>19</fpage>&#x02013;<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1016/0165-5876(89)90290-5</pub-id><pub-id pub-id-type="pmid">2707975</pub-id>
</mixed-citation></ref><ref id="B28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>GR</given-names></name><name><surname>Fleischman</surname><given-names>RW</given-names></name><name><surname>Rosenkrantz</surname><given-names>H</given-names></name><name><surname>Braude</surname><given-names>MC</given-names></name></person-group>. <article-title>Oral and intravenous toxicity of Delta9-tetrahydrocannabinol in rhesus monkeys</article-title>. <source>Toxicol Appl Pharmacol</source>. (<year>1974</year>) <volume>27</volume>(<issue>3</issue>):<fpage>648</fpage>&#x02013;<lpage>65</lpage>. <pub-id pub-id-type="doi">10.1016/0041-008X(74)90044-1</pub-id><pub-id pub-id-type="pmid">4212215</pub-id>
</mixed-citation></ref><ref id="B29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiaramonte</surname><given-names>R</given-names></name><name><surname>Bonfiglio</surname><given-names>M</given-names></name></person-group>. <article-title>Acoustic analysis of voice in Parkinson's disease: a systematic review of voice disability and meta-analysis of studies</article-title>. <source>Rev Neurol</source>. (<year>2020</year>) <volume>70</volume>(<issue>11</issue>):<fpage>393</fpage>&#x02013;<lpage>405</lpage>. <pub-id pub-id-type="doi">10.33588/rn.7011.2019414</pub-id><pub-id pub-id-type="pmid">32436206</pub-id>
</mixed-citation></ref><ref id="B30"><label>30.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chittora</surname><given-names>A</given-names></name><name><surname>Patil</surname><given-names>H</given-names></name></person-group>. <source>Significance of Unvoiced Segments and Fundamental Frequency in Infant Cry Analysis.</source>
<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer</publisher-name> (<year>2015</year>). p. <fpage>273</fpage>&#x02013;<lpage>81</lpage>.</mixed-citation></ref><ref id="B31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orlandi</surname><given-names>S</given-names></name><name><surname>Reyes Garcia</surname><given-names>CA</given-names></name><name><surname>Bandini</surname><given-names>A</given-names></name><name><surname>Donzelli</surname><given-names>G</given-names></name><name><surname>Manfredi</surname><given-names>C</given-names></name></person-group>. <article-title>Application of pattern recognition techniques to the classification of full-term and preterm infant cry</article-title>. <source>J Voice</source>. (<year>2016</year>) <volume>30</volume>(<issue>6</issue>):<fpage>656</fpage>&#x02013;<lpage>63</lpage>. <pub-id pub-id-type="doi">10.1016/j.jvoice.2015.08.007</pub-id><pub-id pub-id-type="pmid">26474712</pub-id>
</mixed-citation></ref><ref id="B32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittora</surname><given-names>A</given-names></name><name><surname>Patil</surname><given-names>HA</given-names></name></person-group>. <article-title>Data collection of infant cries for research and analysis</article-title>. <source>J Voice</source>. (<year>2017</year>) <volume>31</volume>(<issue>2</issue>):<fpage>252.e215</fpage>&#x02013;<lpage>e226</lpage>. <pub-id pub-id-type="doi">10.1016/j.jvoice.2016.07.007</pub-id></mixed-citation></ref><ref id="B33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hammoud</surname><given-names>M</given-names></name><name><surname>Getahun</surname><given-names>MN</given-names></name><name><surname>Baldycheva</surname><given-names>A</given-names></name><name><surname>Somov</surname><given-names>A</given-names></name></person-group>. <article-title>Machine learning-based infant crying interpretation</article-title>. <source>Front Artif Intell</source>. (<year>2024</year>) <volume>7</volume>:<fpage>1337356</fpage>. <pub-id pub-id-type="doi">10.3389/frai.2024.1337356</pub-id><pub-id pub-id-type="pmid">38390346</pub-id>
</mixed-citation></ref><ref id="B34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hariharan</surname><given-names>M</given-names></name><name><surname>Chee</surname><given-names>LS</given-names></name><name><surname>Yaacob</surname><given-names>S</given-names></name></person-group>. <article-title>Analysis of infant cry through weighted linear prediction cepstral coefficients and probabilistic neural network</article-title>. <source>J Med Syst</source>. (<year>2012</year>) <volume>36</volume>(<issue>3</issue>):<fpage>1309</fpage>&#x02013;<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1007/s10916-010-9591-z</pub-id><pub-id pub-id-type="pmid">20844933</pub-id>
</mixed-citation></ref><ref id="B35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aggarwal</surname><given-names>G</given-names></name><name><surname>Jhajharia</surname><given-names>K</given-names></name><name><surname>Izhar</surname><given-names>J</given-names></name><name><surname>Kumar</surname><given-names>M</given-names></name><name><surname>Abualigah</surname><given-names>L</given-names></name></person-group>. <article-title>A machine learning approach to classify biomedical acoustic features for baby cries</article-title>. <source>J Voice</source>. (<year>2023</year>). <pub-id pub-id-type="doi">10.1016/j.jvoice.2023.06.014</pub-id><pub-id pub-id-type="pmid">37479635</pub-id>
</mixed-citation></ref><ref id="B36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zabidi</surname><given-names>A</given-names></name><name><surname>Yassin</surname><given-names>I</given-names></name><name><surname>Hassan</surname><given-names>H</given-names></name><name><surname>Ismail</surname><given-names>N</given-names></name><name><surname>Hamzah</surname><given-names>M</given-names></name><name><surname>Rizman</surname><given-names>Z</given-names></name><etal/></person-group>
<article-title>Detection of asphyxia in infants using deep learning convolutional neural network (CNN) trained on mel frequency cepstrum coefficient (MFCC) features extracted from cry sounds</article-title>. <source>J Fund Appl Sci</source>. (<year>2017</year>) <volume>9</volume>:<fpage>768</fpage>&#x02013;<lpage>78</lpage>. <pub-id pub-id-type="doi">10.4314/jfas.v9i3s.59</pub-id></mixed-citation></ref><ref id="B37"><label>37.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kuo</surname><given-names>K</given-names></name></person-group>. <article-title>Infant cry signal detection, pattern extraction and recognition</article-title>. In: <source>2018 International Conference on Information and Computer Technologies (ICICT); 2018 Mar 23&#x02013;25.</source>
<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2018</year>). p. <fpage>159</fpage>&#x02013;<lpage>63</lpage>. <pub-id pub-id-type="doi">10.1109/INFOCT.2018.8356861</pub-id></mixed-citation></ref><ref id="B38"><label>38.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dewi</surname><given-names>S</given-names></name><name><surname>Prasasti</surname><given-names>A</given-names></name><name><surname>Irawan</surname><given-names>B</given-names></name></person-group>. <article-title>Analysis of lfcc feature extraction in baby crying classification using knn</article-title>. In: <source>2019 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS); 2019 Nov 05&#x02013;07.</source>
<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2019</year>). <pub-id pub-id-type="doi">10.1109/IoTaIS47347.2019.8980389</pub-id></mixed-citation></ref><ref id="B39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coro</surname><given-names>G</given-names></name><name><surname>Bardelli</surname><given-names>S</given-names></name><name><surname>Cuttano</surname><given-names>A</given-names></name><name><surname>Scaramuzzo</surname><given-names>RT</given-names></name><name><surname>Ciantelli</surname><given-names>M</given-names></name></person-group>. <article-title>A self-training automatic infant-cry detector</article-title>. <source>Neural Comput Appl</source>. (<year>2023</year>) <volume>35</volume>(<issue>11</issue>):<fpage>8543</fpage>&#x02013;<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1007/s00521-022-08129-w</pub-id></mixed-citation></ref><ref id="B40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wasz-Hockert</surname><given-names>O</given-names></name><name><surname>Partanen</surname><given-names>TJ</given-names></name><name><surname>Vuorenkoski</surname><given-names>V</given-names></name><name><surname>Michelsson</surname><given-names>K</given-names></name><name><surname>Valanne</surname><given-names>E</given-names></name></person-group>. <article-title>The identification of some specific meanings in infant vocalization</article-title>. <source>Experientia</source>. (<year>1964</year>) <volume>20</volume>(<issue>3</issue>):<fpage>154</fpage>. <pub-id pub-id-type="doi">10.1007/BF02150709</pub-id><pub-id pub-id-type="pmid">4159066</pub-id>
</mixed-citation></ref><ref id="B41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>ZhuParris</surname><given-names>A</given-names></name><name><surname>Kruizinga</surname><given-names>MD</given-names></name><name><surname>van Gent</surname><given-names>M</given-names></name><name><surname>Dessing</surname><given-names>E</given-names></name><name><surname>Exadaktylos</surname><given-names>V</given-names></name><name><surname>Doll</surname><given-names>RJ</given-names></name><etal/></person-group>
<article-title>Development and technical validation of a smartphone-based cry detection algorithm</article-title>. <source>Front Pediatr</source>. (<year>2021</year>) <volume>9</volume>:<fpage>651356</fpage>. <pub-id pub-id-type="doi">10.3389/fped.2021.651356</pub-id><pub-id pub-id-type="pmid">33928059</pub-id>
</mixed-citation></ref><ref id="B42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laguna</surname><given-names>A</given-names></name><name><surname>Pusil</surname><given-names>S</given-names></name><name><surname>Baz&#x000e1;n</surname><given-names>A</given-names></name><name><surname>Zegarra-Valdivia</surname><given-names>JA</given-names></name><name><surname>Paltrinieri</surname><given-names>AL</given-names></name><name><surname>Piras</surname><given-names>P</given-names></name><etal/></person-group>
<article-title>Multi-modal analysis of infant cry types characterization: acoustics, body language and brain signals</article-title>. <source>Comput Biol Med</source>. (<year>2023</year>) <volume>167</volume>:<fpage>107626</fpage>. <pub-id pub-id-type="doi">10.1016/j.compbiomed.2023.107626</pub-id><pub-id pub-id-type="pmid">37918262</pub-id>
</mixed-citation></ref><ref id="B43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manigault</surname><given-names>AW</given-names></name><name><surname>Sheinkopf</surname><given-names>SJ</given-names></name><name><surname>Silverman</surname><given-names>HF</given-names></name><name><surname>Lester</surname><given-names>BM</given-names></name></person-group>. <article-title>Newborn cry acoustics in the assessment of neonatal opioid withdrawal syndrome using machine learning</article-title>. <source>JAMA Netw Open</source>. (<year>2022</year>) <volume>5</volume>(<issue>10</issue>):<fpage>e2238783</fpage>. <pub-id pub-id-type="doi">10.1001/jamanetworkopen.2022.38783</pub-id><pub-id pub-id-type="pmid">36301544</pub-id>
</mixed-citation></ref><ref id="B44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>YC</given-names></name><name><surname>Wijaya</surname><given-names>I</given-names></name><name><surname>Yang</surname><given-names>MT</given-names></name><name><surname>Cuevas Juarez</surname><given-names>JR</given-names></name><name><surname>Chang</surname><given-names>HT</given-names></name></person-group>. <article-title>Deep learning for infant cry recognition</article-title>. <source>Int J Environ Res Public Health</source>. (<year>2022</year>) <volume>19</volume>(<issue>10</issue>). <pub-id pub-id-type="doi">10.3390/ijerph19106311</pub-id></mixed-citation></ref><ref id="B45"><label>45.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Orlandi</surname><given-names>S</given-names></name><name><surname>Manfredi</surname><given-names>C</given-names></name><name><surname>Bocchi</surname><given-names>L</given-names></name><name><surname>Scattoni</surname><given-names>ML</given-names></name></person-group>. <article-title>Automatic newborn cry analysis: a non-invasive tool to help autism early diagnosis</article-title>. In: <source>Annual International Conference of the IEEE Engineering in Medicine and Biology Society IEEE Engineering in Medicine and Biology Society Annual International Conference; 2012 Aug 28&#x02013;2012 Sep 01</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2012</year>). p. <fpage>2953</fpage>&#x02013;<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1109/EMBC.2012.6346583</pub-id></mixed-citation></ref><ref id="B46"><label>46.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mukhopadhyay</surname><given-names>J</given-names></name><name><surname>Saha</surname><given-names>B</given-names></name><name><surname>Majumdar</surname><given-names>B</given-names></name><name><surname>Majumdar</surname><given-names>AK</given-names></name><name><surname>Gorain</surname><given-names>S</given-names></name><name><surname>Arya</surname><given-names>BK</given-names></name><etal/></person-group>
<article-title>An evaluation of human perception for neonatal cry using a database of cry and underlying cause</article-title>. In: <source>2013 Indian Conference on Medical Informatics and Telemedicine (ICMIT); 2013 Mar 28&#x02013;30</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2013</year>). p. <fpage>64</fpage>&#x02013;<lpage>7</lpage>. <pub-id pub-id-type="doi">10.1109/IndianCMIT.2013.6529410</pub-id></mixed-citation></ref><ref id="B47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mampe</surname><given-names>B</given-names></name><name><surname>Friederici</surname><given-names>AD</given-names></name><name><surname>Christophe</surname><given-names>A</given-names></name><name><surname>Wermke</surname><given-names>K</given-names></name></person-group>. <article-title>Newborns&#x02019; cry melody is shaped by their native language</article-title>. <source>Curr Biol</source>. (<year>2009</year>) <volume>19</volume>(<issue>23</issue>):<fpage>1994</fpage>&#x02013;<lpage>7</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2009.09.064</pub-id><pub-id pub-id-type="pmid">19896378</pub-id>
</mixed-citation></ref><ref id="B48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wermke</surname><given-names>K</given-names></name><name><surname>Teiser</surname><given-names>J</given-names></name><name><surname>Yovsi</surname><given-names>E</given-names></name><name><surname>Kohlenberg</surname><given-names>P</given-names></name><name><surname>Wermke</surname><given-names>P</given-names></name><name><surname>Robb</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>Fundamental frequency variation within neonatal crying: does ambient language matter?</article-title>
<source>Speech Lang Hear</source>. (<year>2016</year>) <volume>19</volume>. <pub-id pub-id-type="doi">10.1080/2050571X.2016.1187903</pub-id><pub-id pub-id-type="pmid">27158499</pub-id>
</mixed-citation></ref><ref id="B49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Floridi</surname><given-names>L</given-names></name></person-group>. <article-title>Ai and its new winter: from myths to realities</article-title>. <source>Philos Technol</source>. (<year>2020</year>) <volume>33</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>3</lpage>. <pub-id pub-id-type="doi">10.1007/s13347-020-00396-6</pub-id></mixed-citation></ref><ref id="B50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doyle</surname><given-names>CM</given-names></name><name><surname>Lasch</surname><given-names>C</given-names></name><name><surname>Elison</surname><given-names>JT</given-names></name></person-group>. <article-title>Emerging evidence for putative neural networks and antecedents of pediatric anxiety in the fetal, neonatal, and infant periods</article-title>. <source>Biol Psychiatry</source>. (<year>2021</year>) <volume>89</volume>(<issue>7</issue>):<fpage>672</fpage>&#x02013;<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2020.11.020</pub-id><pub-id pub-id-type="pmid">33518264</pub-id>
</mixed-citation></ref><ref id="B51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>He</surname><given-names>Z</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Kang</surname><given-names>Y</given-names></name><etal/></person-group>
<article-title>Differentiate preterm and term infant brains and characterize the corresponding biomarkers via dicccol-based multi-modality graph neural networks</article-title>. <source>Front Neurosci</source>. (<year>2022</year>) <volume>16</volume>:<fpage>951508</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2022.951508</pub-id><pub-id pub-id-type="pmid">36312010</pub-id>
</mixed-citation></ref><ref id="B52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witteman</surname><given-names>J</given-names></name><name><surname>Van</surname><given-names>IMH</given-names></name><name><surname>Rilling</surname><given-names>JK</given-names></name><name><surname>Bos</surname><given-names>PA</given-names></name><name><surname>Schiller</surname><given-names>NO</given-names></name><name><surname>Bakermans-Kranenburg</surname><given-names>MJ</given-names></name></person-group>. <article-title>Towards a neural model of infant cry perception</article-title>. <source>Neurosci Biobehav Rev</source>. (<year>2019</year>) <volume>99</volume>:<fpage>23</fpage>&#x02013;<lpage>32</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2019.01.026</pub-id><pub-id pub-id-type="pmid">30710581</pub-id>
</mixed-citation></ref><ref id="B53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>S</given-names></name><name><surname>Xiang</surname><given-names>W</given-names></name><name><surname>Atkinson</surname><given-names>I</given-names></name></person-group>. <article-title>Hybridized neural networks for non-invasive and continuous mortality risk assessment in neonates</article-title>. <source>Comput Biol Med</source>. (<year>2021</year>) <volume>134</volume>:<fpage>104521</fpage>. <pub-id pub-id-type="doi">10.1016/j.compbiomed.2021.104521</pub-id><pub-id pub-id-type="pmid">34111664</pub-id>
</mixed-citation></ref><ref id="B54"><label>54.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sahak</surname><given-names>R</given-names></name><name><surname>Mansor</surname><given-names>W</given-names></name><name><surname>Lee</surname><given-names>YK</given-names></name><name><surname>Yassin</surname><given-names>AM</given-names></name><name><surname>Zabidi</surname><given-names>A</given-names></name></person-group>. <article-title>Performance of combined support vector machine and principal component analysis in recognizing infant cry with asphyxia</article-title>. In: <source>Annual International Conference of the IEEE Engineering in Medicine and Biology Society IEEE Engineering in Medicine and Biology Society Annual International Conference; 2010 Aug 31&#x02013; 2010 Sep 04</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2010</year>). p. <fpage>6292</fpage>&#x02013;<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1109/IEMBS.2010.5628084</pub-id></mixed-citation></ref><ref id="B55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabon</surname><given-names>S</given-names></name><name><surname>Met-Montot</surname><given-names>B</given-names></name><name><surname>Por&#x000e9;e</surname><given-names>F</given-names></name><name><surname>Rosec</surname><given-names>O</given-names></name><name><surname>Simon</surname><given-names>A</given-names></name><name><surname>Carrault</surname><given-names>G</given-names></name></person-group>. <article-title>Extraction of premature Newborns&#x02019; spontaneous cries in the real context of neonatal intensive care units</article-title>. <source>Sensors (Basel, Switzerland)</source>. (<year>2022</year>) <volume>22</volume>(<issue>5</issue>). <pub-id pub-id-type="doi">10.3390/s22051823</pub-id><pub-id pub-id-type="pmid">35270967</pub-id>
</mixed-citation></ref><ref id="B56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farsaie Alaie</surname><given-names>H</given-names></name><name><surname>Abou-Abbas</surname><given-names>L</given-names></name><name><surname>Tadj</surname><given-names>C</given-names></name></person-group>. <article-title>Cry-based infant pathology classification using GMMs</article-title>. <source>Speech Commun</source>. (<year>2016</year>) <volume>77</volume>:<fpage>28</fpage>&#x02013;<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1016/j.specom.2015.12.001</pub-id><pub-id pub-id-type="pmid">27524848</pub-id>
</mixed-citation></ref><ref id="B57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashwini</surname><given-names>K</given-names></name><name><surname>Vincent</surname><given-names>P</given-names></name><name><surname>Srinivasan</surname><given-names>K</given-names></name><name><surname>Chang</surname><given-names>CY</given-names></name></person-group>. <article-title>Deep learning assisted neonatal cry classification via support vector machine models</article-title>. <source>Front Public Health</source>. (<year>2021</year>) <volume>9</volume>:<fpage>670352</fpage>. <pub-id pub-id-type="doi">10.3389/fpubh.2021.670352</pub-id><pub-id pub-id-type="pmid">34178926</pub-id>
</mixed-citation></ref><ref id="B58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Guo</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Dong</surname><given-names>S</given-names></name><name><surname>Cui</surname><given-names>G</given-names></name></person-group>. <article-title>Constructing <italic>in situ</italic> polymerized electrolyte on lithiophilic anode for high-performance lithium&#x02013;air batteries operating in ambient conditions</article-title>. <source>Energy Storage Mater</source>. (<year>2021</year>) <volume>43</volume>:<fpage>221</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/j.ensm.2021.08.041</pub-id></mixed-citation></ref><ref id="B59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zayed</surname><given-names>Y</given-names></name><name><surname>Hasasneh</surname><given-names>A</given-names></name><name><surname>Tadj</surname><given-names>C</given-names></name></person-group>. <article-title>Infant cry signal diagnostic system using deep learning and fused features</article-title>. <source>Diagnostics</source>. (<year>2023</year>) <volume>13</volume>(<issue>12</issue>). <pub-id pub-id-type="doi">10.3390/diagnostics13122107</pub-id></mixed-citation></ref><ref id="B60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Ting</surname><given-names>HN</given-names></name><name><surname>Choo</surname><given-names>YM</given-names></name></person-group>. <article-title>Baby cry recognition based on woa-vmd and an improved dempster-shafer evidence theory</article-title>. <source>Comput Methods Programs Biomed</source>. (<year>2024</year>) <volume>245</volume>:<fpage>108043</fpage>. <pub-id pub-id-type="doi">10.1016/j.cmpb.2024.108043</pub-id><pub-id pub-id-type="pmid">38306944</pub-id>
</mixed-citation></ref><ref id="B61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laguna</surname><given-names>A</given-names></name><name><surname>Pusil</surname><given-names>S</given-names></name><name><surname>Acero-Pousa</surname><given-names>I</given-names></name><name><surname>Zegarra-Valdivia</surname><given-names>JA</given-names></name><name><surname>Paltrinieri</surname><given-names>AL</given-names></name><name><surname>Baz&#x000e1;n</surname><given-names>&#x000c0;</given-names></name><etal/></person-group>
<article-title>How can cry acoustics associate Newborns' Distress levels with neurophysiological and behavioral signals?</article-title>
<source>Front Neurosci</source>. (<year>2023</year>) <volume>17</volume>:<fpage>1266873</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2023.1266873</pub-id><pub-id pub-id-type="pmid">37799341</pub-id>
</mixed-citation></ref><ref id="B62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porter</surname><given-names>FL</given-names></name><name><surname>Porges</surname><given-names>SW</given-names></name><name><surname>Marshall</surname><given-names>RE</given-names></name></person-group>. <article-title>Newborn pain cries and vagal tone: parallel changes in response to circumcision</article-title>. <source>Child Dev</source>. (<year>1988</year>) <volume>59</volume>(<issue>2</issue>):<fpage>495</fpage>&#x02013;<lpage>505</lpage>. <pub-id pub-id-type="doi">10.2307/1130327</pub-id><pub-id pub-id-type="pmid">3359867</pub-id>
</mixed-citation></ref><ref id="B63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamamoto</surname><given-names>S</given-names></name><name><surname>Yoshitomi</surname><given-names>Y</given-names></name><name><surname>Tabuse</surname><given-names>M</given-names></name><name><surname>Kushida</surname><given-names>K</given-names></name><name><surname>Asada</surname><given-names>T</given-names></name></person-group>. <article-title>Recognition of a baby's emotional cry towards robotics baby caregiver</article-title>. <source>Int J Adv Robot Syst</source>. (<year>2017</year>) <volume>10</volume>(<issue>2</issue>):<fpage>86</fpage>. <pub-id pub-id-type="doi">10.5772/55406</pub-id></mixed-citation></ref><ref id="B64"><label>64.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Saraswathy</surname><given-names>J</given-names></name><name><surname>Hariharan</surname><given-names>M</given-names></name><name><surname>Yaacob</surname><given-names>S</given-names></name><name><surname>Khairunizam</surname><given-names>W</given-names></name></person-group>. <article-title>Automatic classification of infant cry: a review</article-title>. In: <source>2012 International Conference on Biomedical Engineering (ICoBE); 2012 Feb 27&#x02013;28.</source>
<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name> (<year>2012</year>). p. <fpage>543</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1109/ICoBE.2012.6179077</pub-id></mixed-citation></ref><ref id="B65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahmoudian</surname><given-names>S</given-names></name><name><surname>Aminrasouli</surname><given-names>N</given-names></name><name><surname>Ahmadi</surname><given-names>ZZ</given-names></name><name><surname>Lenarz</surname><given-names>T</given-names></name><name><surname>Farhadi</surname><given-names>M</given-names></name></person-group>. <article-title>Acoustic analysis of crying signal in infants with disabling hearing impairment</article-title>. <source>J Voice</source>. (<year>2019</year>) <volume>33</volume>(<issue>6</issue>):<fpage>946.e7</fpage>&#x02013;<lpage>e13</lpage>. <pub-id pub-id-type="doi">10.1016/j.jvoice.2018.05.016</pub-id><pub-id pub-id-type="pmid">30055981</pub-id>
</mixed-citation></ref><ref id="B66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lester</surname><given-names>BM</given-names></name></person-group>. <article-title>Spectrum analysis of the cry sounds of well-nourished and malnourished infants</article-title>. <source>Child Dev</source>. (<year>1976</year>) <volume>47</volume>(<issue>1</issue>):<fpage>237</fpage>&#x02013;<lpage>41</lpage>. <pub-id pub-id-type="doi">10.2307/1128305</pub-id><pub-id pub-id-type="pmid">954495</pub-id>
</mixed-citation></ref><ref id="B67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donzelli</surname><given-names>GP</given-names></name><name><surname>Rapisardi</surname><given-names>G</given-names></name><name><surname>Moroni</surname><given-names>M</given-names></name><name><surname>Zani</surname><given-names>S</given-names></name><name><surname>Tomasini</surname><given-names>B</given-names></name><name><surname>Ismaelli</surname><given-names>A</given-names></name><etal/></person-group>
<article-title>Computerized cry analysis in infants affected by severe protein energy malnutrition</article-title>. <source>Acta Paediatr</source>. (<year>1994</year>) <volume>83</volume>(<issue>2</issue>):<fpage>204</fpage>&#x02013;<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1111/j.1651-2227.1994.tb13052.x</pub-id><pub-id pub-id-type="pmid">8193504</pub-id>
</mixed-citation></ref><ref id="B68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lester</surname><given-names>BM</given-names></name><name><surname>Dreher</surname><given-names>M</given-names></name></person-group>. <article-title>Effects of marijuana use during pregnancy on newborn cry</article-title>. <source>Child Dev</source>. (<year>1989</year>) <volume>60</volume>:<fpage>765</fpage>&#x02013;<lpage>71</lpage>. <pub-id pub-id-type="doi">10.2307/1131016</pub-id><pub-id pub-id-type="pmid">2758874</pub-id>
</mixed-citation></ref><ref id="B69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lawford</surname><given-names>HLS</given-names></name><name><surname>Sazon</surname><given-names>H</given-names></name><name><surname>Richard</surname><given-names>C</given-names></name><name><surname>Robb</surname><given-names>MP</given-names></name><name><surname>Bora</surname><given-names>S</given-names></name></person-group>. <article-title>Acoustic cry characteristics of infants as a marker of neurological dysfunction: a systematic review and meta-analysis</article-title>. <source>Pediatr Neurol</source>. (<year>2022</year>) <volume>129</volume>:<fpage>72</fpage>&#x02013;<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1016/j.pediatrneurol.2021.10.017</pub-id><pub-id pub-id-type="pmid">35245810</pub-id>
</mixed-citation></ref><ref id="B70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tenold</surname><given-names>JL</given-names></name><name><surname>Crowell</surname><given-names>DH</given-names></name><name><surname>Jones</surname><given-names>RH</given-names></name><name><surname>Daniel</surname><given-names>TH</given-names></name><name><surname>McPherson</surname><given-names>DF</given-names></name><name><surname>Popper</surname><given-names>AN</given-names></name></person-group>. <article-title>Cepstral and stationarity analyses of full-term and premature infants&#x02019; cries</article-title>. <source>J Acoust Soc Am</source>. (<year>1974</year>) <volume>56</volume>(<issue>3</issue>):<fpage>975</fpage>&#x02013;<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1121/1.1903358</pub-id><pub-id pub-id-type="pmid">4424880</pub-id>
</mixed-citation></ref><ref id="B71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheinkopf</surname><given-names>SJ</given-names></name><name><surname>Iverson</surname><given-names>JM</given-names></name><name><surname>Rinaldi</surname><given-names>ML</given-names></name><name><surname>Lester</surname><given-names>BM</given-names></name></person-group>. <article-title>Atypical cry acoustics in 6-month-old infants at risk for autism spectrum disorder</article-title>. <source>Autism Res</source>. (<year>2012</year>) <volume>5</volume>(<issue>5</issue>):<fpage>331</fpage>&#x02013;<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1002/aur.1244</pub-id><pub-id pub-id-type="pmid">22890558</pub-id>
</mixed-citation></ref><ref id="B72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>English</surname><given-names>MS</given-names></name><name><surname>Tenenbaum</surname><given-names>EJ</given-names></name><name><surname>Levine</surname><given-names>TP</given-names></name><name><surname>Lester</surname><given-names>BM</given-names></name><name><surname>Sheinkopf</surname><given-names>SJ</given-names></name></person-group>. <article-title>Perception of cry characteristics in 1-month-old infants later diagnosed with autism spectrum disorder</article-title>. <source>J Autism Dev Disord</source>. (<year>2019</year>) <volume>49</volume>(<issue>3</issue>):<fpage>834</fpage>&#x02013;<lpage>44</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-018-3788-2</pub-id><pub-id pub-id-type="pmid">30361941</pub-id>
</mixed-citation></ref><ref id="B73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khozaei</surname><given-names>A</given-names></name><name><surname>Moradi</surname><given-names>H</given-names></name><name><surname>Hosseini</surname><given-names>R</given-names></name><name><surname>Pouretemad</surname><given-names>H</given-names></name><name><surname>Eskandari</surname><given-names>B</given-names></name></person-group>. <article-title>Early screening of autism Spectrum disorder using cry features</article-title>. <source>PLoS One</source>. (<year>2020</year>) <volume>15</volume>(<issue>12</issue>):<fpage>e0241690</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0241690</pub-id><pub-id pub-id-type="pmid">33301502</pub-id>
</mixed-citation></ref><ref id="B74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porges</surname><given-names>SW</given-names></name></person-group>. <article-title>The polyvagal theory: phylogenetic substrates of a social nervous system</article-title>. <source>Int J Psychophysiol</source>. (<year>2001</year>) <volume>42</volume>(<issue>2</issue>):<fpage>123</fpage>&#x02013;<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1016/S0167-8760(01)00162-3</pub-id><pub-id pub-id-type="pmid">11587772</pub-id>
</mixed-citation></ref><ref id="B75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porges</surname><given-names>SW</given-names></name><name><surname>Doussard-Roosevelt</surname><given-names>JA</given-names></name><name><surname>Maiti</surname><given-names>AK</given-names></name></person-group>. <article-title>Vagal tone and the physiological regulation of emotion</article-title>. <source>Monogr Soc Res Child Dev</source>. (<year>1994</year>) <volume>59</volume>(<issue>2&#x02013;3</issue>):<fpage>167</fpage>&#x02013;<lpage>86</lpage>. <pub-id pub-id-type="doi">10.1111/j.1540-5834.1994.tb01283.x</pub-id><pub-id pub-id-type="pmid">7984159</pub-id>
</mixed-citation></ref></ref-list></back></article>