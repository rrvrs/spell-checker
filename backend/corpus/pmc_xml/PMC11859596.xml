<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006424</article-id><article-id pub-id-type="pmc">PMC11859596</article-id><article-id pub-id-type="doi">10.3390/s25041196</article-id><article-id pub-id-type="publisher-id">sensors-25-01196</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Electric Motor Vibration Signal Classification Using Wigner&#x02013;Ville Distribution for Fault Diagnosis</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-6787-8510</contrib-id><name><surname>Wu</surname><given-names>Jian-Da</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af1-sensors-25-01196" ref-type="aff">1</xref><xref rid="c1-sensors-25-01196" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Luo</surname><given-names>Wen-Jun</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><xref rid="af2-sensors-25-01196" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5975-2392</contrib-id><name><surname>Yao</surname><given-names>Kai-Chao</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af2-sensors-25-01196" ref-type="aff">2</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Lerga</surname><given-names>Jonatan</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Zdravevski</surname><given-names>Eftim</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Kov&#x000e1;cs</surname><given-names>P&#x000e9;ter</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01196"><label>1</label>Graduate Institute of Vehicle Engineering, National Changhua University of Education, Changhua 50007, Taiwan</aff><aff id="af2-sensors-25-01196"><label>2</label>Department of Industrial Education and Technology, National Changhua University of Education, Changhua 50007, Taiwan; <email>wenjun_2020@ctu.edu.tw</email> (W.-J.L.); <email>kcyao@cc.ncue.edu.tw</email> (K.-C.Y.)</aff><author-notes><corresp id="c1-sensors-25-01196"><label>*</label>Correspondence: <email>jdwu@cc.ncue.edu.tw</email></corresp></author-notes><pub-date pub-type="epub"><day>15</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1196</elocation-id><history><date date-type="received"><day>17</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>11</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>13</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Noise and vibration signal classification can be applied to fault diagnosis in mechanical and electronic systems such as electric vehicles. Traditional signal classification technology uses signal time and frequency domain characteristics as the identification basis. This study proposes a technique for visualizing sound signals using the Wigner&#x02013;Ville distribution (WVD) method to extract vibration signal characteristics and artificial neural networks as the signal classification basis. A brushless motor is used as the machinery power source to verify the feasibility of this method to classify different signal vibration characteristics. In this experimental work, six states in various brushless motor revolutions were deliberately designed for measuring vibration signals. The brushless motor vibration signal is imaged using the WVD analysis method to extract the vibration signal characteristics. Through the WVD method, the brushless motor data is converted, and the YOLO (you only look once) deep coiling machine neural method is used to identify and classify the brushless motor WVD images. The Wagener analysis method parameters and recognition rates are discussed, thereby improving accurate motor fault diagnostic capabilities. This research provides a method for fault diagnosis that can be accurately performed without dismantling the brushless motor. The proposed approach can improve the reliability and stability of brushless motor applications.</p></abstract><kwd-group><kwd>Wigner&#x02013;Ville distribution method</kwd><kwd>brushless motor fault diagnosis</kwd><kwd>object detection</kwd><kwd>YOLO</kwd></kwd-group><funding-group><funding-statement>This research received no external funding.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01196"><title>1. Introduction</title><p>In traditional motor fault diagnosis, mechanical structures are inspected under operating conditions to identify and confirm issues. With advances in technology, sensors are now used to analyze mechanical faults like those in motors, enabling faster resolution. Vibration and sound data are commonly used to pinpoint fault locations. Accelerometers are often employed to collect vibration signals, recording device vibrations accurately. For vibration signal analysis, methods like Fourier transform (FFT) and wavelet transform are commonly used to extract signal features. However, FFT has limited resolution because it does not synchronize the time and frequency domains, leading to a loss of time-domain information when converting to the frequency domain. As a result, time-domain vibration signals cannot be fully observed.</p><p>This research uses the Wigner&#x02013;Ville distribution to convert the brushless motor vibration signal into an image. YOLO object detection to identify fault types is then applied. Lohmann, A. W. [<xref rid="B1-sensors-25-01196" ref-type="bibr">1</xref>] in 1993 defined the Wigner function distribution and described the Wigner and Fourier transformations from a geometric perspective. Meng, Q. and Qu, L. [<xref rid="B2-sensors-25-01196" ref-type="bibr">2</xref>] in 1991 suggested using the Wigner distribution for rotating machinery fault diagnosis, showing that it can effectively analyze time-frequency characteristics and provide useful insights. Weinbub, J. and Ferry, D. K. [<xref rid="B3-sensors-25-01196" ref-type="bibr">3</xref>] proposed the Wigner function in 1932, which offers important quantum method information relevant to physical systems.</p><p>In 2003, Geng, Z. et al. [<xref rid="B4-sensors-25-01196" ref-type="bibr">4</xref>] proposed engine vibration analysis and diagnostic methods focusing on feature extraction from reciprocating engine vibrations. Zhang, Z. [<xref rid="B5-sensors-25-01196" ref-type="bibr">5</xref>] in 2019 introduced the optimal linear normal Wigner distribution for noise linear frequency modulation signals, utilizing a three-parameter linear integral transformation. Brajovi&#x00107;, M. and Popovi&#x00107;-Bugarin, V. [<xref rid="B6-sensors-25-01196" ref-type="bibr">6</xref>] in 2015 added the Wigner distribution algorithm to the ant optimization method to estimate instantaneous frequency in high-noise environments. Stankovic, L. and Katkovnik, V. [<xref rid="B7-sensors-25-01196" ref-type="bibr">7</xref>] addressed challenges in using the Wigner distribution for time-frequency representation and proposed an adaptive algorithm to improve analysis. Qiu, L. [<xref rid="B8-sensors-25-01196" ref-type="bibr">8</xref>] in 1993 introduced the Wigner&#x02013;Ville distribution for analyzing non-stationary signals.</p><p>In 1999, Lee, S. K. [<xref rid="B9-sensors-25-01196" ref-type="bibr">9</xref>] applied Wigner analysis to detect pulse signals in damaged gears, where such signals are often masked by noise. Dragoman, D. [<xref rid="B10-sensors-25-01196" ref-type="bibr">10</xref>] in 2005 demonstrated the Wigner distribution&#x02019;s versatility across various signal-processing fields, especially in optics. Chen, J. Y. and Li, B. Z. [<xref rid="B11-sensors-25-01196" ref-type="bibr">11</xref>] developed short-term Wigner (STWD) and derived the WVD (Wigner&#x02013;Ville distribution) as a tool for analyzing non-stationary signals, revealing multiple frequency components simultaneously. Liu, X. et al. [<xref rid="B12-sensors-25-01196" ref-type="bibr">12</xref>] proposed optical applications, Wigner analysis enhances directional and local image features. Wu, J. D. and Huang, C. K. [<xref rid="B13-sensors-25-01196" ref-type="bibr">13</xref>] proposed engine fault diagnosis based on intake manifold pressure analysis using Weigl&#x02019;s method and highlighted the Wigner distribution&#x02019;s ability to provide clear time-domain and frequency-domain energy spectra.</p><p>Huang, H. B. et al. [<xref rid="B14-sensors-25-01196" ref-type="bibr">14</xref>] applied the Wigner distribution to analyze vehicle suspension noise and correlated their findings with expert evaluations, establishing an analysis method for vehicle chassis systems. Tang, B. et al. [<xref rid="B15-sensors-25-01196" ref-type="bibr">15</xref>] used wavelet transformation and Wigner analysis for diagnosing large wind turbine faults. Tao, X et al. [<xref rid="B16-sensors-25-01196" ref-type="bibr">16</xref>] proposed a bearing fault detection method based on wavelet transform and generalized Gaussian distribution modeling, which can use wavelet transform to extract vibration signal features. Dhandapani, R. et al. [<xref rid="B17-sensors-25-01196" ref-type="bibr">17</xref>] proposed a bearing fault diagnosis and classification method based on generalized Gaussian distribution and multi-scale dispersed entropy features in 2022 and used machine learning for diagnosis. In deep learning, Lee, K. B. and Shin, H. S. [<xref rid="B18-sensors-25-01196" ref-type="bibr">18</xref>] used algorithms to detect tunnel accidents, identifying reverse vehicles, parked cars, people, and flames within 10 s. Liu, J. [<xref rid="B19-sensors-25-01196" ref-type="bibr">19</xref>] summarized deep learning theories in self-driving car image recognition. Widjojo, D. et al. [<xref rid="B20-sensors-25-01196" ref-type="bibr">20</xref>] classified automobile sheet metal damage using CNN (Convolutional neural networks) for faster data classification. Rao, A.S et al. [<xref rid="B21-sensors-25-01196" ref-type="bibr">21</xref>] in 2022 classified vehicle models using deep learning. Kulkarni, R. et al. [<xref rid="B22-sensors-25-01196" ref-type="bibr">22</xref>] highlighted challenges in traffic light and lane detection for autonomous vehicles. Silva, J. D. et al. [<xref rid="B23-sensors-25-01196" ref-type="bibr">23</xref>] applied micro machine learning to analyze potholes, enhancing model training by correcting image boundaries first. In agriculture, Kurniadi, F. A. et al. [<xref rid="B24-sensors-25-01196" ref-type="bibr">24</xref>] used drones to photograph dairy cows and applied YOLO for effective cattle identification, noting reduced accuracy with increased flight altitude. Reddy, B. et al. [<xref rid="B25-sensors-25-01196" ref-type="bibr">25</xref>] applied YOLO to identify motorcycle violations such as helmet-less riding or overloading. Sun, Z. [<xref rid="B26-sensors-25-01196" ref-type="bibr">26</xref>] YOLO has also been applied for real-time airport safety monitoring. Liu, L et al. [<xref rid="B27-sensors-25-01196" ref-type="bibr">27</xref>] published a method for estimating the remaining useful life (RUL) of lithium-ion batteries using small sample data. The Deep Autoregressive Recurrent Neural Network (DAR-RNN) proposed by Zhang, C. et al. [<xref rid="B28-sensors-25-01196" ref-type="bibr">28</xref>] predicts the remaining useful life (RUL) of lithium-ion batteries throughout their entire life cycle. In order to enhance the classification capability of brushless motor faults, this study established a brushless motor fault vibration signal database. By applying the Wigner analysis method to these signals, the vibration signal characteristics are expressed, the Wigner analysis method parameters are further studied, and the analysis parameters are optimized to improve fault classification accuracy and reliability.</p><p>In order to enhance the brushless motor fault classification capability, this study established a brushless motor fault vibration signal database. By applying the Wigner analysis method to these signals, the vibration signal characteristics are expressed, and the Wigner analysis method parameters are further studied. The analysis parameters are optimized to improve the fault classification accuracy and reliability. This study applies YOLO object detection to Wigner&#x02013;Ville for brushless motor fault diagnosis. First, we decided to conduct vibration analysis on brushless motors and use accelerometers to collect data on the fault conditions of brushless motors. The data was divided into six states. After establishing a brushless motor vibration database, we used Wigner&#x02013;Ville to analyze the vibration data. Visualization is used as the basis for image recognition. In the image recognition software application, YOLO is selected for data testing, training and model establishment. The time delay parameters in Wigner&#x02013;Ville are adjusted to find the most suitable method for analyzing the brushless motor vibration signal coefficient. The reason why we chose YOLO in the recognition system is that it performs well in image classification and improves its feature extraction capability in the architecture, which can maintain high image analysis accuracy. Therefore, we chose to use the YOLO system in image recognition as the main framework for feature recognition.</p></sec><sec id="sec2-sensors-25-01196"><title>2. Feature Extraction Methods Using Wigner&#x02013;Ville Distribution</title><p>The Wigner&#x02013;Ville distribution is a time-frequency analysis method used to analyze the instantaneous signal frequencies. In this study the Wigner&#x02013;Ville distribution is used to analyze brushless motor fault data, and the brushless motor working conditions are divided into six states. The following is the Wigner&#x02013;Ville distribution derivation process. The Wigner&#x02013;Ville distribution was proposed by the Hungarian physicist Eugene Wigner in 1932. The time-frequency mathematical form of the Wigner&#x02013;Ville distribution is as follows: Equations (1) and (2).<disp-formula id="FD1-sensors-25-01196"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">&#x0221e;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>&#x022c5;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02217;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>&#x022c5;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="sans-serif">&#x003c9;</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
<list list-type="simple"><list-item><p><inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> represents a Wigner&#x02013;Ville distribution time-frequency function, showing the brushless motor vibration signal energy distribution across time and frequency.</p></list-item><list-item><p><inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the brushless motor vibration signal, which is awaiting analysis.</p></list-item><list-item><p><inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02217;</mml:mo><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the conjugate of <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For a real-valued brushless motor vibration signal, the conjugate is equal to the signal itself. For complex signals, the conjugate means taking the negative of the imaginary part of the complex number.</p></list-item><list-item><p><inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the time delay coefficient, representing the difference between two time points of the brushless motor vibration signal.</p></list-item><list-item><p><inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> represents the brushless motor vibration signal frequency.</p></list-item><list-item><p><inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the imaginary unit.</p></list-item><list-item><p><inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="sans-serif">&#x003c9;</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the complex exponential function that describes the brushless motor vibration signal phase changes at different times and frequencies.</p></list-item><list-item><p><inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="sans-serif">&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is a small increment of the time delay coefficient.</p></list-item></list></p><p>If Equation (1) is applied to a signal, Equation (1) becomes Equation (2).<disp-formula id="FD2-sensors-25-01196"><label>(2)</label><mml:math id="mm11" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003c9;</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">&#x0221e;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>&#x022c5;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02217;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>&#x022c5;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="sans-serif">&#x003c9;</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>Equation (2) illustrates the brushless motor vibration signal energy distribution in time and frequency. The brushless motor vibration signal characteristics at different times can be observed.</p><p>The Wigner&#x02013;Ville distribution principle can be understood from Equations (1) and (2). After these experiments it was found that the Wigner&#x02013;Ville distribution can provide good time-frequency resolution in analyzing brushless motor vibration signals and determine various categories. The brushless motor vibration signal energy distribution is different, and the brushless motor vibration signal can be presented through the Wigner&#x02013;Ville distribution two-dimensional image. When the brushless motor vibration signal changes in different states, the changes can be distinguished through the two-dimensional image, allowing the brushless motor vibration signal to be accurately identified. The brushless motor vibration signal is visualized to facilitate judgment of the brushless motor&#x02019;s abnormal status, allowing the signal to be cross analyzed.</p><p>When the brushless motor vibration signal is converted from the signal acquirer through MATLAB 2023 (MathWorks, Natick, MA, USA), and before using Wigner&#x02013;Ville on the signal, the Hilbert transformation is first performed on the signal. Time-frequency analysis is then performed on the brushless motor vibration signal. Hilbert transformation can be used to ensure better results for the signal. The Hilbert transformation can be understood from Equation (3).<disp-formula id="FD3-sensors-25-01196"><label>(3)</label><mml:math id="mm12" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">{</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">}</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">&#x0221e;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mi>d</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
<list list-type="simple"><list-item><p><inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the input brushless motor vibration signal.</p></list-item><list-item><p><inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> represents the brushless motor vibration signal time length.</p></list-item><list-item><p><inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> represents the Hilbert transformation time delay coefficient.</p></list-item></list>
</p><p>In signal processing a real signal number is converted into a complex signal number through Hilbert transformation. The original signal phase characteristics are retained after the analysis is completed. This conversion can be used to obtain more information from the brushless motor vibration signal. The brushless motor&#x02019;s vibration characteristics can be extracted using Wigner&#x02013;Ville. Hilbert transformation can capture the vibration signal energy changes in nonlinear systems and is suitable for use in analyzing mechanical vibrations.</p><p>In <xref rid="sensors-25-01196-f001" ref-type="fig">Figure 1</xref> and <xref rid="sensors-25-01196-f002" ref-type="fig">Figure 2</xref>, the sine wave as the input signal and the brushless motor vibration signal are represented, with the characteristics displayed in 2D. The signal characteristics are shown on a plane, further highlighting that the brushless motor normal-state vibration signal characteristic values are well presented after Wigner&#x02013;Ville and transformation.</p></sec><sec id="sec3-sensors-25-01196"><title>3. Object Detection Principle</title><sec id="sec3dot1-sensors-25-01196"><title>3.1. Principles of Deep Learning</title><p>Deep learning is a subset of machine learning and has become increasingly popular in recent years. One well-known deep learning algorithm is the convolutional neural network, which will be discussed in later chapters. Deep learning is a key part of artificial intelligence, built on machine learning principles. Machine learning uses large datasets and information from big data to analyze and solve problems, such as classification and identification. Historically, machine learning has been categorized into three types: supervised learning, unsupervised learning, and reinforcement learning, each contributing to various studies before deep learning was fully developed.</p><p>Supervised learning involves labeling the training data, defining its characteristics, and using it for tasks like regression, classification, and prediction. The computer is provided with the correct answers in advance, allowing it to train and correct the data to achieve better accuracy. However, supervised learning requires extensive preparatory work, and handling large datasets can be computationally challenging. Unsupervised learning allows the model to discover patterns in the data without predefined labels, helping the computer identify hidden rules. It is often used in cluster analysis and recommendation systems. However, without a standard answer, data distortion can occur. Reinforcement learning doesn&#x02019;t require labeled data. Instead, the model learns through continuous interaction with its environment, optimizing its performance over time based on weighted outcomes. <xref rid="sensors-25-01196-f003" ref-type="fig">Figure 3</xref> shows the evolution of deep learning.</p><p>Deep learning advances on these foundations using neural networks, which mimic biological brains. Initially, neural networks faced issues like vanishing gradients, but significant progress, especially since 2006, has led to the rise of multi-layer neural networks, driving the deep learning revolution. The development of neural networks began with the simulation of neural processes. However, challenges like vanishing gradients and complex calculations led to a period of stagnation. In 2006, Hinton et al. successfully trained multi-layer neural networks, marking a breakthrough in deep learning [<xref rid="B29-sensors-25-01196" ref-type="bibr">29</xref>]. Deep learning, which allows neural networks to pass through multiple layers, initially struggled due to limitations in CPU computing power. However, with the advent of GPUs, deep learning experienced a surge in popularity. The neural networks concept, first introduced by Rosenblatt in 1958 as a single-layer model, evolved over time as scholars adopted multi-layer architectures, paving the way for modern deep learning [<xref rid="B30-sensors-25-01196" ref-type="bibr">30</xref>].</p></sec><sec id="sec3dot2-sensors-25-01196"><title>3.2. Principles of Convolutional Neural Networks</title><p>Convolutional neural networks (CNN) analyze images by comparing local features, making them effective for image recognition even when the image is flipped or deformed. The convolution operation uses nonlinear transformation to extract features from images, but handling a large number of images can be computationally intensive. CNN reduces the dimensionality of images through pooling layers, which results in a feature map. <xref rid="sensors-25-01196-f004" ref-type="fig">Figure 4</xref> Shows that the CNN structure includes an input layer, convolution layer, pooling layer, and fully connected layer. The input layer represents the image data.</p><p>The convolution layer acts as a filter, comparing local image features and calculating pixel correlations. Multiple layers can enhance the image features. The pooling layer compresses the image by retaining core features and reducing irrelevant data, which helps lower the computational load. The fully connected layer converts the 3D image data into 1D and functions as a classifier, enhancing image recognition by integrating features from previous layers. <xref rid="sensors-25-01196-f004" ref-type="fig">Figure 4</xref> shows how the convolution layer works, applying filters to sharpen or blur the image by combining pixel values.</p><p>The pooling operation, shown in <xref rid="sensors-25-01196-f004" ref-type="fig">Figure 4</xref>, extracts maximum or average values from the feature map, reducing parameters while retaining important features. Pooling simplifies the image while preserving essential information for identification. The fully connected layer is illustrated in <xref rid="sensors-25-01196-f004" ref-type="fig">Figure 4</xref>. This layer integrates feature values from previous layers into one, improving image classification accuracy by reducing the influence of feature positions.</p></sec><sec id="sec3dot3-sensors-25-01196"><title>3.3. YOLO (You Only Look Once) Principle</title><p>Traditional object detection methods using classifiers fall behind the YOLO system in terms of speed and accuracy. YOLO, introduced by Joseph Redmon in 2015 with YOLO v1, has evolved to YOLOv8, improving both speed and applications. Unlike earlier methods, YOLO processes images by resizing them, running a single convolutional network, and setting thresholds for accuracy. By marking boundary coordinates and categories, it enables multi-object detection and improves real-time performance through neural network-based regression testing [<xref rid="B31-sensors-25-01196" ref-type="bibr">31</xref>].</p><p>In YOLO, the input image is divided into cells, each responsible for detecting objects. Each cell predicts a bounding box with center coordinates (x, y), width (w), height (h), and a confidence score. The confidence score indicates the likelihood of an object being present in the cell and defines how confidence is calculated in YOLO&#x02019;s end-to-end training which can be expressed as system <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>O</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>&#x02217;</mml:mo><mml:msubsup><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mo>&#x000a0;</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Binary values (0 and 1) can be used to determine the presence of an object in the cell, and the <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. The value mentioned in <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>O</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>&#x02217;</mml:mo><mml:msubsup><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mo>&#x000a0;</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> represents the intersection of the detected object area in the image and the actual object area. This value is divided by the union of these two areas, as expressed in Equation (4). The model accuracy can be assessed based on the degree of overlap between the predicted object area and the actual object area. This assessment is particularly crucial when multiple objects are present in the image. Generally, a higher IOU value indicates a more accurate model prediction. A threshold is typically established, and lowering the IOU threshold during testing can result in a gap in accuracy. Usually, the IOU is set to be greater than 0.5.<disp-formula id="FD4-sensors-25-01196"><label>(4)</label><mml:math id="mm19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mo>&#x000a0;</mml:mo><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In <xref rid="sensors-25-01196-f005" ref-type="fig">Figure 5</xref>, the molecular part illustrates the intersection between the object area detected by the two graphics and the actual object area, with the slashed portion representing this intersection. The denominator part depicts the detected and actual object areas, while the slashed part represents their union. <xref rid="sensors-25-01196-f005" ref-type="fig">Figure 5</xref> is a schematic diagram of the IOU.</p><p>In the YOLO algorithm, accuracy is a crucial parameter, defined as the proportion of correctly detected results. It includes the ratio of correct predictions to prediction errors. This can be assessed using a confusion matrix, which categorizes results into four types: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN), as shown in <xref rid="sensors-25-01196-t001" ref-type="table">Table 1</xref>.</p><p>For instance, in the WVD transformation image context, TP indicates correct identification of a normal brushless motor state, while TN reflects the correct identification of a fault. FP occurs when a normal state is misidentified as a fault, and FN is when a faulty image is incorrectly classified as normal. The system accuracy can be calculated using the Equation for Precision in Equation (5) which relates TP and FP to the total number of correctly identified samples<disp-formula id="FD5-sensors-25-01196"><label>(5)</label><mml:math id="mm20" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>There is also a very important numerical recall rate in the YOLO algorithm. The recall rate refers to how many numbers in the TP are correctly predicted in the original sample. I In the recall rate, it will be observed that the correct number of false negatives (FN) identifying misidentifications can be used to test the system&#x02019;s sensitivity. When the recall rate is low, it means that samples that should have been identified will be missed during prediction, so the system recall rate is expected to reach 100%, that is, the larger the recall rate value, the better, which means that the model can avoid omissions when predicting, and the recall rate Equation is as shown in Equation (6).<disp-formula id="FD6-sensors-25-01196"><label>(6)</label><mml:math id="mm21" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Mean average precision (mAP) is the average accuracy in multiple types of problems. Average precision (AP) is the average accuracy of different categories. mAP is an indicator commonly used to measure performance in machine learning models and can evaluate the model as shown in Equation (7). Whether it is effective, when identifying the brushless motor WVD type figures, mAP is also used as an indicator, and the accuracy of all categories can be obtained to determine whether various brushless motor WVD type figures can be effectively identified. To facilitate species identification, the following equation is used:<disp-formula id="FD7-sensors-25-01196"><label>(7)</label><mml:math id="mm22" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:msubsup><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Among them, <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> means that there are k types of AP in the commonly recognized figures, and n = is the number of types.</p><p>YOLO (You Only Look Once) has diverse applications, functioning as both a figure recognition and a real-time image recognition system. It represents an innovative approach in image recognition, significantly enhancing detection speed. In contrast to previous methods like R-CNN (Regions with Convolutional Neural Networks), which are time-consuming and computationally intensive, YOLO streamlines the process.</p><p>YOLO operates by grid-dividing the image beforehand to facilitate boundary selection for identifying multiple objects within a single figure. The model then trains the image through segmentation and prediction using a deep convolutional neural network with forward propagation. The YOLO system has evolved through several versions. YOLOv1, the original version, markedly improved detection speed but still had accuracy issues. YOLOv2, released in 2017, introduced batch normalization to mitigate the gradient disappearance, enhance training speed, and incorporate multi-scale training. YOLOv3 followed in 2018, featuring Darknet-53 with 53 convolutional layers and a Residual network to manage gradient issues, improving small object prediction. In 2020, YOLOv4 was launched, focusing on further speed and accuracy improvements over YOLOv3. The same year, YOLOv5 was introduced, leveraging the PyTorch framework for easier sample training while enhancing computational efficiency. YOLOv6, released in 2021, doubled the speed of its predecessor while maintaining accuracy. YOLOv7, announced in 2022, upgraded its backbone network and added advanced feature extraction techniques. Finally, YOLOv8, unveiled in 2023, combines the strengths of YOLOv7, incorporating new anchor-free detection and closed mosaic enhancement for versatile sample training. YOLOv8 was launched in 2023. It combines the features of the previous generation with sculptural improvements. The Anchor-Free design can predict the boundaries or key points of the object. It can perform the position and shape of the object through the central body or rectangle of the object. The Anchor-Free design can reduce design overhead and reduce the number of calculations, improve ability to learn, and avoid excessive problems.</p></sec></sec><sec sec-type="discussion" id="sec4-sensors-25-01196"><title>4. Discussion</title><sec id="sec4dot1-sensors-25-01196"><title>4.1. System Structure</title><p>This study used brushless motor vibration signals with different types of faults to identify fault types. The data acquisition equipment includes an accelerometer, a data acquisition card NI-6024E (National Instruments, Austin, TX, USA), and a data acquisition module NI-9233 (National Instruments, Austin, TX, USA). The accelerometer is installed on the brushless motor with an accelerometer and data acquisition system to record vibration signals. The brushless motor vibration signal is acquired through LabVIEW (National Instruments, Austin, TX, USA), the sampling frequency is set to 1000 Hz, the sampling time is 3 s, with 3000 points, and the number of samples for each fault type is 50 pieces of data, with a total of six settings projected, and a total of 300 data. During the training process, the 300 data were split into 240 data as training data and 60 data as verification data for model training.</p><p>A fault test was conducted on the brushless motor equipment. Because the brushless motor has a wide range of applications and the stability of its surrounding systems are also taken into consideration, six related fault items were set, namely loose screws on the brushless motor bracket. The brushless motor bracket screws are loose, the brushless motor bearings are worn, the brushless motor body fixing screws, the brushless motor shaft center is worn, and the brushless motor is in a normal state. The fault categories and sample numbers are in <xref rid="sensors-25-01196-t002" ref-type="table">Table 2</xref>.</p><p>Basic brushless DC motor control, compared with traditional brushed motors, requires driver control to realize its effect. By receiving signals from the controller to confirm the rotor position, feasible control signals can be sent to adjust the DC motor. Brushless motors can achieve electrical commutation using power components to replace the traditional brushed motor carbon fibers. Brushless motors are relatively simple to maintain and have a long life.</p><p>The brushless motor used in this paper is X4120II KV400 brushless motor (Yuan-hang Technology, China), which is often used in drones. For the brushless motor characteristics discussion, this motor is used as the experimental framework because brushless motors are very important in life. Brushless motors are used in everything from daily home appliances to mobile vehicles. The difference between brushless motors and traditional brushed motors is that they can switch the current direction through electronic commutation. Compared with traditional brushed motors, they have the advantage of high efficiency and can provide the same power. In terms of size, it can be made smaller, which is an advantage for use in unmanned vehicles. This paper next discusses brushless motor maintenance compared to traditional brushed motors. Because of component wear such as carbon brushes, brushless motors can have simpler maintenance. In the past, control accuracy was a disadvantage in brushless motors, but with the current technological progress and improvement in controllers, the control circuit can be more precise and use higher frequencies for control, giving brushless motors more accurate control. This paper decided to study and explore the faults and states of brushless motors, trying to find a way to easily identify the brushless motor fault states and predict faults in advance to protect equipment and user safety. In the experimental process the brushless motor vibration signals were plotted using the Wigner analysis method.</p><p>The brushless motor model used in this paper is X4120II KV400, where KV400 means that each volt can produce a speed of 400 RPM. In this paper, 2000 RPM is used for experimental sampling. The motor stator outer diameter is 41 mm, the number of stator slots is 24N, the number of rotor poles is 22P, the rotor diameter is 46.2 mm, and the length of the brushless motor is 31.5 m. Detailed specifications are shown in <xref rid="sensors-25-01196-t003" ref-type="table">Table 3</xref>.</p><p>The equipment used in the experiment is built on the Windows 11 environment, and the training process uses the CPU and GPU respectively, as mentioned in <xref rid="sensors-25-01196-t004" ref-type="table">Table 4</xref>. Deep learning operating environment and equipment specifications. The brushless motor Wigner characteristic diagram is drawn using MATLAB 2023 (MathWorks, Natick, MA, USA), which can present the characteristics of various types of brushless motor fault diagrams in the form of figures.</p></sec><sec id="sec4dot2-sensors-25-01196"><title>4.2. Experimental Works and Data Measurement</title><p>This study used the WVD to study brushless motor vibration signal fault diagnosis and extends the WVD sampling point study to find the Wagner analysis applicable parameters for the brushless motor vibration signals, among which the number of WVD sampling points were studied individually. The sampling points are N = 2, 5, 10, 15, 20, 25, 30, showing the brushless motor vibration signal diagram in each parameter and the experimental process. First of all, this research simulated brushless motor states and built an experimental platform for signal analysis. As shown in the brushless motor experimental architecture diagram in <xref rid="sensors-25-01196-f006" ref-type="fig">Figure 6</xref>. the motor experimental combination was constructed into the experimental platform. The platform flatness was confirmed. The brushless motor body is fixed onto the brushless motor bracket. The brushless motor bracket was set up on the experimental platform. The brushless motor stability with the connected platform and the relationship between the brushless motor and connected platform was studied in this experiment. When used in equipment, the fault state is detected and the WVD is used to monitor the various brushless motor states and identify the most suitable experimental parameters for the brushless motor. </p><p>Brushless DC Motor Fault Diagnosis Flowchart. It is first decided to use a brushless DC motor to simulate the fault state in the experiment, and then the vibration accelerometer is installed. After trying each position, the vibration is accelerated. The gauge is installed in the appropriate position, and the data collection is completed through the data acquisition system (NI-6024E) and data acquisition card (NI-9233). Through MATLAB 2023 (MathWorks, Natick, MA, USA) the brushless motor vibration signal is collected using WVD and the analysis method was used to draw the figure, and the WVD parameters were adjusted. We tried to find the parameters suitable for use on the brushless motor and successfully used YOLO v8 to draw the brushless motor WVD chart. In the past, brushless motor fault diagnosis and their platforms required disassembly to clearly determine which side had a fault. In this study the brushless motor and the surrounding structure fault vibration signals are collected. This allows for a faster and more convenient way to diagnose faults in electric vehicles. <xref rid="sensors-25-01196-f007" ref-type="fig">Figure 7</xref> is the time-frequency diagram and Fourier transform image of the brushless motor in a normal state. It can be seen that the signal is a low-frequency signal, and the extraction length is 3 s. After Fourier transform, obvious features can be seen. The research process of this study is as shown in <xref rid="sensors-25-01196-f008" ref-type="fig">Figure 8</xref>. Brushless DC Motor Fault Diagnosis Flowchart.</p><p>Brushless motor Wagner figure with N (Scaling factor) 2~30. The changes in the brushless motor vibration signal after WVD analysis can be observed in <xref rid="sensors-25-01196-f009" ref-type="fig">Figure 9</xref>. When the brushless motor is in a normal state, the frequency distribution is relatively regular. Under fault conditions, respective abnormal characteristics will appear, which are key indicators for identifying the fault condition of the brushless motor. When N (the scaling factor) gradually increases, more cross-interference can be observed in the image. The impact of N (the scaling factor) on image recognition performance is explained in <xref rid="sensors-25-01196-t005" ref-type="table">Table 5</xref> and <xref rid="sensors-25-01196-t006" ref-type="table">Table 6</xref>.</p></sec><sec id="sec4dot3-sensors-25-01196"><title>4.3. Object Detection Based on Wigner&#x02013;Ville Distribution Motor Vibration Signal Fault Diagnosis Analysis</title><p>In this experiment, the vibration signal was analyzed for various brushless motor states. In this experiment the first parameter changed is the parameter N for the number of sampling points in the WVD analysis method. N is the scaling factor that affects the time scale. The WVD analysis method was successfully used to identify the brushless motor status and determine the parameter N used for the number of sampling points as the experimental change parameter. It can be seen that when the number of sampling points changes, the brushless motor WVD analysis diagram will change significantly. However, what needs to be confirmed in the experiment is what parameters are the most suitable parameters for analyzing the brushless motor vibration signals. This was verified in this experiment. In the YOLOv8 picture training the appropriate number of iterations is shown. In addition to adjusting the number of sampling points N in the WVD analysis method, various iterations are also applied when training the models. The goal is to find a smaller number of layers that still achieve a high mAP while confirming the WVD parameters. The experimental results are shown in <xref rid="sensors-25-01196-t005" ref-type="table">Table 5</xref>. The calculation was carried out from iteration number 1 to 50 according to 1, 10, 20, 30, 40, 50. The results will be calculated and the data recorded in <xref rid="sensors-25-01196-t005" ref-type="table">Table 5</xref>. It can be seen that when the parameter N = 2, the operation result is the best, and according to the operation result from the N = 2 part of the statistical results, the best result is presented in <xref rid="sensors-25-01196-t006" ref-type="table">Table 6</xref> when the number of iterations is 40.</p><p>The brushless motor vibration signals were successfully imaged using WVD. During the image formation process, the changes in the key parameter N (Scaling factor) in the WVD were discussed, mainly focusing on the feature extraction points.</p><p>The model can be used to accurately predict brushless motor faults based on WVD. <xref rid="sensors-25-01196-f010" ref-type="fig">Figure 10</xref>a shows the confusion matrix for brushless motor fault detection. The confusion matrix provides a clear view of the model&#x02019;s prediction accuracy, indicating whether false positives or false negatives are present and displaying the proportion of these errors. The prediction accuracy for the brushless motor failure in the training model shows that the status of each type of brushless motor has been correctly judged and analyzed. In <xref rid="sensors-25-01196-f010" ref-type="fig">Figure 10</xref>b,c when the Scaling factor N = 2 and the number of iterations is set to 40, the F1-confidence curve and the recall-confidence curve demonstrate strong performance. The reason for using a scaling factor of N = 2 and 40 iterations is that, based on previous experimental data, this ratio and number of iterations yield the best results. Therefore, the F1 curve of the training results using this ratio shows that the model performs fault identification with high confidence.</p><p>When comparing research methods, this study also used the Pseudo Wigner&#x02013;Ville Distribution (PWV) for feature extraction. Both perform quite well in terms of recognition results such as recognition rate. In the future, WVD and PWV can be applied to brushless faults application, because their effectiveness, reliability and practicability in fault diagnosis systems have been proven in this study. As shown in <xref rid="sensors-25-01196-t007" ref-type="table">Table 7</xref>, when the PWV parameters are adjusted to 2 and the number of iterations is 50, the training data results for each brushless motor state were obtained.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-01196"><title>5. Conclusions</title><p>This research identified new brushless motor analysis methods and used them as the experimental basis for higher frequencies currently used in the field of electric vehicles. Brushless motors are suitable for many fields, such as drones, electric vehicles, electric motorcycles, etc. This paper attempted to find a method that can identify brushless motor fault signals and, through graphical methods, present the motor vibration signal. After experimentation, this study chose the WVD to extract brushless motor vibration signal features. During these experiments, it was proven that the WVD is useful. For the brushless motor vibration signals, with good signal analysis, this research successfully used the brushless motor vibration signals to clearly determine the brushless motor fault characteristics using the WVD. The vibration fault signal can be effectively seen from the picture.</p><p>Neural-like methods have been used to identify images in the past. In recent years, with the booming development of artificial intelligence, YOLOv8 was chosen to classify brushless motor WVD images quickly and efficiently. Through image gallery training and testing, this research successfully completed brushless motor WVD vibration signal fault figure classification. This research further studied the WVD analysis method interval parameters and obtained the vibration signal suitable for use in brushless motors. The optimal interval parameter was identified using the mAP50-95 data affected by each parameter change. When the interval parameter exceeds 20, mAP50-95 will gradually decrease. Therefore, it is recommended that the brushless motor fault state be identified using the WVD interval parameter set to less than 20, so that it is easier to obtain significant identification effects. This study used WVD and YOLO to classify vibration signals for motor fault diagnosis. These algorithms can successfully and accurately determine what kind of fault state the brushless motor will be in. In the future, the proposed method will provide effective electric mobile vehicle fault diagnosis.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Investigation, W.-J.L.; Supervision, J.-D.W. and K.-C.Y. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The original contributions presented in this study are included in the article. Further inquiries can be directed to the corresponding author(s).</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01196"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lohmann</surname><given-names>A.W.</given-names></name>
</person-group><article-title>Image rotation, Wigner rotation, and the fractional Fourier transform</article-title><source>J. Opt. Soc. Am. A</source><year>1993</year><volume>10</volume><fpage>2181</fpage><lpage>2186</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.10.002181</pub-id></element-citation></ref><ref id="B2-sensors-25-01196"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Meng</surname><given-names>Q.</given-names></name>
<name><surname>Qu</surname><given-names>L.</given-names></name>
</person-group><article-title>Rotating machinery fault diagnosis using Wigner distribution</article-title><source>Mech. Syst. Signal Process.</source><year>1991</year><volume>5</volume><fpage>155</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/0888-3270(91)90040-C</pub-id></element-citation></ref><ref id="B3-sensors-25-01196"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Weinbub</surname><given-names>J.</given-names></name>
<name><surname>Ferry</surname><given-names>D.K.</given-names></name>
</person-group><article-title>Recent advances in Wigner function approaches</article-title><source>Appl. Phys. Rev.</source><year>2018</year><volume>5</volume><fpage>041104</fpage><pub-id pub-id-type="doi">10.1063/1.5046663</pub-id></element-citation></ref><ref id="B4-sensors-25-01196"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Geng</surname><given-names>Z.</given-names></name>
<name><surname>Chen</surname><given-names>J.</given-names></name>
<name><surname>Barry</surname><given-names>J.H.</given-names></name>
</person-group><article-title>Analysis of engine vibration and design of an applicable diagnosing approach</article-title><source>Int. J. Mech. Sci.</source><year>2003</year><volume>45</volume><fpage>1391</fpage><lpage>1410</lpage><pub-id pub-id-type="doi">10.1016/j.ijmecsci.2003.09.012</pub-id></element-citation></ref><ref id="B5-sensors-25-01196"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>Z.</given-names></name>
</person-group><article-title>The Optimal Linear Canonical Wigner Distribution of Noisy Linear Frequency-Modulated Signals</article-title><source>IEEE Signal Process. Lett.</source><year>2019</year><volume>26</volume><fpage>1127</fpage><lpage>1131</lpage><pub-id pub-id-type="doi">10.1109/LSP.2019.2922510</pub-id></element-citation></ref><ref id="B6-sensors-25-01196"><label>6.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Brajovi&#x00107;</surname><given-names>M.</given-names></name>
<name><surname>Popovi&#x00107;-Bugarin</surname><given-names>V.</given-names></name>
</person-group><article-title>Instantaneous frequency estimation using Ant colony optimization and Wigner distribution</article-title><source>Proceedings of the 4th Mediterranean Conference on Embedded Computing (MECO)</source><conf-loc>Budva, Montenegro</conf-loc><conf-date>14&#x02013;18 June 2015</conf-date><pub-id pub-id-type="doi">10.1109/MECO.2015.7181941</pub-id></element-citation></ref><ref id="B7-sensors-25-01196"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Stankovic</surname><given-names>L.</given-names></name>
<name><surname>Katkovnik</surname><given-names>V.</given-names></name>
</person-group><article-title>The Wigner distribution of noisy signals with adaptive time-frequency varying window</article-title><source>IEEE Trans. Signal Process.</source><year>1999</year><volume>47</volume><fpage>1099</fpage><lpage>1108</lpage><pub-id pub-id-type="doi">10.1109/78.752607</pub-id></element-citation></ref><ref id="B8-sensors-25-01196"><label>8.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Qiu</surname><given-names>L.</given-names></name>
</person-group><article-title>Wigner-Ville distribution and windowed Wigner-Ville distribution of noisy signals</article-title><source>Proceedings of the IEEE Singapore International Conference on Networks/International Conference on Information Engineering</source><conf-loc>Singapore</conf-loc><conf-date>6&#x02013;11 September 1993</conf-date><pub-id pub-id-type="doi">10.1109/SICON.1993.515792</pub-id></element-citation></ref><ref id="B9-sensors-25-01196"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lee</surname><given-names>S.K.</given-names></name>
</person-group><article-title>Application of the L-Wigner distribution to the diagnosis of local defects of gear tooth</article-title><source>KSME Int. J.</source><year>1999</year><volume>13</volume><fpage>144</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1007/BF02943666</pub-id></element-citation></ref><ref id="B10-sensors-25-01196"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dragoman</surname><given-names>D.</given-names></name>
</person-group><article-title>Applications of the Wigner Distribution Function in Signal Processing</article-title><source>EURASIP J. Adv. Signal Process</source><year>2005</year><volume>10</volume><fpage>1520</fpage><lpage>1534</lpage><pub-id pub-id-type="doi">10.1155/ASP.2005.1520</pub-id></element-citation></ref><ref id="B11-sensors-25-01196"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>J.Y.</given-names></name>
<name><surname>Li</surname><given-names>B.Z.</given-names></name>
</person-group><article-title>The short-time Wigner&#x02013;Ville distribution</article-title><source>Signal Process.</source><year>2024</year><volume>219</volume><fpage>109402</fpage><pub-id pub-id-type="doi">10.1016/j.sigpro.2024.109402</pub-id></element-citation></ref><ref id="B12-sensors-25-01196"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>X.</given-names></name>
<name><surname>Shi</surname><given-names>J.</given-names></name>
<name><surname>Yu</surname><given-names>X.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
</person-group><article-title>Local motion blur detection by Wigner distribution function</article-title><source>Optik</source><year>2022</year><volume>251</volume><fpage>168375</fpage><pub-id pub-id-type="doi">10.1016/j.ijleo.2021.168375</pub-id></element-citation></ref><ref id="B13-sensors-25-01196"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wu</surname><given-names>J.D.</given-names></name>
<name><surname>Huang</surname><given-names>C.K.</given-names></name>
</person-group><article-title>An engine fault diagnosis system using intake manifold pressure signal and Wigner&#x02013;Ville distribution technique</article-title><source>Expert Syst. Appl.</source><year>2011</year><volume>38</volume><fpage>536</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2010.06.099</pub-id></element-citation></ref><ref id="B14-sensors-25-01196"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>H.B.</given-names></name>
<name><surname>Li</surname><given-names>R.X.</given-names></name>
<name><surname>Huang</surname><given-names>X.R.</given-names></name>
<name><surname>Yang</surname><given-names>M.L.</given-names></name>
<name><surname>Ding</surname><given-names>W.P.</given-names></name>
</person-group><article-title>Sound quality evaluation of vehicle suspension shock absorber rattling noise based on the Wigner&#x02013;Ville distribution</article-title><source>Appl. Acoust.</source><year>2015</year><volume>100</volume><fpage>18</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.apacoust.2015.06.018</pub-id></element-citation></ref><ref id="B15-sensors-25-01196"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Tang</surname><given-names>B.</given-names></name>
<name><surname>Liu</surname><given-names>W.</given-names></name>
<name><surname>Song</surname><given-names>T.</given-names></name>
</person-group><article-title>Wind turbine fault diagnosis based on Morlet wavelet transformation and Wigner-Ville distribution</article-title><source>Renew. Energy</source><year>2010</year><volume>35</volume><fpage>2862</fpage><lpage>2866</lpage><pub-id pub-id-type="doi">10.1016/j.renene.2010.05.012</pub-id></element-citation></ref><ref id="B16-sensors-25-01196"><label>16.</label><element-citation publication-type="other"><person-group person-group-type="author">
<name><surname>Tao</surname><given-names>X.</given-names></name>
<name><surname>Ren</surname><given-names>C.</given-names></name>
<name><surname>Wu</surname><given-names>Y.</given-names></name>
<name><surname>Li</surname><given-names>Q.</given-names></name>
<name><surname>Guo</surname><given-names>W.</given-names></name>
<name><surname>Liu</surname><given-names>R.</given-names></name>
<name><surname>He</surname><given-names>Q.</given-names></name>
<name><surname>Zou</surname><given-names>J.</given-names></name>
</person-group><article-title>Bearings fault detection using wavelet transform and generalized Gaussian density modeling, Measurement 2020, 155, 107557</article-title><source>155</source><pub-id pub-id-type="doi">10.1016/j.measurement.2020.107557</pub-id></element-citation></ref><ref id="B17-sensors-25-01196"><label>17.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Dhandapani</surname><given-names>R.</given-names></name>
<name><surname>Mitiche</surname><given-names>I.</given-names></name>
<name><surname>McMeekin</surname><given-names>S.</given-names></name>
<name><surname>Morison</surname><given-names>G.</given-names></name>
</person-group><article-title>Bearing Faults Diagnosis and Classification Using Generalized Gaussian Distribution Multiscale Dispersion Entropy Features</article-title><source>Proceedings of the 30th European Signal Processing Conference (EUSIPCO)</source><conf-loc>Belgrade, Serbia</conf-loc><conf-date>29 August&#x02013;2 September 2022</conf-date><fpage>1452</fpage><lpage>1456</lpage><pub-id pub-id-type="doi">10.23919/EUSIPCO55093.2022.9909560</pub-id></element-citation></ref><ref id="B18-sensors-25-01196"><label>18.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Lee</surname><given-names>K.B.</given-names></name>
<name><surname>Shin</surname><given-names>H.S.</given-names></name>
</person-group><article-title>An Application of a Deep Learning Algorithm for Automatic Detection of Unexpected Accidents Under Bad CCTV Monitoring Conditions in Tunnels</article-title><source>Proceedings of the International Conference on Deep Learning and Machine Learning in Emerging Applications</source><conf-loc>Istanbul, Turkey</conf-loc><conf-date>26&#x02013;28 August 2019</conf-date><pub-id pub-id-type="doi">10.1109/Deep-ML.2019.00010</pub-id></element-citation></ref><ref id="B19-sensors-25-01196"><label>19.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>J.</given-names></name>
</person-group><article-title>Survey of the Image Recognition Based on Deep Learning Network for Autonomous Driving Car</article-title><source>Proceedings of the International Conference on Information Science, Computer Technology and Transportation (ISCTT)</source><conf-loc>Shenyang, China</conf-loc><conf-date>13&#x02013;15 November 2020</conf-date><pub-id pub-id-type="doi">10.1109/ISCTT51595.2020.00007</pub-id></element-citation></ref><ref id="B20-sensors-25-01196"><label>20.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Widjojo</surname><given-names>D.</given-names></name>
<name><surname>Setyati</surname><given-names>E.</given-names></name>
<name><surname>Kristian</surname><given-names>Y.</given-names></name>
</person-group><article-title>Integrated Deep Learning System for Car Damage Detection and Classification Using Deep Transfer Learning</article-title><source>Proceedings of the IEEE Information Technology International Seminar (ITIS)</source><conf-loc>Surabaya, Indonesia</conf-loc><conf-date>19&#x02013;21 October 2022</conf-date><pub-id pub-id-type="doi">10.1109/ITIS57155.2022.10010292</pub-id></element-citation></ref><ref id="B21-sensors-25-01196"><label>21.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Rao</surname><given-names>A.S.</given-names></name>
<name><surname>Sapna</surname><given-names>S.</given-names></name>
<name><surname>Akshay</surname><given-names>T.</given-names></name>
<name><surname>Shenoy</surname><given-names>A.S.</given-names></name>
<name><surname>Adithya</surname><given-names>B.V.</given-names></name>
<name><surname>Dias</surname><given-names>A.</given-names></name>
</person-group><article-title>Identification of Car Make and Model Using Deep Learning and Computer Vision Techniques</article-title><source>Proceedings of the International Conference on Artificial Intelligence and Data Engineering (AIDE)</source><conf-loc>Karkala, India</conf-loc><conf-date>22&#x02013;23 December 2022</conf-date><pub-id pub-id-type="doi">10.1109/AIDE57180.2022.10060631</pub-id></element-citation></ref><ref id="B22-sensors-25-01196"><label>22.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kulkarni</surname><given-names>R.</given-names></name>
<name><surname>Dhavalikar</surname><given-names>S.</given-names></name>
<name><surname>Bangar</surname><given-names>S.</given-names></name>
</person-group><article-title>Traffic Light Detection and Recognition for Self Driving Cars Using Deep Learning</article-title><source>Proceedings of the Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)</source><conf-loc>Pune, India</conf-loc><conf-date>16&#x02013;18 August 2018</conf-date><pub-id pub-id-type="doi">10.1109/ICCUBEA.2018.8697819</pub-id></element-citation></ref><ref id="B23-sensors-25-01196"><label>23.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Silva</surname><given-names>J.D.</given-names></name>
<name><surname>Flores</surname><given-names>T.</given-names></name>
<name><surname>J&#x000fa;nior</surname><given-names>S.</given-names></name>
<name><surname>Silva</surname><given-names>I.</given-names></name>
</person-group><article-title>TinyML-Based Pothole Detection: A Comparative Analysis of YOLO and FOMO Model Performance</article-title><source>Proceedings of the IEEE Latin American Conference on Computational Intelligence (LA-CCI)</source><conf-loc>Recife, Brazil</conf-loc><conf-date>29 October&#x02013;1 November 2023</conf-date><pub-id pub-id-type="doi">10.1109/LA-CCI58595.2023.10409357</pub-id></element-citation></ref><ref id="B24-sensors-25-01196"><label>24.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kurniadi</surname><given-names>F.A.</given-names></name>
<name><surname>Setianingsih</surname><given-names>C.</given-names></name>
<name><surname>Syaputra</surname><given-names>R.E.</given-names></name>
</person-group><article-title>Innovation in Livestock Surveillance: Applying the YOLO Algorithm to UAV Imagery and Videography</article-title><source>Proceedings of the IEEE 9th International Conference on Smart Instrumentation, Measurement and Applications (ICSIMA)</source><conf-loc>Kuala Lumpur, Malaysia</conf-loc><conf-date>17&#x02013;18 October 2023</conf-date><pub-id pub-id-type="doi">10.1109/ICSIMA59853.2023.10373473</pub-id></element-citation></ref><ref id="B25-sensors-25-01196"><label>25.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Baby Chithra</surname><given-names>R.</given-names></name>
<name><surname>Salna</surname><given-names>J.</given-names></name>
<name><surname>Ujwal</surname><given-names>A.R.</given-names></name>
<name><surname>Rishab</surname><given-names>C.L.</given-names></name>
<name><surname>Vinay</surname><given-names>R.</given-names></name>
<name><surname>Arun Dev</surname><given-names>M.</given-names></name>
</person-group><article-title>Traffic Rule Violation Recognition for Two Wheeler using YOLO Algorithm</article-title><source>Proceedings of the Second International Conference on Electronics and Renewable Systems (ICEARS)</source><conf-loc>Tuticorin, India</conf-loc><conf-date>2&#x02013;4 March 2023</conf-date><pub-id pub-id-type="doi">10.1109/ICEARS56392.2023.10085537</pub-id></element-citation></ref><ref id="B26-sensors-25-01196"><label>26.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Sun</surname><given-names>Z.</given-names></name>
</person-group><article-title>Research on the Application of Convolutional Neural Network Based on the YOLO Algorithm in Airport Intelligent Monitoring</article-title><source>Proceedings of the Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)</source><conf-loc>Shenyang, China</conf-loc><conf-date>25&#x02013;27 February 2023</conf-date><pub-id pub-id-type="doi">10.1109/ACCTCS58815.2023.00071</pub-id></element-citation></ref><ref id="B27-sensors-25-01196"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>L.</given-names></name>
<name><surname>Sun</surname><given-names>W.</given-names></name>
<name><surname>Yue</surname><given-names>C.</given-names></name>
<name><surname>Zhu</surname><given-names>Y.</given-names></name>
<name><surname>Xia</surname><given-names>W.</given-names></name>
</person-group><article-title>Remaining Useful Life Estimation of Lithium-Ion Batteries Based on Small Sample Models</article-title><source>Energies</source><year>2024</year><volume>17</volume><elocation-id>4932</elocation-id><pub-id pub-id-type="doi">10.3390/en17194932</pub-id></element-citation></ref><ref id="B28-sensors-25-01196"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>C.</given-names></name>
<name><surname>Wang</surname><given-names>S.</given-names></name>
<name><surname>Yu</surname><given-names>C.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Fernandez</surname><given-names>C.A.</given-names></name>
</person-group><article-title>Complete Ensemble Empirical Mode Decomposition with Adaptive Noise Deep Autoregressive Recurrent Neural Network Method for the Whole Life Remaining Useful Life Prediction of Lithium-Ion Batteries</article-title><source>Ionics</source><year>2023</year><volume>29</volume><fpage>4337</fpage><lpage>4349</lpage><pub-id pub-id-type="doi">10.1007/s11581-023-05152-2</pub-id></element-citation></ref><ref id="B29-sensors-25-01196"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hinton</surname><given-names>G.E.</given-names></name>
<name><surname>Osindero</surname><given-names>S.</given-names></name>
<name><surname>The</surname><given-names>Y.W.</given-names></name>
</person-group><article-title>A Fast Learning Algorithm for deep belief nets</article-title><source>Neural Comput.</source><year>2006</year><volume>18</volume><fpage>1527</fpage><lpage>1554</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1527</pub-id><pub-id pub-id-type="pmid">16764513</pub-id>
</element-citation></ref><ref id="B30-sensors-25-01196"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Rosenblatt</surname><given-names>F.</given-names></name>
</person-group><article-title>The perceptron: A probabilistic model for information storage and organization in the brain</article-title><source>Psychol. Rev.</source><year>1958</year><volume>65</volume><fpage>386</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1037/h0042519</pub-id><pub-id pub-id-type="pmid">13602029</pub-id>
</element-citation></ref><ref id="B31-sensors-25-01196"><label>31.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Redmon</surname><given-names>J.</given-names></name>
<name><surname>Divvala</surname><given-names>S.</given-names></name>
<name><surname>Girshick</surname><given-names>R.</given-names></name>
<name><surname>Farhadi</surname><given-names>A.</given-names></name>
</person-group><article-title>You Only Look Once: Unified, Real-Time Object Detection</article-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>27&#x02013;30 June 2016</conf-date><pub-id pub-id-type="doi">10.1109/CVPR.2016.91</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01196-f001"><label>Figure 1</label><caption><p>Sine wave WVD 2D time-frequency energy diagram. The bluer areas indicate lower vibration energy, while the green areas represent moderate vibration energy, and the yellow regions correspond to higher vibration energy.</p></caption><graphic xlink:href="sensors-25-01196-g001" position="float"/></fig><fig position="float" id="sensors-25-01196-f002"><label>Figure 2</label><caption><p>Brushless motor normal state vibration signal WVD 2D time-frequency energy diagram. The bluer areas indicate lower vibration energy, while the green areas represent moderate vibration energy, and the yellow regions correspond to higher vibration energy.</p></caption><graphic xlink:href="sensors-25-01196-g002" position="float"/></fig><fig position="float" id="sensors-25-01196-f003"><label>Figure 3</label><caption><p>The evolution of deep learning.</p></caption><graphic xlink:href="sensors-25-01196-g003" position="float"/></fig><fig position="float" id="sensors-25-01196-f004"><label>Figure 4</label><caption><p>CNN architecture.</p></caption><graphic xlink:href="sensors-25-01196-g004" position="float"/></fig><fig position="float" id="sensors-25-01196-f005"><label>Figure 5</label><caption><p>IOU diagram.</p></caption><graphic xlink:href="sensors-25-01196-g005" position="float"/></fig><fig position="float" id="sensors-25-01196-f006"><label>Figure 6</label><caption><p>Brushless motor experimental architecture diagram. (<bold>a</bold>) Normal brushless motor status diagram; (<bold>b</bold>) Motor fixed screw loose, the fixing screws of the motor body are loose; (<bold>c</bold>) Motor bracket screw loose is the brushless motor bracket&#x02019;s fault; (<bold>d</bold>) Motor bottom screw loose is the motor bracket base screw loose; (<bold>e</bold>) Motor shaft wear means the middle shaft of the motor is damaged; (<bold>f</bold>) Motor bearing not fixed means the motor bearing is damaged.</p></caption><graphic xlink:href="sensors-25-01196-g006" position="float"/></fig><fig position="float" id="sensors-25-01196-f007"><label>Figure 7</label><caption><p>Time-frequency diagram and Fourier transform image of the brushless motor in normal state.</p></caption><graphic xlink:href="sensors-25-01196-g007" position="float"/></fig><fig position="float" id="sensors-25-01196-f008"><label>Figure 8</label><caption><p>Brushless DC Motor Fault Diagnosis Flowchart.</p></caption><graphic xlink:href="sensors-25-01196-g008" position="float"/></fig><fig position="float" id="sensors-25-01196-f009"><label>Figure 9</label><caption><p>Brushless motor WVD figure with sampling points 2~30.</p></caption><graphic xlink:href="sensors-25-01196-g009" position="float"/></fig><fig position="float" id="sensors-25-01196-f010"><label>Figure 10</label><caption><p>When the interval parameter N = 2 and the number of iterations is equal to 40, (<bold>a</bold>) confusion matrix figure; (<bold>b</bold>) confidence curve; (<bold>c</bold>) Recall-confidence curve figure.</p></caption><graphic xlink:href="sensors-25-01196-g010a" position="float"/><graphic xlink:href="sensors-25-01196-g010b" position="float"/></fig><table-wrap position="float" id="sensors-25-01196-t001"><object-id pub-id-type="pii">sensors-25-01196-t001_Table 1</object-id><label>Table 1</label><caption><p>Confusion matrix table.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Confusion Matrix</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Actual Values</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Positive</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Negative</th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Predicted</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Positive</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">TP</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">FP</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Negative</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">FN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">TN</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01196-t002"><object-id pub-id-type="pii">sensors-25-01196-t002_Table 2</object-id><label>Table 2</label><caption><p>Brushless motor fault categories and sample number table.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Class</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Samples</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Normal</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor fixing screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bracket screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bottom screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor shaft wear</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bearing not fixed</td><td align="center" valign="middle" rowspan="1" colspan="1">50</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Total</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">300</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01196-t003"><object-id pub-id-type="pii">sensors-25-01196-t003_Table 3</object-id><label>Table 3</label><caption><p>Brushless motor specification sheet.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Brushless Motor Specification Sheet</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Specifications</td><td align="center" valign="middle" rowspan="1" colspan="1">X412011</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Stator Diameter</td><td align="center" valign="middle" rowspan="1" colspan="1">41 mm</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Stator Arms</td><td align="center" valign="middle" rowspan="1" colspan="1">24 N</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Stator Poles</td><td align="center" valign="middle" rowspan="1" colspan="1">22 P</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor KV</td><td align="center" valign="middle" rowspan="1" colspan="1">400</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Rotor Diameter</td><td align="center" valign="middle" rowspan="1" colspan="1">46.2 mm</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Motor Body Length</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">31.5 mm</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01196-t004"><object-id pub-id-type="pii">sensors-25-01196-t004_Table 4</object-id><label>Table 4</label><caption><p>Deep learning operating environment and equipment specifications.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Equipment Specifications.</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Operating System</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Windows 11</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CPU</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Intel(R) Core(TM) i7-10870H CPU</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GPU</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GeForce GTX 1650</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RAM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32.0 GB</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">MATLAB</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2023</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01196-t007"><object-id pub-id-type="pii">sensors-25-01196-t007_Table 7</object-id><label>Table 7</label><caption><p>When the PWV parameters are adjusted to 2 and the number of iterations is 50, the training data results for each brushless motor state were obtained.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Class Name</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">P (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">R (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">mAP50 (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">mAP50-95 (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">F1</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bracket screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">99.4</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.7</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bottom screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">99.4</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.7</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bearing not fixed</td><td align="center" valign="middle" rowspan="1" colspan="1">99.4</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.7</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor fixing screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">99.4</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.7</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Normal condition</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">93.7</td><td align="center" valign="middle" rowspan="1" colspan="1">99.75</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor shaft wear</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.75</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">all</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.7</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01196-t005"><object-id pub-id-type="pii">sensors-25-01196-t005_Table 5</object-id><label>Table 5</label><caption><p>mAP50-95 statistics interval points.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">N (Scaling Factor)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">mAP50-95 (%)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">85.25</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">87.28</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">84.57</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">15</td><td align="center" valign="middle" rowspan="1" colspan="1">83.05</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">75.87</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">25</td><td align="center" valign="middle" rowspan="1" colspan="1">71.87</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">66.42</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01196-t006"><object-id pub-id-type="pii">sensors-25-01196-t006_Table 6</object-id><label>Table 6</label><caption><p>When the WVD parameters are adjusted to 2 and the number of iterations is 40, the training data results for each brushless motor state were obtained.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Class Name</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">P (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">R (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">mAP50 (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">mAP50-95 (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">F1</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bracket screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">99.3</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.65</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bottom screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">99.2</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.60</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor bearing not fixed</td><td align="center" valign="middle" rowspan="1" colspan="1">99.6</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.80</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor fixing screw loose</td><td align="center" valign="middle" rowspan="1" colspan="1">99.3</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">93.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.65</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Normal condition</td><td align="center" valign="middle" rowspan="1" colspan="1">99.3</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.65</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Motor shaft wear</td><td align="center" valign="middle" rowspan="1" colspan="1">99.3</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" rowspan="1" colspan="1">99.65</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">all</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.67</td></tr></tbody></table></table-wrap></floats-group></article>