<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Imaging Inform Med</journal-id><journal-id journal-id-type="iso-abbrev">J Imaging Inform Med</journal-id><journal-title-group><journal-title>Journal of Imaging Informatics in Medicine</journal-title></journal-title-group><issn pub-type="ppub">2948-2925</issn><issn pub-type="epub">2948-2933</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39322813</article-id><article-id pub-id-type="pmc">PMC12092861</article-id>
<article-id pub-id-type="publisher-id">1274</article-id><article-id pub-id-type="doi">10.1007/s10278-024-01274-9</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Large Language Model to Detect Negated Expressions in Radiology Reports</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7966-4683</contrib-id><name><surname>Su</surname><given-names>Yvonne</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9536-7504</contrib-id><name><surname>Babore</surname><given-names>Yonatan B.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6654-7434</contrib-id><name><surname>Kahn</surname><given-names>Charles E.</given-names><suffix>Jr.</suffix></name><address><email>ckahn@upenn.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00b30xv10</institution-id><institution-id institution-id-type="GRID">grid.25879.31</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8972</institution-id><institution>Department of Radiology, </institution><institution>Perelman School of Medicine, University of Pennsylvania, </institution></institution-wrap>3400 Spruce Street, Philadelphia, 19104 PA USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00b30xv10</institution-id><institution-id institution-id-type="GRID">grid.25879.31</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8972</institution-id><institution>Institute for Biomedical Informatics, </institution><institution>University of Pennsylvania, </institution></institution-wrap>Philadelphia, PA USA </aff></contrib-group><pub-date pub-type="epub"><day>25</day><month>9</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>25</day><month>9</month><year>2024</year></pub-date><pub-date pub-type="collection"><month>6</month><year>2025</year></pub-date><volume>38</volume><issue>3</issue><fpage>1297</fpage><lpage>1303</lpage><history><date date-type="received"><day>23</day><month>5</month><year>2024</year></date><date date-type="rev-recd"><day>28</day><month>8</month><year>2024</year></date><date date-type="accepted"><day>12</day><month>9</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Natural language processing (NLP) is crucial to extract information accurately from unstructured text to provide insights for clinical decision-making, quality improvement, and medical research. This study compared the performance of a rule-based NLP system and a medical-domain transformer-based model to detect negated concepts in radiology reports. Using a corpus of 984 de-identified radiology reports from a large U.S.-based academic health system (1000 consecutive reports, excluding 16 duplicates), the investigators compared the rule-based medspaCy system and the Clinical Assertion and Negation Classification Bidirectional Encoder Representations from Transformers (CAN-BERT) system to detect negated expressions of terms from RadLex, the Unified Medical Language System Metathesaurus, and the Radiology Gamuts Ontology. Power analysis determined a sample size of 382 terms to achieve <italic>&#x003b1;</italic>&#x02009;=&#x02009;0.05 and <italic>&#x003b2;</italic>&#x02009;=&#x02009;0.8 for McNemar&#x02019;s test; based on an estimate of 15% negated terms, 2800 randomly selected terms were annotated manually as negated or not negated. Precision, recall, and F1 of the two models were compared using McNemar&#x02019;s test. Of the 2800 terms, 387 (13.8%) were negated. For negation detection, medspaCy attained a recall of 0.795, precision of 0.356, and F1 of 0.492. CAN-BERT achieved a recall of 0.785, precision of 0.768, and F1 of 0.777. Although recall was not significantly different, CAN-BERT had significantly better precision (<italic>&#x003c7;</italic>2&#x02009;=&#x02009;304.64; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). The transformer-based CAN-BERT model detected negated terms in radiology reports with high precision and recall; its precision significantly exceeded that of the rule-based medspaCy system. Use of this system will improve data extraction from textual reports to support information retrieval, AI model training, and discovery of causal relationships. </p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Large language models</kwd><kwd>Negated expression (negex) detection</kwd><kwd>Named entity recognition</kwd><kwd>Natural language processing</kwd><kwd>Radiology reports</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Society for Imaging Informatics in Medicine 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">The electronic health record (EHR) can serve as a rich source of information for clinical decision-making, quality improvement, and medical research, but much of its content is in the form of unstructured narrative (&#x0201c;free&#x0201d;) text [<xref ref-type="bibr" rid="CR1">1</xref>]. In radiology, natural language processing (NLP) has found numerous applications [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>], including detection of critical results for diagnostic surveillance [<xref ref-type="bibr" rid="CR4">4</xref>] and cohort building for epidemiological studies [<xref ref-type="bibr" rid="CR5">5</xref>]. The current study harnesses named entity recognition (NER), an NLP technique that identifies and categorizes textual information; biomedical NER tasks include extraction of symptoms, signs, diseases, and treatments [<xref ref-type="bibr" rid="CR6">6</xref>]. In radiology, NER models are designed to extract entities of interest, such as diseases and anatomical structures, from unstructured text [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. Numerous general NLP toolkits have been validated for clinical text, including cTAKES, MedTagger, and medspaCy [<xref ref-type="bibr" rid="CR9">9</xref>&#x02013;<xref ref-type="bibr" rid="CR11">11</xref>]. However, NLP pipelines leveraging domain-specific ontologies, such as RadLex, often outperform general-purpose dictionaries in mining radiology reports for named entities [<xref ref-type="bibr" rid="CR8">8</xref>]. Transformer-based models, which apply the notion of &#x0201c;attention&#x0201d; to leverage sentence context, can further improve the detection of named entities in radiology reports [<xref ref-type="bibr" rid="CR7">7</xref>].</p><p id="Par3">It is not enough to simply identify diseases, imaging findings, or anatomic features: radiology reports are rich in modifier terms that contain vital context without which report analysis would lead to incorrect or misleading conclusions. NLP researchers have been able to improve extraction of temporospatial relationships (e.g., &#x0201c;<italic>acute thalamic</italic> stroke&#x0201d;) and the negation of recognized entities (e.g., &#x0201c;<italic>no</italic> pleural effusion identified&#x0201d;) [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>]. Correct identification of negation is particularly important given the prevalence of negative findings in radiology reports [<xref ref-type="bibr" rid="CR14">14</xref>]. If models mistakenly classify negated terms as positive instances, they will generate incorrect associations among terms. &#x0201c;Negation detection&#x0201d; evaluates whether the underlying text affirms or negates the presence of an identified entity. Making the negation-detection process precise is a critical step toward a reliable interpretation of EHR data in radiology [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. Detection of negation based solely on syntax and regular expressions is difficult, as negation phrases can occur before the entity of interest, occur after it, or be may be confounded by pseudo-negation, double negatives, and other unusual negation styles [<xref ref-type="bibr" rid="CR16">16</xref>]. Rule-based algorithms, such as NegEx, NegFinder, and NegHunter, have shown F1 scores, computed as the harmonic mean of precision and recall, from 0.84 to 0.89 for negation detection in narrative clinical text such as discharge summaries [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>].</p><p id="Par4">Large language models (LLMs) have demonstrated strong performance across various NLP tasks [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. Bidirectional encoders, such as BERT, RoBERTa, NegBERT, and CheXbert, have shown significantly improved negation detection over rule-based algorithms; models trained specifically on radiology reports, such as RadBERT, showed some of the most robust negation and uncertainty detection [<xref ref-type="bibr" rid="CR21">21</xref>&#x02013;<xref ref-type="bibr" rid="CR26">26</xref>]. For example, negation detection in radiology reports achieved an F1 score of 0.932 for a rule-based approach and 0.961 for a BERT-based system [<xref ref-type="bibr" rid="CR27">27</xref>]. The current study sought to compare the performance in a real-world clinical setting of a rule-based model and a pre-trained LLM on a collection of radiology reports without use of a conventional training dataset.</p></sec><sec id="Sec2"><title>Materials and Methods</title><sec id="Sec3"><title>Data Collection</title><p id="Par5">This retrospective study was HIPAA-compliant and was approved by the investigators&#x02019; Institutional Review Board. From a convenience sample of 1000 consecutive de-identified radiology reports from a large, multi-hospital U.S. academic health system, 16 duplicate reports were excluded to yield a study cohort of 984 reports. The sample cohort included 599 female patients (60.9%); mean patient age was 56.8&#x000a0;years. There were 357 radiographic exams (36.3%), 294 CTs (29.9%), 167 MRIs (16.9%), and 100 ultrasound exams (10.1%); the remaining 66 exams (6.7%) included fluoroscopy, mammography, nuclear medicine, and interventional radiology procedures. Of the 984 reports, 277 (28.2%) were dictated by a radiology trainee and subsequently edited and approved by an attending radiologist; the others were reported by an attending radiologist only. More than 90% of reports were based on a reporting template, but all reports contained mostly narrative (&#x0201c;free&#x0201d;) text.</p><p id="Par6">The investigators applied the rule-based medspaCy model to identify names of diseases and imaging findings [<xref ref-type="bibr" rid="CR11">11</xref>]. Three medical terminology sources served as reference vocabularies: the RadLex radiology lexicon (version 4.1), Unified Medical Language System Metathesaurus (version 2022AB), and Radiology Gamuts Ontology (version 1.0) [<xref ref-type="bibr" rid="CR28">28</xref>&#x02013;<xref ref-type="bibr" rid="CR30">30</xref>]. In this study, a &#x0201c;term&#x0201d; indicates an occurrence in a radiology report of a named entity from one of the three terminology sources.</p><p id="Par7">Using the terms identified by medspaCy, we compared the performance for detection of negated terms of the medspaCy model to that of the Clinical Assertion and Negation Classification Bidirectional Encoder Representations from Transformers (CAN-BERT) model, an LLM trained on large clinical datasets from MIMIC III and the i2b2/VA challenge [<xref ref-type="bibr" rid="CR31">31</xref>]. To ensure patient data security, all text processing was completed using Python 3.7 20 on local computers without internet connections. The report text corpus was split into separate sentences for processing by the medspaCy model, which labeled terms as negated or not negated based on their position and the sentence structure. The report text also was split into sentences for the pre-trained CAN-BERT model, and special [CLS] and [SEP] tokens were added to the beginning and end of the sentences to generate hidden states for each token. CAN-BERT&#x02019;s output was passed through a simple fully connected (classification) layer to label terms as negated or not negated. A cross-entropy loss function was calculated to measure the difference between the model predictions and the actual labels with an Adam optimizer to adjust the model parameters to minimize the loss function.</p></sec><sec id="Sec4"><title>Negation Definition and Validation</title><p id="Par8">Each named entity identified within the text corpus was labeled as negated or not negated. An entity was classified as negated if the report explicitly asserted the entity was absent (for example, &#x0201c;There is no evidence of pneumothorax&#x0201d;). All other mentions of named entities, including uncertain mentions (e.g., &#x0201c;Cardiomegaly may be present&#x0201d;), queries (e.g., &#x0201c;Rule out gallstones&#x0201d;), and pseudo-negations (&#x0201c;No clear pneumothorax&#x0201d;), were categorized as not negated. Two fourth-year medical students manually annotated the reports under guidance of a board-certified radiologist with more than 30&#x000a0;years of experience. Annotations were performed independently; disagreements were resolved by consensus to establish the reference standard for comparison with annotations made by medspaCy and CAN-BERT.</p></sec><sec id="Sec5"><title>Statistical Analysis</title><p id="Par9">Power analysis indicated that 382 negated terms would provide appropriate statistical power (<italic>&#x003b1;</italic>&#x02009;=&#x02009;0.05, <italic>&#x003b2;</italic>&#x02009;=&#x02009;0.8) to conduct McNemar&#x02019;s test. Preliminary manual review of the reports yielded an estimate that 15% of terms were negated. Thus, one could expect that a sample of 2547 terms (382/15%) would yield the requisite number of negated terms; to assure an adequate sample, we chose to analyze 2800 terms. Therefore, from among all the terms that appeared in the report text corpus, 2800 terms were chosen at random and were annotated manually as negated or not negated.</p><p id="Par10">The models&#x02019; performance was evaluated against the reference standard using McNemar&#x02019;s test on R 4.0.3 (R Foundation, Vienna, Austria). Each model&#x02019;s precision, recall, and F1 scores were calculated; the optimal operating point for CAN-BERT was selected as the one that maximized the true positive ratio minus the false positive ration. Bootstrap resampling was used to assess for statistical significance: each of 10,000 bootstrapped trials sampled 2800 times with replacement from the medspaCy and CAN-BERT predictions. A receiver operating characteristic (ROC) curve was calculated for both models; the areas under the curves (AUC) were compared using DeLong&#x02019;s statistic.</p></sec></sec><sec id="Sec6"><title>Results</title><p id="Par11">A total of 30,210&#x000a0;terms were identified in the text corpus. Among the sample of 2800 terms, 387 terms (13.7%) were annotated as negated in the reference standard, which met the sample size required by the power analysis. Performance of CAN-BERT and medspaCy is shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>, which highlights examples of the four possible outcome scenarios for the two models. The negation status of 2053 entities was identified correctly by both models (73.3%, 2053/2800), and 82 were incorrectly identified by both models (2.9%, 82/2800). CAN-BERT correctly identified the negation status of the entities for a total of 2621 instances, whereas medspaCy did so with slightly less frequency at 2150 correct identifications (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). However, medspaCy made more errors, with 650 incorrectly determined negation statuses compared to CAN-BERT&#x02019;s 179 incorrect identifications. McNemar&#x02019;s chi-squared test yielded a value of 304.64 (<italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), indicating a statistically significant difference in model performance.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Examples of negation detection. A MedspaCy correctly identifies the term of interest as negated; CAN-BERT does not. B Both medspaCy and CAN-BERT incorrectly identified the term of interest as negated. C CAN-BERT correctly identifies the term as negated; medspaCy does not. D Both medspaCy and CAN-BERT correctly identify the term as not negated</p></caption><graphic xlink:href="10278_2024_1274_Fig1_HTML" id="MO1"/></fig><table-wrap id="Tab1"><label>Table 1</label><caption><p>Comparison of performance of medspaCy and CAN-BERT to correctly detect negated entities</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="2"><bold>medspaCy</bold></th></tr><tr><th align="left"><bold>CAN-BERT</bold></th><th align="left"><bold>Correct</bold></th><th align="left"><bold>Incorrect</bold></th></tr></thead><tbody><tr><td align="left">Correct</td><td align="left">2053</td><td align="left">568</td></tr><tr><td align="left">Incorrect</td><td align="left">97</td><td align="left">82</td></tr></tbody></table><table-wrap-foot><p>McNemar&#x02019;s <italic>&#x003c7;</italic>2&#x02009;=&#x02009;304.64</p><p><italic>p</italic>-value&#x02009;&#x0003c;&#x02009;0.001</p></table-wrap-foot></table-wrap></p><p id="Par12">CAN-BERT outperformed medspaCy overall as shown by their receiver operating characteristic (ROC) curves (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). The area under the ROC curve (AUC) was 0.94 for CAN-BERT and 0.77 for medspaCy; the difference was statistically significant at <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001. The medspaCy system generated only one ROC data point because the model is rule-based. CAN-BERT&#x02019;s optimal operating point yielded precision of 0.768 (vs. 0.356 for medspaCy; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) and F1 score of 0.777 (vs. 0.492 for medspaCy; <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) (Tables&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>&#x000a0;and <xref rid="Tab3" ref-type="table">3</xref>). The models achieved similar recall.<fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>Receiver operating characteristic (ROC) curves for CAN-BERT (&#x0201c;BERT&#x0201d;) and medspaCy. AUC = area under the ROC curve</p></caption><graphic xlink:href="10278_2024_1274_Fig2_HTML" id="MO2"/></fig><table-wrap id="Tab2"><label>Table 2</label><caption><p>Confusion matrices for negated-term detection for (A) Medspacy and (B) CAN-BERT</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="5"><bold>A</bold></th></tr><tr><th align="left" colspan="2"/><th align="left" colspan="3">Reference standard</th></tr></thead><tbody><tr><td align="left" colspan="2">MedspaCy assertion</td><td align="left">Negated</td><td align="left">Not negated</td><td align="left">Total</td></tr><tr><td align="left" colspan="2">Negated</td><td align="left">315</td><td align="left">569</td><td align="left">884</td></tr><tr><td align="left" colspan="2">Not negated</td><td align="left">81</td><td align="left">1835</td><td align="left">1916</td></tr><tr><td align="left" colspan="2">Total</td><td align="left">396</td><td align="left">2404</td><td align="left">2800</td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="5">B</th></tr><tr><th align="left"/><th align="left" colspan="4">Reference standard</th></tr></thead><tbody><tr><td align="left" colspan="2">CAN-BERT assertion</td><td align="left">Negated</td><td align="left">Not negated</td><td align="left">Total</td></tr><tr><td align="left" colspan="2">Negated</td><td align="left">311</td><td align="left">94</td><td align="left">405</td></tr><tr><td align="left" colspan="2">Not negated</td><td align="left">85</td><td align="left">2310</td><td align="left">2395</td></tr><tr><td align="left" colspan="2">Total</td><td align="left">396</td><td align="left">2404</td><td align="left">2800</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Negation-detection performance of medspaCy and CAN-BERT</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left"><bold>medspaCy</bold></th><th align="left"><bold>CAN-BERT</bold></th><th align="left"><bold><italic>p-</italic></bold><bold>value</bold></th></tr></thead><tbody><tr><td align="left">Precision</td><td char="." align="char">0.356</td><td char="." align="char">0.768</td><td align="left"><italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001<sup>a</sup></td></tr><tr><td align="left">Recall</td><td char="." align="char">0.795</td><td char="." align="char">0.785</td><td align="left"><italic>p</italic>&#x02009;=&#x02009;0.727</td></tr><tr><td align="left">F1 score</td><td char="." align="char">0.492</td><td char="." align="char">0.777</td><td align="left"><italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001<sup>a</sup></td></tr><tr><td align="left">Specificity</td><td char="." align="char">0.763</td><td char="." align="char">0.961</td><td align="left"><italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001<sup>a</sup></td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.768</td><td char="." align="char">0.936</td><td align="left"><italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001<sup>a</sup></td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>Statistically significant</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec7"><title>Discussion</title><p id="Par13">In this study, CAN-BERT achieved better performance in negation detection than the medspaCy model.&#x000a0;Some recent studies have suggested that LLMs have a poorer ability to detect negated expressions; these studies used common-sense knowledge to test the LLM models [<xref ref-type="bibr" rid="CR32">32</xref>&#x02013;<xref ref-type="bibr" rid="CR34">34</xref>]. A possible explanation for this difference comes from the data each study used to test the models. In the present study, both models were tested with highly specialized textual data, namely radiology reports, and both models received specialized training in medical knowledge data from their developers.
</p><p id="Par14">The current investigation sought to address a critical gap in previous research: generalizability remains a significant challenge in negation detection [<xref ref-type="bibr" rid="CR35">35</xref>]. Deep learning has been applied successfully for negation detection in limited domains, such as oncology reports, chest CT reports, and whole-body PET/CT reports [<xref ref-type="bibr" rid="CR36">36</xref>&#x02013;<xref ref-type="bibr" rid="CR40">40</xref>]. A recent study applied negation detection to a diverse set of radiology reports, but to only 12 pathological findings based on the institution&#x02019;s &#x0201c;list of important keywords&#x0201d; [<xref ref-type="bibr" rid="CR41">41</xref>]. In contrast, the current work sought to evaluate negation detection based on comprehensive medical vocabularies to achieve a more robust and complete evaluation across a wide variety of radiology reports.</p><p id="Par15">CAN-BERT&#x02019;s significantly greater precision over medspaCy suggests that although rule-based systems can identify negations effectively, an LLM may have stronger performance in a novel dataset where the negation patterns are highly variable and different from the training dataset [<xref ref-type="bibr" rid="CR26">26</xref>]. CAN-BERT&#x02019;s robustness can be attributed to its training on diverse clinical datasets, which likely provided a rich linguistic foundation, enabling it to generalize better to unseen data [<xref ref-type="bibr" rid="CR31">31</xref>]. The reliance on contextual understanding allows CAN-BERT to discern the subtleties of clinical language, often laden with jargon, abbreviations, and complex sentence structures [<xref ref-type="bibr" rid="CR16">16</xref>].</p><p id="Par16">This study has several limitations. It was based on a relatively small number of radiology reports from a single center, which may limit generalizability of the results. The text corpus may contain biases related to local choices of terminology and regional patient demographics. Furthermore, the scope of negation detection was restricted to binary classification, which, although useful for this study, may overlook the subtleties of language that convey uncertainty or gradations of certainty and potentially lead to data oversimplification. Another limitation arises from the potential for bias in the manual annotation process. Despite the oversight of experienced medical professionals, the subjective nature of interpreting medical text can introduce variability in the reference standard against which the NLP systems were evaluated. Finally, this study compared two NLP systems, and although CAN-BERT outperformed medspaCy in our analysis, it is possible that other models or combinations of models could yield different or improved results.</p><p id="Par17">The outcomes of this study hold considerable significance in the context of using EHR to enhance patient care. Broadly, the ability of an NLP system to discern the presence and absence of conditions in radiology reports can streamline workflows, alleviate the workload on healthcare professionals, and potentially lead to more prompt and precise diagnoses [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR16">16</xref>]. Detection of negated terms in clinical text can support research efforts to deduce causal relationships among entities in radiology reports [<xref ref-type="bibr" rid="CR42">42</xref>]. Further research will explore the analysis of larger datasets from a variety of institutions, the classification of named entities in terms of the certainty of their presence or absence, and the development of consensus guidelines to reduce annotation bias. Additionally, further studies could evaluate the performance of a broader range of NLP systems to find the most effective tools for clinical application.</p></sec><sec id="Sec8"><title>Conclusion</title><p id="Par18">Large language models such as CAN-BERT may be better suited for the complex task of detecting negated terms in complex clinical text, such as radiology reports. Subsequent research should concentrate on enhancing these models, augmenting their training datasets with a broader range of medical specializations, and formulating more complex models to interpret the full spectrum of clinical documentation. Furthermore, the results of this study could help researchers select suitable NLP tools for specific analytical tasks. Improved detection of negated expressions in radiology reports will enable more accurate text mining for information retrieval, quality improvement, automated text understanding, and training of image-based AI models [<xref ref-type="bibr" rid="CR43">43</xref>].</p></sec></body><back><fn-group><fn><p>Presented as a&#x000a0;poster at the 2023 Conference on Machine Intelligence in Medical Imaging.</p></fn><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>Yvonne Su and Yonatan B. Babore contributed equally to this report.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author Contributions</title><p>All authors contributed to the study conception and design, data collection, and analysis. All authors contributed to writing and editing the manuscript. All authors approved the final manuscript.</p></notes><notes><title>Declarations</title><notes id="FPar1"><title>Ethics Approval</title><p id="Par19">Study protocol approved by the University of Pennsylvania IRB. Informed consent from patients was waived.</p></notes><notes id="FPar2" notes-type="COI-statement"><title>Competing Interests</title><p id="Par20">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Landolsi</surname><given-names>MY</given-names></name><name><surname>Hlaoua</surname><given-names>L</given-names></name><name><surname>Ben Romdhane</surname><given-names>L</given-names></name></person-group><article-title>Information extraction from electronic medical documents: state of the art and future research directions</article-title><source>Knowl Inf Syst</source><year>2023</year><volume>65</volume><fpage>463</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1007/s10115-022-01779-1</pub-id><pub-id pub-id-type="pmid">36405956</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Landolsi MY, Hlaoua L, Ben Romdhane L: Information extraction from electronic medical documents: state of the art and future research directions. Knowl Inf Syst 65:463-516, 2023<pub-id pub-id-type="pmid">36405956</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Casey</surname><given-names>A</given-names></name><etal/></person-group><article-title>A systematic review of natural language processing applied to radiology reports</article-title><source>BMC Med Inform Decis Mak</source><year>2021</year><volume>21</volume><fpage>179</fpage><pub-id pub-id-type="doi">10.1186/s12911-021-01533-7</pub-id><pub-id pub-id-type="pmid">34082729</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Casey A, et al.: A systematic review of natural language processing applied to radiology reports. BMC Med Inform Decis Mak 21:179, 2021<pub-id pub-id-type="pmid">34082729</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Linna</surname><given-names>N</given-names></name><name><surname>Kahn</surname><given-names>CE</given-names><suffix>Jr</suffix></name></person-group><article-title>Applications of natural language processing in radiology: A systematic review</article-title><source>Int J Med Inform</source><year>2022</year><volume>163</volume><fpage>104779</fpage><pub-id pub-id-type="doi">10.1016/j.ijmedinf.2022.104779</pub-id><pub-id pub-id-type="pmid">35533413</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Linna N, Kahn CE Jr.: Applications of natural language processing in radiology: A systematic review. Int J Med Inform 163:104779, 2022<pub-id pub-id-type="pmid">35533413</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Lakhani</surname><given-names>P</given-names></name><name><surname>Kim</surname><given-names>W</given-names></name><name><surname>Langlotz</surname><given-names>CP</given-names></name></person-group><article-title>Automated detection of critical results in radiology reports</article-title><source>J Digit Imaging</source><year>2012</year><volume>25</volume><fpage>30</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1007/s10278-011-9426-6</pub-id><pub-id pub-id-type="pmid">22038514</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Lakhani P, Kim W, Langlotz CP: Automated detection of critical results in radiology reports. J Digit Imaging 25:30-36, 2012<pub-id pub-id-type="pmid">22038514</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Hripcsak</surname><given-names>G</given-names></name><name><surname>Austin</surname><given-names>JH</given-names></name><name><surname>Alderson</surname><given-names>PO</given-names></name><name><surname>Friedman</surname><given-names>C</given-names></name></person-group><article-title>Use of natural language processing to translate clinical information from a database of 889,921 chest radiographic reports</article-title><source>Radiology</source><year>2002</year><volume>224</volume><fpage>157</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1148/radiol.2241011118</pub-id><pub-id pub-id-type="pmid">12091676</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Hripcsak G, Austin JH, Alderson PO, Friedman C: Use of natural language processing to translate clinical information from a database of 889,921 chest radiographic reports. Radiology 224:157-163, 2002<pub-id pub-id-type="pmid">12091676</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Fraile Navarro</surname><given-names>D</given-names></name><etal/></person-group><article-title>Clinical named entity recognition and relation extraction using natural language processing of medical free text: A systematic review</article-title><source>Int J Med Inform</source><year>2023</year><volume>177</volume><fpage>105122</fpage><pub-id pub-id-type="doi">10.1016/j.ijmedinf.2023.105122</pub-id><pub-id pub-id-type="pmid">37295138</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Fraile Navarro D, et al.: Clinical named entity recognition and relation extraction using natural language processing of medical free text: A systematic review. Int J Med Inform 177:105122, 2023<pub-id pub-id-type="pmid">37295138</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Godoy E, et al.: A named entity recognition framework using transformers to identify relevant clinical findings from mammographic radiological reports: SPIE, 2023</mixed-citation></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuji</surname><given-names>S</given-names></name><name><surname>Wen</surname><given-names>A</given-names></name><name><surname>Takahashi</surname><given-names>N</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Ogasawara</surname><given-names>K</given-names></name><name><surname>Jiang</surname><given-names>G</given-names></name></person-group><article-title>Developing a RadLex-based named entity recognition tool for mining textual radiology reports: development and performance evaluation study</article-title><source>J Med Internet Res</source><year>2021</year><volume>23</volume><fpage>e25378</fpage><pub-id pub-id-type="doi">10.2196/25378</pub-id><pub-id pub-id-type="pmid">34714247</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Tsuji S, Wen A, Takahashi N, Zhang H, Ogasawara K, Jiang G: Developing a RadLex-based named entity recognition tool for mining textual radiology reports: development and performance evaluation study. J Med Internet Res 23:e25378, 2021<pub-id pub-id-type="pmid">34714247</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Savova</surname><given-names>GK</given-names></name><etal/></person-group><article-title>Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications</article-title><source>J Am Med Informatics Assoc</source><year>2010</year><volume>17</volume><fpage>507</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1136/jamia.2009.001560</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Savova GK, et al.: Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications. J Am Med Informatics Assoc 17:507-513, 2010</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>HBS</given-names></name><name><surname>Sohn</surname><given-names>S</given-names></name><etal/></person-group><article-title>An information extraction framework for cohort identification using electronic health record</article-title><source>AMIA Jt Summits Transl Sci Proc</source><year>2013</year><volume>149&#x02013;115</volume><fpage>2013</fpage></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Liu H BS, Sohn S, et al.: An information extraction framework for cohort identification using electronic health record. AMIA Jt Summits Transl Sci Proc 2013:149-115, 2013</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Eyre</surname><given-names>H</given-names></name><etal/></person-group><article-title>Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python</article-title><source>AMIA Annu Symp Proc</source><year>2021</year><volume>438&#x02013;447</volume><fpage>2021</fpage></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Eyre H, et al.: Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python. AMIA Annu Symp Proc 2021:438-447, 2021</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Alex</surname><given-names>B</given-names></name><name><surname>Grover</surname><given-names>C</given-names></name><name><surname>Tobin</surname><given-names>R</given-names></name><name><surname>Sudlow</surname><given-names>C</given-names></name><name><surname>Mair</surname><given-names>G</given-names></name><name><surname>Whiteley</surname><given-names>W</given-names></name></person-group><article-title>Text mining brain imaging reports</article-title><source>J Biomed Semantics</source><year>2019</year><volume>10</volume><fpage>23</fpage><pub-id pub-id-type="doi">10.1186/s13326-019-0211-7</pub-id><pub-id pub-id-type="pmid">31711539</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Alex B, Grover C, Tobin R, Sudlow C, Mair G, Whiteley W: Text mining brain imaging reports. J Biomed Semantics 10:23, 2019<pub-id pub-id-type="pmid">31711539</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Mehrabi</surname><given-names>S</given-names></name><etal/></person-group><article-title>DEEPEN: A negation detection system for clinical text incorporating dependency relation into NegEx</article-title><source>J Biomed Inform</source><year>2015</year><volume>54</volume><fpage>213</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.jbi.2015.02.010</pub-id><pub-id pub-id-type="pmid">25791500</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Mehrabi S, et al.: DEEPEN: A negation detection system for clinical text incorporating dependency relation into NegEx. J Biomed Inform 54:213-219, 2015<pub-id pub-id-type="pmid">25791500</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Bagheri</surname><given-names>M</given-names></name><name><surname>Summers</surname><given-names>R</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name></person-group><article-title>NegBio: a high-performance tool for negation and uncertainty detection in radiology reports</article-title><source>AMIA Jt Summits Transl Sci Proc</source><year>2017</year><volume>188&#x02013;196</volume><fpage>2018</fpage></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Peng Y, Wang X, Lu L, Bagheri M, Summers R, Lu Z: NegBio: a high-performance tool for negation and uncertainty detection in radiology reports. AMIA Jt Summits Transl Sci Proc 2017:188-196, 2018</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Chapman</surname><given-names>WW</given-names></name><name><surname>Bridewell</surname><given-names>W</given-names></name><name><surname>Hanbury</surname><given-names>P</given-names></name><name><surname>Cooper</surname><given-names>GF</given-names></name><name><surname>Buchanan</surname><given-names>BG</given-names></name></person-group><article-title>A simple algorithm for identifying negated findings and diseases in discharge summaries</article-title><source>J Biomed Inform</source><year>2001</year><volume>34</volume><fpage>301</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1006/jbin.2001.1029</pub-id><pub-id pub-id-type="pmid">12123149</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Chapman WW, Bridewell W, Hanbury P, Cooper GF, Buchanan BG: A simple algorithm for identifying negated findings and diseases in discharge summaries. J Biomed Inform 34:301-310, 2001<pub-id pub-id-type="pmid">12123149</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Chapman WW, Bridewell W, Hanbury P, Cooper GF, Buchanan BG: Evaluation of negation phrases in narrative clinical reports. Proc AMIA Symp:105&#x02013;109, 2001</mixed-citation></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Gindl</surname><given-names>S</given-names></name><name><surname>Kaiser</surname><given-names>K</given-names></name><name><surname>Miksch</surname><given-names>S</given-names></name></person-group><article-title>Syntactical negation detection in clinical practice guidelines</article-title><source>Stud Health Technol Inform</source><year>2008</year><volume>136</volume><fpage>187</fpage><lpage>192</lpage><pub-id pub-id-type="pmid">18487729</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Gindl S, Kaiser K, Miksch S: Syntactical negation detection in clinical practice guidelines. Stud Health Technol Inform 136:187-192, 2008<pub-id pub-id-type="pmid">18487729</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Mutalik</surname><given-names>PG</given-names></name><name><surname>Deshpande</surname><given-names>A</given-names></name><name><surname>Nadkarni</surname><given-names>PM</given-names></name></person-group><article-title>Use of general-purpose negation detection to augment concept indexing of medical documents: a quantitative study using the UMLS</article-title><source>J Am Med Informatics Assoc</source><year>2001</year><volume>8</volume><fpage>598</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1136/jamia.2001.0080598</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Mutalik PG, Deshpande A, Nadkarni PM: Use of general-purpose negation detection to augment concept indexing of medical documents: a quantitative study using the UMLS. J Am Med Informatics Assoc 8:598-609, 2001</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Thirunavukarasu</surname><given-names>AJ</given-names></name><name><surname>Ting</surname><given-names>DSJ</given-names></name><name><surname>Elangovan</surname><given-names>K</given-names></name><name><surname>Gutierrez</surname><given-names>L</given-names></name><name><surname>Tan</surname><given-names>TF</given-names></name><name><surname>Ting</surname><given-names>DSW</given-names></name></person-group><article-title>Large language models in medicine</article-title><source>Nat Med</source><year>2023</year><volume>29</volume><fpage>1930</fpage><lpage>1940</lpage><pub-id pub-id-type="doi">10.1038/s41591-023-02448-8</pub-id><pub-id pub-id-type="pmid">37460753</pub-id>
</element-citation><mixed-citation id="mc-CR19" publication-type="journal">Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW: Large language models in medicine. Nat Med 29:1930-1940, 2023<pub-id pub-id-type="pmid">37460753</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Min</surname><given-names>B</given-names></name><etal/></person-group><article-title>Recent advances in natural language processing via large pre-trained language models: a survey</article-title><source>ACM Comput Surv</source><year>2023</year><volume>56</volume><fpage>1</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1145/3605943</pub-id></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Min B, et al.: Recent advances in natural language processing via large pre-trained language models: a survey. ACM Comput Surv 56:1-40, 2023</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Smit A, Jain S, Rajpurkar P, Pareek A, Ng AY, Lungren MP: CheXbert: Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT. arXiv [preprint]:<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/hep-th/2004.09167">arXiv:2004.09167</ext-link> [cs.CL]</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Devlin J, Chang M-W, Lee K, Toutanova K: BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv [preprint]:<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/hep-th/1810.04805">arXiv:1810.04805</ext-link> [cs.CL], 2018</mixed-citation></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>C</given-names></name><name><surname>Bethard</surname><given-names>S</given-names></name><name><surname>Dligach</surname><given-names>D</given-names></name><name><surname>Sadeque</surname><given-names>F</given-names></name><name><surname>Savova</surname><given-names>G</given-names></name><name><surname>Miller</surname><given-names>TA</given-names></name></person-group><article-title>Does BERT need domain adaptation for clinical negation detection?</article-title><source>J Am Med Inform Assoc</source><year>2020</year><volume>27</volume><fpage>584</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1093/jamia/ocaa001</pub-id><pub-id pub-id-type="pmid">32044989</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Lin C, Bethard S, Dligach D, Sadeque F, Savova G, Miller TA: Does BERT need domain adaptation for clinical negation detection? J Am Med Inform Assoc 27:584-591, 2020<pub-id pub-id-type="pmid">32044989</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Liu Y, et al.: RoBERTa: A robustly optimized BERT pretraining approach. arXiv [preprint]:<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/hep-th/1907.11692">arXiv:1907.11692</ext-link> [cs.CL], 2019</mixed-citation></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Jaiswal</surname><given-names>A</given-names></name><name><surname>Tang</surname><given-names>L</given-names></name><name><surname>Ghosh</surname><given-names>M</given-names></name><name><surname>Rousseau</surname><given-names>JF</given-names></name><name><surname>Peng</surname><given-names>Y</given-names></name><name><surname>Ding</surname><given-names>Y</given-names></name></person-group><article-title>RadBERT-CL: Factually-aware contrastive learning for radiology report classification</article-title><source>Proceedings of Machine Learning Research</source><year>2021</year><volume>158</volume><fpage>196</fpage><lpage>208</lpage><pub-id pub-id-type="pmid">35498230</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal">Jaiswal A, Tang L, Ghosh M, Rousseau JF, Peng Y, Ding Y: RadBERT-CL: Factually-aware contrastive learning for radiology report classification. Proceedings of Machine Learning Research 158:196-208, 2021<pub-id pub-id-type="pmid">35498230</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Sykes</surname><given-names>D</given-names></name><etal/></person-group><article-title>Comparison of rule-based and neural network models for negation detection in radiology reports</article-title><source>Natural Language Engineering</source><year>2021</year><volume>27</volume><fpage>203</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1017/S1351324920000509</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Sykes D, et al.: Comparison of rule-based and neural network models for negation detection in radiology reports. Natural Language Engineering 27:203-224, 2021</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>van Es</surname><given-names>B</given-names></name><etal/></person-group><article-title>Negation detection in Dutch clinical texts: an evaluation of rule-based and machine learning methods</article-title><source>BMC Bioinformatics</source><year>2023</year><volume>24</volume><fpage>10</fpage><pub-id pub-id-type="doi">10.1186/s12859-022-05130-x</pub-id><pub-id pub-id-type="pmid">36624385</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal">van Es B, et al.: Negation detection in Dutch clinical texts: an evaluation of rule-based and machine learning methods. BMC Bioinformatics 24:10, 2023<pub-id pub-id-type="pmid">36624385</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name><surname>Langlotz</surname><given-names>CP</given-names></name></person-group><article-title>RadLex: a new method for indexing online educational materials</article-title><source>RadioGraphics</source><year>2006</year><volume>26</volume><fpage>1595</fpage><lpage>1597</lpage><pub-id pub-id-type="doi">10.1148/rg.266065168</pub-id><pub-id pub-id-type="pmid">17102038</pub-id>
</element-citation><mixed-citation id="mc-CR28" publication-type="journal">Langlotz CP: RadLex: a new method for indexing online educational materials. RadioGraphics 26:1595-1597, 2006<pub-id pub-id-type="pmid">17102038</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="book"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>SJ</given-names></name><name><surname>Powell</surname><given-names>T</given-names></name><name><surname>Humphreys</surname><given-names>BL</given-names></name></person-group><source>The Unified Medical Language System (UMLS) Project</source><year>2002</year><publisher-loc>New York</publisher-loc><publisher-name>Marcel Dekker Inc</publisher-name></element-citation><mixed-citation id="mc-CR29" publication-type="book">Nelson SJ, Powell T, Humphreys BL: The Unified Medical Language System (UMLS) Project, New York: Marcel Dekker, Inc., 2002</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Budovec</surname><given-names>JJ</given-names></name><name><surname>Lam</surname><given-names>CA</given-names></name><name><surname>Kahn</surname><given-names>CE</given-names><suffix>Jr</suffix></name></person-group><article-title>Radiology Gamuts Ontology: differential diagnosis for the Semantic Web</article-title><source>RadioGraphics</source><year>2014</year><volume>34</volume><fpage>254</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1148/rg.341135036</pub-id><pub-id pub-id-type="pmid">24428295</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Budovec JJ, Lam CA, Kahn CE Jr.: Radiology Gamuts Ontology: differential diagnosis for the Semantic Web. RadioGraphics 34:254-264, 2014<pub-id pub-id-type="pmid">24428295</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">van Aken B, et al.: Assertion detection in clinical notes: Medical language models to the rescue? Proc. Proceedings of the Second Workshop on Natural Language Processing for Medical Conversations: City</mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Kassner N, Sch&#x000fc;tze H: Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly. arXiv [preprint]:<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/hep-th/1911.03343">arXiv:1911.03343</ext-link> [cs.CL], 2019</mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Truong TH, Baldwin T, Verspoor K, Cohn T: Language models are not naysayers: an analysis of language models on negation benchmarks. arXiv [preprint]:<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2306.08189">arXiv:2306.08189</ext-link>, 2023</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Garc&#x000ed;a-Ferrero I, Altuna B, &#x000c1;lvez J, Gonzalez-Dios I, Rigau G: This is not a dataset: A large negation benchmark to challenge large language models. arXiv [preprint]:<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2310.15941">arXiv:2310.15941</ext-link>, 2023</mixed-citation></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>S</given-names></name><etal/></person-group><article-title>Negation's not solved: generalizability versus optimizability in clinical natural language processing</article-title><source>PLoS One</source><year>2014</year><volume>9</volume><fpage>e112774</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0112774</pub-id><pub-id pub-id-type="pmid">25393544</pub-id>
</element-citation><mixed-citation id="mc-CR35" publication-type="journal">Wu S, et al.: Negation's not solved: generalizability versus optimizability in clinical natural language processing. PLoS One 9:e112774, 2014<pub-id pub-id-type="pmid">25393544</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>Sugimoto</surname><given-names>K</given-names></name><etal/></person-group><article-title>Extracting clinical terms from radiology reports with deep learning</article-title><source>J Biomed Inform</source><year>2021</year><volume>116</volume><fpage>103729</fpage><pub-id pub-id-type="doi">10.1016/j.jbi.2021.103729</pub-id><pub-id pub-id-type="pmid">33711545</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal">Sugimoto K, et al.: Extracting clinical terms from radiology reports with deep learning. J Biomed Inform 116:103729, 2021<pub-id pub-id-type="pmid">33711545</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name><surname>Sugimoto</surname><given-names>K</given-names></name><etal/></person-group><article-title>Classification of diagnostic certainty in radiology reports with deep learning</article-title><source>Stud Health Technol Inform</source><year>2024</year><volume>310</volume><fpage>569</fpage><lpage>573</lpage><pub-id pub-id-type="pmid">38269873</pub-id>
</element-citation><mixed-citation id="mc-CR37" publication-type="journal">Sugimoto K, et al.: Classification of diagnostic certainty in radiology reports with deep learning. Stud Health Technol Inform 310:569-573, 2024<pub-id pub-id-type="pmid">38269873</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name><surname>Irvin</surname><given-names>JA</given-names></name><etal/></person-group><article-title>CheXED: Comparison of a Deep Learning Model to a Clinical Decision Support System for Pneumonia in the Emergency Department</article-title><source>J Thorac Imaging</source><year>2022</year><volume>37</volume><fpage>162</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1097/RTI.0000000000000622</pub-id><pub-id pub-id-type="pmid">34561377</pub-id>
</element-citation><mixed-citation id="mc-CR38" publication-type="journal">Irvin JA, et al.: CheXED: Comparison of a Deep Learning Model to a Clinical Decision Support System for Pneumonia in the Emergency Department. J Thorac Imaging 37:162-167, 2022<pub-id pub-id-type="pmid">34561377</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name><surname>Fink</surname><given-names>MA</given-names></name><etal/></person-group><article-title>Deep learning-based assessment of oncologic outcomes from natural language processing of structured radiology reports</article-title><source>Radiol Artif Intell</source><year>2022</year><volume>4</volume><fpage>e220055</fpage><pub-id pub-id-type="doi">10.1148/ryai.220055</pub-id><pub-id pub-id-type="pmid">36204531</pub-id>
</element-citation><mixed-citation id="mc-CR39" publication-type="journal">Fink MA, et al.: Deep learning-based assessment of oncologic outcomes from natural language processing of structured radiology reports. Radiol Artif Intell 4:e220055, 2022<pub-id pub-id-type="pmid">36204531</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name><surname>Nishigaki</surname><given-names>D</given-names></name><etal/></person-group><article-title>BERT-based transfer learning in sentence-level anatomic classification of free-text radiology reports</article-title><source>Radiol Artif Intell</source><year>2023</year><volume>5</volume><fpage>e220097</fpage><pub-id pub-id-type="doi">10.1148/ryai.220097</pub-id><pub-id pub-id-type="pmid">37035437</pub-id>
</element-citation><mixed-citation id="mc-CR40" publication-type="journal">Nishigaki D, et al.: BERT-based transfer learning in sentence-level anatomic classification of free-text radiology reports. Radiol Artif Intell 5:e220097, 2023<pub-id pub-id-type="pmid">37035437</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name><surname>Weng</surname><given-names>KH</given-names></name><name><surname>Liu</surname><given-names>CF</given-names></name><name><surname>Chen</surname><given-names>CJ</given-names></name></person-group><article-title>Deep learning approach for negation and speculation detection for automated important finding flagging and extraction in radiology report: internal validation and technique comparison study</article-title><source>JMIR Med Inform</source><year>2023</year><volume>11</volume><fpage>e46348</fpage><pub-id pub-id-type="doi">10.2196/46348</pub-id><pub-id pub-id-type="pmid">37097731</pub-id>
</element-citation><mixed-citation id="mc-CR41" publication-type="journal">Weng KH, Liu CF, Chen CJ: Deep learning approach for negation and speculation detection for automated important finding flagging and extraction in radiology report: internal validation and technique comparison study. JMIR Med Inform 11:e46348, 2023<pub-id pub-id-type="pmid">37097731</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>Sebro</surname><given-names>RA</given-names></name><name><surname>Kahn</surname><given-names>CE</given-names><suffix>Jr</suffix></name></person-group><article-title>Automated detection of causal relationships among diseases and imaging findings in textual radiology reports</article-title><source>J Am Med Informatics Assoc</source><year>2023</year><volume>30</volume><fpage>1701</fpage><lpage>1706</lpage><pub-id pub-id-type="doi">10.1093/jamia/ocad119</pub-id></element-citation><mixed-citation id="mc-CR42" publication-type="journal">Sebro RA, Kahn CE Jr: Automated detection of causal relationships among diseases and imaging findings in textual radiology reports. J Am Med Informatics Assoc 30:1701-1706, 2023</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>AS</given-names></name><name><surname>Do</surname><given-names>BH</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Rubin</surname><given-names>DL</given-names></name></person-group><article-title>Evaluation of negation and uncertainty detection and its impact on precision and recall in search</article-title><source>J Digit Imaging</source><year>2011</year><volume>24</volume><fpage>234</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1007/s10278-009-9250-4</pub-id><pub-id pub-id-type="pmid">19902298</pub-id>
</element-citation><mixed-citation id="mc-CR43" publication-type="journal">Wu AS, Do BH, Kim J, Rubin DL: Evaluation of negation and uncertainty detection and its impact on precision and recall in search. J Digit Imaging 24:234-242, 2011<pub-id pub-id-type="pmid">19902298</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>