<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006427</article-id><article-id pub-id-type="pmc">PMC11861042</article-id><article-id pub-id-type="doi">10.3390/s25041195</article-id><article-id pub-id-type="publisher-id">sensors-25-01195</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Adaptive Exposure Control for Line-Structured Light Sensors Based on Global Grayscale Statistics</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Li</surname><given-names>Yuehua</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af1-sensors-25-01195" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Qingfeng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><xref rid="af1-sensors-25-01195" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8612-1521</contrib-id><name><surname>Hu</surname><given-names>Po</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="af2-sensors-25-01195" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Hao</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><xref rid="af1-sensors-25-01195" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Ziheng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="af1-sensors-25-01195" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Xiaohong</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="af1-sensors-25-01195" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhou</surname><given-names>Jingbo</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x02013; review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="af1-sensors-25-01195" ref-type="aff">1</xref><xref rid="c1-sensors-25-01195" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Vanlanduit</surname><given-names>Steve</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01195"><label>1</label>School of Mechanical Engineering, Hebei University of Science and Technology, Shijiazhuang 050018, China; <email>yuehua.hrbin@163.com</email> (Y.L.); <email>zhaoqqf973@126.com</email> (Q.Z.); <email>zh99150@outlook.com</email> (H.Z.); <email>18033857268@163.com</email> (Z.Z.); <email>liuxh@hebust.edu.cn</email> (X.L.)</aff><aff id="af2-sensors-25-01195"><label>2</label>School of Mechanical Engineering, Shijiazhuang Tiedao University, Shijiazhuang 050043, China; <email>hupo@stdu.edu.cn</email></aff><author-notes><corresp id="c1-sensors-25-01195"><label>*</label>Correspondence: <email>zhoujingbo@hebust.edu.cn</email>; Tel.: +86-18333193615</corresp></author-notes><pub-date pub-type="epub"><day>16</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1195</elocation-id><history><date date-type="received"><day>12</day><month>1</month><year>2025</year></date><date date-type="rev-recd"><day>25</day><month>1</month><year>2025</year></date><date date-type="accepted"><day>10</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Stripe images are crucial for ensuring the measurement quality of line-structured light sensors. To improve the measurement effectiveness of objects with different shapes, materials, and colors, an adaptive exposure method is proposed based on global grayscale statistical analysis of stripe images. The logarithm sum of grayscale statistical results is calculated as the quality evaluation parameter for each stripe image. Theoretical analysis and experiments demonstrate that the proposed quality evaluation value exhibits an approximate linear relationship with a camera&#x02019;s exposure time. Subsequently, an adaptive exposure control method is developed. The influence of control system parameters on measurement results is also analyzed in detail. The experimental results show that our method can adaptively adjust a camera&#x02019;s exposure time according to different surface characteristics. Both the number of effective measurement points and the accuracy are improved.</p></abstract><kwd-group><kwd>line-structured light sensor</kwd><kwd>quality evaluation of stripe images</kwd><kwd>global grayscale statistics</kwd><kwd>adaptive exposure control</kwd></kwd-group><funding-group><award-group><funding-source>Natural Science Foundation of Hebei Province</funding-source><award-id>E2022208020</award-id><award-id>E2024208086</award-id></award-group><award-group><funding-source>Hebei Provincial Department of Education</funding-source><award-id>CXZZSS2023092</award-id></award-group><funding-statement>This research was funded by the Natural Science Foundation of Hebei Province, grant number E2022208020, E2024208086, and by Hebei Provincial Department of Education, grant number CXZZSS2023092.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01195"><title>1. Introduction</title><p>Line-structured light sensors (LSLSs) mainly comprise a camera and a laser line projector. In the measurement process, a laser line is projected onto the object, and the camera captures perturbed stripe images. A two-dimensional (2D) profile can be calculated according to the pixel coordinates of the laser stripe, the camera&#x02019;s intrinsic parameters, and the equation of the laser plane [<xref rid="B1-sensors-25-01195" ref-type="bibr">1</xref>]. LSLSs have the advantages of having a simple structure, fast measurement speed, and high accuracy. They have broad application prospects in various fields, such as three-dimensional (3D) measurement [<xref rid="B2-sensors-25-01195" ref-type="bibr">2</xref>], quality inspection [<xref rid="B3-sensors-25-01195" ref-type="bibr">3</xref>], and character recognition [<xref rid="B4-sensors-25-01195" ref-type="bibr">4</xref>].</p><p>Currently, research on LSLSs mainly focuses on the center extraction of stripe images [<xref rid="B5-sensors-25-01195" ref-type="bibr">5</xref>], sensor calibration [<xref rid="B6-sensors-25-01195" ref-type="bibr">6</xref>], and the integration of sensors with other motion coordinate systems for different measurement applications [<xref rid="B7-sensors-25-01195" ref-type="bibr">7</xref>,<xref rid="B8-sensors-25-01195" ref-type="bibr">8</xref>]. Once the sensor has been calibrated, the camera&#x02019;s intrinsic parameters, such as the distortion parameters and the relative position between the camera and laser line projector, are kept unchanged. However, stripe images are always changing according to the geometry, material, color, and surface roughness of the object being measured. The quality of stripe images affects the accuracy and reliability of the center extraction results, thereby influencing the final measurement results. Ensuring stripe image quality with adaptive control is the key to achieving high-precision results and is a core issue in LSLS research [<xref rid="B9-sensors-25-01195" ref-type="bibr">9</xref>].</p><p>Most research on the adaptive control of structured light measurements focuses on fringe projection systems based on digital light processing (DLP) [<xref rid="B10-sensors-25-01195" ref-type="bibr">10</xref>]. With DLP devices, flexible fringe patterns can be generated, and the intensity can be adjusted even at the pixel level [<xref rid="B11-sensors-25-01195" ref-type="bibr">11</xref>,<xref rid="B12-sensors-25-01195" ref-type="bibr">12</xref>]. Adaptive control can be achieved by automatically adjusting the camera exposure time and fusing the fringe images [<xref rid="B13-sensors-25-01195" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-01195" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-01195" ref-type="bibr">15</xref>]. Other strategies include generating optimal fringe projection patterns via surface segmentation [<xref rid="B16-sensors-25-01195" ref-type="bibr">16</xref>], the analysis of saturated pixels in captured images [<xref rid="B17-sensors-25-01195" ref-type="bibr">17</xref>], and the application of intensity coefficient templates [<xref rid="B18-sensors-25-01195" ref-type="bibr">18</xref>], misaligned gray code [<xref rid="B19-sensors-25-01195" ref-type="bibr">19</xref>], local surface reflectivity [<xref rid="B20-sensors-25-01195" ref-type="bibr">20</xref>], and accurate optical models [<xref rid="B21-sensors-25-01195" ref-type="bibr">21</xref>]. To enhance the measurement efficiency of highly reflective surfaces, adaptive projection can be combined with a curve-fitting algorithm [<xref rid="B22-sensors-25-01195" ref-type="bibr">22</xref>] or the original and inverse projection method [<xref rid="B23-sensors-25-01195" ref-type="bibr">23</xref>]. All of these methods enable measurement flexibility and facilitate the implementation of structured light methods. In contrast to DLP-based 3D measurement techniques, LSLSs feature a simpler design and lower cost. The laser line is emitted from a semiconductor laser source and shaped by a Powell lens. Its brightness can be adjusted only as a whole. Additionally, the sensor keeps moving during the scanning process, rendering DLP-based adaptive control methods unsuitable for LSLSs.</p><p>Variations in color, material, and roughness directly impact the quality of stripe images. To address issues such as reflection interference, overexposure, and underexposure, different methods have been developed to enhance the accuracy of stripe center extraction, like the mass&#x02013;spring method [<xref rid="B24-sensors-25-01195" ref-type="bibr">24</xref>], the stripe segmentation method [<xref rid="B25-sensors-25-01195" ref-type="bibr">25</xref>], and the multi-scale analysis method [<xref rid="B26-sensors-25-01195" ref-type="bibr">26</xref>]. However, these methods are often intricate and time consuming. Enhancing the quality of stripe images themselves is a more effective approach to improving measurement results. Song et al. [<xref rid="B27-sensors-25-01195" ref-type="bibr">27</xref>] employed wavelet decomposition to adjust the brightness of stripe images by regulating the input voltage of the laser projector. Tang et al. [<xref rid="B28-sensors-25-01195" ref-type="bibr">28</xref>] utilized dual-tree complex wavelet transform to control laser intensity. It is important to note that wavelet technology presents substantial computational challenges, and the aforementioned wavelet-based methods are solely designed for selecting an optimal intensity, thereby lacking real-time control capabilities. In a separate effort, Li et al. [<xref rid="B29-sensors-25-01195" ref-type="bibr">29</xref>] devised an imaging system for laser scanners using a silicon-based reflective liquid crystal (LCoS) device and explored optical image adaptation methods for rectifying local oversaturation. The LCoS device effectively attenuates the light reaching the image pixels, thus avoiding overexposure. However, this method requires additional hardware such as optical devices, the LCoS device, and control units. It also introduces more complex calibration processes. Zhou et al. [<xref rid="B30-sensors-25-01195" ref-type="bibr">30</xref>] achieved adaptive sensor control by modulating the camera exposure time to make the average stripe width within a desired range. The computation of stripe width is time consuming, however, and hinders the increase in sampling frequency.</p><p>The width of the stripe directly affects the uncertainty of center extraction. Typically, when the stripe width is between 8 and 10 pixels, optimal uncertainty values can be achieved [<xref rid="B31-sensors-25-01195" ref-type="bibr">31</xref>]. However, width computation is time consuming and may not meet real-time adaptive control requirements. It is known that the grayscale variation of laser stripes directly relates to the grayscale distribution curves of stripe images. Our research aims to derive a quality evaluation parameter from the grayscale distribution curve. By adjusting the camera&#x02019;s exposure time, stripe quality can be maintained within an ideal range. This, in turn, enhances the integrity and accuracy of the measurement results.</p></sec><sec id="sec2-sensors-25-01195"><title>2. Measurement Principle</title><sec id="sec2dot1-sensors-25-01195"><title>2.1. Measurement Principle of LSLS</title><p>As shown in <xref rid="sensors-25-01195-f001" ref-type="fig">Figure 1</xref>a, the line-structured light measurement system (LSLMS) mainly consists of a camera (MV-SUA133GM, MindVision Technology Co. Ltd., Shenzhen, China), a laser line projector (Shengzuan Technology Co. Ltd., Shenzhen, China), and a linear stage. The laser line is projected onto the part, and the camera captures stripe images perturbed by the surface. Based on the pixel coordinates of the stripe center, the camera&#x02019;s intrinsic parameters, and the equation of laser plane, the corresponding profile can be solved. As the linear stage moves, a series of profiles can be obtained. With the pre-calibrated relative relationship between sensor and motion direction, 3D results can be achieved.</p><p>The measurement principle is illustrated in <xref rid="sensors-25-01195-f001" ref-type="fig">Figure 1</xref>b. O<sub>W</sub>X<sub>W</sub>Y<sub>W</sub>Z<sub>W</sub> and o<sub>c</sub>x<sub>c</sub>y<sub>c</sub>z<sub>c</sub> are the world and the camera coordinate systems, respectively. o<sub>c</sub>u<sub>c</sub>v<sub>c</sub> is the pixel coordinate system with o<sub>c</sub>u<sub>c</sub>//o<sub>c</sub>x<sub>c</sub>, o<sub>c</sub>v<sub>c</sub>//o<sub>c</sub>y<sub>c</sub>. o<sub>c</sub>x<sub>c</sub> is the optical axis, and <italic toggle="yes">f<sub>c</sub></italic> is the focal length of the lens. O<sub>W</sub>X<sub>W</sub>Y<sub>W</sub>Z<sub>W</sub> is positioned on the top surface of the linear stage with the O<sub>W</sub>X<sub>W</sub> axis aligned with the scanning direction. This would make the surface reconstruction more convenient. Here, we mainly focus on the adaptive control of the LSLMS.</p></sec><sec id="sec2dot2-sensors-25-01195"><title>2.2. Evaluation of Stripe Images</title><p>The quality evaluation of stripe images serves as a fundamental prerequisite for the implementation of adaptive control. Among the various techniques of image analysis, the grayscale histogram is one of the most commonly used methods. Grayscale statistical values of stripe images can be expressed as <italic toggle="yes">H</italic>(<italic toggle="yes">I</italic>) = <italic toggle="yes">n<sub>I</sub></italic>, where <italic toggle="yes">I</italic> represents the grayscale values, <italic toggle="yes">I</italic> = 0, 1, 2, &#x02026;, 255, and <italic toggle="yes">n<sub>I</sub></italic> is the number of pixels with the grayscale value <italic toggle="yes">I</italic>. In the measuring process, the total number of pixels remains unchanged. Thus, normalization is not necessary in this area of research.</p><p><xref rid="sensors-25-01195-f002" ref-type="fig">Figure 2</xref> shows a stripe image and its corresponding histogram curve. Unlike the common visual inspection images, it can be seen that only the pixels within the stripe area are highlighted. These pixels account for only a minuscule proportion of the entire image, while the majority of pixels have a grayscale value of 0. For our camera, it has 1280 &#x000d7; 1024 pixels. During the measurement process, the number of pixels with a grayscale value of 0 can reach up to 1.2 &#x000d7; 10<sup>6</sup>. The number of pixels with other grayscale values is extremely small, resulting in an &#x0201c;L&#x0201d; shape in the histogram curve. In this scenario, the variation in this curve is hardly visible when the camera exposure time is changed. Therefore, this histogram curve cannot be directly utilized for adaptive control.</p><p>When a laser stripe is projected onto an object, the reflected light carries the geometric information of the profile. The grayscale value of each pixel, <italic toggle="yes">T</italic>, in the image can be expressed by<disp-formula id="FD1-sensors-25-01195"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:mi>s</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>&#x003b5;</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">t</italic> is the exposure time, <italic toggle="yes">&#x003b1;</italic> is the amplification circuit gain, <italic toggle="yes">p</italic> is the charge transfer efficiency, <italic toggle="yes">R</italic> is the sensitivity, <italic toggle="yes">s</italic> is the pixel area, <italic toggle="yes">I<sub>d</sub></italic> is the diffuse intensity, <italic toggle="yes">I<sub>s</sub></italic> is the specular intensity, <italic toggle="yes">I<sub>e</sub></italic> is the reflected intensity of ambient light, and <italic toggle="yes">&#x003b5;</italic> represents the noise. It can be seen that the grayscale value of the pixel is linearly related to the exposure time. For this special illumination scenario of laser stripes, the number of pixels with different grayscale values varies with the exposure time, as shown in <xref rid="sensors-25-01195-f003" ref-type="fig">Figure 3</xref>.</p><p>Due to the narrow and thin characteristics of the laser stripe, the gray value of the pixels on the stripe firstly increases to <italic toggle="yes">I</italic><sub>1</sub> when the exposure time increases by &#x00394;<italic toggle="yes">t</italic>. Assuming the number of pixels is <italic toggle="yes">N</italic><sub>1</sub> for <italic toggle="yes">I</italic><sub>1</sub>, the remaining pixels with the grayscale value <italic toggle="yes">I</italic><sub>0</sub> changes from the initial value of <italic toggle="yes">N</italic><sub>0</sub> to <italic toggle="yes">N</italic><sub>0</sub> &#x02212; <italic toggle="yes">N</italic><sub>1</sub>. As can be seen from Equation (1), the gray values of all pixels on the stripe increase with the exposure time. When the exposure time increases by another &#x00394;<italic toggle="yes">t</italic>, the gray value of these stripe pixels further increases and &#x0201c;migrates&#x0201d; to <italic toggle="yes">I</italic><sub>2</sub>. At this time, another <italic toggle="yes">N</italic><sub>2</sub> pixel increases from the total pixels to <italic toggle="yes">I</italic><sub>2</sub>, and so on until <italic toggle="yes">N</italic><sub>1</sub> reaches <italic toggle="yes">I</italic><sub>255</sub> and is saturated.</p><p>The total number of pixels, <italic toggle="yes">N</italic><sub>0</sub>, does not change along with the exposure time. Assume that the camera exposure time increases uniformly by <italic toggle="yes">&#x003bb;</italic> times, and the number of migrated pixels is <italic toggle="yes">N<sub>k</sub></italic>. The number of pixels corresponding to each gray value is logarithmically processed and then summed as<disp-formula id="FD2-sensors-25-01195"><label>(2)</label><mml:math id="mm2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mfenced><mml:mrow><mml:mi>&#x003bb;</mml:mi><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>log</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Since <italic toggle="yes">N</italic><sub>0</sub> &#x02248; 1.3 &#x000d7; 10<sup>6</sup>, the number of pixels on the laser stripe, <italic toggle="yes">&#x003bb;N<sub>k</sub></italic>, is about 1.3 &#x000d7; 10<sup>4</sup> under normal exposure conditions (the width of the stripe is calculated as 10 pixels). Therefore, log(<italic toggle="yes">N</italic><sub>0</sub> &#x02212; <italic toggle="yes">&#x003bb;N<sub>k</sub></italic>) &#x02248; log(<italic toggle="yes">N</italic><sub>0</sub>), <italic toggle="yes">f</italic>(<italic toggle="yes">&#x003bb;</italic>&#x00394;<italic toggle="yes">t</italic>) increases approximately linearly with the exposure time. To illustrate the relationship between the gray distribution and the exposure time more clearly, we calculate the logarithmic curve of the gray distribution by Equation (3).<disp-formula id="FD3-sensors-25-01195"><label>(3)</label><mml:math id="mm3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mfenced><mml:mi>I</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>H</mml:mi><mml:mfenced><mml:mi>I</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">H</italic>(<italic toggle="yes">I</italic>) is the gray distribution of the current stripe image plus 1 to avoid singular values. Furthermore, the stripe quality at exposure time <italic toggle="yes">t</italic> is defined as<disp-formula id="FD4-sensors-25-01195"><label>(4)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mfenced><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>255</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mi>Q</mml:mi><mml:mfenced><mml:mi>I</mml:mi></mml:mfenced></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In this case, the deviation in the quality parameters between the current and the reference stripe is<disp-formula id="FD5-sensors-25-01195"><label>(5)</label><mml:math id="mm5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mfenced><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>255</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>log</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>H</mml:mi><mml:mfenced><mml:mi>I</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>log</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:msub><mml:mi>H</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mfenced><mml:mi>I</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where &#x003b1; is the ratio of the number of effective cross-sections, and <italic toggle="yes">H<sub>r</sub></italic>(<italic toggle="yes">I</italic>) is the gray distribution of the reference stripe image.</p></sec><sec id="sec2dot3-sensors-25-01195"><title>2.3. Adaptive Control of Exposure Time</title><p>The block diagram of the adaptive control system is shown in <xref rid="sensors-25-01195-f004" ref-type="fig">Figure 4</xref>. When adaptive control is not applied, the measurement process is typically accomplished through the following steps: capturing the stripe images, extracting the stripe center points, and computing the measurement profile according to the camera&#x02019;s intrinsic parameters and the equation of laser plane. The exposure time of the camera is fixed for the entire scanning process. Nevertheless, the surface characteristics of the object may change during the measurement process, which makes it difficult to ensure the quality of the laser stripe.</p><p>Based on the gray distribution curve, the stripe quality value can be calculated in real time according to Equation (4). Simultaneously, the occlusion ratio &#x003b1; of the image and the reference stripe quality value can be calculated according to the center extraction result. By comparing the current stripe quality value with the reference value, the deviation of stripe quality <italic toggle="yes">E</italic>(<italic toggle="yes">t</italic>) can be obtained. Here, <italic toggle="yes">&#x003b2;</italic> is a conversion factor that connects the stripe quality values and camera exposure time, <italic toggle="yes">E<sub>f</sub></italic>(<italic toggle="yes">t</italic>) is the filtered result of <italic toggle="yes">E</italic>(<italic toggle="yes">t</italic>), and <italic toggle="yes">K<sub>p</sub></italic> is the proportional gain. When the stripe quality value is consistent with that of the ideal stripe image, the camera achieves the optimal exposure time and a high-quality stripe image can be obtained.</p></sec></sec><sec id="sec3-sensors-25-01195"><title>3. Experiment and Discussion</title><sec id="sec3dot1-sensors-25-01195"><title>3.1. Relationship Between Exposure Time and Stripe Quality</title><p>To analyze the influence of exposure time on the quality values of laser stripe, objects with different materials and colors are selected to obtain the logarithmic curves under different exposure times, as shown in <xref rid="sensors-25-01195-f005" ref-type="fig">Figure 5</xref>a&#x02013;c. For these cases, it can be seen that the number of large gray pixels increases with the exposure time. The gray logarithmic curves move upwards and the area under the curve becomes larger. Thus, the value of image quality <italic toggle="yes">F</italic>(<italic toggle="yes">t</italic>) also increases. The lighter the color of the measured surface, the more significant the upward shift in the curves, and higher-quality values can be obtained by integration. The logarithmic curve reaches its maximum value at zero, which indicates that the gray values of most pixels are zero under normal circumstances. The stripe images are processed using a computer with an Intel i5-3470 CPU and 4GB RAM. The computation time for each stripe quality value is 1.8ms, which has been reduced effectively compared with the width computation method [<xref rid="B30-sensors-25-01195" ref-type="bibr">30</xref>].</p><p>The corresponding curves, <italic toggle="yes">F</italic>(<italic toggle="yes">t</italic>), can be obtained for the three cases, as shown in <xref rid="sensors-25-01195-f005" ref-type="fig">Figure 5</xref>d. It can be observed that <italic toggle="yes">F</italic>(<italic toggle="yes">t</italic>) exhibits an approximately linear relationship with the exposure time, which is also consistent with the conclusion drawn from the analysis of Equation (2). The exposure time has included all of the cases, from under- to overexposure. This indicates that the stripe quality can be evaluated by Equation (4), and the conversion coefficient <italic toggle="yes">&#x003b2;</italic> between the quality parameter and the camera exposure time can be determined by fitting the curves in <xref rid="sensors-25-01195-f005" ref-type="fig">Figure 5</xref>d. The proposed quality parameters change linearly with the exposure time, which is beneficial to the adaptive control. Although the values of <italic toggle="yes">&#x003b2;</italic> are different for different surface colors, it does not affect the control performance. When the measurement is performed on the brown surface, <italic toggle="yes">&#x003b2;</italic> can be obtained as 0.053 through linear fitting.</p></sec><sec id="sec3dot2-sensors-25-01195"><title>3.2. Control Performance Analysis</title><p>To validate the effectiveness of the adaptive control method, color stripes are printed on a piece of paper, and it is then folded into an &#x0201c;M&#x0201d; shape, as shown in <xref rid="sensors-25-01195-f006" ref-type="fig">Figure 6</xref>a. The laser line is carefully adjusted to align with the stripes, and the scanning direction is perpendicular to them. This configuration is beneficial for analyzing the adaptive adjustment process of the exposure time. The exposure time can be manually adjusted to an optimal value at the initial position. When adaptive control is not applied, the camera exposure time remains constant throughout the whole measurement process. When a darker-color stripe is scanned, the deviation in stripe quality parameter <italic toggle="yes">E</italic>(<italic toggle="yes">t</italic>) is reduced to a negative value. In this case, part of the laser stripes may become too dark to extract center points. Moreover, when the laser plane intersects the high reflective regions, the laser stripe may become overexposed, leading to a large positive deviation, as shown in <xref rid="sensors-25-01195-f006" ref-type="fig">Figure 6</xref>b.</p><p>When adaptive control is implemented, the exposure time can be adjusted during the same scanning process. This adjustment ensures that the deviation of stripe quality remains within the ideal range. The adaptive adjustment process of the stripe quality and camera exposure time over the entire measuring process is shown in <xref rid="sensors-25-01195-f006" ref-type="fig">Figure 6</xref>c. The camera&#x02019;s exposure time increases in areas with low reflectivity and decreases at high-reflectivity regions. This ensures that <italic toggle="yes">E</italic>(<italic toggle="yes">t</italic>) is within an ideal range.</p><p>The measurement results obtained without and with adaptive control are shown in <xref rid="sensors-25-01195-f007" ref-type="fig">Figure 7</xref>. Without adaptive control, the problem of underexposure exists in the low-reflectivity area, resulting in the loss of measurement data points, as shown in <xref rid="sensors-25-01195-f007" ref-type="fig">Figure 7</xref>a. When the adaptive control is employed, the measured result exhibits better integrity, as shown in <xref rid="sensors-25-01195-f007" ref-type="fig">Figure 7</xref>b. This further validates the superiority of the adaptive control method.</p><p>The proportional coefficient <italic toggle="yes">K<sub>p</sub></italic> has a significant influence on the control performance. The adaptive adjustment process of exposure time is analyzed when the surface color changes abruptly (dark blue to beige). When <italic toggle="yes">K<sub>p</sub></italic> = 0.2, the adjustment process is slow, as shown by <xref rid="sensors-25-01195-f008" ref-type="fig">Figure 8</xref>a. The exposure time cannot be tuned to the desired value in time, leading to an excessive deviation in quality parameters. It can also be seen that the fluctuation in the stripe quality has little influence on camera exposure time, resulting in a more stable exposure time. When <italic toggle="yes">K<sub>p</sub></italic> is increased to 1.0, the maximum deviation of <italic toggle="yes">E</italic>(<italic toggle="yes">t</italic>) is rapidly reduced to the stable region, as shown in <xref rid="sensors-25-01195-f008" ref-type="fig">Figure 8</xref>b. The overshoot is only 2.7% and can quickly reach a stable state. As <italic toggle="yes">K<sub>p</sub></italic> continues to increase, the maximum deviation decreases, yet not significantly, due to the oscillatory instability, as shown in <xref rid="sensors-25-01195-f008" ref-type="fig">Figure 8</xref>c.</p><p>To further investigate the relationship between the system performance and K<italic toggle="yes"><sub>p</sub></italic>, the maximum deviations (MDs) are obtained and shown in <xref rid="sensors-25-01195-t001" ref-type="table">Table 1</xref>. It can be seen that the MD decreases when <italic toggle="yes">K<sub>p</sub></italic> increases. The stable time is computed with a tolerance of &#x025b3; = 5%. When <italic toggle="yes">K<sub>p</sub></italic> = 1.0, it also rapidly decreases to 25 ms. However, when <italic toggle="yes">K<sub>p</sub></italic> is larger than 1.0, the stable time no longer decreases significantly. This is due to the instability of the system. Through the above experiments, it can be seen that the adaptive control system can successfully achieve the adaptive control according to the color of measured object. The stable time can be controlled within 30ms, even in the case of sudden color change. Thus, adaptive control can be realized during the scanning process.</p></sec><sec id="sec3dot3-sensors-25-01195"><title>3.3. Occlusion</title><p>The measurement results are influenced not only by color, but also by geometry. When the object has a complex geometry, part of the stripe may be blocked by itself. To ensure the control stability, a coefficient of effective laser stripe, &#x003b1;, is introduced. The object is shown in <xref rid="sensors-25-01195-f009" ref-type="fig">Figure 9</xref>a. The whole measurement process can be divided into five stages: p<sub>1</sub>&#x02014;the laser plane does not intersect the object, p<sub>2</sub>&#x02014;the laser plane intersects the side of the object, p<sub>3</sub>&#x02014;the laser plane intersects the top surface, p<sub>4</sub>&#x02014;part of the stripe is blocked, and p<sub>5</sub>&#x02014;the stripe moves out of the occlusion area. The typical stripe images corresponding to these stages are shown in <xref rid="sensors-25-01195-f009" ref-type="fig">Figure 9</xref>b.</p><p>The adaptive controlled exposure time during the scanning process is shown in <xref rid="sensors-25-01195-f009" ref-type="fig">Figure 9</xref>c. When the laser plane does not intersect the surface, the system automatically adjusts the exposure time to a stable value of approximately 4 ms. When the laser stripe is projected onto the side of the object, the light intensity reflected into the camera increases dramatically since this surface faces the camera. The stripe quality parameter also increases. To keep the quality parameter within the desired range, the control system adjusts the deviation by reducing the exposure time. When the laser stripe moves onto the top surface, the exposure time automatically increases due to the darker color. When part of the stripe is blocked, the control system can still modulate the quality parameters of the laser stripe. Therefore, the adaptive control has been realized for the whole scanning. <xref rid="sensors-25-01195-f009" ref-type="fig">Figure 9</xref>d is the measurement result which further validates the effectiveness of the control method.</p></sec><sec id="sec3dot4-sensors-25-01195"><title>3.4. Plane Measurement</title><p>To evaluate the performance of the control system, three typical planes with different materials and colors were measured. <xref rid="sensors-25-01195-f010" ref-type="fig">Figure 10</xref>a shows a precision aluminum plane, <xref rid="sensors-25-01195-f010" ref-type="fig">Figure 10</xref>b shows a polyurethane part after precision milling, and <xref rid="sensors-25-01195-f010" ref-type="fig">Figure 10</xref>c shows a ceramic plane (Al<sub>2</sub>O<sub>3</sub>). For conventional LSLSs, the camera&#x02019;s exposure time is usually identical in the measurement of different surfaces or manually adjusted to a fixed value according to the material of measured surfaces.</p><p>The scanning processes of the aforementioned surfaces are carried out with different exposure times. The point cloud data of the aluminum plane are shown in <xref rid="sensors-25-01195-f011" ref-type="fig">Figure 11</xref>. When the exposure time is 1 ms, dense points can be obtained only in the center region. Massive points are lost at the edge due to underexposure. As the exposure time increases, the underexposed part of the laser stripe gradually reaches the threshold value, enabling the extraction of the stripe&#x02019;s center.</p><p>As the exposure time increases, the number of effective points can be significantly improved. For further analysis, the measurement results are corrected through plane fitting to remove the inclined component. The residual data are shown in <xref rid="sensors-25-01195-f012" ref-type="fig">Figure 12</xref>a,b. When adaptive control is implemented, partial images of the laser stripe are taken on the above three surfaces, and the center extraction results are shown in <xref rid="sensors-25-01195-f012" ref-type="fig">Figure 12</xref>c,d. It can be observed that for the aluminum plane, the middle region is overexposed, resulting in a large measurement error. For the ceramic plane, the laser stripes are more homogeneous, and a better center extraction result is achieved. Here, the width of the laser stripe with adaptive control ranges from 8 to 10 pixels. This is consistent with the conclusion in reference [<xref rid="B31-sensors-25-01195" ref-type="bibr">31</xref>] that the uncertainty of the center extraction results achieves the smallest value when the stripe width ranges from 8 to 10 pixels.</p><p>The PV (Peak-to-Valley), AVR (average), and RMS (Root Mean Square) values of the three different measured surfaces were calculated at various exposure times, including the optimal time derived from adaptive control. The results are presented in <xref rid="sensors-25-01195-t002" ref-type="table">Table 2</xref>, <xref rid="sensors-25-01195-t003" ref-type="table">Table 3</xref> and <xref rid="sensors-25-01195-t004" ref-type="table">Table 4</xref>. For ceramic and aluminum planes, the PV value increases with the exposure time. The ceramic plane is white, and the laser stripe can reach a satisfied width at an exposure time of 1ms. On the other hand, the aluminum plane demonstrates a specular phenomenon, which makes part of laser stripe overexposed. The PV values also increase steadily with the increase in the exposure time.</p></sec><sec id="sec3dot5-sensors-25-01195"><title>3.5. Measurement and Analysis of Complex Surfaces</title><p>To further validate the feasibility of the method, experiments were carried out on complex surfaces with different materials. <xref rid="sensors-25-01195-f013" ref-type="fig">Figure 13</xref>a shows three parts to be measured. The first one is a hyperboloid surface, on which several characters were carved. It was made of polyurethane, which has excellent diffuse reflection characteristics. The second one is an aluminum part which has a precision milled freeform surface. The third one is a ceramic part with rich colors. For the polyurethane plane in <xref rid="sensors-25-01195-f010" ref-type="fig">Figure 10</xref>b, it is easy to obtain ideal measurement results. However, for the complex surface in <xref rid="sensors-25-01195-f013" ref-type="fig">Figure 13</xref>a, the angle between the normal surface and the camera&#x02019;s optical axis varies greatly. When this angle is small, the light entering the camera is intense, and overexposure is likely to occur. Conversely, when the angle is too large, the light entering the camera is weak, resulting in underexposure. This causes the loss of measurement points, as shown in <xref rid="sensors-25-01195-f013" ref-type="fig">Figure 13</xref>b. After measuring the polyurethane plane, the optimal exposure time is selected and is then directly applied to measure the aluminum and ceramic surfaces. In this situation, a large number of missing points can be observed, indicating that the optimal exposure time is not the same for different materials. However, when the adaptive control method is employed, the system can automatically adjust the exposure time based on the shape, surface material, roughness, and color of the measured surface. The improvement can be seen in <xref rid="sensors-25-01195-f013" ref-type="fig">Figure 13</xref>c.</p><p>For each intersection profile, the number of ideal center points should be equal to the column number of the stripe image. However, when the maximum gray value of a specific cross-section profile is less than the threshold <italic toggle="yes">T<sub>g</sub></italic> = 70, the center point of this profile is not computed. This situation includes two possibilities. The cross-section profile is underexposed, or there is no stripe presented due to self-blocking. Otherwise, one center point can be computed for this column of the stripe. The ratio of effective points, <italic toggle="yes">Q</italic><sub>eff</sub>, can be defined as<disp-formula id="FD6-sensors-25-01195"><label>(6)</label><mml:math id="mm6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>eff</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>eff</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:msub><mml:mo>&#x022c5;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>val</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>&#x022c5;</mml:mo><mml:mn>100</mml:mn><mml:mo>%</mml:mo><mml:mo>&#x000a0;</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">N</italic><sub>eff</sub> is the total number of effective points, <italic toggle="yes">V<sub>c</sub></italic> is the column of each stripe image, and <italic toggle="yes">N</italic><sub>val</sub> is the number of stripe images. The ratio of effective points is presented in <xref rid="sensors-25-01195-t005" ref-type="table">Table 5</xref>. It is evident that <italic toggle="yes">Q</italic><sub>eff</sub> can be notably enhanced for all scenarios by employing the adaptive control method.</p><p>Not only is the quantity of the point cloud important, so is the quality. The measured point cloud depends on the quality of the stripe images. Different objects (or even different areas of the same part) have diverse shapes and colors. If a fixed exposure time is adopted for the traditional sensors, the stripe image may experience underexposure or overexposure. <xref rid="sensors-25-01195-f014" ref-type="fig">Figure 14</xref> shows a cross-sectional result during the scanning process of the ceramic part. <xref rid="sensors-25-01195-f014" ref-type="fig">Figure 14</xref>a illustrates the camera exposure time and stripe quality with adaptive control. It can be seen that the exposure time can be adjusted adaptively with the change in the surface, ensuring the stripe quality deviation within the ideal range. If a fixed exposure time (<italic toggle="yes">t</italic> = 2.5 ms) is employed, overexposure occurs when the laser stripe is scanned to this cross-section profile, as shown in <xref rid="sensors-25-01195-f014" ref-type="fig">Figure 14</xref>b. Overexposure leads to incorrect stripe center points. When adaptive control is applied, the system automatically reduces the camera&#x02019;s exposure time, and the stripe center points are more accurate, as shown in <xref rid="sensors-25-01195-f014" ref-type="fig">Figure 14</xref>c. This further validates the necessity of the adaptive control method.</p></sec></sec><sec sec-type="conclusions" id="sec4-sensors-25-01195"><title>4. Conclusions</title><p>This paper proposed an adaptive control method for LSLMS. The method incorporates a quality evaluation strategy of stripe images based on global grayscale statistics. The relationship between the quality parameters of laser stripe and the camera exposure time is derived and analyzed. We find that the proposed stripe quality value grows linearly with the exposure time, which is beneficial for the adaptive control. In addition, the influence of the proportional coefficient on system performance is analyzed. The optimal performance can be achieved when the proportional coefficient is 1.0. With the control method, the camera&#x02019;s exposure time is automatically adjusted according to the color of the measured surface. The laser stripe quality parameter can be controlled within the desired range and better results can be achieved. The measurement results of complex surfaces show that the adaptive control method improves the completeness and accuracy. It also has the advantages of simplicity and ease of use. In the future, intelligent control algorithms can be introduced to further improve the performance of the control system.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, Y.L.; Data curation, Q.Z.; Formal analysis, Y.L.; Funding acquisition, Y.L.; Investigation, H.Z.; Methodology, P.H. and J.Z.; Project administration, J.Z.; Software, Q.Z., P.H. and H.Z.; Validation, Q.Z., Z.Z. and X.L.; Writing&#x02014;original draft, Y.L. and Z.Z.; Writing&#x02014;review and editing, P.H., X.L. and J.Z. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data are contained within the article.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01195"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Guo</surname><given-names>D.</given-names></name>
<name><surname>Cui</surname><given-names>J.</given-names></name>
<name><surname>Chen</surname><given-names>Y.</given-names></name>
<name><surname>Wu</surname><given-names>Y.</given-names></name>
</person-group><article-title>Line structured light calibration based on a freely placed single cylindrical object</article-title><source>Opt. Lasers Eng.</source><year>2024</year><volume>178</volume><fpage>108326</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2024.108236</pub-id></element-citation></ref><ref id="B2-sensors-25-01195"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lin</surname><given-names>H.</given-names></name>
<name><surname>Zhang</surname><given-names>H.</given-names></name>
<name><surname>Huo</surname><given-names>J.</given-names></name>
<name><surname>Li</surname><given-names>J.</given-names></name>
<name><surname>Zhang</surname><given-names>H.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
</person-group><article-title>High-precision 3D reconstruction of underwater concrete using integrated line structured light and stereo vision</article-title><source>Autom. Constr.</source><year>2025</year><volume>169</volume><fpage>105883</fpage><pub-id pub-id-type="doi">10.1016/j.autcon.2024.105883</pub-id></element-citation></ref><ref id="B3-sensors-25-01195"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mao</surname><given-names>Q.</given-names></name>
<name><surname>Cui</surname><given-names>H.</given-names></name>
<name><surname>Hu</surname><given-names>Q.</given-names></name>
<name><surname>Ren</surname><given-names>X.</given-names></name>
</person-group><article-title>A rigorous fastener inspection approach for high-speed railway from structured light sensors</article-title><source>ISPRS J. Photogramm. Remote Sens.</source><year>2018</year><volume>143</volume><fpage>249</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2017.11.007</pub-id></element-citation></ref><ref id="B4-sensors-25-01195"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cheng</surname><given-names>A.</given-names></name>
<name><surname>Lu</surname><given-names>S.</given-names></name>
<name><surname>Gao</surname><given-names>F.</given-names></name>
</person-group><article-title>Anomaly detection of tire tiny text: Mechanism and method</article-title><source>IEEE Trans. Autom. Sci. Eng.</source><year>2024</year><volume>21</volume><fpage>1911</fpage><lpage>1928</lpage><pub-id pub-id-type="doi">10.1109/TASE.2023.3257831</pub-id></element-citation></ref><ref id="B5-sensors-25-01195"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wan</surname><given-names>Z.</given-names></name>
<name><surname>Lai</surname><given-names>L.</given-names></name>
<name><surname>Yin</surname><given-names>X.</given-names></name>
<name><surname>Mao</surname><given-names>J.</given-names></name>
<name><surname>Zhu</surname><given-names>L.</given-names></name>
</person-group><article-title>Robot line structured light vision measurement system: Light strip center extraction and system calibration</article-title><source>Opt. Eng.</source><year>2021</year><volume>60</volume><fpage>114102</fpage><pub-id pub-id-type="doi">10.1117/1.OE.60.11.114102</pub-id></element-citation></ref><ref id="B6-sensors-25-01195"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Fu</surname><given-names>Y.</given-names></name>
<name><surname>Zhong</surname><given-names>K.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Bao</surname><given-names>W.</given-names></name>
</person-group><article-title>A direct calibration method for line structured light measurement system based on parallel lines</article-title><source>Opt. Commun.</source><year>2022</year><volume>508</volume><fpage>127699</fpage><pub-id pub-id-type="doi">10.1016/j.optcom.2021.127699</pub-id></element-citation></ref><ref id="B7-sensors-25-01195"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>Z.</given-names></name>
<name><surname>Zhang</surname><given-names>X.</given-names></name>
<name><surname>Shen</surname><given-names>Y.</given-names></name>
<name><surname>Zheng</surname><given-names>Z.</given-names></name>
</person-group><article-title>Pose calibration of line structured light probe based on ball bar target in cylindrical coordinate measuring machines</article-title><source>Measurement</source><year>2021</year><volume>171</volume><fpage>108760</fpage><pub-id pub-id-type="doi">10.1016/j.measurement.2020.108760</pub-id></element-citation></ref><ref id="B8-sensors-25-01195"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>C.</given-names></name>
<name><surname>Fu</surname><given-names>X.</given-names></name>
<name><surname>Duan</surname><given-names>F.</given-names></name>
<name><surname>Li</surname><given-names>T.</given-names></name>
<name><surname>Li</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>R.</given-names></name>
</person-group><article-title>A novel method to calibrate the rotation axis of a line-structured light 3-dimensional measurement system</article-title><source>Opt. Lasers Eng.</source><year>2023</year><volume>164</volume><fpage>107524</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2023.107524</pub-id></element-citation></ref><ref id="B9-sensors-25-01195"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Zhou</surname><given-names>J.</given-names></name>
<name><surname>Liu</surname><given-names>L.</given-names></name>
</person-group><article-title>Research progress of the line structured light measurement technique</article-title><source>J. Hebei Univ. Sci. Technol.</source><year>2018</year><volume>39</volume><fpage>115</fpage><lpage>124</lpage></element-citation></ref><ref id="B10-sensors-25-01195"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Liu</surname><given-names>Z.</given-names></name>
<name><surname>Li</surname><given-names>M.</given-names></name>
<name><surname>Lu</surname><given-names>X.</given-names></name>
<name><surname>Zhang</surname><given-names>M.</given-names></name>
</person-group><article-title>On-machine detection technology and application progress of high dynamic range fringe structured light</article-title><source>Chin. Opt.</source><year>2024</year><volume>17</volume><fpage>1</fpage><lpage>18</lpage></element-citation></ref><ref id="B11-sensors-25-01195"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Waddington</surname><given-names>C.</given-names></name>
<name><surname>Kofman</surname><given-names>J.</given-names></name>
</person-group><article-title>Camera-independent saturation avoidance in measuring high-reflectivity-variation surfaces using pixel-wise composed images from projected patterns of different maximum gray level</article-title><source>Opt. Commun.</source><year>2014</year><volume>333</volume><fpage>32</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1016/j.optcom.2014.07.039</pub-id></element-citation></ref><ref id="B12-sensors-25-01195"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Babaie</surname><given-names>G.</given-names></name>
<name><surname>Abolbashari</surname><given-names>M.</given-names></name>
<name><surname>Farahi</surname><given-names>F.</given-names></name>
</person-group><article-title>Dynamics range enhancement in digital fringe projection technique</article-title><source>Precis. Eng.</source><year>2015</year><volume>39</volume><fpage>243</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1016/j.precisioneng.2014.06.007</pub-id></element-citation></ref><ref id="B13-sensors-25-01195"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ekstrand</surname><given-names>L.</given-names></name>
<name><surname>Zhang</surname><given-names>S.</given-names></name>
</person-group><article-title>Autoexposure for three-dimensional shape measurement using a digital-light-processing projector</article-title><source>Opt. Eng.</source><year>2011</year><volume>50</volume><fpage>123603</fpage><pub-id pub-id-type="doi">10.1117/1.3662387</pub-id></element-citation></ref><ref id="B14-sensors-25-01195"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jiang</surname><given-names>H.</given-names></name>
<name><surname>Zhao</surname><given-names>H.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
</person-group><article-title>High dynamic range fringe acquisition: A novel 3-D scanning technique for high-reflective surfaces</article-title><source>Opt. Lasers Eng.</source><year>2012</year><volume>50</volume><fpage>1484</fpage><lpage>1493</lpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2011.11.021</pub-id></element-citation></ref><ref id="B15-sensors-25-01195"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Song</surname><given-names>Z.</given-names></name>
<name><surname>Jiang</surname><given-names>H.</given-names></name>
<name><surname>Lin</surname><given-names>H.</given-names></name>
<name><surname>Tang</surname><given-names>S.</given-names></name>
</person-group><article-title>A high dynamic range structured light means for the 3D measurement of specular surface</article-title><source>Opt. Lasers Eng.</source><year>2017</year><volume>95</volume><fpage>8</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2017.03.008</pub-id></element-citation></ref><ref id="B16-sensors-25-01195"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Feng</surname><given-names>S.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Chen</surname><given-names>Q.</given-names></name>
<name><surname>Zuo</surname><given-names>C.</given-names></name>
<name><surname>Li</surname><given-names>R.</given-names></name>
<name><surname>Shen</surname><given-names>G.</given-names></name>
</person-group><article-title>General solution for high dynamic range three-dimensional shape measurement using the fringe projection technique</article-title><source>Opt. Lasers Eng.</source><year>2014</year><volume>59</volume><fpage>56</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2014.03.003</pub-id></element-citation></ref><ref id="B17-sensors-25-01195"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Lin</surname><given-names>H.</given-names></name>
<name><surname>Gao</surname><given-names>J.</given-names></name>
<name><surname>Mei</surname><given-names>Q.</given-names></name>
<name><surname>He</surname><given-names>Y.</given-names></name>
<name><surname>Liu</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
</person-group><article-title>Adaptive digital fringe projection technique for high dynamic range three-dimensional shape measurement</article-title><source>Opt. Express</source><year>2016</year><volume>24</volume><fpage>7703</fpage><lpage>7718</lpage><pub-id pub-id-type="doi">10.1364/OE.24.007703</pub-id><pub-id pub-id-type="pmid">27137056</pub-id>
</element-citation></ref><ref id="B18-sensors-25-01195"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Yang</surname><given-names>Y.</given-names></name>
<name><surname>Xu</surname><given-names>P.</given-names></name>
<name><surname>Liu</surname><given-names>J.</given-names></name>
</person-group><article-title>Adaptive fringe projection algorithm for image saturation suppression</article-title><source>Precis. Eng.</source><year>2023</year><volume>82</volume><fpage>140</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1016/j.precisioneng.2023.03.015</pub-id></element-citation></ref><ref id="B19-sensors-25-01195"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hu</surname><given-names>J.</given-names></name>
<name><surname>Zhu</surname><given-names>J.</given-names></name>
<name><surname>Zhou</surname><given-names>P.</given-names></name>
</person-group><article-title>Efficient 3D measurement of a HDR surface based on adaptive fringe projection</article-title><source>Appl. Opt.</source><year>2022</year><volume>61</volume><fpage>9028</fpage><lpage>9036</lpage><pub-id pub-id-type="doi">10.1364/AO.470064</pub-id><pub-id pub-id-type="pmid">36607032</pub-id>
</element-citation></ref><ref id="B20-sensors-25-01195"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>C.</given-names></name>
<name><surname>Gao</surname><given-names>N.</given-names></name>
<name><surname>Wang</surname><given-names>X.</given-names></name>
<name><surname>Zhang</surname><given-names>Z.</given-names></name>
</person-group><article-title>Adaptive projection intensity adjustment for avoiding saturation in three-dimensional shape measurement</article-title><source>Opt. Commun.</source><year>2018</year><volume>410</volume><fpage>694</fpage><lpage>702</lpage><pub-id pub-id-type="doi">10.1016/j.optcom.2017.11.009</pub-id></element-citation></ref><ref id="B21-sensors-25-01195"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fu</surname><given-names>Y.</given-names></name>
<name><surname>Fan</surname><given-names>J.</given-names></name>
<name><surname>Jing</surname><given-names>F.</given-names></name>
<name><surname>Tan</surname><given-names>M.</given-names></name>
</person-group><article-title>High Dynamic Range Structured Light 3-D Measurement Based on Region Adaptive Fringe Brightness</article-title><source>IEEE Trans. Ind. Electron.</source><year>2024</year><volume>71</volume><fpage>8080</fpage><lpage>8090</lpage><pub-id pub-id-type="doi">10.1109/TIE.2023.3303655</pub-id></element-citation></ref><ref id="B22-sensors-25-01195"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Xu</surname><given-names>P.</given-names></name>
<name><surname>Liu</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>J.</given-names></name>
</person-group><article-title>High dynamic range 3D measurement technique based on adaptive fringe projection and curve fitting</article-title><source>Appl. Opt.</source><year>2023</year><volume>62</volume><fpage>3265</fpage><lpage>3274</lpage><pub-id pub-id-type="doi">10.1364/AO.488583</pub-id><pub-id pub-id-type="pmid">37132826</pub-id>
</element-citation></ref><ref id="B23-sensors-25-01195"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>J.</given-names></name>
<name><surname>Yang</surname><given-names>Y.</given-names></name>
</person-group><article-title>A new method for high dynamic range 3D measurement combining adaptive fringe projection and original-inverse fringe projection</article-title><source>Opt. Lasers Eng.</source><year>2023</year><volume>163</volume><fpage>107490</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2023.107490</pub-id></element-citation></ref><ref id="B24-sensors-25-01195"><label>24.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Schnee</surname><given-names>J.</given-names></name>
<name><surname>Futterlieb</surname><given-names>J.</given-names></name>
</person-group><article-title>Laser Line Segmentation with Dynamic Line Models</article-title><source>Proceedings of the Computer Analysis of Images and Patterns&#x02014;14th International Conference</source><conf-loc>Seville, Spain</conf-loc><conf-date>29&#x02013;31 August 2011</conf-date><comment>Part I (2011)</comment><fpage>126</fpage><lpage>134</lpage></element-citation></ref><ref id="B25-sensors-25-01195"><label>25.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Du</surname><given-names>J.</given-names></name>
<name><surname>Xiong</surname><given-names>W.</given-names></name>
<name><surname>Chen</surname><given-names>W.</given-names></name>
<name><surname>Cheng</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>Y.</given-names></name>
<name><surname>Gu</surname><given-names>Y.</given-names></name>
<name><surname>Chia</surname><given-names>S.C.</given-names></name>
</person-group><article-title>Robust Laser Stripe Extraction Using Ridge Segmentation and Region Ranking for 3D Reconstruction of Reflective and Uneven Surface</article-title><source>Proceedings of the 2015 IEEE International Conference on Image Processing</source><conf-loc>Quebec City, QC, Canada</conf-loc><conf-date>27&#x02013;30 September 2015</conf-date><fpage>27</fpage><lpage>30</lpage></element-citation></ref><ref id="B26-sensors-25-01195"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>F.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Liu</surname><given-names>Z.</given-names></name>
</person-group><article-title>A multi-scale analysis based method for extracting coordinates of laser light stripe centers</article-title><source>Acta Opt. Sin.</source><year>2014</year><volume>34</volume><fpage>1110002</fpage></element-citation></ref><ref id="B27-sensors-25-01195"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Song</surname><given-names>J.</given-names></name>
<name><surname>Sun</surname><given-names>C.</given-names></name>
<name><surname>Wang</surname><given-names>P.</given-names></name>
</person-group><article-title>Techniques of light intensity adaptive adjusting for the 3D measurement system of the solder paste</article-title><source>Chin. J. Sens. Actuators</source><year>2012</year><volume>25</volume><fpage>1166</fpage><lpage>1171</lpage></element-citation></ref><ref id="B28-sensors-25-01195"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Tang</surname><given-names>R.Y.</given-names></name>
<name><surname>Shen</surname><given-names>H.H.</given-names></name>
<name><surname>Hong-Kun</surname><given-names>H.E.</given-names></name>
<name><surname>Gao</surname><given-names>F.</given-names></name>
</person-group><article-title>Adaptive intensity of laser control based on dual-tree complex wavelet transform</article-title><source>Laser</source><year>2015</year><volume>7</volume><fpage>113</fpage><lpage>116</lpage></element-citation></ref><ref id="B29-sensors-25-01195"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Sun</surname><given-names>C.</given-names></name>
<name><surname>Wang</surname><given-names>P.</given-names></name>
</person-group><article-title>The image adaptive method for solder paste 3D measurement system</article-title><source>Opt. Lasers Eng.</source><year>2015</year><volume>66</volume><fpage>41</fpage><lpage>51</lpage></element-citation></ref><ref id="B30-sensors-25-01195"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhou</surname><given-names>J.</given-names></name>
<name><surname>Pan</surname><given-names>L.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
<name><surname>Liu</surname><given-names>P.</given-names></name>
<name><surname>Liu</surname><given-names>L.</given-names></name>
</person-group><article-title>Real-time stripe width computation using back propagation neural network for adaptive control of line structured light sensors</article-title><source>Sensors</source><year>2020</year><volume>20</volume><elocation-id>2618</elocation-id><pub-id pub-id-type="doi">10.3390/s20092618</pub-id><pub-id pub-id-type="pmid">32375352</pub-id>
</element-citation></ref><ref id="B31-sensors-25-01195"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhou</surname><given-names>J.</given-names></name>
<name><surname>Wang</surname><given-names>K.</given-names></name>
<name><surname>Yang</surname><given-names>G.</given-names></name>
<name><surname>Liu</surname><given-names>X.</given-names></name>
<name><surname>Du</surname><given-names>R.</given-names></name>
<name><surname>Li</surname><given-names>Y.</given-names></name>
</person-group><article-title>Real-time uncertainty estimation of stripe center extraction results using adaptive BP neural network</article-title><source>Measurement</source><year>2022</year><volume>194</volume><fpage>111022</fpage><pub-id pub-id-type="doi">10.1016/j.measurement.2022.111022</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01195-f001"><label>Figure 1</label><caption><p>Line-structured light measurement system. (<bold>a</bold>) System components. (<bold>b</bold>) Measurement principle.</p></caption><graphic xlink:href="sensors-25-01195-g001" position="float"/></fig><fig position="float" id="sensors-25-01195-f002"><label>Figure 2</label><caption><p>Image of laser stripe and its corresponding histogram curve.</p></caption><graphic xlink:href="sensors-25-01195-g002" position="float"/></fig><fig position="float" id="sensors-25-01195-f003"><label>Figure 3</label><caption><p>Variation in the number of different grayscale pixels with exposure time.</p></caption><graphic xlink:href="sensors-25-01195-g003" position="float"/></fig><fig position="float" id="sensors-25-01195-f004"><label>Figure 4</label><caption><p>Block diagram of the adaptive control system.</p></caption><graphic xlink:href="sensors-25-01195-g004" position="float"/></fig><fig position="float" id="sensors-25-01195-f005"><label>Figure 5</label><caption><p>Influence of exposure time on stripe quality. (<bold>a</bold>&#x02013;<bold>c</bold>) Logarithmic curves of gray distribution on different surfaces at different exposure times, and (<bold>d</bold>) stripe quality curves of different surfaces under different exposure times.</p></caption><graphic xlink:href="sensors-25-01195-g005" position="float"/></fig><fig position="float" id="sensors-25-01195-f006"><label>Figure 6</label><caption><p>Measurement process without and with adaptive control; (<bold>a</bold>) paper with color stripe, (<bold>b</bold>) without adaptive control, and (<bold>c</bold>) with adaptive control.</p></caption><graphic xlink:href="sensors-25-01195-g006" position="float"/></fig><fig position="float" id="sensors-25-01195-f007"><label>Figure 7</label><caption><p>Measurement results of LSLS for the color stripe surface (<bold>a</bold>) without adaptive control and (<bold>b</bold>) with adaptive control.</p></caption><graphic xlink:href="sensors-25-01195-g007" position="float"/></fig><fig position="float" id="sensors-25-01195-f008"><label>Figure 8</label><caption><p>Changes in surface exposure time and stripe quality under different <italic toggle="yes">K<sub>p</sub></italic> (<bold>a</bold>) <italic toggle="yes">K<sub>p</sub></italic> = 0.2, (<bold>b</bold>) <italic toggle="yes">K<sub>p</sub></italic> = 1.0, (<bold>c</bold>) <italic toggle="yes">K<sub>p</sub></italic> = 4.0.</p></caption><graphic xlink:href="sensors-25-01195-g008" position="float"/></fig><fig position="float" id="sensors-25-01195-f009"><label>Figure 9</label><caption><p>Scanning process and measurement results in the presence of laser stripe occlusion. (<bold>a</bold>) Measured object. (<bold>b</bold>) Images of the light stripe at different positions. (<bold>c</bold>) Changes in exposure time and quality of the stripe in measurement process. (<bold>d</bold>) Measurement results.</p></caption><graphic xlink:href="sensors-25-01195-g009" position="float"/></fig><fig position="float" id="sensors-25-01195-f010"><label>Figure 10</label><caption><p>Flat surfaces of different materials (<bold>a</bold>) aluminum plane, (<bold>b</bold>) polyurethane plane, (<bold>c</bold>) ceramic plane.</p></caption><graphic xlink:href="sensors-25-01195-g010" position="float"/></fig><fig position="float" id="sensors-25-01195-f011"><label>Figure 11</label><caption><p>Measurement results of aluminum plane at different exposure times, (<bold>a</bold>) 1 ms, (<bold>b</bold>) 2 ms, (<bold>c</bold>) 6 ms, and (<bold>d</bold>) 10 ms.</p></caption><graphic xlink:href="sensors-25-01195-g011" position="float"/></fig><fig position="float" id="sensors-25-01195-f012"><label>Figure 12</label><caption><p>Measurement results and corresponding laser stripes: (<bold>a</bold>) aluminum plane, (<bold>b</bold>) ceramic plane, (<bold>c</bold>) laser stripe for aluminum plane, and (<bold>d</bold>) laser stripe for ceramic plane.</p></caption><graphic xlink:href="sensors-25-01195-g012" position="float"/></fig><fig position="float" id="sensors-25-01195-f013"><label>Figure 13</label><caption><p>Typical complex surfaces and measurement results; (<bold>a</bold>) the measured object, (<bold>b</bold>) without adaptive control, and (<bold>c</bold>) with adaptive control.</p></caption><graphic xlink:href="sensors-25-01195-g013" position="float"/></fig><fig position="float" id="sensors-25-01195-f014"><label>Figure 14</label><caption><p>Adaptive measurement process and cross-sectional profile analysis. (<bold>a</bold>) Adaptive control process of exposure time during scanning (<bold>b</bold>) without adaptive control, and (<bold>c</bold>) with adaptive control.</p></caption><graphic xlink:href="sensors-25-01195-g014" position="float"/></fig><table-wrap position="float" id="sensors-25-01195-t001"><object-id pub-id-type="pii">sensors-25-01195-t001_Table 1</object-id><label>Table 1</label><caption><p>System performance under different proportional coefficients.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">K<sub>p</sub></italic>
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">0.2</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">0.6</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1.0</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1.6</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2.0</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">3.0</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">4.0</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">MD</td><td align="center" valign="middle" rowspan="1" colspan="1">157.3</td><td align="center" valign="middle" rowspan="1" colspan="1">117.9</td><td align="center" valign="middle" rowspan="1" colspan="1">80.0</td><td align="center" valign="middle" rowspan="1" colspan="1">59.6</td><td align="center" valign="middle" rowspan="1" colspan="1">47.9</td><td align="center" valign="middle" rowspan="1" colspan="1">34.7</td><td align="center" valign="middle" rowspan="1" colspan="1">25.4</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Stable time (ms)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">36</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">26</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">23</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01195-t002"><object-id pub-id-type="pii">sensors-25-01195-t002_Table 2</object-id><label>Table 2</label><caption><p>Measurement results of the aluminum plane (unit: mm).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Exposure Time</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">6 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">10 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">14 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">18 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Optimal</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">PV</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2608</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2630</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4494</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6056</td><td align="center" valign="middle" rowspan="1" colspan="1">0.6265</td><td align="center" valign="middle" rowspan="1" colspan="1">0.7407</td><td align="center" valign="middle" rowspan="1" colspan="1">0.3112</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">AVR</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0236</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0225</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0239</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0326</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0417</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0502</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0218</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RMS</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0297</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0287</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0313</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0444</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0563</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0689</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0283</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01195-t003"><object-id pub-id-type="pii">sensors-25-01195-t003_Table 3</object-id><label>Table 3</label><caption><p>Measurement results of the polyurethane plane (unit: mm).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Exposure Time</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">6 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">10 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">14 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">18 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Optimal</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">PV</td><td align="center" valign="middle" rowspan="1" colspan="1">0.3260</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2202</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1897</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2257</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2840</td><td align="center" valign="middle" rowspan="1" colspan="1">0.3213</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1859</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">AVR</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0263</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0212</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0182</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0201</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0257</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0286</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0181</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RMS</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0336</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0267</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0230</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0253</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0322</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0361</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0227</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01195-t004"><object-id pub-id-type="pii">sensors-25-01195-t004_Table 4</object-id><label>Table 4</label><caption><p>Measurement results of the ceramic plane (unit: mm).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Exposure Time</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">1 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">2 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">6 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">10 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">14 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">18 ms</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Optimal</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">PV</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1652</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1866</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2598</td><td align="center" valign="middle" rowspan="1" colspan="1">0.3225</td><td align="center" valign="middle" rowspan="1" colspan="1">0.3697</td><td align="center" valign="middle" rowspan="1" colspan="1">0.4875</td><td align="center" valign="middle" rowspan="1" colspan="1">0.1788</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">AVR</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0144</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0136</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0221</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0282</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0384</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0489</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0126</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RMS</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0182</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0172</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0277</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0355</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0482</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0609</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0158</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-01195-t005"><object-id pub-id-type="pii">sensors-25-01195-t005_Table 5</object-id><label>Table 5</label><caption><p>Effect of adaptive control on the effective point ratio of the parts.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Parts with Different Materials</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Polyurethane</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Aluminum</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Ceramic</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Without adaptive control</td><td align="center" valign="middle" rowspan="1" colspan="1">79.2%</td><td align="center" valign="middle" rowspan="1" colspan="1">75.4%</td><td align="center" valign="middle" rowspan="1" colspan="1">68.6%</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">With adaptive control</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.9%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.2%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">70.5%</td></tr></tbody></table></table-wrap></floats-group></article>