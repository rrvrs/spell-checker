<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="review-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40006307</article-id><article-id pub-id-type="pmc">PMC11859953</article-id><article-id pub-id-type="doi">10.3390/s25041078</article-id><article-id pub-id-type="publisher-id">sensors-25-01078</article-id><article-categories><subj-group subj-group-type="heading"><subject>Review</subject></subj-group></article-categories><title-group><article-title>Overview of Respiratory Sensor Solutions to Support Patient Diagnosis and Monitoring</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-2104-7997</contrib-id><name><surname>Karpiel</surname><given-names>Ilona</given-names></name><xref rid="af1-sensors-25-01078" ref-type="aff">1</xref><xref rid="c1-sensors-25-01078" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-3793-5374</contrib-id><name><surname>Mysi&#x00144;ski</surname><given-names>Maciej</given-names></name><xref rid="af1-sensors-25-01078" ref-type="aff">1</xref><xref rid="af2-sensors-25-01078" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0074-4179</contrib-id><name><surname>Olesz</surname><given-names>Kamil</given-names></name><xref rid="af1-sensors-25-01078" ref-type="aff">1</xref><xref rid="af2-sensors-25-01078" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-3896-0547</contrib-id><name><surname>Czerw</surname><given-names>Marek</given-names></name><xref rid="af1-sensors-25-01078" ref-type="aff">1</xref><xref rid="af3-sensors-25-01078" ref-type="aff">3</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Gargiulo</surname><given-names>Gaetano D.</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name><surname>Andreozzi</surname><given-names>Emilio</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-01078"><label>1</label>Lukasiewicz Research Network-Krakow Institute of Technology, Zakopia&#x00144;ska 73, 30-418 Krak&#x000f3;w, Poland; <email>maciej.mysinski@kit.lukasiewicz.gov.pl</email> (M.M.); <email>kamil.olesz@kit.lukasiewicz.gov.pl</email> (K.O.); <email>marek.czerw@kit.lukasiewicz.gov.pl</email> (M.C.)</aff><aff id="af2-sensors-25-01078"><label>2</label>Institute of Biomedical Engineering, Faculty of Science and Technology, University of Silesia in Katowice, 39 B&#x00119;dzi&#x00144;ska, 41-200 Sosnowiec, Poland</aff><aff id="af3-sensors-25-01078"><label>3</label>Department of Biosensors and Processing of Biomedical Signals, Faculty of Biomedical Engineering, Silesian University of Technology, 44-100 Gliwice, Poland</aff><author-notes><corresp id="c1-sensors-25-01078"><label>*</label>Correspondence: <email>ilona.karpiel@kit.lukasiewicz.gov.pl</email></corresp></author-notes><pub-date pub-type="epub"><day>11</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>2</month><year>2025</year></pub-date><volume>25</volume><issue>4</issue><elocation-id>1078</elocation-id><history><date date-type="received"><day>11</day><month>12</month><year>2024</year></date><date date-type="rev-recd"><day>03</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>07</day><month>2</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>Between 2018 and 2024, the global market has experienced significant advancements in sensor technologies for monitoring patients&#x02019; health conditions, which have demonstrated a pivotal role in diagnostics, treatment monitoring, and healthcare optimization. Progress in microelectronics, device miniaturization, and wireless communication technologies has facilitated the development of sophisticated sensors, including wearable devices such as smartwatches and fitness trackers, enabling the real-time monitoring of key health parameters. These devices are widely employed across clinical settings, nursing care, and daily life to collect critical data on vital signs, including heart rate, blood pressure, oxygen saturation, and respiratory rate. A systematic review of the developments within this period highlights the transformative potential of AI and IoT-based technologies in healthcare personalization, particularly in disease symptom prediction and public health management. Furthermore, innovative techniques such as respiratory inductive plethysmography (RIP) and millimeter-wave radar systems (mmTAA) have emerged as precise, non-contact solutions for respiratory monitoring, with applications spanning diagnostics, therapeutic interventions, and enhanced safety in daily life.</p></abstract><kwd-group><kwd>respiratory sensor</kwd><kwd>respiratory monitoring devices</kwd><kwd>wearable respiratory sensors</kwd><kwd>telemedicine in respiratory care</kwd></kwd-group><funding-group><funding-statement>This research received no external funding.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-01078"><title>1. Introduction</title><p>A noticeable trend is the growing popularity of wearable devices, such as smartwatches and fitness bands, which can simply connect to a smartphone&#x02014;a device most people have with them at all times. These devices allow for the measurement of basic health parameters, increasing people&#x02019;s awareness of health. There are also wearable devices, which are medical devices that, through connections to dedicated applications, allow a doctor to monitor health in real time and take faster action on required critical situations. The widespread use of miniaturized and wearable sensors plays a key role in medicine, enabling the remote monitoring of patients by doctors. With the help of such medical devices, doctors can remotely observe health conditions, make precise diagnostic decisions, and adjust therapies according to the current state of health. They do not have to be guided by past results, only, instead, by the current state.</p><p>One of the key issues is the diagnosis of the respiratory system, and the available devices and sensors allow for different observations of respiratory parameters depending on the needs. Using the available devices [<xref rid="B1-sensors-25-01078" ref-type="bibr">1</xref>,<xref rid="B2-sensors-25-01078" ref-type="bibr">2</xref>,<xref rid="B3-sensors-25-01078" ref-type="bibr">3</xref>,<xref rid="B4-sensors-25-01078" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-01078" ref-type="bibr">5</xref>], we can monitor parameters such as respiratory rate (RR), tidal volume (TV), oxygen saturation (SpO2), chest movements, and periods of apnea and hypopnea. These devices also allow for the monitoring of sleep, respiratory rhythm, and changes in body position. Recent years have shown an increase in the importance of respiratory diagnostics for general health assessments, but also for sudden exacerbations of disease. Selecting appropriate diagnostic techniques can help to highlight respiratory problems in specific cases. Various sensors and techniques will be used, for example, to check the status of an asthma exacerbation, to monitor a patient during sleep, or to observe patient parameters in the intensive care unit.</p><p>Moreover, the development of artificial intelligence (AI) has enabled more sophisticated analysis of the data collected by health sensors. AI can help to identify patterns and detect abnormalities in health parameters, which can lead to faster diagnosis and intervention.</p><p>With the increase in health data collection, there are also concerns about data security and patient privacy. Companies and organizations must take precautions to protect this information from unauthorized access. As this technology grows, regulations and standards are also being introduced to ensure the safety and effectiveness of health sensors. Organizations, such as the Food and Drug Administration (FDA) in the United States, are implementing regulations for the registration and approval of such devices. The health sensor market is growing rapidly, and more and more companies are investing in this field. Competition and innovation are contributing to the rapid introduction of new products and lower costs.</p></sec><sec id="sec2-sensors-25-01078"><title>2. Materials and Methods</title><p>This study reviewed the available solutions that emerged between 2018 and 2024, focusing on monitoring or diagnosing patients with upper respiratory tract conditions. The review was conducted without the use of AI tools for generating comparisons. The search for articles was conducted in the IEEE Xplore database between 9 October and 31 October 2024, using terms related to machine learning, artificial intelligence, and respiratory monitoring techniques. Additionally, the GitHub platform was searched for repositories of databases related to respiratory monitoring, which provided additional resources supporting the development of new AI-based solutions. As a result, a full-text review of 111 articles was conducted, from which 77 publications were selected that best met the review criteria. Our team focused on the IEEE Xplore database, considering it to be the most suitable for engineering and technological research, offering more relevant and up-to-date resources compared to databases like PubMed, Scopus, or Web of Science, which focus on other fields. Studies in the review were selected at all stages by three analysts working independently, as shown in <xref rid="sensors-25-01078-f001" ref-type="fig">Figure 1</xref>.</p></sec><sec id="sec3-sensors-25-01078"><title>3. Open Database</title><p>In today&#x02019;s world, medicine and information technology are closely collaborating, leading to increased accessibility and the exchange of medical data. International organizations are developing standards and protocols to facilitate the exchange of medical data between different information systems. Interoperability is crucial for the global exchange of medical information. There is a noticeable trend indicating a growing demand for data, particularly physiological signals, respiratory signals, respiratory parameters, and others. <xref rid="sensors-25-01078-f002" ref-type="fig">Figure 2</xref> presents the number of responses to a query related to signals in the publicly available PhysioNet database. The database was searched and the most relevant keywords were &#x0201c;respiration&#x0201d; and &#x0201c;respiratory,&#x0201d; which together form a dataset of 21 results (with one dataset appearing twice).</p><p>Databases containing signals are essential in the context of modern medicine and information technology because they are key to modern diagnostics and patient monitoring. They are crucial for the development and validation of AI algorithms, and the PhysioNet database provides the actual data needed to train machine learning algorithms. The keyword &#x0201c;Respiration&#x0201d; appears relatively infrequently and the reviewed databases, although widely used, do not respond 100% to market demand and the needs of researchers who are in the process of designing new devices.</p><p>The characteristics (I) of the bases in response to the keyword &#x0201c;respiration&#x0201d; are as follows:<list list-type="bullet"><list-item><p>Simultaneous physiological measurements with five devices at different cognitive and physical loads: Measurement included electrocardiography (ECG), photoplethysmography, accelerometry, oxygen saturation respiration, heart rate (HR), heart rate variability (HRV), and RR intervals ranging from 1 Hz to 8000 Hz [<xref rid="B6-sensors-25-01078" ref-type="bibr">6</xref>].</p></list-item><list-item><p>MIMIC-IV waveform database: The MIMIC-IV waveform database is a collection of physiological signals and measurements from patients in intensive care units, including electrocardiograms, photoplethysmograms, respiratory parameters, blood pressure measured invasively and non-invasively, and other measurements. These measurements and signals are obtained directly from the bedside monitor and provide a detailed picture of the physiology of critically ill patients [<xref rid="B7-sensors-25-01078" ref-type="bibr">7</xref>].</p></list-item><list-item><p>NInFEA: Non-Invasive Multimodal Fetal ECG-Doppler Dataset for Antenatal Cardiology Research: The first publicly available dataset of simultaneous non-invasive electrophysiological recordings, fetal pulsed-wave Doppler (PWD), and maternal respiratory signals [<xref rid="B8-sensors-25-01078" ref-type="bibr">8</xref>].</p></list-item><list-item><p>Electrocardiogram, skin conductance and respiration from spider-fearful individuals watching spider video clips: This project includes an electrocardiogram, skin conductance, and respiration as raw data (unfiltered, unprocessed) recorded from consenting individuals afraid of spiders using a BITalino portable biosignal measurement device (PLUX&#x02014;Wireless Biosignals SA, Lisbon, Portugal) with a sampling rate set to 100 Hz per channel at a resolution of 10 bits [<xref rid="B9-sensors-25-01078" ref-type="bibr">9</xref>].</p></list-item><list-item><p>MIMIC-III waveform database: The MIMIC-III waveform database contains 67,830 sets of records for approximately 30,000 intensive care unit patients. The majority of record sets include a waveform record containing digital signals (usually including ECG, ABP, respiration, and PPG) and a &#x02018;numerical&#x02019; record containing a time series of periodic measurements, each representing a quasi-continuous record of vital signs [<xref rid="B10-sensors-25-01078" ref-type="bibr">10</xref>].</p></list-item><list-item><p>MIMIC-III waveform database matched subset: Matched subset of the &#x02018;MIMIC-III waveform database&#x02019;. Matches records with the older clinical database &#x02018;MIMIC-III clinical database&#x02019;. Contains 22,317 waveform records and 22,247 numerical records for 10,282 different ICU patients [<xref rid="B11-sensors-25-01078" ref-type="bibr">11</xref>].</p></list-item><list-item><p>Cerebral Vasoregulation in Elderly with Stroke: Contains multimodal data from a large study investigating the effects of ischemic stroke on cerebral vasoregulation. The cross sectional study compared 60 subjects who suffered strokes to 60 control subjects, collecting the following data for each patient across multiple days: transcranial Doppler of cerebral arteries, 24 h blood pressure numerics, high resolution waveforms (ECG, blood pressure, CO<sub>2</sub>, and respiration) during various movement tasks, 24 h ECG, EMG (electromyography), accelerometer recordings, and gait pressure recordings during a walking test [<xref rid="B12-sensors-25-01078" ref-type="bibr">12</xref>].</p></list-item><list-item><p>BIDMC PPG and Respiration Dataset: Dataset contains signals and numerics extracted from the larger MIMIC II matched waveform database, along with manual breath annotations made from two annotators using the impedance respiratory signal [<xref rid="B13-sensors-25-01078" ref-type="bibr">13</xref>].</p></list-item></list></p><p>The second characterization (II) of the bases in response to the keyword &#x0201c;respiratory&#x0201d; is as follows:<list list-type="bullet"><list-item><p>Pressure, flow, and dynamic thoraco-abdominal circumferences data for adults breathing under CPAP therapy: This database of respiratory pressure, flow, and dynamic chest and abdominal circumferences was collected from 30 healthy adults at the University of Canterbury. Measurements were made using a bidirectional Venturi taper and a tape measure with rotary encoders, which recorded chest expansion and contraction at different pressures and breathing conditions. The data were intended to validate respiratory monitoring systems for use in primary care and home settings [<xref rid="B14-sensors-25-01078" ref-type="bibr">14</xref>].</p></list-item><list-item><p>Cerebral perfusion and cognitive decline in type 2 diabetes: This collection includes studies on vasoregulation and blood flow involving 70 patients with type 2 diabetes and 70 healthy control patients aged 50&#x02013;85 years [<xref rid="B15-sensors-25-01078" ref-type="bibr">15</xref>].</p></list-item><list-item><p>Cerebromicrovascular Disease in Elderly with Diabetes: This database from a prospective study evaluates the effects of type 2 diabetes on cerebral vasoregulation, perfusion, and functional outcomes in 69 participants aged 55&#x02013;75 with diabetes and in a control group. Data include measurements of blood flow, pressure, heart rate, respiratory parameters, gait, balance, and MRI images, including CASL, FLAIR, and DTI [<xref rid="B16-sensors-25-01078" ref-type="bibr">16</xref>].</p></list-item><list-item><p>CPAP Pressure and Flow Data from a Local Trial of 30 Adults at the University of Canterbury: The study includes pressure and flow measurements during breathing with CPAP (Continuous Positive Airway Pressure) from 30 patients [<xref rid="B17-sensors-25-01078" ref-type="bibr">17</xref>].</p></list-item><list-item><p>Upper body thermal images and associated clinical data from a pilot cohort study of COVID-19: The database contains upper-body thermal recordings from 252 patients in the COVID-19 study who performed breath-holds in four positions. The data include PCR results, demographics, vital signs, activities, medications, respiratory symptoms, and respiratory rate. The aim of the study was to analyze temperature patterns for developing algorithms to analyze thermal recordings [<xref rid="B18-sensors-25-01078" ref-type="bibr">18</xref>].</p></list-item><list-item><p>MIMIC-III and eICU-CRD: Feature Representation by FIDDLE Preprocessing: This collection of data is derived from the MIMIC-III and eICU databases, and includes the features and labels for five prediction tasks related to three adverse outcomes: in-hospital mortality (48 h), acute respiratory failure (4 h, 12 h), and shock (4 h, 12 h) [<xref rid="B19-sensors-25-01078" ref-type="bibr">19</xref>].</p></list-item><list-item><p>Cerebral Vasoregulation in Diabetes: A database of studies evaluating the effects of type 2 diabetes on cerebral vasoregulation and body function. It contains data from 37 diabetics and 49 control subjects aged 55&#x02013;75, with continuous measurements of cerebral blood flow (TCD, MRI), heart rate, blood pressure, respiratory parameters, balance, gait, and laboratory results [<xref rid="B20-sensors-25-01078" ref-type="bibr">20</xref>].</p></list-item><list-item><p>OpenOximetry Repository: The OpenOximetry database contains clinical and laboratory data on pulse oximetry, including high-frequency waveforms, oxygen saturation readings, and other physiological parameters. It enables research on the impact of physiological variables on pulse oximeter performance [<xref rid="B21-sensors-25-01078" ref-type="bibr">21</xref>].</p></list-item><list-item><p>A Temporal Dataset for Respiratory Support in Critically Ill Patients: The dataset includes 90-day hourly respiratory parameters, such as ventilation data, breathing support interventions, and other parameters from 50,920 ICU patients. The data are sourced from MIMIC v2.2 and also contain laboratory results and therapy details [<xref rid="B22-sensors-25-01078" ref-type="bibr">22</xref>].</p></list-item><list-item><p>Respiratory and heart rate monitoring dataset from aeration study: The dataset includes respiratory pressure and flow, electrical impedance tomography (EIT), ECG, and heart rate belt (HRB) data collected from 20 healthy individuals. Participants breathed through a full-face mask with a pressure gauge and flowmeter [<xref rid="B23-sensors-25-01078" ref-type="bibr">23</xref>].</p></list-item><list-item><p>Simulated Obstructive Disease Respiratory Pressure and Flow: The dataset includes respiratory pressure and flow parameters collected from 20 healthy adults simulating COPD effects, such as gas trapping during exhalation. Tests were conducted using a Venturi splitter with a device attached to the oral exhalation outlet [<xref rid="B24-sensors-25-01078" ref-type="bibr">24</xref>].</p></list-item><list-item><p>Respiratory dataset from PEEP study with expiratory occlusion: The dataset includes respiratory pressure and flow, dynamic chest and abdominal circumference data, and aeration from EIT, which were collected from 80 adults. Participants breathed with CPAP support, and the study was conducted with approval from the University of Canterbury HREC [<xref rid="B25-sensors-25-01078" ref-type="bibr">25</xref>].</p></list-item></list></p><p>In addition to the databases appearing in the PhysioNet database, several databases were found that also answer our query and can provide the necessary signals:<list list-type="bullet"><list-item><p>Cough Database contains samples of coughing and other breathing-related sounds. It is a useful source of data for research on respiratory problems [<xref rid="B26-sensors-25-01078" ref-type="bibr">26</xref>].</p></list-item><list-item><p>Polysomnographic databases include the SHHS (Sleep Heart Health Study) or NSRR (National Sleep Research Resource), which contain data related to breathing during sleep [<xref rid="B27-sensors-25-01078" ref-type="bibr">27</xref>,<xref rid="B28-sensors-25-01078" ref-type="bibr">28</xref>].</p></list-item></list></p><p>Projects are also underway to collect a large amount of data:<list list-type="bullet"><list-item><p>Chronic Obstructive Pulmonary Disease Gene &#x0201c;COPDGene&#x0201d; is a multi-center research project to understand and investigate the causes and mechanisms of chronic obstructive pulmonary disease (COPD), a serious respiratory condition [<xref rid="B29-sensors-25-01078" ref-type="bibr">29</xref>].</p></list-item></list></p></sec><sec id="sec4-sensors-25-01078"><title>4. Algorithms</title><p>A sizable portion of the algorithms, programs, and databases that are made available on the Internet and used by the whole world are on the GitHub platform. <xref rid="sensors-25-01078-t001" ref-type="table">Table 1</xref> shows the databases used in the development of new solutions based on AI. The review of repositories was carried out from 9 October 2024 to 31 October 2024. The keyword &#x0201c;Respiration&#x0201d; on the GitHub platform appears 566 times, and &#x0201c;Respiratory&#x0201d; yields 4300 results. Narrowing the search to &#x0201c;Topics&#x0201d;, the word &#x0201c;Respiration&#x0201d; obtains 23 results, and &#x0201c;Respiratory&#x0201d; 14. Other items were not included in the review.</p><p>Unfortunately, the content is not verified, despite the fact that it is a popular way of posting data. There is a lack of order, verification, and review. A sizable part of the content of repositories is empty or contains only part of the code, without descriptions and reliable information. It is worth mentioning that the selected keywords are also related to other topics besides human respiration analysis algorithms, i.e., soil respiration, database intermediary programs, visualization programs (without analysis), libraries for handling integrated circuits, converter schemes, and more. This ambiguity complicates the search for relevant materials and diminishes the usability of these repositories for researchers and developers. To address these challenges, there is a growing need for a structured approach to organizing and verifying data within such repositories. Implementing a standardized method for documenting and reviewing contributions could significantly enhance the quality of shared resources. One promising solution is the concept of the &#x02019;Shared Open Network&#x02019; (SON), which emphasizes collaboration, verification, and transparency among users. By fostering a community-driven environment, SON can facilitate the effective exchange of high-quality information, making it easier for researchers to find credible data and tools tailored to their specific needs. In this way, we can strive toward a more reliable and efficient landscape for data sharing and analysis in various fields, including human respiration studies. In <xref rid="sensors-25-01078-t001" ref-type="table">Table 1</xref>, we present solutions that appear on platforms such as GitHub, blogs, and other open source sources, but none of them are medical devices that could be tested under real-world conditions that could be implemented shortly. Some solutions have been in existence for more than 10 years, and they are still being developed and modified. Still, they are not for the evaluation of physiological parameters in real conditions, including the hospital or home.</p></sec><sec sec-type="results" id="sec5-sensors-25-01078"><title>5. Results</title><p>We conducted a systematic search in one electronic database: IEEE explore. We searched for articles published between January 2018 and October 2024. The search was conducted between 9 October and 31 October, 2024. The reference lists of the included articles were reviewed to check for possible articles that could be included. Regarding search terms, the search strategies applied differed depending on the nature of the databases chosen for the search. For example, PubMed allows for the application of limiters such as &#x0201c;humans&#x0201d; and &#x0201c;English&#x0201d; language articles. The terms identified were (&#x0201c;Artificial Intelligence&#x0201d; OR &#x0201c;Respiratory Belt&#x0201d; OR &#x0201c;Respiratory Inductance Plethysmography&#x0201c; OR &#x0201c;Respiratory Inductive Plethysmography&#x0201d;, OR &#x0201c; Respiratory Sensor&#x0201d;), which are presented in <xref rid="sensors-25-01078-f002" ref-type="fig">Figure 2</xref>.</p><p>We reviewed the full text of 434 articles. The selection process aimed to ensure the inclusion of diverse and high-quality resources, focusing on technical and engineering-oriented solutions in respiratory monitoring. The review may vary depending on the database selected and the keywords chosen by the specialists. Our team chose to review the IEEE Xplore database, which is managed by the Institute of Electrical and Electronics Engineers (IEEE), which focuses mainly on the literature in engineering, computer science, telecommunications, and related technologies. This database was prioritized due to its extensive repository of peer-reviewed articles that align with the technical aspects of our research goals, offering insights into cutting-edge innovations in IoT, AI, and sensor-based respiratory monitoring. Our choice is based on the conviction that IEEE Xplore is a better choice for technical, engineering, and IT research and projects, offering more relevant, up-to-date and industry-specific resources compared to PubMed, which focuses on biomedical sciences. We skipped searching databases such as Scopus and Web of Science, focusing only on one specific one. The table is divided into 4 sections and includes the 74 publications our team selected, taking into account the abbreviated description of the method. To ensure clarity in data categorization, publications were grouped based on their focus areas, including disease detection, AI integration, and real-time monitoring applications.</p><p>Six papers were repeated in response to queries, and six did not fit into our review and were omitted from the review paper description. The review focused on solutions that were dedicated to various conditions, applied or prepared for diagnosis and later therapy, and the real-time monitoring of patients at home and in facilities. Particular emphasis was placed on evaluating the practical application and readiness level of these technologies in clinical and non-clinical environments. There are so many similar solutions, as it turns out, that keywords do not necessarily allow for a precise narrowing of the topic. The abundance of overlapping solutions highlights the challenge of distinguishing innovative methodologies from incremental advancements, necessitating rigorous criteria for inclusion and detailed analysis. <xref rid="sensors-25-01078-t002" ref-type="table">Table 2</xref> shows the results, the areas of which fall into six main groups, i.e., vital signs monitoring [<xref rid="B48-sensors-25-01078" ref-type="bibr">48</xref>,<xref rid="B49-sensors-25-01078" ref-type="bibr">49</xref>], disease detection and diagnosis [<xref rid="B50-sensors-25-01078" ref-type="bibr">50</xref>,<xref rid="B51-sensors-25-01078" ref-type="bibr">51</xref>], application in diagnostic breathing sounds [<xref rid="B52-sensors-25-01078" ref-type="bibr">52</xref>,<xref rid="B53-sensors-25-01078" ref-type="bibr">53</xref>], innovative technologies in disease detection [<xref rid="B54-sensors-25-01078" ref-type="bibr">54</xref>,<xref rid="B55-sensors-25-01078" ref-type="bibr">55</xref>], use of AI in the COVID-19 pandemic [<xref rid="B56-sensors-25-01078" ref-type="bibr">56</xref>,<xref rid="B57-sensors-25-01078" ref-type="bibr">57</xref>], and, in general, the challenges and future of AI in health monitoring.</p><table-wrap position="anchor" id="sensors-25-01078-t002"><object-id pub-id-type="pii">sensors-25-01078-t002_Table 2</object-id><label>Table 2</label><caption><p>Summary of scientific publications on respiratory sensor solutions for patient diagnosis and monitoring.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Authors (Year)</th><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Methods</th><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Description</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Parameters</th></tr></thead><tbody><tr><td colspan="3" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Keywords: Respiratory Belt [Index Terms, Autor Keywords, IEEE Terms]</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Coronel et al., 2021 [<xref rid="B58-sensors-25-01078" ref-type="bibr">58</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3D Camera, SpO2 desaturation.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Using the respiratory signal from a 3D camera, a new algorithm was developed that detects reduced respiratory motion and SpO2 desaturation to evaluate respiratory events</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory motion.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">He et al., 2020 [<xref rid="B59-sensors-25-01078" ref-type="bibr">59</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x0201c;Kinect&#x0201d; sensor, IR-UWB Radar.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A system for monitoring respiratory rate in a room using three impulse radio ultra-wideband (IR-UWB) radars and a Kinect camera. The IR-UWB radar system covers the entire room, allowing for the respiratory monitoring of individuals regardless of their orientation relative to the radar. The Kinect camera tracks 3D joint coordinates, enabling the precise localization of individuals. The results demonstrated high effectiveness in tracking both single and multiple subjects and in estimating respiratory rate.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory motion.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Kusche et al., 2022 [<xref rid="B60-sensors-25-01078" ref-type="bibr">60</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32-channel differential EMG.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A novel non-invasive respiratory monitoring device using a dry electrode belt for capturing diaphragm EMG signals from the thorax.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiration through thorax movement.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Vanbuis et al., 2022 [<xref rid="B61-sensors-25-01078" ref-type="bibr">61</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Cardio-respiratory polysomnography, tracheal sound sensors.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The three-step sleep scoring model for Type III sleep studies was trained and tested using 300 and 100 independent recordings from patients suspected of having sleep breathing disorders, with the steps as follows: classification using a multi-layer perceptron, correction of sleep transition rules according to AASM guidelines, and sequence correction using a Viterbi hidden Markov model.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sound, respiration, heart rate, oxidation.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Alam et al., 2019 [<xref rid="B62-sensors-25-01078" ref-type="bibr">62</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electronic circuit with a push button (Arduino) integrated into a chest belt.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A non-invasive, wearable solution to track and analyze respiratory rate in real time. The circuit detects chest movements associated with breathing, and the push button registers these movements to calculate and display the respiratory rate via a Bluetooth application.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Qiu et al., 2021 [<xref rid="B63-sensors-25-01078" ref-type="bibr">63</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Two-electrode bioimpedance (BioZ) sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">It can be used for the accurate monitoring of breathing rate in both static and dynamic conditions, including the calculation of the respiratory rate. The sensor measures the change in chest impedance resulting from breathing. Additionally, an integrated medical-grade infrared temperature sensor allows for body temperature measurement. The recorded data are transmitted via a Bluetooth module to a computer for processing and visualization.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Sharma et al., 2019 [<xref rid="B64-sensors-25-01078" ref-type="bibr">64</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Radio frequency (RF) sensor (near-field coherent sensing) placed near the xiphoid process.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The sensor uses an RF signal at a frequency of 1.8 GHz, which is modulated by the movement of internal organs and then received and demodulated by the receiving antenna. This sensor enables the monitoring of breathing rate and lung volume by detecting peaks in the respiratory cycle.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, lung volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Laufer et al., 2020 [<xref rid="B65-sensors-25-01078" ref-type="bibr">65</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Thoracic belt to measure changes in the circumference of the chest or abdomen.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">This belt allows for the accurate monitoring of changes in body circumference, enabling the determination of respiratory parameters such as breathing rate. The measurement results were compared with a motion capture system, which served as a reference.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Nedoma et al., 2018 [<xref rid="B66-sensors-25-01078" ref-type="bibr">66</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Optical interferometric sensor based on fiber-optic and connected to an optical interrogator.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Measures respiratory rate and pulse rate and allows for the improvement of MR images of the head, compensating the respiratory motion. The sensor is encased in a thin layer of polyurethane, which provides immunity to electromagnetic interference (EMI) and allows its use in environments with magnetic resonance imaging (MRI).</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, heart rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Shakhih et al., 2018 [<xref rid="B67-sensors-25-01078" ref-type="bibr">67</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Infrared thermal imaging camera (ITI).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Uses an infrared thermal imaging camera (ITI) for thermal imaging to assess the timing of inspiration (TI) and expiration (TE) during prolonged expiration breathing.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Nassi et al., 2022 [<xref rid="B68-sensors-25-01078" ref-type="bibr">68</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Polysomnography, artificial neural network.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Uses a neural network (WaveNet) to analyze 9656 polysomnographic recordings from Massachusetts General Hospital (MGH). It detects obstructive apnea, central apnea, hypopnea, and respiratory effort-related arousals.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, apnea.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Tataraidze et al., 2019 [<xref rid="B69-sensors-25-01078" ref-type="bibr">69</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Wi-Fi signal.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Analyzes channel status information (CSI) from the Wi-Fi connection between the smartphone and the access point for breath detection.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Wang et al., 2021 [<xref rid="B70-sensors-25-01078" ref-type="bibr">70</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breathing sensor in the form of a piezoresistive matrix.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">It is used to monitor force distribution and dynamic resistance waveforms for respiratory rate analysis. The matrix (composed of graphite and silver paste) is placed on the mattress to record changes in the pressure exerted on it during breathing.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Erdyarahman et al., 2022 [<xref rid="B71-sensors-25-01078" ref-type="bibr">71</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A non-contact radar system using frequency-modulated continuous wave (FMCW) technology.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The radar uses frequency-modulated continuous wave (FMCW) technology to monitor small movements in near real time. Electromagnetic waves are emitted by a transmitting antenna (Tx), reflected off a target (e.g., chest), and received by a receiving antenna (Rx).</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Cruz et al., 2021 [<xref rid="B72-sensors-25-01078" ref-type="bibr">72</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pulse oximeter, artificial neural network.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The selected five pulse rate features, namely, time of peaks, peaks, time of valleys, valleys, and time since the last peak, provide a proper estimation of RR. The neural network helps in the classification of the labels of valleys such as inspiration, expiration, and neutral.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate through heart rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Bevilacqua et al., 2022 [<xref rid="B73-sensors-25-01078" ref-type="bibr">73</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Piezoelectric belt, data acquisition is via a DAQ board.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The algorithm takes advantage of an adaptive bandwidth filter to identify the breathing condition and to quantitatively determine the respiratory rate. The algorithm detects moments of dyspnea by identifying outliers. Pocz&#x00105;tek formularzaD&#x000f3;&#x00142; formularza</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Guede-Fernandez et al., 2019 [<xref rid="B74-sensors-25-01078" ref-type="bibr">74</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory inductance plethysmography (RIP) belt.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Drowsiness detection is based on the real-time analysis of respiratory rate variability (RRV) using an RIP belt and signal quality assessment to reduce the number of false alarms associated with body movements. The method includes signal quality assessment to reduce false alarms caused by body movements, rather than drowsiness.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Sanae et al., 2022 [<xref rid="B75-sensors-25-01078" ref-type="bibr">75</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A sensor in the smart seatbelt buckle (SSB) to detect driver drowsiness based on breath duration.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The accuracy of the calculated breath time obtained using the smart seatbelt buckle (SSB) was assessed in comparison to reference respiratory sensors. Subsequently, based on this breath time, an attempt was made to estimate the drowsiness level during driving simulation, achieving a high correlation and indicating the possibility of assessing a drowsiness level of 4 or higher.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Padasdao et al., 2018 [<xref rid="B76-sensors-25-01078" ref-type="bibr">76</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Non-contact detection of chest circumference change.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The sensor uses a modified direct current (dc) motor as an electromagnetic (EM) generator, mounted on the chest, to record changes in chest circumference and tidal volume (TV), while simultaneously generating energy to power the sensor.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Nedoma et al., 2022 [<xref rid="B77-sensors-25-01078" ref-type="bibr">77</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breath sensor (FOBM, pneumatic respiratory belt) in magnetic resonance (MR).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The article described the testing of fiber-optic Bragg grating embedded in an oxygen breathing mask (FOBM) in a real MR environment using 3 T imaging, as well as the comparison of results with other methods, such as the navigator technique and pneumatic respiratory belt. The FOBM approach provides reliable and accurate results, with an overall image quality score of 3.3 &#x000b1; 0.4 for FOBM, compared to 3.7 &#x000b1; 0.5 for the Siemens reference system and 3.8 &#x000b1; 0.2 for respiratory belts.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breath peaks.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">H&#x000e4;rm&#x000e4; et al., 2023 [<xref rid="B78-sensors-25-01078" ref-type="bibr">78</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Deep learning, audio, RIP sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Predicts the next moment of inhalation based on the speaker&#x02019;s speech using deep learning techniques.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Inhalation moment.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Zhang et al., 2021 [<xref rid="B79-sensors-25-01078" ref-type="bibr">79</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Radio frequency (RF) sensor integrated in furniture, near-field coherent sensing (NCS) technique.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A breath sensor integrated into a bed or chair that detects breathing by modifying the structure of a radio frequency (RF) coaxial cable with a designed notch and utilizes the near-field coherent sensing (NCS) technique. The sensor records respiratory waveforms and determines the breathing rate, and it can also assess the heart rate in the same configuration with appropriate filtering. The sensor design is engineered to tolerate significant positional variation, allowing it to adapt to different user positions.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory waveform, respiratory rate, heart rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Mukhopadhyay et al., 2018 [<xref rid="B80-sensors-25-01078" ref-type="bibr">80</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A wearable IoT-based sensor. A pressure-sensitive textile fabric attached to a belt.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Real-time respiratory signal monitoring. The converted-to-electric-signal chest/stomach movement is transmitted to a central base station, where it is displayed in real time and uploaded to an online repository for future analysis.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory waveform.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Addeh et al., 2023 [<xref rid="B81-sensors-25-01078" ref-type="bibr">81</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Elastic band around abdomen, fMRI.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">There is no guarantee that a given respiratory event evident in the abdominal respiratory belt transducer timeseries, such as a deep breath or pause in breathing, will be detectable in both respiratory volume per time (RVT) and respiratory variation (RV). In addition, RVT and RV do not show similar behavior during some respiratory events, especially when the subject breathes deeply at a low rate, while they use similar respiratory response functions.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, breathing pattern.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Piuzzi et al., 2019 [<xref rid="B82-sensors-25-01078" ref-type="bibr">82</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A 1-channel bioimpedance and ECG using a one or two pair electrode configuration.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The measurement performance was compared in two-electrode and four-electrode configurations, assessing the sensitivity of heart activity detection and comparing the results with a respiratory belt and an ECG device.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiration rate and waveform through bioimpedance, ECG.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Erdogan et al., 2019 [<xref rid="B83-sensors-25-01078" ref-type="bibr">83</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A 24 GHz microwave Doppler sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A network system was developed to gather data from distributed nodes, simultaneously monitoring multiple patients and tracking parameters such as temperature, pressure, and humidity. The system also enables real-time monitoring of cough and apnea and provides warning signals to caregivers in emergency situations.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Altekreeti et al., 2021 [<xref rid="B84-sensors-25-01078" ref-type="bibr">84</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Chest belt with force&#x02013;pressure sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A neonatal apnea detection system utilizing a sensor embedded in a soft smart e-textile chest belt that is integrated with a smartphone app.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Zhao et al., 2020 [<xref rid="B85-sensors-25-01078" ref-type="bibr">85</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Doppler radar sensor, depth camera.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Non-contact respiration detection using the fusion of a Doppler radar sensor and depth camera. The proposed fusion scheme, using a Bayesian fusion algorithm, can provide more accurate respiratory rate estimation compared to using a single sensor.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Nabavi et al., 2020 [<xref rid="B86-sensors-25-01078" ref-type="bibr">86</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Direct oral cavity pressure sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Tracks respiratory patterns and detects respiratory events regardless of airway, i.e., nasal and oral. Minimal susceptibility to motion artifacts. Direct measurement of oral pressure with 99% accuracy compared to a reference measurement.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, breathing pattern.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Nallanthighal et al., 2021 [<xref rid="B87-sensors-25-01078" ref-type="bibr">87</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory belt, microphone.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Analysis of breathing belt data and phoneme-matched audio data.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory waveform, speech signal.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Kjar et al., 2021 [<xref rid="B88-sensors-25-01078" ref-type="bibr">88</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Plethysmography belt.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Analysis of respiratory and chest movement patterns using plethysmography belt signals to distinguish between obstructive and central sleep apnea.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Polysomnography (PSG).</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Li et al., 2023 [<xref rid="B89-sensors-25-01078" ref-type="bibr">89</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Four-dimensional imaging radar using a variational mode separation (VMS) algorithm to separate respiratory and cardiac signals.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The proposed VMS algorithm separates the weaker cardiac motion pattern from the stronger respiratory motion pattern, reducing the influence of respiratory harmonics on the heart signal.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, heart rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Torres et al., 2019 [<xref rid="B90-sensors-25-01078" ref-type="bibr">90</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP sensor, mobile app.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The system uses a sensor on a belt, a Raspberry Pi to process the data, and an HTTP server to upload the results to the mobile app. The device has been proven to be effective for people who are uncomfortable using a mouthpiece, and provides a convenient tool for initial lung diagnosis.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Slastnikov et al., 2021 [<xref rid="B91-sensors-25-01078" ref-type="bibr">91</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Review and analysis of methods for detecting the human respiratory wave: MRI with a respiratory belt; the acoustic method; polysomnography using a thermistor and nasal pressure transducer; and implementations of respiratory wave detection based on video signals from RGB, RGB-D, and thermal cameras.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The features of video-based respiratory wave detection in newborns are discussed, and a selected method for the video-based detection of this wave is presented.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory waveform.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Islam et al., [<xref rid="B92-sensors-25-01078" ref-type="bibr">92</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Microwave Doppler radar.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Microwave Doppler radar was used for respiration monitoring, and the feasibility of separating the respiratory signals from multiple subjects was explored using ICA with the JADE algorithm. The method successfully separated signals from two subjects 1 m apart at a distance of 2.89 m from the radar.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory waveform.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Valentina et al., 2018 [<xref rid="B93-sensors-25-01078" ref-type="bibr">93</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory belt, 14-channel electroencephalogram (EEG), 6-channel electrogastrogram (EGG), 1-channel electrooculogram (EOG), 1-channel electrocardiogram.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The study measured brain, eye, cardiac, respiratory, and gastric activity using EEG, EOG, ECG, a respiratory belt, and EGG. Subjects, after fasting, watched film clips with different emotional content, followed by undergoing a water load test. Results showed increased gastric activity in response to emotional stimuli, suggesting central nervous system (CNS) to enteric nervous system (ENS) inhibition, aligning with animal model findings.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breathing pattern, EGG, EEG, EOG, ECG.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Sacco et al., 2020 [<xref rid="B94-sensors-25-01078" ref-type="bibr">94</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Frequency-Modulated Continuous Wave (FMCW) radar</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The 5.8 GHz FMCW radar, specifically designed for measuring respiratory rate and heartbeat, was tested in four orientations of the subject relative to the antenna. Results were compared with photoplethysmograph and respiratory belt measurements, demonstrating high accuracy in all scenarios.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, heart rate</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">W. Kang et al., 2024 [<xref rid="B95-sensors-25-01078" ref-type="bibr">95</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">FMCW radar (Frequency-Modulated Continuous Wave) with a metasurface antenna and passive metasurface tags.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Monitors the breath of the driver and passengers in a car. The use of metasurface tags improves the signal-to-noise ratio and enables the precise differentiation of the breaths of different individuals in the presence of interference inside the vehicle.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">G. Deshpande et al., 2023 [<xref rid="B96-sensors-25-01078" ref-type="bibr">96</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The microphone built into a smartphone.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Extracts breath patterns from speech signals recorded using a smartphone&#x02019;s microphone. The study showed that different categories of breath can be identified based on speech signals with a classification accuracy of 79%.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breathing pattern through speech.</td></tr><tr><td colspan="3" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Keyword: Respiratory Inductance Plethysmography [ALL]</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Elfaramawy et al., 2019 [<xref rid="B97-sensors-25-01078" ref-type="bibr">97</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The Inertial Measurement Unit (IMU) and microphone.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The wireless system uses wearable sensors with a low-power 9-axis IMU and MEMS microphone to monitor breathing and coughing rates in real time. Data processing algorithms calculate respiratory frequency and coughing events. Tests show high accuracy compared to respiratory inductance plethysmography.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, breathing pattern, cough rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Bricout et al., 2019 [<xref rid="B98-sensors-25-01078" ref-type="bibr">98</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Adaptive Accelerometry Derived Respiration (ADR).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The ADR method uses two 3-axis accelerometers to monitor breathing by analyzing chest and abdominal motions. Compared to measuring airflow through the nose, the method achieves 74% agreement, suggesting a high accuracy in assessing respiratory rate and volume.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Bin Nesar et al., 2022 [<xref rid="B99-sensors-25-01078" ref-type="bibr">99</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LiDAR (Light Detection and Ranging) system, multi-pixel thermal sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The system consists of a rotating LiDAR scanner and a multi-pixel thermal sensor. It is used to determine both respiratory rate and tidal volume, and enables posture assessment and the separate evaluation of nasal and mouth breathing.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Sadr et al., 2019 [<xref rid="B100-sensors-25-01078" ref-type="bibr">100</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Electrocardiogram (ECG), respiratory induction plethysmography (RIP).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">ECG and RIP signals were analyzed in different combinations. The QRS area and Principal Component Analysis (P CA) methods were used to estimate ECG-derived respiratory (EDR) signals and Cardiopulmonary Coupling (CPC) spectra. Classification of sleep apnea was performed using Linear Discriminant Analysis (LDA).</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Hurtado et al., 2020 [<xref rid="B101-sensors-25-01078" ref-type="bibr">101</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP belt, temperature sensor, machine learning, Random Forest regression.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Temperature and breathing signals were used to process temperature-related features to train machine learning models to predict TV (tidal volume) and MV (minute ventilation). The best results were obtained with Random Forest regression, achieving minimal error for TV and MV.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Tidal volume, minute ventilation.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Huysmans et al., 2020 [<xref rid="B102-sensors-25-01078" ref-type="bibr">102</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Tachogram, RIP sensor, convolutional neural network (CNN).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Tachogram data and respiratory inductive plethysmography (RIP) signals were used to classify sleep using a 1D convolutional neural network (CNN) to classify 30 s epochs and to detect and classify sleep apnea.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, heart rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Mannee et al., 2020 [<xref rid="B103-sensors-25-01078" ref-type="bibr">103</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP sensor in a smart shirt.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A smart t-shirt with an inductive sensor measures changes in the transverse circumference of the chest and abdomen. It was used to monitor lung hyperinflation (LH). The effects of temperature and girth on the sensor data were tested. The results showed a linear relationship between temperature and RIP signal, and confirmed a linear relationship between girth and sensor signal.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, lung hyperinflation.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Hill et al., 2021 [<xref rid="B104-sensors-25-01078" ref-type="bibr">104</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LiDAR system and thermal sensor in a breathing mask for non-contact breath monitoring.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The system measures changes in respiratory mask temperature and chest and abdominal movements using a thermal sensor and LiDAR system. The results were compared with data from RIP, capnometry, spirometry, and pulse oximetry. A high correlation was obtained between LiDAR measurements and tidal volume values and capnometer data.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Guo et al., 2019 [<xref rid="B105-sensors-25-01078" ref-type="bibr">105</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Flexible Tactile Sensor Array on a mattress.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A system of tactile sensors on a bed was used to distinguish between chest and abdominal movements by measuring pressure changes on the mattress. Tests were conducted, comparing the results with respiratory induction plethysmography (RIP). The sensor showed a high accuracy in measuring respiratory rate, and also noted differences in the phase of pressure changes depending on gender and lying position.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Song et al., 2023 [<xref rid="B106-sensors-25-01078" ref-type="bibr">106</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A bed-sized tactile sensor sheet.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A bed-sized tactile sensor sheet was used to monitor and identify chest and abdominal position and movements during sleep. Optimal measurement areas were studied based on the distribution of body pressure on the mat. A suitable mathematical model and discriminative feature procedure were proposed, which improved the accuracy of the measurements and the usefulness of the method in the early detection of respiratory diseases.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, respiratory pressure distribution.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Rathore et al., 2022 [<xref rid="B107-sensors-25-01078" ref-type="bibr">107</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP sensor, residual fluctuation analysis (DFA).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The utility of respiratory rate (BR) for determining the ventilatory threshold (VT1) was studied in comparison with classical methods based on gas analysis and heart rate (HR). Residual fluctuation analysis (DFA) and respiratory induction plethysmography (RIP) were used to validate the model.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, ventilatory threshold.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Nabavi et al., 2023 [<xref rid="B108-sensors-25-01078" ref-type="bibr">108</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">A sensor based on surface acoustic waves (SAW) near the nose or mouth.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The SAW sensor for continuous breath monitoring, based on humidity measurements, was characterized by high sensitivity and precision in determining the respiratory rate and breath patterns. Its effectiveness has been confirmed through a comparison with a traditional breath monitoring belt.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, breathing pattern.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Akamatsu et al., 2023 [<xref rid="B109-sensors-25-01078" ref-type="bibr">109</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Face image analysis based on video recordings.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The CalibrationPhys method was applied, which enabled the measurement of heart rate and respiratory rate through the analysis of facial images in video. This method uses synchronized recordings from multiple cameras and employs contrastive learning to predict pulse and breath waves.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate and heart rate through facial video.</td></tr><tr><td colspan="3" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Keyword: Respiratory Inductive Plethysmography [ALL]</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Senyurek et al., 2019 [<xref rid="B110-sensors-25-01078" ref-type="bibr">110</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP sensor, AI algorithms.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The inductive sensor monitors changes in chest volume associated with smoking. The study compared the effectiveness of deep learning algorithms, such as convolutional neural networks (CNNs) and Long Short-Term Memory (LSTM), with traditional methods, such as support vector machines (SVMs), Markov models, and decision trees, in detecting smoke inhalation.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Schulz et al., 2018 [<xref rid="B111-sensors-25-01078" ref-type="bibr">111</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP sensor, 64-channel EEG, 3-channel ECG.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The study monitored heart rate (BBI), respiratory rate, and power EEG (PEEG) from a 64-channel EEG in 21 healthy subjects to analyze interactions occurring in the Central Cardiovascular and Respiratory Network (CCRN).</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, heart rate, EEG, ECG.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Azimi et al., 2018 [<xref rid="B112-sensors-25-01078" ref-type="bibr">112</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dual RIP sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The method uses the sum of signals from two RIP sensors as an alternative to the airflow signal in detecting apnea and shallow breathing events.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, apnea.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Mateu-Mateus et al., 2020 [<xref rid="B113-sensors-25-01078" ref-type="bibr">113</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Optical camera with computer algorithms, RIP sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The method uses a camera to track chest movements from a lateral perspective. The algorithm analyzes the consecutive frames of the video in gray tones, which reduces the computational cost and allows for real-time analysis. In addition, a signal quality index is determined.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breathing pattern.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Belsare et al., 2020 [<xref rid="B114-sensors-25-01078" ref-type="bibr">114</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Personal Automatic Cigarette Tracker v2 (PACT-2) is a system that uses an RIP sensor to analyze respiratory signals. It measures parameters such as the duration of inhalation and exhalation, as well as respiratory volume, providing new indicators of the depth and timing of smoke inhalation.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Lyakhova et al., 2018 [<xref rid="B115-sensors-25-01078" ref-type="bibr">115</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Bioimpedance and plethysmography using inductive and piezoelectric sensors.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The wireless device records bioimpedance, inductive plethysmography, and piezoelectric signals, synchronizing the measurements. It analyzes the data in MATLAB, processing the signals and calculating the main relevant parameters.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, respiratory wave.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Huang et al., 2021 [<xref rid="B116-sensors-25-01078" ref-type="bibr">116</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The induction sensor measures chest wall and abdominal movements during the spontaneous breathing test (SBT). The instantaneous phase difference (IPD) method assesses the asynchrony of these movements, supporting extubation.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, spontaneous breathing trial.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Huang et al., 2018 [<xref rid="B117-sensors-25-01078" ref-type="bibr">117</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RIP using the instantaneous phase difference (IPD) method.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The RIP sensor measures tidal volume, and the instantaneous phase difference (IPD) method assesses the synchronization between chest wall movements (TMV) and abdominal wall movements (AWM) in patients with COPD.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Tidal volume.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Zhu et al., 2019 [<xref rid="B118-sensors-25-01078" ref-type="bibr">118</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Infrared camera and video analysis</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The use of an infrared camera and analysis of the recordings tracks the movement of selected feature points on the body of a sleeping patient and extracts the respiratory rate using independent component analysis.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Sol&#x00102;-Soler et al., 2023 [<xref rid="B119-sensors-25-01078" ref-type="bibr">119</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pneumotachograph, RIP belt.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Pneumotachograph and inductive plethysmography belts for breath measurement.Comparison of the breathing pattern characteristics obtained from sensors, pneumotachograph, and inductive plethysmography belts was used to assess breathing variability in healthy volunteers.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breathing pattern.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Zhang et al., 2024 [<xref rid="B120-sensors-25-01078" ref-type="bibr">120</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Millimeter-wave radar (mmWave Radar), AI, RIP for reference.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The mmTAA system, based on millimeter-wave (mmWave) technology, is used for the non-invasive measurement of TAA (Target Angle and Azimuth) and for detecting and monitoring breath without physical contact. It utilizes an mmWave radar with multiple antennas and an advanced neural network, TAANet, which allows for the accurate determination of the centroid position of RC-AB, enabling precise measurements.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breathing pattern.</td></tr><tr><td colspan="3" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Keyword: Artificial Intelligence AND (respiratory signal OR respiratory rate) [Index Terms, Autor Keywords, IEEE Terms]</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Karvounis et al., 2021 [<xref rid="B48-sensors-25-01078" ref-type="bibr">48</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Prototype wrist sensor.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The wrist sensor monitors real-time vital signs such as heart rate, respiratory rate, oxygen saturation, temperature, and changes in systolic blood pressure. The collected data are sent to a cloud-based environment, where it can be processed using machine learning techniques or Information Mining Algorithms. Automatic alerts are sent to medical personnel, enabling quick intervention.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, temperature, SpO2, PPG, ECG, blood pressure, motion.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Chen et al., 2021 [<xref rid="B49-sensors-25-01078" ref-type="bibr">49</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Barometric sensor and signal processing algorithm.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A barometric sensor placed on a desk in a person&#x02019;s environment monitors pressure changes caused by breathing and coughing. A signal processing algorithm is used with a sparsity-based filter. It effectively detects coughing and assesses the respiratory rate, achieving 97.33% accuracy in detecting coughing and 98.98% specificity in assessing breath.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, respiratory waveform, breathing pattern, cough detection.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Jiang et al., 2022 [<xref rid="B50-sensors-25-01078" ref-type="bibr">50</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ECG, 9-axis MEMS IMU sensor, PPG.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The impact of the COVID-19 virus on overall health was discussed, and existing vital sign monitoring systems and their limitations were analyzed. Potential options for estimating lung function using sensor fusion and artificial intelligence (AI) techniques were also explored. The prototype device demonstrated performance comparable to or better than similar commercial devices.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate through ECG, lung volume through IMU sensor, heart rate, cough detection, temperature.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Ghimire et al., 2020 [<xref rid="B121-sensors-25-01078" ref-type="bibr">121</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>An overview of the applications of artificial intelligence, machine learning, and deep learning in solving COVID-19 pandemic problems.</bold>
</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">An overview of the use of artificial intelligence, machine learning, and deep learning in the context of the COVID-19 pandemic. Applications included diagnostics, mortality forecasting, vaccine and drug development, sentiment analysis of comments on COVID-19, and disinformation detection. The review included the most successful models in the field.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Not specified.</bold>
</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Fakotakis et al., 2023 [<xref rid="B122-sensors-25-01078" ref-type="bibr">122</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Acoustic sensor, machine learning techniques.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A monitoring system equipped with an acoustic sensor and sound detection was discussed for recognizing drug activation and assessing medication adherence in patients with asthma. The article presented the use of machine learning techniques in the Respiratory and Drug Actuation suite (RDA) for sound processing, feature extraction, and classification.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sound detection for recognizing drug activation.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Elias et al., 2021 [<xref rid="B123-sensors-25-01078" ref-type="bibr">123</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Acoustic collar, thermoelectric sensor, AI.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">A neck device equipped with acoustic and thermoelectric sensors, linked to an artificial intelligence algorithm, was used for the non-invasive assessment of pathophysiological status and the dynamic observation of lesions resulting from COVID-19 infection. The device effectively distinguished between patients with mild symptoms and those with acute symptoms of respiratory failure.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sound detection of vocal system.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Chawla i Walia, 2022 [<xref rid="B52-sensors-25-01078" ref-type="bibr">52</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AI algorithms to analyze lung images, respiratory sounds, and medical textual data.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Artificial Intelligence based Techniques in Respiratory Healthcare Services: A Review</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Husain et al., 2022 [<xref rid="B124-sensors-25-01078" ref-type="bibr">124</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Review of AI technology for COVID-19 disease detection using cough, breath, and speech recordings.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The review included 24 studies and eight applications using artificial intelligence algorithms to detect COVID-19 from audio recordings of coughs, breathing, and speech. AI-based methods could prove effective in screening and diagnosing respiratory diseases, which could save time and play an important role in the fight against COVID-19 and future pandemics.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Yahyaoui i Yumusak, 2021 [<xref rid="B125-sensors-25-01078" ref-type="bibr">125</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AI algorithms for detecting respiratory diseases</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Deep And Machine Learning Towards Pneumonia And Asthma Detection</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Ward et al., 2021 [<xref rid="B126-sensors-25-01078" ref-type="bibr">126</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Long-wave infrared (LWIR) face detection, deep convolutional network (DNN), cough sounds.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The COVID-19 non-contact symptom detection device uses LWIR face detection to monitor facial temperature and an acoustic sensor and light convolutional network to determine whether a person is coughing. The system was tested on two datasets: one with infrared images of the face and the other with audio recordings of coughing, confirming its effectiveness in detecting symptoms.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Dong i Yao, 2021 [<xref rid="B56-sensors-25-01078" ref-type="bibr">56</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Internet of Things (IoT) technology to monitor physiological parameters, including breathing.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The paper described the application of IoT technology for respiratory monitoring in the context of the COVID-19 pandemic, discussing various methods such as inertial sensors, thermal cameras, optical cameras, microphones, radar, and WiFi. An IoT platform for monitoring COVID-19 was presented, including symptoms, quarantine, contacts, social distance, epidemic forecasting, and virus mutation.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Misra et al., 2023 [<xref rid="B57-sensors-25-01078" ref-type="bibr">57</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">KEdge analytical platform (fuzzy interference system).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">KEdge is an advanced analytics platform that uses IoT sensor data to assess patient health by analyzing physiological parameters such as respiratory rate, ECG signals, pulse rate (PR), blood oxygen saturation (SpO2), and blood pressure. The system uses a two-stage analytical process and a fuzzy inference system (FIS) to assess the severity of cardiac and respiratory conditions and the health condition index (CI).</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, ECG, heart rate, SpO2, blood pressure.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Campana et al., 2022 [<xref rid="B127-sensors-25-01078" ref-type="bibr">127</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">L3-Net deep embedding model for automatic analysis of audible cough and breath samples to identify patients with COVID-19</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">L3-Net, based on Transfer Learning, enables COVID-19 detection from smartphone breath and cough recordings. The model, trained on 2 million audio recordings, effectively extracts hidden audio features, which are analyzed by SVM classifiers and logistic regression. It is suitable for deployment on mobile devices.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Abdullah i Bilal Er, 2022 [<xref rid="B51-sensors-25-01078" ref-type="bibr">51</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Hybrid convolutional neural network (CNN)&#x02013;Long Short-Term Memory (LSTM) model for lung signal classification</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The model combines CNN and LSTM structures to extract features and classify lung sounds as normal or abnormal. It uses Cosine Similarity-based Multilevel Discrete Wavelet Transform Decomposition (CS-MDWTD) and the Butterworth filter for noise reduction, and then classifies sounds using CNN-LSTM networks. The model was tested on the Respiratory Sound Database (ICBHI 2017), achieving a classification accuracy of over 90%.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Rani et al., 2021 [<xref rid="B53-sensors-25-01078" ref-type="bibr">53</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Machine learning classifiers: support vector machine (SVM), k-Nearest Neighbors (KNN), Na&#x000ef;ve Bayes Classifier, and artificial neural networks (ANN); acoustic features of lung sounds.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Automatic lung sound classification model using artificial intelligence (SVM, KNN, Na&#x000ef;ve Bayes, ANN) to diagnose lung diseases. The method identifies various differentiating features of lung sounds, such as the sound of wheezing, which can be useful in the diagnosis of asthma. The model achieved an average accuracy of 95.6%.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Lung sounds.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Grooby et al., 2023 [<xref rid="B54-sensors-25-01078" ref-type="bibr">54</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">An artificial intelligence-based model using non-negative matrix factorization (NMF) and non-negative matrix cofactorization (NMCF).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Noisy Neonatal Chest Sound Separation for high-quality heart and lung sound separation of neonatal chest sounds based on artificial intelligence NMF and NMCF methods.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Chest sounds.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Kuang et al., 2023 [<xref rid="B55-sensors-25-01078" ref-type="bibr">55</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Remote photoplethysmography (rPPG) technology, facial video.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">rPPG technology is used to measure physiological indicators based on facial video, including HR and respiratory rate (RR). Remote photoplethysmography signal are enhanced based on generative adversarial networks.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Respiratory rate, heart rate.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Romero Gomez i Orjuela-Canon, 2021 [<xref rid="B128-sensors-25-01078" ref-type="bibr">128</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ANN, machine learning techniques, sound signal.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The use of artificial intelligence to analyze respiratory sounds, such as crackles and wheezes, which are associated with respiratory diseases. AI algorithms are used to classify these sounds based on the Respiratory Sound Database from the ICBHI 2017 challenge.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Not specified.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">T&#x000fc;rk&#x000e7;etin et al., 2023 [<xref rid="B129-sensors-25-01078" ref-type="bibr">129</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ANN, sound signal.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The use of artificial intelligence to analyze sound signals, such as cough, breath, and the sound /a/, for diagnosing respiratory diseases (asthma, COPD, pneumonia).</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breath detection, cough detection.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Pouramirarsalani et al., 2024 [<xref rid="B130-sensors-25-01078" ref-type="bibr">130</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The microphone built into a mobile phone.</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">The use of a microphone and mobile phone to record acoustic signals related to breathing during sleep, which are then analyzed for sleep apnea diagnosis. The classification model based on artificial intelligence and optimization using the PSO algorithm enabled effective diagnosis, achieving a classification accuracy of 87.5%.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sleep apnea.</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Saeed et al., 2023 [<xref rid="B131-sensors-25-01078" ref-type="bibr">131</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Radar technology and Wi-Fi (radar systems based on SDR).</td><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Utilization of radio technologies, including radar and SDR (software-defined radio), for detecting breath patterns. The radar system tracks subtle chest movements associated with breathing, while SDR systems analyze Wi-Fi signals, enabling the accurate classification of breath patterns using deep learning algorithms, achieving a high classification accuracy</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Breathing pattern.</td></tr></tbody></table></table-wrap><p>Each of these categories represents a pivotal area of respiratory monitoring, with implications for both individual patient care and public health. The use of AI and IoT solutions in the COVID-19 pandemic, for instance, demonstrates their scalability and adaptability in large-scale health crises. As AI and IoT technologies develop, the potential for using these tools to personalize healthcare is growing. Examples shown in <xref rid="sensors-25-01078-t002" ref-type="table">Table 2</xref>, such as the use of AI to analyze audio and image signals, point to the potential to create advanced predictive algorithms that can forecast the onset of disease symptoms or predict the risk of disease exacerbation. These predictive capabilities are particularly relevant for chronic respiratory diseases, where early intervention can significantly impact patient outcomes. For instance, algorithms capable of detecting subtle changes in lung sounds could serve as early warning systems for exacerbations in COPD patients. Relying on multi-modal data&#x02014;including information on heart rhythm, breathing, lung sounds, or signals from motion sensors&#x02014;could enable a more comprehensive assessment of a patient&#x02019;s health. This could lead to personalized therapy tailored to individual patients, which is particularly important for chronic diseases, such as chronic obstructive pulmonary disease (COPD) or diabetes. The integration of multi-modal data, as evidenced in the reviewed studies, not only enhances diagnostic accuracy but also opens pathways for developing holistic health monitoring platforms that address comorbidities. Another important aspect is the possibility of using combined AI and IoT systems to manage public health. Solutions such as IoT-based platforms for monitoring and controlling the COVID-19 pandemic show that similar systems can be adapted to monitor other infectious diseases or the broader population health. By leveraging real-time data aggregation and analytics, these systems can facilitate proactive measures, such as the early identification of outbreaks and resource optimization during healthcare crises. Automated collection and analysis of data on symptoms, test results, and human contact information can support a rapid response to potential outbreaks, which is crucial in the context of future pandemics. Such capabilities exemplify the shift towards data-driven public health strategies, which rely on AI and IoT integration for scalability and precision.</p><p>Respiratory induction plethysmography (RIP) is a modern and non-invasive method of monitoring respiratory patterns that is increasingly used in the analysis of smoking behavior. A key aspect of a respiratory sensor in diagnostics and monitoring is its ability to accurately and continuously record breathing patterns, allowing for the detection of abnormalities and early identification of potential health risks, such as airway obstruction or apnea. Thanks to advanced data analysis algorithms, the information collected by the sensors&#x02014;which includes parameters such as breathing rhythm, tidal volume, and the synchronization of chest and abdominal movements&#x02014;can be processed in real time. This makes it possible to create predictive algorithms that support both the personalization of therapy and monitoring in home and clinical settings. In addition, integration with AI and IoT technologies allows for the analysis of multi-modal data, which improves the accuracy of diagnoses and opens up new possibilities in the management of chronic diseases such as COPD and asthma. This technique uses inductive sensors to measure changes in the volume of the thorax and abdomen, which allows for detailed monitoring of respiratory parameters such as tidal volume (TV), respiratory rate, and the duration of inhalation and exhalation phases. In the context of smoking, RIP enables precise detection of respiratory patterns associated with smoke inhalation, which can be crucial in assessing its impact on the respiratory system.</p><p>In recent years, the effectiveness of RIP has been significantly improved by the use of advanced artificial intelligence algorithms [<xref rid="B132-sensors-25-01078" ref-type="bibr">132</xref>,<xref rid="B133-sensors-25-01078" ref-type="bibr">133</xref>,<xref rid="B134-sensors-25-01078" ref-type="bibr">134</xref>,<xref rid="B135-sensors-25-01078" ref-type="bibr">135</xref>] such as convolutional neural networks (CNN) and Long Short-Term Memory (LSTM). Specifically, CNNs excel in identifying spatial patterns in respiratory data, while LSTMs are particularly effective in modeling temporal dependencies in respiratory cycles, making them ideal for dynamic applications like detecting irregular smoke inhalation patterns, demonstrating improved sensitivity and specificity in complex scenarios, such as distinguishing smoking behavior from other respiratory events. Studies have shown that these deep learning algorithms outperform traditional methods such as support vector machines (SVM), Markov models, or decision trees in detecting smoke inhalation patterns, suggesting their potential in the precise monitoring of smokers&#x02019; behavior. Moreover, the method has a wide range of applications in clinical diagnostics, including monitoring the synchrony of chest and abdominal movements in patients with chronic obstructive pulmonary disease (COPD), assessing respiratory asynchrony during the spontaneous breathing test (SBT), and detecting apneas and shallow breathing.</p><p>Despite its many advantages, RIP is not without its limitations. Inductive sensors are susceptible to interference from non-respiratory body movements, which can affect the quality and accuracy of data. In addition, this technology requires precise calibration and proper positioning of sensors on the patient&#x02019;s body, which can be challenging in a home setting. Advanced algorithms that incorporate motion artifact correction and dynamic re-calibration techniques have been proposed to address these issues, enhancing the reliability in non-clinical environments. However, the development of more advanced filtering and correction algorithms, as well as integration with other measurement methods such as heart rate (HR) monitoring and electroencephalography (EEG), can significantly improve the quality and versatility of RIP applications [<xref rid="B136-sensors-25-01078" ref-type="bibr">136</xref>]. The use of RIP in combination with bioimpedance and piezoelectric signal analysis also allows for a more comprehensive assessment of the patient&#x02019;s health status, which may be particularly important in the context of integrated cardiorespiratory monitoring.</p><p>As the technology evolves, the introduction of more compact, wireless systems, such as the Personal Automatic Cigarette Tracker v2 (PACT-2), and the integration of RIP with optical and infrared methods of chest movement analysis, may revolutionize the way respiratory health is monitored, both in clinical and home settings [<xref rid="B137-sensors-25-01078" ref-type="bibr">137</xref>,<xref rid="B138-sensors-25-01078" ref-type="bibr">138</xref>]. Furthermore, hybrid systems that combine RIP with advanced radar technologies offer promising avenues for creating low-cost, contactless solutions capable of delivering comparable accuracy to traditional methods.</p><p>The latest developments in radar technology raise significant and impactful issues for modern applications. In 2024, Kang et al. [<xref rid="B95-sensors-25-01078" ref-type="bibr">95</xref>] described the advanced use of Frequency Modulation Continuous Wave (FMCW) radar technology combined with a metasurface antenna and passive metasurface tags, designed to monitor the breathing of the driver and passengers in a car. In the context of contemporary challenges, such as road safety and increasing vehicle automation, this solution holds great potential for accident prevention. For instance, it can detect symptoms of driver fatigue or health issues like sleep apnea, enabling timely interventions. Moreover, the ability to precisely track passengers&#x02019; breathing in real time offers opportunities for the development of intelligent climate control systems or personalized cabin settings, significantly enhancing travel comfort. This innovation also paves the way for medical diagnostics while driving and the seamless integration with autonomous vehicle systems, fostering a safer and more intuitive driving environment. Similarly, Zhang et al. [<xref rid="B120-sensors-25-01078" ref-type="bibr">120</xref>] introduced the mmTAA system in 2024, which utilizes millimeter-wave (mmWave) radar with multiple antennas and an advanced neural network, TAANet, for the non-invasive measurement of Target Angle and Azimuth (TAA) and monitoring of respiratory activity. This system excels at accurately determining the centroid position of respiratory chest and abdominal movements (RC-AB), achieving precision comparable to traditional methods, such as Optoelectronic Plethysmography (OEP). The mmTAA system demonstrates immense potential for revolutionizing respiratory health monitoring in daily life by providing a non-contact, reliable solution. Its practical implementation in wearable and stationary devices could bridge the gap between clinical-grade accuracy and everyday usability. Its ability to continuously track respiratory parameters in a discreet and user-friendly manner could significantly improve the early diagnosis and management of respiratory conditions, such as respiratory insufficiency or sleep disorders. Together, these innovations showcase the transformative power of radar technology in enhancing safety, comfort, and health monitoring in modern vehicles and daily life. By integrating advanced signal processing, metasurface designs, and machine learning, they address critical challenges in mobility and healthcare, pointing towards a future where technology seamlessly enhances both safety and well-being.</p><sec id="sec5dot1-sensors-25-01078"><title>5.1. Development of Respiratory Monitoring Technologies for Infants and Children</title><p>This review also helped to locate a niche of sorts when it comes to the use of similar devices that will support respiratory monitoring, but in MRI, fMRI or rsfMRI studies [<xref rid="B81-sensors-25-01078" ref-type="bibr">81</xref>]. Monitoring respiration in infants and young children poses significant challenges due to the irregularity of their breathing patterns and the various physiological conditions that can affect monitoring accuracy. In infants, particularly in the first months of life, there are notable fluctuations in breathing rates, a result of the immaturity of the respiratory and autonomic systems. Research has shown that infants can exhibit breathing rates ranging from 30 to 60 breaths per minute, with distinct periods of rapid breathing interspersed with slower breaths. For instance, studies such as those conducted by Njeru et al. [<xref rid="B139-sensors-25-01078" ref-type="bibr">139</xref>] and Arzi et al. [<xref rid="B140-sensors-25-01078" ref-type="bibr">140</xref>] document the variability in infant breathing and the impact of sleep on respiratory patterns. The inclusion of real-time monitoring tools that adapt dynamically to these fluctuations is critical for ensuring reliable assessments during sleep studies or developmental evaluations. This variability, often exacerbated during sleep, can be a critical indicator of respiratory health and development in infants.</p></sec><sec id="sec5dot2-sensors-25-01078"><title>5.2. From Non-Specific Methods to Dedicated Solutions</title><p>The transition from non-specific methods to dedicated solutions in respiratory monitoring illustrates the versatility of engineering devices originally designed for unrelated tasks. Many technologies, such as buttons used in input devices or radios [<xref rid="B62-sensors-25-01078" ref-type="bibr">62</xref>,<xref rid="B64-sensors-25-01078" ref-type="bibr">64</xref>], have been tested in experimental setups to assess their feasibility for respiratory analysis, despite their lack of direct implementation in clinical environments. Similarly, motion-sensing technologies like Kinect [<xref rid="B59-sensors-25-01078" ref-type="bibr">59</xref>], initially developed for gaming and motion detection, have shown potential when repurposed for monitoring respiratory patterns. These methods, while not inherently intended for respiratory analysis, have been adapted with some success due to their ability to capture relevant physiological data.</p><p>Further, technologies dedicated to a single function, such as sensors used exclusively for sleep monitoring, are being progressively refined and modified for real-time respiratory monitoring applications. An example includes their evolution from tracking sleep-related events to providing continuous feedback during day-to-day activities. Additionally, respiratory detection is increasingly used to support other modalities, such as magnetic resonance imaging (MRI), where respiratory signals [<xref rid="B66-sensors-25-01078" ref-type="bibr">66</xref>] are employed to minimize motion artifacts by synchronizing image acquisition with periods of breath-hold or reduced motion.</p><p>Even non-respiratory tools, like pulse monitors, have been leveraged to extract respiratory parameters such as breathing rate, demonstrating how multipurpose data can enhance clinical insights. Meanwhile, proximity-based devices like LiDAR [<xref rid="B99-sensors-25-01078" ref-type="bibr">99</xref>], which require the subject to remain within a specific field of detection, highlight the range of contactless solutions emerging for respiratory monitoring. These devices complement traditional approaches, and are often validated against gold-standard methods like plethysmography, where new techniques are benchmarked against established respiratory measurement tools [<xref rid="B118-sensors-25-01078" ref-type="bibr">118</xref>]. This trend showcases the potential of flexible, multi-functional engineering methods in advancing respiratory diagnostics beyond their original intent.</p></sec><sec id="sec5dot3-sensors-25-01078"><title>5.3. The Need for Advanced Monitoring in a Medical Context</title><p>Monitoring respiration in children is crucial not only for assessing their development, but also for the early detection of potential health risks, such as Sudden Infant Death Syndrome (SIDS) and asthma. Studies indicate that infants are particularly vulnerable to SIDS in the early months of life, and early respiratory monitoring can help to identify the risk and potential preventive interventions [<xref rid="B141-sensors-25-01078" ref-type="bibr">141</xref>,<xref rid="B142-sensors-25-01078" ref-type="bibr">142</xref>]. Furthermore, children with asthma and allergies may experience breathing difficulties, necessitating the precise monitoring of their respiratory patterns to tailor therapy and manage symptoms effectively [<xref rid="B143-sensors-25-01078" ref-type="bibr">143</xref>,<xref rid="B144-sensors-25-01078" ref-type="bibr">144</xref>]. Integrating modern respiratory monitoring technologies, such as remote sensing and real-time analysis, can provide valuable data and enhance care for children with specific health needs.</p></sec></sec><sec sec-type="conclusions" id="sec6-sensors-25-01078"><title>6. Conclusions</title><p>Devices in the form of wearable respiratory belts can be utilized in various contexts, including sleep monitoring, patient assessment, and even sports training. Their capability to track respiratory parameters offers valuable insights into respiratory health and can aid in the early identification of potential issues. As technology evolves, ongoing comparisons of available solutions are essential to ensure that theoretical advancements keep pace with practical developments. This continuous evaluation will facilitate the refinement of current solutions and the emergence of novel approaches, thus driving innovation in respiratory monitoring.</p><p>The integration of AI and IoT in respiratory monitoring systems holds significant promise for personalized healthcare and precision diagnostics. Key areas for future research include optimizing analytical algorithms for the more accurate detection of respiratory changes and the early identification of health risks. The combination of different technologies&#x02014;such as breath monitoring, sound analysis, and imaging&#x02014;may enable the development of advanced diagnostic and predictive systems.</p><p>One of the challenges that remains is improving the accuracy of monitoring in home settings, particularly in minimizing disturbances caused by body movements. The miniaturization of wearable devices, along with the integration of multimodal data (e.g., heart rate, breath patterns, sound signals), is expected to enhance personalized therapies, particularly for chronic conditions such as COPD. Furthermore, the integration of these systems with public health monitoring platforms can contribute to rapid responses in the face of health crises, such as pandemics.</p><p>While these advancements are promising, further studies are needed to address issues related to data privacy and security. Additionally, regulatory frameworks and user education will be crucial to ensuring the safe and responsible implementation of respiratory monitoring technologies in clinical practice.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#x02019;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, I.K. and M.M.; methodology, I.K. and M.M.; writing&#x02014;original draft preparation, I.K., M.M. and K.O.; writing&#x02014;review and editing, I.K., M.M. and K.O.; formal analysis, M.M. and M.C.; visualization, I.K. and M.M.; supervision, I.K. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>No new data were created or analyzed in this study. Data sharing is not applicable to this article.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-01078"><label>1.</label><element-citation publication-type="webpage"><article-title>Natus Medical Incorporated&#x02014;Natus</article-title><comment>Available online: <ext-link xlink:href="https://natus.com/" ext-link-type="uri">https://natus.com/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2023-11-03">(accessed on 3 November 2023)</date-in-citation></element-citation></ref><ref id="B2-sensors-25-01078"><label>2.</label><element-citation publication-type="webpage"><article-title>Modern Breath Training|Mindfield &#x000ae; eSense Respiration</article-title><comment>Available online: <ext-link xlink:href="https://mindfield.de/en/esense-respiration/" ext-link-type="uri">https://mindfield.de/en/esense-respiration/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2023-11-03">(accessed on 3 November 2023)</date-in-citation></element-citation></ref><ref id="B3-sensors-25-01078"><label>3.</label><element-citation publication-type="webpage"><article-title>Respiration Sensor&#x02014;SA9311M</article-title><comment>Available online: <ext-link xlink:href="https://thoughttechnology.com/respiration-sensor-sa9311m/" ext-link-type="uri">https://thoughttechnology.com/respiration-sensor-sa9311m/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2023-11-03">(accessed on 3 November 2023)</date-in-citation></element-citation></ref><ref id="B4-sensors-25-01078"><label>4.</label><element-citation publication-type="webpage"><article-title>RESPeRATE Ultra&#x02014;2breathe</article-title><comment>Available online: <ext-link xlink:href="https://2breathe.com/product/productresperate-ultra/" ext-link-type="uri">https://2breathe.com/product/productresperate-ultra/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2023-11-03">(accessed on 3 November 2023)</date-in-citation></element-citation></ref><ref id="B5-sensors-25-01078"><label>5.</label><element-citation publication-type="webpage"><article-title>2breathe&#x02014;Sleep Inducer&#x02014;2breathe</article-title><comment>Available online: <ext-link xlink:href="https://2breathe.com/product/2breathe-sleep-inducer/" ext-link-type="uri">https://2breathe.com/product/2breathe-sleep-inducer/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2023-11-03">(accessed on 3 November 2023)</date-in-citation></element-citation></ref><ref id="B6-sensors-25-01078"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vollmer</surname><given-names>M.</given-names></name>
<name><surname>Bl&#x000e4;sing</surname><given-names>D.</given-names></name>
<name><surname>Reiser</surname><given-names>J.E.</given-names></name>
<name><surname>Nisser</surname><given-names>M.</given-names></name>
<name><surname>Buder</surname><given-names>A.</given-names></name>
</person-group><article-title>Simultaneous physiological measurements with five devices at different cognitive and physical loads (version 1.0.2)</article-title><source>PhysioNet</source><year>2023</year><pub-id pub-id-type="doi">10.13026/DDZR-DW82</pub-id></element-citation></ref><ref id="B7-sensors-25-01078"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Moody</surname><given-names>B.</given-names></name>
<name><surname>Hao</surname><given-names>S.</given-names></name>
<name><surname>Gow</surname><given-names>B.</given-names></name>
<name><surname>Pollard</surname><given-names>T.</given-names></name>
<name><surname>Zong</surname><given-names>W.</given-names></name>
<name><surname>Mark</surname><given-names>R.</given-names></name>
</person-group><article-title>MIMIC-IV Waveform Database (version 0.1.0)</article-title><source>PhysioNet</source><year>2022</year><pub-id pub-id-type="doi">10.13026/A2MW-F949</pub-id></element-citation></ref><ref id="B8-sensors-25-01078"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pani</surname><given-names>D.</given-names></name>
<name><surname>Sulas</surname><given-names>E.</given-names></name>
<name><surname>Urru</surname><given-names>M.</given-names></name>
<name><surname>Sameni</surname><given-names>R.</given-names></name>
<name><surname>Raffo</surname><given-names>L.</given-names></name>
<name><surname>Tumbarello</surname><given-names>R.</given-names></name>
</person-group><article-title>NInFEA: Non-Invasive Multimodal Foetal ECG-Doppler Dataset for Antenatal Cardiology Research (version 1.0.0)</article-title><source>PhysioNet</source><year>2020</year><pub-id pub-id-type="doi">10.13026/C4N5-3B04</pub-id></element-citation></ref><ref id="B9-sensors-25-01078"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ihmig</surname><given-names>F.R.</given-names></name>
<name><surname>Gogeascoechea</surname><given-names>A.</given-names></name>
<name><surname>Sch&#x000e4;fer</surname><given-names>S.</given-names></name>
<name><surname>Lass-Hennemann</surname><given-names>J.</given-names></name>
<name><surname>Michael</surname><given-names>T.</given-names></name>
</person-group><article-title>Electrocardiogram, skin conductance and respiration from spider-fearful individuals watching spider video clips (version 1.0.0)</article-title><source>PhysioNet</source><year>2020</year><pub-id pub-id-type="doi">10.13026/KC0E-6A32</pub-id></element-citation></ref><ref id="B10-sensors-25-01078"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Moody</surname><given-names>B.</given-names></name>
<name><surname>Moody</surname><given-names>G.</given-names></name>
<name><surname>Villarroel</surname><given-names>M.</given-names></name>
<name><surname>Clifford</surname><given-names>G.</given-names></name>
<name><surname>Silva</surname><given-names>I.</given-names></name>
</person-group><article-title>MIMIC-III Waveform Database (version 1.0)</article-title><source>PhysioNet</source><year>2020</year><pub-id pub-id-type="doi">10.13026/C2607M</pub-id></element-citation></ref><ref id="B11-sensors-25-01078"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Moody</surname><given-names>B.</given-names></name>
<name><surname>Moody</surname><given-names>G.</given-names></name>
<name><surname>Villarroel</surname><given-names>M.</given-names></name>
<name><surname>Clifford</surname><given-names>G.</given-names></name>
<name><surname>Silva</surname><given-names>I.</given-names></name>
</person-group><article-title>MIMIC-III Waveform Database Matched Subset (version 1.0)</article-title><source>PhysioNet</source><year>2020</year><pub-id pub-id-type="doi">10.13026/C2294B</pub-id></element-citation></ref><ref id="B12-sensors-25-01078"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Novak</surname><given-names>V.</given-names></name>
</person-group><article-title>Cerebral Vasoregulation in Elderly with Stroke</article-title><source>PhysioNet</source><year>2018</year><pub-id pub-id-type="doi">10.13026/C2DW96</pub-id></element-citation></ref><ref id="B13-sensors-25-01078"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Pimentel</surname><given-names>M.</given-names></name>
<name><surname>Johnson</surname><given-names>A.E.W.</given-names></name>
<name><surname>Charlton</surname><given-names>P.</given-names></name>
<name><surname>Birrenkott</surname><given-names>D.</given-names></name>
<name><surname>Watkinson</surname><given-names>P.</given-names></name>
<name><surname>Tarassenko</surname><given-names>L.</given-names></name>
<name><surname>Clifton</surname><given-names>D.</given-names></name>
</person-group><article-title>BIDMC PPG and Respiration Dataset</article-title><source>PhysioNet</source><year>2018</year><pub-id pub-id-type="doi">10.13026/C2208R</pub-id></element-citation></ref><ref id="B14-sensors-25-01078"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Guy</surname><given-names>E.F.S.</given-names></name>
<name><surname>Knopp</surname><given-names>J.</given-names></name>
<name><surname>Lerios</surname><given-names>T.</given-names></name>
<name><surname>Chase</surname><given-names>J.G.</given-names></name>
</person-group><article-title>Pressure, flow, and dynamic thoraco-abdominal circumferences data for adults breathing under CPAP therapy (version 1.0.0)</article-title><source>PhysioNet</source><year>2023</year><pub-id pub-id-type="doi">10.13026/WMZM-D487</pub-id></element-citation></ref><ref id="B15-sensors-25-01078"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Novak</surname><given-names>V.</given-names></name>
<name><surname>Quispe</surname><given-names>R.</given-names></name>
<name><surname>Saunders</surname><given-names>C.</given-names></name>
</person-group><article-title>Cerebral perfusion and cognitive decline in type 2 diabetes (version 1.0.1)</article-title><source>PhysioNet</source><year>2022</year><pub-id pub-id-type="doi">10.13026/PGN6-6K53</pub-id></element-citation></ref><ref id="B16-sensors-25-01078"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Novak</surname><given-names>V.</given-names></name>
<name><surname>Quispe</surname><given-names>R.</given-names></name>
</person-group><article-title>Cerebromicrovascular Disease in Elderly with Diabetes (version 1.0.1)</article-title><source>PhysioNet</source><year>2022</year><pub-id pub-id-type="doi">10.13026/00BM-0X81</pub-id></element-citation></ref><ref id="B17-sensors-25-01078"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Guy</surname><given-names>E.</given-names></name>
<name><surname>Knopp</surname><given-names>J.</given-names></name>
<name><surname>Chase</surname><given-names>G.</given-names></name>
</person-group><article-title>CPAP Pressure and Flow Data from a Local Trial of 30 Adults at the University of Canterbury (version 1.0.1)</article-title><source>PhysioNet</source><year>2022</year><pub-id pub-id-type="doi">10.13026/XFAE-VV63</pub-id></element-citation></ref><ref id="B18-sensors-25-01078"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Tamez-Pe&#x000f1;a</surname><given-names>J.</given-names></name>
<name><surname>Yala</surname><given-names>A.</given-names></name>
<name><surname>Cardona</surname><given-names>S.</given-names></name>
<name><surname>Ortiz-Lopez</surname><given-names>R.</given-names></name>
<name><surname>Trevino</surname><given-names>V.</given-names></name>
</person-group><article-title>Upper body thermal images and associated clinical data from a pilot cohort study of COVID-19 (version 1.1)</article-title><source>PhysioNet</source><year>2021</year><pub-id pub-id-type="doi">10.13026/WFR2-5973</pub-id></element-citation></ref><ref id="B19-sensors-25-01078"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Tang</surname><given-names>S.</given-names></name>
<name><surname>Davarmanesh</surname><given-names>P.</given-names></name>
<name><surname>Song</surname><given-names>Y.</given-names></name>
<name><surname>Koutra</surname><given-names>D.</given-names></name>
<name><surname>Sjoding</surname><given-names>M.</given-names></name>
<name><surname>Wiens</surname><given-names>J.</given-names></name>
</person-group><article-title>MIMIC-III and eICU-CRD: Feature Representation by FIDDLE Preprocessing (version 1.0.0)</article-title><source>PhysioNet</source><year>2021</year><pub-id pub-id-type="doi">10.13026/2QTG-K467</pub-id></element-citation></ref><ref id="B20-sensors-25-01078"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Novak</surname><given-names>V.</given-names></name>
<name><surname>Mendez</surname><given-names>L.</given-names></name>
</person-group><article-title>Cerebral Vasoregulation in Diabetes (version 1.0.0)</article-title><source>PhysioNet</source><year>2020</year><pub-id pub-id-type="doi">10.13026/C8AX-AQ77</pub-id></element-citation></ref><ref id="B21-sensors-25-01078"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fong</surname><given-names>N.</given-names></name>
<name><surname>Lipnick</surname><given-names>M.</given-names></name>
<name><surname>Bickler</surname><given-names>P.</given-names></name>
<name><surname>Feiner</surname><given-names>J.</given-names></name>
<name><surname>Law</surname><given-names>T.</given-names></name>
</person-group><article-title>OpenOximetry Repository (version 1.0.1)</article-title><source>PhysioNet</source><year>2024</year><pub-id pub-id-type="doi">10.13026/2G7Z-T345</pub-id></element-citation></ref><ref id="B22-sensors-25-01078"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Moukheiber</surname><given-names>M.</given-names></name>
<name><surname>Moukheiber</surname><given-names>L.</given-names></name>
<name><surname>Moukheiber</surname><given-names>D.</given-names></name>
<name><surname>Hao</surname><given-names>S.</given-names></name>
<name><surname>Celi</surname><given-names>L.A.</given-names></name>
<name><surname>Lee</surname><given-names>H.-C.</given-names></name>
</person-group><article-title>A Temporal Dataset for Respiratory Support in Critically Ill Patients (version 1.0.0)</article-title><source>PhysioNet</source><year>2024</year><pub-id pub-id-type="doi">10.13026/0D8J-2W14</pub-id></element-citation></ref><ref id="B23-sensors-25-01078"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Guy</surname><given-names>E.F.S.</given-names></name>
<name><surname>Flett</surname><given-names>I.</given-names></name>
<name><surname>Clifton</surname><given-names>J.A.</given-names></name>
<name><surname>Calj&#x000e9;-van der Klei</surname><given-names>T.</given-names></name>
<name><surname>Chen</surname><given-names>R.</given-names></name>
<name><surname>Knopp</surname><given-names>J.</given-names></name>
<name><surname>Moeller</surname><given-names>K.</given-names></name>
<name><surname>Chase</surname><given-names>J.G.</given-names></name>
</person-group><article-title>Respiratory and heart rate monitoring dataset from aeration study (version 1.0.0)</article-title><source>PhysioNet</source><year>2024</year><pub-id pub-id-type="doi">10.13026/E4DT-F689</pub-id></element-citation></ref><ref id="B24-sensors-25-01078"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Clifton</surname><given-names>J.A.</given-names></name>
<name><surname>Guy</surname><given-names>E.F.S.</given-names></name>
<name><surname>Calj&#x000e9;-van der Klei</surname><given-names>T.</given-names></name>
<name><surname>Knopp</surname><given-names>J.</given-names></name>
<name><surname>Chase</surname><given-names>J.G.</given-names></name>
</person-group><article-title>Simulated Obstructive Disease Respiratory Pressure and Flow (version 1.0.0)</article-title><source>PhysioNet</source><year>2023</year><pub-id pub-id-type="doi">10.13026/XCZC-3662</pub-id></element-citation></ref><ref id="B25-sensors-25-01078"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Guy</surname><given-names>E.F.S.</given-names></name>
<name><surname>Clifton</surname><given-names>J.A.</given-names></name>
<name><surname>Calj&#x000e9;-van der Klei</surname><given-names>T.</given-names></name>
<name><surname>Chen</surname><given-names>R.</given-names></name>
<name><surname>Knopp</surname><given-names>J.</given-names></name>
<name><surname>Moeller</surname><given-names>K.</given-names></name>
<name><surname>Chase</surname><given-names>J.G.</given-names></name>
</person-group><article-title>Respiratory dataset from PEEP study with expiratory occlusion (version 1.0.0)</article-title><source>PhysioNet</source><year>2023</year><pub-id pub-id-type="doi">10.13026/D767-E709</pub-id></element-citation></ref><ref id="B26-sensors-25-01078"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Orlandic</surname><given-names>L.</given-names></name>
<name><surname>Teijeiro</surname><given-names>T.</given-names></name>
<name><surname>Atienza</surname><given-names>D.</given-names></name>
</person-group><article-title>The COUGHVID crowdsourcing dataset, a corpus for the study of large-scale cough analysis algorithms</article-title><source>Sci. Data</source><year>2021</year><volume>8</volume><fpage>156</fpage><pub-id pub-id-type="doi">10.1038/s41597-021-00937-4</pub-id><pub-id pub-id-type="pmid">34162883</pub-id>
</element-citation></ref><ref id="B27-sensors-25-01078"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mueller</surname><given-names>R.</given-names></name>
</person-group><article-title>Sleep Heart Health Study (SHHS)</article-title><source>Natl. Sleep Res. Resour.</source><year>2014</year><pub-id pub-id-type="doi">10.25822/GHY8-KS59</pub-id></element-citation></ref><ref id="B28-sensors-25-01078"><label>28.</label><element-citation publication-type="webpage"><article-title>Sleep Data&#x02014;National Sleep Research Resource&#x02014;NSRR</article-title><comment>Available online: <ext-link xlink:href="https://sleepdata.org/" ext-link-type="uri">https://sleepdata.org/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2023-11-03">(accessed on 3 November 2023)</date-in-citation></element-citation></ref><ref id="B29-sensors-25-01078"><label>29.</label><element-citation publication-type="webpage"><article-title>Home | COPDGene</article-title><comment>Available online: <ext-link xlink:href="https://www.copdfoundation.org/Research/Research-Projects-and-Consortia/COPDGene.aspx" ext-link-type="uri">https://www.copdfoundation.org/Research/Research-Projects-and-Consortia/COPDGene.aspx</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2023-11-03">(accessed on 3 November 2023)</date-in-citation></element-citation></ref><ref id="B30-sensors-25-01078"><label>30.</label><element-citation publication-type="webpage"><article-title>Respiratory Rate Estimation by Peterhcharlton</article-title><comment>Available online: <ext-link xlink:href="https://peterhcharlton.github.io/RRest/index.html" ext-link-type="uri">https://peterhcharlton.github.io/RRest/index.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-01-15">(accessed on 15 January 2024)</date-in-citation></element-citation></ref><ref id="B31-sensors-25-01078"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Charlton</surname><given-names>P.H.</given-names></name>
<name><surname>Bonnici</surname><given-names>T.</given-names></name>
<name><surname>Tarassenko</surname><given-names>L.</given-names></name>
<name><surname>Clifton</surname><given-names>D.A.</given-names></name>
<name><surname>Beale</surname><given-names>R.</given-names></name>
<name><surname>Watkinson</surname><given-names>P.J.</given-names></name>
</person-group><article-title>An assessment of algorithms to estimate respiratory rate from the electrocardiogram and photoplethysmogram</article-title><source>Physiol. Meas.</source><year>2016</year><volume>37</volume><fpage>610</fpage><lpage>626</lpage><pub-id pub-id-type="doi">10.1088/0967-3334/37/4/610</pub-id><pub-id pub-id-type="pmid">27027672</pub-id>
</element-citation></ref><ref id="B32-sensors-25-01078"><label>32.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Nagy</surname><given-names>&#x000c1;.</given-names></name>
</person-group><article-title>Cezius/Neonatal-Respiration-Monitoring-Algorithm. GitHub 2023</article-title><comment>Available online: <ext-link xlink:href="https://github.com/cezius/Neonatal-Respiration-Monitoring-Algorithm" ext-link-type="uri">https://github.com/cezius/Neonatal-Respiration-Monitoring-Algorithm</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B33-sensors-25-01078"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Nagy</surname><given-names>&#x000c1;.</given-names></name>
<name><surname>F&#x000f6;ldesy</surname><given-names>P.</given-names></name>
<name><surname>J&#x000e1;noki</surname><given-names>I.</given-names></name>
<name><surname>Terbe</surname><given-names>D.</given-names></name>
<name><surname>Siket</surname><given-names>M.</given-names></name>
<name><surname>Szab&#x000f3;</surname><given-names>M.</given-names></name>
<name><surname>Varga</surname><given-names>J.</given-names></name>
<name><surname>Zar&#x000e1;ndy</surname><given-names>&#x000c1;.</given-names></name>
</person-group><article-title>Continuous Camera-Based Premature-Infant Monitoring Algorithms for NICU</article-title><source>Appl. Sci.</source><year>2021</year><volume>11</volume><elocation-id>7215</elocation-id><pub-id pub-id-type="doi">10.3390/app11167215</pub-id></element-citation></ref><ref id="B34-sensors-25-01078"><label>34.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Misharin</surname><given-names>A.</given-names></name>
</person-group><article-title>Lvetech/ALT. GitHub 2024</article-title><comment>Available online: <ext-link xlink:href="https://github.com/lvetech/ALT" ext-link-type="uri">https://github.com/lvetech/ALT</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B35-sensors-25-01078"><label>35.</label><element-citation publication-type="webpage"><article-title>Contactless Sleep Monitoring</article-title><comment>Available online: <ext-link xlink:href="https://lvetechnologies.com/" ext-link-type="uri">https://lvetechnologies.com/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-08-28">(accessed on 28 August 2024)</date-in-citation></element-citation></ref><ref id="B36-sensors-25-01078"><label>36.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Mishra</surname><given-names>M.</given-names></name>
</person-group><article-title>Mayank31398/Real-Time-Visual-Respiration-Rate-Estimation-with-Dynamic-Scene-Adaptation. GitHub 2023</article-title><comment>Available online: <ext-link xlink:href="https://github.com/mayank31398/real-time-visual-respiration-rate-estimation-with-dynamic-scene-adaptation" ext-link-type="uri">https://github.com/mayank31398/real-time-visual-respiration-rate-estimation-with-dynamic-scene-adaptation</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B37-sensors-25-01078"><label>37.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Chatterjee</surname><given-names>A.</given-names></name>
<name><surname>Prathosh</surname><given-names>A.P.</given-names></name>
<name><surname>Praveena</surname><given-names>P.</given-names></name>
<name><surname>Upadhya</surname><given-names>V.</given-names></name>
</person-group><article-title>Real-Time Visual Respiration Rate Estimation with Dynamic Scene Adaptation</article-title><source>Proceedings of the 2016 IEEE 16th International Conference on Bioinformatics and Bioengineering (BIBE)</source><conf-loc>Taichung, Taiwan</conf-loc><conf-date>31 October&#x02013;2 November 2016</conf-date><fpage>154</fpage><lpage>160</lpage></element-citation></ref><ref id="B38-sensors-25-01078"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Grund</surname><given-names>M.</given-names></name>
<name><surname>Al</surname><given-names>E.</given-names></name>
<name><surname>Pabst</surname><given-names>M.</given-names></name>
<name><surname>Dabbagh</surname><given-names>A.</given-names></name>
<name><surname>Stephani</surname><given-names>T.</given-names></name>
<name><surname>Nierhaus</surname><given-names>T.</given-names></name>
<name><surname>Gaebler</surname><given-names>M.</given-names></name>
<name><surname>Villringer</surname><given-names>A.</given-names></name>
</person-group><article-title>Respiration, Heartbeat, and Conscious Tactile Perception</article-title><source>J. Neurosci.</source><year>2022</year><volume>42</volume><fpage>643</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0592-21.2021</pub-id><pub-id pub-id-type="pmid">34853084</pub-id>
</element-citation></ref><ref id="B39-sensors-25-01078"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Sun</surname><given-names>H.</given-names></name>
<name><surname>Ganglberger</surname><given-names>W.</given-names></name>
<name><surname>Panneerselvam</surname><given-names>E.</given-names></name>
<name><surname>Leone</surname><given-names>M.J.</given-names></name>
<name><surname>Quadri</surname><given-names>S.A.</given-names></name>
<name><surname>Goparaju</surname><given-names>B.</given-names></name>
<name><surname>Tesh</surname><given-names>R.A.</given-names></name>
<name><surname>Akeju</surname><given-names>O.</given-names></name>
<name><surname>Thomas</surname><given-names>R.J.</given-names></name>
<name><surname>Westover</surname><given-names>M.B.</given-names></name>
</person-group><article-title>Sleep staging from electrocardiography and respiration with deep learning</article-title><source>Sleep</source><year>2020</year><volume>43</volume><fpage>zsz306</fpage><pub-id pub-id-type="doi">10.1093/sleep/zsz306</pub-id><pub-id pub-id-type="pmid">31863111</pub-id>
</element-citation></ref><ref id="B40-sensors-25-01078"><label>40.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Pal</surname><given-names>S.</given-names></name>
<name><surname>Bauer</surname><given-names>S.</given-names></name>
<name><surname>Kumar</surname><given-names>C.</given-names></name>
</person-group><article-title>isuparnopal/RF_respiration_monitoring. GitHub 2024</article-title><comment>Available online: <ext-link xlink:href="https://github.com/isuparnopal/RF_respiration_monitoring" ext-link-type="uri">https://github.com/isuparnopal/RF_respiration_monitoring</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B41-sensors-25-01078"><label>41.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Yang</surname><given-names>Y.</given-names></name>
<name><surname>Cao</surname><given-names>J.</given-names></name>
<name><surname>Liu</surname><given-names>X.</given-names></name>
<name><surname>Liu</surname><given-names>X.</given-names></name>
</person-group><article-title>Multi-Breath: Separate Respiration Monitoring for Multiple Persons with UWB Radar</article-title><source>Proceedings of the 2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)</source><conf-loc>Milwaukee, WI, USA</conf-loc><conf-date>15&#x02013;19 July 2019</conf-date><fpage>840</fpage><lpage>849</lpage></element-citation></ref><ref id="B42-sensors-25-01078"><label>42.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Kim</surname><given-names>M.</given-names></name>
</person-group><article-title>Mins-n/UWB_Radar_Respiration_Monitoring. GitHub 2024</article-title><comment>Available online: <ext-link xlink:href="https://github.com/mins-n/UWB_Radar_Respiration_Monitoring" ext-link-type="uri">https://github.com/mins-n/UWB_Radar_Respiration_Monitoring</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B43-sensors-25-01078"><label>43.</label><element-citation publication-type="book"><person-group person-group-type="author">
<name><surname>Manne</surname><given-names>S.K.R.</given-names></name>
<name><surname>Zhu</surname><given-names>S.</given-names></name>
<name><surname>Ostadabbas</surname><given-names>S.</given-names></name>
<name><surname>Wan</surname><given-names>M.</given-names></name>
</person-group><article-title>Automatic Infant Respiration Estimation from Video: A Deep Flow-Based Algorithm and a Novel Public Benchmark</article-title><source>Perinatal, Preterm and Paediatric Image Analysis</source><person-group person-group-type="editor">
<name><surname>Link-Sourani</surname><given-names>D.</given-names></name>
<name><surname>Abaci Turk</surname><given-names>E.</given-names></name>
<name><surname>Macgowan</surname><given-names>C.</given-names></name>
<name><surname>Hutter</surname><given-names>J.</given-names></name>
<name><surname>Melbourne</surname><given-names>A.</given-names></name>
<name><surname>Licandro</surname><given-names>R.</given-names></name>
</person-group><comment>Lecture Notes in Computer Science</comment><publisher-name>Springer Nature</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2023</year><volume>Volume 14246</volume><fpage>111</fpage><lpage>120</lpage><isbn>978-3-031-45543-8</isbn></element-citation></ref><ref id="B44-sensors-25-01078"><label>44.</label><element-citation publication-type="webpage"><article-title>Ubicomplab/rPPG-Toolbox. GitHub 2024</article-title><comment>Available online: <ext-link xlink:href="https://github.com/Ubicomplab/rPPG-Toolbox/" ext-link-type="uri">https://github.com/Ubicomplab/rPPG-Toolbox/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B45-sensors-25-01078"><label>45.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Rathore</surname><given-names>K.S.</given-names></name>
</person-group><article-title>Kapil19-dev/RESPIRATION_RATE_ESTIMATION. GitHub 2024</article-title><comment>Available online: <ext-link xlink:href="https://github.com/Kapil19-dev/RESPIRATION_RATE_ESTIMATION" ext-link-type="uri">https://github.com/Kapil19-dev/RESPIRATION_RATE_ESTIMATION</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B46-sensors-25-01078"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ghibaudo</surname><given-names>V.</given-names></name>
<name><surname>Granget</surname><given-names>J.</given-names></name>
<name><surname>Dereli</surname><given-names>M.</given-names></name>
<name><surname>Buonviso</surname><given-names>N.</given-names></name>
<name><surname>Garcia</surname><given-names>S.</given-names></name>
</person-group><article-title>A Unifying Method to Study Respiratory Sinus Arrhythmia Dynamics Implemented in a New Toolbox</article-title><source>eNeuro</source><year>2023</year><volume>10</volume><comment>ENEURO.0197-23.2023</comment><pub-id pub-id-type="doi">10.1523/ENEURO.0197-23.2023</pub-id></element-citation></ref><ref id="B47-sensors-25-01078"><label>47.</label><element-citation publication-type="webpage"><person-group person-group-type="author">
<name><surname>Samuel</surname><given-names>G.</given-names></name>
</person-group><article-title>samuelgarcia/physio. GitHub 2024</article-title><comment>Available online: <ext-link xlink:href="https://github.com/samuelgarcia/physio" ext-link-type="uri">https://github.com/samuelgarcia/physio</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B48-sensors-25-01078"><label>48.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Karvounis</surname><given-names>E.</given-names></name>
<name><surname>Vavva</surname><given-names>M.</given-names></name>
<name><surname>Giannakeas</surname><given-names>N.</given-names></name>
<name><surname>Tzallas</surname><given-names>A.T.</given-names></name>
<name><surname>Smanis</surname><given-names>I.</given-names></name>
<name><surname>Tsipouras</surname><given-names>M.G.</given-names></name>
</person-group><article-title>A Hospital Healthcare Monitoring System Using Internet of Things Technologies</article-title><source>Proceedings of the 2021 6th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM)</source><conf-loc>Preveza, Greece</conf-loc><conf-date>24&#x02013;26 September 2021</conf-date><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B49-sensors-25-01078"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Chen</surname><given-names>X.</given-names></name>
<name><surname>Jiang</surname><given-names>S.</given-names></name>
<name><surname>Li</surname><given-names>Z.</given-names></name>
<name><surname>Lo</surname><given-names>B.</given-names></name>
</person-group><article-title>A Pervasive Respiratory Monitoring Sensor for COVID-19 Pandemic</article-title><source>IEEE Open J. Eng. Med. Biol.</source><year>2021</year><volume>2</volume><fpage>11</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1109/OJEMB.2020.3042051</pub-id><pub-id pub-id-type="pmid">34786558</pub-id>
</element-citation></ref><ref id="B50-sensors-25-01078"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Jiang</surname><given-names>W.</given-names></name>
<name><surname>Majumder</surname><given-names>S.</given-names></name>
<name><surname>Kumar</surname><given-names>S.</given-names></name>
<name><surname>Subramaniam</surname><given-names>S.</given-names></name>
<name><surname>Li</surname><given-names>X.</given-names></name>
<name><surname>Khedri</surname><given-names>R.</given-names></name>
<name><surname>Mondal</surname><given-names>T.</given-names></name>
<name><surname>Abolghasemian</surname><given-names>M.</given-names></name>
<name><surname>Satia</surname><given-names>I.</given-names></name>
<name><surname>Deen</surname><given-names>M.J.</given-names></name>
</person-group><article-title>A Wearable Tele-Health System towards Monitoring COVID-19 and Chronic Diseases</article-title><source>IEEE Rev. Biomed. Eng.</source><year>2022</year><volume>15</volume><fpage>61</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1109/RBME.2021.3069815</pub-id><pub-id pub-id-type="pmid">33784625</pub-id>
</element-citation></ref><ref id="B51-sensors-25-01078"><label>51.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Abdullah</surname><given-names>K.H.</given-names></name>
<name><surname>Bilal Er</surname><given-names>M.</given-names></name>
</person-group><article-title>Lung sound signal classification by using Cosine Similarity-based Multilevel Discrete Wavelet Transform Decomposition with CNN-LSTM Hybrid model</article-title><source>Proceedings of the 2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST)</source><conf-loc>Delhi, India</conf-loc><conf-date>9&#x02013;10 December 2022</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B52-sensors-25-01078"><label>52.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Chawla</surname><given-names>J.</given-names></name>
<name><surname>Walia</surname><given-names>N.K.</given-names></name>
</person-group><article-title>Artificial Intelligence based Techniques in Respiratory Healthcare Services: A Review</article-title><source>Proceedings of the 2022 3rd International Conference on Computing, Analytics and Networks (ICAN)</source><conf-loc>Rajpura, Punjab, India</conf-loc><conf-date>18&#x02013;19 November 2022</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B53-sensors-25-01078"><label>53.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Rani</surname><given-names>S.</given-names></name>
<name><surname>Chaurasia</surname><given-names>A.</given-names></name>
<name><surname>Dutta</surname><given-names>M.K.</given-names></name>
<name><surname>Myska</surname><given-names>V.</given-names></name>
<name><surname>Burget</surname><given-names>R.</given-names></name>
</person-group><article-title>Machine learning approach for automatic lungs sound diagnosis from pulmonary signals</article-title><source>Proceedings of the 2021 44th International Conference on Telecommunications and Signal Processing (TSP)</source><conf-loc>Brno, Czech Republic</conf-loc><conf-date>26&#x02013;28 July 2021</conf-date><fpage>366</fpage><lpage>371</lpage></element-citation></ref><ref id="B54-sensors-25-01078"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Grooby</surname><given-names>E.</given-names></name>
<name><surname>Sitaula</surname><given-names>C.</given-names></name>
<name><surname>Fattahi</surname><given-names>D.</given-names></name>
<name><surname>Sameni</surname><given-names>R.</given-names></name>
<name><surname>Tan</surname><given-names>K.</given-names></name>
<name><surname>Zhou</surname><given-names>L.</given-names></name>
<name><surname>King</surname><given-names>A.</given-names></name>
<name><surname>Ramanathan</surname><given-names>A.</given-names></name>
<name><surname>Malhotra</surname><given-names>A.</given-names></name>
<name><surname>Dumont</surname><given-names>G.</given-names></name>
<etal/>
</person-group><article-title>Noisy Neonatal Chest Sound Separation for High-Quality Heart and Lung Sounds</article-title><source>IEEE J. Biomed. Health Inform.</source><year>2023</year><volume>27</volume><fpage>2635</fpage><lpage>2646</lpage><pub-id pub-id-type="doi">10.1109/JBHI.2022.3215995</pub-id><pub-id pub-id-type="pmid">36264732</pub-id>
</element-citation></ref><ref id="B55-sensors-25-01078"><label>55.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kuang</surname><given-names>H.</given-names></name>
<name><surname>Ao</surname><given-names>C.</given-names></name>
<name><surname>Ma</surname><given-names>X.</given-names></name>
<name><surname>Liu</surname><given-names>X.</given-names></name>
</person-group><article-title>Remote photoplethysmography signals enhancement based on generative adversarial networks</article-title><source>Proceedings of the 2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)</source><conf-loc>Chongqing, China</conf-loc><conf-date>26&#x02013;28 May 2023</conf-date><fpage>792</fpage><lpage>796</lpage></element-citation></ref><ref id="B56-sensors-25-01078"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Dong</surname><given-names>Y.</given-names></name>
<name><surname>Yao</surname><given-names>Y.-D.</given-names></name>
</person-group><article-title>IoT Platform for COVID-19 Prevention and Control: A Survey</article-title><source>IEEE Access</source><year>2021</year><volume>9</volume><fpage>49929</fpage><lpage>49941</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2021.3068276</pub-id><pub-id pub-id-type="pmid">34812390</pub-id>
</element-citation></ref><ref id="B57-sensors-25-01078"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Misra</surname><given-names>S.</given-names></name>
<name><surname>Pal</surname><given-names>S.</given-names></name>
<name><surname>Deb</surname><given-names>P.K.</given-names></name>
<name><surname>Gupta</surname><given-names>E.</given-names></name>
</person-group><article-title>KEdge: Fuzzy-Based Multi-AI Model Coalescence Solution for Mobile Healthcare System</article-title><source>IEEE Syst. J.</source><year>2023</year><volume>17</volume><fpage>1721</fpage><lpage>1728</lpage><pub-id pub-id-type="doi">10.1109/JSYST.2023.3239395</pub-id></element-citation></ref><ref id="B58-sensors-25-01078"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Coronel</surname><given-names>C.</given-names></name>
<name><surname>Wiesmeyr</surname><given-names>C.</given-names></name>
<name><surname>Garn</surname><given-names>H.</given-names></name>
<name><surname>Kohn</surname><given-names>B.</given-names></name>
<name><surname>Wimmer</surname><given-names>M.</given-names></name>
<name><surname>Mandl</surname><given-names>M.</given-names></name>
<name><surname>Glos</surname><given-names>M.</given-names></name>
<name><surname>Penzel</surname><given-names>T.</given-names></name>
<name><surname>Klosch</surname><given-names>G.</given-names></name>
<name><surname>Stefanic-Kejik</surname><given-names>A.</given-names></name>
<etal/>
</person-group><article-title>3D Camera and Pulse Oximeter for Respiratory Events Detection</article-title><source>IEEE J. Biomed. Health Inform.</source><year>2021</year><volume>25</volume><fpage>181</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1109/JBHI.2020.2984954</pub-id><pub-id pub-id-type="pmid">32324578</pub-id>
</element-citation></ref><ref id="B59-sensors-25-01078"><label>59.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>He</surname><given-names>S.</given-names></name>
<name><surname>Mehta</surname><given-names>V.</given-names></name>
<name><surname>Bolic</surname><given-names>M.</given-names></name>
</person-group><article-title>A Joint Localization Assisted Respiratory Rate Estimation using IR-UWB Radars</article-title><source>Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Montreal, QC, Canada</conf-loc><conf-date>20&#x02013;24 July 2020</conf-date><fpage>489</fpage><lpage>493</lpage></element-citation></ref><ref id="B60-sensors-25-01078"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kusche</surname><given-names>R.</given-names></name>
<name><surname>Grashoff</surname><given-names>J.</given-names></name>
<name><surname>Oltmann</surname><given-names>A.</given-names></name>
<name><surname>Rostalski</surname><given-names>P.</given-names></name>
</person-group><article-title>A Multichannel EMG System for Spatial Measurement of Diaphragm Activities</article-title><source>IEEE Sens. J.</source><year>2022</year><volume>22</volume><fpage>23393</fpage><lpage>23402</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2022.3213868</pub-id></element-citation></ref><ref id="B61-sensors-25-01078"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Vanbuis</surname><given-names>J.</given-names></name>
<name><surname>Feuilloy</surname><given-names>M.</given-names></name>
<name><surname>Baffet</surname><given-names>G.</given-names></name>
<name><surname>Meslier</surname><given-names>N.</given-names></name>
<name><surname>Gagnadoux</surname><given-names>F.</given-names></name>
<name><surname>Girault</surname><given-names>J.-M.</given-names></name>
</person-group><article-title>A New Sleep Staging System for Type III Sleep Studies Equipped With a Tracheal Sound Sensor</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2022</year><volume>69</volume><fpage>1225</fpage><lpage>1236</lpage><pub-id pub-id-type="doi">10.1109/TBME.2021.3120927</pub-id><pub-id pub-id-type="pmid">34665717</pub-id>
</element-citation></ref><ref id="B62-sensors-25-01078"><label>62.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Alam</surname><given-names>M.M.</given-names></name>
<name><surname>Hussain</surname><given-names>M.</given-names></name>
<name><surname>Amin</surname><given-names>M.A.</given-names></name>
</person-group><article-title>A Novel Design of a Respiratory Rate Monitoring System using a Push Switch Circuit and Arduino Micocontroller</article-title><source>Proceedings of the 2019 International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST)</source><conf-loc>Dhaka, Bangladesh</conf-loc><conf-date>10&#x02013;12 January 2019</conf-date><fpage>470</fpage><lpage>473</lpage></element-citation></ref><ref id="B63-sensors-25-01078"><label>63.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Qiu</surname><given-names>C.</given-names></name>
<name><surname>Yuce</surname><given-names>M.R.</given-names></name>
</person-group><article-title>A Wearable Bioimpedance Chest Patch for IoHT-Connected Respiration Monitoring</article-title><source>Proceedings of the 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Guadalajara, Jalisco, Mexico</conf-loc><conf-date>1&#x02013;5 November 2021</conf-date><fpage>6924</fpage><lpage>6927</lpage></element-citation></ref><ref id="B64-sensors-25-01078"><label>64.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Sharma</surname><given-names>P.</given-names></name>
<name><surname>Hui</surname><given-names>X.</given-names></name>
<name><surname>Kan</surname><given-names>E.C.</given-names></name>
</person-group><article-title>A Wearable RF Sensor for Monitoring Respiratory Patterns</article-title><source>Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</source><conf-loc>Berlin, Germany</conf-loc><conf-date>23&#x02013;27 July 2019</conf-date><fpage>1217</fpage><lpage>1223</lpage></element-citation></ref><ref id="B65-sensors-25-01078"><label>65.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Laufer</surname><given-names>B.</given-names></name>
<name><surname>Krueger-Ziolek</surname><given-names>S.</given-names></name>
<name><surname>Docherty</surname><given-names>P.D.</given-names></name>
<name><surname>Hoeflinger</surname><given-names>F.</given-names></name>
<name><surname>Reindl</surname><given-names>L.</given-names></name>
<name><surname>Moeller</surname><given-names>K.</given-names></name>
</person-group><article-title>An alternative way to measure respiration induced changes of circumferences: A pilot study</article-title><source>Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Montreal, QC, Canada</conf-loc><conf-date>20&#x02013;24 July 2020</conf-date><fpage>4632</fpage><lpage>4635</lpage></element-citation></ref><ref id="B66-sensors-25-01078"><label>66.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Nedoma</surname><given-names>J.</given-names></name>
<name><surname>Fajkus</surname><given-names>M.</given-names></name>
<name><surname>Kepak</surname><given-names>S.</given-names></name>
<name><surname>Cubik</surname><given-names>J.</given-names></name>
<name><surname>Zabka</surname><given-names>S.</given-names></name>
<name><surname>Martinek</surname><given-names>R.</given-names></name>
<name><surname>Slany</surname><given-names>V.</given-names></name>
<name><surname>Marecek</surname><given-names>J.</given-names></name>
</person-group><article-title>An Interferometric Sensor for Monitoring Respiratory and Heart Rate of the Human Body</article-title><source>Proceedings of the 2018 IEEE 20th International Conference on e-Health Networking, Applications and Services (Healthcom)</source><conf-loc>Ostrava, Czech Republic</conf-loc><conf-date>17&#x02013;20 September 2018</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B67-sensors-25-01078"><label>67.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Shakhih</surname><given-names>M.F.</given-names></name>
<name><surname>Nursyazana</surname><given-names>R.</given-names></name>
<name><surname>Asnida</surname><given-names>A.W.</given-names></name>
<name><surname>Maheza Irna</surname><given-names>M.S.</given-names></name>
</person-group><article-title>Assessment of Prolonged Expiration Breathing Using Infrared Thermal Imaging Modality: A Case Study</article-title><source>Proceedings of the 2018 2nd International Conference on BioSignal Analysis, Processing and Systems (ICBAPS)</source><conf-loc>Kuching, Malaysia</conf-loc><conf-date>24&#x02013;26 July 2018</conf-date><fpage>181</fpage><lpage>186</lpage></element-citation></ref><ref id="B68-sensors-25-01078"><label>68.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Nassi</surname><given-names>T.E.</given-names></name>
<name><surname>Ganglberger</surname><given-names>W.</given-names></name>
<name><surname>Sun</surname><given-names>H.</given-names></name>
<name><surname>Bucklin</surname><given-names>A.A.</given-names></name>
<name><surname>Biswal</surname><given-names>S.</given-names></name>
<name><surname>Van Putten</surname><given-names>M.J.A.M.</given-names></name>
<name><surname>Thomas</surname><given-names>R.J.</given-names></name>
<name><surname>Westover</surname><given-names>M.B.</given-names></name>
</person-group><article-title>Automated Scoring of Respiratory Events in Sleep with a Single Effort Belt and Deep Neural Networks</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2022</year><volume>69</volume><fpage>2094</fpage><lpage>2104</lpage><pub-id pub-id-type="doi">10.1109/TBME.2021.3136753</pub-id><pub-id pub-id-type="pmid">34928786</pub-id>
</element-citation></ref><ref id="B69-sensors-25-01078"><label>69.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Tataraidze</surname><given-names>A.</given-names></name>
<name><surname>Olesyuk</surname><given-names>R.</given-names></name>
<name><surname>Pikhletsky</surname><given-names>M.</given-names></name>
</person-group><article-title>Can We Monitor Breathing During Sleep via Wi-Fi on Smartphone?</article-title><source>Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</source><conf-loc>Berlin, Germany</conf-loc><conf-date>23&#x02013;27 July 2019</conf-date><fpage>6710</fpage><lpage>6713</lpage></element-citation></ref><ref id="B70-sensors-25-01078"><label>70.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Wang</surname><given-names>R.</given-names></name>
<name><surname>Zhang</surname><given-names>Y.</given-names></name>
<name><surname>Chen</surname><given-names>X.</given-names></name>
<name><surname>Lin</surname><given-names>F.</given-names></name>
<name><surname>He</surname><given-names>R.</given-names></name>
<name><surname>Lv</surname><given-names>R.</given-names></name>
<name><surname>Gao</surname><given-names>S.</given-names></name>
</person-group><article-title>Chest and Abdomen Respiratory Monitoring by Large Area Piezoresistive Array</article-title><source>Proceedings of the 2021 IEEE International Conference on Flexible and Printable Sensors and Systems (FLEPS)</source><conf-loc>Manchester, UK</conf-loc><conf-date>20&#x02013;23 June 2021</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B71-sensors-25-01078"><label>71.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Erdyarahman</surname><given-names>R.</given-names></name>
<name><surname>Suratman</surname><given-names>F.Y.</given-names></name>
<name><surname>Pramudita</surname><given-names>A.A.</given-names></name>
</person-group><article-title>Contactless Human Respiratory Frequency Monitoring System Based on FMCW Radar</article-title><source>Proceedings of the 2022 IEEE Asia Pacific Conference on Wireless and Mobile (APWiMob)</source><conf-loc>Bandung, Indonesia</conf-loc><conf-date>9&#x02013;10 December 2022</conf-date><fpage>1</fpage><lpage>7</lpage></element-citation></ref><ref id="B72-sensors-25-01078"><label>72.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Cruz</surname><given-names>J.C.D.</given-names></name>
<name><surname>Mercado</surname><given-names>I.L.R.</given-names></name>
<name><surname>Algabre</surname><given-names>M.K.N.</given-names></name>
</person-group><article-title>Deriving Heart Rate and Respiratory Rate from Pulse Oximetry Using Neural Networks</article-title><source>Proceedings of the 2021 IEEE 13th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)</source><conf-loc>Manila, Philippines</conf-loc><conf-date>28&#x02013;30 November 2021</conf-date><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B73-sensors-25-01078"><label>73.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Bevilacqua</surname><given-names>N.</given-names></name>
<name><surname>Andria</surname><given-names>G.</given-names></name>
<name><surname>Attivissimo</surname><given-names>F.</given-names></name>
<name><surname>Di Nisio</surname><given-names>A.</given-names></name>
<name><surname>Spadavecchia</surname><given-names>M.</given-names></name>
</person-group><article-title>Development of an adaptive bandwidth filter for the estimation of respiratory parameters using a piezoelectric belt</article-title><source>Proceedings of the 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA)</source><conf-loc>Messina, Italy</conf-loc><conf-date>22&#x02013;24 June 2022</conf-date><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B74-sensors-25-01078"><label>74.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Guede-Fernandez</surname><given-names>F.</given-names></name>
<name><surname>Fernandez-Chimeno</surname><given-names>M.</given-names></name>
<name><surname>Ramos-Castro</surname><given-names>J.</given-names></name>
<name><surname>Garcia-Gonzalez</surname><given-names>M.A.</given-names></name>
</person-group><article-title>Driver Drowsiness Detection Based on Respiratory Signal Analysis</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>81826</fpage><lpage>81838</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2924481</pub-id></element-citation></ref><ref id="B75-sensors-25-01078"><label>75.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Sanae</surname><given-names>A.</given-names></name>
<name><surname>Kawanaka</surname><given-names>H.</given-names></name>
<name><surname>Oguri</surname><given-names>K.</given-names></name>
</person-group><article-title>Drowsiness Estimation from Respiratory Index Obtained by Using Smart Seat Belt Buckle</article-title><source>Proceedings of the 2022 IEEE 11th Global Conference on Consumer Electronics (GCCE)</source><conf-loc>Osaka, Japan</conf-loc><conf-date>18&#x02013;21 October 2022</conf-date><fpage>479</fpage><lpage>481</lpage></element-citation></ref><ref id="B76-sensors-25-01078"><label>76.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Padasdao</surname><given-names>B.</given-names></name>
<name><surname>Shahhaidar</surname><given-names>E.</given-names></name>
<name><surname>Stickley</surname><given-names>C.</given-names></name>
<name><surname>Boric-Lubecke</surname><given-names>O.</given-names></name>
</person-group><article-title>Electromagnetic Biosensing of Tidal Volume</article-title><source>IEEE Sens. J.</source><year>2018</year><volume>18</volume><fpage>6391</fpage><lpage>6398</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2018.2844178</pub-id></element-citation></ref><ref id="B77-sensors-25-01078"><label>77.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Nedoma</surname><given-names>J.</given-names></name>
<name><surname>Kostelansky</surname><given-names>M.</given-names></name>
<name><surname>Vilimek</surname><given-names>D.</given-names></name>
<name><surname>Ladrova</surname><given-names>M.</given-names></name>
<name><surname>Martinek</surname><given-names>R.</given-names></name>
<name><surname>Kahankova</surname><given-names>R.</given-names></name>
<name><surname>Fajkus</surname><given-names>M.</given-names></name>
<name><surname>Brablik</surname><given-names>J.</given-names></name>
<name><surname>Hanzlikova</surname><given-names>P.</given-names></name>
<name><surname>Mohammed</surname><given-names>M.A.</given-names></name>
<etal/>
</person-group><article-title>Fiber-Optic Breathing Mask: An Alternative Solution for MRI Respiratory Triggering</article-title><source>IEEE Trans. Instrum. Meas.</source><year>2022</year><volume>71</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1109/TIM.2022.3168933</pub-id></element-citation></ref><ref id="B78-sensors-25-01078"><label>78.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>H&#x000e4;rm&#x000e4;</surname><given-names>A.</given-names></name>
<name><surname>Gro&#x000df;ekath&#x000f6;fer</surname><given-names>U.</given-names></name>
<name><surname>Ouweltjes</surname><given-names>O.</given-names></name>
<name><surname>Nallanthighal</surname><given-names>V.S.</given-names></name>
</person-group><article-title>Forecasting of Breathing Events from Speech for Respiratory Support</article-title><source>Proceedings of the ICASSP 2023&#x02014;2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</source><conf-loc>Rhodes Island, Greece</conf-loc><conf-date>4&#x02013;10 June 2023</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B79-sensors-25-01078"><label>79.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>Z.</given-names></name>
<name><surname>Sharma</surname><given-names>P.</given-names></name>
<name><surname>Zhou</surname><given-names>J.</given-names></name>
<name><surname>Hui</surname><given-names>X.</given-names></name>
<name><surname>Kan</surname><given-names>E.C.</given-names></name>
</person-group><article-title>Furniture-Integrated Respiration Sensors by Notched Transmission Lines</article-title><source>IEEE Sens. J.</source><year>2021</year><volume>21</volume><fpage>5303</fpage><lpage>5311</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2020.3028970</pub-id><pub-id pub-id-type="pmid">33746625</pub-id>
</element-citation></ref><ref id="B80-sensors-25-01078"><label>80.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Mukhopadhyay</surname><given-names>B.</given-names></name>
<name><surname>Sharma</surname><given-names>O.</given-names></name>
<name><surname>Kar</surname><given-names>S.</given-names></name>
</person-group><article-title>IoT Based Wearable Knitted Fabric Respiratory Monitoring System</article-title><source>Proceedings of the 2018 IEEE SENSORS</source><conf-loc>New Delhi, India</conf-loc><conf-date>28&#x02013;31 October 2018</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B81-sensors-25-01078"><label>81.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Addeh</surname><given-names>A.</given-names></name>
<name><surname>Ardila</surname><given-names>K.</given-names></name>
<name><surname>Vega</surname><given-names>F.</given-names></name>
<name><surname>Golestani</surname><given-names>A.</given-names></name>
<name><surname>MacDonald</surname><given-names>M.E.</given-names></name>
</person-group><article-title>Limitations of the Derived Respiratory Variation Measurements Used in Functional Magnetic Resonance Imaging</article-title><source>Proceedings of the 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)</source><conf-loc>Cartagena, Colombia</conf-loc><conf-date>18&#x02013;21 April 2023</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B82-sensors-25-01078"><label>82.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Piuzzi</surname><given-names>E.</given-names></name>
<name><surname>Pisa</surname><given-names>S.</given-names></name>
<name><surname>Pittella</surname><given-names>E.</given-names></name>
<name><surname>Podesta</surname><given-names>L.</given-names></name>
<name><surname>Sangiovanni</surname><given-names>S.</given-names></name>
</person-group><article-title>Low-Cost and Portable Impedance Plethysmography System for the Simultaneous Detection of Respiratory and Heart Activities</article-title><source>IEEE Sens. J.</source><year>2019</year><volume>19</volume><fpage>2735</fpage><lpage>2746</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2018.2887303</pub-id></element-citation></ref><ref id="B83-sensors-25-01078"><label>83.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Erdogan</surname><given-names>S.</given-names></name>
<name><surname>Yilmaz</surname><given-names>S.</given-names></name>
<name><surname>Oncu</surname><given-names>A.</given-names></name>
</person-group><article-title>Microwave Noncontact Vital Sign Measurements for Medical Applications</article-title><source>Proceedings of the 2019 IEEE International Symposium on Medical Measurements and Applications (MeMeA)</source><conf-loc>Istanbul, Turkey</conf-loc><conf-date>26&#x02013;28 June 2019</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B84-sensors-25-01078"><label>84.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Altekreeti</surname><given-names>A.</given-names></name>
<name><surname>Roberts</surname><given-names>M.</given-names></name>
<name><surname>Convey</surname><given-names>D.</given-names></name>
<name><surname>Leighton</surname><given-names>S.</given-names></name>
<name><surname>Setear</surname><given-names>M.</given-names></name>
<name><surname>Cay</surname><given-names>G.</given-names></name>
<name><surname>Solanki</surname><given-names>D.</given-names></name>
<name><surname>Mankodiya</surname><given-names>K.</given-names></name>
</person-group><article-title>NAPNEA: A Cost Effective Neonatal Apnea Detection System</article-title><source>Proceedings of the 2021 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)</source><conf-loc>Washington, DC, USA</conf-loc><conf-date>16&#x02013;18 December 2021</conf-date><fpage>113</fpage><lpage>114</lpage></element-citation></ref><ref id="B85-sensors-25-01078"><label>85.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Zhao</surname><given-names>H.</given-names></name>
<name><surname>Gao</surname><given-names>X.</given-names></name>
<name><surname>Jiang</surname><given-names>X.</given-names></name>
<name><surname>Hong</surname><given-names>H.</given-names></name>
<name><surname>Liu</surname><given-names>X.</given-names></name>
</person-group><article-title>Non-contact Robust Respiration Detection by Using Radar-Depth Camera Sensor Fusion</article-title><source>Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Montreal, QC, Canada</conf-loc><conf-date>20&#x02013;24 July 2020</conf-date><fpage>4183</fpage><lpage>4186</lpage></element-citation></ref><ref id="B86-sensors-25-01078"><label>86.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Nabavi</surname><given-names>S.</given-names></name>
<name><surname>Bhadra</surname><given-names>S.</given-names></name>
</person-group><article-title>Oral Cavity Pressure Measurement-based Respiratory Monitoring System with Reduced Susceptibility to Motion Artifacts</article-title><source>Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Montreal, QC, Canada</conf-loc><conf-date>20&#x02013;24 July 2020</conf-date><fpage>5900</fpage><lpage>5904</lpage></element-citation></ref><ref id="B87-sensors-25-01078"><label>87.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Nallanthighal</surname><given-names>V.S.</given-names></name>
<name><surname>Harma</surname><given-names>A.</given-names></name>
<name><surname>Strik</surname><given-names>H.</given-names></name>
<name><surname>Doss</surname><given-names>M.M.</given-names></name>
</person-group><article-title>Phoneme Based Respiratory Analysis of Read Speech</article-title><source>Proceedings of the 2021 29th European Signal Processing Conference (EUSIPCO)</source><conf-loc>Dublin, Ireland</conf-loc><conf-date>23&#x02013;27 August 2021</conf-date><fpage>191</fpage><lpage>195</lpage></element-citation></ref><ref id="B88-sensors-25-01078"><label>88.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Kjar</surname><given-names>M.R.</given-names></name>
<name><surname>Brink-Kjar</surname><given-names>A.</given-names></name>
<name><surname>Hanif</surname><given-names>U.</given-names></name>
<name><surname>Mignot</surname><given-names>E.</given-names></name>
<name><surname>Jennum</surname><given-names>P.</given-names></name>
<name><surname>Sorensen</surname><given-names>H.B.D.</given-names></name>
</person-group><article-title>Polysomnographic Plethysmography Excursions are Reduced in Obese Elderly Men</article-title><source>Proceedings of the 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Guadalajara, Jalisco, Mexico</conf-loc><conf-date>1&#x02013;5 November 2021</conf-date><fpage>2396</fpage><lpage>2399</lpage></element-citation></ref><ref id="B89-sensors-25-01078"><label>89.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Li</surname><given-names>Z.</given-names></name>
<name><surname>Jin</surname><given-names>T.</given-names></name>
<name><surname>Hu</surname><given-names>X.</given-names></name>
<name><surname>Song</surname><given-names>Y.</given-names></name>
<name><surname>Zhang</surname><given-names>J.</given-names></name>
<name><surname>Sang</surname><given-names>Z.</given-names></name>
</person-group><article-title>Remote Respiratory and Cardiac Motion Patterns Separation With 4D Imaging Radars</article-title><source>IEEE J. Biomed. Health Inform.</source><year>2023</year><volume>27</volume><fpage>2717</fpage><lpage>2728</lpage><pub-id pub-id-type="doi">10.1109/JBHI.2022.3171554</pub-id><pub-id pub-id-type="pmid">35503846</pub-id>
</element-citation></ref><ref id="B90-sensors-25-01078"><label>90.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Torres</surname><given-names>J.L.</given-names></name>
<name><surname>Yumang</surname><given-names>A.</given-names></name>
<name><surname>Hortinela</surname><given-names>C.</given-names></name>
<name><surname>Plameras</surname><given-names>J.M.F.</given-names></name>
<name><surname>Si</surname><given-names>J.E.Z.</given-names></name>
<name><surname>Uywan</surname><given-names>J.A.O.</given-names></name>
</person-group><article-title>Respiratory Inductance Plethysmography for Long-Distance Medical Consultation Using Mobile Application for Android Smartphones</article-title><source>Proceedings of the 2019 IEEE International Conference on Consumer Electronics&#x02014;Asia (ICCE-Asia)</source><conf-loc>Bangkok, Thailand</conf-loc><conf-date>12&#x02013;14 June 2019</conf-date><fpage>187</fpage><lpage>189</lpage></element-citation></ref><ref id="B91-sensors-25-01078"><label>91.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Slastnikov</surname><given-names>K.</given-names></name>
<name><surname>Koscheeva</surname><given-names>E.</given-names></name>
<name><surname>Chupov</surname><given-names>A.</given-names></name>
<name><surname>Konstantinova</surname><given-names>A.</given-names></name>
</person-group><article-title>Review of Instrumental Methods for Detecting the Respiratory Signal</article-title><source>Proceedings of the 2021 IEEE Ural-Siberian Conference on Computational Technologies in Cognitive Science, Genomics and Biomedicine (CSGB)</source><conf-loc>Novosibirsk-Yekaterinburg, Russia</conf-loc><conf-date>26&#x02013;28 May 2021</conf-date><fpage>110</fpage><lpage>113</lpage></element-citation></ref><ref id="B92-sensors-25-01078"><label>92.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Islam</surname><given-names>S.M.M.</given-names></name>
<name><surname>Yavari</surname><given-names>E.</given-names></name>
<name><surname>Rahman</surname><given-names>A.</given-names></name>
<name><surname>Lubecke</surname><given-names>V.M.</given-names></name>
<name><surname>Boric-Lubecke</surname><given-names>O.</given-names></name>
</person-group><article-title>Separation of Respiratory Signatures for Multiple Subjects Using Independent Component Analysis with the JADE Algorithm</article-title><source>Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</source><conf-loc>Honolulu, HI, USA</conf-loc><conf-date>18&#x02013;21 July 2018</conf-date><fpage>1234</fpage><lpage>1237</lpage></element-citation></ref><ref id="B93-sensors-25-01078"><label>93.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Valentina</surname><given-names>Z.</given-names></name>
<name><surname>Mario</surname><given-names>V.</given-names></name>
<name><surname>Juliane</surname><given-names>C.</given-names></name>
<name><surname>Vincent</surname><given-names>N.</given-names></name>
<name><surname>Sami</surname><given-names>A.</given-names></name>
<name><surname>Morwena</surname><given-names>L.</given-names></name>
</person-group><article-title>The Gastric Myoelectrical Activity Response to Emotional Stimuli</article-title><source>Proceedings of the 2018 IX International Seminar of Biomedical Engineering (SIB)</source><conf-loc>Bogota, Colombia</conf-loc><conf-date>16&#x02013;18 May 2018</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B94-sensors-25-01078"><label>94.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Sacco</surname><given-names>G.</given-names></name>
<name><surname>Piuzzi</surname><given-names>E.</given-names></name>
<name><surname>Pittella</surname><given-names>E.</given-names></name>
<name><surname>Pisa</surname><given-names>S.</given-names></name>
</person-group><article-title>Vital Signs Monitoring for Different Chest Orientations Using an FMCW Radar</article-title><source>Proceedings of the 2020 XXXIIIrd General Assembly and Scientific Symposium of the International Union of Radio Science</source><conf-loc>Rome, Italy</conf-loc><conf-date>29 August&#x02013;5 September 2020</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B95-sensors-25-01078"><label>95.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kang</surname><given-names>W.</given-names></name>
<name><surname>Zhou</surname><given-names>C.</given-names></name>
<name><surname>Wu</surname><given-names>W.</given-names></name>
</person-group><article-title>Respiration Monitoring of All Occupants in a Vehicle Using Time-Division Multiplexing FMCW Radar Based on Metasurface Technology</article-title><source>IEEE Trans. Microw. Theory Technol.</source><year>2024</year><volume>72</volume><fpage>4960</fpage><lpage>4974</lpage><pub-id pub-id-type="doi">10.1109/TMTT.2024.3361949</pub-id></element-citation></ref><ref id="B96-sensors-25-01078"><label>96.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Deshpande</surname><given-names>G.</given-names></name>
<name><surname>Schuller</surname><given-names>B.W.</given-names></name>
<name><surname>Deshpande</surname><given-names>P.</given-names></name>
<name><surname>Joshi</surname><given-names>A.R.</given-names></name>
</person-group><article-title>Automatic Breathing Pattern Analysis from Reading-Speech Signals</article-title><source>Proceedings of the 2023 45th Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Sydney, Australia</conf-loc><conf-date>24&#x02013;27 July 2023</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B97-sensors-25-01078"><label>97.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Elfaramawy</surname><given-names>T.</given-names></name>
<name><surname>Fall</surname><given-names>C.L.</given-names></name>
<name><surname>Arab</surname><given-names>S.</given-names></name>
<name><surname>Morissette</surname><given-names>M.</given-names></name>
<name><surname>Lellouche</surname><given-names>F.</given-names></name>
<name><surname>Gosselin</surname><given-names>B.</given-names></name>
</person-group><article-title>A Wireless Respiratory Monitoring System Using a Wearable Patch Sensor Network</article-title><source>IEEE Sens. J.</source><year>2019</year><volume>19</volume><fpage>650</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2018.2877617</pub-id></element-citation></ref><ref id="B98-sensors-25-01078"><label>98.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Bricout</surname><given-names>A.</given-names></name>
<name><surname>Fontecave-Jallon</surname><given-names>J.</given-names></name>
<name><surname>Colas</surname><given-names>D.</given-names></name>
<name><surname>Gerard</surname><given-names>G.</given-names></name>
<name><surname>Pepin</surname><given-names>J.-L.</given-names></name>
<name><surname>Gumery</surname><given-names>P.-Y.</given-names></name>
</person-group><article-title>Adaptive Accelerometry Derived Respiration: Comparison with Respiratory Inductance Plethysmography during Sleep</article-title><source>Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</source><conf-loc>Berlin, Germany</conf-loc><conf-date>23&#x02013;27 July 2019</conf-date><fpage>6714</fpage><lpage>6717</lpage></element-citation></ref><ref id="B99-sensors-25-01078"><label>99.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Bin Nesar</surname><given-names>M.S.</given-names></name>
<name><surname>Trippe</surname><given-names>K.</given-names></name>
<name><surname>Stapley</surname><given-names>R.</given-names></name>
<name><surname>Whitaker</surname><given-names>B.M.</given-names></name>
<name><surname>Hill</surname><given-names>B.</given-names></name>
</person-group><article-title>Improving Touchless Respiratory Monitoring via LiDAR Orientation and Thermal Imaging</article-title><source>Proceedings of the 2022 IEEE Aerospace Conference (AERO)</source><conf-loc>Big Sky, MT, USA</conf-loc><conf-date>5&#x02013;12 March 2022</conf-date><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="B100-sensors-25-01078"><label>100.</label><element-citation publication-type="gov"><person-group person-group-type="author">
<name><surname>Sadr</surname><given-names>N.</given-names></name>
</person-group><article-title>Non-invasive Diagnosis of Sleep Apnoea Using ECG and Respiratory Bands</article-title><comment>Available online: <ext-link xlink:href="https://pubmed.ncbi.nlm.nih.gov/31946204/" ext-link-type="uri">https://pubmed.ncbi.nlm.nih.gov/31946204/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-06">(accessed on 6 February 2025)</date-in-citation></element-citation></ref><ref id="B101-sensors-25-01078"><label>101.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Hurtado</surname><given-names>D.E.</given-names></name>
<name><surname>Chavez</surname><given-names>J.A.P.</given-names></name>
<name><surname>Mansilla</surname><given-names>R.</given-names></name>
<name><surname>Lopez</surname><given-names>R.</given-names></name>
<name><surname>Abusleme</surname><given-names>A.</given-names></name>
</person-group><article-title>Respiratory Volume Monitoring: A Machine-Learning Approach to the Non-Invasive Prediction of Tidal Volume and Minute Ventilation</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>227936</fpage><lpage>227944</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.3045603</pub-id></element-citation></ref><ref id="B102-sensors-25-01078"><label>102.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Huysmans</surname><given-names>D.</given-names></name>
<name><surname>Castro</surname><given-names>I.</given-names></name>
<name><surname>Heffinck</surname><given-names>E.</given-names></name>
<name><surname>Deviaene</surname><given-names>M.</given-names></name>
<name><surname>Borz&#x000e9;e</surname><given-names>P.</given-names></name>
<name><surname>Buyse</surname><given-names>B.</given-names></name>
<name><surname>Testelmans</surname><given-names>D.</given-names></name>
<name><surname>Van Huffel</surname><given-names>S.</given-names></name>
<name><surname>Varon</surname><given-names>C.</given-names></name>
</person-group><article-title>Sleep-Wake Classification for Home Monitoring of Sleep Apnea Patients</article-title><source>Comput. Cardiol.</source><year>2020</year><volume>2020</volume><fpage>9344196</fpage></element-citation></ref><ref id="B103-sensors-25-01078"><label>103.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mannee</surname><given-names>D.</given-names></name>
<name><surname>Van Helvoort</surname><given-names>H.</given-names></name>
<name><surname>De Jongh</surname><given-names>F.</given-names></name>
</person-group><article-title>The Feasibility of Measuring Lung Hyperinflation with a Smart Shirt: An in Vitro Study</article-title><source>IEEE Sens. J.</source><year>2020</year><volume>20</volume><fpage>15154</fpage><lpage>15162</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2020.3010265</pub-id></element-citation></ref><ref id="B104-sensors-25-01078"><label>104.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Hill</surname><given-names>B.</given-names></name>
<name><surname>Stapley</surname><given-names>R.</given-names></name>
<name><surname>Bin Nesar</surname><given-names>M.S.</given-names></name>
<name><surname>Whitaker</surname><given-names>B.M.</given-names></name>
</person-group><article-title>Touchless Respiratory Monitor Preliminary Data and Results</article-title><source>Proceedings of the 2021 IEEE Aerospace Conference (50100)</source><conf-loc>Big Sky, MT, USA</conf-loc><conf-date>6&#x02013;13 March 2021</conf-date><fpage>1</fpage><lpage>7</lpage></element-citation></ref><ref id="B105-sensors-25-01078"><label>105.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Guo</surname><given-names>S.</given-names></name>
<name><surname>Zhao</surname><given-names>X.</given-names></name>
<name><surname>Matsuo</surname><given-names>K.</given-names></name>
<name><surname>Liu</surname><given-names>J.</given-names></name>
<name><surname>Mukai</surname><given-names>T.</given-names></name>
</person-group><article-title>Unconstrained Detection of the Respiratory Motions of Chest and Abdomen in Different Lying Positions Using a Flexible Tactile Sensor Array</article-title><source>IEEE Sens. J.</source><year>2019</year><volume>19</volume><fpage>10067</fpage><lpage>10076</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2019.2925022</pub-id></element-citation></ref><ref id="B106-sensors-25-01078"><label>106.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Song</surname><given-names>Y.</given-names></name>
<name><surname>Guo</surname><given-names>S.</given-names></name>
<name><surname>Xiao</surname><given-names>S.</given-names></name>
<name><surname>Zhao</surname><given-names>X.</given-names></name>
</person-group><article-title>Unconstrained Identification of the Positions of Chest and Abdomen and Detection of Respiratory Motions in Sleep by Using a Bed-Size Tactile Sensor Sheet</article-title><source>IEEE Sens. J.</source><year>2023</year><volume>23</volume><fpage>16276</fpage><lpage>16286</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2023.3282746</pub-id></element-citation></ref><ref id="B107-sensors-25-01078"><label>107.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Rathore</surname><given-names>K.S.</given-names></name>
<name><surname>Sricharan</surname><given-names>V.</given-names></name>
<name><surname>Preejith</surname><given-names>S.</given-names></name>
<name><surname>Sivaprakasam</surname><given-names>M.</given-names></name>
</person-group><article-title>MRNet&#x02014;A Deep Learning Based Multitasking Model for Respiration Rate Estimation in Practical Settings</article-title><source>Proceedings of the 2022 IEEE 10th International Conference on Serious Games and Applications for Health (SeGAH)</source><conf-loc>Sydney, Australia</conf-loc><conf-date>10&#x02013;12 August 2022</conf-date><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B108-sensors-25-01078"><label>108.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Nabavi</surname><given-names>S.K.</given-names></name>
<name><surname>Moghadam</surname><given-names>A.K.</given-names></name>
<name><surname>Salahi</surname><given-names>S.</given-names></name>
</person-group><article-title>A Highly Sensitive Surface Acoustic Wave Sensor for Continuous Respiratory Monitoring</article-title><source>Proceedings of the 2023 IEEE SENSORS</source><conf-loc>Vienna, Austria</conf-loc><conf-date>29 October&#x02013;1 November 2023</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B109-sensors-25-01078"><label>109.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Akamatsu</surname><given-names>Y.</given-names></name>
<name><surname>Umematsu</surname><given-names>T.</given-names></name>
<name><surname>Imaoka</surname><given-names>H.</given-names></name>
</person-group><article-title>CalibrationPhys: Self-supervised Video-based Heart and Respiratory Rate Measurements by Calibrating Between Multiple Cameras</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type="arxiv">2310.15043</pub-id><pub-id pub-id-type="doi">10.1109/JBHI.2023.3345486</pub-id></element-citation></ref><ref id="B110-sensors-25-01078"><label>110.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Senyurek</surname><given-names>V.Y.</given-names></name>
<name><surname>Imtiaz</surname><given-names>M.H.</given-names></name>
<name><surname>Belsare</surname><given-names>P.</given-names></name>
<name><surname>Tiffany</surname><given-names>S.</given-names></name>
<name><surname>Sazonov</surname><given-names>E.</given-names></name>
</person-group><article-title>A Comparison of SVM and CNN-LSTM Based Approach for Detecting Smoke Inhalations from Respiratory signal</article-title><source>Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</source><conf-loc>Berlin, Germany</conf-loc><conf-date>23&#x02013;27 July 2019</conf-date><fpage>3262</fpage><lpage>3265</lpage></element-citation></ref><ref id="B111-sensors-25-01078"><label>111.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Schulz</surname><given-names>S.</given-names></name>
<name><surname>Serra Juh&#x000e9;</surname><given-names>A.</given-names></name>
<name><surname>Giraldo</surname><given-names>B.</given-names></name>
<name><surname>Haueisen</surname><given-names>J.</given-names></name>
<name><surname>Baer</surname><given-names>K.-J.</given-names></name>
<name><surname>Voss</surname><given-names>A.</given-names></name>
</person-group><article-title>Analysis of Linear and Nonlinear Central-Cardiorespiratory Coupling Pathways in Healthy Subjects</article-title><source>Proceedings of the 2018 Computing in Cardiology Conference</source><conf-loc>Maastricht, The Netherlands</conf-loc><conf-date>23&#x02013;26 September 2018</conf-date></element-citation></ref><ref id="B112-sensors-25-01078"><label>112.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Azimi</surname><given-names>H.</given-names></name>
<name><surname>Gilakjani</surname><given-names>S.S.</given-names></name>
<name><surname>Bouchard</surname><given-names>M.</given-names></name>
<name><surname>Goubran</surname><given-names>R.A.</given-names></name>
<name><surname>Knoefel</surname><given-names>F.</given-names></name>
</person-group><article-title>Automatic apnea-hypopnea events detection using an alternative sensor</article-title><source>Proceedings of the 2018 IEEE Sensors Applications Symposium (SAS)</source><conf-loc>Seoul, Republic of Korea</conf-loc><conf-date>12&#x02013;14 March 2018</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B113-sensors-25-01078"><label>113.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Mateu-Mateus</surname><given-names>M.</given-names></name>
<name><surname>Guede-Fernandez</surname><given-names>F.</given-names></name>
<name><surname>Garcia-Gonzalez</surname><given-names>M.A.</given-names></name>
<name><surname>Ramos-Castro</surname><given-names>J.J.</given-names></name>
<name><surname>Fernandez-Chimeno</surname><given-names>M.</given-names></name>
</person-group><article-title>Camera-Based Method for Respiratory Rhythm Extraction from a Lateral Perspective</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>154924</fpage><lpage>154939</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.3018616</pub-id></element-citation></ref><ref id="B114-sensors-25-01078"><label>114.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Belsare</surname><given-names>P.</given-names></name>
<name><surname>Senyurek</surname><given-names>V.Y.</given-names></name>
<name><surname>Imtiaz</surname><given-names>M.H.</given-names></name>
<name><surname>Tiffany</surname><given-names>S.</given-names></name>
<name><surname>Sazonov</surname><given-names>E.</given-names></name>
</person-group><article-title>Computation of Cigarette Smoke Exposure Metrics from Breathing</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2020</year><volume>67</volume><fpage>2309</fpage><lpage>2316</lpage><pub-id pub-id-type="doi">10.1109/TBME.2019.2958843</pub-id><pub-id pub-id-type="pmid">31831405</pub-id>
</element-citation></ref><ref id="B115-sensors-25-01078"><label>115.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Lyakhova</surname><given-names>E.K.</given-names></name>
<name><surname>Shlyakhotka</surname><given-names>A.V.</given-names></name>
<name><surname>Sutyagina</surname><given-names>A.D.</given-names></name>
</person-group><article-title>Design of a wearable module for respiratory rate registration rased on multiply network</article-title><source>Proceedings of the 2018 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus)</source><conf-loc>Moscow, Russia</conf-loc><conf-date>29 January&#x02013;1 February 2018</conf-date><fpage>1212</fpage><lpage>1215</lpage></element-citation></ref><ref id="B116-sensors-25-01078"><label>116.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>P.-H.</given-names></name>
<name><surname>Chung</surname><given-names>W.-C.</given-names></name>
<name><surname>Sheu</surname><given-names>C.-C.</given-names></name>
<name><surname>Tsai</surname><given-names>J.-R.</given-names></name>
<name><surname>Hsiao</surname><given-names>T.-C.</given-names></name>
</person-group><article-title>Is the asynchronous phase of thoracoabdominal movement a novel feature of successful extubation? A preliminary result</article-title><source>Proceedings of the 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Guadalajara, Jalisco, Mexico</conf-loc><conf-date>1&#x02013;5 November 2021</conf-date><fpage>752</fpage><lpage>756</lpage></element-citation></ref><ref id="B117-sensors-25-01078"><label>117.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Huang</surname><given-names>P.-H.</given-names></name>
<name><surname>Luo</surname><given-names>Y.-F.</given-names></name>
<name><surname>Yeh</surname><given-names>C.-F.</given-names></name>
<name><surname>Hsiao</surname><given-names>T.-C.</given-names></name>
</person-group><article-title>Towards instantaneous phase difference on the COPD pre-discrimination</article-title><source>Proceedings of the 2018 IEEE 23rd International Conference on Digital Signal Processing (DSP)</source><conf-loc>Shanghai, China</conf-loc><conf-date>19&#x02013;21 November 2018</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B118-sensors-25-01078"><label>118.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhu</surname><given-names>K.</given-names></name>
<name><surname>Li</surname><given-names>M.</given-names></name>
<name><surname>Akbarian</surname><given-names>S.</given-names></name>
<name><surname>Hafezi</surname><given-names>M.</given-names></name>
<name><surname>Yadollahi</surname><given-names>A.</given-names></name>
<name><surname>Taati</surname><given-names>B.</given-names></name>
</person-group><article-title>Vision-Based Heart and Respiratory Rate Monitoring During Sleep&#x02014;A Validation Study for the Population at Risk of Sleep Apnea</article-title><source>IEEE J. Transl. Eng. Health Med.</source><year>2019</year><volume>7</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1109/JTEHM.2019.2946147</pub-id><pub-id pub-id-type="pmid">32166048</pub-id>
</element-citation></ref><ref id="B119-sensors-25-01078"><label>119.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Sol&#x000e0;-Soler</surname><given-names>J.</given-names></name>
<name><surname>P&#x000e9;rez</surname><given-names>D.R.</given-names></name>
<name><surname>Balchin</surname><given-names>L.</given-names></name>
<name><surname>Serra</surname><given-names>A.M.</given-names></name>
<name><surname>Torn&#x000e9;</surname><given-names>M.L.</given-names></name>
<name><surname>Koborzan</surname><given-names>M.R.P.</given-names></name>
<name><surname>Giraldo</surname><given-names>B.F.G.</given-names></name>
</person-group><article-title>Respiratory Pattern Analysis for Different Breathing Types and Recording Sensors in Healthy Subjects</article-title><source>Proceedings of the 2023 45th Annual International Conference of the IEEE Engineering in Medicine &#x00026; Biology Society (EMBC)</source><conf-loc>Sydney, Australia</conf-loc><conf-date>24&#x02013;27 July 2023</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B120-sensors-25-01078"><label>120.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Zhang</surname><given-names>F.</given-names></name>
<name><surname>Zhang</surname><given-names>Z.</given-names></name>
<name><surname>Kang</surname><given-names>L.</given-names></name>
<name><surname>Zhou</surname><given-names>A.</given-names></name>
</person-group><article-title><italic toggle="yes">mmTAA</italic>: A Contact-Less Thoracoabdominal Asynchrony Measurement System Based on Mmwave Sensing</article-title><source>IEEE Trans. Mobile Comput.</source><year>2024</year><volume>24</volume><fpage>627</fpage><lpage>641</lpage><pub-id pub-id-type="doi">10.1109/TMC.2024.3461784</pub-id></element-citation></ref><ref id="B121-sensors-25-01078"><label>121.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Ghimire</surname><given-names>A.</given-names></name>
<name><surname>Thapa</surname><given-names>S.</given-names></name>
<name><surname>Jha</surname><given-names>A.K.</given-names></name>
<name><surname>Kumar</surname><given-names>A.</given-names></name>
<name><surname>Kumar</surname><given-names>A.</given-names></name>
<name><surname>Adhikari</surname><given-names>S.</given-names></name>
</person-group><article-title>AI and IoT Solutions for Tackling COVID-19 Pandemic</article-title><source>Proceedings of the 2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA)</source><conf-loc>Coimbatore, India</conf-loc><conf-date>5&#x02013;7 November 2020</conf-date><fpage>1083</fpage><lpage>1092</lpage></element-citation></ref><ref id="B122-sensors-25-01078"><label>122.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Nikos Fakotakis</surname><given-names>D.</given-names></name>
<name><surname>Nousias</surname><given-names>S.</given-names></name>
<name><surname>Arvanitis</surname><given-names>G.</given-names></name>
<name><surname>Zacharaki</surname><given-names>E.I.</given-names></name>
<name><surname>Moustakas</surname><given-names>K.</given-names></name>
</person-group><article-title>AI Sound Recognition on Asthma Medication Adherence: Evaluation With the RDA Benchmark Suite</article-title><source>IEEE Access</source><year>2023</year><volume>11</volume><fpage>13810</fpage><lpage>13829</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2023.3243547</pub-id></element-citation></ref><ref id="B123-sensors-25-01078"><label>123.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Elias</surname><given-names>V.</given-names></name>
<name><surname>Rabih</surname><given-names>A.</given-names></name>
<name><surname>Bin</surname><given-names>S.</given-names></name>
<name><surname>Aziz</surname><given-names>H.</given-names></name>
<name><surname>Nassar</surname><given-names>G.</given-names></name>
</person-group><article-title>An autonomous acoustic collar to quantify the severity of covid-19 effects by analyzing the vibratory components of vocal and respiratory systems</article-title><source>Proceedings of the 2021 IEEE International Conference on Design &#x00026; Test of Integrated Micro &#x00026; Nano-Systems (DTS)</source><conf-loc>Sfax, Tunisia</conf-loc><conf-date>7&#x02013;10 June 2021</conf-date><fpage>1</fpage><lpage>7</lpage></element-citation></ref><ref id="B124-sensors-25-01078"><label>124.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Husain</surname><given-names>M.</given-names></name>
<name><surname>Simpkin</surname><given-names>A.</given-names></name>
<name><surname>Gibbons</surname><given-names>C.</given-names></name>
<name><surname>Talkar</surname><given-names>T.</given-names></name>
<name><surname>Low</surname><given-names>D.</given-names></name>
<name><surname>Bonato</surname><given-names>P.</given-names></name>
<name><surname>Ghosh</surname><given-names>S.S.</given-names></name>
<name><surname>Quatieri</surname><given-names>T.</given-names></name>
<name><surname>O&#x02019;Keeffe</surname><given-names>D.T.</given-names></name>
</person-group><article-title>Artificial Intelligence for Detecting COVID-19 With the Aid of Human Cough, Breathing and Speech Signals: Scoping Review</article-title><source>IEEE Open J. Eng. Med. Biol.</source><year>2022</year><volume>3</volume><fpage>235</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1109/OJEMB.2022.3143688</pub-id><pub-id pub-id-type="pmid">36819937</pub-id>
</element-citation></ref><ref id="B125-sensors-25-01078"><label>125.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Yahyaoui</surname><given-names>A.</given-names></name>
<name><surname>Yumusak</surname><given-names>N.</given-names></name>
</person-group><article-title>Deep and Machine Learning Towards Pneumonia And Asthma Detection</article-title><source>Proceedings of the 2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)</source><conf-loc>Zallaq, Bahrain</conf-loc><conf-date>29&#x02013;30 September 2021</conf-date><fpage>494</fpage><lpage>497</lpage></element-citation></ref><ref id="B126-sensors-25-01078"><label>126.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Ward</surname><given-names>R.J.</given-names></name>
<name><surname>Mark Jjunju</surname><given-names>F.P.</given-names></name>
<name><surname>Kabenge</surname><given-names>I.</given-names></name>
<name><surname>Wanyenze</surname><given-names>R.</given-names></name>
<name><surname>Griffith</surname><given-names>E.J.</given-names></name>
<name><surname>Banadda</surname><given-names>N.</given-names></name>
<name><surname>Taylor</surname><given-names>S.</given-names></name>
<name><surname>Marshall</surname><given-names>A.</given-names></name>
</person-group><article-title>FluNet: An AI-Enabled Influenza-Like Warning System</article-title><source>IEEE Sens. J.</source><year>2021</year><volume>21</volume><fpage>24740</fpage><lpage>24748</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2021.3113467</pub-id><pub-id pub-id-type="pmid">35582344</pub-id>
</element-citation></ref><ref id="B127-sensors-25-01078"><label>127.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Campana</surname><given-names>M.G.</given-names></name>
<name><surname>Rovati</surname><given-names>A.</given-names></name>
<name><surname>Delmastro</surname><given-names>F.</given-names></name>
<name><surname>Pagani</surname><given-names>E.</given-names></name>
</person-group><article-title>L<sup>3</sup>-Net Deep Audio Embeddings to Improve COVID-19 Detection from Smartphone Data</article-title><source>Proceedings of the 2022 IEEE International Conference on Smart Computing (SMARTCOMP)</source><conf-loc>Helsinki, Finland</conf-loc><conf-date>20&#x02013;24 June 2022</conf-date><fpage>100</fpage><lpage>107</lpage></element-citation></ref><ref id="B128-sensors-25-01078"><label>128.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Romero Gomez</surname><given-names>A.F.</given-names></name>
<name><surname>Orjuela-Canon</surname><given-names>A.D.</given-names></name>
</person-group><article-title>Respiratory Sounds Classification employing a Multi-label Approach</article-title><source>Proceedings of the 2021 IEEE Colombian Conference on Applications of Computational Intelligence (ColCACI)</source><conf-loc>Cali, Colombia</conf-loc><conf-date>26&#x02013;28 May 2021</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B129-sensors-25-01078"><label>129.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>T&#x000fc;rk&#x000e7;etin</surname><given-names>A.&#x000d6;.</given-names></name>
<name><surname>Ko&#x000e7;</surname><given-names>T.</given-names></name>
<name><surname>&#x000c7;ilekar</surname><given-names>&#x0015e;.</given-names></name>
</person-group><article-title>The Use of ANN in the Sound Detection of Lung Diseases: Example of COPD, Asthma, Pneumonia</article-title><source>Proceedings of the 2023 31st Signal Processing and Communications Applications Conference (SIU), IEEE</source><conf-loc>Istanbul, Turkiye</conf-loc><conf-date>5&#x02013;8 July 2023</conf-date><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="B130-sensors-25-01078"><label>130.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Pouramirarsalani</surname><given-names>S.</given-names></name>
<name><surname>Maleki</surname><given-names>S.E.</given-names></name>
<name><surname>Rajebi</surname><given-names>S.</given-names></name>
<name><surname>Manaf</surname><given-names>N.V.</given-names></name>
<name><surname>Roohany</surname><given-names>A.</given-names></name>
</person-group><article-title>Diagnosis of sleep apnea by optimal fuzzy system based on respiratory signals</article-title><source>Proceedings of the 2024 10th International Conference on Artificial Intelligence and Robotics (QICAR)</source><conf-loc>Qazvin, Iran</conf-loc><conf-date>29 February 2024</conf-date><fpage>100</fpage><lpage>105</lpage></element-citation></ref><ref id="B131-sensors-25-01078"><label>131.</label><element-citation publication-type="confproc"><person-group person-group-type="author">
<name><surname>Saeed</surname><given-names>U.</given-names></name>
<name><surname>Zheng</surname><given-names>D.</given-names></name>
<name><surname>Shah</surname><given-names>B.A.</given-names></name>
<name><surname>Shah</surname><given-names>S.I.</given-names></name>
<name><surname>Jan</surname><given-names>S.U.</given-names></name>
<name><surname>Ahmad</surname><given-names>J.</given-names></name>
<name><surname>Abbasi</surname><given-names>Q.H.</given-names></name>
<name><surname>Shah</surname><given-names>S.A.</given-names></name>
<name><surname>Boulila</surname><given-names>W.</given-names></name>
</person-group><article-title>Contactless Breathing Waveform Detection Through RF Sensing: Radar vs. Wi-Fi Techniques</article-title><source>Proceedings of the 2023 IEEE Tenth International Conference on Communications and Networking (ComNet)</source><conf-loc>Hammamet, Tunisia</conf-loc><conf-date>1&#x02013;3 November 2023</conf-date><fpage>1</fpage><lpage>10</lpage></element-citation></ref><ref id="B132-sensors-25-01078"><label>132.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>AL-Khalidi</surname><given-names>F.Q.</given-names></name>
<name><surname>Saatchi</surname><given-names>R.</given-names></name>
<name><surname>Burke</surname><given-names>D.</given-names></name>
<name><surname>Elphick</surname><given-names>H.</given-names></name>
<name><surname>Tan</surname><given-names>S.</given-names></name>
</person-group><article-title>Respiration rate monitoring methods: A review</article-title><source>Pediatr. Pulmonol.</source><year>2011</year><volume>46</volume><fpage>523</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1002/ppul.21416</pub-id><pub-id pub-id-type="pmid">21560260</pub-id>
</element-citation></ref><ref id="B133-sensors-25-01078"><label>133.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>LeCun</surname><given-names>Y.</given-names></name>
<name><surname>Bengio</surname><given-names>Y.</given-names></name>
<name><surname>Hinton</surname><given-names>G.</given-names></name>
</person-group><article-title>Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id>
</element-citation></ref><ref id="B134-sensors-25-01078"><label>134.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kalaiyarasan</surname><given-names>K.</given-names></name>
<name><surname>Sridhar</surname><given-names>R.</given-names></name>
</person-group><article-title>Artificial Intelligence in Respiratory Medicine: The Journey So Far&#x02014;A review</article-title><source>J. Assoc. Pulmonol. Tamil Nadu</source><year>2023</year><volume>6</volume><fpage>53</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.4103/japt.japt_13_23</pub-id></element-citation></ref><ref id="B135-sensors-25-01078"><label>135.</label><element-citation publication-type="webpage"><article-title>Artificial Intelligence in Pulmonary Medicine: Computer Vision, Predictive Model and COVID-19</article-title><comment>Available online: <ext-link xlink:href="https://err.ersjournals.com/lens/errev/29/157/200181" ext-link-type="uri">https://err.ersjournals.com/lens/errev/29/157/200181</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2024-09-06">(accessed on 6 September 2024)</date-in-citation></element-citation></ref><ref id="B136-sensors-25-01078"><label>136.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>De Georgia</surname><given-names>M.A.</given-names></name>
<name><surname>Deogaonkar</surname><given-names>A.</given-names></name>
</person-group><article-title>Multimodal Monitoring in the Neurological Intensive Care Unit</article-title><source>Neurologist</source><year>2005</year><volume>11</volume><fpage>45</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1097/01.nrl.0000149993.99956.09</pub-id><pub-id pub-id-type="pmid">15631643</pub-id>
</element-citation></ref><ref id="B137-sensors-25-01078"><label>137.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Alvarez-Estevez</surname><given-names>D.</given-names></name>
<name><surname>Rijsman</surname><given-names>R.M.</given-names></name>
</person-group><article-title>Computer-assisted analysis of polysomnographic recordings improves inter-scorer associated agreement and scoring times</article-title><source>PLoS ONE</source><year>2022</year><volume>17</volume><elocation-id>e0275530</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0275530</pub-id><pub-id pub-id-type="pmid">36174095</pub-id>
</element-citation></ref><ref id="B138-sensors-25-01078"><label>138.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Shen</surname><given-names>S.</given-names></name>
<name><surname>Zhou</surname><given-names>Q.</given-names></name>
<name><surname>Chen</surname><given-names>G.</given-names></name>
<name><surname>Fang</surname><given-names>Y.</given-names></name>
<name><surname>Kurilova</surname><given-names>O.</given-names></name>
<name><surname>Liu</surname><given-names>Z.</given-names></name>
<name><surname>Li</surname><given-names>S.</given-names></name>
<name><surname>Chen</surname><given-names>J.</given-names></name>
</person-group><article-title>Advances in wearable respiration sensors</article-title><source>Mater. Today</source><year>2024</year><volume>72</volume><fpage>140</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1016/j.mattod.2023.12.003</pub-id></element-citation></ref><ref id="B139-sensors-25-01078"><label>139.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Njeru</surname><given-names>C.M.</given-names></name>
<name><surname>Ansermino</surname><given-names>J.M.</given-names></name>
<name><surname>Macharia</surname><given-names>W.M.</given-names></name>
<name><surname>Dunsmuir</surname><given-names>D.T.</given-names></name>
</person-group><article-title>Variability of respiratory rate measurements in neonates- every minute counts</article-title><source>BMC Pediatr.</source><year>2022</year><volume>22</volume><elocation-id>16</elocation-id><pub-id pub-id-type="doi">10.1186/s12887-021-03087-z</pub-id><pub-id pub-id-type="pmid">34980049</pub-id>
</element-citation></ref><ref id="B140-sensors-25-01078"><label>140.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Arzi</surname><given-names>A.</given-names></name>
<name><surname>Sela</surname><given-names>L.</given-names></name>
<name><surname>Green</surname><given-names>A.</given-names></name>
<name><surname>Givaty</surname><given-names>G.</given-names></name>
<name><surname>Dagan</surname><given-names>Y.</given-names></name>
<name><surname>Sobel</surname><given-names>N.</given-names></name>
</person-group><article-title>The Influence of Odorants on Respiratory Patterns in Sleep</article-title><source>Chem. Sens.</source><year>2010</year><volume>35</volume><fpage>31</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1093/chemse/bjp079</pub-id></element-citation></ref><ref id="B141-sensors-25-01078"><label>141.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Kinney</surname><given-names>H.C.</given-names></name>
<name><surname>Thach</surname><given-names>B.T.</given-names></name>
</person-group><article-title>The Sudden Infant Death Syndrome</article-title><source>N. Engl. J. Med.</source><year>2009</year><volume>361</volume><fpage>795</fpage><lpage>805</lpage><pub-id pub-id-type="doi">10.1056/NEJMra0803836</pub-id><pub-id pub-id-type="pmid">19692691</pub-id>
</element-citation></ref><ref id="B142-sensors-25-01078"><label>142.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Fraile-Martinez</surname><given-names>O.</given-names></name>
<name><surname>Garc&#x000ed;a-Montero</surname><given-names>C.</given-names></name>
<name><surname>D&#x000ed;ez</surname><given-names>S.C.</given-names></name>
<name><surname>Bravo</surname><given-names>C.</given-names></name>
<name><surname>De Guadalupe Quintana-Coronado</surname><given-names>M.</given-names></name>
<name><surname>Lopez-Gonzalez</surname><given-names>L.</given-names></name>
<name><surname>Barrena-Bl&#x000e1;zquez</surname><given-names>S.</given-names></name>
<name><surname>Garc&#x000ed;a-Honduvilla</surname><given-names>N.</given-names></name>
<name><surname>De Le&#x000f3;n-Luis</surname><given-names>J.A.</given-names></name>
<name><surname>Rodriguez-Mart&#x000ed;n</surname><given-names>S.</given-names></name>
<etal/>
</person-group><article-title>Sudden Infant Death Syndrome (SIDS): State of the Art and Future Directions</article-title><source>Int. J. Med. Sci.</source><year>2024</year><volume>21</volume><fpage>848</fpage><lpage>861</lpage><pub-id pub-id-type="doi">10.7150/ijms.89490</pub-id><pub-id pub-id-type="pmid">38617004</pub-id>
</element-citation></ref><ref id="B143-sensors-25-01078"><label>143.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Papadopoulos</surname><given-names>N.G.</given-names></name>
<name><surname>Custovic</surname><given-names>A.</given-names></name>
<name><surname>Deschildre</surname><given-names>A.</given-names></name>
<name><surname>Gern</surname><given-names>J.E.</given-names></name>
<name><surname>Nieto Garcia</surname><given-names>A.</given-names></name>
<name><surname>Miligkos</surname><given-names>M.</given-names></name>
<name><surname>Phipatanakul</surname><given-names>W.</given-names></name>
<name><surname>Wong</surname><given-names>G.</given-names></name>
<name><surname>Xepapadaki</surname><given-names>P.</given-names></name>
<name><surname>Agache</surname><given-names>I.</given-names></name>
<etal/>
</person-group><article-title>Recommendations for asthma monitoring in children: A PeARL document endorsed by APAPARI, EAACI, INTERASMA, REG, and WAO</article-title><source>Pediatr. Allergy Immunol.</source><year>2024</year><volume>35</volume><fpage>e14129</fpage><pub-id pub-id-type="doi">10.1111/pai.14129</pub-id><pub-id pub-id-type="pmid">38664926</pub-id>
</element-citation></ref><ref id="B144-sensors-25-01078"><label>144.</label><element-citation publication-type="journal"><person-group person-group-type="author">
<name><surname>Cloutier</surname><given-names>M.M.</given-names></name>
<name><surname>Teach</surname><given-names>S.J.</given-names></name>
<name><surname>Lemanske</surname><given-names>R.F.</given-names></name>
<name><surname>Blake</surname><given-names>K.V.</given-names></name>
</person-group><article-title>The 2020 Focused Updates to the NIH Asthma Management Guidelines: Key Points for Pediatricians</article-title><source>Pediatrics</source><year>2021</year><volume>147</volume><fpage>e2021050286</fpage><pub-id pub-id-type="doi">10.1542/peds.2021-050286</pub-id><pub-id pub-id-type="pmid">33941586</pub-id>
</element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-01078-f001"><label>Figure 1</label><caption><p>Tally of search results and selected records for publications, databases, and algorithms.</p></caption><graphic xlink:href="sensors-25-01078-g001" position="float"/></fig><fig position="float" id="sensors-25-01078-f002"><label>Figure 2</label><caption><p>Characteristics of the results obtained from the PhysioNet and IEEE database in response to selected keywords from 1 January 2018&#x02013;27 November 2024.</p></caption><graphic xlink:href="sensors-25-01078-g002" position="float"/></fig><table-wrap position="float" id="sensors-25-01078-t001"><object-id pub-id-type="pii">sensors-25-01078-t001_Table 1</object-id><label>Table 1</label><caption><p>Algorithms, databases, and software sources hosted on the Github platform.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Name</th><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Programming Language/Environment</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Author</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Rrest [<xref rid="B30-sensors-25-01078" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-01078" ref-type="bibr">31</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm estimates the respiratory rate from ECG or PPG. It analyzes frequency (Fourier) and checks the time between successive ECG heartbeats or PPG beat episodes. It then modulates the signal in three ways&#x02014;changing the baseline, amplitude, or frequency.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Matlab</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Peter Charlson</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Neonatal-Respiration-Monitoring-Algorithm [<xref rid="B32-sensors-25-01078" ref-type="bibr">32</xref>,<xref rid="B33-sensors-25-01078" ref-type="bibr">33</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm estimates the respiratory rate based on a video (individual, consecutive frames). A convolutional neural network searches for abdominal movements in the area of interest (ROI) and estimates the respiratory rate (RPM) based on them. The algorithm is designed for videos of infants lying in care units (works with good focus and lighting). It works only on hdf5 files.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Adam Nagy</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ALT [<xref rid="B34-sensors-25-01078" ref-type="bibr">34</xref>,<xref rid="B35-sensors-25-01078" ref-type="bibr">35</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Embedded on a Raspberry Pi, the system includes a camera and a light source (sub-black) with a depth-of-field detector. The collected image frames are processed by the AI&#x02014;ALT &#x0201c;superimposes&#x0201d; a texture (dots) on the person, mapping the positions of the various body parts, then checks the differences in the positions of the superimposed dots for each successive frame. In this way, it checks, for example, chest movements both through breaths and small areas with a visible heartbeat. It is mainly used to monitor vital signs during sleep.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Alexander Misharin</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Real-time visual respiration rate estimation with dynamic scene adaptation [<xref rid="B36-sensors-25-01078" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-01078" ref-type="bibr">37</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm focuses on the real-time estimation of respiration rate based on video analysis. It uses image processing and machine learning techniques to track chest and abdominal movements, even in changing scene conditions, such as variations in lighting or a person&#x02019;s position. The algorithm is designed to work in different environments, making it useful for remote health monitoring.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python/Matlab</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mayank Mishra</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">respirationCA [<xref rid="B38-sensors-25-01078" ref-type="bibr">38</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm analyzes how phases of the respiratory cycle and moments in the cardiac cycle affect tactile perception. It synchronizes (phase-locking) respiratory signals with expected stimuli to identify moments of peak heart rate and associated higher alertness. The analysis reveals that tactile detection is lowest when the pulse wave reaches the finger and highest during diastole. This suggests that these changes are not merely physiological artifacts but result from cognitive processes that model the body&#x02019;s internal state and may adjust respiration to fit the task at hand.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Matlab/R</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Martin Grund</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ecg_respiration_sleep_staging [<xref rid="B39-sensors-25-01078" ref-type="bibr">39</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Deep neural networks are developed to classify sleep stages using the ECG and respiratory signals from 8682 polysomnographs. Five types of networks are trained to analyze ECG R-peaks and respiratory effort.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python + PTH models</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Harvard Medical School</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RF_respiration_monitoring [<xref rid="B40-sensors-25-01078" ref-type="bibr">40</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm uses radio frequency signals to monitor respiration. It processes reflected RF waves to detect breathing movements and extract respiratory patterns. The system is designed for real-time monitoring, offering continuous updates on the breathing rate and patterns.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Matlab + simulink</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">isuparnopal</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">UWB_Radar_Respiration_Monitoring [<xref rid="B41-sensors-25-01078" ref-type="bibr">41</xref>,<xref rid="B42-sensors-25-01078" ref-type="bibr">42</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm uses ultra-wideband (UWB) radar to monitor respiration rates. It processes radar signals to detect and analyze chest movements caused by breathing. The algorithm extracts respiratory patterns from the radar data and calculates the respiratory rate. This non-invasive method enables the real-time monitoring of respiration without physical contact.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python, Matlab</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Minsun Kim</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Infant-Respiration-Estimation [<xref rid="B43-sensors-25-01078" ref-type="bibr">43</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm estimates infant respiration rates from video data. It uses computer vision techniques to analyze subtle chest movements associated with breathing. The algorithm processes these movements to accurately determine the respiratory rate in real time. This non-invasive method is designed to monitor infant breathing without the need for physical sensors.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sarah Ostadabbas (Northeastern University)</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">rPPG_Toolbox [<xref rid="B44-sensors-25-01078" ref-type="bibr">44</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm estimates respiration and heart rates using remote photoplethysmography (rPPG). It processes video data to extract and analyze subtle changes in skin color caused by blood flow variations. The toolbox provides tools for detecting and tracking these physiological signals in real time. This non-invasive method offers an alternative to traditional monitoring techniques by leveraging standard video footage.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Ubiquitous Computing Lab (University of Washington)</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RESPIRATION_RATE_ESTIMATION [<xref rid="B45-sensors-25-01078" ref-type="bibr">45</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The algorithm estimates respiration rates from video footage. It uses computer vision techniques to analyze the motion of the chest and abdomen, extracting features related to breathing. The algorithm processes these features to calculate the respiratory rate in real time. This approach offers a non-invasive method for monitoring respiration by leveraging visual data.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Kapil Singh Rahtore (Indian Institute Of Tecnhology Madras)</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Physio [<xref rid="B46-sensors-25-01078" ref-type="bibr">46</xref>,<xref rid="B47-sensors-25-01078" ref-type="bibr">47</xref>]</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The repository is designed for processing and analyzing physiological signals, such as ECG and EEG. It provides tools for handling, preprocessing, and extracting features from these signals. The repository also includes visualization capabilities to aid in interpreting the data. It is intended to streamline the analysis of physiological data, potentially integrating with existing databases like PhysioNet.</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Python</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Samuel Garcia</td></tr></tbody></table></table-wrap></floats-group></article>