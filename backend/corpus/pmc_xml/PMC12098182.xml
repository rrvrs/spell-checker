<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Drug Saf</journal-id><journal-id journal-id-type="iso-abbrev">Drug Saf</journal-id><journal-title-group><journal-title>Drug Safety</journal-title></journal-title-group><issn pub-type="ppub">0114-5916</issn><issn pub-type="epub">1179-1942</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39979771</article-id><article-id pub-id-type="pmc">PMC12098182</article-id>
<article-id pub-id-type="publisher-id">1520</article-id><article-id pub-id-type="doi">10.1007/s40264-025-01520-1</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Research Article</subject></subj-group></article-categories><title-group><article-title>Leveraging FDA Labeling Documents and Large Language Model to Enhance Annotation, Profiling, and Classification of Drug Adverse Events with AskFDALabel</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4093-3708</contrib-id><name><surname>Wu</surname><given-names>Leihong</given-names></name><address><email>leihong.wu@fda.hhs.gov</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Fang</surname><given-names>Hong</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Qu</surname><given-names>Yanyan</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Xu</surname><given-names>Joshua</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Tong</surname><given-names>Weida</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05jmhh281</institution-id><institution-id institution-id-type="GRID">grid.483504.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2158 7187</institution-id><institution>Division of Bioinformatics and Biostatistics, </institution><institution>National Center for Toxicological Research, U.S. FDA, </institution></institution-wrap>3900 NCTR Rd, Jefferson, AR 72079 USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05jmhh281</institution-id><institution-id institution-id-type="GRID">grid.483504.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2158 7187</institution-id><institution>Office of Scientific Coordination, </institution><institution>National Center for Toxicological Research, U.S. FDA, </institution></institution-wrap>3900 NCTR Rd, Jefferson, AR 72079 USA </aff></contrib-group><pub-date pub-type="epub"><day>20</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>20</day><month>2</month><year>2025</year></pub-date><pub-date pub-type="ppub"><year>2025</year></pub-date><volume>48</volume><issue>6</issue><fpage>655</fpage><lpage>665</lpage><history><date date-type="accepted"><day>20</day><month>1</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">Drug adverse events (AEs) represent a significant public health concern. US Food and Drug Administration (FDA) drug labeling documents are an essential resource for studying drug safety such as assessing a drug&#x02019;s likelihood to cause certain organ toxicities; however, the manual extraction of AEs is labor-intensive, requires specialized expertise, and is challenging to maintain, due to frequent updates of the labeling documents.</p></sec><sec><title>Objective</title><p id="Par2">To automate the extraction of AE data from FDA drug labeling documents, we developed a workflow based on AskFDALabel, a large language model (LLM)-powered framework, and its demonstration in drug safety studies.</p></sec><sec><title>Methods</title><p id="Par3">This framework incorporates a retrieval-augmented generation (RAG) component based on FDALabel to enhance standard LLM inference. Key steps include (1) selection of a task-specific template, (2) FDALabel database querying, and (3) content preparation for LLM processing. We evaluated the performance of the framework in three benchmark experiments, including drug-induced liver injury (DILI) classification, drug-induced cardiotoxicity (DICT) classification, and AE term recognition.</p></sec><sec><title>Results</title><p id="Par4">AskFDALabel achieved F1-scores of 0.978 for DILI, 0.931 for DICT, and 0.911 for AE annotation, outperforming other traditional methods. It also provided cited labeling content and detailed explanations, facilitating manual verification.</p></sec><sec><title>Conclusion</title><p id="Par5">AskFDALabel exhibited high consistency with human AE annotation, particularly in classifying and profiling DILI and DICT. Thus, it can significantly enhance the efficiency and accuracy of AE annotation, with promising potential for advanced AE surveillance and drug safety research.</p></sec><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1007/s40264-025-01520-1.</p></sec></abstract><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Switzerland AG 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="d33e202"><title>Key Points</title><p id="Par6">
<table-wrap id="Taba"><table frame="hsides" rules="groups"><tbody><tr><td align="left">AskFDALabel incorporates term-of-interest (TOI) recognition and retrieval-augmented generation (RAG) for an enhanced drug adverse event (AE) annotation.</td></tr><tr><td align="left">AE extraction through automation with AskFDALabel is highly consistent with the results from the manual curation by experts.</td></tr><tr><td align="left">Both drug-induced liver injury and drug-induced cardiotoxicity classification with AskFDALabel achieved a high F1-score above 90%.</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec2"><title>Introduction</title><p id="Par7">Drug adverse events (AEs) are a major cause of death in the United States (US) [<xref ref-type="bibr" rid="CR1">1</xref>]. Data from the US Food and Drug Administration (FDA) Adverse Events Reporting System (FAERS) reveal that the number of annual AE reported cases associated with &#x0201c;death&#x0201d; has surpassed 70,000 since 2020 [<xref ref-type="bibr" rid="CR2">2</xref>]. Identifying, profiling, classifying, and monitoring AEs from various drug safety documents, such as drug labeling documents, individual case safety reports (ICSRs), literature, and other data sources, are at the center of current AE research, and are also critical for drug safety review in many regulatory agencies, including the FDA.</p><p id="Par8">FDA drug labeling documents serve as authoritative resources for AE research. These documents, submitted by manufacturer and then approved by the FDA, contain important drug safety information in sections such as &#x0201c;Boxed Warnings,&#x0201d; &#x0201c;Warnings and Precautions,&#x0201d; and &#x0201c;Adverse Reactions.&#x0201d; Due to their comprehensiveness and reliability, these documents are the primary source for researchers and healthcare professionals as a key reference for understanding drugs&#x02019; safety profiles [<xref ref-type="bibr" rid="CR3">3</xref>]. Recently, the FDA National Center for Toxicological Research (NCTR) developed FDALabel [<xref ref-type="bibr" rid="CR4">4</xref>], a tool widely recognized within and outside the FDA, enabling users to efficiently access and query over 150,000 drug labeling documents.</p><p id="Par9">Over the past decades, FDA drug labeling documents have been used extensively in AE studies. For example, the Side Effect Resource (SIDER) has curated AEs for 1430 marketed medicines, with most sourced from FDA drug labeling documents [<xref ref-type="bibr" rid="CR5">5</xref>]. Wu et al. systematically analyzed and compared the AE profiles of 1164 drugs by mapping their labeling documents to Medical Dictionary for Regulatory Activities (MedDRA) [<xref ref-type="bibr" rid="CR6">6</xref>]. Roberts et al. developed a benchmark for AE detection by manually annotating 200 drug labeling documents, which was used for the Adverse Reaction Extraction Challenge at the 2017 Text Analysis Conference (TAC) [<xref ref-type="bibr" rid="CR7">7</xref>]. Similarly, Bayer et al. manually annotated another 200 drug labeling documents, by focusing on detecting AE terms particularly relevant to FDA reviewers [<xref ref-type="bibr" rid="CR8">8</xref>].</p><p id="Par10">Additionally, FDA drug labeling documents have been widely used in drug toxicity classification and annotation. For example, during the past two decades, the research team at the NCTR has produced several drug-induced toxicity benchmark datasets by manually reading and analyzing drug labeling documents, such as those for drug-induced liver injury (DILI) [<xref ref-type="bibr" rid="CR9">9</xref>&#x02013;<xref ref-type="bibr" rid="CR11">11</xref>], drug-induced cardiotoxicity (DICT) [<xref ref-type="bibr" rid="CR12">12</xref>], drug-induced renal injury list (DIRIL) [<xref ref-type="bibr" rid="CR13">13</xref>], and others, which offer large collections of manually curated drug toxicity annotations. These datasets have spurred numerous artificial intelligence (AI)/machine learning initiatives on drug toxicity prediction [<xref ref-type="bibr" rid="CR14">14</xref>&#x02013;<xref ref-type="bibr" rid="CR18">18</xref>].</p><p id="Par11">Labeling-based AE annotation and profiling by human experts poses three main challenges. First, it typically requires a labor-intensive, time-consuming manual process of extracting and annotating AE data. Frequent updates to labeling documents necessitate regular repetition of this process, making the maintenance of up-to-date AE monitoring an expensive, if not impossible, process. Second, to reduce the cost of this process, some studies applied standardized terminologies like MedDRA for AE extraction, but this often led to missing some critical AEs, as the FDA does not mandate the use of MedDRA terminology in labeling [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. Last, the manual AE extraction from the labeling documents is expertise-dependent, which could lead to varying results among experts.</p><p id="Par12">Recent advancements in large language models (LLMs) have offered a transformative opportunity to modernize labeling-based AE research. LLMs have the potential to automate and streamline AE term extraction, profiling, and classification. These models can now analyze vast amounts of textual data with high consistency and accuracy, reducing the burden of manual curation and minimizing variation among human experts.</p><p id="Par13">With concerns for security, regulatory agencies such as the FDA have primarily been employing LLMs locally to analyze data. We developed AskFDALabel (version 1) [<xref ref-type="bibr" rid="CR20">20</xref>], a framework to employ open-source LLMs in a secure environment with a retrieval-augmented generation (RAG) mechanism to enhance the efficiency and effectiveness of drug labeling document analysis for reviewers and research scientists. In the first version, we explored the potential to use locally hosted models (e.g., Llama [<xref ref-type="bibr" rid="CR21">21</xref>] and Falcon [<xref ref-type="bibr" rid="CR22">22</xref>]) with RAG to provide more relevant and accurate responses from FDA labeling documents [<xref ref-type="bibr" rid="CR20">20</xref>]. Additionally, we fine-tuned the employed LLMs using low-rank adaptation (LoRA) and Alpaca strategy [<xref ref-type="bibr" rid="CR23">23</xref>], which involved automatically generating training content through a larger LLM, such as GPT-3.5.</p><p id="Par14">In this paper, we further improved AskFDALabel as a tool to interface with FDA labeling documents in a study of drug safety. Particularly, we introduced new features in the current AskFDALabel framework (version 2), such as the term-of-interest (TOI) recognition, a database-enhanced RAG process, and special templates. We then outlined the results obtained from three experiments: (1) DILI classification, (2) DICT classification, and (3) drug AE profiling, and evaluate their performance by comparing existing methods, including manual review.</p></sec><sec id="Sec3"><title>Material and Method</title><sec id="Sec4"><title>Datasets</title><sec id="Sec5"><title>Drug-Induced Liver Injury (DILI) Dataset</title><p id="Par15">We used 287 DILI annotated drugs, retrieved from the original DILI class publication [<xref ref-type="bibr" rid="CR9">9</xref>]. Among them, 76 drugs were currently labeled as &#x0201c;withdraw&#x0201d; or &#x0201c;discontinued.&#x0201d; Since their drug labeling documents were not searchable in the FDALabel database, they were excluded for this analysis. For the remaining 211 available drugs, we further combined the classifications &#x0201c;most&#x0201d; and &#x0201c;less&#x0201d; DILI concern as DILI positive, where &#x0201c;no&#x0201d; DILI concern is considered as DILI negative. This resulted in 154 DILI-positive and 57 DILI-negative drugs.</p></sec><sec id="Sec6"><title>Drug-Induced Cardiotoxicity (DICT) Dataset</title><p id="Par16">For DICT analysis, we processed 1184 drugs labeled with DICT concern levels&#x02014;i.e., most, less, or no DICT concern&#x02014;from a previous publication [<xref ref-type="bibr" rid="CR12">12</xref>]. We successfully found and processed the labeling for 1167 of these drugs. As with the DILI classification analysis, we combined the most and less DICT concern groups into a DICT-positive category. This resulted in 829 DICT-positive and 338 DICT-negative drugs.</p></sec><sec id="Sec7"><title>Drug Adverse Event (AE) Profiling</title><p id="Par17">To evaluate the performance of the generated AE profile from labeling documents, we processed 200 drugs with AE profiles that had been manually annotated by human in the TAC 2017 challenge [<xref ref-type="bibr" rid="CR24">24</xref>]. In detail, over 26,000 adverse reaction terms (~13,000 unique terms) were manually annotated by human reviewers in TAC, which is around 70 AEs per labeling document. The whole effort took years to complete, with a group of reviewers from the FDA and National Institutes of Health (NIH) [<xref ref-type="bibr" rid="CR7">7</xref>]. We conducted the analyses based on both section level (which included 476 labeling sections in total) and the whole drug document level (200 drug labels). For the section level analysis, we used the original labeling content provided by the dataset; for the whole drug document level analysis, we only used the drug name, and the most recent labeling document was automatically retrieved by AskFDALabel during the study.</p></sec></sec><sec id="Sec8"><title>Term-of-Interest (TOI) Recognition</title><p id="Par18">We implemented a new TOI recognition feature in the AskFDALabel framework by utilizing an LLM. In a previous study, we designed a simple hard-coded approach to let the user manually annotate the key attribute terms inside the query. For example, instead of the query &#x0201c;What are the adverse events reported for abacavir?&#x0201d;, the user can substitute &#x0201c;What are the adverse events reported for abacavir?&#x0201d; Although such an approach will increase users&#x02019; preparation time to input their queries, it can largely improve the accuracy and relevance of the RAG process.</p><p id="Par19">In addition to the hard-coded approach, we also used an LLM-based TOI recognition approach to identify and extract key attribute terms. In contrast to regular named entity recognition (NER) approaches to train a model based on a tagging annotator, the LLM-based approach tried to directly recognize TOIs in a generative style. For example, using the input query &#x0201c;What are the adverse events reported for abacavir?&#x0201d;, the LLM is expected to respond &#x0201c;[Drug-Name] Abacavir&#x0201d; with appropriate prompts. The LLM-based NER prompt used in this step is provided in the electronic supplementary material (Online resource 1).</p></sec><sec id="Sec9"><title>Retrieval Augmented Generation (RAG) Process</title><p id="Par20">Most, if not all, RAG technologies are based on the idea of semantic similarity or relevance to the input query to fetch relevant information from a large corpus of text. In general, the reference texts will be segmented into smaller text chunks, where vectorization will be performed to digitalize the text into a one-dimensional, numerical vector. Word embedding approaches such as Global Vectors for Word Representation (GloVe), Sentence&#x02013;Bidirectional Encoder Representations from Transformers (SBERT), and Doc2Vec are applied in this transformation process [<xref ref-type="bibr" rid="CR25">25</xref>&#x02013;<xref ref-type="bibr" rid="CR27">27</xref>].</p><p id="Par21">In this study, we developed a hybrid information retrieval process, named FDALabel-based RAG, by combining an LLM with a regular database search in the RAG process. This approach has the advantages of regular database searching; by using an appropriate database query, the user will not risk a hallucination in the results. In contrast, an LLM model auto-detects keywords mentioned in the user input and then converts it into the database-search query.</p><p id="Par22">For example, in DILI classification, after the user query identifies the drug of interest, a database query will be generated to retrieve labeling documents that meet certain criteria consistent with the guidance during manual reading. Particularly, the drug must be a human prescription drug (preferred) or over-the-counter (OTC) drug. Single-ingredient drugs are preferred over combined drugs in the query. In addition, we used the most recently revised labeling data. For DILI classification, three labeling sections were considered in the RAG process: &#x0201c;Boxed Warnings,&#x0201d; &#x0201c;Warnings and Precautions,&#x0201d; and &#x0201c;Adverse Reactions.&#x0201d;</p><p id="Par23">After the labeling content was retrieved, the next step was to use the LLM to find DILI keywords from the selected labeling sections. The prompt used in this step is provided in Online resource 1 (see the electronic supplementary material). As a result, the model would return any DILI keywords found in these labeling sections.</p><p id="Par24">Finally, we used the exact criteria for DILI classification mentioned in a previous publication [<xref ref-type="bibr" rid="CR9">9</xref>] to judge the DILI based on the LLM output.</p></sec><sec id="Sec10"><title>Special Templates</title><p id="Par25">Special templates are a novel design in the AskFDALabel framework to enable better handling of distinct user requests in one platform. For example, a query such as &#x0201c;What are the adverse events of abacavir?&#x0201d; relies on a single labeling document; whereas another such as &#x0201c;What are the newly added/reported adverse events of tamoxifen in the past five years?&#x0201d; will require information from multiple labeling documents. To cope with common user requests, we implemented several task-specific templates and designed an LLM-enabled module to automatically determine which special template is the best fit for a given query.</p><p id="Par26">In this study, we used the locally hosted model Llama&#x000a0;3.1-70B to determine whether special templates would be used for the given query, and which one(s). We designed a special template for each experiment: (1) for DILI classification, the template was designed to automate the classification scheme to assess DILI [<xref ref-type="bibr" rid="CR9">9</xref>] based on the labeling description; (2) for DICT classification, the template was designed to classify DICT [<xref ref-type="bibr" rid="CR12">12</xref>] based on the labeling description; and (3) for drug AE profiling, the template was designed to generate an AE profile of a given drug summarizing all AEs mentioned in its most recent labeling documents. A typical question that fits into the first template is &#x0201c;What are the adverse events reported for abacavir?&#x0201d; The detailed prompts used to determine the appropriate template to use and prompts for these three templates are provided in Online resource 1 (see the electronic supplementary material).</p><p id="Par27">When a special template was selected, the RAG process used different criteria to get the labeling document and return the information required by each template. In DILI classification, it returned &#x0201c;Boxed Warnings,&#x0201d; &#x0201c;Warnings and Precautions,&#x0201d; and &#x0201c;Adverse Reactions&#x0201d; sections since only these three sections are used in DILI classification. For DICT classification, the above three sections plus the &#x0201c;Overdosage&#x0201d; section were considered, due to the different guidance provided by human scientists in previous publications [<xref ref-type="bibr" rid="CR12">12</xref>]. For AE analysis, the entire labeling document was used in the RAG process.</p></sec><sec id="Sec11"><title>The LLM Core of AskFDALabel</title><p id="Par28">In the most recent AskFDALabel framework, we used Llama 3.1-70B [<xref ref-type="bibr" rid="CR28">28</xref>], the latest released Llama model at the time, as the LLM core for AskFDALabel. It had two major advantages: (1) The Llama3.1 series supported up to 128,000 input tokens, which enabled us to fit the entire labeling document into the input prompt. The previous Llama model used in AskFDALabel supports only 4000 tokens, which forced the segmentation of the labeling document into multiple text chunks. (2) The 70B model proved to be a significant improvement overall in comparison to the previously tested 8B and 13B models.</p><p id="Par29">All the LLM experiments ran on a graphics processing unit (GPU) server with eight H100 80 Gb GPUs. Four of the eight GPUs were utilized for this study to handle the Llama 3.1-70B model. The model was loaded in fp16 format using vLLM [<xref ref-type="bibr" rid="CR29">29</xref>].</p></sec><sec id="Sec12"><title>Exact and Semantic-Based Matching to Evaluate AE Profiling</title><p id="Par30">To better evaluate the performance of drug AE profiling, we introduced two matching algorithms&#x02014;exact and semantic-based matching. The exact match only counts the ground truth term that appears exactly in the AskFDALabel response. On the other hand, semantic-based matching will also consider terms that have semantically similar terms in the AskFDALabel response. To implement semantic-based matching, an LLM-based approach was applied to define semantically similar terms between the LLM result and the ground truth (i.e., human reviewer annotations). For an example, see Fig. <xref rid="Fig1" ref-type="fig">1</xref>, which illustrates the drug AE profiling contents for raxibacumab generated by AskFDALabel. The hash tags (##) indicate exactly matched terms, and the dollar tags ($$) indicate semantically matched terms. For instance, the exact term &#x0201c;infusion-related reaction&#x0201d; is not found in the generated drug AE profile; however, the profile contains &#x0201c;injection site reaction,&#x0201d; a semantically similar term. Therefore, &#x0201c;infusion-related reaction&#x0201d; will be considered as a semantically matched term, but not as an exactly matched term. The detailed prompts used for semantic matching are provided in Online resource 1 (see the electronic supplementary material).<fig id="Fig1"><label>Fig. 1</label><caption><p>An example of drug AE profiling contents for raxibacumab generated by AskFDALabel. We matched the generated AE profile with human annotation (ground truth) in two ways: (1) hash tags (##) indicated human-annotated AEs were matched exactly in the AE profiling; (2) dollar tags ($$) indicated human-annotated AEs were matched semantically based on LLM determination. <italic>AE</italic> adverse event, <italic>FDA</italic> Food and Drug Administration, <italic>LLM</italic> large language model</p></caption><graphic xlink:href="40264_2025_1520_Fig1_HTML" id="MO1"/></fig></p></sec></sec><sec id="Sec13"><title>Result</title><sec id="Sec14"><title>AskFDALabel Framework</title><p id="Par31">The overall framework of AskFDALabel is shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. This framework integrated a RAG component based on FDALabel, enhancing the capabilities of a regular LLM inference pipeline. Key steps in this RAG-based enhancement included (1) template selection, (2) FDALabel database query, and (3) content preparation for LLM inference.<fig id="Fig2"><label>Fig. 2</label><caption><p>The AskFDALabel framework for drug AE analysis. This framework introduces a structured, end-to-end pipeline that processes user queries through a series of specialized steps, rather than directly using an LLM. Upon receiving a user query, the framework determines the appropriate template to apply based on the query type. For example, in a DILI classification task (<italic>first template in figure</italic>), the framework identifies and extracts the drug name, retrieves the most recent labeling document from the FDALabel database, and extracts AE sections, such as &#x0201c;Boxed Warnings,&#x0201d; &#x0201c;Warnings and Precautions,&#x0201d; and &#x0201c;Adverse Reactions.&#x0201d; The LLM then identifies DILI-related keywords from these sections. A post-processing step evaluates the extracted keywords to assess whether the drug poses a DILI risk. The pipeline&#x02019;s output is then provided to the user. <italic>AE</italic> adverse event, <italic>DILI</italic> drug-induced liver injury, <italic>FDA</italic> Food and Drug Administration, <italic>LLM</italic> large language model, <italic>TOI</italic> term-of-interest</p></caption><graphic xlink:href="40264_2025_1520_Fig2_HTML" id="MO2"/></fig></p><p id="Par32">We began the process by identifying the nature of the user query through template selection, which involved determining the focus of the inquiry, (e.g., drug name, AEs, or other entities). Next, we employed a specialized LLM-based inference to select the appropriate processing template. Based on the chosen template, we executed a query on the FDALabel database to retrieve relevant information. Depending on the template requirements, this involved retrieving sections, such as AEs, from a single labeling document, or gathering data from multiple documents. Retrieved information was then organized into a prompt format that the LLM could interpret. If multiple references were gathered, the initial user query (e.g., &#x0201c;What are the adverse events reported for abacavir?&#x0201d;) could be split into sub-queries (e.g., &#x0201c;What adverse events are reported in the Boxed Warnings section for abacavir?&#x0201d;). These sub-queries were processed by the LLM individually, and a final response was compiled from all sub-query outputs.</p><p id="Par33">This integrated framework leveraged FDALabel data to improve the relevance and specificity of responses to user queries, enhancing the standard LLM inference pipeline for applications in AE research and classification tasks such as DILI classification.</p></sec><sec id="Sec15"><title>Large Language Model (LLM)-Based TOI Recognition</title><p id="Par34">LLM-based TOI recognition was implemented in the updated version of FDALabel. To evaluate its performance to identify TOI such as drug names, we evaluated its performance in recognizing a drug name from 2141 unique drug trade names from FDALabel that satisfied the following criteria: (1) human prescription, (2) New Drug Application (NDA), (3) remove Repacker and Relabeler, and (4) Reference Listed Drug (RLD). Additionally, we manually validated the result to make sure the synonyms were also considered as correct. For example, drugs Atelvia and Actonel were identified as &#x0201c;risedronate sodium,&#x0201d; the generic name of these drugs. As a result, 2037 drugs (95.14%) were successfully identified by the LLM search, of which 1848 drug names were exactly used in the database query, and the remaining 189 drugs were identified using a semantically similar name, such as using &#x0201c;risedronate sodium&#x0201d; instead of &#x0201c;Atelvia.&#x0201d; With that said, LLM-based TOI recognition can accurately identify and recognize drug names from the free-text style of user inputs. Therefore, we decided to use the LLM-based TOI recognition in the AskFDALabel framework.</p></sec><sec id="Sec16"><title>DILI Classification</title><p id="Par35">AskFDALabel was applied to 211 DILI annotated drugs. As the results show, 153 of 154 DILI-positive drugs (99.4%) and 44 of 57 DILI-negative drugs (77.2%) were labeled consistently between the manual curation and our AskFDALabel output. This result outperformed previous Bidirectional Encoder Representations from Transformers (BERT)- and keyword-based DILI classification results, even without the needs of training a predictive model [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR30">30</xref>].</p><p id="Par36">Moreover, we investigated the 14 mismatched (i.e., 13 false-positive and 1 false-negative) cases between AskFDALabel and manual curation (Online resource 2; see the electronic supplementary material). These 14 cases were manually verified with the following criteria: (1) the drug labeling document used for the AskFDALabel process is valid, as the name on the labeling document matches the given drug name; (2) DILI-related keywords found by AskFDALabel could be manually found in the given reference; and (3) a review of the labeling document could determine whether the discrepancy between the human and AskFDALabel result is due to a labeling document update since the manual reading.</p><p id="Par37">We found that AskFDALabel responses to seven of 13 false-positive cases could be verified, as their references contained DILI-related terms. Among the seven verified cases, four were due to labeling updates. For example, the labeling document for Desfaral (deferoxamine) did not have any hepatic information in 2008 according to the labeling archive from DailyMed, but its labeling was updated in 2010 to include such information. Similarly, the labeling document for ketamine did not mention DILI-related terms before 2020, but a new subsection titled &#x0201c;Drug-Induced Liver Injury&#x0201d; was added in 2021. Metronidazole&#x02019;s labeling was updated in 2024 to include hepatic information in the &#x0201c;Adverse Reactions&#x0201d; section, which was not present in its previous labeling. For the other three cases, we found keywords such as &#x0201c;alkaline phosphatase increased&#x0201d; or &#x0201c;elevation in liver function tests&#x0201d; to confirm they could be DILI-positive drugs. Validation notes are provided in Online resource 2.</p><p id="Par38">On the other side, clotrimazole, which was determined to have &#x0201c;no&#x0201d; DILI concern by AskFDALabel but &#x0201c;less&#x0201d; DILI by a human scientist, is the only false-negative case reported in this study. A potential reason for this is the latest labeling documents of clotrimazole used by the AskFDALabel framework are for the topically administered product. After consulting with our DILI experts, they agree that it is better to primarily focus on the product that was taken orally or parenterally. Further investigation is needed to see whether a revision of the special template focusing on oral drugs could further improve performance.</p><p id="Par39">By reconsidering these verified mismatched results as correct, only one false-negative drug and six false-positive drugs remained. The updated F1-score was 0.978 (Table <xref rid="Tab1" ref-type="table">1</xref>). That said, we demonstrated that using AskFDALabel can retrieve results that are accurate and highly consistent with those processed by human reviewers. Also, using the automated process, the current framework is capable of capturing the impact on DILI classification resulting from recent changes in the labeling document. The detailed DILI classification results for all assessed drugs are provided in Online resource 3.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Statistical summary of DILI and DICT classification result</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Approach</th><th align="left">Accuracy</th><th align="left">Recall</th><th align="left">Precision</th><th align="left">Specificity</th><th align="left">F1-score</th></tr></thead><tbody><tr><td align="left" rowspan="4">DILI classification</td><td align="left">AskFDALabel</td><td char="." align="char"><bold>0.967</bold></td><td char="." align="char">0.994</td><td char="." align="char"><bold>0.962</bold></td><td char="." align="char"><bold>0.895</bold></td><td char="." align="char"><bold>0.978</bold></td></tr><tr><td align="left">BERT model [<xref ref-type="bibr" rid="CR19">19</xref>]</td><td char="." align="char">0.927</td><td char="." align="char"><bold>1.000</bold></td><td char="." align="char">0.784</td><td char="." align="char">0.900</td><td char="." align="char">0.879</td></tr><tr><td align="left">Keywords [<xref ref-type="bibr" rid="CR19">19</xref>]</td><td char="." align="char">0.822</td><td char="." align="char"><bold>1.000</bold></td><td char="." align="char">0.581</td><td char="." align="char">0.764</td><td char="." align="char">0.735</td></tr><tr><td align="left">XGBoost [<xref ref-type="bibr" rid="CR30">30</xref>]</td><td char="." align="char">0.839</td><td char="." align="char">0.651</td><td char="." align="char">0.856</td><td char="." align="char">0.941</td><td char="." align="char">0.740</td></tr><tr><td align="left" rowspan="3">DICT classification</td><td align="left">AskFDALabel</td><td char="." align="char"><bold>0.901</bold></td><td char="." align="char"><bold>0.941</bold></td><td char="." align="char"><bold>0.921</bold></td><td char="." align="char"><bold>0.802</bold></td><td char="." align="char"><bold>0.931</bold></td></tr><tr><td align="left">Prev. LLM [<xref ref-type="bibr" rid="CR20">20</xref>]</td><td char="." align="char">0.776</td><td char="." align="char">0.608</td><td char="." align="char">0.907</td><td char="." align="char">0.940</td><td char="." align="char">0.728</td></tr><tr><td align="left">ChatGPT (3.5) [<xref ref-type="bibr" rid="CR20">20</xref>]</td><td char="." align="char">0.715</td><td char="." align="char">0.908</td><td char="." align="char">0.647</td><td char="." align="char">0.531</td><td char="." align="char">0.756</td></tr></tbody></table><table-wrap-foot><p>Bold value in each column represents the best performance across all approaches for DILI and DICT classification</p><p><italic>BERT</italic> Bidirectional Encoder Representations from Transformers, <italic>DICT</italic> drug-induced cardiotoxicity, <italic>DILI</italic> drug-induced liver injury, <italic>FDA</italic> Food and Drug Administration, <italic>LLM</italic> large language model</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec17"><title>DICT Classification</title><p id="Par40">Similarly, we processed the 1167 DICT drugs, where 780 of 829 DICT-positive drugs (94.1%) and 271 of 338 DICT-negative drugs (80.2%) were correctly classified by AskFDALabel. The statistical measurement is summarized in Table <xref rid="Tab1" ref-type="table">1</xref>. The overall F1-score for DICT classification was 0.931, significantly improving upon results from a previous LLM (Llama 13B) used in AskFDALabel (F1-score = 0.728) and GPT-3.5 (F1-score = 0.756) [<xref ref-type="bibr" rid="CR20">20</xref>]. This superior performance may be attributed to the use of the newer LLM (Llama 3.1-70B) and the hybrid information retrieval strategy. The complete DICT classification results for all assessed drugs are provided in Online resource 4 (see the electronic supplementary material).</p></sec><sec id="Sec18"><title>Drug AE Profiling</title><p id="Par41">In this section, we performed two sub-experiments on the drug AE profiling: (1) We used the original labeling contents provided by the TAC dataset. This enabled us to develop a comparative study for AskFDALabel to compare currently existing approaches within the same dataset. (2) We followed the AskFDALabel framework, using the drug name to retrieve the most recent labeling documents for the AE profiling process. The content of the labeling documents could be updated during the past years and, therefore, may identify newly reported AEs.</p><p id="Par42">Sub-experiment 1 contained 476 data samples, where each sample represented content from one section of the labeling document. To determine the true positives, which were the profiles annotated by both human and LLM, we mapped each line of the AE profiling to human-annotated AEs, and added tags if an AE was matched. Based on the exact match, the recall and F1-score on the section level were 0.825 and 0.827, respectively.</p><p id="Par43">Additionally, we considered semantically similar terms between the AskFDALabel result and the human annotations. As a result, the average semantic-based recall and F1-score for all 476 samples were 0.939 and 0.911, respectively, which were higher than previously reported approaches in the TAC 2017 challenge [<xref ref-type="bibr" rid="CR7">7</xref>] as well as when using the NER predictive model based on RxBERT [<xref ref-type="bibr" rid="CR31">31</xref>]. Moreover, our LLM-based approach had another significant advantage in that it did not need to train the NER model with an already annotated dataset.</p><p id="Par44">Next, sub-experiment 2 retrieved the most up-to-date labeling documents based on the drug name. The generated AE profile for each drug was then compared to the true AE profile annotated by reviewers (which was still based on the older version) on the whole labeling level. As a result, 188 drug names were successfully processed and their AE profiles were generated by AskFDALabel. Twelve drugs could not be processed. Some of the drugs, such as &#x0201c;Arcapta&#x0201d; and &#x0201c;Belviq,&#x0201d; had been discontinued since the TAC annotation. Therefore, their labeling information was no longer available in the current FDALabel database.</p><p id="Par45">As summarized in Table <xref rid="Tab2" ref-type="table">2</xref>, the average semantic-based recall for 188 drugs on the whole labeling level was 0.895, and the overall F1-score was 0.859. The decreased performance compared to directly using TAC contents may have been due to the inaccuracy in labeling retrieval. For example, a drug named KIT was incorrectly processed due to its name after examination, but another major reason could be the result of labeling updates during the past decade since the human annotation. In other words, the different AE terms found by AskFDALabel could still be true AEs. For example, &#x0201c;anaphylaxis&#x0201d; was found in the raxibacumab AE profiling by AskFDALabel but not in the TAC 2017 human annotation, due to the label update of raxibacumab on 06/2021; therefore, the annotations by both humans and AskFDALabel were accurate because of the different accessed time of the labeling data. The AE profiling generated by AskFDALabel made it much easier to catch these recent labeling updates related to AE changes.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Performance on TAC 2017 dataset and drug AE profiling</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Approaches</th><th align="left">Precision</th><th align="left">Recall</th><th align="left">F1-score</th></tr></thead><tbody><tr><td align="left" rowspan="4"><p>Sub-experiment 1:</p><p>TAC original</p><p>labeling</p></td><td align="left">AskFDALabel&#x02014;exact</td><td char="." align="char">0.858</td><td char="." align="char">0.825</td><td char="." align="char">0.827</td></tr><tr><td align="left">AskFDALabel&#x02014;semantic</td><td char="." align="char"><bold>0.906</bold></td><td char="." align="char"><bold>0.939</bold></td><td char="." align="char"><bold>0.911</bold></td></tr><tr><td align="left">TAC 2017&#x02014;SOTA [<xref ref-type="bibr" rid="CR7">7</xref>]</td><td char="." align="char">0.851</td><td char="." align="char">0.853</td><td char="." align="char">0.852</td></tr><tr><td align="left">RxBERT [<xref ref-type="bibr" rid="CR31">31</xref>]</td><td char="." align="char">0.893</td><td char="." align="char">0.885</td><td char="." align="char">0.889</td></tr><tr><td align="left" rowspan="3"><p>Sub-experiment 2:</p><p>most up-to-date labeling</p></td><td align="left">Exact&#x02014;up to 1024 tokens output</td><td char="." align="char">0.758</td><td char="." align="char">0.769</td><td char="." align="char">0.753</td></tr><tr><td align="left">Semantic&#x02014;up to 1024 tokens output</td><td char="." align="char">0.840</td><td char="." align="char">0.895</td><td char="." align="char">0.859</td></tr><tr><td align="left">Semantic&#x02014;up to 4096 tokens output</td><td char="." align="char"><bold>0.848</bold></td><td char="." align="char"><bold>0.904</bold></td><td char="." align="char"><bold>0.870</bold></td></tr></tbody></table><table-wrap-foot><p><italic>AE</italic> adverse event, <italic>FDA</italic> Food and Drug Administration, <italic>TAC</italic> Text Analysis Conference, <italic>SOTA</italic> State-Of-The-Art</p></table-wrap-foot></table-wrap></p><p id="Par46">Moreover, we investigated the impact of output length on the final performance for drug name only (Table <xref rid="Tab2" ref-type="table">2</xref>). In this study, the output length was set to 1024 tokens per section by default. Although this output length met most of the requirements during our experiment, it was not enough for a few labeling documents that could contain hundreds of AE terms in one section. Therefore, we further increased the output length to 4096, with everything else unchanged. As a result, performance increased slightly compared to that of the 1024 output length, although longer output length also increase the processing time from 160 min to 180 min, for processing 200 drugs. Note that the increase of maximum output would not affect most of the queries since their outputs did not reach the token limits.</p><p id="Par47">In all, we demonstrated that AskFDALabel also generated high-quality AE profiling for a given drug. The detailed AE profiling report of the 188 drugs supporting the above analysis is provided in Online resource 5 (see the electronic supplementary material).</p></sec></sec><sec id="Sec19"><title>Discussion</title><sec id="Sec20"><title>Improved RAG with Hybrid Information Retrieval</title><p id="Par48">One important feature of AskFDALabel is the utilization of hybrid information retrieval, which combined database query with LLM inference to find the most relevant references for the user query.</p><p id="Par49">Database query has been widely used in past decades and is still the main approach for most information retrieval tasks. While database query has several advantages, the most important, if not the only one, for regulatory tasks is authenticity. In other words, database query will exactly return the record that has been stored in the knowledgebase, whereas semantic similarity search may lead to similar but not exactly matching results. Thus, database query helps eliminate a major concern related to applying generative LLMs into the regulatory settings.</p><p id="Par50">In AskFDALabel, we combined database query with an LLM by breaking down the whole information retrieval process of regular RAG into several steps. In some steps, such as template selection, entity recognition used an LLM to take advantage of its flexibility. For other steps such as labeling document retrieval, we decided to use a more conservative approach such as database query instead of a semantic similarity search, to ensure the retrieved reference would be relevant to the query, particularly when we knew the query was under a specific template.</p><p id="Par51">In this study, we demonstrated that using such a hybrid information retrieval approach can provide promising result in all three tasks, which further indicated that combining an LLM with conventional technologies instead of relying on it alone could provide better and more explainable outcomes.</p></sec><sec id="Sec21"><title>Enhancing Regulatory Science with Modularized and Customizable Templates</title><p id="Par52">In this study, we presented FDALabel-based RAG, which restricted the reference used in the LLM inference solely to the specific labeling documents instead of using the full scope of the LLM&#x02019;s inherent knowledge. For example, we did not expect AskFDALabel to process such tasks as &#x0201c;rephrase my proposal,&#x0201d; or &#x0201c;suggest a travel plan for my weekend,&#x0201d; but only to focus on labeling document review and analysis.</p><p id="Par53">Moreover, the AskFDALabel framework is designed to &#x0201c;plug-and-play&#x0201d; the foundation LLMs, like Llama 3.1-70B. One advantage of this strategy was the ability to directly benefit from the features introduced in the newer models, such as the increased token size newly introduced in Llama 3.1.</p><p id="Par54">Along with directly using the foundation model, developing a fine-tuned LLM for such a specific task will be an option for future exploration. To do that, a large corpus of documents must be collected to train/fine-tune domain-specific LLMs, in addition to the demanding requirement of massive hardware resources. Currently, externally hosted LLMs such as ChatGPT from OpenAI and Gemini from Google are not allowed for use in regulatory research and review at the agency. When policy changes, they will be explored and compared with Llama in terms of efficiency, cost, and performance gain for the AskFDALabel framework.</p></sec><sec id="Sec22"><title>Integrating Human Expertise into the LLM Framework</title><p id="Par55">In general, the manual reviewing process for labeling analysis can be divided into two steps. First, a strategy or protocol needs to be developed for the specific task. For example, for DILI classification, the reviewer needs to define which labeling section needs to be reviewed, the weight of different keywords in each section, and the severity level of DILI. After developing the strategy, the second step for reviewers is to undertake a labor-intensive process, such as manual document comparison or exhaustive database searches, to gather necessary information required for this task. Such processes might entail, for example, manually reading the labeling document and identifying and extracting all DILI-relevant keywords from section texts. This step is also prone to human errors or inconsistencies.</p><p id="Par56">That said, AskFDALabel is designed to automate the second step, to augment the reviewers&#x02019; analytical capabilities. Our current experiments demonstrated that with appropriate templates and prompts, AskFDALabel can generate highly consistent and reproducible results for human reviewers, which will largely reduce the manual effort involved in implementing the designed annotation strategy in the second step. Particularly, the output of AskFDALabel can provide information beyond the final answer, such as, which labeling document (i.e., its set-id) was referred to, or which DILI-related keywords were found and used to determine the DILI classes. This additional information can help reviewers more efficiently check and validate the AskFDALabel output, and increases the reliability and trustworthiness of applying AskFDALabel to their daily tasks.</p></sec><sec id="Sec23"><title>Limitations and Future Directions</title><p id="Par57">Our approach used fixed structured query language (SQL) queries to retrieve labeling documents by drug name, ensuring stability and data consistency. However, this static method limits adaptability for specific user inputs, such as routes of administration or dosage forms. Future work may incorporate LLMs to dynamically generate SQL queries from user prompts, though testing is required to confirm reliability.</p><p id="Par58">Additionally, fine-tuning LLMs with domain-specific data is expected to enhance their performance in addressing regulatory-specific queries, but care must be taken to balance improvements with computational costs and potential risks of overfitting to narrow datasets.</p><p id="Par59">While this study used only public drug labeling documents, AskFDALabel&#x02019;s framework is adaptable for secure, non-public data, enabling comparisons across historical and bioequivalent documents. These promising results suggest broader potential for applying AI to confidential regulatory documents, such as safety reports and training materials, advancing AI&#x02019;s role in regulatory science.</p></sec></sec><sec id="Sec24"><title>Conclusion</title><p id="Par60">AskFDALabel could be a game-changer since it has shown not only high accuracy and consistency, but also a capability to handle an ever-growing volume of data with a scalable and automated approach. Moreover, by providing additional explanations and cited references along with its answers, it can enhance the reliability of the automated process, making it easier for human reviewers to verify and trust the AI outputs. In all, we demonstrated that the generative AI could enhance the efficacy and effectiveness of drug safety research, particularly with, but possibly not limited to, drug labeling documents.</p><p id="Par61">In conclusion, the integration of advanced natural language processing (NLP) techniques and LLM-powered systems like AskFDALabel represents a significant leap forward in the field of AE research and drug safety. By automating the labor-intensive processes of AE annotation, profiling, and classification, AskFDALabel not only enhances efficiency but also improves the accuracy and consistency of data extraction from FDA drug labeling documents. This innovation has the potential to transform regulatory practices and advance the understanding of AE annotation, profiling, monitoring, and drug toxicity classification, ultimately contributing to the safe and effective use of drugs for better patient outcomes. The evaluation of AskFDALabel across multiple benchmark datasets demonstrates its effectiveness, marking a promising step toward more reliable and scalable solutions in pharmacovigilance and drug safety research.</p></sec><sec id="Sec25" sec-type="supplementary-material"><title>Supplementary Information</title><p>Below is the link to the electronic supplementary material.<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="40264_2025_1520_MOESM1_ESM.pdf"><caption><p>Supplementary file1 (PDF 164 KB)</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="40264_2025_1520_MOESM2_ESM.xlsx"><caption><p>Supplementary file2 (XLSX 14 KB)</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="40264_2025_1520_MOESM3_ESM.xlsx"><caption><p>Supplementary file3 (XLSX 35 KB)</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM4"><media xlink:href="40264_2025_1520_MOESM4_ESM.xlsx"><caption><p>Supplementary file4 (XLSX 132 KB)</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM5"><media xlink:href="40264_2025_1520_MOESM5_ESM.xlsx"><caption><p>Supplementary file5 (XLSX 374 KB)</p></caption></media></supplementary-material></p></sec></body><back><ack><title>Acknowledgement</title><p>The authors want to thank Ebony Cotton, Dongying Li, Lan Ying, Magnus Gray, and Skylar Connor for providing valuable suggestions and comments during the development and testing of AskFDALabel framework. We would like to thank Joanne Berger, FDA Library, for editing a draft of the manuscript.</p></ack><notes><title>Declarations</title><notes id="FPar1" notes-type="funding"><title>Funding</title><p id="Par62">Not applicable.</p></notes><notes id="FPar2" notes-type="COI-statement"><title>Conflict of Interest</title><p id="Par63">The authors declared no conflicts of interest.</p></notes><notes id="FPar3"><title>Disclaimer</title><p id="Par64">The views presented in this article do not necessarily reflect those of the US Food and Drug Administration. Any mention of commercial products is for clarification and is not intended as an endorsement.</p></notes><notes id="FPar4"><title>Ethics Approval</title><p id="Par65">Not applicable.</p></notes><notes id="FPar5"><title>Consent to Participate</title><p id="Par66">Not applicable.</p></notes><notes id="FPar6"><title>Consent for Publication</title><p id="Par67">Not applicable.</p></notes><notes id="FPar7"><title>Availability of Data and Materials</title><p id="Par68">The FDALabel database can be accessed from <ext-link ext-link-type="uri" xlink:href="https://nctr-crs.fda.gov/fdalabel/ui/search">https://nctr-crs.fda.gov/fdalabel/ui/search</ext-link>. All data used in this study can be found in the electronic supplementary material (Online resources 3&#x02013;5).</p></notes><notes id="FPar8"><title>Code Availability</title><p id="Par69">The prompt and SQL query used in the study can be found in the electronic supplementary material (Online resource 1).</p></notes><notes id="FPar9" notes-type="author-contribution"><title>Author Contributions</title><p id="Par70">LW and WT initiated the concept; LW, JX, YQ, and HF did the experiment and data analysis; LW, HF, and WT wrote the first draft of the manuscript. All authors read and revised the manuscript.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Lazarou</surname><given-names>J</given-names></name><name><surname>Pomeranz</surname><given-names>BH</given-names></name><name><surname>Corey</surname><given-names>PN</given-names></name></person-group><article-title>Incidence of adverse drug reactions in hospitalized patients: a meta-analysis of prospective studies</article-title><source>JAMA</source><year>1998</year><volume>279</volume><issue>15</issue><fpage>1200</fpage><lpage>1205</lpage><pub-id pub-id-type="doi">10.1001/jama.279.15.1200</pub-id><pub-id pub-id-type="pmid">9555760</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal">Lazarou J, Pomeranz BH, Corey PN. Incidence of adverse drug reactions in hospitalized patients: a meta-analysis of prospective studies. JAMA. 1998;279(15):1200&#x02013;5.<pub-id pub-id-type="pmid">9555760</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">FDA US. FDA Adverse Event Reporting System (FAERS) Public Dashboard. 2024 [cited; Available from: <ext-link ext-link-type="uri" xlink:href="https://fis.fda.gov/sense/app/95239e26-e0be-42d9-a960-9a5f7f1c25ee/sheet/7a47a261-d58b-4203-a8aa-6d3021737452/state/analysis">https://fis.fda.gov/sense/app/95239e26-e0be-42d9-a960-9a5f7f1c25ee/sheet/7a47a261-d58b-4203-a8aa-6d3021737452/state/analysis</ext-link></mixed-citation></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>H</given-names></name><name><surname>Harris</surname><given-names>SC</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Zhou</surname><given-names>G</given-names></name><name><surname>Zhang</surname><given-names>G</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><etal/></person-group><article-title>FDA drug labeling: rich resources to facilitate precision medicine, drug safety, and regulatory science</article-title><source>Drug Discov Today</source><year>2016</year><volume>21</volume><issue>10</issue><fpage>1566</fpage><lpage>1570</lpage><pub-id pub-id-type="doi">10.1016/j.drudis.2016.06.006</pub-id><pub-id pub-id-type="pmid">27319291</pub-id>
</element-citation><mixed-citation id="mc-CR3" publication-type="journal">Fang H, Harris SC, Liu Z, Zhou G, Zhang G, Xu J, et al. FDA drug labeling: rich resources to facilitate precision medicine, drug safety, and regulatory science. Drug Discov Today. 2016;21(10):1566&#x02013;70.<pub-id pub-id-type="pmid">27319291</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>H</given-names></name><name><surname>Harris</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Thakkar</surname><given-names>S</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Ingle</surname><given-names>T</given-names></name><etal/></person-group><article-title>FDALabel for drug repurposing studies and beyond</article-title><source>Nat Biotechnol</source><year>2020</year><volume>38</volume><issue>12</issue><fpage>1378</fpage><lpage>1379</lpage><pub-id pub-id-type="doi">10.1038/s41587-020-00751-0</pub-id><pub-id pub-id-type="pmid">33235392</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Fang H, Harris S, Liu Z, Thakkar S, Yang J, Ingle T, et al. FDALabel for drug repurposing studies and beyond. Nat Biotechnol. 2020;38(12):1378&#x02013;9.<pub-id pub-id-type="pmid">33235392</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhn</surname><given-names>M</given-names></name><name><surname>Letunic</surname><given-names>I</given-names></name><name><surname>Jensen</surname><given-names>LJ</given-names></name><name><surname>Bork</surname><given-names>P</given-names></name></person-group><article-title>The SIDER database of drugs and side effects</article-title><source>Nucleic Acids Res</source><year>2015</year><volume>44</volume><issue>D1</issue><fpage>D1075</fpage><lpage>D1079</lpage><pub-id pub-id-type="doi">10.1093/nar/gkv1075</pub-id><pub-id pub-id-type="pmid">26481350</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Kuhn M, Letunic I, Jensen LJ, Bork P. The SIDER database of drugs and side effects. Nucleic Acids Res. 2015;44(D1):D1075&#x02013;9.<pub-id pub-id-type="pmid">26481350</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Ingle</surname><given-names>T</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Zhao-Wong</surname><given-names>A</given-names></name><name><surname>Harris</surname><given-names>S</given-names></name><name><surname>Thakkar</surname><given-names>S</given-names></name><etal/></person-group><article-title>Study of serious adverse drug reactions using FDA-approved drug labeling and MedDRA</article-title><source>BMC Bioinform</source><year>2019</year><volume>20</volume><fpage>129</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1186/s12859-019-2628-5</pub-id></element-citation><mixed-citation id="mc-CR6" publication-type="journal">Wu L, Ingle T, Liu Z, Zhao-Wong A, Harris S, Thakkar S, et al. Study of serious adverse drug reactions using FDA-approved drug labeling and MedDRA. BMC Bioinform. 2019;20:129&#x02013;39.</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Roberts K, Demner-Fushman D, Tonning JM. Overview of the TAC 2017 adverse reaction extraction from drug labels track. TAC; 2017.</mixed-citation></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name><surname>Bayer</surname><given-names>S</given-names></name><name><surname>Clark</surname><given-names>C</given-names></name><name><surname>Dang</surname><given-names>O</given-names></name><name><surname>Aberdeen</surname><given-names>J</given-names></name><name><surname>Brajovic</surname><given-names>S</given-names></name><name><surname>Swank</surname><given-names>K</given-names></name><etal/></person-group><article-title>ADE eval: an evaluation of text processing systems for adverse event extraction from drug labels for pharmacovigilance</article-title><source>Drug Saf</source><year>2021</year><volume>44</volume><fpage>83</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1007/s40264-020-00996-3</pub-id><pub-id pub-id-type="pmid">33006728</pub-id>
</element-citation><mixed-citation id="mc-CR8" publication-type="journal">Bayer S, Clark C, Dang O, Aberdeen J, Brajovic S, Swank K, et al. ADE eval: an evaluation of text processing systems for adverse event extraction from drug labels for pharmacovigilance. Drug Saf. 2021;44:83&#x02013;94.<pub-id pub-id-type="pmid">33006728</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Vijay</surname><given-names>V</given-names></name><name><surname>Shi</surname><given-names>Q</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Fang</surname><given-names>H</given-names></name><name><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>FDA-approved drug labeling for the study of drug-induced liver injury</article-title><source>Drug Discov Today</source><year>2011</year><volume>16</volume><issue>15&#x02013;16</issue><fpage>697</fpage><lpage>703</lpage><pub-id pub-id-type="doi">10.1016/j.drudis.2011.05.007</pub-id><pub-id pub-id-type="pmid">21624500</pub-id>
</element-citation><mixed-citation id="mc-CR9" publication-type="journal">Chen M, Vijay V, Shi Q, Liu Z, Fang H, Tong W. FDA-approved drug labeling for the study of drug-induced liver injury. Drug Discov Today. 2011;16(15&#x02013;16):697&#x02013;703.<pub-id pub-id-type="pmid">21624500</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Suzuki</surname><given-names>A</given-names></name><name><surname>Thakkar</surname><given-names>S</given-names></name><name><surname>Yu</surname><given-names>K</given-names></name><name><surname>Hu</surname><given-names>C</given-names></name><name><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>DILIrank: the largest reference drug list ranked by the risk for developing drug-induced liver injury in humans</article-title><source>Drug Discov Today</source><year>2016</year><volume>21</volume><issue>4</issue><fpage>648</fpage><lpage>653</lpage><pub-id pub-id-type="doi">10.1016/j.drudis.2016.02.015</pub-id><pub-id pub-id-type="pmid">26948801</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Chen M, Suzuki A, Thakkar S, Yu K, Hu C, Tong W. DILIrank: the largest reference drug list ranked by the risk for developing drug-induced liver injury in humans. Drug Discov Today. 2016;21(4):648&#x02013;53.<pub-id pub-id-type="pmid">26948801</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Thakkar</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Roberts</surname><given-names>R</given-names></name><name><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>Drug-induced liver injury severity and toxicity (DILIst): binary classification of 1279 drugs by human hepatotoxicity</article-title><source>Drug Discov Today</source><year>2020</year><volume>25</volume><issue>1</issue><fpage>201</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.drudis.2019.09.022</pub-id><pub-id pub-id-type="pmid">31669330</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Thakkar S, Li T, Liu Z, Wu L, Roberts R, Tong W. Drug-induced liver injury severity and toxicity (DILIst): binary classification of 1279 drugs by human hepatotoxicity. Drug Discov Today. 2020;25(1):201&#x02013;8.<pub-id pub-id-type="pmid">31669330</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Qu</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>D</given-names></name><name><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>DICTrank: the largest reference list of 1318 human drugs ranked by risk of drug-induced cardiotoxicity using FDA labeling</article-title><source>Drug Discov Today</source><year>2023</year><volume>15</volume><issue>1</issue><fpage>103770</fpage><pub-id pub-id-type="doi">10.1016/j.drudis.2023.103770</pub-id></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Qu Y, Li T, Liu Z, Li D, Tong W. DICTrank: the largest reference list of 1318 human drugs ranked by risk of drug-induced cardiotoxicity using FDA labeling. Drug Discov Today. 2023;15(1):103770.</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Connor</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Qu</surname><given-names>Y</given-names></name><name><surname>Roberts</surname><given-names>RA</given-names></name><name><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>Generation of a drug-induced renal injury list to facilitate the development of new approach methodologies for nephrotoxicity</article-title><source>Drug Discov Today</source><year>2024</year><volume>29</volume><issue>4</issue><fpage>103938</fpage><pub-id pub-id-type="doi">10.1016/j.drudis.2024.103938</pub-id><pub-id pub-id-type="pmid">38432353</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Connor S, Li T, Qu Y, Roberts RA, Tong W. Generation of a drug-induced renal injury list to facilitate the development of new approach methodologies for nephrotoxicity. Drug Discov Today. 2024;29(4):103938.<pub-id pub-id-type="pmid">38432353</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Silberg J, Swanson K, Simon E, Zhang A, Ghazizadeh Z, Ogden S, et al. UniTox: leveraging LLMs to curate a unified dataset of drug-induced toxicity from FDA labels. In: The thirty-eight conference on neural information processing systems datasets and benchmarks track; 2024.</mixed-citation></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>DP</given-names></name><name><surname>Lazic</surname><given-names>SE</given-names></name><name><surname>Foster</surname><given-names>AJ</given-names></name><name><surname>Semenova</surname><given-names>E</given-names></name><name><surname>Morgan</surname><given-names>P</given-names></name></person-group><article-title>Predicting drug-induced liver injury with Bayesian machine learning</article-title><source>Chem Res Toxicol</source><year>2019</year><volume>33</volume><issue>1</issue><fpage>239</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1021/acs.chemrestox.9b00264</pub-id><pub-id pub-id-type="pmid">31535850</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Williams DP, Lazic SE, Foster AJ, Semenova E, Morgan P. Predicting drug-induced liver injury with Bayesian machine learning. Chem Res Toxicol. 2019;33(1):239&#x02013;48.<pub-id pub-id-type="pmid">31535850</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Zheng</surname><given-names>R</given-names></name><name><surname>Qiu</surname><given-names>R</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><etal/></person-group><article-title>ResNet18DNN: prediction approach of drug-induced liver injury by deep neural network with ResNet18</article-title><source>Brief Bioinform</source><year>2022</year><volume>23</volume><issue>1</issue><fpage>bbab503</fpage><pub-id pub-id-type="doi">10.1093/bib/bbab503</pub-id><pub-id pub-id-type="pmid">34882224</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Chen Z, Jiang Y, Zhang X, Zheng R, Qiu R, Sun Y, et al. ResNet18DNN: prediction approach of drug-induced liver injury by deep neural network with ResNet18. Brief Bioinform. 2022;23(1):bbab503.<pub-id pub-id-type="pmid">34882224</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Minerali</surname><given-names>E</given-names></name><name><surname>Foil</surname><given-names>DH</given-names></name><name><surname>Zorn</surname><given-names>KM</given-names></name><name><surname>Lane</surname><given-names>TR</given-names></name><name><surname>Ekins</surname><given-names>S</given-names></name></person-group><article-title>Comparing machine learning algorithms for predicting drug-induced liver injury (DILI)</article-title><source>Mol Pharm</source><year>2020</year><volume>17</volume><issue>7</issue><fpage>2628</fpage><lpage>2637</lpage><pub-id pub-id-type="doi">10.1021/acs.molpharmaceut.0c00326</pub-id><pub-id pub-id-type="pmid">32422053</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal">Minerali E, Foil DH, Zorn KM, Lane TR, Ekins S. Comparing machine learning algorithms for predicting drug-induced liver injury (DILI). Mol Pharm. 2020;17(7):2628&#x02013;37.<pub-id pub-id-type="pmid">32422053</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>P</given-names></name><name><surname>Masilamani</surname><given-names>V</given-names></name><name><surname>Mukherjee</surname><given-names>A</given-names></name></person-group><article-title>A knowledge graph embedding based approach to predict the adverse drug reactions using a deep neural network</article-title><source>J Biomed Inform</source><year>2022</year><volume>132</volume><fpage>104122</fpage><pub-id pub-id-type="doi">10.1016/j.jbi.2022.104122</pub-id><pub-id pub-id-type="pmid">35753606</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Joshi P, Masilamani V, Mukherjee A. A knowledge graph embedding based approach to predict the adverse drug reactions using a deep neural network. J Biomed Inform. 2022;132: 104122.<pub-id pub-id-type="pmid">35753606</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>BERT-based natural language processing of drug labeling documents: a case study for classifying drug-induced liver injury risk</article-title><source>Front Artif Intell</source><year>2021</year><volume>4</volume><fpage>729834</fpage><pub-id pub-id-type="doi">10.3389/frai.2021.729834</pub-id><pub-id pub-id-type="pmid">34939028</pub-id>
</element-citation><mixed-citation id="mc-CR19" publication-type="journal">Wu Y, Liu Z, Wu L, Chen M, Tong W. BERT-based natural language processing of drug labeling documents: a case study for classifying drug-induced liver injury risk. Front Artif Intell. 2021;4: 729834.<pub-id pub-id-type="pmid">34939028</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Thakkar</surname><given-names>S</given-names></name><name><surname>Gray</surname><given-names>M</given-names></name><name><surname>Qu</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>D</given-names></name><etal/></person-group><article-title>A framework enabling LLMs into regulatory environment for transparency and trustworthiness and its application to drug labeling document</article-title><source>Regul Toxicol Pharmacol</source><year>2024</year><volume>149</volume><fpage>105613</fpage><pub-id pub-id-type="doi">10.1016/j.yrtph.2024.105613</pub-id><pub-id pub-id-type="pmid">38570021</pub-id>
</element-citation><mixed-citation id="mc-CR20" publication-type="journal">Wu L, Xu J, Thakkar S, Gray M, Qu Y, Li D, et al. A framework enabling LLMs into regulatory environment for transparency and trustworthiness and its application to drug labeling document. Regul Toxicol Pharmacol. 2024;149: 105613.<pub-id pub-id-type="pmid">38570021</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Touvron H, Lavril T, Izacard G, Martinet X, Lachaux M-A, Lacroix T, et al. Llama: open and efficient foundation language models. arXiv:230213971; 2023.</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Almazrouei E, Alobeidli H, Alshamsi A, Cappelli A, Cojocaru R, Debbah M, et al. The Falcon series of open language models. arXiv:231116867. 2023.</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Taori R, Gulrajani I, Zhang T, Dubois Y, Li X, Guestrin C, et al. Stanford Alpaca: an instruction-following Llama model; 2023.</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">(NIST) USNIoSaT. Text Analysis Conference (TAC) 2017. 2017 [cited 2024; <ext-link ext-link-type="uri" xlink:href="https://tac.nist.gov/2017/">https://tac.nist.gov/2017/</ext-link></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Pennington J, Socher R, Manning CD. Glove: global vectors for word representation. In: Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP); 2014. p. 1532&#x02013;43.</mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Reimers N, Gurevych I. Sentence-BERT: sentence embeddings using Siamese BERT-networks. arXiv:190810084; 2019.</mixed-citation></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Chen</surname><given-names>K</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name></person-group><article-title>Distributed representations of words and phrases and their compositionality</article-title><source>Adv Neural Inf Process Syst</source><year>2013</year><volume>26</volume><fpage>3111</fpage><lpage>3119</lpage></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J. Distributed representations of words and phrases and their compositionality. Adv Neural Inf Process Syst. 2013;26:3111&#x02013;9.</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Meta. Meet Llama 3.1. 2024 [cited 08/02/2024]. Available from <ext-link ext-link-type="uri" xlink:href="https://llama.meta.com/">https://llama.meta.com/</ext-link></mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Kwon W, Li Z, Zhuang S, Sheng Y, Zheng L, Yu CH, et al. Efficient memory management for large language model serving with paged attention. In: Proceedings of the 29th symposium on operating systems principles; 2023. pp. 611&#x02013;626.</mixed-citation></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Wingerd</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Thakkar</surname><given-names>S</given-names></name><etal/></person-group><article-title>Automatic text classification of drug-induced liver injury using document-term matrix and XGBoost</article-title><source>Front Artif Intell</source><year>2024</year><volume>7</volume><fpage>1401810</fpage><pub-id pub-id-type="doi">10.3389/frai.2024.1401810</pub-id><pub-id pub-id-type="pmid">38887604</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal">Chen M, Wu Y, Wingerd B, Liu Z, Xu J, Thakkar S, et al. Automatic text classification of drug-induced liver injury using document-term matrix and XGBoost. Front Artif Intell. 2024;7:1401810.<pub-id pub-id-type="pmid">38887604</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>L</given-names></name><name><surname>Gray</surname><given-names>M</given-names></name><name><surname>Dang</surname><given-names>O</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Fang</surname><given-names>H</given-names></name><name><surname>Tong</surname><given-names>W</given-names></name></person-group><article-title>RxBERT: enhancing drug labeling text mining and analysis with AI language modeling</article-title><source>Exp Biol Med</source><year>2023</year><volume>248</volume><issue>21</issue><fpage>1937</fpage><lpage>1943</lpage><pub-id pub-id-type="doi">10.1177/15353702231220669</pub-id></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Wu L, Gray M, Dang O, Xu J, Fang H, Tong W. RxBERT: enhancing drug labeling text mining and analysis with AI language modeling. Exp Biol Med. 2023;248(21):1937&#x02013;43.</mixed-citation></citation-alternatives></ref></ref-list></back></article>