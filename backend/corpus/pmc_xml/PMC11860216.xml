<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Prostate Cancer Prostatic Dis</journal-id><journal-id journal-id-type="iso-abbrev">Prostate Cancer Prostatic Dis</journal-id><journal-title-group><journal-title>Prostate Cancer and Prostatic Diseases</journal-title></journal-title-group><issn pub-type="ppub">1365-7852</issn><issn pub-type="epub">1476-5608</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38871841</article-id><article-id pub-id-type="pmc">PMC11860216</article-id>
<article-id pub-id-type="publisher-id">847</article-id><article-id pub-id-type="doi">10.1038/s41391-024-00847-7</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Can ChatGPT provide high-quality patient information on male lower urinary tract symptoms suggestive of benign prostate enlargement?</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Puerto Nino</surname><given-names>Angie K.</given-names></name><address><email>angie.puerto-nino@helsinki.fi</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Garcia Perez</surname><given-names>Valentina</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4953-0091</contrib-id><name><surname>Secco</surname><given-names>Silvia</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2190-512X</contrib-id><name><surname>De Nunzio</surname><given-names>Cosimo</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2890-3159</contrib-id><name><surname>Lombardo</surname><given-names>Riccardo</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Tikkinen</surname><given-names>Kari A. O.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff6">6</xref><xref ref-type="aff" rid="Aff7">7</xref><xref ref-type="aff" rid="Aff8">8</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1507-7783</contrib-id><name><surname>Elterman</surname><given-names>Dean S.</given-names></name><address><email>Dean.Elterman@uhn.ca</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/040af2s02</institution-id><institution-id institution-id-type="GRID">grid.7737.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 0410 2071</institution-id><institution>Faculty of Medicine, </institution><institution>University of Helsinki, </institution></institution-wrap>Helsinki, Finland </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03dbr7087</institution-id><institution-id institution-id-type="GRID">grid.17063.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 2938</institution-id><institution>Division of Urology, Department of Surgery, </institution><institution>University of Toronto, </institution></institution-wrap>Toronto, ON Canada </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02mhbdp94</institution-id><institution-id institution-id-type="GRID">grid.7247.6</institution-id><institution-id institution-id-type="ISNI">0000000419370714</institution-id><institution>Faculty of Medicine, </institution><institution>University of the Andes, </institution></institution-wrap>Bogota, Colombia </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00htrxv69</institution-id><institution-id institution-id-type="GRID">grid.416200.1</institution-id><institution>Department of Urology, </institution><institution>Niguarda Hospital, </institution></institution-wrap>Milan, Italy </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02be6w209</institution-id><institution-id institution-id-type="GRID">grid.7841.a</institution-id><institution>Urology Unit, </institution><institution>Ospedale Sant&#x02019;Andrea, La Sapienza University of Rome, </institution></institution-wrap>Rome, Italy </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/040af2s02</institution-id><institution-id institution-id-type="GRID">grid.7737.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 0410 2071</institution-id><institution>Department of Urology, </institution><institution>University of Helsinki and Helsinki University Hospital, </institution></institution-wrap>Helsinki, Finland </aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01x8yyz38</institution-id><institution-id institution-id-type="GRID">grid.416155.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 0628 2117</institution-id><institution>Department of Surgery, </institution><institution>South Karelian Central Hospital, </institution></institution-wrap>Lappeenranta, Finland </aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02fa3aq29</institution-id><institution-id institution-id-type="GRID">grid.25073.33</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8227</institution-id><institution>Department of Health Research Methods, Evidence and Impact, </institution><institution>McMaster University, </institution></institution-wrap>Hamilton, ON Canada </aff></contrib-group><pub-date pub-type="epub"><day>13</day><month>6</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>13</day><month>6</month><year>2024</year></pub-date><pub-date pub-type="ppub"><year>2025</year></pub-date><volume>28</volume><issue>1</issue><fpage>167</fpage><lpage>172</lpage><history><date date-type="received"><day>26</day><month>3</month><year>2024</year></date><date date-type="rev-recd"><day>3</day><month>5</month><year>2024</year></date><date date-type="accepted"><day>10</day><month>5</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p id="Par1">ChatGPT has recently emerged as a novel resource for patients&#x02019; disease-specific inquiries. There is, however, limited evidence assessing the quality of the information. We evaluated the accuracy and quality of the ChatGPT&#x02019;s responses on male lower urinary tract symptoms (LUTS) suggestive of benign prostate enlargement (BPE) when compared to two reference resources.</p></sec><sec><title>Methods</title><p id="Par2">Using patient information websites from the European Association of Urology and the American Urological Association as reference material, we formulated 88 BPE-centric questions for ChatGPT 4.0+. Independently and in duplicate, we compared the ChatGPT&#x02019;s responses and the reference material, calculating accuracy through F1 score, precision, and recall metrics. We used a 5-point Likert scale for quality rating. We evaluated examiner agreement using the interclass correlation coefficient and assessed the difference in the quality scores with the Wilcoxon signed-rank test.</p></sec><sec><title>Results</title><p id="Par3">ChatGPT addressed all (88/88) LUTS/BPE-related questions. For the 88 questions, the recorded F1 score was 0.79 (range: 0&#x02013;1), precision 0.66 (range: 0&#x02013;1), recall 0.97 (range: 0&#x02013;1), and the quality score had a median of 4 (range&#x02009;=&#x02009;1&#x02013;5). Examiners had a good level of agreement (ICC&#x02009;=&#x02009;0.86). We found no statistically significant difference between the scores given by the examiners and the overall quality of the responses (<italic>p</italic>&#x02009;=&#x02009;0.72).</p></sec><sec><title>Discussion</title><p id="Par4">ChatGPT demostrated a potential utility in educating patients about BPE/LUTS, its prognosis, and treatment that helps in the decision-making process. One must exercise prudence when recommending this as the sole information outlet. Additional studies are needed to completely understand the full extent of AI&#x02019;s efficacy in delivering patient education in urology.</p></sec></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Translational research</kwd><kwd>Outcomes research</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par5">In the midst of growing medical data and reduced accessibility to healthcare professionals, patients are increasingly seeking guidance from search engines and video-streaming platforms [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. As a result, major urological associations, such as the European Association of Urology (EAU) and the American Urological Association (AUA), have designed online resources that furnish patients with high-quality information and help guide their decision-making process [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]. Nonetheless, the rise of modern technologies has shifted the focus from established institutions to new methods of information garnering such as social media, video tutorials, and artificial intelligence (AI) since they offer more immediate and efficient methods of information retrieval [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>].</p><p id="Par6">With more than 1.5 million visits per month and more than 180 million active users, ChatGPT is rapidly becoming the fastest-growing AI language models in the world [<xref ref-type="bibr" rid="CR7">7</xref>]. This impressive growth can be attributed to its user-friendly chatbot interface, which enables users to pose questions in a conversational style, closely mirroring human interaction [<xref ref-type="bibr" rid="CR2">2</xref>]. As an increased proportion of physicians and patients continue to explore AI as a tool to further their knowledge or aid the deliverance of healthcare-related services, the need has surfaced to evaluate the accuracy and quality of such technology [<xref ref-type="bibr" rid="CR1">1</xref>]. A survey, conducted among urologists between April and May 2023, revealed that ~20% had utilized ChatGPT in clinical settings, 56% believed in its potential to aid in clinical decision-making, and more than half suspected that this might be used by their patients for self-management [<xref ref-type="bibr" rid="CR8">8</xref>].</p><p id="Par7">A limited number of studies, with marked heterogeneity in their results, have been conducted to evaluate the accuracy and reliability of ChatGPT in answering urological queries. In the field of pediatric urology, ChatGPT&#x02019;s performance showed a 92% accuracy rate when compared to verified resources [<xref ref-type="bibr" rid="CR9">9</xref>]. Similarly, studies on its ability to educate patients for robotic-assisted prostatectomy found a 79% concordance between source material and ChatGPT&#x02019;s responses, and even higher rates of accuracy when evaluating only the information provided by the AI chatbot [<xref ref-type="bibr" rid="CR10">10</xref>]. Conversely, for prostate cancer-related queries, the answers were found to have low performance with an F1 score of 0.426, a precision score of 0.349, a recall score of 0.549, and a general quality score (GQS) levels of 3.62&#x02009;&#x000b1;&#x02009;0.49 [<xref ref-type="bibr" rid="CR11">11</xref>]. These findings are further corroborated by other studies, evaluating ChatGPT&#x02019;s answers to multiple urological diseases queries, including BPE, and found a moderate to low quality of responses [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>]. Overall, these heterogeneous results suggest that ChatGPT&#x02019;s effectiveness varies across different urological conditions, potentially performing better in some areas and worse in others.</p><p id="Par8">In light of such conflicting reports about ChatGPT&#x02019;s quality and accuracy, as well as the lack of current studies investigating its performance in lower urinary tract symptoms (LUTS) suggestive of benign prostate enlargement (BPE) related inquiries, our study aims to evaluate the accuracy and precision of the information provided by ChatGPT&#x02019;s chatbot (ChatGPT 4.0+) on male LUTS suggestive of BPE compared to two reference resources extracted from the EAU&#x02019;s patient information portal and the AUA&#x02019;s patient guide manual.</p></sec><sec id="Sec2" sec-type="materials|methods"><title>Materials and methods</title><sec id="Sec3"><title>Information acquisition and data extraction</title><p id="Par9">To start, we scoured the patient information websites from the EAU and AUA in order to identify frequently asked questions and topics of interest. From this, we formulated 88 BPE-centric queries that ranged from concept definition (e.g., &#x0201c;What is BPE?&#x0201d;), symptoms and diagnostics evaluations (e.g., &#x0201d;What are the normal values of uroflowmetry?&#x0201d;), risk and complications (e.g., What are the risks of BPE?), conservative management and pharmacotherapy (e.g., &#x0201c;What are the most common side effects of &#x003b1;1-blockers in the treatment of BPE?&#x0201d;), and surgical treatment options (e.g., &#x0201c;What minimally invasive procedures are available for BPE?&#x0201d;), see Appendix&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>. These questions were then fed to ChatGPT in an independent manner (for each question a new conversation was started) with the response recorded and later compared to the reference material previously mentioned, see Appendix&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>.</p></sec><sec id="Sec4"><title>Performance metrics</title><p id="Par10">Two examiners independently and in duplicate classified the responses into one of four categories. When examiners found that the ChatGPT&#x02019;s response was false despite a true version of the statement being present in the source material, they rated it as true negative (TN). If the source material had information not generated by ChatGPT, the examiners classified the response as false negative (FN). Conversely, when ChatGPT&#x02019;s response was true and verifiable in the source material, examiners categorized it as true positive (TP). If the statement provided by ChatGPT was true according to the current literature but was not present in the reference source, we classified it as false positive (FP). Examiners resolved the discrepancies between the grading by either reaching a mutual consensus or asking a senior specialist.</p><p id="Par11">Once we finished all classifications, we calculated the F1 score, precision, and recall metrics (formula below). We decided to use the F1 score as it is a validated machine-learning metric for the assessment of a model&#x02019;s accuracy by evaluating the model&#x02019;s capability of making a correct prediction across a binary class database. The score does this by calculating the harmonic means of both precision and recall measurements on a scale of 0&#x02013;1, where 0 are all incorrect predictions and 1 represents completely accurate predictions.<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Precision}=\frac{{TP}}{({TP}+{FP})}{Recall}=\frac{{TP}}{({TP}+{FN})}F1{Score}=2\times \frac{({Precision}\times {Recall})}{({Precision}+{Recall})}$$\end{document}</tex-math><mml:math id="M2"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41391_2024_847_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p></sec><sec id="Sec5"><title>General quality scores (GQS)</title><p id="Par12">We generated a GQS using a 5-point Likert scale (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). The GQS evaluated the quality of the responses generated by ChatGPT. The grading aimed to assess each response&#x02019;s truthfulness, relevancy, structure, and language. Examiners granted a GQS score of 1 when the information was false or misleading, the text was disorganized or used incomprehensible language, and had zero value to the patient. In contrast, examiners gave a GQS score of 5 when the information was extremely accurate, flawlessly organized, used patient-friendly language, and was totally relevant for the patient. We determined the final GQS score by calculating the mean of the two examiners&#x02019; scores for each question.<table-wrap id="Tab1"><label>Table 1</label><caption><p>General quality score.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>General quality score</th><th>Description</th></tr></thead><tbody><tr><td><bold>1</bold></td><td><p>- Truthfulness: contains false or misleading information</p><p>- Relevancy/value: does not answer the question or lacks patient benefit</p><p>- Structure: disorganized text</p><p>- Language: uses 90&#x02013;100% medical jargon or incomprehensible language</p></td></tr><tr><td><bold>2</bold></td><td><p>- Truthfulness: information is somewhat accurate but outdated</p><p>- Relevancy/value: partially addresses the question but offers limited value to patients or &#x0003e;90% of the content is off-topic</p><p>- Structure: poorly organized text</p><p>- Language: uses 50&#x02013;90% medical jargon or unfamiliar language</p></td></tr><tr><td><bold>3</bold></td><td><p>- Truthfulness: adequate information but may lack comprehensive details</p><p>- Relevancy/value: partially addresses the question with some value to patients or 50&#x02013;90% of the content is off-topic</p><p>- Structure: semi-organized text</p><p>- Language: uses &#x0003c;50% medical jargon or unfamiliar language</p></td></tr><tr><td><bold>4</bold></td><td><p>- Truthfulness: accurate information</p><p>- Relevancy/value: fully addresses the question with valuable insights for patients or &#x0003c;50% of the content is off-topic</p><p>- Structure: well-organized text</p><p>- Language: uses lay language (7-grade reading level)</p></td></tr><tr><td><bold>5</bold></td><td><p>- Truthfulness: extremely accurate information</p><p>- Relevancy/value: fully addresses the question offering significant value to patients with no irrelevant content</p><p>- Structure: flawlessly organized text and easy to follow</p><p>- Language: uses patient-friendly terminology and lay language (7-grade reading level)</p></td></tr></tbody></table></table-wrap></p><p id="Par13">We evaluated the level of agreement on the GQS scores between the two examiners using the interclass correlation coefficient (ICC; (2,1)). The difference in the GQS scores between the two examiners was assessed by the Wilcoxon signed-rank test. A <italic>p</italic> value&#x02009;&#x0003c;&#x02009;0.05 was considered statistically significant. We used SAS version 9.4 for all analyses [<xref ref-type="bibr" rid="CR14">14</xref>].</p></sec></sec><sec id="Sec6" sec-type="results"><title>Results</title><p id="Par14">ChatGPT addressed 88 questions across eight categories related to BPE (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). 71.6% of the questions (<italic>n</italic>&#x02009;=&#x02009;63) focused on BPE management, including conventional surgical interventions (<italic>n</italic>&#x02009;=&#x02009;27), minimally invasive surgical therapies (MIST, <italic>n</italic>&#x02009;=&#x02009;21), and pharmacotherapy (<italic>n</italic>&#x02009;=&#x02009;15) (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). ChatGPT generated responses to all 88 questions with a total of 22,946 words and 1430 sentences. In contrast, the EAU website contained 4914 words and 200 sentences, while the AUA patient guide had 3472 words and 238 sentences. AI-generated responses had almost three times more words than the source material (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). For instance, Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref> describes a few examples of the responses provided by ChatGPT and the reference materials. Performance metrics of the ChatGPT&#x02019;s responses fluctuated from 0.5 to 1.0, including F1 score (range&#x02009;=&#x02009;0.67&#x02013;1.0), precision scores (range&#x02009;=&#x02009;0.5&#x02013;1.0), and recall (range&#x02009;=&#x02009;0.9&#x02013;1.0) (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). GQS scores ranged from 3.5 to 5 (Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>).<table-wrap id="Tab2"><label>Table 2</label><caption><p>Descriptive statistics and performance metrics by BPE category.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>General concepts</th><th>Risk &#x00026; complications</th><th>Symptoms</th><th>Testing</th><th>Conservative management</th><th>Pharmacotherapy</th><th>Surgical intervention</th><th>MIST</th></tr></thead><tbody><tr><td>No. of questions</td><td>4</td><td>6</td><td>4</td><td>9</td><td>2</td><td>15</td><td>27</td><td>21</td></tr><tr><td>No. of words ChatGPT</td><td>979</td><td>1811</td><td>950</td><td>1870</td><td>541</td><td>3435</td><td>7674</td><td>6302</td></tr><tr><td>No. of sentences ChatGPT</td><td>72</td><td>122</td><td>63</td><td>128</td><td>45</td><td>247</td><td>575</td><td>463</td></tr><tr><td>No. of words EAU</td><td>95</td><td>332</td><td>260</td><td>119</td><td>643</td><td>781</td><td>2159</td><td>675</td></tr><tr><td>No. of sentences EAU</td><td>6</td><td>20</td><td>24</td><td>9</td><td>50</td><td>58</td><td>115</td><td>40</td></tr><tr><td>No. of words AUA</td><td>181</td><td>185</td><td>323</td><td>730</td><td>180</td><td>214</td><td>1139</td><td>507</td></tr><tr><td>No. of sentences AUA</td><td>28</td><td>20</td><td>31</td><td>72</td><td>18</td><td>17</td><td>100</td><td>47</td></tr><tr><td>F1 score</td><td>0.86</td><td>1.00</td><td>1.00</td><td>0.94</td><td>1.00</td><td>0.75</td><td>0.71</td><td>0.67</td></tr><tr><td>Precision score</td><td>0.75</td><td>1.00</td><td>1.00</td><td>0.89</td><td>1.00</td><td>0.64</td><td>0.58</td><td>0.50</td></tr><tr><td>Recall score</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td><td>0.90</td><td>0.94</td><td>1.00</td></tr><tr><td>GQS Score</td><td>4.50</td><td>3.50</td><td>5.00</td><td>4.40</td><td>3.50</td><td>4.00</td><td>4.00</td><td>3.80</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Examples of responses provided by ChatGPT and reference materials.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Question</th><th>ChatGPT&#x02019;s response</th><th>Reference material</th></tr></thead><tbody><tr><td><bold>What is benign prostatic enlargement?</bold></td><td><p><italic>You know how some parts of our body can change as we get older? Well, for many men, the prostate gland is one of those parts. The prostate is a small gland that sits below the bladder, kind of like a doughnut around the tube we pee through, called the urethra</italic>.</p><p><italic>Benign Prostatic Enlargement, or BPE, is when this gland gets bigger over time. The word &#x02018;benign&#x02019; is essential here &#x02013; it means that this growth isn&#x02019;t cancerous or harmful in that sense. However, as the prostate grows, it can press on that pee tube (the urethra), making it harder for urine to flow through</italic>.</p><p><italic>Here are some things you might notice if your prostate is getting larger:</italic></p><p>&#x02022;&#x02009;<italic>Starting trouble: You might find it a bit hard to start peeing</italic>.</p><p>&#x02022;&#x02009;<italic>Stream changes: Your urine flow might be weaker or stop and start</italic>.</p><p>&#x02022;&#x02009;<italic>Night visits: You might find yourself getting up to pee more often at night</italic>.</p><p>&#x02022;&#x02009;<italic>Rush to go: Sometimes, you may feel a sudden need to pee</italic>.</p><p>&#x02022;&#x02009;<italic>Not quite done: After you pee, it might feel like there&#x02019;s still some left or you might notice a few drops coming out later</italic>.</p><p><italic>The good news is, not everyone with a growing prostate will have these issues. And even if you do, we have various ways to help, from medicines to other treatments.&#x000a0;If you&#x02019;re noticing any of these changes, it&#x02019;s essential to let me know. We can figure out if it&#x02019;s due to your prostate or something else and then decide on the best steps to take</italic>.</p></td><td><p><bold>EAU patient portal:</bold></p><p>Benign prostatic enlargement, or BPE, is the medical term for an enlarged prostate, a condition that is common in men over 50. In BPE, the enlarged prostate can block the flow of urine and cause changes to how your bladder stores urine.</p><p><bold>AUA patient portal:</bold></p><p>Benign Prostatic Hyperplasia (BPH), which is better known as an enlarged prostate, you are not alone. It is a common condition for men as they age. In fact, about half of all men between ages 51 and 60 have BPH. Up to 90 percent of men over age 80 have it.</p></td></tr><tr><td><bold>What is uroflowmetry?</bold></td><td><p><italic>Uroflowmetry is a test we use to see how well you can urinate. Think of it like a speedometer for your urine. It tells us how fast the urine comes out and how much you&#x02019;re able to release</italic>.</p><p><italic>Here&#x02019;s what you can expect:</italic></p><p><italic>Come Ready: We&#x02019;ll ask you to arrive with a full bladder, so you&#x02019;re ready to urinate</italic>.</p><p><italic>Private Setup: You&#x02019;ll be given privacy to urinate into a special toilet or funnel. This device is connected to a computer that does all the measuring</italic>.</p><p><italic>The Graph: The computer will make a graph that shows the flow of your urine from start to finish. We look at things like the speed of your flow, how long it takes, and the total amount</italic>.</p><p><italic>What We Learn: This graph can give us clues about how well your bladder and the tube you urinate through are working. For example, if the flow is slower than usual, it might mean there&#x02019;s some blockage or the muscles are weak</italic>.</p><p><italic>It&#x02019;s a straightforward and painless test. The main goal is to better understand what&#x02019;s happening when you urinate, so we can help with any issues you might be facing</italic>.</p></td><td><p><bold>EAU patient portal:</bold></p><p>Uroflowmetry is a simple test that electronically records the rate of urine flow. It is easily done in privacy at the hospital or clinic. This test helps your healthcare provider check whether the flow of your urine is blocked.</p><p><bold>AUA patient portal:</bold></p><p>Uroflowmetry measures how fast urine flows. This is done to diagnose the problem. It may also be done before surgery.</p></td></tr><tr><td><bold>What are the most common side effects of alpha 1-adrenoceptor antagonists (&#x003b1;1-blockers)?</bold></td><td><p><italic>Alpha 1-Adrenoceptor antagonists, or &#x003b1;1-blockers, are generally well-tolerated, but like all medications, they can have side effects. Some of the most common side effects include:</italic></p><p><italic>Orthostatic Hypotension: This is a sudden drop in blood pressure when a person stands up from a sitting or lying position. It can lead to dizziness or feeling lightheaded, and in some cases, fainting</italic>.</p><p><italic>Dizziness: Apart from orthostatic hypotension, some people might just feel generally dizzy when taking &#x003b1;1-blockers</italic>.</p><p><italic>Fatigue: Some people might feel unusually tired or weak</italic>.</p><p><italic>Headache: Some patients report headaches when starting on these medications</italic>.</p><p><italic>Nasal Congestion: The medications can cause the blood vessels in the nasal passages to expand, leading to stuffiness or congestion</italic>.</p><p><italic>Retrograde Ejaculation: This is when semen goes backward into the bladder during ejaculation instead of out through the penis. It&#x02019;s harmless and doesn&#x02019;t affect orgasm, but it can reduce the volume of semen expelled and might interfere with fertility</italic>.</p><p><italic>Palpitations: Some people might feel like their heart is beating too hard, too fast, skipping a beat, or fluttering</italic>.</p><p><italic>Swelling in the Ankles or Feet: This is due to fluid buildup, also known as peripheral edema</italic>.</p><p><italic>Gastrointestinal Symptoms: Some patients might experience nausea, diarrhea, or abdominal discomfort</italic>.</p><p><italic>It&#x02019;s worth noting that while these side effects are possible, they don&#x02019;t occur in everyone, and some people might experience them more mildly than others. It&#x02019;s always essential for patients to discuss any side effects or concerns with their healthcare provider. Adjustments in dosage or switching to another medication might be necessary in some cases</italic>.</p></td><td><p><bold>EAU patient portal:</bold></p><p>Loss of strength, dizziness, and slightly reduced blood pressure, are possible but temporary. It is possible that these medicines can affect sexual function (sex drive and ejaculation).</p><p><bold>AUA patient portal:</bold></p><p>Side effects may include dizziness, lightheadedness, fatigue and difficulty ejaculating. Men with moderate to severe BPH and men who are bothered by their symptoms are good candidates. Alpha blockers are not a good choice if you plan to have cataract surgery soon.</p></td></tr></tbody></table></table-wrap></p><p id="Par15">The overall performance metrics showed an F1 score of 0.79, a precision score of 0.66, and a recall score of 0.97 (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). The GQS scores from both examiners had a median of 4 (range&#x02009;=&#x02009;1&#x02013;5). When compared, the examiners found no statistically significant difference between the scores they assigned to the overall quality of the responses (<italic>p</italic>&#x02009;=&#x02009;0.72), and they determined a good level of agreement between them, with an ICC of 0.86.<fig id="Fig1"><label>Fig. 1</label><caption><title>ChatGPT&#x02019;s performance metrics.</title><p>F1 score, precision, and recall of ChatGPT&#x02019;s responses on male lower urinary tract symtpoms suggestive of benign prostate enlargement compared to the European Association of Urology and the American Urological Association patient resources.</p></caption><graphic xlink:href="41391_2024_847_Fig1_HTML" id="d33e1019"/></fig></p></sec><sec id="Sec7" sec-type="discussion"><title>Discussion</title><p id="Par16">The integration of AI into medical practice is an evolving and innovative initiative that has gained attention for its potential to enhance information availability, guide decision-making processes, and optimize executive operations within healthcare [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. Notably, ChatGPT has already demonstrated its utility in other medical domains by successfully accomplishing tasks traditionally performed by physicians, such as test-taking, medical record documentation, and scientific literature production [<xref ref-type="bibr" rid="CR15">15</xref>&#x02013;<xref ref-type="bibr" rid="CR18">18</xref>]. Nonetheless, its competency in delivering accurate and patient-friendly information remains controversial. Our study sought to assess the precision, accuracy, and quality of ChatGPT&#x02019;s chatbot-generated responses to common patient queries regarding BPE definitions, symptomatology, diagnostic testing, risks, and treatments.</p><p id="Par17">Our results indicated that ChatGPT was able to respond to all 88 queries. Performance metrics, such as F1 scores, precision, and recall, consistently remained above 0.5 suggesting a consistency level of over 50% between responses and source materials. In terms of content quality, the overall GQS score was 4, with 86% of queries attaining the maximum score of 5. However, it is important to note the word count difference between the chatbot responses and the source materials. We observed that despite the accuracy of the content, the information provided by ChatGPT could be excessive, producing three times more words than the original materials, and not entirely relevant to the patient&#x02019;s needs. For instance, when asked about alpha-blockers in the treatment of BPE, the AI&#x02019;s response included extensive explanations of its usage in hypertension which, while accurate, may not have been directly pertinent to the patient&#x02019;s query regarding BPE treatment.</p><p id="Par18">The accuracy and quality of the model fluctuated greatly depending on the inquired topic. It excelled in areas regarding BPE concept, symptoms, and diagnostics, with F1 scores ranging from 0.86 to 1 and GQS scores above 4.4. However, it did not perform as well when addressing topics related to MIST, with the lowest precision score of 0.67 recorded and GQS scores that are notably lower. Such variation is anticipated since emergent technologies often have limited or outdated data for AI systems like ChatGPT to extract from.</p><p id="Par19">Our findings align closely with what has been documented in existing literature, where significant accuracy heterogeneity has been found not only across researchers but also within subtopics of a given paper, mainly due to prompt composition and ability to validate the pertinence of the answers [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. This is evident in the exploration of ChatGPT&#x02019;s application within various areas of urology, including urologic oncology, sexual health, and pediatric urology [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR21">21</xref>]. Although there is a lack of consensus regarding the overall accuracy of ChatGPT&#x02019;s responses, the majority of studies agree that its performance varies depending on the type of question and what it pertains to [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR22">22</xref>]. It was generally observed that the most accurate responses had to do with quality of life or information-based queries whereas decision-making questions lacked accuracy and consistency [<xref ref-type="bibr" rid="CR23">23</xref>].</p><p id="Par20">In addition to all the potential applications in the medical field, it is crucial to consider the legal implications associated with the deployment of such technologies. There are legal gaps related to liability, accountability, and data protection policies that should be addressed before their integration into our practice [<xref ref-type="bibr" rid="CR24">24</xref>]. Without ensuring accountability for potential medical outcomes and confidentiality breaches, their progress in our field will be in vain. Nevertheless, we recognize the potential of all AI technologies in aiding a wide range of health-related fields, such as radiological and histological analysis, prediction models, and prognostic assistance [<xref ref-type="bibr" rid="CR23">23</xref>].</p><p id="Par21">As an academic exercise, we asked ChatGPT to list its potential contributions to the medical field. Among ChatGPT&#x02019;s responses, the integration of AI into wearable devices for real-time monitoring and the application of image/pattern recognition are particularly promising and achievable. However, it is essential to remember that the speculation on future developments and the realization of actual advancements will depend solely on ongoing research, technological progress, and the ethical considerations surrounding them.</p><p id="Par22">One of the largest limitations of the study was the lack of validated questionnaires to evaluate ChatGPT&#x02019;s response quality, as well as the scarce information regarding suitable metrics to assess AI. We recognize that the 5-point Likert scale we employed for assessment introduces a degree of subjectivity into the ratings, as examiners might differ in valuations of specific criteria. Furthermore, it is important to acknowledge that the version of ChatGPT used had access to information only up until April 2023. Therefore, any further improvements to the AI model or additions to BPE data could not be captured in our current findings. Overall, this study adds to the ongoing discussion on ChatGPT&#x02019;s performance highlighting its accuracy and reliability. Nonetheless, more studies including patient evaluation of the information delivered by ChatGPT compared to reference material and with a broader inclusion of pathologies need to be conducted to truly generalize the usage of this tool across the field of urology.</p></sec><sec id="Sec8" sec-type="conclusion"><title>Conclusion</title><p id="Par23">ChatGPT, as an AI-powered chatbot, demonstrates a potential utility for educating patients about BPE, its prognostic outcomes, and management strategies that aid the decision-making process. Nonetheless, one should be cautious when advising patients to use this as the exclusive source of information, particularly when considering minimally invasive procedures. As novel technologies continue to progress and become more integrated within healthcare settings, we anticipate they will become significant conduits for information acquisition. Additional studies are needed to completely understand the full extent of AI&#x02019;s efficacy in delivering patient education.</p></sec><sec id="Sec9" sec-type="supplementary-material"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41391_2024_847_MOESM1_ESM.docx"><caption><p>Appendix 1</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn><fn><p>These authors contributed equally: Angie K. Puerto Nino, Valentina Garcia Perez.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41391-024-00847-7.</p></sec><notes notes-type="author-contribution"><title>Author contributions</title><p>DSE, SS, AKPN, and VGP were responsible for designing the protocol. AKPN and VGP were responsible for acquisition and analysis of data and drafting the manuscript. DSE was responsible for coordinating the group and supervising the project. SS, CDN, RL, and KAOT were responsible for critical revision of the manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open Access funding provided by University of Helsinki (including Helsinki University Central Hospital).</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>The dataset analyzed during the current study is available in the supplementary material (Appendix&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>).</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par24">The authors declare no competing interests.</p></notes><notes id="FPar2"><title>Ethics approval and consent to participate</title><p id="Par25">No ethics approval was required due to the nature of this study and the absence of patient data utilization or patient participation.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">Johnson D, Goodman R, Patrinely J, Stone C, Zimmerman E, Donald R, et al. Assessing the accuracy and reliability of AI-generated medical responses: an evaluation of the Chat-GPT model. Res Sq [Preprint]. 2023:rs.3.rs-2566942. 10.21203/rs.3.rs-2566942/v1</mixed-citation></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>E</given-names></name><name><surname>Bonfiglioli</surname><given-names>C</given-names></name><name><surname>Brunner</surname><given-names>M</given-names></name><name><surname>Frawley</surname><given-names>J</given-names></name></person-group><article-title>Parents&#x02019; use of social media as a health information source for their children: a scoping review</article-title><source>Acad Pediatr</source><year>2022</year><volume>22</volume><fpage>526</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.acap.2021.12.006</pub-id><pub-id pub-id-type="pmid">34906742</pub-id>
</element-citation><mixed-citation id="mc-CR2" publication-type="journal">Frey E, Bonfiglioli C, Brunner M, Frawley J. Parents&#x02019; use of social media as a health information source for their children: a scoping review. Acad Pediatr. 2022;22:526&#x02013;39.<pub-id pub-id-type="pmid">34906742</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Co&#x0015f;kun B, Gravas S, Sakalis V. Benign prostatic enlargement patient information. Eur Assoc Urol. 2022. <ext-link ext-link-type="uri" xlink:href="https://patients.uroweb.org/other-diseases/benign-prostatic-enlargement/">https://patients.uroweb.org/other-diseases/benign-prostatic-enlargement/</ext-link>.</mixed-citation></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Kevin</surname><given-names>T</given-names></name><name><surname>McVary</surname><given-names>HEF</given-names></name></person-group><article-title>Surgical management of lower urinary tract symptoms attributed to benign prostatic hyperplasia AUA guideline amendment 2019</article-title><source>J Urol</source><year>2019</year><volume>202</volume><fpage>592</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1097/JU.0000000000000319</pub-id><pub-id pub-id-type="pmid">31059668</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal">Kevin T, McVary HEF. Surgical management of lower urinary tract symptoms attributed to benign prostatic hyperplasia AUA guideline amendment 2019. J Urol. 2019;202:592&#x02013;8.<pub-id pub-id-type="pmid">31059668</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname><given-names>CJ</given-names></name><name><surname>Wisener</surname><given-names>J</given-names></name><name><surname>Ward</surname><given-names>B</given-names></name><name><surname>Behbahani</surname><given-names>S</given-names></name><name><surname>Shah</surname><given-names>T</given-names></name><name><surname>Fano</surname><given-names>A</given-names></name><etal/></person-group><article-title>YouTube as a patient education resource for male hypogonadism and testosterone therapy</article-title><source>Sex Med</source><year>2021</year><volume>9</volume><fpage>100324</fpage><lpage>100324</lpage><pub-id pub-id-type="doi">10.1016/j.esxm.2021.100324</pub-id><pub-id pub-id-type="pmid">33752104</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal">Warren CJ, Wisener J, Ward B, Behbahani S, Shah T, Fano A, et al. YouTube as a patient education resource for male hypogonadism and testosterone therapy. Sex Med. 2021;9:100324&#x02013;100324.<pub-id pub-id-type="pmid">33752104</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name><surname>Bai</surname><given-names>G</given-names></name><name><surname>Fu</surname><given-names>K</given-names></name><name><surname>Fu</surname><given-names>W</given-names></name><name><surname>Liu</surname><given-names>G</given-names></name></person-group><article-title>Quality of internet videos related to pediatric urology in mainland China: a cross-sectional study</article-title><source>Front Public Health</source><year>2022</year><volume>10</volume><fpage>924748</fpage><pub-id pub-id-type="doi">10.3389/fpubh.2022.924748</pub-id><pub-id pub-id-type="pmid">35784238</pub-id>
</element-citation><mixed-citation id="mc-CR6" publication-type="journal">Bai G, Fu K, Fu W, Liu G. Quality of internet videos related to pediatric urology in mainland China: a cross-sectional study. Front Public Health. 2022;10:924748.<pub-id pub-id-type="pmid">35784238</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Duarte F. Number of ChatGPT users (Nov 2023). Exploiding topics. <ext-link ext-link-type="uri" xlink:href="https://explodingtopics.com/blog/chatgpt-users">https://explodingtopics.com/blog/chatgpt-users</ext-link>. 2023.</mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Eppler M, Ganjavi C, Ramacciotti LS, Piazza P, Rodler S, Checcucci E, et al. Awareness and use of ChatGPT and large language models: a prospective cross-sectional global survey in urology. Eur Urol. 2023;85:146&#x02013;53.</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Caglar U, Yildiz O, Meric A, Ayranci A, Gelmis M, Sarilar O, et al. Evaluating the performance of ChatGPT in answering questions related to pediatric urology. J Pediatr Urol. 2024;20:26.e1&#x02013;26.e5.</mixed-citation></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name><surname>Gabriel</surname><given-names>J</given-names></name><name><surname>Shafik</surname><given-names>L</given-names></name><name><surname>Alanbuki</surname><given-names>A</given-names></name><name><surname>Larner</surname><given-names>T</given-names></name></person-group><article-title>The utility of the ChatGPT artificial intelligence tool for patient education and enquiry in robotic radical prostatectomy</article-title><source>Int Urol Nephrol</source><year>2023</year><volume>55</volume><fpage>2717</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1007/s11255-023-03729-4</pub-id><pub-id pub-id-type="pmid">37528247</pub-id>
</element-citation><mixed-citation id="mc-CR10" publication-type="journal">Gabriel J, Shafik L, Alanbuki A, Larner T. The utility of the ChatGPT artificial intelligence tool for patient education and enquiry in robotic radical prostatectomy. Int Urol Nephrol. 2023;55:2717&#x02013;32.<pub-id pub-id-type="pmid">37528247</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Coskun</surname><given-names>B</given-names></name><name><surname>Ocakoglu</surname><given-names>G</given-names></name><name><surname>Yetemen</surname><given-names>M</given-names></name><name><surname>Kaygisiz</surname><given-names>O</given-names></name></person-group><article-title>Can ChatGPT, an artificial intelligence language model, provide accurate and high-quality patient information on prostate cancer?</article-title><source>Urology</source><year>2023</year><volume>180</volume><fpage>35</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/j.urology.2023.05.040</pub-id><pub-id pub-id-type="pmid">37406864</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal">Coskun B, Ocakoglu G, Yetemen M, Kaygisiz O. Can ChatGPT, an artificial intelligence language model, provide accurate and high-quality patient information on prostate cancer? Urology. 2023;180:35&#x02013;58.<pub-id pub-id-type="pmid">37406864</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Szczesniewski</surname><given-names>JJ</given-names></name><name><surname>Tellez Fouz</surname><given-names>C</given-names></name><name><surname>Ramos Alba</surname><given-names>A</given-names></name><name><surname>Diaz Goizueta</surname><given-names>FJ</given-names></name><name><surname>Garc&#x000ed;a Tello</surname><given-names>A</given-names></name><name><surname>Llanes Gonz&#x000e1;lez</surname><given-names>L</given-names></name></person-group><article-title>ChatGPT and most frequent urological diseases: analysing the quality of information and potential risks for patients</article-title><source>World J Urol</source><year>2023</year><volume>41</volume><fpage>3149</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1007/s00345-023-04563-0</pub-id><pub-id pub-id-type="pmid">37632558</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal">Szczesniewski JJ, Tellez Fouz C, Ramos Alba A, Diaz Goizueta FJ, Garc&#x000ed;a Tello A, Llanes Gonz&#x000e1;lez L. ChatGPT and most frequent urological diseases: analysing the quality of information and potential risks for patients. World J Urol. 2023;41:3149&#x02013;53.<pub-id pub-id-type="pmid">37632558</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Whiles</surname><given-names>BB</given-names></name><name><surname>Bird</surname><given-names>VG</given-names></name><name><surname>Canales</surname><given-names>BK</given-names></name><name><surname>DiBianco</surname><given-names>JM</given-names></name><name><surname>Terry</surname><given-names>RS</given-names></name></person-group><article-title>Caution! AI bot has entered the patient chat: ChatGPT has limitations in providing accurate urologic healthcare advice</article-title><source>Urology</source><year>2023</year><volume>180</volume><fpage>278</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/j.urology.2023.07.010</pub-id><pub-id pub-id-type="pmid">37467806</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal">Whiles BB, Bird VG, Canales BK, DiBianco JM, Terry RS. Caution! AI bot has entered the patient chat: ChatGPT has limitations in providing accurate urologic healthcare advice. Urology 2023;180:278&#x02013;84.<pub-id pub-id-type="pmid">37467806</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="book"><person-group person-group-type="author"><collab>SAS Institute Inc.</collab></person-group><source>SAS&#x000ae; 9.4 language reference: concepts</source><year>2016</year><edition>6th ed</edition><publisher-loc>Cary, NC</publisher-loc><publisher-name>SAS Institute Inc</publisher-name></element-citation><mixed-citation id="mc-CR14" publication-type="book">SAS Institute Inc. SAS&#x000ae; 9.4 language reference: concepts. 6th ed. Cary, NC: SAS Institute Inc; 2016.</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name></person-group><article-title>Utility of ChatGPT in clinical practice</article-title><source>J Med Internet Res</source><year>2023</year><volume>25</volume><fpage>e48568</fpage><pub-id pub-id-type="doi">10.2196/48568</pub-id><pub-id pub-id-type="pmid">37379067</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal">Liu J, Wang C, Liu S. Utility of ChatGPT in clinical practice. J Med Internet Res. 2023;25:e48568.<pub-id pub-id-type="pmid">37379067</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Abramson</surname><given-names>M</given-names></name><name><surname>Feiertag</surname><given-names>N</given-names></name><name><surname>Javidi</surname><given-names>D</given-names></name><name><surname>Babar</surname><given-names>M</given-names></name><name><surname>Loeb</surname><given-names>S</given-names></name><name><surname>Watts</surname><given-names>K</given-names></name></person-group><article-title>Accuracy of prostate cancer screening recommendations for high&#x02010;risk populations on YouTube and TikTok</article-title><source>BJUI Compass</source><year>2023</year><volume>4</volume><fpage>206</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1002/bco2.200</pub-id><pub-id pub-id-type="pmid">36816146</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal">Abramson M, Feiertag N, Javidi D, Babar M, Loeb S, Watts K. Accuracy of prostate cancer screening recommendations for high&#x02010;risk populations on YouTube and TikTok. BJUI Compass. 2023;4:206&#x02013;13.<pub-id pub-id-type="pmid">36816146</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Jeblick K, Schachtner B, Dexl J, Mittermeier A, St&#x000fc;ber AT, Topalis J, et al. ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports. Eur Radiol. 2023;34:2817&#x02013;25.</mixed-citation></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name><surname>Brin</surname><given-names>D</given-names></name><name><surname>Sorin</surname><given-names>V</given-names></name><name><surname>Vaid</surname><given-names>A</given-names></name><name><surname>Soroush</surname><given-names>A</given-names></name><name><surname>Glicksberg</surname><given-names>BS</given-names></name><name><surname>Charney</surname><given-names>AW</given-names></name><etal/></person-group><article-title>Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments</article-title><source>Sci Rep</source><year>2023</year><volume>13</volume><fpage>16492</fpage><pub-id pub-id-type="doi">10.1038/s41598-023-43436-9</pub-id><pub-id pub-id-type="pmid">37779171</pub-id>
</element-citation><mixed-citation id="mc-CR18" publication-type="journal">Brin D, Sorin V, Vaid A, Soroush A, Glicksberg BS, Charney AW, et al. Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments. Sci Rep. 2023;13:16492.<pub-id pub-id-type="pmid">37779171</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>RS</given-names></name><name><surname>Patrinely</surname><given-names>JR</given-names></name><name><surname>Stone</surname><given-names>CA</given-names></name><name><surname>Zimmerman</surname><given-names>E</given-names></name><name><surname>Donald</surname><given-names>RR</given-names></name><name><surname>Chang</surname><given-names>SS</given-names></name><etal/></person-group><article-title>Accuracy and reliability of Chatbot responses to physician questions</article-title><source>JAMA Netw Open</source><year>2023</year><volume>6</volume><fpage>e2336483</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2023.36483</pub-id><pub-id pub-id-type="pmid">37782499</pub-id>
</element-citation><mixed-citation id="mc-CR19" publication-type="journal">Goodman RS, Patrinely JR, Stone CA, Zimmerman E, Donald RR, Chang SS, et al. Accuracy and reliability of Chatbot responses to physician questions. JAMA Netw Open. 2023;6:e2336483.<pub-id pub-id-type="pmid">37782499</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Lee P, Bubeck S, Petro J. Benefits, limits, and risks of GPT-4 as an AI Chatbot for medicine. N Engl J Med. 2023;388:1233&#x02013;9.</mixed-citation></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name><surname>Cocci</surname><given-names>A</given-names></name><name><surname>Pezzoli</surname><given-names>M</given-names></name><name><surname>Lo Re</surname><given-names>M</given-names></name><name><surname>Russo</surname><given-names>GI</given-names></name><name><surname>Asmundo</surname><given-names>MG</given-names></name><name><surname>Fode</surname><given-names>M</given-names></name><etal/></person-group><article-title>Quality of information and appropriateness of ChatGPT outputs for urology patients</article-title><source>Prostate Cancer Prostatic Dis</source><year>2024</year><volume>27</volume><fpage>103</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/s41391-023-00705-y</pub-id><pub-id pub-id-type="pmid">37516804</pub-id>
</element-citation><mixed-citation id="mc-CR21" publication-type="journal">Cocci A, Pezzoli M, Lo Re M, Russo GI, Asmundo MG, Fode M, et al. Quality of information and appropriateness of ChatGPT outputs for urology patients. Prostate Cancer Prostatic Dis. 2024;27:103&#x02013;8.<pub-id pub-id-type="pmid">37516804</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Daungsupawong</surname><given-names>H</given-names></name><name><surname>Wiwanitkit</surname><given-names>V</given-names></name></person-group><article-title>Social determinants of health into evaluations of quality and appropriateness of AI assistant ChatGPT</article-title><source>Prostate Cancer Prostatic Dis</source><year>2024</year><volume>27</volume><fpage>158</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1038/s41391-023-00735-6</pub-id><pub-id pub-id-type="pmid">37803243</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal">Daungsupawong H, Wiwanitkit V. Social determinants of health into evaluations of quality and appropriateness of AI assistant ChatGPT. Prostate Cancer Prostatic Dis. 2024;27:158&#x02013;158.<pub-id pub-id-type="pmid">37803243</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name><surname>Lombardo</surname><given-names>R</given-names></name><name><surname>Cicione</surname><given-names>A</given-names></name><name><surname>Santoro</surname><given-names>G</given-names></name><name><surname>De Nunzio</surname><given-names>C</given-names></name></person-group><article-title>ChatGPT in prostate cancer: myth or reality?</article-title><source>Prostate Cancer Prostatic Dis</source><year>2024</year><volume>27</volume><fpage>9</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1038/s41391-023-00750-7</pub-id><pub-id pub-id-type="pmid">37950022</pub-id>
</element-citation><mixed-citation id="mc-CR23" publication-type="journal">Lombardo R, Cicione A, Santoro G, De Nunzio C. ChatGPT in prostate cancer: myth or reality? Prostate Cancer Prostatic Dis. 2024;27:9&#x02013;10.<pub-id pub-id-type="pmid">37950022</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Adhikari</surname><given-names>K</given-names></name><name><surname>Naik</surname><given-names>N</given-names></name><name><surname>Hameed</surname><given-names>BZ</given-names></name><name><surname>Raghunath</surname><given-names>SK</given-names></name><name><surname>Somani</surname><given-names>BK</given-names></name></person-group><article-title>Exploring the ethical, legal, and social implications of ChatGPT in urology</article-title><source>Curr Urol Rep</source><year>2024</year><volume>25</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1007/s11934-023-01185-2</pub-id><pub-id pub-id-type="pmid">37735339</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal">Adhikari K, Naik N, Hameed BZ, Raghunath SK, Somani BK. Exploring the ethical, legal, and social implications of ChatGPT in urology. Curr Urol Rep. 2024;25:1&#x02013;8.<pub-id pub-id-type="pmid">37735339</pub-id>
</mixed-citation></citation-alternatives></ref></ref-list></back></article>