<!--

File produced by pipelineRunner package (for JATS 2 SCJATS with pipeline SCJATS)
At: 2025-05-21T08:56:32.547Z

Version        : 1.16.1
Last update    : 2024-08-27
Modified by    : dunnm

-->
<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="review-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Psychoradiology</journal-id><journal-id journal-id-type="iso-abbrev">Psychoradiology</journal-id><journal-id journal-id-type="publisher-id">psyrad</journal-id><journal-title-group><journal-title>Psychoradiology</journal-title></journal-title-group><issn pub-type="epub">2634-4416</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40401160</article-id><article-id pub-id-type="pmc">PMC12093097</article-id><article-id pub-id-type="doi">10.1093/psyrad/kkaf007</article-id><article-id pub-id-type="publisher-id">kkaf007</article-id><article-categories><subj-group subj-group-type="heading"><subject>Review</subject></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/MED00385</subject><subject>AcademicSubjects/MED00800</subject><subject>AcademicSubjects/MED00870</subject><subject>AcademicSubjects/SCI01870</subject><subject>AcademicSubjects/SCI02100</subject></subj-group></article-categories><title-group><article-title>Advances in functional magnetic resonance imaging-based brain function mapping: a deep learning perspective</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Zhao</surname><given-names>Lin</given-names></name><!--<string-name>(&#x08d75;&#x09e9f;)</string-name>--><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft">Writing - original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &#x00026; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing">Writing - review &#x00026; editing</role><!--lin.zhao.research@gmail.com--><aff>
<institution>School of Computing, University of Georgia</institution>, <addr-line>Athens 30602 GA</addr-line>, <country country="US">USA</country></aff><xref rid="cor1" ref-type="corresp"/></contrib></contrib-group><author-notes><corresp id="cor1">Correspondence: Lin Zhao, <email>lin.zhao.research@gmail.com</email></corresp></author-notes><pub-date pub-type="collection"><year>2025</year></pub-date><pub-date pub-type="epub" iso-8601-date="2025-04-29"><day>29</day><month>4</month><year>2025</year></pub-date><pub-date pub-type="pmc-release"><day>29</day><month>4</month><year>2025</year></pub-date><volume>5</volume><elocation-id>kkaf007</elocation-id><history><date date-type="received"><day>26</day><month>10</month><year>2024</year></date><date date-type="rev-recd"><day>21</day><month>3</month><year>2025</year></date><date date-type="accepted"><day>24</day><month>4</month><year>2025</year></date><date date-type="corrected-typeset"><day>21</day><month>5</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2025. Published by Oxford University Press on behalf of West China School of Medicine/West China Hospital (WCSM/WCH) of Sichuan University.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="kkaf007.pdf"/><abstract><title>Abstract</title><p>Functional magnetic resonance imaging (fMRI) provides a powerful tool for studying brain function by capturing neural activity in a non-invasive manner. Mapping brain function from fMRI data enables researchers to investigate the spatial and temporal dynamics of neural processes, providing insights into how the brain responds to various tasks and stimuli. In this review, we explore the evolution of deep learning-based methods for brain function mapping using fMRI. We begin by discussing various network architectures such as convolutional neural networks, recurrent neural networks, and transformers. We further examine supervised, unsupervised, and self-supervised learning paradigms for fMRI-based brain function mapping, highlighting the strengths and limitations of each approach. Additionally, we discuss emerging trends such as fMRI embedding, brain foundation models, and brain-inspired artificial intelligence, emphasizing their potential to revolutionize brain function mapping. Finally, we delve into the real-world applications and prospective impact of these advancements, particularly in the diagnosis of neural disorders, neuroscientific research, and brain&#x02013;computer interfaces for decoding brain activity. This review aims to provide a comprehensive overview of current techniques and future directions in the field of deep learning and fMRI-based brain function mapping.</p></abstract><kwd-group><kwd>fMRI</kwd><kwd>brain function mapping</kwd><kwd>deep learning</kwd></kwd-group><counts><page-count count="12"/></counts></article-meta></front><body><sec sec-type="intro" id="sec1"><title>Introduction</title><p>Exploring and understanding the mechanisms of human brain function and its organization have been intense interests in the field of neuroscience for centuries (Brodmann, <xref rid="bib8" ref-type="bibr">1909</xref>; Belliveau <italic toggle="yes">et al</italic>., <xref rid="bib5" ref-type="bibr">1991</xref>; Raichle <italic toggle="yes">et al</italic>., <xref rid="bib86" ref-type="bibr">2001</xref>; Biswal <italic toggle="yes">et al</italic>., <xref rid="bib7" ref-type="bibr">2010</xref>). Since the early 1990s, functional magnetic resonance imaging (fMRI) based on blood-oxygen-level-dependent (BOLD) contrast has emerged as a dominant tool for imaging-based brain function research (O'Craven <italic toggle="yes">et al</italic>., <xref rid="bib73" ref-type="bibr">1999</xref>; Logothetis <italic toggle="yes">et al</italic>., <xref rid="bib63" ref-type="bibr">2001</xref>; Bassett and Bullmore, <xref rid="bib4" ref-type="bibr">2006</xref>; Logothetis, <xref rid="bib64" ref-type="bibr">2008</xref>). By imaging changes in blood flow and oxygenation levels (hemodynamic response), BOLD fMRI establishes an indirect mapping of neural activity and offers an <italic toggle="yes">in vivo</italic>, non-invasive tool to study the complex and dynamic processes of the brain (Heeger and Ress, <xref rid="bib35" ref-type="bibr">2002</xref>; Logothetis <italic toggle="yes">et al</italic>., <xref rid="bib63" ref-type="bibr">2001</xref>). Uncovering meaningful functional patterns and accurately mapping brain activity from the rich information contained in BOLD fMRI signals has since become a major focus for researchers in this field.</p><p>After decades of research, it has been revealed that human brain function is organized through the interaction of multiple concurrent neural networks, commonly referred to as functional brain networks (FBNs) (Von Der Malsburg, <xref rid="bib97" ref-type="bibr">1994</xref>; Cordes <italic toggle="yes">et al</italic>., <xref rid="bib14" ref-type="bibr">2000</xref>; Van Den Heuvel and Pol, <xref rid="bib95" ref-type="bibr">2010</xref>; Power <italic toggle="yes">et al</italic>., <xref rid="bib79" ref-type="bibr">2011</xref>). These FBNs distributed across specific neuroanatomical regions have become an established representation of brain function organization. Various methods have been developed to identify and reconstruct FBNs from noisy fMRI data, including the general linear model (GLM) for task-based fMRI (tfMRI) (Friston <italic toggle="yes">et al</italic>., <xref rid="bib29" ref-type="bibr">1994</xref>; Worsley, <xref rid="bib102" ref-type="bibr">1997</xref>), independent component analysis (ICA) for resting-state fMRI (rsfMRI) (Calhoun and Adali, <xref rid="bib9" ref-type="bibr">2006</xref>; Calhoun <italic toggle="yes">et al</italic>., <xref rid="bib10" ref-type="bibr">2009</xref>), and sparse dictionary learning (SDL) for both tfMRI and rsfMRI (Lv <italic toggle="yes">et al</italic>., <xref rid="bib65" ref-type="bibr">2014</xref>, <xref rid="bib66" ref-type="bibr">2015</xref>). The number of FBNs reconstructed from fMRI data is limited by the linear components in GLM and brain sources in ICA. In contrast, SDL, through an over-complete dictionary, can decompose fMRI data into hundreds or thousands of concurrent FBNs, offering a more detailed mapping of brain function.</p><p>Compared with traditional methods, deep learning has proven to be a powerful representation technique across various domains (LeCun <italic toggle="yes">et al</italic>., <xref rid="bib48" ref-type="bibr">2015</xref>; Goodfellow <italic toggle="yes">et al</italic>., <xref rid="bib32" ref-type="bibr">2016</xref>; He <italic toggle="yes">et al</italic>., <xref rid="bib34" ref-type="bibr">2016</xref>; Vaswani <italic toggle="yes">et al</italic>., <xref rid="bib96" ref-type="bibr">2017</xref>). Deep learning models such as convolutional neural networks (CNNs) (LeCun <italic toggle="yes">et al</italic>., <xref rid="bib47" ref-type="bibr">1995</xref>) and recurrent neural networks (RNNs) (Hochreiter and Schmidhuber, <xref rid="bib38" ref-type="bibr">1997</xref>) have been widely used to capture the complex spatiotemporal dynamics in fMRI data, offering robust representations of brain function. For example, CNNs have effectively identified individual FBNs from fMRI data using supervised learning (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib132" ref-type="bibr">2017b</xref>, <xref rid="bib135" ref-type="bibr">2018c</xref>), while convolutional autoencoders excel at learning temporal patterns and spatial maps of brain activity in an unsupervised manner (Huang <italic toggle="yes">et al</italic>., <xref rid="bib43" ref-type="bibr">2017</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib123" ref-type="bibr">2021</xref>). Recurrent units, such as long short-term memory (LSTM) networks (Hochreiter and Schmidhuber, <xref rid="bib38" ref-type="bibr">1997</xref>), have been extensively applied to model the temporal correlations in fMRI time series (Li <italic toggle="yes">et al</italic>., <xref rid="bib50" ref-type="bibr">2019</xref>, <xref rid="bib52" ref-type="bibr">2020</xref>). In addition to these established models, neural architecture search (NAS) methods (Zoph and Le, <xref rid="bib138" ref-type="bibr">2016</xref>; Liu <italic toggle="yes">et al</italic>., <xref rid="bib56" ref-type="bibr">2018</xref>) have been employed to autonomously discover neural network architectures optimized for aligning with the functional architecture of the human brain, offering new pathways for understanding and modeling brain function (Zhang <italic toggle="yes">et al</italic>., <xref rid="bib121" ref-type="bibr">2019b</xref>; Li <italic toggle="yes">et al</italic>., <xref rid="bib51" ref-type="bibr">2021a</xref>, <xref rid="bib53" ref-type="bibr">b</xref>).</p><p>Recently, transformers and the self-attention mechanism have revolutionized artificial intelligence (AI) (Vaswani <italic toggle="yes">et al</italic>., <xref rid="bib96" ref-type="bibr">2017</xref>), driving the development of large-scale language/visual foundation models such as GPTs (Radford <italic toggle="yes">et al</italic>., <xref rid="bib85" ref-type="bibr">2018</xref>; Achiam <italic toggle="yes">et al</italic>., <xref rid="bib1" ref-type="bibr">2023</xref>). These advancements have also extended to brain functional mapping, where the self-attention mechanism, with its ability to capture long-range relationships across spatial and temporal dimensions, proves particularly effective for modeling complex neural dynamics and interactions (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib127" ref-type="bibr">2022</xref>, <xref rid="bib128" ref-type="bibr">2023c</xref>). The brain foundation models are emerging as powerful tools by applying the same principles to large-scale neuroimaging datasets, enabling generalizable representations of brain activity that can be fine-tuned for various cognitive tasks (Thomas <italic toggle="yes">et al</italic>., <xref rid="bib94" ref-type="bibr">2022</xref>; Ortega Caro <italic toggle="yes">et al</italic>., <xref rid="bib75" ref-type="bibr">2024</xref>; Yang <italic toggle="yes">et al</italic>., <xref rid="bib108" ref-type="bibr">2024</xref>). The representation of brain function from fMRI is not confined to FBNs. Traditional FBN representations, which can be regarded as one-hot embeddings, may lack the nuance required to capture the full complexity of brain function. By contrast, embedding brain activity as dense vectors offers a more refined, richer and precise modeling representation of neural dynamics (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib124" ref-type="bibr">2023a</xref>, <xref rid="bib128" ref-type="bibr">c</xref>). This approach further allows for aligning the semantic representations of the human brain with the semantic representations of AI models, providing deeper insights about the mechanisms underlying intelligence (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib124" ref-type="bibr">2023a</xref>; Liu <italic toggle="yes">et al</italic>., <xref rid="bib59" ref-type="bibr">2023b</xref>; Zhou <italic toggle="yes">et al</italic>., <xref rid="bib136" ref-type="bibr">2023</xref>).</p><p>In this review, we focus on the representation and mapping methods of brain function using deep learning techniques and fMRI data, aiming to identify key trends, challenges, and emerging opportunities in this rapidly evolving field. Rather than merely summarizing existing methods, we seek to highlight gaps in the current literature and propose new research directions to advance the field. This review is organized as follows: Section 2 elaborates on the various network architectures employed in the representation of brain function, including CNNs, RNNs, transformers, and methods involving NAS. Section 3 details the training schemes utilized in these studies, differentiating between supervised, unsupervised, and self-supervised training approaches. Section 4 summarizes current research trends, challenges, and future directions in the context of large foundation models. We conclude the review by discussing the current and potential impacts of these advanced techniques on neuroscience and clinical applications.</p></sec><sec id="sec2"><title>Network architectures for brain function representation</title><p>In this section, we will delve into the various deep learning network architectures that have been employed to represent and map brain function using fMRI data. Each architecture brings unique strengths, enabling the capture of different aspects of brain activity. We will review the fundamental concepts, architectural designs, and specific applications of several prominent network architectures, such as CNNs, RNNs, transformers, deep belief networks (DBNs), graph neural networks (GNNs), and NAS techniques.</p><sec id="sec2-1"><title>Convolutional neural networks</title><p>CNNs have revolutionized the field of computer vision by enabling automatic feature extraction and hierarchical pattern recognition, significantly improving performance in tasks such as image classification, object detection, and segmentation (LeCun <italic toggle="yes">et al</italic>., <xref rid="bib47" ref-type="bibr">1995</xref>; He <italic toggle="yes">et al</italic>., <xref rid="bib34" ref-type="bibr">2016</xref>). With inductive biases, CNNs can effectively capture the spatial structure and hierarchies in 1D time series, 3D/4D image data. fMRI data are inherently 4D, consisting of three spatial dimensions and one temporal dimension. Each fMRI scan generates a series of volumes over time, capturing changes in blood flow and oxygenation levels. The time series extracted from each voxel is 1D, while considering the spatial volume at each time point provides a 3D representation. Treating the entire fMRI scan as a whole maintains its original 4D form. This multi-dimensional nature of fMRI data allows for the application of 1D, 3D, and 4D CNNs.</p><sec id="sec2-1-1"><title>1D convolutional neural networks</title><p>1D CNNs are specifically designed to handle sequential data. In the context of fMRI, each voxel's time series data can be treated as a 1D sequence, where the temporal dimension is the primary focus. By applying convolutional filters along the temporal axis, 1D CNNs are able to learn temporal dependencies and patterns within the time series data.</p><p>When applied to fMRI data, the architecture of 1D CNNs typically includes multiple convolutional layers, each followed by activation functions and pooling layers (Huang <italic toggle="yes">et al</italic>., <xref rid="bib43" ref-type="bibr">2017</xref>; Zhang <italic toggle="yes">et al</italic>., <xref rid="bib120" ref-type="bibr">2018b</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib123" ref-type="bibr">2021</xref>, <xref rid="bib126" ref-type="bibr">2024</xref>). This hierarchical structure enables the network to capture both low-level, high-frequency temporal features and high-level, low-frequency temporal features. However, high-level features are often multi-dimensional and abstract, making them difficult to interpret. To address this, specific designs such as Feature Interpreter (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib123" ref-type="bibr">2021</xref>, <xref rid="bib126" ref-type="bibr">2024</xref>) have been developed to elucidate the hierarchical features of fMRI time series.</p><p>Alternatively, some approaches employ only a single convolutional layer, allowing the extracted features to directly correlate with the temporal characteristics of the fMRI time series (Liu <italic toggle="yes">et al</italic>., <xref rid="bib57" ref-type="bibr">2019</xref>; Wang <italic toggle="yes">et al</italic>., <xref rid="bib101" ref-type="bibr">2023</xref>). For instance, Liu <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib57" ref-type="bibr">2019</xref>) utilized a one-layer 1D CNN model to classify the fMRI time series from gyri and sulci of ceberal cortex (Fig.&#x000a0;<xref rid="fig1" ref-type="fig">1</xref>). By examining the weights of the fully connected layer that generates the predictions, they identified filters corresponding to gyri and sulci and analyzed them to explore the unique characteristics of these signals (Liu <italic toggle="yes">et al</italic>., <xref rid="bib57" ref-type="bibr">2019</xref>).</p><fig position="float" id="fig1"><label>Figure 1:</label><caption><p>The architecture of the 1D CNN model proposed in Liu <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib57" ref-type="bibr">2019</xref>). This model is composed of a sequence of layers, including a convolutional layer, a max-pooling layer, a global average pooling (GAP) layer, a dropout layer, and a softmax layer. Each row in the convolutional layer corresponds to a different convolutional channel, and there are correspondences between the filters and weights in the model.</p></caption><graphic xlink:href="kkaf007fig1" position="float"/></fig><p>Moreover, 1D CNNs are less prone to overfitting due to the extensive amount of time series data in each 4D volume. In contrast, 3D and 4D CNNs often face challenges that the number of parameters is greatly larger than the number of data samples.</p></sec><sec id="sec2-1-2"><title>3D convolutional neural networks</title><p>3D CNNs extend the convolutional operations to three dimensions, making them particularly suitable for analyzing volumetric data such as 3D volumes in an fMRI scan. 3D CNNs have been widely utilized in fMRI data analysis and FBN recognition. For instance, methods such as ICA and SDL can effectively reconstruct dozens or hundreds of FBNs from whole-brain fMRI signals, despite the lack of direct correspondences for these networks across different subjects. 3D CNNs can classify and recognize these derived FBNs (Ren <italic toggle="yes">et al</italic>., <xref rid="bib87" ref-type="bibr">2017</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib133" ref-type="bibr">2018a</xref>) (Fig.&#x000a0;<xref rid="fig2" ref-type="fig">2</xref>), and have also been applied to differentiate autism spectrum disorder (ASD) by analyzing the 3D overlap patterns of FBNs (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib134" ref-type="bibr">2018b</xref>). These networks typically consist of 3D convolutional layers, max-pooling layers, and fully connected layers for classification tasks. Additionally, 3D CNNs can represent the 3D volume of each time point as a 1D vector for further analysis (Dong <italic toggle="yes">et al</italic>., <xref rid="bib23" ref-type="bibr">2020b</xref>). In Dong <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib23" ref-type="bibr">2020b</xref>), a deeper architecture with several residual blocks&#x02014;each containing two 3D convolutional layers and up/down pooling layers&#x02014;was employed, achieving a depth of 34 convolutional layers, showing the improved performance compared with shallow models.</p><fig position="float" id="fig2"><label>Figure 2:</label><caption><p>The architecture of the 3D CNN model proposed in Zhao <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib133" ref-type="bibr">2018a</xref>).</p></caption><graphic xlink:href="kkaf007fig2" position="float"/></fig></sec><sec id="sec2-1-3"><title>4D convolutional neural networks</title><p>4D CNNs integrate both spatial and temporal information, making them powerful for analyzing dynamic volumetric data such as fMRI data. Figure&#x000a0;<xref rid="fig3" ref-type="fig">3</xref> illustrates the 4D convolution and deconvolution operations, which extend traditional 3D convolutions by incorporating a temporal dimension. The 4D convolution processes 4D fMRI data across spatial and temporal axes, enabling the extraction of spatiotemporal features, while the 4D deconvolution reconstructs feature maps to restore original spatial&#x02013;temporal resolutions. 4D CNNs have been used to characterize FBNs (Jiang <italic toggle="yes">et al</italic>., <xref rid="bib44" ref-type="bibr">2023</xref>) and identify abnormal patterns in ASD (Liu <italic toggle="yes">et al</italic>., <xref rid="bib58" ref-type="bibr">2023a</xref>). Additionally, 4D CNNs have been employed to model both the spatial and temporal patterns of targeted FBNs (Yan <italic toggle="yes">et al</italic>., <xref rid="bib107" ref-type="bibr">2021b</xref>) and to classify attention deficit/hyperactivity disorder (ADHD) based on fMRI data (Mao <italic toggle="yes">et al</italic>., <xref rid="bib71" ref-type="bibr">2019</xref>). Besides directly applying 4D convolutions, some studies process 4D fMRI data by using 3D CNNs for spatial information and 1D CNNs for temporal information. For example, a spatio-temporal CNN (ST-CNN) was proposed to identify the default mode network (DMN) from fMRI data (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib135" ref-type="bibr">2018c</xref>).</p><fig position="float" id="fig3"><label>Figure 3:</label><caption><p>The illustration of 4D convolution/deconvolution operation when applied to fMRI data (Jiang <italic toggle="yes">et al</italic>., <xref rid="bib44" ref-type="bibr">2023</xref>).</p></caption><graphic xlink:href="kkaf007fig3" position="float"/></fig></sec></sec><sec id="sec2-2"><title>Recurrent neural networks</title><p>RNNs are highly effective at modeling sequential data due to their capability to retain information from previous inputs via internal states. This makes them particularly well-suited for modeling the temporal dependencies in fMRI data. In the field of brain functional mapping, RNNs have been extensively applied to identify evolving patterns of brain activity over time (Wang <italic toggle="yes">et al</italic>., <xref rid="bib98" ref-type="bibr">2018</xref>) and to decompose FBNs (Cui <italic toggle="yes">et al</italic>., <xref rid="bib15" ref-type="bibr">2019</xref>; Li <italic toggle="yes">et al</italic>., <xref rid="bib50" ref-type="bibr">2019</xref>, <xref rid="bib51" ref-type="bibr">2021a</xref>, <xref rid="bib53" ref-type="bibr">b</xref>; Qiang <italic toggle="yes">et al</italic>., <xref rid="bib80" ref-type="bibr">2021</xref>). Typically, each 3D fMRI volume at a given time point is embedded as a vector using a fully connected layer, and recurrent models, such as LSTM (Hochreiter and Schmidhuber, <xref rid="bib38" ref-type="bibr">1997</xref>), are employed to model the temporal dependencies of these vectors (Fig.&#x000a0;<xref rid="fig4" ref-type="fig">4</xref>). LSTM networks are particularly effective in handling long-range dependencies and mitigating the vanishing gradient problem commonly encountered in traditional RNNs.</p><fig position="float" id="fig4"><label>Figure 4:</label><caption><p>The architecture of the DSRNN model proposed in Wang <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib98" ref-type="bibr">2018</xref>). It consists of a fully connected layer to extract activated brain regions, followed by two recurrent layers to capture temporal dynamics. A softmax classifier is finally applied for brain state recognition.</p></caption><graphic xlink:href="kkaf007fig4" position="float"/></fig></sec><sec id="sec2-3"><title>Transformer and self-attention</title><p>Transformer was designed to handle sequential data by utilizing self-attention mechanisms, which allow them to weigh the importance of different parts of the input sequence independently. Unlike traditional recurrent models, transformers can process entire sequences in parallel, making them highly efficient and effective for tasks involving long-range dependencies. In the context of fMRI data modeling, transformers have emerged as powerful tools for capturing complex patterns of brain activity (Dong <italic toggle="yes">et al</italic>., <xref rid="bib24" ref-type="bibr">2020c</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib127" ref-type="bibr">2022</xref>; Mao <italic toggle="yes">et al</italic>., <xref rid="bib70" ref-type="bibr">2024</xref>). In Dong <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib24" ref-type="bibr">2020c</xref>), a self-attention mechanism was utilized to model the temporal relationship of each time point's representation. In Zhao <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib124" ref-type="bibr">2023a</xref>), the multi-head self-attention (MSA) module in the Transformer model demonstrated better representation ability than LSTM in modeling fMRI data. Transformer has also been employed to encode the brain function in a latent space as dense embedding vectors (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib127" ref-type="bibr">2022</xref>, <xref rid="bib128" ref-type="bibr">2023c</xref>). In Kim <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib45" ref-type="bibr">2023</xref>), a SwiFT (Swin 4D fMRI Transformer) model was proposed to learn brain dynamics directly from 4D fMRI volumes to predict sex, age, and cognitive intelligence.</p></sec><sec id="sec2-4"><title>Deep belief networks</title><p>DBNs are built using layers of restricted Boltzmann machines (RBMs) (Hinton and Salakhutdinov, <xref rid="bib36" ref-type="bibr">2006</xref>), which are shallow, two-layer neural nets. Each RBM in a DBN learns to model the probability distribution of its inputs, and the layers are stacked such that the outputs of one RBM serve as the inputs to the next (Hinton, <xref rid="bib37" ref-type="bibr">2009</xref>). This hierarchical structure allows DBNs to capture complex, high-level features of the input data by learning progressively abstract representations. In brain function representation, both RBMs and DBNs have been widely used (Huang <italic toggle="yes">et al</italic>., <xref rid="bib42" ref-type="bibr">2016</xref>; Li <italic toggle="yes">et al</italic>., <xref rid="bib55" ref-type="bibr">2018b</xref>; Hu <italic toggle="yes">et al</italic>., <xref rid="bib39" ref-type="bibr">2018</xref>, <xref rid="bib49" ref-type="bibr">2018a</xref>; Dong <italic toggle="yes">et al</italic>., <xref rid="bib21" ref-type="bibr">2019</xref>; Zhang <italic toggle="yes">et al</italic>., <xref rid="bib119" ref-type="bibr">2019a</xref>, <xref rid="bib121" ref-type="bibr">b</xref>, <xref rid="bib122" ref-type="bibr">c</xref>; Qiang <italic toggle="yes">et al</italic>., <xref rid="bib83" ref-type="bibr">2020b</xref>; Ren <italic toggle="yes">et al</italic>., <xref rid="bib88" ref-type="bibr">2021</xref>; Pang <italic toggle="yes">et al</italic>., <xref rid="bib76" ref-type="bibr">2022a</xref>). For instance, RBMs were initially proposed to learn latent sources (components) of input fMRI data, where each latent component is associated with a time course (Huang <italic toggle="yes">et al</italic>., <xref rid="bib42" ref-type="bibr">2016</xref>). The number of units in the visible layer corresponds to the number of fMRI time points, while the hidden layer units represent latent sources. Using these learned latent components, spatial maps can be derived by multiplying the feature matrix with the input fMRI signals (Fig.&#x000a0;<xref rid="fig2" ref-type="fig">2b</xref>). Similarly, in Hu <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib39" ref-type="bibr">2018</xref>), the visible units represent the fMRI time points, the hidden units capture the latent components, and the weights between the layers correspond to the time courses (Fig.&#x000a0;<xref rid="fig5" ref-type="fig">5</xref>). The model's output is then interpreted as spatial maps.</p><fig position="float" id="fig5"><label>Figure 5:</label><caption><p>The RBM model proposed in Hu <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib39" ref-type="bibr">2018</xref>) interprets the weights as latent time courses, with its output representing spatial maps.</p></caption><graphic xlink:href="kkaf007fig5" position="float"/></fig><p>In Li <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib49" ref-type="bibr">2018a</xref>), a two-layer DBN was applied to fMRI blind source separation, where the overall latent factors were derived by linearly combining the weight matrix from all hidden layers. Zhang <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib121" ref-type="bibr">2019b</xref>) adopted a three-layer DBN and using the NAS to optimize the number of hidden units in the DBN. Later, a volumetric sparse DBN was proposed (Dong <italic toggle="yes">et al</italic>., <xref rid="bib21" ref-type="bibr">2019</xref>), which differed from earlier approaches (Hu <italic toggle="yes">et al</italic>., <xref rid="bib39" ref-type="bibr">2018</xref>; Li <italic toggle="yes">et al</italic>., <xref rid="bib49" ref-type="bibr">2018a</xref>) by using visible units corresponding to the number of voxels in the fMRI scans. Each row of the weight matrix was mapped back into the original 3D brain image space and interpreted as an FBN. More recently, a novel prior knowledge-guided DBN (PKG-DBN) was introduced to address the limitations in hierarchical FBN analysis (Pang <italic toggle="yes">et al</italic>., <xref rid="bib77" ref-type="bibr">2022b</xref>). This approach enforces part of the time courses learned from the DBN to be task-related (either positively or negatively), with the remaining components being linear combinations of the task-related elements.</p></sec><sec id="sec2-5"><title>Graph neural networks</title><p>GNNs are designed to operate on graph-structured data (Scarselli <italic toggle="yes">et al</italic>., <xref rid="bib89" ref-type="bibr">2008</xref>; Wu <italic toggle="yes">et al</italic>., <xref rid="bib103" ref-type="bibr">2020</xref>). Unlike traditional neural networks that work on Euclidean data such as images or sequences, GNNs leverage the structure of graphs to propagate information between nodes, enabling the learning of both node-level and graph-level representations. In fMRI data representation, different brain regions can be represented as nodes and their functional connections as edges, forming a graph that captures the brain's connectivity structure. For example, in Yuan <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib114" ref-type="bibr">2018</xref>), different group-wise FBNs are modeled as nodes and their interactions are modeled as edges, and a time-evolving graph model was then utilized to represent dynamic change of those interactions over time. In Zhang <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib116" ref-type="bibr">2021a</xref>), a multi-layer graph convolution network (GCN) was adopted to simultaneously model brain structure and function in mild cognitive impairment (MCI). Gadgil <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib30" ref-type="bibr">2020</xref>) proposed a spatial-temporal GCN (ST-GCN) to model the non-stationary nature of functional connectivity where each region of interest is represented as the node in the spatiotemporal graph.</p></sec><sec id="sec2-6"><title>Neural architecture search</title><p>NAS is an automated method for designing neural network architectures that aims to optimize their performance for specific tasks (Zoph and Le, <xref rid="bib138" ref-type="bibr">2016</xref>; Liu <italic toggle="yes">et al</italic>., <xref rid="bib56" ref-type="bibr">2018</xref>). Unlike traditional approaches where architectures are manually designed by experts, NAS uses algorithms to explore a vast space of potential architectures and automatically identify the most effective designs.</p><p>For brain function representation, one of the key advantages of NAS is its ability to systematically explore a wide range of architectures, including unconventional designs that may be more aligned with the complex nature of brain function. NAS has been applied to search the structure of RNN cells for decomposing the spatiotemporal FBNs from fMRI (Li <italic toggle="yes">et al</italic>., <xref rid="bib52" ref-type="bibr">2020</xref>, <xref rid="bib51" ref-type="bibr">2021a</xref>, <xref rid="bib53" ref-type="bibr">b</xref>; Dai <italic toggle="yes">et al</italic>., <xref rid="bib19" ref-type="bibr">2022</xref>), the optimal CNN structure for fMRI signal classfication (Dai <italic toggle="yes">et al</italic>., <xref rid="bib18" ref-type="bibr">2020</xref>), and the number of units in each layer of DBNs (Zhang <italic toggle="yes">et al</italic>., <xref rid="bib121" ref-type="bibr">2019b</xref>; Qiang <italic toggle="yes">et al</italic>., <xref rid="bib82" ref-type="bibr">2020a</xref>; Ren <italic toggle="yes">et al</italic>., <xref rid="bib88" ref-type="bibr">2021</xref>; Pang <italic toggle="yes">et al</italic>., <xref rid="bib76" ref-type="bibr">2022a</xref>) for identifing FBNs. Compared to manually crafted network architectures, NAS-optimized neural networks have demonstrated improved performance in these tasks. Among these works, different searching strategies are employed to search the optimal network structures such as evolutionary algorithms (Li <italic toggle="yes">et al</italic>., <xref rid="bib52" ref-type="bibr">2020</xref>, <xref rid="bib53" ref-type="bibr">2021b</xref>; Zhang <italic toggle="yes">et al</italic>., <xref rid="bib121" ref-type="bibr">2019b</xref>; Qiang <italic toggle="yes">et al</italic>., <xref rid="bib82" ref-type="bibr">2020a</xref>; Ren <italic toggle="yes">et al</italic>., <xref rid="bib80" ref-type="bibr">2021</xref>), a gradient-based method (Li <italic toggle="yes">et al</italic>., <xref rid="bib51" ref-type="bibr">2021a</xref>)(Fig. <xref rid="fig6" ref-type="fig">6</xref>), a graph-based method (Dai <italic toggle="yes">et al</italic>., <xref rid="bib19" ref-type="bibr">2022</xref>), and adaptive boosting technique (Dai <italic toggle="yes">et al</italic>., <xref rid="bib18" ref-type="bibr">2020</xref>).</p><fig position="float" id="fig6"><label>Figure 6:</label><caption><p>The differentiable NAS framework, as illustrated in Li <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib51" ref-type="bibr">2021a</xref>), automatically searches for the connections between computational nodes within an RNN cell and optimizes the activation function.</p></caption><graphic xlink:href="kkaf007fig6" position="float"/></fig></sec></sec><sec id="sec3"><title>Learning paradigms for fMRI-based brain function mapping</title><p>For fMRI-based brain function mapping, various learning paradigms have been employed. Supervised learning involves training models on labeled datasets, enabling the accurate identification and classification of brain states or FBNs. However, due to the limited availability of annotations, unsupervised learning has been widely adopted to uncover hidden structures and patterns embodied in fMRI data. More recently, self-supervised learning has emerged as a promising approach, allowing models to learn from large-scale unlabeled data through surrogate tasks, thereby reducing the reliance on extensive labeling while producing high-quality representations of neural activity.</p><sec id="sec3-1"><title>Supervised learning approaches</title><p>Supervised learning approaches rely on the availability of labeled data, where the goal is to map input, such as fMRI data, to known output labels, such as brain states or FBNs derived from other methods. The input and output labels for supervised learning tasks vary depending on the specific objective (Ren <italic toggle="yes">et al</italic>., <xref rid="bib87" ref-type="bibr">2017</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib135" ref-type="bibr">2018c</xref>, <xref rid="bib130" ref-type="bibr">2019</xref>; Wang <italic toggle="yes">et al</italic>., <xref rid="bib98" ref-type="bibr">2018</xref>; Yu <italic toggle="yes">et al</italic>., <xref rid="bib109" ref-type="bibr">2022</xref>, <xref rid="bib113" ref-type="bibr">2023c</xref>). For example, while SDL methods can reconstruct hundreds of FBNs, accurately classifying these networks remains challenging due to their intrinsic variability, noise, and lack of direct correspondence across subjects. Deep learning-based approaches can help address these challenges. Ren <italic toggle="yes">et al</italic>. (<xref rid="bib87" ref-type="bibr">2017</xref> and Zhao <italic toggle="yes">et al</italic>. (<xref rid="bib132" ref-type="bibr">2017b</xref>) used a 3D CNN was to process the volumetric representations of FBNs and predict their respective classes. To mitigate the need for large labeled datasets, Zhao <italic toggle="yes">et al</italic>. (<xref rid="bib133" ref-type="bibr">2018a</xref>) proposed an iteratively optimized CNN (IO-CNN) framework with automatic weak label initialization, reducing reliance on extensive annotated data.</p><p>For modeling fMRI data, Zhao <italic toggle="yes">et al</italic>. (<xref rid="bib135" ref-type="bibr">2018c</xref>) introduced a deep ST-CNN to model 4D fMRI data, using the data as input and the spatial patterns and temporal dynamics of the default mode network (DMN) as supervisory labels. Similarly, in Yan <italic toggle="yes">et al</italic>. (<xref rid="bib106" ref-type="bibr">2021a</xref>, <xref rid="bib105" ref-type="bibr">2022</xref>), a multi-head guided attention GNN (multi-head GAGNN) was developed to simultaneously capture the spatiotemporal patterns of multiple brain functional networks. The input in these models is the 4D fMRI data, with the supervision labels being the 10 resting state networks (RSNs) and their associated temporal patterns. In Cui <italic toggle="yes">et al</italic>. (<xref rid="bib16" ref-type="bibr">2018a</xref>, <xref rid="bib17" ref-type="bibr">b</xref>), a deep RNN (DRNN) framework was proposed to model FBNs from tfMRI data. In this approach, the task design stimulus curves for each subject are gathered into a stimulus matrix as the input, while the whole-brain tfMRI signals are aggregated into a large signal matrix as the output.</p><p>For brain state recognition, Wang <italic toggle="yes">et al</italic>. (<xref rid="bib98" ref-type="bibr">2018</xref>) proposed a five-layer deep sparse RNN (DSRNN) to accurately classify brain states. In this model, the input consists of fMRI data at specific time points, and the output is the corresponding brain state, making it a classification task. In Liu <italic toggle="yes">et al</italic>. (<xref rid="bib57" ref-type="bibr">2019</xref>) and Wang <italic toggle="yes">et al</italic>. (<xref rid="bib101" ref-type="bibr">2023</xref>), fMRI signal representation is formulated as a classification task, using a 1D CNN model to distinguish between gyral and sulcal fMRI time series. By analyzing the weights in the fully connected layer responsible for predictions, they identified filters corresponding to gyri and sulci, which were then studied to uncover the distinct features of these signals. Building on this, Dai <italic toggle="yes">et al</italic>. (<xref rid="bib18" ref-type="bibr">2020</xref>) demonstrated that CNN models initially developed for two-class (gyral vs sulcal) classification could be further optimized to handle more complex tasks, such as three-class classification (three-hinge gyral vs two-hinge gyral vs sulcal).</p></sec><sec id="sec3-2"><title>Unsupervised learning approaches</title><p>Unsupervised learning involves training models on data without labels and annotations, allowing them to discover hidden structures and patterns independently. This approach is especially valuable for brain function mapping where the &#x0201c;ground truth&#x0201d; for individual/group brain function is lacking.</p></sec><sec id="sec3-3"><title>Autoencoder</title><p>Autoencoders are a type of artificial neural network designed to learn efficient, compressed representations of input data. They consist of two main parts: an encoder, which compresses the input data into a latent space, and a decoder, which reconstructs the input from the compressed representation. Autoencoders are particularly useful for brain function mapping because they can reduce the dimensionality of the data while preserving important features, making it easier to analyze and interpret complex neural patterns in fMRI data. Spatially, fMRI scans consist of a vast number of voxels, each representing a small volume of brain tissue. Analyzing these voxels individually is impractical due to their sheer number and the intricate relationships between different brain regions. These regions often exhibit similar functional characteristics, which suggest underlying patterns and groupings that are not explicitly labeled in the data. Autoencoders can address this challenge by compressing the spatial dimensions of the data, enabling the identification of these meaningful patterns. Through this compression, autoencoders uncover latent structures within the brain, such as FBNs, without requiring labeled data, making them invaluable for exploratory analysis.</p><p>Various types of autoencoders have been employed for brain function mapping, each tailored to different aspects of the data. Convolutional autoencoders (CAEs) are particularly effective for handling both spatial and temporal data. 1D convolutional layers were adopted in CAE models to capture the characteristics of fMRI time series (Huang <italic toggle="yes">et al</italic>., <xref rid="bib43" ref-type="bibr">2017</xref>, <xref rid="bib41" ref-type="bibr">2018</xref>; Wang <italic toggle="yes">et al</italic>., <xref rid="bib99" ref-type="bibr">2019</xref>; Makkie <italic toggle="yes">et al</italic>., <xref rid="bib68" ref-type="bibr">2019</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib123" ref-type="bibr">2021</xref>, <xref rid="bib126" ref-type="bibr">2024</xref>). A 3D CAE model was used to extract spatial brain network features (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib131" ref-type="bibr">2017a</xref>) and learn representations for 3D fMRI volumes (Dong <italic toggle="yes">et al</italic>., <xref rid="bib23" ref-type="bibr">2020b</xref>). Recurrent autoencoders (RAEs), on the other hand, are well-suited for modeling temporal dynamics in fMRI data (Li <italic toggle="yes">et al</italic>., <xref rid="bib50" ref-type="bibr">2019</xref>; Cui <italic toggle="yes">et al</italic>., <xref rid="bib15" ref-type="bibr">2019</xref>; Li <italic toggle="yes">et al</italic>., <xref rid="bib52" ref-type="bibr">2020</xref>, <xref rid="bib53" ref-type="bibr">2021b</xref>; Qiang <italic toggle="yes">et al</italic>., <xref rid="bib80" ref-type="bibr">2021</xref>; Dai <italic toggle="yes">et al</italic>., <xref rid="bib19" ref-type="bibr">2022</xref>). These models typically use fully connected layers to reduce spatial dimensions, followed by recurrent layers that capture temporal dependencies across time steps (Fig.&#x000a0;<xref rid="fig7" ref-type="fig">7</xref>). Variational autoencoders (VAEs) introduce a probabilistic approach to the latent space, enabling the generation of new data samples that reflect the variability in brain function. This is useful for both data augmentation and understanding the distribution of neural activity (Qiang <italic toggle="yes">et al</italic>., <xref rid="bib82" ref-type="bibr">2020a</xref>, <xref rid="bib80" ref-type="bibr">2021</xref>). Additionally, attention-based (Liu <italic toggle="yes">et&#x000a0;al</italic>., <xref rid="bib62" ref-type="bibr">2023c</xref>, <xref rid="bib60" ref-type="bibr">2024a</xref>, <xref rid="bib61" ref-type="bibr">b</xref>) and transformer-based methods (Dong <italic toggle="yes">et al</italic>., <xref rid="bib24" ref-type="bibr">2020c</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib127" ref-type="bibr">2022</xref>, <xref rid="bib128" ref-type="bibr">2023c</xref>) have been incorporated into autoencoders to further enhance the representation of brain function data.</p><fig position="float" id="fig7"><label>Figure 7:</label><caption><p>The deep sparsity recurrent autoencoder (DSRAE) proposed in Li <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib50" ref-type="bibr">2019</xref>) compresses fMRI volumes by reducing the number of voxels in successive layers. Initially, the fully connected layer reduces the voxel count to 128, followed by further reduction to 64 in the first recurrent layer, and finally to 32 in the second recurrent layer. This spatial compression enables the model to uncover latent patterns, such as functional brain networks (FBNs), from the vast number of fMRI voxels.</p></caption><graphic xlink:href="kkaf007fig7" position="float"/></fig></sec><sec id="sec3-4"><title>Generative adversarial networks</title><p>Generative adversarial networks (GANs) consist of two neural networks: a generator and a discriminator, which are trained simultaneously through an adversarial process. The generator network creates synthetic data that mimic the distribution of the training data, while the discriminator network attempts to distinguish between real and generated data. This adversarial training setup drives both networks to improve continuously, leading to a generator capable of producing data that closely resemble the original.</p><p>In brain function mapping, GANs can capture the underlying distribution of fMRI data and generate new samples that reflect the variability and complexity of brain function. In Dong <italic toggle="yes">et al</italic>. (<xref rid="bib22" ref-type="bibr">2020a</xref>), the trained discriminator encodes representations of real fMRI data, with the features extracted by the discriminator interpreted as functional brain networks. A recurrent Wasserstein GAN (RWGAN) was proposed in Qiang <italic toggle="yes">et al</italic>. (<xref rid="bib81" ref-type="bibr">2022</xref>) to learn brain representations from volumetric fMRI data. In this model, the discriminator acts as a deep feature extractor, while the generator produces high-quality synthetic data for fMRI augmentation. Additionally, the VAE&#x02013;GAN framework, which combines a VAE with a GAN, was introduced for functional brain network identification and fMRI data augmentation (Qiang <italic toggle="yes">et al</italic>., <xref rid="bib84" ref-type="bibr">2023</xref>).</p></sec><sec id="sec3-5"><title>Self-supervised learning approaches</title><p>Self-supervised learning has recently gained attention in fMRI-based brain function analysis, offering a promising alternative that allows models to learn meaningful representations from unlabeled data with surrogate tasks. For fMRI data representation, these tasks often include predicting missing data points (Ortega Caro <italic toggle="yes">et al</italic>., <xref rid="bib75" ref-type="bibr">2024</xref>), reconstructing temporal sequences (Yang <italic toggle="yes">et al</italic>., <xref rid="bib108" ref-type="bibr">2024</xref>), or generating future brain states based on past activity. By leveraging large amounts of unlabeled fMRI data, self-supervised learning has shown great potential in learning robust, generalizable representations that can later be fine-tuned for specific tasks, such as brain state recognition or functional network identification.</p><p>Building on this promising paradigm, recent works have made significant advancements in applying self-supervised learning to brain function mapping through a variety of innovative approaches. In Thomas <italic toggle="yes">et al</italic>. (<xref rid="bib94" ref-type="bibr">2022</xref>), sequences of brain activity are represented similarly to text in natural language processing (NLP), and self-supervised learning frameworks are introduced by applying techniques such as sequence-to-sequence autoencoding, causal language modeling, and masked language modeling to uncover spatiotemporal patterns in brain dynamics from large-scale neuroimaging data. Inspired by masked image modeling (MIM) (He <italic toggle="yes">et al</italic>., <xref rid="bib33" ref-type="bibr">2022</xref>), BrainLM introduces a Transformer masked autoencoder pre-trained to reconstruct masked signals in fMRI recordings by leveraging both visible and masked tokens (Ortega Caro <italic toggle="yes">et al</italic>., <xref rid="bib75" ref-type="bibr">2024</xref>). The pre-trained model can then be fine-tuned for specific tasks or applied directly for zero-shot inference. Similarly, BrainMAE takes a region-aware approach by randomly masking regions of interest (ROIs) within fMRI segments and challenging the model to reconstruct these masked signals, thus learning functional relationships between brain regions (Yang <italic toggle="yes">et al</italic>., <xref rid="bib108" ref-type="bibr">2024</xref>). In Malkiel <italic toggle="yes">et al</italic>. (<xref rid="bib69" ref-type="bibr">2022</xref>), a Transformer framework for fMRI (TFF) was proposed, utilizing self-supervised pre-training to reconstruct 3D fMRI volumes. After pre-training, the model is fine-tuned for specific tasks such as age prediction and schizophrenia diagnosis. SwiFT (Swin 4D fMRI Transformer) utilizes contrastive learning for pre-training (Kim <italic toggle="yes">et al</italic>., <xref rid="bib45" ref-type="bibr">2023</xref>), employing two types of loss functions: instance contrastive loss, which distinguishes between fMRI sub-sequences from different subjects, and local&#x02013;local temporal contrastive loss, which differentiates fMRI sub-sequences from different timestamps within the same subject.</p></sec></sec><sec id="sec4"><title>Trends, challenges, and opportunities</title><p>As advancements continue to unfold, new trends, challenges, and opportunities are emerging with the potential to shape the future of brain function mapping and neuroimaging research. These developments have the potential to drive significant improvements in how brain activity is represented, modeled, and understood. In this section, we highlight three critical areas of growth: the development of fMRI embeddings, which aim to create more compact and informative representations of brain activity; foundation models, which offer a generalized framework for applying learned representations across multiple tasks; and brain-inspired AI, which seeks to bridge the gap between human cognition and artificial intelligence, enhancing the capabilities of AI systems.</p><sec id="sec4-1"><title>fMRI embedding</title><p>Traditional brain functional mapping and representation, such as FBNs, often rely on methods like ICA and SDL to extract spatial and temporal patterns from fMRI data. The whole brain's functional profile can be viewed as discrete, one-hot embeddings which only encode the presence or absence of specific FBNs. Such representations fail to capture the variability, complexity, and inter-subject differences inherent in brain activity patterns across diverse populations and dynamic time points. Recently, researchers have started applying embedding techniques to profile the whole brain's function representation as continuous vectors (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib127" ref-type="bibr">2022</xref>; Thomas <italic toggle="yes">et al</italic>., <xref rid="bib94" ref-type="bibr">2022</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib124" ref-type="bibr">2023a</xref>, <xref rid="bib128" ref-type="bibr">c</xref>). Previous studies (e.g. Casanova <italic toggle="yes">et al</italic>., <xref rid="bib11" ref-type="bibr">2021</xref>) explored the concept of embedding brain function by linearly projecting FBNs into lower-dimensional spaces, reducing the dimensionality of FBNs to a more compact representation. However, it remains limited by the challenges previously discussed. Rather than treating brain activity as isolated, independent components like FBNs, several studies on fMRI embeddings represent functional brain patterns as dense vectors in a continuous space. In Zhao <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib127" ref-type="bibr">2022</xref>, <xref rid="bib128" ref-type="bibr">2023c</xref>), an unsupervised embedding framework was proposed using an encoding&#x02013;decoding architecture, where 4D fMRI signals are rearranged into 2D matrices and passed through linear transformation and transformer layers to reduce spatial dimensionality while exploring temporal relationships (Fig.&#x000a0;<xref rid="fig8" ref-type="fig">8</xref>). By learning from large-scale fMRI datasets, these models can capture both the regularity and variability of brain activity across individuals and time points, resulting in a more compact and meaningful representation. This approach enables better comparisons between brain states, more accurate brain function mapping, and improved performance on downstream tasks such as brain state prediction and network identification.</p><fig position="float" id="fig8"><label>Figure 8:</label><caption><p>The fMRI embedding framework proposed by Zhao <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib128" ref-type="bibr">2023c</xref>) restructures 4D fMRI signals into 2D matrices. These matrices are then processed through linear transformations and transformer layers, effectively reducing spatial dimensionality while capturing temporal relationships within the data.</p></caption><graphic xlink:href="kkaf007fig8" position="float"/></fig><p>Building on these advancements, future work in fMRI embeddings can explore several promising directions. First, improving the interpretability of these embeddings will be essential for translating insights into practical applications in neuroscience and clinical settings. A particularly promising approach is the incorporation of biologically informed constraints or priors into embedding models, which could generate representations that more closely align with known brain structures and functions. Additionally, future studies could investigate the integration of multimodal data&#x02014;such as electroencephalography (EEG) or magnetoencephalography (MEG)&#x02014;into the embedding framework, creating richer, more comprehensive models of brain activity that capture both spatial and temporal dynamics across different imaging modalities. Lastly, self-supervised learning techniques hold significant potential in this area. These approaches can help models learn more robust and generalizable representations from unlabeled and noisy data, further enhancing their effectiveness for brain function mapping and other neuroimaging tasks.</p></sec><sec id="sec4-2"><title>Brain foundation models</title><p>Foundation models have emerged as a transformative approach in fields like NLP and computer vision (Radford <italic toggle="yes">et al</italic>., <xref rid="bib85" ref-type="bibr">2018</xref>; Dosovitskiy <italic toggle="yes">et al</italic>., <xref rid="bib25" ref-type="bibr">2020</xref>; Oquab <italic toggle="yes">et al</italic>., <xref rid="bib74" ref-type="bibr">2023</xref>; Dubey <italic toggle="yes">et al</italic>., <xref rid="bib27" ref-type="bibr">2024</xref>). These models are pre-trained on large-scale datasets and can be fine-tuned or directly applied for a variety of downstream tasks. The key benefit of foundation models lies in their ability to learn rich, generalizable features from large amounts of data, making them highly adaptable to new tasks with strong performance.</p><p>Inspired by the success of foundation models in language and vision, researchers have begun exploring the brain foundation model for diverse brain-related tasks with large-scale pre-training (Thomas <italic toggle="yes">et al</italic>., <xref rid="bib94" ref-type="bibr">2022</xref>; Ortega Caro <italic toggle="yes">et al</italic>., <xref rid="bib75" ref-type="bibr">2024</xref>; Yang <italic toggle="yes">et al</italic>., <xref rid="bib108" ref-type="bibr">2024</xref>; Kim <italic toggle="yes">et al</italic>., <xref rid="bib45" ref-type="bibr">2023</xref>). For example, Thomas <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib94" ref-type="bibr">2022</xref>) proposed a framework that models the dynamics of brain activity by treating sequences of brain signals similarly to how sequences of text are modeled in NLP. The study demonstrated that pre-trained models significantly outperformed others in downstream adaptation tasks on two benchmark mental state decoding datasets. Brain Language Model (BrainLM) is a foundation model for brain activity dynamics, trained on 6700 h of fMRI recordings using self-supervised masked-prediction training (Ortega Caro <italic toggle="yes">et al</italic>., <xref rid="bib75" ref-type="bibr">2024</xref>). It excels in both fine-tuning and zero-shot inference tasks, enabling the accurate prediction of clinical variables, identification of intrinsic functional networks, and generation of interpretable latent representations. BrainMAE is designed to learn representations directly from fMRI time-series data using a self-supervised masked autoencoding framework (Yang <italic toggle="yes">et al</italic>., <xref rid="bib108" ref-type="bibr">2024</xref>). It incorporates a region-aware graph attention mechanism to capture relationships between ROIs and effectively models the rich temporal dynamics of fMRI data. BrainMAE consistently outperforms baseline methods across various downstream tasks, including steady-state variable prediction and transient mental state decoding.</p><p>Despite these advancements, brain foundation models still face several challenges. One major issue is the limited availability of large-scale, high-quality fMRI datasets, which restricts the model's ability to generalize across diverse populations. To mitigate this limitation, researchers increasingly employ strategies such as transfer learning, data augmentation, and synthetic data generation. Transfer learning utilizes pre-trained neural networks, capturing generalizable features that can be efficiently fine-tuned to smaller, task-specific fMRI datasets, thus enhancing model performance (Zhang <italic toggle="yes">et al</italic>., <xref rid="bib115" ref-type="bibr">2018a</xref>; Svanera <italic toggle="yes">et al</italic>., <xref rid="bib92" ref-type="bibr">2019</xref>; Al-Hiyali <italic toggle="yes">et al</italic>., <xref rid="bib3" ref-type="bibr">2021</xref>). Data augmentation techniques, such as Gaussian noise and Mixup, expand dataset variability, strengthening the robustness and generalizability of models (Pei <italic toggle="yes">et al</italic>., <xref rid="bib78" ref-type="bibr">2022</xref>; Smucny <italic toggle="yes">et al</italic>., <xref rid="bib91" ref-type="bibr">2022</xref>). Additionally, synthetic data generation methods, such as GANs (Zhuang <italic toggle="yes">et al</italic>., <xref rid="bib137" ref-type="bibr">2019</xref>), VAEs (Qiang <italic toggle="yes">et al</italic>., <xref rid="bib80" ref-type="bibr">2021</xref>), and diffusion models (<xref rid="bib40" ref-type="bibr">Hu et, al</xref>.), have demonstrated promise in creating realistic artificial fMRI samples that closely resemble brain activity, which can effectively alleviate the data limitation.</p><p>Another key area for improvement is interpretability&#x02014;while these models offer powerful capabilities, gaining a deeper understanding of their decision-making processes is crucial for their application in both clinical and neuroscientific contexts. Additionally, further exploration of their potential clinical value is essential, as these models could offer new insights into diagnosis, treatment planning, and understanding of brain disorders in real-world medical scenarios. Addressing these challenges will be crucial to unlocking the full potential of brain foundation models in advancing neuroscience and healthcare applications.</p></sec><sec id="sec4-3"><title>Brain-inspired AI</title><p>While current AI models have achieved remarkable success, they still lack the flexibility, adaptability, and efficiency demonstrated by biological neural networks (BNNs). Brain-inspired AI seeks to bridge this gap by drawing the inspirations from the human brain, such as the organizational and functional principles, to develop more efficient and powerful AI systems (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib129" ref-type="bibr">2023d</xref>). Recent studies have shown that the responses of artificial neural networks (ANNs) to external stimuli closely mirror those of their biological counterparts in various domains, including visual (Zhao <italic toggle="yes">et al</italic>., <xref rid="bib124" ref-type="bibr">2023a</xref>; Yamins and DiCarlo, <xref rid="bib104" ref-type="bibr">2016</xref>; Kriegeskorte, <xref rid="bib46" ref-type="bibr">2015</xref>), auditory (Zhou <italic toggle="yes">et al</italic>., <xref rid="bib136" ref-type="bibr">2023</xref>; Li <italic toggle="yes">et al</italic>., <xref rid="bib54" ref-type="bibr">2023</xref>; Millet <italic toggle="yes">et al</italic>., <xref rid="bib72" ref-type="bibr">2022</xref>), and linguistic processing (Liu <italic toggle="yes">et al</italic>., <xref rid="bib59" ref-type="bibr">2023b</xref>; Caucheteux and King, <xref rid="bib12" ref-type="bibr">2022</xref>; Schrimpf <italic toggle="yes">et al</italic>., <xref rid="bib90" ref-type="bibr">2021</xref>). Additionally, the topology of ANNs are similar to BNNs (Du <italic toggle="yes">et al</italic>., <xref rid="bib26" ref-type="bibr">2023</xref>). This intriguing correspondence suggests that ANNs may evolve to process and organize information in ways similar to the human brain. Another group of works (Yu <italic toggle="yes">et al</italic>., <xref rid="bib111" ref-type="bibr">2023a</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib125" ref-type="bibr">2023b</xref>; Lyu <italic toggle="yes">et al</italic>., <xref rid="bib67" ref-type="bibr">2024</xref>; Yu <italic toggle="yes">et al</italic>., <xref rid="bib110" ref-type="bibr">2024</xref>) have sought to incorporate brain organizational principles, such as core-periphery organization, directly into ANN architectures, leading to improved performance. Building on these advancements, researchers can leverage brain-inspired AI models to develop more precise and efficient brain mapping tools that capture the dynamic complexity of neural processes. In turn, these enhanced maps could provide critical insights to refine AI architectures and learning mechanisms, making them more flexible, adaptive, and context-aware&#x02014;traits akin to the human brain. This synergy between neuroscience and AI holds great promise for breakthroughs in personalized healthcare, advanced cognitive computing, and brain&#x02013;computer interfaces, paving the way for more intelligent and human-aligned AI technologies.</p></sec></sec><sec id="sec5"><title>Real-world applications and prospective impact</title><p>In this section, we focus on the real-world applications and prospective impact of brain function mapping. Advances in mapping the intricate processes of the brain hold significant promise for a range of fields, including neuroscience, mental health, and neurotechnology. For example, more accurate brain maps can facilitate early detection and treatment of neurological disorders such as Alzheimer's, improving patient outcomes. Additionally, detailed brain function mapping can enhance brain&#x02013;computer interfaces, providing new avenues for assistive technologies that restore movement or communication capabilities in individuals with disabilities. As these techniques continue to evolve, they will play a crucial role in advancing both scientific understanding and practical applications in healthcare and beyond.</p><sec id="sec5-1"><title>Neural disorders and clinical applications</title><p>One of the most promising applications of brain function mapping lies in its potential to advance the diagnosis and treatment of neural disorders (Zhang <italic toggle="yes">et&#x000a0;al</italic>., <xref rid="bib117" ref-type="bibr">2021b</xref>; Yu <italic toggle="yes">et&#x000a0;al</italic>., <xref rid="bib113" ref-type="bibr">2023c</xref>). For example, the extracted spatiotemporal patterns of brain activities can be used to detect ADHD (Mao <italic toggle="yes">et al</italic>., <xref rid="bib71" ref-type="bibr">2019</xref>; Dong <italic toggle="yes">et al</italic>., <xref rid="bib24" ref-type="bibr">2020c</xref>; Qiang <italic toggle="yes">et al</italic>., <xref rid="bib82" ref-type="bibr">2020a</xref>). The 3D CNNs proposed by Zhao <italic toggle="yes">et al</italic>. (<xref rid="bib134" ref-type="bibr">2018b</xref>) have demonstrated the ability to differentiate ASD from healthy controls, offering a valuable tool for early diagnosis. Similarly, by integrating brain functional profiles, Zhang <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib116" ref-type="bibr">2021a</xref>) successfully differentiated MCI patients from elderly normal controls, a critical step in managing early-stage cognitive decline. Moreover, Zhang <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib118" ref-type="bibr">2023</xref>) leveraged brain functional connectivity to learn clinical group-related feature vectors, achieving higher accuracy in classifying Alzheimer's disease. These advancements highlight the potential of brain function mapping to transform the clinical landscape, enabling earlier diagnoses and more targeted interventions for neurological disorders.</p></sec><sec id="sec5-2"><title>Neurosurgical practices and clinical decision-making</title><p>Brain function mapping holds great promise for neurosurgical applications, facilitating precise surgical interventions and improving patient outcomes. Accurate preoperative brain functional mapping can guide surgical procedures by identifying and preserving critical functional regions associated with language, vision, and motor activities, thereby minimizing postoperative neurological deficits. For example, detailed, patient-specific brain maps allow neurosurgeons to precisely visualize essential cortical and subcortical regions and inform surgical trajectories and help surgeons effectively avoid damaging eloquent areas during operations. Brain function mapping also enables predictive neurosurgical outcomes. For example, individualized brain functional mapping can be utilized to forecast individual patient responses to surgical treatments, estimate recovery trajectories, and predict the risk of postoperative complications, ultimately aiding neurosurgeons in selecting the most effective therapeutic strategies.</p></sec><sec id="sec5-3"><title>Advancing neuroscientific understanding</title><p>Beyond clinical applications, brain function mapping plays a pivotal role in advancing neuroscientific understanding. The represented patterns of brain activity uncover new insights into brain function and organization. For instance, a group of have systematically examined the characteristics of gyri and sulci fMRI signals, suggesting distinct functional roles for gyri and sulci and providing insights into their underlying mechanisms (Zhang <italic toggle="yes">et al</italic>., <xref rid="bib120" ref-type="bibr">2018b</xref>; Liu <italic toggle="yes">et al</italic>., <xref rid="bib57" ref-type="bibr">2019</xref>; Zhao <italic toggle="yes">et al</italic>., <xref rid="bib123" ref-type="bibr">2021</xref>; Wang <italic toggle="yes">et al</italic>., <xref rid="bib101" ref-type="bibr">2023</xref>, <xref rid="bib100" ref-type="bibr">2024</xref>). In addition, a twin transformer framework proposed by Yu <italic toggle="yes">et&#x000a0;al</italic>. (<xref rid="bib112" ref-type="bibr">2023b</xref>) effectively disentangles the spatiotemporal patterns of gyri and sulci, revealing that these brain structures may collaborate in a core&#x02013;periphery network manner. These findings deepen our understanding of the brain's structural and functional complexity and highlight how advanced models can elucidate the brain's intricate dynamics. This expanding body of work not only sheds light on previously unexplored brain mechanisms but also opens new avenues for future research in neuroscience.</p></sec><sec id="sec5-4"><title>Decoding brain activity</title><p>Another exciting application of brain function mapping is the ability to decode specific mental states, sensory perceptions, and even language directly from brain activity. AI models have made significant strides in decoding visual perception from brain signals, allowing researchers to reconstruct images based on what individuals are seeing or imagining. For instance, using fMRI data, these models can predict visual stimuli with impressive accuracy (Fang <italic toggle="yes">et al</italic>., <xref rid="bib28" ref-type="bibr">2020</xref>; Chen <italic toggle="yes">et al</italic>., <xref rid="bib13" ref-type="bibr">2023</xref>; Takagi and Nishimoto, <xref rid="bib93" ref-type="bibr">2023</xref>). Similarly, decoding language from brain activity has gained traction (Gauthier and Ivanova, <xref rid="bib31" ref-type="bibr">2018</xref>; Affolter <italic toggle="yes">et al</italic>., <xref rid="bib2" ref-type="bibr">2020</xref>), with AI-driven methods showing promise in translating neural signals into speech or text (D&#x000b4;efossez <italic toggle="yes">et al</italic>., <xref rid="bib20" ref-type="bibr">2023</xref>; Berezutskaya <italic toggle="yes">et al</italic>., <xref rid="bib6" ref-type="bibr">2023</xref>), offering a pathway for enhancing communication for individuals with speech impairments.</p><p>These advances hold great potential for brain&#x02013;computer interfaces (BCIs) by enabling direct neural control of assistive devices, thereby enhancing mobility, communication, and overall independence for individuals with disabilities. BCIs leveraging brain decoding could enable paralyzed individuals to control external devices or communicate by translating their thoughts into actions or speech. Moreover, sensory decoding, such as interpreting auditory or tactile information from brain signals, could open doors to new rehabilitation tools for people with sensory deficits, creating new opportunities for restoring lost functions. As these innovations continue to evolve, they hold the promise of not only improving the functionality and autonomy of people with disabilities but also advancing our understanding of the brain's capacity to adapt and interact with the external world in ways previously thought impossible.</p></sec></sec></body><back><sec id="sec6"><title>Author contributions</title><p>Lin Zhao (Conceptualization, Data curation, Investigation, Methodology, Validation, Visualization, Writing&#x02014;original draft, Writing&#x02014;review &#x00026; editing).</p></sec><sec sec-type="COI-statement" id="sec7"><title>Conflict of interest</title><p>None declared.</p></sec><ref-list id="ref1"><title>References</title><ref id="bib1"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Achiam</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Adler</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Agarwal</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Gpt-4 technical report</article-title>. <pub-id pub-id-type="arxiv">arXiv:2303.08774</pub-id>.</mixed-citation></ref><ref id="bib2"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Affolter</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Egressy</surname> &#x000a0;<given-names>B</given-names></string-name>, <string-name><surname>Pascual</surname> &#x000a0;<given-names>D</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020</year>) <article-title>Brain2word: decoding brain activity for language generation</article-title>. <pub-id pub-id-type="arxiv">arXiv:2009.04765</pub-id>.</mixed-citation></ref><ref id="bib3"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Al-Hiyali</surname> &#x000a0;<given-names>MI</given-names></string-name>, <string-name><surname>Yahya</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Faye</surname> &#x000a0;<given-names>I</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021</year>) <article-title>Classification of bold fmri signals using wavelet transform and transfer learning for detection of autism spectrum disorder</article-title>. In <source>2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>94</fpage>&#x02013;<lpage>8</lpage>.</mixed-citation></ref><ref id="bib4"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Bassett</surname> &#x000a0;<given-names>DS</given-names></string-name>, <string-name><surname>Bullmore</surname> &#x000a0;<given-names>E.</given-names></string-name></person-group> (<year>2006</year>) <article-title>Small-world brain networks</article-title>. <source>Neurosci</source>. <volume>12</volume>:<fpage>512</fpage>&#x02013;<lpage>23</lpage>.</mixed-citation></ref><ref id="bib5"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Belliveau</surname> &#x000a0;<given-names>JW</given-names></string-name>, <string-name><surname>Kennedy</surname> &#x000a0;<given-names>DN</given-names></string-name>, <string-name><surname>McKinstry</surname> &#x000a0;<given-names>RC</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>1991</year>) <article-title>Functional mapping of the human visual cortex by magnetic resonance imaging</article-title>. <source>Science</source>. <volume>254</volume>:<fpage>716</fpage>&#x02013;<lpage>9</lpage>.<pub-id pub-id-type="pmid">1948051</pub-id>
</mixed-citation></ref><ref id="bib6"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Berezutskaya</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Freudenburg</surname> &#x000a0;<given-names>ZV</given-names></string-name>, <string-name><surname>Vansteensel</surname> &#x000a0;<given-names>MJ</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Direct speech reconstruction from sensorimotor brain activity with optimized deep learning models</article-title>. <source>J Neural Eng</source>. <volume>20</volume>:<fpage>056010</fpage>.</mixed-citation></ref><ref id="bib7"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Biswal</surname> &#x000a0;<given-names>BB</given-names></string-name>, <string-name><surname>Mennes</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Zuo</surname> &#x000a0;<given-names>X-N</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2010</year>) <article-title>Toward discovery science of human brain function</article-title>. <source>Proc Natl Acad Sci</source>. <volume>107</volume>:<fpage>4734</fpage>&#x02013;<lpage>9</lpage>.<pub-id pub-id-type="pmid">20176931</pub-id>
</mixed-citation></ref><ref id="bib8"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Brodmann</surname> &#x000a0;<given-names>K.</given-names></string-name>
</person-group> (<year>1909</year>) <source>Vergleichende Lokalisationslehre der Grosshirnrinde in Ihren Prinzipien Dargestellt auf Grund Des Zellenbaues</source>. <publisher-loc>Barth</publisher-loc>: <publisher-name>Leipzig</publisher-name>.</mixed-citation></ref><ref id="bib9"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Calhoun</surname> &#x000a0;<given-names>VD</given-names></string-name>, <string-name><surname>Adali</surname> &#x000a0;<given-names>T.</given-names></string-name></person-group> (<year>2006</year>) <article-title>Unmixing fmri with independent component analysis</article-title>. <source>IEEE Eng Med Biol Mag</source>. <volume>25</volume>:<fpage>79</fpage>&#x02013;<lpage>90</lpage>.</mixed-citation></ref><ref id="bib10"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Calhoun</surname> &#x000a0;<given-names>VD</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Adal&#x00131;</surname> &#x000a0;<given-names>T.</given-names></string-name></person-group> (<year>2009</year>) <article-title>A review of group ICA for fMRI data and ICA for joint inference of imaging, genetic, and ERP data</article-title>. <source>Neuroimage</source>. <volume>45</volume>:<fpage>S163</fpage>&#x02013;<lpage>72</lpage>.<pub-id pub-id-type="pmid">19059344</pub-id>
</mixed-citation></ref><ref id="bib11"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Casanova</surname> &#x000a0;<given-names>R</given-names></string-name>, <string-name><surname>Lyday</surname> &#x000a0;<given-names>RG</given-names></string-name>, <string-name><surname>Bahrami</surname> &#x000a0;<given-names>M</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021</year>) <article-title>Embedding functional brain networks in low dimensional spaces using manifold learning techniques</article-title>. <source>Front Neuroinform</source>. <volume>15</volume>:<fpage>740143</fpage>.<pub-id pub-id-type="pmid">35002665</pub-id>
</mixed-citation></ref><ref id="bib12"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Caucheteux</surname> &#x000a0;<given-names>C</given-names></string-name>, <string-name><surname>King</surname> &#x000a0;<given-names>J-R.</given-names></string-name></person-group> (<year>2022</year>) <article-title>Brains and algorithms partially converge in natural language processing</article-title>. <source>Commun Biol</source>. <volume>5</volume>:<fpage>134</fpage>.<pub-id pub-id-type="pmid">35173264</pub-id>
</mixed-citation></ref><ref id="bib13"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Chen</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Qing</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Xiang</surname> &#x000a0;<given-names>T</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Seeing beyond the brain: conditional diffusion model with sparse masked modeling for vision decoding</article-title>. In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>. <publisher-loc>Vancouver, BC</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>22710</fpage>&#x02013;<lpage>20</lpage>.</mixed-citation></ref><ref id="bib14"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Cordes</surname> &#x000a0;<given-names>D</given-names></string-name>, <string-name><surname>Haughton</surname> &#x000a0;<given-names>VM</given-names></string-name>, <string-name><surname>Arfanakis</surname> &#x000a0;<given-names>K</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2000</year>) <article-title>Mapping functionally related regions of brain with functional connectivity MR imaging</article-title>. <source>Am J Neuroradiol</source>. <volume>21</volume>:<fpage>1636</fpage>&#x02013;<lpage>44</lpage>.<pub-id pub-id-type="pmid">11039342</pub-id>
</mixed-citation></ref><ref id="bib15"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Cui</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Modeling brain diverse and complex hemodynamic response patterns via deep recurrent autoencoder</article-title>. <source>IEEE Trans Cogn Dev Syst</source>. <volume>12</volume>:<fpage>733</fpage>&#x02013;<lpage>43</lpage>.</mixed-citation></ref><ref id="bib16"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Cui</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018a</year>) <article-title>Identifying brain networks at multiple time scales via deep recurrent neural network</article-title>. <source>IEEE J Biomed Health Inform</source>. <volume>23</volume>:<fpage>2515</fpage>&#x02013;<lpage>25</lpage>.<pub-id pub-id-type="pmid">30475739</pub-id>
</mixed-citation></ref><ref id="bib17"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Cui</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018b</year>) <article-title>Identifying brain networks of multiple time scales via deep recurrent neural network</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part III 11</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>284</fpage>&#x02013;<lpage>92</lpage>.</mixed-citation></ref><ref id="bib18"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>F</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>Q</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020</year>) <article-title>Optimize CNN model for fMRI signal classification via adanet-based neural architecture search</article-title>. In <source>2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1399</fpage>&#x02013;<lpage>403</lpage>.</mixed-citation></ref><ref id="bib19"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Graph representation neural architecture search for optimal spatial/temporal functional brain network decomposition</article-title>. In <source>International Workshop on Machine Learning in Medical Imaging</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>279</fpage>&#x02013;<lpage>87</lpage>.</mixed-citation></ref><ref id="bib20"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>D&#x000e9;fossez</surname> &#x000a0;<given-names>A</given-names></string-name>, <string-name><surname>Caucheteux</surname> &#x000a0;<given-names>C</given-names></string-name>, <string-name><surname>Rapin</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Decoding speech perception from non-invasive brain recordings</article-title>. <source>Nat Mach Intell</source>. <volume>5</volume>:<fpage>1097</fpage>&#x02013;<lpage>107</lpage>.</mixed-citation></ref><ref id="bib21"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>F</given-names></string-name>, <string-name><surname>Ning</surname> &#x000a0;<given-names>Q</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Modeling hierarchical brain networks via volumetric sparse deep belief network</article-title>. <source>IEEE Trans Biomed Eng</source>. <volume>67</volume>:<fpage>1739</fpage>&#x02013;<lpage>48</lpage>.<pub-id pub-id-type="pmid">31647417</pub-id>
</mixed-citation></ref><ref id="bib22"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Lv</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020a</year>) <article-title>A novel fMRI representation learning framework with GAN</article-title>. In <publisher-loc>Berlin</publisher-loc> &#x000a0;<source>Machine Learning in Medical Imaging: 11th International Workshop, MLMI 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Proceedings 11</source>. <publisher-name>Springer</publisher-name>, <fpage>21</fpage>&#x02013;<lpage>9</lpage>.</mixed-citation></ref><ref id="bib23"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Lv</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020b</year>) <article-title>Discovering functional brain networks with 3D residual autoencoder (RESAE)</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2020: 23rd International Conference, Lima, Peru, October 4&#x02013;8, 2020, Proceedings, Part VII 23</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>498</fpage>&#x02013;<lpage>507</lpage>.</mixed-citation></ref><ref id="bib24"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Lv</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020c</year>) <article-title>Spatiotemporal attention autoencoder (STAAE) for ADHD classification</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02014;MICCAI 2020: 23rd International Conference, Lima, Peru, October 4&#x02013;8, 2020, Proceedings, Part VII 23</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>508</fpage>&#x02013;<lpage>17</lpage>.</mixed-citation></ref><ref id="bib25"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Dosovitskiy</surname> &#x000a0;<given-names>A</given-names></string-name>, <string-name><surname>Beyer</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Kolesnikov</surname> &#x000a0;<given-names>A</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020</year>) <article-title>An image is worth 16&#x000d7;16 words: transformers for image recognition at scale</article-title>. <pub-id pub-id-type="arxiv">arXiv:2010.11929</pub-id>.</mixed-citation></ref><ref id="bib26"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Du</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Guo</surname> &#x000a0;<given-names>L</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Topological similarity between artificial and biological neural networks</article-title>. In <source>2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1</fpage>&#x02013;<lpage>5</lpage>.</mixed-citation></ref><ref id="bib27"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Dubey</surname> &#x000a0;<given-names>A</given-names></string-name>, <string-name><surname>Jauhri</surname> &#x000a0;<given-names>A</given-names></string-name>, <string-name><surname>Pandey</surname> &#x000a0;<given-names>A</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>The llama 3 herd of models</article-title>. <pub-id pub-id-type="arxiv">arXiv:2407.21783</pub-id>.</mixed-citation></ref><ref id="bib28"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Fang</surname> &#x000a0;<given-names>T</given-names></string-name>, <string-name><surname>Qi</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Pan</surname> &#x000a0;<given-names>G.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Reconstructing perceptive images from brain activity by shape-semantic gan</article-title>. <source>Adv Neural Inf Process Syst</source>. <volume>33</volume>:<fpage>13038</fpage>&#x02013;<lpage>48</lpage>.</mixed-citation></ref><ref id="bib29"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Friston</surname> &#x000a0;<given-names>KJ</given-names></string-name>, <string-name><surname>Holmes</surname> &#x000a0;<given-names>AP</given-names></string-name>, <string-name><surname>Worsley</surname> &#x000a0;<given-names>KJ</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>1994</year>) <article-title>Statistical parametric maps in functional imaging: a general linear approach</article-title>. <source>Hum Brain Mapp</source>. <volume>2</volume>:<fpage>189</fpage>&#x02013;<lpage>210</lpage>.</mixed-citation></ref><ref id="bib30"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Gadgil</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Pfefferbaum</surname> &#x000a0;<given-names>A</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020</year>) <article-title>Spatio-temporal graph convolution for resting-state fMRI analysis</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2020: 23rd International Conference, Lima, Peru, October 4&#x02013;8, 2020, Proceedings, Part VII 23</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>528</fpage>&#x02013;<lpage>38</lpage>.</mixed-citation></ref><ref id="bib31"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Gauthier</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Ivanova</surname> &#x000a0;<given-names>A.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Does the brain represent words? An evaluation of brain decoding studies of language understanding</article-title>. <pub-id pub-id-type="arxiv">arXiv:1806.00591</pub-id>.</mixed-citation></ref><ref id="bib32"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Goodfellow</surname> &#x000a0;<given-names>I</given-names></string-name>, <string-name><surname>Bengio</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Courville</surname> &#x000a0;<given-names>A.</given-names></string-name></person-group> (<year>2016</year>). <source>Deep Learning</source>, <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="bib33"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>He</surname> &#x000a0;<given-names>K</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Xie</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Masked autoencoders are scalable vision learners</article-title>. In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>. <publisher-loc>New Orleans, LA</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>16000</fpage>&#x02013;<lpage>9</lpage>.</mixed-citation></ref><ref id="bib34"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>He</surname> &#x000a0;<given-names>K</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Ren</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2016</year>) <article-title>Deep residual learning for image recognition</article-title>. In <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>. <publisher-loc>Las Vegas, NV</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>770</fpage>&#x02013;<lpage>8</lpage>.</mixed-citation></ref><ref id="bib35"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Heeger</surname> &#x000a0;<given-names>DJ</given-names></string-name>, <string-name><surname>Ress</surname> &#x000a0;<given-names>D.</given-names></string-name></person-group> (<year>2002</year>) <article-title>What does fMRI tell us about neuronal activity?</article-title>. <source>Nat Rev Neurosci</source>. <volume>3</volume>:<fpage>142</fpage>&#x02013;<lpage>51</lpage>.<pub-id pub-id-type="pmid">11836522</pub-id>
</mixed-citation></ref><ref id="bib36"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hinton</surname> &#x000a0;<given-names>GE</given-names></string-name>, <string-name><surname>Salakhutdinov</surname> &#x000a0;<given-names>RR.</given-names></string-name></person-group> (<year>2006</year>) <article-title>Reducing the dimensionality of data with neural networks</article-title>. <source>Science</source>. <volume>313</volume>:<fpage>504</fpage>&#x02013;<lpage>7</lpage>.<pub-id pub-id-type="pmid">16873662</pub-id>
</mixed-citation></ref><ref id="bib37"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hinton</surname> &#x000a0;<given-names>GE.</given-names></string-name>
</person-group> (<year>2009</year>) <article-title>Deep belief networks</article-title>. <source>Scholarpedia</source>. <volume>4</volume>:<fpage>5947</fpage>.</mixed-citation></ref><ref id="bib38"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hochreiter</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname> &#x000a0;<given-names>J.</given-names></string-name></person-group> (<year>1997</year>) <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>. <volume>9</volume>:<fpage>1735</fpage>&#x02013;<lpage>80</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id>
</mixed-citation></ref><ref id="bib39"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Peng</surname> &#x000a0;<given-names>B</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018</year>) <article-title>Latent source mining in fmri via restricted boltzmann machine</article-title>. <source>Hum Brain Mapp</source>. <volume>39</volume>:<fpage>2368</fpage>&#x02013;<lpage>80</lpage>.<pub-id pub-id-type="pmid">29457314</pub-id>
</mixed-citation></ref><ref id="bib40"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Hu</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>W</given-names></string-name>, <string-name><surname>Yuan</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2025</year>) <article-title>Synthesizing realistic fMRI: a physiological dynamics-driven hierarchical diffusion model for efficient fmri acquisition</article-title>. In <source>The Thirteenth International Conference on Learning Representations</source>.</mixed-citation></ref><ref id="bib41"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018</year>) <article-title>Modeling task fMRI data via mixture of deep expert networks</article-title>. In <source>2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>82</fpage>&#x02013;<lpage>6</lpage>.</mixed-citation></ref><ref id="bib42"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Han</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2016</year>) <article-title>Latent source mining in fMRI data via deep neural network</article-title>. In <source>2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>638</fpage>&#x02013;<lpage>41</lpage>.</mixed-citation></ref><ref id="bib43"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2017</year>) <article-title>Modeling task fmri data via deep convolutional autoencoder</article-title>. <source>IEEE Trans Med Imaging</source>. <volume>37</volume>:<fpage>1551</fpage>&#x02013;<lpage>61</lpage>.<pub-id pub-id-type="pmid">28641247</pub-id>
</mixed-citation></ref><ref id="bib44"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Jiang</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Yan</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Characterizing functional brain networks via spatio-temporal attention 4D convolutional neural networks (STA-4DCNNs)</article-title>. <source>Neural Netw</source>. <volume>158</volume>:<fpage>99</fpage>&#x02013;<lpage>110</lpage>.<pub-id pub-id-type="pmid">36446159</pub-id>
</mixed-citation></ref><ref id="bib45"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Kim</surname> &#x000a0;<given-names>P</given-names></string-name>, <string-name><surname>Kwon</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Joo</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Swift: Swin 4D fMRI transformer</article-title>. <source>Adv Neural Inf Process Syst</source>. <volume>36</volume>:<fpage>42015</fpage>&#x02013;<lpage>37</lpage>.</mixed-citation></ref><ref id="bib46"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Kriegeskorte</surname> &#x000a0;<given-names>N.</given-names></string-name>
</person-group> (<year>2015</year>) <article-title>Deep neural networks: a new framework for modeling biological vision and brain information processing</article-title>. <source>Annu Rev Vis Sci</source>. <volume>1</volume>:<fpage>417</fpage>&#x02013;<lpage>46</lpage>.<pub-id pub-id-type="pmid">28532370</pub-id>
</mixed-citation></ref><ref id="bib47"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>LeCun</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Bengio</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>1995</year>) <article-title>Convolutional networks for images, speech, and time series</article-title>. <source>BHB or HBBN</source>. <volume>3361</volume>:<fpage>1995</fpage>.</mixed-citation></ref><ref id="bib48"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>LeCun</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Bengio</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Hinton</surname> &#x000a0;<given-names>G.</given-names></string-name></person-group> (<year>2015</year>) <article-title>Deep learning</article-title>. <source>Nature</source>. <volume>521</volume>:<fpage>436</fpage>&#x02013;<lpage>44</lpage>.<pub-id pub-id-type="pmid">26017442</pub-id>
</mixed-citation></ref><ref id="bib49"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018a</year>) <article-title>Latent source mining of fMRI data via deep belief network</article-title>. In <source>2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>595</fpage>&#x02013;<lpage>8</lpage>.</mixed-citation></ref><ref id="bib50"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>F</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Simultaneous spatial-temporal decomposition of connectome-scale brain networks by deep sparse recurrent auto-encoders</article-title>. In <source>Information Processing in Medical Imaging: 26th International Conference, IPMI 2019, Hong Kong, China, June 2&#x02013;7, 2019, Proceedings 26</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>579</fpage>&#x02013;<lpage>91</lpage>.</mixed-citation></ref><ref id="bib51"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>T.</given-names></string-name></person-group> (<year>2021a</year>) <article-title>Differentiable neural architecture search for optimal spatial/temporal brain function network decomposition</article-title>. <source>Med Image Anal</source>. <volume>69</volume>:<fpage>101974</fpage>.<pub-id pub-id-type="pmid">33588118</pub-id>
</mixed-citation></ref><ref id="bib52"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name>, <string-name><surname>Lv</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020</year>) <article-title>Neural architecture search for optimization of spatial-temporal brain network decomposition</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2020: 23rd International Conference, Lima, Peru, October 4&#x02013;8, 2020, Proceedings, Part VII 23</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>377</fpage>&#x02013;<lpage>86</lpage>.</mixed-citation></ref><ref id="bib53"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021b</year>) <article-title>Evolutional neural architecture search for optimization of spatiotemporal brain network decomposition</article-title>. <source>IEEE Trans Biomed Eng</source>. <volume>69</volume>:<fpage>624</fpage>&#x02013;<lpage>34</lpage>.</mixed-citation></ref><ref id="bib54"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Anumanchipalli</surname> &#x000a0;<given-names>GK</given-names></string-name>, <string-name><surname>Mohamed</surname> &#x000a0;<given-names>A</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Dissecting neural computations in the human auditory pathway using deep neural networks for speech</article-title>. <source>Nat Neurosci</source>. <volume>26</volume>:<fpage>2213</fpage>&#x02013;<lpage>25</lpage>.<pub-id pub-id-type="pmid">37904043</pub-id>
</mixed-citation></ref><ref id="bib55"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018b</year>) <article-title>Deep neural networks for exploration of transcriptome of adult mouse brain</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinf</source>. <volume>17</volume>:<issue>2</issue>:<fpage>536</fpage>&#x02013;<lpage>46</lpage>.</mixed-citation></ref><ref id="bib56"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Simonyan</surname> &#x000a0;<given-names>K</given-names></string-name>, <string-name><surname>Yang</surname> &#x000a0;<given-names>Y.</given-names></string-name></person-group> (<year>2018</year>) <article-title>Darts: differentiable architecture search</article-title>. <pub-id pub-id-type="arxiv">arXiv:1806.09055</pub-id>.</mixed-citation></ref><ref id="bib57"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Jiang</surname> &#x000a0;<given-names>X</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>The cerebral cortex is bisectionally segregated into two fundamentally different functional units of gyri and sulci</article-title>. <source>Cereb Cortex</source>. <volume>29</volume>:<fpage>4238</fpage>&#x02013;<lpage>52</lpage>.<pub-id pub-id-type="pmid">30541110</pub-id>
</mixed-citation></ref><ref id="bib58"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023a</year>) <article-title>An ASD classification based on a pseudo 4D resnet: utilizing spatial and temporal convolution</article-title>. <source>IEEE Syst Man Cybern Mag</source>. <volume>9</volume>:<fpage>9</fpage>&#x02013;<lpage>18</lpage>.</mixed-citation></ref><ref id="bib59"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Zhou</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Shi</surname> &#x000a0;<given-names>G</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group>, (<year>2023b</year>) <article-title>Coupling artificial neurons in bert and biological neurons in the human brain</article-title>. In <source>Proceedings of the AAAI Conference on Artificial Intelligence</source>, Vol. <volume>37</volume>, <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>AAAI Press</publisher-name>, <fpage>8888</fpage>&#x02013;<lpage>96</lpage>.</mixed-citation></ref><ref id="bib60"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>E</given-names></string-name>, <string-name><surname>He</surname> &#x000a0;<given-names>M</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024a</year>) <article-title>Mapping dynamic spatial patterns of brain function with spatial-wise attention</article-title>. <source>J Neural Eng</source>. <volume>21</volume>:<issue>2</issue>:<fpage>026005</fpage>.</mixed-citation></ref><ref id="bib61"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>E</given-names></string-name>, <string-name><surname>Kang</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024b</year>) <article-title>Spatial-temporal convolutional attention for discovering and characterizing functional brain networks in task fmri</article-title>. <source>Neuroimage</source>. <volume>287</volume>:<fpage>120519</fpage>.<pub-id pub-id-type="pmid">38280690</pub-id>
</mixed-citation></ref><ref id="bib62"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>E</given-names></string-name>, <string-name><surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023c</year>) <article-title>Spatial-temporal convolutional attention for mapping functional brain networks</article-title>. In <source>2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Cartagena, Colombia</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1</fpage>&#x02013;<lpage>4</lpage>.</mixed-citation></ref><ref id="bib63"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Logothetis</surname> &#x000a0;<given-names>NK</given-names></string-name>, <string-name><surname>Pauls</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Augath</surname> &#x000a0;<given-names>M</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2001</year>) <article-title>Neurophysiological investigation of the basis of the fMRI signal</article-title>. <source>Nature</source>. <volume>412</volume>:<fpage>150</fpage>&#x02013;<lpage>7</lpage>.<pub-id pub-id-type="pmid">11449264</pub-id>
</mixed-citation></ref><ref id="bib64"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Logothetis</surname> &#x000a0;<given-names>NK.</given-names></string-name>
</person-group> (<year>2008</year>) <article-title>What we can do and what we cannot do with fMRI</article-title>. <source>Nature</source>. <volume>453</volume>:<fpage>869</fpage>&#x02013;<lpage>78</lpage>.<pub-id pub-id-type="pmid">18548064</pub-id>
</mixed-citation></ref><ref id="bib65"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lv</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Jiang</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>X</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2014</year>) <article-title>Holistic atlases of functional networks and interactions reveal reciprocal organizational architecture of cortical function</article-title>. <source>IEEE Trans Biomed Eng</source>. <volume>62</volume>:<fpage>1120</fpage>&#x02013;<lpage>31</lpage>.<pub-id pub-id-type="pmid">25420254</pub-id>
</mixed-citation></ref><ref id="bib66"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lv</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Jiang</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>X</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2015</year>) <article-title>Sparse representation of whole-brain fmri signals for identification of functional networks</article-title>. <source>Med Image Anal</source>. <volume>20</volume>:<fpage>112</fpage>&#x02013;<lpage>34</lpage>.<pub-id pub-id-type="pmid">25476415</pub-id>
</mixed-citation></ref><ref id="bib67"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Lyu</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>GP-GPT: large language model for gene-phenotype mapping</article-title>. <pub-id pub-id-type="arxiv">arXiv:2409.09825</pub-id>.</mixed-citation></ref><ref id="bib68"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Makkie</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Fast and scalable distributed deep convolutional autoencoder for fMRI big data analytics</article-title>. <source>Neurocomputing</source>. <volume>325</volume>:<fpage>20</fpage>&#x02013;<lpage>30</lpage>.<pub-id pub-id-type="pmid">31354187</pub-id>
</mixed-citation></ref><ref id="bib69"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Malkiel</surname> &#x000a0;<given-names>I</given-names></string-name>, <string-name><surname>Rosenman</surname> &#x000a0;<given-names>G</given-names></string-name>, <string-name><surname>Wolf</surname> &#x000a0;<given-names>L</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Self-supervised transformers for fmri representation</article-title>. In <source>International Conference on Medical Imaging with Deep Learning</source>. <publisher-loc>Z&#x000fc;rich, Switzerland</publisher-loc>: <publisher-name>PMLR</publisher-name>, <fpage>895</fpage>&#x02013;<lpage>913</lpage>.</mixed-citation></ref><ref id="bib70"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Mao</surname> &#x000a0;<given-names>W</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>He</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>Brain structural connectivity guided vision transformers for identification of functional connectivity characteristics in preterm neonates</article-title>. <source>IEEE J Biomed Health Inform</source>. <volume>28</volume>:<fpage>2223</fpage>&#x02013;<lpage>34</lpage>.<pub-id pub-id-type="pmid">38285570</pub-id>
</mixed-citation></ref><ref id="bib71"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Mao</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Su</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Xu</surname> &#x000a0;<given-names>G</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Spatio-temporal deep learning method for ADHD fMRI classification</article-title>. <source>Inf Sci</source>. <volume>499</volume>:<fpage>1</fpage>&#x02013;<lpage>11</lpage>.</mixed-citation></ref><ref id="bib72"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Millet</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Caucheteux</surname> &#x000a0;<given-names>C</given-names></string-name>, <string-name><surname>Boubenec</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Toward a realistic model of speech processing in the brain with self-supervised learning</article-title>. <source>Adv Neural Inf Process Syst</source>. <volume>35</volume>:<fpage>33428</fpage>&#x02013;<lpage>43</lpage>.</mixed-citation></ref><ref id="bib73"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>O'Craven</surname> &#x000a0;<given-names>KM</given-names></string-name>, <string-name><surname>Downing</surname> &#x000a0;<given-names>PE</given-names></string-name>, <string-name><surname>Kanwisher</surname> &#x000a0;<given-names>N.</given-names></string-name></person-group> (<year>1999</year>) <article-title>fMRI evidence for objects as the units of attentional selection</article-title>. <source>Nature</source>. <volume>401</volume>:<fpage>584</fpage>&#x02013;<lpage>7</lpage>.<pub-id pub-id-type="pmid">10524624</pub-id>
</mixed-citation></ref><ref id="bib74"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Oquab</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Darcet</surname> &#x000a0;<given-names>T</given-names></string-name>, <string-name><surname>Moutakanni</surname> &#x000a0;<given-names>T</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Dinov2: learning robust visual features without supervision</article-title>. <pub-id pub-id-type="arxiv">arXiv:2304.07193</pub-id>.</mixed-citation></ref><ref id="bib75"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Ortega&#x000a0;Caro</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Oliveira&#x000a0;Fonseca</surname> &#x000a0;<given-names>AH</given-names></string-name>, <string-name><surname>Averill</surname> &#x000a0;<given-names>C</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>Brainlm: a foundation model for brain activity recordings</article-title>. <source>The Twelfth International Conference on Learning Representations</source>, <publisher-loc>Vienna, Austria</publisher-loc>: <publisher-name>ICLR 2024</publisher-name>.</mixed-citation></ref><ref id="bib76"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Pang</surname> &#x000a0;<given-names>T</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Han</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022a</year>) <article-title>Gumbel- softmax based neural architecture search for hierarchical brain networks decomposition</article-title>. <source>Med Image Anal</source>. <volume>82</volume>:<fpage>102570</fpage>.<pub-id pub-id-type="pmid">36055050</pub-id>
</mixed-citation></ref><ref id="bib77"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Pang</surname> &#x000a0;<given-names>T</given-names></string-name>, <string-name><surname>Zhu</surname> &#x000a0;<given-names>D</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>T</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022b</year>) <article-title>Hierarchical brain networks decomposition via prior knowledge guided deep belief network</article-title>. In <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>251</fpage>&#x02013;<lpage>60</lpage>.</mixed-citation></ref><ref id="bib78"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Pei</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>C</given-names></string-name>, <string-name><surname>Cao</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Data augmentation for fmri- based functional connectivity and its application to cross-site adhd classification</article-title>. <source>IEEE Trans Instrum Meas</source>. <volume>72</volume>:<fpage>1</fpage>&#x02013;<lpage>15</lpage>.</mixed-citation></ref><ref id="bib79"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Power</surname> &#x000a0;<given-names>JD</given-names></string-name>, <string-name><surname>Cohen</surname> &#x000a0;<given-names>AL</given-names></string-name>, <string-name><surname>Nelson</surname> &#x000a0;<given-names>SM</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2011</year>) <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source>. <volume>72</volume>:<fpage>665</fpage>&#x02013;<lpage>78</lpage>.<pub-id pub-id-type="pmid">22099467</pub-id>
</mixed-citation></ref><ref id="bib80"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Liang</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021</year>) <article-title>Modeling and augmenting of fmri data using deep recurrent variational auto-encoder</article-title>. <source>J Neural Eng</source>. <volume>18</volume>:<fpage>0460b6</fpage>.</mixed-citation></ref><ref id="bib81"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Liang</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Learning brain representation using recurrent wasserstein generative adversarial net</article-title>. <source>Comput Methods Programs Biomed</source>. <volume>223</volume>:<fpage>106979</fpage>.<pub-id pub-id-type="pmid">35792364</pub-id>
</mixed-citation></ref><ref id="bib82"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Sun</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020a</year>) <article-title>Deep variational autoencoder for modeling functional brain networks and ADHD identification</article-title>. In <source>2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>554</fpage>&#x02013;<lpage>7</lpage>.</mixed-citation></ref><ref id="bib83"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020b</year>) <article-title>Modeling task-based fMRI data via deep belief network with neural architecture search</article-title>. <source>Comput Med Imaging Graph</source>. <volume>83</volume>:<fpage>101747</fpage>.<pub-id pub-id-type="pmid">32593949</pub-id>
</mixed-citation></ref><ref id="bib84"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Qiang</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Gao</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Functional brain network identification and fMRI augmentation using a VAE-GAN framework</article-title>. <source>Comput Biol Med</source>. <volume>165</volume>:<fpage>107395</fpage>.<pub-id pub-id-type="pmid">37669583</pub-id>
</mixed-citation></ref><ref id="bib85"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Radford</surname> &#x000a0;<given-names>A</given-names></string-name>, <string-name><surname>Narasimhan</surname> &#x000a0;<given-names>K</given-names></string-name>, <string-name><surname>Salimans</surname> &#x000a0;<given-names>T</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018</year>) <article-title>Improving language understanding by generative pre-training</article-title>. <comment><ext-link xlink:href="https://www.mikecaptain.com/resources/pdf/GPT-1.pdf" ext-link-type="uri">https://www.mikecaptain.com/resources/pdf/GPT-1.pdf</ext-link></comment></mixed-citation></ref><ref id="bib86"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Raichle</surname> &#x000a0;<given-names>ME</given-names></string-name>, <string-name><surname>MacLeod</surname> &#x000a0;<given-names>AM</given-names></string-name>, <string-name><surname>Snyder</surname> &#x000a0;<given-names>AZ</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2001</year>) <article-title>A default mode of brain function</article-title>. <source>Proc Natl Acad Sci</source>. <volume>98</volume>:<fpage>676</fpage>&#x02013;<lpage>82</lpage>.<pub-id pub-id-type="pmid">11209064</pub-id>
</mixed-citation></ref><ref id="bib87"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Ren</surname> &#x000a0;<given-names>D</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2017</year>) <article-title>3-D functional brain network classification using convolutional neural networks</article-title>. In <source>2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1217</fpage>&#x02013;<lpage>21</lpage>.</mixed-citation></ref><ref id="bib88"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Ren</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Tao</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021</year>) <article-title>Modeling hierarchical spatial and temporal patterns of naturalistic fMRI volume via volumetric deep belief network with neural architecture search</article-title>. In <source>2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>130</fpage>&#x02013;<lpage>4</lpage>.</mixed-citation></ref><ref id="bib89"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Scarselli</surname> &#x000a0;<given-names>F</given-names></string-name>, <string-name><surname>Gori</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Chung&#x000a0;Tsoi</surname> &#x000a0;<given-names>Ah</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2008</year>) <article-title>The graph neural network model</article-title>. <source>IEEE Trans Neural Netw</source>. <volume>20</volume>:<fpage>61</fpage>&#x02013;<lpage>80</lpage>.<pub-id pub-id-type="pmid">19068426</pub-id>
</mixed-citation></ref><ref id="bib90"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Schrimpf</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Blank</surname> &#x000a0;<given-names>IA</given-names></string-name>, <string-name><surname>Tuckute</surname> &#x000a0;<given-names>G</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021</year>) <article-title>The neural architecture of language: integrative modeling converges on predictive processing</article-title>. <source>Proc Natl Acad Sci</source>. <volume>118</volume>:<fpage>e2105646118</fpage>.<pub-id pub-id-type="pmid">34737231</pub-id>
</mixed-citation></ref><ref id="bib91"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Smucny</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Shi</surname> &#x000a0;<given-names>G</given-names></string-name>, <string-name><surname>Lesh</surname> &#x000a0;<given-names>TA</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Data augmentation with mixup: enhancing performance of a functional neuroimaging-based prognostic deep learning classifier in recent onset psychosis</article-title>. <source>NeuroImage Clinical</source>. <volume>36</volume>:<fpage>103214</fpage>.<pub-id pub-id-type="pmid">36183611</pub-id>
</mixed-citation></ref><ref id="bib92"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Svanera</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Savardi</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Benini</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Transfer learning of deep neural network representations for fMRI decoding</article-title>. <source>J Neurosci Methods</source>. <volume>328</volume>:<fpage>108319</fpage>.<pub-id pub-id-type="pmid">31585315</pub-id>
</mixed-citation></ref><ref id="bib93"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Takagi</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Nishimoto</surname> &#x000a0;<given-names>S.</given-names></string-name></person-group> (<year>2023</year>) <article-title>High-resolution image reconstruction with latent diffusion models from human brain activity</article-title>. In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>. <publisher-loc>Vancouver, BC</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>14453</fpage>&#x02013;<lpage>63</lpage>.</mixed-citation></ref><ref id="bib94"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Thomas</surname> &#x000a0;<given-names>A</given-names></string-name>, <string-name><surname>R&#x000b4;e</surname> &#x000a0;<given-names>C</given-names></string-name>, <string-name><surname>Poldrack</surname> &#x000a0;<given-names>R.</given-names></string-name></person-group> (<year>2022</year>) <article-title>Self-supervised learning of brain dynamics from broad neuroimaging data</article-title>. <source>Adv Neural Inf Process Syst</source>. <volume>35</volume>:<fpage>21255</fpage>&#x02013;<lpage>69</lpage>.</mixed-citation></ref><ref id="bib95"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Van&#x000a0;Den&#x000a0;Heuvel</surname> &#x000a0;<given-names>MP</given-names></string-name>, <string-name><surname>Hulshoff&#x000a0;Pol</surname> &#x000a0;<given-names>HE.</given-names></string-name></person-group> (<year>2010</year>) <article-title>Exploring the brain network: a review on resting-state fMRI functional connectivity</article-title>. <source>Eur Neuropsychopharmacol</source>. <volume>20</volume>:<fpage>519</fpage>&#x02013;<lpage>34</lpage>.<pub-id pub-id-type="pmid">20471808</pub-id>
</mixed-citation></ref><ref id="bib96"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Vaswani</surname> &#x000a0;<given-names>A</given-names></string-name>, <string-name><surname>Shazeer</surname> &#x000a0;<given-names>N</given-names></string-name>, <string-name><surname>Parmar</surname> &#x000a0;<given-names>N</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2017</year>) <article-title>Attention is all you need</article-title>. <source>Adv Neural Inf Process Syst</source>. <volume>30</volume>, <comment><ext-link xlink:href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" ext-link-type="uri">https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html</ext-link></comment></mixed-citation></ref><ref id="bib97"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Von&#x000a0;Der&#x000a0;Malsburg</surname> &#x000a0;<given-names>C.</given-names></string-name>
</person-group> (<year>1994</year>) <article-title>The correlation theory of brain function</article-title>. In <source>Models of Neural Networks: Temporal Aspects of Coding and Information Processing in Biological Systems</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>95</fpage>&#x02013;<lpage>119</lpage>.</mixed-citation></ref><ref id="bib98"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018</year>) <article-title>Recognizing brain states using deep sparse recurrent neural network</article-title>. <source>IEEE Trans Med Imaging</source>. <volume>38</volume>:<fpage>1058</fpage>&#x02013;<lpage>68</lpage>.<pub-id pub-id-type="pmid">30369441</pub-id>
</mixed-citation></ref><ref id="bib99"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Explore the hierarchical auditory information processing via deep convolutional autoencoder</article-title>. In <source>2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1788</fpage>&#x02013;<lpage>91</lpage>.</mixed-citation></ref><ref id="bib100"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Yang</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>Frequency-specific functional difference between gyri and sulci in naturalistic paradigm fmri</article-title>. <source>BS&#x00026;F</source>. <volume>229</volume>:<fpage>431</fpage>&#x02013;<lpage>442</lpage>.</mixed-citation></ref><ref id="bib101"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>He</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Modeling functional difference between gyri and sulci within intrinsic connectivity networks</article-title>. <source>Cereb Cortex</source>. <volume>33</volume>:<fpage>933</fpage>&#x02013;<lpage>47</lpage>.<pub-id pub-id-type="pmid">35332916</pub-id>
</mixed-citation></ref><ref id="bib102"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Worsley</surname> &#x000a0;<given-names>KJ.</given-names></string-name>
</person-group> (<year>1997</year>) <article-title>An overview and some new developments in the statistical analysis of pet and fmri data</article-title>. <source>Hum Brain Mapp</source>. <volume>5</volume>:<fpage>254</fpage>&#x02013;<lpage>8</lpage>.<pub-id pub-id-type="pmid">20408225</pub-id>
</mixed-citation></ref><ref id="bib103"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Pan</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>F</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2020</year>) <article-title>A comprehensive survey on graph neural networks</article-title>. <source>IEEE Trans Neural Netw Learning Syst</source>. <volume>32</volume>:<fpage>4</fpage>&#x02013;<lpage>24</lpage>.</mixed-citation></ref><ref id="bib104"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yamins</surname> &#x000a0;<given-names>DL</given-names></string-name>, <string-name><surname>DiCarlo</surname> &#x000a0;<given-names>JJ.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Using goal-driven deep learning models to understand sensory cortex</article-title>. <source>Nat Neurosci</source>. <volume>19</volume>:<fpage>356</fpage>&#x02013;<lpage>65</lpage>.<pub-id pub-id-type="pmid">26906502</pub-id>
</mixed-citation></ref><ref id="bib105"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yan</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Xiao</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Modeling spatio-temporal patterns of holistic functional brain networks via multi-head guided attention graph neural networks (multi-head GAGNNs)</article-title>. <source>Med Image Anal</source>. <volume>80</volume>:<fpage>102518</fpage>.<pub-id pub-id-type="pmid">35749981</pub-id>
</mixed-citation></ref><ref id="bib106"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Yan</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021a</year>) <article-title>Multi- head GAGNN: a multi-head guided attention graph neural network for modeling spatio-temporal patterns of holistic brain functional networks</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2021: 24th International Conference, Strasbourg, France, September 27&#x02013; October 1, 2021, Proceedings, Part VII 24</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>564</fpage>&#x02013;<lpage>73</lpage>.</mixed-citation></ref><ref id="bib107"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Yan</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Jiang</surname> &#x000a0;<given-names>M</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021b</year>) <article-title>A guided attention 4D convolutional neural network for modeling spatio-temporal patterns of functional brain networks</article-title>. In <source>Pattern Recognition and Computer Vision: 4th Chinese Conference, PRCV 2021, Beijing, China, October 29&#x02013;November 1, 2021, Proceedings, Part III 4</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>350</fpage>&#x02013;<lpage>61</lpage>.</mixed-citation></ref><ref id="bib108"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Yang</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Mao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>X</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>Brainmae: a region-aware self-supervised learning framework for brain signals</article-title>. <pub-id pub-id-type="arxiv">arXiv:2406.17086</pub-id>.</mixed-citation></ref><ref id="bib109"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yu</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Shi</surname> &#x000a0;<given-names>E</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>R</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>A hybrid learning framework for fine-grained interpretation of brain spatiotemporal patterns during naturalistic functional magnetic resonance imaging</article-title>. <source>Front Hum Neurosci</source>. <volume>16</volume>:<fpage>944543</fpage>.<pub-id pub-id-type="pmid">36248685</pub-id>
</mixed-citation></ref><ref id="bib110"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Yu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>Cp- clip: core-periphery feature alignment clip for zero-shot medical image analysis</article-title>. In <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>88</fpage>&#x02013;<lpage>97</lpage>.</mixed-citation></ref><ref id="bib111"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Yu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023a</year>) <article-title>Core-periphery principle guided redesign of self- attention in transformers</article-title>. <pub-id pub-id-type="arxiv">arXiv:2303.15569</pub-id>.</mixed-citation></ref><ref id="bib112"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Yu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023b</year>) <article-title>Gyri vs. sulci: disentangling brain core-periphery functional networks via twin-transformer</article-title>. <pub-id pub-id-type="arxiv">arXiv:2302.00146</pub-id></mixed-citation></ref><ref id="bib113"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Yu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Lyu</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023c</year>) <article-title>Supervised deep tree in Alzheimer's disease</article-title>. In <source>2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1</fpage>&#x02013;<lpage>5</lpage>.</mixed-citation></ref><ref id="bib114"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yuan</surname> &#x000a0;<given-names>J</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018</year>) <article-title>Spatio-temporal modeling of connectome-scale brain network interactions via time-evolving graphs</article-title>. <source>Neuroimage</source>. <volume>180</volume>:<fpage>350</fpage>&#x02013;<lpage>69</lpage>.<pub-id pub-id-type="pmid">29102809</pub-id>
</mixed-citation></ref><ref id="bib115"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>P-H</given-names></string-name>, <string-name><surname>Ramadge</surname> &#x000a0;<given-names>P.</given-names></string-name></person-group> (<year>2018a</year>) <article-title>Transfer learning on fmri datasets</article-title>. In <source>International Conference on Artificial Intelligence and Statistics</source>. <publisher-name>PMLR</publisher-name>, <fpage>595</fpage>&#x02013;<lpage>603</lpage>.</mixed-citation></ref><ref id="bib116"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Gao</surname> &#x000a0;<given-names>J</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021a</year>) <article-title>Deep fusion of brain structure- function in mild cognitive impairment</article-title>. <source>Med Image Anal</source>. <volume>72</volume>:<fpage>102082</fpage>.<pub-id pub-id-type="pmid">34004495</pub-id>
</mixed-citation></ref><ref id="bib117"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Wang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>T</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021b</year>) <article-title>Disease2vec: representing Alzheimer's progression via disease embedding tree</article-title>. <pub-id pub-id-type="arxiv">arXiv:2102.06847</pub-id>.</mixed-citation></ref><ref id="bib118"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Yu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Lyu</surname> &#x000a0;<given-names>Y</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Representative functional connectivity learning for multiple clinical groups in Alzheimer's disease</article-title>. In <source>2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1</fpage>&#x02013;<lpage>5</lpage>.</mixed-citation></ref><ref id="bib119"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019a</year>) <article-title>Discovering hierarchical common brain networks via multimodal deep belief network</article-title>. <source>Med Image Anal</source>. <volume>54</volume>:<fpage>238</fpage>&#x02013;<lpage>52</lpage>.<pub-id pub-id-type="pmid">30954851</pub-id>
</mixed-citation></ref><ref id="bib120"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>S</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Huang</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018b</year>) <article-title>Deep learning models unveiled functional difference between cortical gyri and sulci</article-title>. <source>IEEE Trans Biomed Eng</source>. <volume>66</volume>:<fpage>1297</fpage>&#x02013;<lpage>308</lpage>.<pub-id pub-id-type="pmid">30281424</pub-id>
</mixed-citation></ref><ref id="bib121"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name>, <string-name><surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>Q</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019b</year>) <article-title>Identify hierarchical structures from task-based fMRI data via hybrid spatiotemporal neural architecture search net</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13&#x02013;17, 2019, Proceedings, Part III 22</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>745</fpage>&#x02013;<lpage>53</lpage>.</mixed-citation></ref><ref id="bib122"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Hu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>He</surname> &#x000a0;<given-names>C</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019c</year>) <article-title>A two-stage DBN-based method to exploring functional brain networks in naturalistic paradigm fMRI</article-title>. In <source>2019 Ieee 16th International Symposium on Biomedical Imaging (Isbi 2019)</source>. <publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1594</fpage>&#x02013;<lpage>7</lpage>.</mixed-citation></ref><ref id="bib123"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Jiang</surname> &#x000a0;<given-names>X</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2021</year>) <article-title>Exploring the functional difference of gyri/sulci via hierarchical interpretable autoencoder</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2021: 24th International Conference, Strasbourg, France, September 27&#x02013; October 1, 2021, Proceedings, Part VII 24</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>701</fpage>&#x02013;<lpage>9</lpage>.</mixed-citation></ref><ref id="bib124"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023a</year>) <article-title>Coupling visual semantics of artificial neural networks and human brain function via synchronized activations</article-title>. <source>IEEE Trans Cogn Dev Syst</source>. <volume>16</volume>:<fpage>584</fpage>&#x02013;<lpage>94</lpage>.</mixed-citation></ref><ref id="bib125"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023b</year>) <article-title>CP-CNN: core- periphery principle guided convolutional neural network</article-title>. <pub-id pub-id-type="arxiv">arXiv:2304.10515</pub-id>.</mixed-citation></ref><ref id="bib126"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2024</year>) <article-title>Hierarchical functional differences between gyri and sulci at different scales</article-title>. <source>Cereb Cortex</source>. <volume>34</volume>:<fpage>bhae057</fpage>.<pub-id pub-id-type="pmid">38483143</pub-id>
</mixed-citation></ref><ref id="bib127"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2022</year>) <article-title>Embedding human brain function via Transformer</article-title>. In <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>366</fpage>&#x02013;<lpage>75</lpage>.</mixed-citation></ref><ref id="bib128"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023c</year>) <article-title>A generic framework for embedding human brain function with temporally correlated autoencoder</article-title>. <source>Med Image Anal</source>. <volume>89</volume>:<fpage>102892</fpage>.<pub-id pub-id-type="pmid">37482031</pub-id>
</mixed-citation></ref><ref id="bib129"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>L</given-names></string-name>, <string-name><surname>Wu</surname> &#x000a0;<given-names>Z</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023d</year>) <article-title>When brain-inspired AI meets AGI</article-title>. <source>Meta-Radiology</source>. <volume>1</volume>:<fpage>100005</fpage>, </mixed-citation></ref><ref id="bib130"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Dai</surname> &#x000a0;<given-names>H</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2019</year>) <article-title>Two-stage spatial temporal deep learning framework for functional brain network modeling</article-title>. In <source>2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)</source>. <publisher-loc>Venice, Italy</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1576</fpage>&#x02013;<lpage>80</lpage>.</mixed-citation></ref><ref id="bib131"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Chen</surname> &#x000a0;<given-names>H</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2017a</year>) <article-title>Constructing fine-granularity functional brain network atlases via deep convolutional autoencoder</article-title>. <source>Med Image Anal</source>. <volume>42</volume>:<fpage>200</fpage>&#x02013;<lpage>11</lpage>.<pub-id pub-id-type="pmid">28843214</pub-id>
</mixed-citation></ref><ref id="bib132"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Dong</surname> &#x000a0;<given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2017b</year>) <article-title>Automatic recognition of fMRI-derived functional networks using 3-D convolutional neural networks</article-title>. <source>IEEE Trans Biomed Eng</source>. <volume>65</volume>:<fpage>1975</fpage>&#x02013;<lpage>84</lpage>.<pub-id pub-id-type="pmid">28641239</pub-id>
</mixed-citation></ref><ref id="bib133"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>F</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>T.</given-names></string-name></person-group> (<year>2018a</year>) <article-title>Automatic recognition of holistic functional brain networks using iteratively optimized convolutional neural networks (IO-CNN) with weak label initialization</article-title>. <source>Med Image Anal</source>. <volume>47</volume>:<fpage>111</fpage>&#x02013;<lpage>26</lpage>.<pub-id pub-id-type="pmid">29705574</pub-id>
</mixed-citation></ref><ref id="bib134"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Ge</surname> &#x000a0;<given-names>F</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>S</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018b</year>) <article-title>3D deep convolutional neural network revealed the value of brain network overlap in differentiating autism spectrum disorder from healthy controls</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02013;MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part III 11</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>172</fpage>&#x02013;<lpage>80</lpage>.</mixed-citation></ref><ref id="bib135"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhao</surname> &#x000a0;<given-names>Y</given-names></string-name>, <string-name><surname>Li</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname> &#x000a0;<given-names>W</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2018c</year>) <article-title>Modeling 4D fMRI data via spatio-temporal convolutional neural networks (ST-CNN)</article-title>. In <source>Medical Image Computing and Computer Assisted Intervention&#x02014;MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part III 11</source>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>181</fpage>&#x02013;<lpage>9</lpage>.</mixed-citation></ref><ref id="bib136"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhou</surname> &#x000a0;<given-names>M</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>X</given-names></string-name>, <string-name><surname>Liu</surname> &#x000a0;<given-names>D</given-names></string-name> &#x000a0;<etal>et al.</etal></person-group> (<year>2023</year>) <article-title>Fine-grained artificial neurons in audio-transformers for disentangling neural auditory encoding</article-title>. In <source>Findings of the Association for Computational Linguistics: ACL 2023</source>. <publisher-loc>Toronto, Canada</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>, <fpage>7943</fpage>&#x02013;<lpage>56</lpage>.</mixed-citation></ref><ref id="bib137"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Zhuang</surname> &#x000a0;<given-names>P</given-names></string-name>, <string-name><surname>Schwing</surname> &#x000a0;<given-names>AG</given-names></string-name>, <string-name><surname>Koyejo</surname> &#x000a0;<given-names>O.</given-names></string-name></person-group> (<year>2019</year>) <article-title>FMRI data augmentation via synthesis</article-title>. In <source>2019 IEEE 16th International symposium on Biomedical Imaging (ISBI 2019)</source>. <publisher-loc>Venice, Italy</publisher-loc>: <publisher-name>IEEE</publisher-name>, <fpage>1783</fpage>&#x02013;<lpage>7</lpage>.</mixed-citation></ref><ref id="bib138"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Zoph</surname> &#x000a0;<given-names>B</given-names></string-name>, <string-name><surname>Le</surname> &#x000a0;<given-names>QV.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Neural architecture search with reinforcement learning</article-title>. <pub-id pub-id-type="arxiv">arXiv:1611.01578</pub-id>.</mixed-citation></ref></ref-list></back></article>