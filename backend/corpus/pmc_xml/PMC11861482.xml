<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Gen Intern Med</journal-id><journal-id journal-id-type="iso-abbrev">J Gen Intern Med</journal-id><journal-title-group><journal-title>Journal of General Internal Medicine</journal-title></journal-title-group><issn pub-type="ppub">0884-8734</issn><issn pub-type="epub">1525-1497</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">39531100</article-id><article-id pub-id-type="pmc">PMC11861482</article-id>
<article-id pub-id-type="publisher-id">9102</article-id><article-id pub-id-type="doi">10.1007/s11606-024-09102-0</article-id><article-categories><subj-group subj-group-type="heading"><subject>Position Papers</subject></subj-group></article-categories><title-group><article-title>Recommendations for Clinicians, Technologists, and Healthcare Organizations on the Use of Generative Artificial Intelligence in Medicine: A Position Statement from the Society of General Internal Medicine</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9217-1533</contrib-id><name><surname>Crowe</surname><given-names>Byron</given-names></name><degrees>MD</degrees><address><email>bcrowe@bidmc.harvard.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Shah</surname><given-names>Shreya</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Teng</surname><given-names>Derek</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Ma</surname><given-names>Stephen P.</given-names></name><degrees>MD PhD</degrees><xref ref-type="aff" rid="Aff19">19</xref></contrib><contrib contrib-type="author"><name><surname>DeCamp</surname><given-names>Matthew</given-names></name><degrees>MD PhD</degrees><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Rosenberg</surname><given-names>Eric I.</given-names></name><degrees>MD, MSPH</degrees><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author"><name><surname>Rodriguez</surname><given-names>Jorge A.</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author"><name><surname>Collins</surname><given-names>Benjamin X.</given-names></name><degrees>MD MS MA</degrees><xref ref-type="aff" rid="Aff8">8</xref><xref ref-type="aff" rid="Aff22">22</xref></contrib><contrib contrib-type="author"><name><surname>Huber</surname><given-names>Kathryn</given-names></name><degrees>MD MS</degrees><xref ref-type="aff" rid="Aff9">9</xref></contrib><contrib contrib-type="author"><name><surname>Karches</surname><given-names>Kyle</given-names></name><degrees>MD PhD</degrees><xref ref-type="aff" rid="Aff10">10</xref></contrib><contrib contrib-type="author"><name><surname>Zucker</surname><given-names>Shana</given-names></name><degrees>MD MPH MS</degrees><xref ref-type="aff" rid="Aff11">11</xref></contrib><contrib contrib-type="author"><name><surname>Kim</surname><given-names>Eun Ji</given-names></name><degrees>MD MS MS</degrees><xref ref-type="aff" rid="Aff12">12</xref></contrib><contrib contrib-type="author"><name><surname>Rotenstein</surname><given-names>Lisa</given-names></name><degrees>MD MBA</degrees><xref ref-type="aff" rid="Aff13">13</xref></contrib><contrib contrib-type="author"><name><surname>Rodman</surname><given-names>Adam</given-names></name><degrees>MD MPH</degrees><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Jones</surname><given-names>Danielle</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="Aff14">14</xref></contrib><contrib contrib-type="author"><name><surname>Richman</surname><given-names>Ilana B.</given-names></name><degrees>MD, MHS</degrees><xref ref-type="aff" rid="Aff15">15</xref></contrib><contrib contrib-type="author"><name><surname>Henry</surname><given-names>Tracey L.</given-names></name><degrees>MD, MPH, MS</degrees><xref ref-type="aff" rid="Aff14">14</xref></contrib><contrib contrib-type="author"><name><surname>Somlo</surname><given-names>Diane</given-names></name><degrees>MD MBA</degrees><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff16">16</xref></contrib><contrib contrib-type="author"><name><surname>Pitts</surname><given-names>Samantha I.</given-names></name><degrees>MD MPH</degrees><xref ref-type="aff" rid="Aff17">17</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Jonathan H.</given-names></name><degrees>MD PhD</degrees><xref ref-type="aff" rid="Aff18">18</xref><xref ref-type="aff" rid="Aff19">19</xref><xref ref-type="aff" rid="Aff20">20</xref></contrib><contrib contrib-type="author"><name><surname>Mishuris</surname><given-names>Rebecca G.</given-names></name><degrees>MD MS MPH</degrees><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff7">7</xref><xref ref-type="aff" rid="Aff21">21</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04drvxt59</institution-id><institution-id institution-id-type="GRID">grid.239395.7</institution-id><institution-id institution-id-type="ISNI">0000 0000 9011 8547</institution-id><institution>Division of General Internal Medicine, </institution><institution>Beth Israel Deaconess Medical Center, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03vek6s52</institution-id><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution>Harvard Medical School, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00f54p054</institution-id><institution-id institution-id-type="GRID">grid.168010.e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8956</institution-id><institution>Department of Medicine, </institution><institution>Stanford University, </institution></institution-wrap>Palo Alto, CA USA </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00f54p054</institution-id><institution-id institution-id-type="GRID">grid.168010.e</institution-id><institution-id institution-id-type="ISNI">0000000419368956</institution-id><institution>Division of Primary Care and Population Health, </institution><institution>Stanford Healthcare AI Applied Research Team, Stanford University School of Medicine, </institution></institution-wrap>Palo Alto, CA USA </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03wmf1y16</institution-id><institution-id institution-id-type="GRID">grid.430503.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 0703 675X</institution-id><institution>Department of Medicine, </institution><institution>University of Colorado, </institution></institution-wrap>Aurora, CO USA </aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02y3ad647</institution-id><institution-id institution-id-type="GRID">grid.15276.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8091</institution-id><institution>Division of General Internal Medicine, Department of Medicine, </institution><institution>University of Florida College of Medicine, </institution></institution-wrap>Gainesville, FL USA </aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04b6nzv94</institution-id><institution-id institution-id-type="GRID">grid.62560.37</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 8294</institution-id><institution>Division of General Internal Medicine, </institution><institution>Brigham and Women&#x02019;s Hospital, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05dq2gs74</institution-id><institution-id institution-id-type="GRID">grid.412807.8</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9916</institution-id><institution>Division of General Internal Medicine and Public Health, </institution><institution>Vanderbilt University Medical Center, </institution></institution-wrap>Nashville, TN USA </aff><aff id="Aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03wmf1y16</institution-id><institution-id institution-id-type="GRID">grid.430503.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 0703 675X</institution-id><institution>Department of Internal Medicine, Kaiser Permanente, Denver, CO, School of Medicine, </institution><institution>University of Colorado, </institution></institution-wrap>Aurora, CO USA </aff><aff id="Aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01p7jjy08</institution-id><institution-id institution-id-type="GRID">grid.262962.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9342</institution-id><institution>Department of Internal Medicine, </institution><institution>Saint Louis University, </institution></institution-wrap>Saint Louis, MO USA </aff><aff id="Aff11"><label>11</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02y070a55</institution-id><institution-id institution-id-type="GRID">grid.414905.d</institution-id><institution-id institution-id-type="ISNI">0000 0000 8525 5459</institution-id><institution>Department of Internal Medicine, </institution><institution>University of Miami Miller School of Medicine, Jackson Memorial Hospital, </institution></institution-wrap>Miami, FL USA </aff><aff id="Aff12"><label>12</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02bxt4m23</institution-id><institution-id institution-id-type="GRID">grid.416477.7</institution-id><institution-id institution-id-type="ISNI">0000 0001 2168 3646</institution-id><institution>Northwell Health, </institution></institution-wrap>New Hyde Park, NY USA </aff><aff id="Aff13"><label>13</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/043mz5j54</institution-id><institution-id institution-id-type="GRID">grid.266102.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 2297 6811</institution-id><institution>Divisions of General Internal Medicine and Clinical Informatics, Department of Medicine, </institution><institution>University of California at San Francisco, </institution></institution-wrap>San Francisco, CA USA </aff><aff id="Aff14"><label>14</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03czfpz43</institution-id><institution-id institution-id-type="GRID">grid.189967.8</institution-id><institution-id institution-id-type="ISNI">0000 0001 0941 6502</institution-id><institution>Division of General Internal Medicine, </institution><institution>Emory University School of Medicine, </institution></institution-wrap>Atlanta, GA USA </aff><aff id="Aff15"><label>15</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03v76x132</institution-id><institution-id institution-id-type="GRID">grid.47100.32</institution-id><institution-id institution-id-type="ISNI">0000000419368710</institution-id><institution>Section of General Internal Medicine, </institution><institution>Yale School of Medicine, </institution></institution-wrap>New Haven, CT USA </aff><aff id="Aff16"><label>16</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/002pd6e78</institution-id><institution-id institution-id-type="GRID">grid.32224.35</institution-id><institution-id institution-id-type="ISNI">0000 0004 0386 9924</institution-id><institution>Department of Medicine, </institution><institution>Massachusetts General Hospital, </institution></institution-wrap>Boston, MA USA </aff><aff id="Aff17"><label>17</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00za53h95</institution-id><institution-id institution-id-type="GRID">grid.21107.35</institution-id><institution-id institution-id-type="ISNI">0000 0001 2171 9311</institution-id><institution>Division of General Internal Medicine, </institution><institution>Johns Hopkins University School of Medicine, </institution></institution-wrap>Baltimore, MD USA </aff><aff id="Aff18"><label>18</label>Stanford Center for Biomedical Informatics Research, Stanford, CA USA </aff><aff id="Aff19"><label>19</label>Division of Hospital Medicine, Stanford, CA USA </aff><aff id="Aff20"><label>20</label>Clinical Excellence Research Center, Stanford, CA USA </aff><aff id="Aff21"><label>21</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04py2rh25</institution-id><institution-id institution-id-type="GRID">grid.452687.a</institution-id><institution-id institution-id-type="ISNI">0000 0004 0378 0997</institution-id><institution>Digital, </institution><institution>Mass General Brigham, </institution></institution-wrap>Somerville, MA USA </aff><aff id="Aff22"><label>22</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02vm5rt34</institution-id><institution-id institution-id-type="GRID">grid.152326.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 2264 7217</institution-id><institution>Department of Biomedical Informatics, </institution><institution>Vanderbilt University, </institution></institution-wrap>Nashville, TN USA </aff></contrib-group><pub-date pub-type="epub"><day>12</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>12</day><month>11</month><year>2024</year></pub-date><pub-date pub-type="ppub"><month>2</month><year>2025</year></pub-date><volume>40</volume><issue>3</issue><fpage>694</fpage><lpage>702</lpage><history><date date-type="received"><day>30</day><month>4</month><year>2024</year></date><date date-type="accepted"><day>27</day><month>9</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Generative artificial intelligence (generative AI) is a new technology with potentially broad applications across important domains of healthcare, but serious questions remain about how to balance the promise of generative AI against unintended consequences from adoption of these tools. In this position statement, we provide recommendations on behalf of the Society of General Internal Medicine on how clinicians, technologists, and healthcare organizations can approach the use of these tools. We focus on three major domains of medical practice where clinicians and technology experts believe generative AI will have substantial immediate and long-term impacts: clinical decision-making, health systems optimization, and the patient-physician relationship. Additionally, we highlight our most important generative AI ethics and equity considerations for these stakeholders. For clinicians, we recommend approaching generative AI similarly to other important biomedical advancements, critically appraising its evidence and utility and incorporating it thoughtfully into practice. For technologists developing generative AI for healthcare applications, we recommend a major frameshift in thinking away from the expectation that clinicians will &#x0201c;supervise&#x0201d; generative AI. Rather, these organizations and individuals should hold themselves and their technologies to the same set of high standards expected of the clinical workforce and strive to design high-performing, well-studied tools that improve care and foster the therapeutic relationship, not simply those that improve efficiency or market share. We further recommend deep and ongoing partnerships with clinicians and patients as necessary collaborators in this work. And for healthcare organizations, we recommend pursuing a combination of both incremental and transformative change with generative AI, directing resources toward both endeavors, and avoiding the urge to rapidly displace the human clinical workforce with generative AI. We affirm that the practice of medicine remains a fundamentally human endeavor which should be enhanced by technology, not displaced by it.</p><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1007/s11606-024-09102-0.</p></sec></abstract><kwd-group xml:lang="en"><title>KEY WORDS</title><kwd>clinical practice</kwd><kwd>artificial intelligence</kwd><kwd>healthcare technology</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Society of General Internal Medicine 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>INTRODUCTION</title><p id="Par2">Generative artificial intelligence (generative AI) recently emerged as a major technology breakthrough. Although &#x0201c;AI&#x0201d; is a broad term, generative AI encompasses a specific set of new tools with advanced capabilities in interpreting and manipulating natural language. Conceptually, generative AI has been compared to other world-changing technologies like the modern Internet and smartphones, fostering robust discussion on societal implications. Although others have written extensively on <italic>how</italic> generative AI works,<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> we focus primarily on <italic>why</italic> this technology is different and ways its application may shape internal medicine and healthcare more broadly.</p><p id="Par3">Briefly, generative AI capabilities are based on a new class of advanced data models &#x0201c;trained&#x0201d; on data such as texts, images, and audio at a massive scale, on the order of billions to trillions of associations spanning the breadth of existing human knowledge.<sup><xref ref-type="bibr" rid="CR2">2</xref></sup> These models are then refined through various technical methods to satisfy human preferences and accomplish specific tasks. By leveraging such a large corpus of information and drawing patterns between the data, generative AI can <italic>generate</italic> new content in response to diverse inputs. We provide several illustrative examples of generative AI output (Supplementary Appendix <xref rid="MOESM1" ref-type="media">1</xref>). For text-based responses like the examples provided, generative AI literally predicts the most likely next word in a sentence &#x02014; but this is an oversimplification and does not do justice to their extensive capabilities. We suggest readers interact firsthand with these widely available tools to appreciate their power and limitations.</p><p id="Par4">The most important concept to internalize for physicians is that generative AI tools can interpret and create content from diverse inputs while exhibiting the ability to reason<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup> &#x02014; domains historically reserved largely for human experts. Generative AI can now complete tasks which previously required substantial human effort and skill such as answering complex questions, summarizing large documents, interpreting and creating images and audio, and much more. In medicine, generative AI is uniquely positioned to address many challenges facing clinicians and patients.<sup><xref ref-type="bibr" rid="CR5">5</xref></sup> However, this sense of optimism must be weighed against unknown impacts of generative AI on healthcare quality, safety, equity, and ethics.<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup> Important questions remain about how this technology will affect care delivery.</p><p id="Par5">In this position statement, we make recommendations on behalf of the Society of General Internal Medicine (SGIM) on the use of generative AI in medicine. We convened a group of clinical, health systems, and technology experts within SGIM to explore three domains of clinical practice where application of generative AI may substantially impact care delivery: clinical decision-making, health systems optimization, and the patient-physician relationship. These categories were selected by expert consensus within the writing group and are consistent with domains identified by the physician community as areas of enthusiasm and concern.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> Additionally, we provide an overview of our most pressing ethical and equity concerns surrounding generative AI implementation. In each section, we review generative AI&#x02019;s potential, highlight key challenges to overcome, and provide actionable recommendations to three groups: clinicians using these tools in frontline patient care, technologists developing these tools for healthcare applications, and healthcare organizations making decisions on adoption of generative AI technology. Each of these categories is composed of many stakeholders but includes individual practitioners, technology companies, health plans, purchasers of healthcare services, and provider organizations like health systems and clinics. We also use the term &#x0201c;industry&#x0201d; throughout when specifically referring to organizations selling generative AI tools for financial gain. While much has already been written about the potential of generative AI in healthcare,<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> our views represent the unique perspective of internal medicine physicians, the largest physician specialty in the United States.<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> Although we anticipate these recommendations will evolve as this technology advances, they are grounded in well-established principles for achieving a high-performing healthcare system including safety, timeliness, effectiveness, efficiency, equity, and patient-centeredness.<sup><xref ref-type="bibr" rid="CR10">10</xref></sup></p><p id="Par6">These recommendations were collaboratively developed by the SGIM committees on Clinical Practice, Health Policy, Ethics, Health Equity, and Research. They were approved by the SGIM Council on April 5, 2024.</p></sec><sec id="Sec2"><title>ENHANCING CLINICAL DECISION-MAKING WITH GENERATIVE AI</title><p id="Par7">Clinical decision-making is a complex cognitive process that is foundational to the practice of medicine. At its most basic level, it may be conceptualized as collecting, organizing, and interpreting information to make a diagnosis and select appropriate treatment. When done well, it also requires application of expert knowledge alongside years of hard-earned experience, judgment in the face of uncertainty, and a deep appreciation of the values, goals, and circumstances of our patients.</p><p id="Par8">Generative AI may support clinical decision-making through analysis of multimodal clinical data and generation of personalized insights into diagnostic and treatment options which reflect the most current medical knowledge. Such tools have already shown impressive performance in diagnostic reasoning, demonstrating the ability to surface correct diagnoses in complex diagnostic challenges<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> and compare favorably to human performance in simulated medical cases.<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup> Studies of real-world implementations of analytic AI have demonstrated strong physician agreement with AI-generated differential diagnoses in internal medicine settings, though important areas of discordance were identified.<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> Better diagnostic supports would be a welcome contribution given that diagnostic harm affects nearly 5% of encounters for outpatients<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> and 0.7% of encounters for inpatients.<sup><xref ref-type="bibr" rid="CR16">16</xref></sup></p><p id="Par9">In addition to diagnostic reasoning, generative AI may assist in treatment decisions which require synthesis of complex scientific-, patient-, and systems-level factors. Generative AI solutions may be directed at all or some of these and may span levels of physician supervision.<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> For example, new generative AI tools allow clinicians to query medical literature using free text questions and receive AI-generated answers alongside relevant citations.<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> This is a useful capability, but the physician retains full oversight of the care process. In contrast, a large benefit of generative AI technologies is automated decision-making, and new industry entrants are currently working toward this purpose.<sup><xref ref-type="bibr" rid="CR19">19</xref>&#x02013;<xref ref-type="bibr" rid="CR21">21</xref></sup> Although protocol-driven care for common internal medicine activities like chronic disease management can be more effective than standard of care,<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> automating clinical decision-making has far-reaching implications and will require rigorous evaluation standards that have not yet been implemented.</p><p id="Par10">Even in its current form, this technology offers a new form of clinical decision support (CDS), with vast and generalizable medical knowledge and the ability to perform a variety of complex cognitive tasks.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> This may lay the foundation for more sophisticated and potentially autonomous tools for diagnosis and treatment.</p><sec id="Sec3"><title>Key Challenges to Overcome</title><p id="Par11">Clinical decision-making is a high-stakes activity, and generative AI currently has serious weaknesses. The most pressing challenge is its propensity to produce inaccurate information, popularly described as &#x0201c;hallucinations,&#x0201d; but more accurately described as &#x0201c;confabulations.&#x0201d;<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> Generative AI can also fail to include important information, an error termed &#x0201c;omissions.&#x0201d; Even small errors in generative AI performance can erode physician confidence, inevitably cause patient harm, and hinder adoption.</p><p id="Par12">The issue of generative AI errors and omissions is particularly salient because there appears to be a rising expectation among technologists and others that physicians will simply &#x0201c;supervise&#x0201d; generative AI tools, carefully fact-checking AI outputs for inaccuracies and mitigating discrepancies. This is a bold supposition, and we believe a frameshift among AI technologists is needed.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> It should not be a foregone conclusion that physicians will recognize when AI tools under-perform, nor that we will divest ourselves of our current professional practice and adopt the role of &#x0201c;AI supervisor.&#x0201d; Instead, technologists should aim to design high-performing tools that engender trust with physicians. Just like airline pilots should not need to question the accuracy of their GPS when making a flight plan, physicians should not need to question the accuracy of generative AI when designing a care plan.</p></sec><sec id="Sec4"><title>Recommendations for Enhancing Clinical Decision-Making with Generative AI</title><p id="Par13">For clinicians:</p><p id="Par14">
<list list-type="bullet"><list-item><p id="Par15">Remain attentive to developments in generative AI as a potentially transformative technology in healthcare and be receptive to using these tools in patient care.</p></list-item><list-item><p id="Par16">As with any new technology, test, or treatment, clinicians should critically appraise the value of generative AI in augmenting their practice and adopt tools that improve care.</p></list-item><list-item><p id="Par17">Recognize that errors and omissions are the major technical weakness of generative AI and understand performance and safeguards of any new tool in this domain.</p></list-item><list-item><p id="Par18">Welcome opportunities to collaborate with technologists in designing generative AI tools to improve performance and acceptability.</p></list-item></list>
</p><p id="Par19">For technologists:</p><p id="Par20">
<list list-type="bullet"><list-item><p id="Par21">Consider perspectives of the clinical care team in the design of generative AI tools and hold yourselves, your colleagues, and your technologies to performance standards expected of the clinical workforce.</p></list-item><list-item><p id="Par22">AI tools should ideally provide outputs that can be viewed as ground truth, but must provide obvious and intuitive mechanisms for verification and error-proofing.</p></list-item><list-item><p id="Par23">Directly partner with clinicians and patients in addition to business and technology leaders to understand real-world user needs.</p></list-item></list>
</p><p id="Par24">For healthcare organizations:</p><p id="Par25">
<list list-type="bullet"><list-item><p id="Par26">Evaluate generative AI tools that improve diagnosis and assist in treatment selection to reduce diagnostic error and improve achievement of therapeutic goals.</p></list-item><list-item><p id="Par27">Partner with physicians to carefully understand acceptability of new generative AI-driven workflows and responsibilities.</p></list-item><list-item><p id="Par28">When evaluating clinical decision tools, focus on preventative care and chronic condition management, as these represent the bulk of contemporary internal medicine practice with large impacts on health.</p></list-item></list>
</p></sec></sec><sec id="Sec5"><title>GENERATIVE AI FOR OPTIMIZING HEALTHCARE SYSTEMS</title><p id="Par29">General internists see many ways that generative AI could strengthen overall health system performance. Three major areas for consideration are improvements to access, population health management, and patient safety. Access challenges arise when the capacity of a system to deliver care is exceeded by demand. In internal medicine &#x02014; and especially primary care &#x02014; access has become critically limited.<sup><xref ref-type="bibr" rid="CR26">26</xref>&#x02013;<xref ref-type="bibr" rid="CR28">28</xref></sup> Generative AI may increase capacity through several mechanisms. First, capacity can be created when manual tasks like chart review and patient triage can be automated. New capacity could also be created if generative AI increases scope of practice, especially among advanced practice providers (APPs) who now provide substantial amounts of internal medicine services.<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> Additionally, capacity could be enhanced with chronic and preventative care partially or fully delivered by generative AI, though such capabilities remain less studied.</p><p id="Par30">Population health is another area where generative AI can extend the reach of the general internist.<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> In the current system, it is often difficult to determine where a patient is in the care journey or identify gaps in care. Although many systems invest heavily in population health efforts, generative AI and its ability to process large amounts of data may provide needed visibility into patient progress at scale, as well as greater visibility into challenges impacting specific communities.</p><p id="Par31">Additionally, generative AI represents a potential step-change in patient safety. Medical errors remain a significant concern across all specialties despite decades of efforts and national attention.<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> Generative AI tools that can anticipate and mitigate errors automatically could provide an entirely new infrastructure on which to base patient safety systems. The transformative potential of generative AI to improve safety has attracted attention of senior leadership within industry and government, including a recent report to the president on the topic.<sup><xref ref-type="bibr" rid="CR32">32</xref></sup></p><sec id="Sec6"><title>Key Challenges to Overcome</title><p id="Par32">Integrating new technologies to create systems-level change is a difficult undertaking spanning individual and organizational factors. Key challenges include mustering leadership support, designing new workflows within complex organizations, allocating resources for implementation, building&#x000a0;new supporting infrastructure and expertise to monitor AI performance, and overcoming institutional inertia.</p></sec><sec id="Sec7"><title>Recommendations for Improving Healthcare Systems with Generative AI</title><p id="Par33">For clinicians:</p><p id="Par34">
<list list-type="bullet"><list-item><p id="Par35">Be open to evaluating and implementing generative AI tools for quality and safety applications.</p></list-item><list-item><p id="Par36">Consider how AI tools can enhance team-based delivery of care by expanding scope of practice.</p></list-item></list>
</p><p id="Par37">For technologists:<list list-type="bullet"><list-item><p id="Par38">Prioritize development of AI tools that address the most pressing systems-level concerns: quality and safety, access, equity, and cost.</p></list-item></list></p><p id="Par39">For healthcare organizations:</p><p id="Par40">
<list list-type="bullet"><list-item><p id="Par41">Consider opportunities for both incremental and transformational systems-level change with generative AI, with resources directed toward both.</p></list-item><list-item><p id="Par42">Ensure strong internal infrastructure is in place to monitor performance of generative AI, especially in clinical use.</p></list-item></list>
</p></sec></sec><sec id="Sec8"><title>IMPROVING PHYSICIAN AND PATIENT EXPERIENCE THROUGH GENERATIVE AI</title><p id="Par43">The experience of giving and receiving medical care has changed dramatically in recent decades due to factors such as the widespread adoption of electronic health records (EHR),<sup><xref ref-type="bibr" rid="CR33">33</xref>&#x02013;<xref ref-type="bibr" rid="CR35">35</xref></sup> reorganization of the physician workforce within large healthcare entities,<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> value-based payment,<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> healthcare consumerism,<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> and the rise of telehealth and asynchronous care.<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup> While altruistic desires and passion for scientific inquiry often motivate individuals to pursue a career in medicine, the current practice environment poses significant challenges to professional fulfillment and cultivation of meaningful patient relationships.<sup><xref ref-type="bibr" rid="CR39">39</xref>&#x02013;<xref ref-type="bibr" rid="CR41">41</xref></sup></p><p id="Par44">Physicians spend a significant proportion of their time on EHR documentation and other administrative tasks instead of direct patient care, and these burdens are particularly high in internal medicine.<sup><xref ref-type="bibr" rid="CR36">36</xref>,<xref ref-type="bibr" rid="CR42">42</xref></sup> For instance, one recent study highlighted that primary care physicians at an academic medical center received 8000&#x02013;15,000 inbox messages annually and spent 36 min on the EHR per patient visit.<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> These increasing demands prevent delivery of comprehensive, high-quality patient care: another study estimated that a typical primary care physician needs 26.7 h per day to deliver all recommended services.<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> These burdens also contribute to physician burnout,<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> physician exit from clinical settings,<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> and patient dissatisfaction.<sup><xref ref-type="bibr" rid="CR47">47</xref></sup></p><p id="Par45">Patients are similarly affected, perceiving these challenges during their care interactions. In a recent national survey,<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> 47% of respondents felt their healthcare providers were overburdened and 64% wished healthcare providers took more time to understand them, findings which reinforce urgency in improving the patient experience in physicians-patient interactions.</p><p id="Par46">Generative AI offers an opportunity to restore humanism in medicine. Early efforts directed at reducing administrative burdens and improving workflows seek to create more time for physicians to spend with their patients. Potential use cases for the application of generative AI include chart review, clinical documentation, inbox management, personalized patient instructions, and prior authorizations.<sup><xref ref-type="bibr" rid="CR49">49</xref></sup> Early results using generative AI for clinical documentation found AI wrote high-quality notes, reduced documentation burden, and garnered favorable physician and patient feedback.<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> Similarly, an early pilot using generative AI for drafting replies to patient portal messages showed favorable usability and improvements in assessments of burden and burnout, although no reduction in time was observed.<sup><xref ref-type="bibr" rid="CR51">51</xref></sup> In addition to administrative tasks, there are numerous other ways that generative AI may be designed to improve patient experience including more empathetic communication,<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> improved patient instructions,<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> and timelier answers to common patient questions.<sup><xref ref-type="bibr" rid="CR54">54</xref></sup></p><p id="Par47">However, generative AI tools &#x02014; like any other technology &#x02014; require intentionality. Ideally, they will be used to fundamentally reimagine clinician and patient interactions rather than simply layered on top of dysfunctional workflows in healthcare. The promise of these technologies will be best realized through creative redesign of medical practice.</p><sec id="Sec9"><title>Key Challenges to Overcome</title><p id="Par48">Improvements to the patient and physician experience with generative AI require that implementations of these technologies do not substitute current workflow problems with new ones. These tools should enhance rather than diminish the patient-physician relationship. Additionally, stakeholders should avoid the temptation to &#x0201c;backfill&#x0201d; new capacity created by generative AI efficiencies, instead finding balance between increased access and improvements in experience. If generative AI becomes another distraction, a new barrier between physicians and our patients, or simply a revenue lever, an opportunity to reimagine care delivery will be missed.</p></sec><sec id="Sec10"><title>Recommendations for Improving the Physician-Patient Relationship with AI</title><p id="Par49">For clinicians:<list list-type="bullet"><list-item><p id="Par50">Explore ways to leverage generative AI to create more time and attention for patients while restoring personal fulfillment in clinical practice.</p></list-item></list></p><p id="Par51">For technologists:</p><p id="Par52">
<list list-type="bullet"><list-item><p id="Par53">Although efficiency is important, understand that it is not the only desirable outcome. Strong patient-physician relationships are a critical element of healthcare delivery that create tremendous value. Generative AI tools should promote rather than hinder these interactions.</p></list-item><list-item><p id="Par54">Ensure solutions are truly improving the experience of giving and receiving care rather than simply layering on new technology.</p></list-item><list-item><p id="Par55">Co-design solutions with clinicians and patients that both incrementally improve and fundamentally redesign clinical workflows.</p></list-item></list>
</p><p id="Par56">For healthcare organizations:</p><p id="Par57">
<list list-type="bullet"><list-item><p id="Par58">Evaluate generative AI solutions that reduce administrative burdens as these tools are presently available, have a growing evidence base, and are demonstrating tangible benefits in improving experience for physicians and patients.</p></list-item><list-item><p id="Par59">Resist the urge to substitute the human workforce with technology solutions. Remember that the practice of medicine is a fundamentally human endeavor and that experience matters.</p></list-item><list-item><p id="Par60">Avoid solutions that simply layer generative AI on top of dysfunctional or burdensome workflows as these will have a high likelihood of failure. Reimagine workflows that make the best use of new AI capabilities.</p></list-item></list>
</p></sec></sec><sec id="Sec11"><title>NAVIGATING THE ETHICAL AND EQUITY LANDSCAPE OF GENERATIVE AI IN MEDICINE</title><p id="Par61">Bias in generative AI is a major concern and has been the subject of significant attention as use of these tools expands.<sup><xref ref-type="bibr" rid="CR55">55</xref>&#x02013;<xref ref-type="bibr" rid="CR57">57</xref></sup> In general terms, bias in generative AI can be thought of as outputs that disadvantage certain populations compared to others. For example, a generative AI trained only to classify skin lesions from white individuals may offer less accurate diagnoses and recommendations for individuals with darker skin tones.<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> Such biases, if unrecognized, can undermine generative AI acceptability, fairness, equity, and effectiveness.</p><p id="Par62">The sources of bias in generative AI are multi-dimensional and can occur at all phases of the technology life cycle.<sup><xref ref-type="bibr" rid="CR59">59</xref></sup> First are biases in data sets on which these solutions are built. This may be caused by inequitable participation in data sets, flaws in data collection, and erroneous characterizations. If certain groups are not well represented in generative AI training data, their specific needs may not be addressed in outputs. Examples include inequitable participation among certain races and genders, sexual orientation, pregnancy status, and others. More insidiously, generative AI systems can exhibit unanticipated biases when allowed to &#x0201c;learn&#x0201d; in an unsupervised fashion, thus perpetuating existing biases in healthcare delivery and outcomes.<sup><xref ref-type="bibr" rid="CR60">60</xref></sup></p><p id="Par63">Additionally, bias can arise in implementation<sup><xref ref-type="bibr" rid="CR61">61</xref>,<xref ref-type="bibr" rid="CR62">62</xref></sup> and reflect human rather than technology biases about where, how, and for whom generative AI is utilized.<sup><xref ref-type="bibr" rid="CR55">55</xref>,<xref ref-type="bibr" rid="CR63">63</xref></sup> For example, consider a care model where patients must use AI before seeing a human. Such a system may inadvertently disadvantage some groups of patients forced to access less desirable AI-driven care. Organizations must guard against such implementation-based impacts on health equity.</p><p id="Par64">Another source of ethical concern is around data privacy, ownership and monetization, and transparency. Specific legal issues notwithstanding,<sup><xref ref-type="bibr" rid="CR64">64</xref>,<xref ref-type="bibr" rid="CR65">65</xref></sup> there are considerable issues of fairness and individual autonomy created when personal data is used to train generative AI. This presents a dilemma: use patient medical records to train generative AI in the interest of the greater good through improved performance or undertake potentially burdensome informed consent efforts which may hamper improvements. Generative AI &#x02014; and the financial incentives to monetize new tools &#x02014; creates new pressures to loosen historical restrictions on use of health data, which may erode trust.</p><p id="Par65">The proprietary nature of generative AI tools also poses ethical challenges around knowledge sharing and financial conflict of interest. The development of AI models is a capital-intensive endeavor dependent upon corporations with a primary profit objective. These entities may not be incentivized to share best practices or advancements, but instead to maintain a competitive advantage through proprietary technology, market domination, and curated evaluations of performance that demonstrate success, not failure. While these strategies are common in industry, these values can conflict with the primary objective of healthcare stakeholders seeking to improve health outcomes. In the pharmaceutical industry, this tension is mitigated by requiring manufacturers to produce extensive safety and efficacy studies as pre-requisites to regulatory approval followed by a period of profitable market exclusivity before introduction of low-cost generics. Although the Food and Drug Administration has proposed regulatory oversight of AI, it does not yet approach the rigor of pharmaceutical regulation.<sup><xref ref-type="bibr" rid="CR66">66</xref></sup> Moreover, there is an ethical dilemma inherent to sequestering technological advancements within industry when broader sharing of such advancements may substantially benefit society. Users of generative AI in healthcare must also recognize the potential for underlying financial conflicts of interests influencing AI outputs, such as AI designed to optimize healthcare revenue rather than optimize health outcomes.</p><p id="Par66">A lack of transparency regarding the design and performance of generative AI tools, as well as the &#x0201c;black box&#x0201d; nature of AI decision-making processes, also introduces tremendous uncertainty for those adopting these solutions and makes it difficult for individual clinicians to act on AI-generated recommendations. Clinicians and patients need clear evidence of AI performance coupled with understandable ways to interpret generative AI outputs beyond &#x0201c;the AI said so.&#x0201d; Both existing and new techniques will likely be required. For example, a &#x0201c;chain of thought&#x0201d; approach can provide a step-by-step breakdown of the reasoning process behind a particular recommendation. Existing AI-based tools like the Epic Deterioration Index<sup><xref ref-type="bibr" rid="CR67">67</xref></sup> already include features which allow physicians to understand specific contributing factors behind AI-based recommendations. Additional techniques like visualizations and natural language explanations can further enhance transparency, making AI recommendations more trustworthy and understandable.</p><p id="Par67">Finally, generative AI tools raise important questions of scope. Medicine is best understood not only as a science but as a &#x0201c;moral practice&#x0201d; requiring human to human interactions.<sup><xref ref-type="bibr" rid="CR68">68</xref></sup> If generative AI algorithms come to define the standard of care, they may undermine physicians&#x02019; ability to connect with patients and exercise clinical discretion. For example, an insurer might require that generative AI evaluates a patient and only reimburses orders that the AI deems necessary, inappropriately narrowing the scope of physician autonomy. Competing AI tools designed for different purposes &#x02014; for example, a clinical recommendation versus prior authorization approval &#x02014; could also yield conflicting recommendations. These concerns call for physicians to define the appropriate use of generative AI involvement in decision-making before these tools arrive at the bedside, and to clearly articulate the value of human judgment.</p><sec id="Sec12"><title>Key Challenges to Overcome</title><p id="Par68">Financial incentives are already placing immense pressure on technology organizations to bring generative AI tools to markets, and the value set of industry fundamentally differs from the values of the medical profession. This distinction may manifest in accelerating tools to market despite inadequate assessment and mitigation of bias, through undesirable tactics to maintain market domination at the expense of patient care, and diminution of the human aspects of care delivery.</p></sec><sec id="Sec13"><title>Recommendations for Navigating Ethical and Equity Issues in Generative AI</title><p id="Par69">For clinicians:</p><p id="Par70">
<list list-type="bullet"><list-item><p id="Par71">Insist on high standards of transparency and evidence for AI tools &#x02014; including AI&#x02019;s potential for bias (differential performance).</p></list-item><list-item><p id="Par72">Do not use generative AI tools to make clinical decisions unless confident that you can justify those decisions to patients and peers.</p></list-item></list>
</p><p id="Par73">For technologists:</p><p id="Par74">
<list list-type="bullet"><list-item><p id="Par75">Seek to address bias in generative AI performance through more representative training data, evaluation and mitigation of bias in outputs, and ongoing monitoring of performance.</p></list-item><list-item><p id="Par76">Fund high-quality studies of generative AI performance in the form of both clinical trials and real-world outcomes evaluations.</p></list-item><list-item><p id="Par77">Recognize that ethical standards differ between healthcare and business organizations and create internal systems of checks and balances to navigate tensions similar to other high-stakes engineering domains such as aerospace, nuclear energy, and automotive safety.</p></list-item><list-item><p id="Par78">Approach the design of AI tools with the mindset that they should work to augment clinicians rather than clinicians augmenting generative AI.</p></list-item><list-item><p id="Par79">Seek to understand the perspectives of patients and community organizations when assessing the equity impact of generative as these stakeholders are often able to surface important concerns early in the adoption process.</p></list-item></list>
</p><p id="Par80">For healthcare organizations:</p><p id="Par81">
<list list-type="bullet"><list-item><p id="Par82">Demand diverse training data sets, transparency into performance, and equitable outcomes in order to promote fairness when using generative AI.</p></list-item><list-item><p id="Par83">Ensure physicians maintain agency and ultimate decision-making authority, irrespective of generative AI recommendations.</p></list-item><list-item><p id="Par84">Critically evaluate data on generative AI performance when making adoption decisions, recognizing that industry may have different incentives than healthcare organizations.</p></list-item></list>
</p></sec></sec><sec id="Sec14"><title>CONCLUSION</title><p id="Par85">Generative AI will undoubtedly impact healthcare in ways both predictable and unpredictable, and there is tremendous promise for positive impact on care delivery, clinician and patient experience, equity, and cost of care. However, choices made in the near-term may have far-reaching consequences for the medical profession broadly and general internal medicine in particular. Embedded in these recommendations are key themes that can guide decisions across stakeholders: a focus on deploying this new technology to enhance rather than impede care, the need for rigorous evaluation and supporting institutional structures to guide generative AI development and implementation, and the recognition that the practice of medicine is, and must remain, a deeply human endeavor. This position statement serves as an important guidepost for all those exploring how generative AI tools may benefit medical practice while guarding against the potential pitfalls of implementing this new technology at scale.</p></sec><sec id="Sec15" sec-type="supplementary-material"><title>Supplementary Information</title><p>Below is the link to the electronic supplementary material.<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="11606_2024_9102_MOESM1_ESM.docx"><caption><p>Supplementary file1 (DOCX 1140 KB)</p></caption></media></supplementary-material></p></sec></body><back><fn-group><fn><p><bold>Publisher's Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>We thank the members of the SGIM Council for their support and feedback on multiple earlier versions of this manuscript. We also thank Dr. James Moses and Dr. William Bornstein for important directional feedback related to health system impacts of generative AI. Finally, we thank Dr. Eileen Reynolds and the Division of General Internal Medicine at Beth Israel Deaconess Medical Center for their generosity in hosting members of this writing group across multiple working sessions.</p></ack><notes><title>Declarations</title><notes id="FPar1" notes-type="COI-statement"><title>Conflict of Interest</title><p id="Par86">BC reports employment and equity with Solera Health outside the submitted work. MD reports consulting on ethics policy issues for the American College of Physicians via an institutional contract. JAR reports serving as a consultant for the Association of American Medical Colleges. EK reports funding from the NIH through K23HL163498 unrelated to the current work. LR reports research funding from FeelBetter Inc, the Agency for Healthcare Research and Quality, the Physicians Foundation, and the American Medical Association. She also serves on the AI Advisory Council for Augmedix, Inc and has received honoraria from Phreesia, Inc. AR reports funding from the Gordon and Betty Moore foundation for research on large language models. JC reports research funding support in part by NIH/National Institute of Allergy and Infectious Diseases (1R01AI17812101), NIH/National Institute on Drug Abuse Clinical Trials Network (UG1DA015815 - CTN-0136), Gordon and Betty Moore Foundation (Grant #12409), Stanford Artificial Intelligence in Medicine and Imaging - Human-Centered Artificial Intelligence (AIMI-HAI) Partnership Grant, American Heart Association - Strategically Focused Research Network - Diversity in Clinical Trials. Additionally, JC reports being co-founder of Reaction Explorer LLC that develops and licenses organic chemistry education software, paid consulting fees from Sutton Pierce, Younker Hyde MacFarlane, and Sykes McAllister as a medical expert witness and paid consulting fees from ISHI Health. RGM reports advisory committee role with Elsevier, outside of this work. All other authors have no conflicts to report.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>NH</given-names></name><name><surname>Entwistle</surname><given-names>D</given-names></name><name><surname>Pfeffer</surname><given-names>MA</given-names></name></person-group><article-title>Creation and Adoption of Large Language Models in Medicine</article-title><source>JAMA</source><year>2023</year><volume>330</volume><issue>9</issue><fpage>866</fpage><pub-id pub-id-type="doi">10.1001/jama.2023.14217</pub-id><pub-id pub-id-type="pmid">37548965</pub-id>
</element-citation><mixed-citation id="mc-CR1" publication-type="journal"><bold>Shah NH, Entwistle D, Pfeffer MA.</bold> Creation and adoption of large language models in medicine. JAMA 2023;330(9):866.<pub-id pub-id-type="pmid">37548965</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other"><bold>Minaee S, Mikolov T, Nikzad N, et al.</bold> Large Language Models: A Survey. 2024 [cited 2024 Feb 29];Available from: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2402.06196">https://arxiv.org/abs/2402.06196</ext-link></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other"><bold>Bubeck S, Chandrasekaran V, Eldan R, et al.</bold> Sparks of Artificial General Intelligence: Early experiments with GPT-4. 2023 [cited 2024 Feb 29];Available from: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2303.12712">https://arxiv.org/abs/2303.12712</ext-link></mixed-citation></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name><surname>Rodman</surname><given-names>A</given-names></name><name><surname>Buckley</surname><given-names>TA</given-names></name><name><surname>Manrai</surname><given-names>AK</given-names></name><name><surname>Morgan</surname><given-names>DJ</given-names></name></person-group><article-title>Artificial Intelligence vs Clinician Performance in Estimating Probabilities of Diagnoses Before and After Testing</article-title><source>JAMA Netw Open</source><year>2023</year><volume>6</volume><issue>12</issue><fpage>e2347075</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2023.47075</pub-id><pub-id pub-id-type="pmid">38079174</pub-id>
</element-citation><mixed-citation id="mc-CR4" publication-type="journal"><bold>Rodman A, Buckley TA, Manrai AK, Morgan DJ.</bold> Artificial intelligence vs clinician performance in estimating probabilities of diagnoses before and after testing. JAMA Netw Open 2023;6(12):e2347075.<pub-id pub-id-type="pmid">38079174</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name><surname>Thirunavukarasu</surname><given-names>AJ</given-names></name><name><surname>Ting</surname><given-names>DSJ</given-names></name><name><surname>Elangovan</surname><given-names>K</given-names></name><name><surname>Gutierrez</surname><given-names>L</given-names></name><name><surname>Tan</surname><given-names>TF</given-names></name><name><surname>Ting</surname><given-names>DSW</given-names></name></person-group><article-title>Large language models in medicine</article-title><source>Nat Med</source><year>2023</year><volume>29</volume><issue>8</issue><fpage>1930</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1038/s41591-023-02448-8</pub-id><pub-id pub-id-type="pmid">37460753</pub-id>
</element-citation><mixed-citation id="mc-CR5" publication-type="journal"><bold>Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW.</bold> Large language models in medicine. Nat Med 2023;29(8):1930&#x02013;40.<pub-id pub-id-type="pmid">37460753</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other"><bold>Wachter RM, Brynjolfsson E.</bold> Will Generative Artificial Intelligence Deliver on Its Promise in Health Care? JAMA [Internet] 2023 [cited 2023 Dec 31];Available from: <ext-link ext-link-type="uri" xlink:href="https://jamanetwork.com/journals/jama/fullarticle/2812615">https://jamanetwork.com/journals/jama/fullarticle/2812615</ext-link></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other"><bold>Biden J.</bold> Executive Order 14110. 2023.</mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other"><bold>Lee P, Goldberg C, Kohane I.</bold> The AI revolution in medicine: GPT-4 and beyond. 1st ed. Hoboken: Pearson; 2023.</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Physician Specialty Data Report, 2021 [Internet]. American Association of Medical Colleges; [cited 2023 Dec 30]. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.aamc.org/data-reports/workforce/data/number-people-active-physician-specialty-2021">https://www.aamc.org/data-reports/workforce/data/number-people-active-physician-specialty-2021</ext-link></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="other">Institute of Medicine (U.S.), editor. Crossing the quality chasm: a new health system for the 21st century. Washington, D.C: National Academy Press; 2001.</mixed-citation></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name><surname>Kanjee</surname><given-names>Z</given-names></name><name><surname>Crowe</surname><given-names>B</given-names></name><name><surname>Rodman</surname><given-names>A</given-names></name></person-group><article-title>Accuracy of a Generative Artificial Intelligence Model in a Complex Diagnostic Challenge</article-title><source>JAMA</source><year>2023</year><volume>330</volume><issue>1</issue><fpage>78</fpage><pub-id pub-id-type="doi">10.1001/jama.2023.8288</pub-id><pub-id pub-id-type="pmid">37318797</pub-id>
</element-citation><mixed-citation id="mc-CR11" publication-type="journal"><bold>Kanjee Z, Crowe B, Rodman A.</bold> accuracy of a generative artificial intelligence model in a complex diagnostic challenge. JAMA 2023;330(1):78.<pub-id pub-id-type="pmid">37318797</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name><surname>Strong</surname><given-names>E</given-names></name><name><surname>DiGiammarino</surname><given-names>A</given-names></name><name><surname>Weng</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Chatbot vs Medical Student Performance on Free-Response Clinical Reasoning Examinations</article-title><source>JAMA Intern Med</source><year>2023</year><volume>183</volume><issue>9</issue><fpage>1028</fpage><pub-id pub-id-type="doi">10.1001/jamainternmed.2023.2909</pub-id><pub-id pub-id-type="pmid">37459090</pub-id>
</element-citation><mixed-citation id="mc-CR12" publication-type="journal"><bold>Strong E, DiGiammarino A, Weng Y, et al.</bold> Chatbot vs medical student performance on free-response clinical reasoning examinations. JAMA Intern Med 2023;183(9):1028.<pub-id pub-id-type="pmid">37459090</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name><surname>Cabral</surname><given-names>S</given-names></name><name><surname>Restrepo</surname><given-names>D</given-names></name><name><surname>Kanjee</surname><given-names>Z</given-names></name><etal/></person-group><article-title>Clinical Reasoning of a Generative Artificial Intelligence Model Compared With Physicians</article-title><source>JAMA Intern Med</source><year>2024</year><volume>184</volume><issue>5</issue><fpage>581</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1001/jamainternmed.2024.0295</pub-id><pub-id pub-id-type="pmid">38557971</pub-id>
</element-citation><mixed-citation id="mc-CR13" publication-type="journal"><bold>Cabral S, Restrepo D, Kanjee Z, et al.</bold> Clinical reasoning of a generative artificial intelligence model compared with physicians. JAMA Intern Med 2024;184(5):581&#x02013;3.<pub-id pub-id-type="pmid">38557971</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name><surname>Zeltzer</surname><given-names>D</given-names></name><name><surname>Herzog</surname><given-names>L</given-names></name><name><surname>Pickman</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Diagnostic Accuracy of Artificial Intelligence in Virtual Primary Care</article-title><source>Mayo Clin Proc Digit Health</source><year>2023</year><volume>1</volume><issue>4</issue><fpage>480</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.mcpdig.2023.08.002</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal"><bold>Zeltzer D, Herzog L, Pickman Y, et al.</bold> Diagnostic accuracy of artificial intelligence in virtual primary care. Mayo Clin Proc Digit Health 2023;1(4):480&#x02013;9.</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>H</given-names></name><name><surname>Meyer</surname><given-names>AND</given-names></name><name><surname>Thomas</surname><given-names>EJ</given-names></name></person-group><article-title>The frequency of diagnostic errors in outpatient care: estimations from three large observational studies involving US adult populations</article-title><source>BMJ Qual Saf</source><year>2014</year><volume>23</volume><issue>9</issue><fpage>727</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1136/bmjqs-2013-002627</pub-id><pub-id pub-id-type="pmid">24742777</pub-id>
</element-citation><mixed-citation id="mc-CR15" publication-type="journal"><bold>Singh H, Meyer AND, Thomas EJ.</bold> The frequency of diagnostic errors in outpatient care: estimations from three large observational studies involving US adult populations. BMJ Qual Saf 2014;23(9):727&#x02013;31.<pub-id pub-id-type="pmid">24742777</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name><surname>Gunderson</surname><given-names>CG</given-names></name><name><surname>Bilan</surname><given-names>VP</given-names></name><name><surname>Holleck</surname><given-names>JL</given-names></name><etal/></person-group><article-title>Prevalence of harmful diagnostic errors in hospitalised adults: a systematic review and meta-analysis</article-title><source>BMJ Qual Saf</source><year>2020</year><volume>29</volume><issue>12</issue><fpage>1008</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1136/bmjqs-2019-010822</pub-id><pub-id pub-id-type="pmid">32269070</pub-id>
</element-citation><mixed-citation id="mc-CR16" publication-type="journal"><bold>Gunderson CG, Bilan VP, Holleck JL, et al.</bold> Prevalence of harmful diagnostic errors in hospitalised adults: a systematic review and meta-analysis. BMJ Qual Saf 2020;29(12):1008&#x02013;18.<pub-id pub-id-type="pmid">32269070</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name><surname>Bitterman</surname><given-names>DS</given-names></name><name><surname>Aerts</surname><given-names>HJWL</given-names></name><name><surname>Mak</surname><given-names>RH</given-names></name></person-group><article-title>Approaching autonomy in medical artificial intelligence</article-title><source>Lancet Digit Health</source><year>2020</year><volume>2</volume><issue>9</issue><fpage>e447</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/S2589-7500(20)30187-4</pub-id><pub-id pub-id-type="pmid">33328110</pub-id>
</element-citation><mixed-citation id="mc-CR17" publication-type="journal"><bold>Bitterman DS, Aerts HJWL, Mak RH.</bold> Approaching autonomy in medical artificial intelligence. Lancet Digit Health 2020;2(9):e447&#x02013;9.<pub-id pub-id-type="pmid">33328110</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">OpenEvidence [Internet]. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.openevidence.com/">https://www.openevidence.com/</ext-link></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">PRNewswire. UpDoc Debuts the World&#x02019;s First AI Assistant That Manages Medication Prescriptions and Chronic Conditions. 2025;Available from: <ext-link ext-link-type="uri" xlink:href="https://www.prnewswire.com/news-releases/updoc-debuts-the-worlds-first-ai-assistant-that-manages-medication-prescriptions-and-chronic-conditions-302027175.html">https://www.prnewswire.com/news-releases/updoc-debuts-the-worlds-first-ai-assistant-that-manages-medication-prescriptions-and-chronic-conditions-302027175.html</ext-link></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Amazon Clinic adds virtual primary care company to marketplace. Beckers Health IT [Internet] [cited 2024 Feb 29];Available from: <ext-link ext-link-type="uri" xlink:href="https://www.beckershospitalreview.com/disruptors/amazon-clinic-adds-virtual-primary-care-company-to-marketplace.html">https://www.beckershospitalreview.com/disruptors/amazon-clinic-adds-virtual-primary-care-company-to-marketplace.html</ext-link></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other"><bold>Kingson J.</bold> New AI-powered doctor&#x02019;s office allows patients to draw blood, take vitals. Axios [Internet] [cited 2024 Feb 29];Available from: <ext-link ext-link-type="uri" xlink:href="https://www.axios.com/2023/12/08/carepod-forward-doctors-office-telehealth-telemedicine">https://www.axios.com/2023/12/08/carepod-forward-doctors-office-telehealth-telemedicine</ext-link></mixed-citation></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name><surname>Nayak</surname><given-names>A</given-names></name><name><surname>Vakili</surname><given-names>S</given-names></name><name><surname>Nayak</surname><given-names>K</given-names></name><etal/></person-group><article-title>Use of Voice-Based Conversational Artificial Intelligence for Basal Insulin Prescription Management Among Patients With Type 2 Diabetes: A Randomized Clinical Trial</article-title><source>JAMA Netw Open</source><year>2023</year><volume>6</volume><issue>12</issue><fpage>e2340232</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2023.40232</pub-id><pub-id pub-id-type="pmid">38039007</pub-id>
</element-citation><mixed-citation id="mc-CR22" publication-type="journal"><bold>Nayak A, Vakili S, Nayak K, et al.</bold> Use of voice-based conversational artificial intelligence for basal insulin prescription management among patients with type 2 diabetes: a randomized clinical trial. JAMA Netw Open 2023;6(12):e2340232.<pub-id pub-id-type="pmid">38039007</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Large language models encode clinical knowledge. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41586-023-06291-2">https://www.nature.com/articles/s41586-023-06291-2</ext-link></mixed-citation></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name><surname>Bhattacharyya</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>VM</given-names></name><name><surname>Bhattacharyya</surname><given-names>D</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><article-title>High Rates of Fabricated and Inaccurate References in ChatGPT-Generated Medical Content</article-title><source>Cureus</source><year>2023</year><volume>15</volume><issue>5</issue><fpage>e39238</fpage><pub-id pub-id-type="pmid">37337480</pub-id>
</element-citation><mixed-citation id="mc-CR24" publication-type="journal"><bold>Bhattacharyya M, Miller VM, Bhattacharyya D, Miller LE.</bold> High rates of fabricated and inaccurate references in chatGPT-generated medical content. Cureus 2023;15(5):e39238.<pub-id pub-id-type="pmid">37337480</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name><surname>Anderer</surname><given-names>S</given-names></name><name><surname>Hswen</surname><given-names>Y</given-names></name></person-group><article-title>AI Developers Should Understand the Risks of Deploying Their Clinical Tools, MIT Expert Says</article-title><source>JAMA</source><year>2024</year><volume>331</volume><issue>8</issue><fpage>629</fpage><pub-id pub-id-type="doi">10.1001/jama.2023.22981</pub-id><pub-id pub-id-type="pmid">38324320</pub-id>
</element-citation><mixed-citation id="mc-CR25" publication-type="journal"><bold>Anderer S, Hswen Y.</bold> AI developers should understand the risks of deploying their clinical tools, MIT expert says. JAMA 2024;331(8):629.<pub-id pub-id-type="pmid">38324320</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name><surname>Bodenheimer</surname><given-names>T</given-names></name></person-group><article-title>Revitalizing Primary Care, Part 1: Root Causes of Primary Care&#x02019;s Problems</article-title><source>Ann Fam Med</source><year>2022</year><volume>20</volume><issue>5</issue><fpage>464</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1370/afm.2858</pub-id><pub-id pub-id-type="pmid">36228065</pub-id>
</element-citation><mixed-citation id="mc-CR26" publication-type="journal"><bold>Bodenheimer T.</bold> Revitalizing primary care, Part 1: Root causes of primary care&#x02019;s problems. Ann Fam Med 2022;20(5):464&#x02013;8.<pub-id pub-id-type="pmid">36228065</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Lin</surname><given-names>D</given-names></name><name><surname>Pforsich</surname><given-names>H</given-names></name><name><surname>Lin</surname><given-names>VW</given-names></name></person-group><article-title>Physician workforce in the United States of America: forecasting nationwide shortages</article-title><source>Hum Resour Health</source><year>2020</year><volume>18</volume><issue>1</issue><fpage>8</fpage><pub-id pub-id-type="doi">10.1186/s12960-020-0448-3</pub-id><pub-id pub-id-type="pmid">32029001</pub-id>
</element-citation><mixed-citation id="mc-CR27" publication-type="journal"><bold>Zhang X, Lin D, Pforsich H, Lin VW.</bold> Physician workforce in the United States of America: forecasting nationwide shortages. Hum Resour Health 2020;18(1):8.<pub-id pub-id-type="pmid">32029001</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Survey of Physician Appointment Wait Times and Medicare and Medicaid Acceptance Rates. AMN Healthcare/Merritt Hawkins; 2022.</mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other"><bold>Patel SY, Auerbach D, Huskamp HA, et al.</bold> Provision of evaluation and management visits by nurse practitioners and physician assistants in the USA from 2013 to 2019: cross-sectional time series study. BMJ 2023;e073933</mixed-citation></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>S</given-names></name><name><surname>Shah</surname><given-names>S</given-names></name><name><surname>Sattler</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>M</given-names></name></person-group><article-title>Predicting Avoidable Health Care Utilization: Practical Considerations for Artificial Intelligence/Machine Learning Models in Population Health</article-title><source>Mayo Clin Proc</source><year>2022</year><volume>97</volume><issue>4</issue><fpage>653</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1016/j.mayocp.2021.11.039</pub-id><pub-id pub-id-type="pmid">35379419</pub-id>
</element-citation><mixed-citation id="mc-CR30" publication-type="journal"><bold>Lin S, Shah S, Sattler A, Smith M.</bold> Predicting avoidable health care utilization: Practical Considerations for Artificial Intelligence/Machine Learning Models in Population Health. Mayo Clin Proc 2022;97(4):653&#x02013;7.<pub-id pub-id-type="pmid">35379419</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Institute of Medicine (US) Committee on Quality of Health Care in America. To Err is Human: Building a Safer Health System [Internet]. Washington (DC): National Academies Press (US); 2000 [cited 2023 Dec 31]. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/books/NBK225182/">http://www.ncbi.nlm.nih.gov/books/NBK225182/</ext-link></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Presidents Council of Advisors on Science and Technology. Report to the President: A Transformational Effort on Patient Safety. 2023.</mixed-citation></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name><surname>Adler-Milstein</surname><given-names>J</given-names></name><name><surname>Jha</surname><given-names>AK</given-names></name></person-group><article-title>HITECH Act Drove Large Gains In Hospital Electronic Health Record Adoption</article-title><source>Health Aff (Millwood)</source><year>2017</year><volume>36</volume><issue>8</issue><fpage>1416</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1377/hlthaff.2016.1651</pub-id><pub-id pub-id-type="pmid">28784734</pub-id>
</element-citation><mixed-citation id="mc-CR33" publication-type="journal"><bold>Adler-Milstein J, Jha AK.</bold> HITECH act drove large gains in hospital electronic health record adoption. Health Aff (Millwood) 2017;36(8):1416&#x02013;22.<pub-id pub-id-type="pmid">28784734</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">National Trends in Hospital and Physician Adoption of Electronic Health Records. Office of the National Coordinator for Health Information Technology.;</mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other"><bold>Kane C.</bold> Recent Changes in Physician Practice Arrangements: Shifts Away from Private Practice and Towards Larger Practice Size Continue Through 2022. American Medical Association; 2023.</mixed-citation></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name><surname>McMahon</surname><given-names>LF</given-names></name><name><surname>Rize</surname><given-names>K</given-names></name><name><surname>Irby-Johnson</surname><given-names>N</given-names></name><name><surname>Chopra</surname><given-names>V</given-names></name></person-group><article-title>Designed to Fail? the Future of Primary Care</article-title><source>J Gen Intern Med</source><year>2021</year><volume>36</volume><issue>2</issue><fpage>515</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1007/s11606-020-06077-6</pub-id><pub-id pub-id-type="pmid">32728962</pub-id>
</element-citation><mixed-citation id="mc-CR36" publication-type="journal"><bold>McMahon LF, Rize K, Irby-Johnson N, Chopra V.</bold> Designed to Fail? the future of primary care. J Gen Intern Med 2021;36(2):515&#x02013;7.<pub-id pub-id-type="pmid">32728962</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>A</given-names></name><name><surname>Ayub</surname><given-names>MH</given-names></name><name><surname>Mishuris</surname><given-names>RG</given-names></name><etal/></person-group><article-title>Telehealth Policy, Practice, and Education: a Position Statement of the Society of General Internal Medicine</article-title><source>J Gen Intern Med</source><year>2023</year><volume>38</volume><issue>11</issue><fpage>2613</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1007/s11606-023-08190-8</pub-id><pub-id pub-id-type="pmid">37095331</pub-id>
</element-citation><mixed-citation id="mc-CR37" publication-type="journal"><bold>Chen A, Ayub MH, Mishuris RG, et al.</bold> Telehealth Policy, Practice, and education: a Position statement of the society of general internal medicine. J Gen Intern Med 2023;38(11):2613&#x02013;20.<pub-id pub-id-type="pmid">37095331</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other"><bold>Kane C.</bold> Telehealth in 2022: Availability Remains Strong but Accounts for a Small Share of Patient Visits for Most Physicians. American Medical Association; 2023.</mixed-citation></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name><surname>Shanafelt</surname><given-names>TD</given-names></name><name><surname>West</surname><given-names>CP</given-names></name><name><surname>Dyrbye</surname><given-names>LN</given-names></name><etal/></person-group><article-title>Changes in Burnout and Satisfaction With Work-Life Integration in Physicians During the First 2 Years of the COVID-19 Pandemic</article-title><source>Mayo Clin Proc</source><year>2022</year><volume>97</volume><issue>12</issue><fpage>2248</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/j.mayocp.2022.09.002</pub-id><pub-id pub-id-type="pmid">36229269</pub-id>
</element-citation><mixed-citation id="mc-CR39" publication-type="journal"><bold>Shanafelt TD, West CP, Dyrbye LN, et al.</bold> Changes in burnout and satisfaction with work-life integration in physicians during the first 2 years of the COVID-19 pandemic. Mayo Clin Proc 2022;97(12):2248&#x02013;58.<pub-id pub-id-type="pmid">36229269</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other"><bold>Jain S.</bold> Have We Overcomplicated The American Physician Burnout Conversation? Forbes [Internet] 2022 [cited 2023 Dec 20];Available from: <ext-link ext-link-type="uri" xlink:href="https://www.forbes.com/sites/sachinjain/2022/10/17/have-we-overcomplicated-the-american-physician-burnout-conversation/?sh=68e0ef867545">https://www.forbes.com/sites/sachinjain/2022/10/17/have-we-overcomplicated-the-american-physician-burnout-conversation/?sh=68e0ef867545</ext-link></mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other"><bold>Pearl R.</bold> Malcolm Gladwell: Tell People What It&#x02019;s Really Like To Be A Doctor. Forbes [Internet] [cited 2023 Dec 20];Available from: <ext-link ext-link-type="uri" xlink:href="https://www.forbes.com/sites/robertpearl/2014/03/13/malcolm-gladwell-tell-people-what-its-really-like-to-be-a-doctor/?sh=2b855ea74420">https://www.forbes.com/sites/robertpearl/2014/03/13/malcolm-gladwell-tell-people-what-its-really-like-to-be-a-doctor/?sh=2b855ea74420</ext-link></mixed-citation></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name><surname>Sinsky</surname><given-names>C</given-names></name><name><surname>Colligan</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>L</given-names></name><etal/></person-group><article-title>Allocation of Physician Time in Ambulatory Practice: A Time and Motion Study in 4 Specialties</article-title><source>Ann Intern Med</source><year>2016</year><volume>165</volume><issue>11</issue><fpage>753</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.7326/M16-0961</pub-id><pub-id pub-id-type="pmid">27595430</pub-id>
</element-citation><mixed-citation id="mc-CR42" publication-type="journal"><bold>Sinsky C, Colligan L, Li L, et al.</bold> Allocation of physician time in ambulatory practice: a time and motion study in 4 specialties. Ann Intern Med 2016;165(11):753&#x02013;60.<pub-id pub-id-type="pmid">27595430</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name><surname>Rotenstein</surname><given-names>LS</given-names></name><name><surname>Holmgren</surname><given-names>AJ</given-names></name><name><surname>Horn</surname><given-names>DM</given-names></name><etal/></person-group><article-title>System-Level Factors and Time Spent on Electronic Health Records by Primary Care Physicians</article-title><source>JAMA Netw Open</source><year>2023</year><volume>6</volume><issue>11</issue><fpage>e2344713</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2023.44713</pub-id><pub-id pub-id-type="pmid">37991757</pub-id>
</element-citation><mixed-citation id="mc-CR43" publication-type="journal"><bold>Rotenstein LS, Holmgren AJ, Horn DM, et al.</bold> System-level factors and time spent on electronic health records by primary care physicians. JAMA Netw Open 2023;6(11):e2344713.<pub-id pub-id-type="pmid">37991757</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR44"><label>44.</label><citation-alternatives><element-citation id="ec-CR44" publication-type="journal"><person-group person-group-type="author"><name><surname>Porter</surname><given-names>J</given-names></name><name><surname>Boyd</surname><given-names>C</given-names></name><name><surname>Skandari</surname><given-names>MR</given-names></name><name><surname>Laiteerapong</surname><given-names>N</given-names></name></person-group><article-title>Revisiting the Time Needed to Provide Adult Primary Care</article-title><source>J Gen Intern Med</source><year>2023</year><volume>38</volume><issue>1</issue><fpage>147</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1007/s11606-022-07707-x</pub-id><pub-id pub-id-type="pmid">35776372</pub-id>
</element-citation><mixed-citation id="mc-CR44" publication-type="journal"><bold>Porter J, Boyd C, Skandari MR, Laiteerapong N.</bold> Revisiting the time needed to provide adult primary care. J Gen Intern Med 2023;38(1):147&#x02013;55.<pub-id pub-id-type="pmid">35776372</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR45"><label>45.</label><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name><surname>Tai-Seale</surname><given-names>M</given-names></name><name><surname>Dillon</surname><given-names>EC</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Physicians&#x02019; Well-Being Linked To In-Basket Messages Generated By Algorithms In Electronic Health Records</article-title><source>Health Aff (Millwood)</source><year>2019</year><volume>38</volume><issue>7</issue><fpage>1073</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1377/hlthaff.2018.05509</pub-id><pub-id pub-id-type="pmid">31260371</pub-id>
</element-citation><mixed-citation id="mc-CR45" publication-type="journal"><bold>Tai-Seale M, Dillon EC, Yang Y, et al.</bold> Physicians&#x02019; well-being linked to in-basket messages generated by algorithms in electronic health records. Health Aff (Millwood) 2019;38(7):1073&#x02013;8.<pub-id pub-id-type="pmid">31260371</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR46"><label>46.</label><citation-alternatives><element-citation id="ec-CR46" publication-type="journal"><person-group person-group-type="author"><name><surname>Ligibel</surname><given-names>JA</given-names></name><name><surname>Goularte</surname><given-names>N</given-names></name><name><surname>Berliner</surname><given-names>JI</given-names></name><etal/></person-group><article-title>Well-Being Parameters and Intention to Leave Current Institution Among Academic Physicians</article-title><source>JAMA Netw Open</source><year>2023</year><volume>6</volume><issue>12</issue><fpage>e2347894</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2023.47894</pub-id><pub-id pub-id-type="pmid">38100103</pub-id>
</element-citation><mixed-citation id="mc-CR46" publication-type="journal"><bold>Ligibel JA, Goularte N, Berliner JI, et al.</bold> Well-being parameters and intention to leave current institution among academic physicians. JAMA Netw Open 2023;6(12):e2347894.<pub-id pub-id-type="pmid">38100103</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR47"><label>47.</label><citation-alternatives><element-citation id="ec-CR47" publication-type="journal"><person-group person-group-type="author"><name><surname>Shachak</surname><given-names>A</given-names></name><name><surname>Reis</surname><given-names>S</given-names></name></person-group><article-title>The impact of electronic medical records on patient&#x02013;doctor communication during consultation: a narrative literature review</article-title><source>J Eval Clin Pract</source><year>2009</year><volume>15</volume><issue>4</issue><fpage>641</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2753.2008.01065.x</pub-id><pub-id pub-id-type="pmid">19522722</pub-id>
</element-citation><mixed-citation id="mc-CR47" publication-type="journal"><bold>Shachak A, Reis S.</bold> The impact of electronic medical records on patient&#x02013;doctor communication during consultation: a narrative literature review. J Eval Clin Pract 2009;15(4):641&#x02013;9.<pub-id pub-id-type="pmid">19522722</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="other">The Patient Experience: Perspectives on Today&#x02019;s Healthcare [Internet]. The Harris Poll; 2023. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.aapa.org/download/113513/?tmstv=1684243672">https://www.aapa.org/download/113513/?tmstv=1684243672</ext-link></mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other"><bold>Bhasker S, Bruce D, Lamb J, Stein G.</bold> Tackling healthcare&#x02019;s biggest burdens with generative AI [Internet]. McKinsey and Company; 2023. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.mckinsey.com/industries/healthcare/our-insights/tackling-healthcares-biggest-burdens-with-generative-ai#">https://www.mckinsey.com/industries/healthcare/our-insights/tackling-healthcares-biggest-burdens-with-generative-ai#</ext-link>/</mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other"><bold>Tierney AA, Gayre G, Hoberman B, et al.</bold> Ambient Artificial Intelligence Scribes to Alleviate the Burden of Clinical Documentation. NEJM Catal [Internet] 2024 [cited 2024 Mar 1];5(3). Available from: http://catalyst.nejm.org/doi/10.1056/CAT.23.0404</mixed-citation></ref><ref id="CR51"><label>51.</label><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia</surname><given-names>P</given-names></name><name><surname>Ma</surname><given-names>SP</given-names></name><name><surname>Shah</surname><given-names>S</given-names></name><etal/></person-group><article-title>Artificial Intelligence-Generated Draft Replies to Patient Inbox Messages</article-title><source>JAMA Netw Open</source><year>2024</year><volume>7</volume><issue>3</issue><fpage>e243201</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.3201</pub-id><pub-id pub-id-type="pmid">38506805</pub-id>
</element-citation><mixed-citation id="mc-CR51" publication-type="journal"><bold>Garcia P, Ma SP, Shah S, et al.</bold> Artificial intelligence&#x02013;generated draft replies to patient inbox messages. JAMA Netw Open 2024;7(3):e243201.<pub-id pub-id-type="pmid">38506805</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR52"><label>52.</label><citation-alternatives><element-citation id="ec-CR52" publication-type="journal"><person-group person-group-type="author"><name><surname>Ayers</surname><given-names>JW</given-names></name><name><surname>Poliak</surname><given-names>A</given-names></name><name><surname>Dredze</surname><given-names>M</given-names></name><etal/></person-group><article-title>Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum</article-title><source>JAMA Intern Med</source><year>2023</year><volume>183</volume><issue>6</issue><fpage>589</fpage><pub-id pub-id-type="doi">10.1001/jamainternmed.2023.1838</pub-id><pub-id pub-id-type="pmid">37115527</pub-id>
</element-citation><mixed-citation id="mc-CR52" publication-type="journal"><bold>Ayers JW, Poliak A, Dredze M, et al.</bold> Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. JAMA Intern Med 2023;183(6):589.<pub-id pub-id-type="pmid">37115527</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR53"><label>53.</label><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name><surname>Zaretsky</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>JM</given-names></name><name><surname>Baskharoun</surname><given-names>S</given-names></name><etal/></person-group><article-title>Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format</article-title><source>JAMA Netw Open</source><year>2024</year><volume>7</volume><issue>3</issue><fpage>e240357</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2024.0357</pub-id><pub-id pub-id-type="pmid">38466307</pub-id>
</element-citation><mixed-citation id="mc-CR53" publication-type="journal"><bold>Zaretsky J, Kim JM, Baskharoun S, et al.</bold> Generative artificial intelligence to transform inpatient discharge summaries to patient-friendly language and format. JAMA Netw Open 2024;7(3):e240357.<pub-id pub-id-type="pmid">38466307</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR54"><label>54.</label><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>T-C</given-names></name><name><surname>Staller</surname><given-names>K</given-names></name><name><surname>Botoman</surname><given-names>V</given-names></name><name><surname>Pathipati</surname><given-names>MP</given-names></name><name><surname>Varma</surname><given-names>S</given-names></name><name><surname>Kuo</surname><given-names>B</given-names></name></person-group><article-title>ChatGPT Answers Common Patient Questions About Colonoscopy</article-title><source>Gastroenterology</source><year>2023</year><volume>165</volume><issue>2</issue><fpage>509</fpage><lpage>511.e7</lpage><pub-id pub-id-type="doi">10.1053/j.gastro.2023.04.033</pub-id><pub-id pub-id-type="pmid">37150470</pub-id>
</element-citation><mixed-citation id="mc-CR54" publication-type="journal"><bold>Lee T-C, Staller K, Botoman V, Pathipati MP, Varma S, Kuo B.</bold> ChatGPT answers common patient questions about colonoscopy. Gastroenterology 2023;165(2):509-511.e7.<pub-id pub-id-type="pmid">37150470</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Ethics and Governance of Artificial Intelligence for Health [Internet]. World Health Organization; 2021. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/publications/i/item/9789240029200">https://www.who.int/publications/i/item/9789240029200</ext-link></mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">AI RMF Playbook [Internet]. National Institutes of Standards and Technology; 2022. Available from: <ext-link ext-link-type="uri" xlink:href="https://airc.nist.gov/AI_RMF_Knowledge_Base/Playbook">https://airc.nist.gov/AI_RMF_Knowledge_Base/Playbook</ext-link></mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="other">Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People [Internet]. The White House; Available from: <ext-link ext-link-type="uri" xlink:href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/">https://www.whitehouse.gov/ostp/ai-bill-of-rights/</ext-link></mixed-citation></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="other"><bold>Daneshjou R, Vodrahalli K, Novoa RA, et al. </bold>Disparities in dermatology AI performance on a diverse, curated clinical image set. Sci Adv 2022;8(32):eabq6147.</mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other"><bold>Schwartz R, Vassilev A, Greene K, Perine L, Burt A, Hall P. </bold>Towards a standard for identifying and managing bias in artificial intelligence [Internet]. Gaithersburg, MD: National Institute of Standards and Technology (U.S.); 2022 [cited 2024 Jun 13]. Available from: <ext-link ext-link-type="uri" xlink:href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf">https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf</ext-link></mixed-citation></ref><ref id="CR60"><label>60.</label><citation-alternatives><element-citation id="ec-CR60" publication-type="journal"><person-group person-group-type="author"><name><surname>Obermeyer</surname><given-names>Z</given-names></name><name><surname>Powers</surname><given-names>B</given-names></name><name><surname>Vogeli</surname><given-names>C</given-names></name><name><surname>Mullainathan</surname><given-names>S</given-names></name></person-group><article-title>Dissecting racial bias in an algorithm used to manage the health of populations</article-title><source>Science</source><year>2019</year><volume>366</volume><issue>6464</issue><fpage>447</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1126/science.aax2342</pub-id><pub-id pub-id-type="pmid">31649194</pub-id>
</element-citation><mixed-citation id="mc-CR60" publication-type="journal"><bold>Obermeyer Z, Powers B, Vogeli C, Mullainathan S.</bold> Dissecting racial bias in an algorithm used to manage the health of populations. Science 2019;366(6464):447&#x02013;53.<pub-id pub-id-type="pmid">31649194</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR61"><label>61.</label><citation-alternatives><element-citation id="ec-CR61" publication-type="journal"><person-group person-group-type="author"><name><surname>Rajkomar</surname><given-names>A</given-names></name><name><surname>Hardt</surname><given-names>M</given-names></name><name><surname>Howell</surname><given-names>MD</given-names></name><name><surname>Corrado</surname><given-names>G</given-names></name><name><surname>Chin</surname><given-names>MH</given-names></name></person-group><article-title>Ensuring Fairness in Machine Learning to Advance Health Equity</article-title><source>Ann Intern Med</source><year>2018</year><volume>169</volume><issue>12</issue><fpage>866</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.7326/M18-1990</pub-id><pub-id pub-id-type="pmid">30508424</pub-id>
</element-citation><mixed-citation id="mc-CR61" publication-type="journal"><bold>Rajkomar A, Hardt M, Howell MD, Corrado G, Chin MH.</bold> Ensuring fairness in machine learning to advance health equity. Ann Intern Med 2018;169(12):866&#x02013;72.<pub-id pub-id-type="pmid">30508424</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR62"><label>62.</label><citation-alternatives><element-citation id="ec-CR62" publication-type="journal"><person-group person-group-type="author"><name><surname>DeCamp</surname><given-names>M</given-names></name><name><surname>Lindvall</surname><given-names>C</given-names></name></person-group><article-title>Mitigating bias in AI at the point of care</article-title><source>Science</source><year>2023</year><volume>381</volume><issue>6654</issue><fpage>150</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1126/science.adh2713</pub-id><pub-id pub-id-type="pmid">37440631</pub-id>
</element-citation><mixed-citation id="mc-CR62" publication-type="journal"><bold>DeCamp M, Lindvall C.</bold> Mitigating bias in AI at the point of care. Science 2023;381(6654):150&#x02013;2.<pub-id pub-id-type="pmid">37440631</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="other"><bold>Allyn B.</bold> Google CEO Pichai says Gemini&#x02019;s AI image results &#x0201c;offended our users&#x0201d; [Internet]. NPR. 2024 [cited 2024 Mar 1];Available from: <ext-link ext-link-type="uri" xlink:href="https://www.npr.org/2024/02/28/1234532775/google-gemini-offended-users-images-race">https://www.npr.org/2024/02/28/1234532775/google-gemini-offended-users-images-race</ext-link></mixed-citation></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="other"><bold>Walsh D.</bold> The legal issues presented by generative AI. MIT Manag [Internet] Available from: <ext-link ext-link-type="uri" xlink:href="https://mitsloan.mit.edu/ideas-made-to-matter/legal-issues-presented-generative-ai">https://mitsloan.mit.edu/ideas-made-to-matter/legal-issues-presented-generative-ai</ext-link></mixed-citation></ref><ref id="CR65"><label>65.</label><citation-alternatives><element-citation id="ec-CR65" publication-type="journal"><person-group person-group-type="author"><name><surname>Bak</surname><given-names>M</given-names></name><name><surname>Madai</surname><given-names>VI</given-names></name><name><surname>Fritzsche</surname><given-names>M-C</given-names></name><name><surname>Mayrhofer</surname><given-names>MT</given-names></name><name><surname>McLennan</surname><given-names>S</given-names></name></person-group><article-title>You Can&#x02019;t Have AI Both Ways: Balancing Health Data Privacy and Access Fairly</article-title><source>Front Genet</source><year>2022</year><volume>13</volume><fpage>929453</fpage><pub-id pub-id-type="doi">10.3389/fgene.2022.929453</pub-id><pub-id pub-id-type="pmid">35769991</pub-id>
</element-citation><mixed-citation id="mc-CR65" publication-type="journal"><bold>Bak M, Madai VI, Fritzsche M-C, Mayrhofer MT, McLennan S.</bold> You Can&#x02019;t Have AI Both Ways: Balancing health data privacy and access fairly. Front Genet 2022;13:929453.<pub-id pub-id-type="pmid">35769991</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="other">Artificial Intelligence and Machine Learning (AI/ML) Software as a Medical Device Action Plan [Internet]. Food and Drug Administration; 2021. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device">https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device</ext-link></mixed-citation></ref><ref id="CR67"><label>67.</label><citation-alternatives><element-citation id="ec-CR67" publication-type="journal"><person-group person-group-type="author"><name><surname>Byrd</surname><given-names>TF</given-names></name><name><surname>Southwell</surname><given-names>B</given-names></name><name><surname>Ravishankar</surname><given-names>A</given-names></name><etal/></person-group><article-title>Validation of a Proprietary Deterioration Index Model and Performance in Hospitalized Adults</article-title><source>JAMA Netw Open</source><year>2023</year><volume>6</volume><issue>7</issue><fpage>e2324176</fpage><pub-id pub-id-type="doi">10.1001/jamanetworkopen.2023.24176</pub-id><pub-id pub-id-type="pmid">37486632</pub-id>
</element-citation><mixed-citation id="mc-CR67" publication-type="journal"><bold>Byrd TF, Southwell B, Ravishankar A, et al.</bold> Validation of a proprietary deterioration index model and performance in hospitalized adults. JAMA Netw Open 2023;6(7):e2324176.<pub-id pub-id-type="pmid">37486632</pub-id>
</mixed-citation></citation-alternatives></ref><ref id="CR68"><label>68.</label><citation-alternatives><element-citation id="ec-CR68" publication-type="book"><person-group person-group-type="author"><name><surname>Montgomery</surname><given-names>K</given-names></name></person-group><source>How doctors think: clinical judgment and the practice of medicine</source><year>2006</year><publisher-loc>Oxford; New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation><mixed-citation id="mc-CR68" publication-type="book"><bold>Montgomery K.</bold> How doctors think: clinical judgment and the practice of medicine. Oxford&#x0202f;; New York: Oxford University Press; 2006.</mixed-citation></citation-alternatives></ref></ref-list></back></article>