<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Neuroergon</journal-id><journal-id journal-id-type="iso-abbrev">Front Neuroergon</journal-id><journal-id journal-id-type="publisher-id">Front. Neuroergonomics</journal-id><journal-title-group><journal-title>Frontiers in Neuroergonomics</journal-title></journal-title-group><issn pub-type="epub">2673-6195</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC12098279</article-id><article-id pub-id-type="doi">10.3389/fnrgo.2025.1548861</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroergonomics</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Detecting sources of anger in automated driving: driving-related and external factor</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Maillant</surname><given-names>Jordan</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref><uri xlink:href="http://loop.frontiersin.org/people/2912506/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/data-curation/"/><role content-type="https://credit.niso.org/contributor-roles/formal-analysis/"/><role content-type="https://credit.niso.org/contributor-roles/investigation/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/software/"/><role content-type="https://credit.niso.org/contributor-roles/visualization/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Jallais</surname><given-names>Christophe</given-names></name><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><uri xlink:href="http://loop.frontiersin.org/people/659673/overview"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Dabic</surname><given-names>St&#x000e9;phanie</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><uri xlink:href="http://loop.frontiersin.org/people/1508129/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/methodology/"/><role content-type="https://credit.niso.org/contributor-roles/project-administration/"/><role content-type="https://credit.niso.org/contributor-roles/resources/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Valeo BRAIN Division</institution>, <addr-line>Annemasse</addr-line>, <country>France</country></aff><aff id="aff2"><sup>2</sup><institution>LESCOT, IFSTTAR, Univ Gustave Eiffel, Univ Lyon</institution>, <addr-line>Lyon</addr-line>, <country>France</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Fabien Lotte, Institut National de Recherche en Informatique et en Automatique (INRIA), France</p></fn><fn fn-type="edited-by"><p>Reviewed by: Alessandro Oronzo Caff&#x000f2;, University of Bari Aldo Moro, Italy</p><p>Katharina Lingelbach, Fraunhofer Institute for Industrial Engineering, Germany</p><p>Stefanos Balaskas, University of Patras, Greece</p></fn><corresp id="c001">*Correspondence: Jordan Maillant <email>jordan.maillant@valeo.com</email></corresp></author-notes><pub-date pub-type="epub"><day>09</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>6</volume><elocation-id>1548861</elocation-id><history><date date-type="received"><day>20</day><month>12</month><year>2024</year></date><date date-type="accepted"><day>18</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2025 Maillant, Jallais and Dabic.</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Maillant, Jallais and Dabic</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><sec><title>Introduction</title><p>Anger while driving is often provoked by on-road events like sudden cut-offs but can also arise from external factors, such as rumination of negative thoughts. With the rise of autonomous vehicles, drivers are expected to engage more in non-driving activities, potentially increasing the occurrence of anger stemming from non-driving-related sources. Given the well-established link between anger and aggressive driving behaviors, it is crucial to detect and understand the various origins of anger in autonomous driving contexts to enhance road safety.</p></sec><sec><title>Methods</title><p>This study investigates whether physiological (cardiac and respiratory activities) and ocular indicators of anger vary depending on its source (driving-related or external) in a simulated autonomous driving environment. Using a combination of autobiographical recall (AR) for external anger induction and driving-related scenarios (DS), 47 participants were exposed to anger and/or neutral conditions across four groups.</p></sec><sec><title>Results</title><p>The results revealed that combined anger induction (incorporating both external and driving-related sources) led to higher subjective anger ratings, more heart rate variability. However, when examined separately, individual anger sources did not produce significant differences in physiological responses and ocular strategies.</p></sec><sec><title>Discussion</title><p>These results suggest that the combination of anger-inducing events, rather than the specific source, is more likely to provoke a heightened state of anger. Consequently, future research should employ combined induction methods to effectively elicit anger in experimental settings. Moreover, anger detection systems should focus on the overall interplay of contributing factors rather than distinguishing between individual sources, as it is this cumulative dynamic that more effectively triggers significant anger responses.</p></sec></abstract><kwd-group><kwd>anger sources</kwd><kwd>anger detection</kwd><kwd>physiological indicators</kwd><kwd>ocular behavior</kwd><kwd>subjective evaluations</kwd><kwd>automated driving</kwd></kwd-group><funding-group><funding-statement>The author(s) declare that financial support was received for the research and/or publication of this article. This research was funded by BPI France as part of the SERENITE project (CORAM 2021).</funding-statement></funding-group><counts><fig-count count="5"/><table-count count="4"/><equation-count count="2"/><ref-count count="65"/><page-count count="15"/><word-count count="10130"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Cognitive Neuroergonomics</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><title>1 Introduction</title><p>Anger is the most studied emotion in driving (Zepf et al., <xref rid="B64" ref-type="bibr">2020</xref>) because it has a detrimental impact on driving performance (Jeon et al., <xref rid="B21" ref-type="bibr">2014</xref>) and visual attention (Zhang et al., <xref rid="B65" ref-type="bibr">2016</xref>). Angry drivers are more likely to exhibit aggressive behavior (Mesken et al., <xref rid="B35" ref-type="bibr">2007</xref>; Precht et al., <xref rid="B41" ref-type="bibr">2017</xref>) and may experience delayed reaction times (Steinhauser et al., <xref rid="B50" ref-type="bibr">2018</xref>). Anger can also negatively impact automated driving, resulting in reduced takeover performance (Sanghavi et al., <xref rid="B44" ref-type="bibr">2020</xref>). Given the prevalence of anger and its harmful effects on driving, a lot of research has been carried out in recent years to detect (Zepf et al., <xref rid="B64" ref-type="bibr">2020</xref>) and prevent or mitigate it (Braun et al., <xref rid="B6" ref-type="bibr">2021</xref>). Nevertheless, the question of the source of anger is rarely addressed. This study focuses on anger detection, asking whether the source of anger is important for the detection process.</p><p>Adopting the perspective of appraisal theorists (Moors et al., <xref rid="B37" ref-type="bibr">2013</xref>), anger arises as a consequence of how we evaluate a situation (Wranik and Scherer, <xref rid="B61" ref-type="bibr">2010</xref>). This recursive evaluation as described in Scherer's principal components model (Scherer, <xref rid="B45" ref-type="bibr">2009</xref>), is based on several key factors:</p><list list-type="bullet"><list-item><p>Relevance (to my objectives).</p></list-item><list-item><p>Implication (what does it imply for me, who are the actors and what are their motives).</p></list-item><list-item><p>Coping (what are my reaction options).</p></list-item><list-item><p>Normative significance (in line with my values and social norms).</p></list-item></list><p>For instance, anger may flare up when another driver's inappropriate behavior (implication) blocks us (coping), making us late for an important appointment (relevance). Also, when for example, a driver uses the emergency lane to overtake during a traffic jam (normative significance). Behaviors like weaving and cutting are commonly reported as major triggers of driver anger (Wickens et al., <xref rid="B60" ref-type="bibr">2013</xref>). In automated driving, vehicle behavior can also influence the driver's emotional state (Alsaid et al., <xref rid="B2" ref-type="bibr">2023</xref>). When given the opportunity, some drivers may take control of the vehicle to prevent anger (coping) if it does not behave as they expect (relevance; Pan et al., <xref rid="B39" ref-type="bibr">2024</xref>). This tendency is especially pronounced under time pressure (implications; Techer et al., <xref rid="B54" ref-type="bibr">2019</xref>).</p><p>While anger during driving often stems from the driving environment, it is not exclusive to it, and may involve external factors. In particular, ruminating on episodes of anger while driving could also be a form of anger during driving that negatively affects performance (Suhr, <xref rid="B52" ref-type="bibr">2016</xref>). Furthermore, the rise of autonomous vehicles, which will encourage more non-driving activities, may introduce additional sources of anger. Consequently, anger behind the wheel can arise from a variety of sources, both related and unrelated to the driving environment.</p><p>Although theories have long diverged on the very definition of emotion (for a short review, see Thanapattheerakul et al., <xref rid="B55" ref-type="bibr">2018</xref>), many agree, and it is the case in the component process model (Scherer, <xref rid="B45" ref-type="bibr">2009</xref>), that emotions involve subjective feelings and physiological and behavioral responses. In autonomous driving, the behavioral aspect of driving is only observable when the driver is taking control. As a result, only physiological and subjective cues remain. Detecting physiological variations in the driver could thus provide clues to his/her emotional state. Because of large inter-individual differences, monitoring physiological variations to infer the driver's emotional state is a major challenge pursued both by industrial and academic research.</p><p>With the same aim of studying anger during driving, researchers employ various induction methods such as videos, images, music, autobiographical recall and driving scenarios (Zepf et al., <xref rid="B64" ref-type="bibr">2020</xref>). Even though many of these techniques have been evaluated as suitable to induce anger (Siedlecka and Denson, <xref rid="B46" ref-type="bibr">2019</xref>), they nevertheless rely on different sources of anger (inherent or not to driving). Two questions arise: Do these distinct sources of anger are accompanied by similar or different subjective and physiological responses? Does being angry before being confronted with anger-provoking road events increase the intensity of the feeling of anger and the associated physiological responses? Answering this question would help determine whether the source of anger matters in detecting anger during driving, and whether it should influence the design of future studies and driver state monitoring systems.</p><p>Most research on recognizing drivers' emotions relies on cardiac signals, followed by electrodermal and respiratory data (Zepf et al., <xref rid="B64" ref-type="bibr">2020</xref>). The Autonomic Nervous System (ANS), which regulates various bodily functions, plays a critical role. It is divided into two main branches: the sympathetic and parasympathetic systems, typically associated with arousing and calming effects, respectively. Emotional arousal (whether positive or negative) activates the sympathetic system, and these changes can be observed in the cardiac and respiratory signals. As described in Li and Zheng (<xref rid="B28" ref-type="bibr">2022</xref>), the standard deviation of all normal to normal RR intervals (SDNN) reflects, in the time domain, the balance between sympathetic and parasympathetic activity. RR intervals correspond to the time between two heart beats [R peaks on an electrocardiogram (ECG)]. The mean of the squared successive differences between adjacent RR intervals (RMSSD) is an indicator of parasympathetic activity. In the frequency domain, high frequencies (HF) are indicative of parasympathetic activity, while low frequencies (LF) mainly reflect sympathetic activity. The LF/HF ratio thus represents the relationship between these two activities. Negative emotions, such as fear and anger, are typically linked to reduced parasympathetic activity, as indicated by lower HF and RMSSD values. The relationship between anger and sympathetic activity, measured by heart rate variability (HRV), is more nuanced and remains a topic of debate (Gullett et al., <xref rid="B14" ref-type="bibr">2023</xref>).</p><p>Although general trends linking ANS responses to emotions have been observed (Kreibig, <xref rid="B24" ref-type="bibr">2010</xref>), significant variations exist across studies. These variations seem to be more pronounced for studies presenting inductions unrelated to driving activity (see <xref rid="T1" ref-type="table">Table 1</xref>). Using the driving scenario (DS) to induce anger, an elevated heart rate (HR) was observed in Wan et al. (<xref rid="B58" ref-type="bibr">2017</xref>) and Stephens and Groeger (<xref rid="B51" ref-type="bibr">2011</xref>) but no variation in Wang et al. (<xref rid="B59" ref-type="bibr">2024</xref>) and Mesken et al. (<xref rid="B35" ref-type="bibr">2007</xref>). While anger is induced by non-driving related methods such as autobiographical recall (AR) or films, some authors found increased HR (FakhrHosseini and Jeon, <xref rid="B12" ref-type="bibr">2019</xref>; Marci et al., <xref rid="B33" ref-type="bibr">2007</xref>; Rainville et al., <xref rid="B42" ref-type="bibr">2006</xref>), decrease HR (Lafont et al., <xref rid="B26" ref-type="bibr">2018</xref>, <xref rid="B25" ref-type="bibr">2019</xref>) or no variation (Francis et al., <xref rid="B13" ref-type="bibr">2015</xref>; Wu et al., <xref rid="B62" ref-type="bibr">2019</xref>). On HRV indicators, when anger is induced by DS, the anger group showed an increase in SDNN though no significant changes in RMSSD, LF, HF, and LF/HF (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>). With non-driving related methods, Marci et al. (<xref rid="B33" ref-type="bibr">2007</xref>) reported a decrease in HF while non-significant modulation was measured in Rainville et al. (<xref rid="B42" ref-type="bibr">2006</xref>) and an increase is observed in Francis et al. (<xref rid="B13" ref-type="bibr">2015</xref>). LF was increased in Francis et al. (<xref rid="B13" ref-type="bibr">2015</xref>) and McCraty et al. (<xref rid="B34" ref-type="bibr">1995</xref>). A decrease in the LF/HF ratio alongside an augmentation of RMSSD was also observed in Lafont et al. (<xref rid="B25" ref-type="bibr">2019</xref>).</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Summary of physiological and ocular modulations depending on the source of anger in the cited articles.</p></caption><table frame="box" rules="all"><thead><tr style="background-color:#919498;color:#ffffff"><th valign="top" align="left" rowspan="1" colspan="1">
<bold>Indicators</bold>
</th><th valign="top" align="left" colspan="2" rowspan="1">
<bold>Anger induction method</bold>
</th></tr></thead><tbody><tr style="background-color:#919498;color:#ffffff"><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">
<bold>Related to driving</bold>
</td><td valign="top" align="left" rowspan="1" colspan="1">
<bold>Unrelated to driving</bold>
</td></tr><tr style="background-color:#dee1e1"><td valign="top" align="left" colspan="3" rowspan="1">
<bold>Cardiac</bold>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">HR</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Stephens and Groeger, <xref rid="B51" ref-type="bibr">2011</xref>; Wan et al., <xref rid="B58" ref-type="bibr">2017</xref>) ns (Mesken et al., <xref rid="B35" ref-type="bibr">2007</xref>; Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (FakhrHosseini and Jeon, <xref rid="B12" ref-type="bibr">2019</xref>; Marci et al., <xref rid="B33" ref-type="bibr">2007</xref>; McCraty et al., <xref rid="B34" ref-type="bibr">1995</xref>; Rainville et al., <xref rid="B42" ref-type="bibr">2006</xref>)<break/>&#x02193; (Lafont et al., <xref rid="B26" ref-type="bibr">2018</xref>, <xref rid="B25" ref-type="bibr">2019</xref>)<break/>ns (Francis et al., <xref rid="B13" ref-type="bibr">2015</xref>; Wu et al., <xref rid="B62" ref-type="bibr">2019</xref>)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">SDNN</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Francis et al., <xref rid="B13" ref-type="bibr">2015</xref>)<break/>ns (FakhrHosseini and Jeon, <xref rid="B12" ref-type="bibr">2019</xref>)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">RMSSD</td><td valign="top" align="left" rowspan="1" colspan="1">ns (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Lafont et al., <xref rid="B25" ref-type="bibr">2019</xref>)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LF</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Wan et al., <xref rid="B58" ref-type="bibr">2017</xref>) ns (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Francis et al., <xref rid="B13" ref-type="bibr">2015</xref>; McCraty et al., <xref rid="B34" ref-type="bibr">1995</xref>)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">HF</td><td valign="top" align="left" rowspan="1" colspan="1">ns (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Francis et al., <xref rid="B13" ref-type="bibr">2015</xref>)<break/>&#x02193; (Marci et al., <xref rid="B33" ref-type="bibr">2007</xref>)<break/>ns (McCraty et al., <xref rid="B34" ref-type="bibr">1995</xref>; Rainville et al., <xref rid="B42" ref-type="bibr">2006</xref>)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">LF/HF</td><td valign="top" align="left" rowspan="1" colspan="1">ns (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (McCraty et al., <xref rid="B34" ref-type="bibr">1995</xref>)<break/>&#x02193; (Lafont et al., <xref rid="B26" ref-type="bibr">2018</xref>)</td></tr><tr style="background-color:#dee1e1"><td valign="top" align="left" colspan="3" rowspan="1">
<bold>Respiratory</bold>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">BR</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Wan et al., <xref rid="B58" ref-type="bibr">2017</xref>) ns (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; (Francis et al., <xref rid="B13" ref-type="bibr">2015</xref>; Rainville et al., <xref rid="B42" ref-type="bibr">2006</xref>)</td></tr><tr style="background-color:#dee1e1"><td valign="top" align="left" colspan="3" rowspan="1">
<bold>Ocular</bold>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Saccade amplitude</td><td rowspan="1" colspan="1"/><td valign="top" align="left" rowspan="1" colspan="1">&#x02193; (Lafont et al., <xref rid="B26" ref-type="bibr">2018</xref>)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Fixations</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; fixations on front view &#x0003e;dashboard (Li G. et al., <xref rid="B27" ref-type="bibr">2020</xref>) &#x02191; fixations on front view (Huo et al., <xref rid="B18" ref-type="bibr">2020</xref>) ns vertical gaze variance (Zhang et al., <xref rid="B65" ref-type="bibr">2016</xref>) &#x02193; horizontal gaze variance (Zhang et al., <xref rid="B65" ref-type="bibr">2016</xref>)</td><td valign="top" align="left" rowspan="1" colspan="1">&#x02191; longer fixations duration (Pan et al., <xref rid="B39" ref-type="bibr">2024</xref>)<break/>&#x02193; horizontal gaze variance (Pan et al., <xref rid="B39" ref-type="bibr">2024</xref>)</td></tr></tbody></table><table-wrap-foot><p>&#x02191; indicates a significant increase; &#x02193; indicates a significant decrease; ns indicates a non-significant effect.</p></table-wrap-foot></table-wrap><p>On respiration, breath rate (BR) was higher in Wan et al. (<xref rid="B58" ref-type="bibr">2017</xref>) and no different in Wang et al. (<xref rid="B59" ref-type="bibr">2024</xref>) while regarding induction by DS. BR was higher in Francis et al. (<xref rid="B13" ref-type="bibr">2015</xref>) and Rainville et al. (<xref rid="B42" ref-type="bibr">2006</xref>) following non-driving-related induction.</p><p>In addition to physiological data, eye behavior data can provide valuable insights into a driver's emotional and attentional state (Skaramagkas et al., <xref rid="B47" ref-type="bibr">2021</xref>). A major advantage for future driver-monitoring systems is that this data can be accessed by infra-red camera without obstructing the driver. Anger during driving impairs the ability to perceive potential hazards (Zhang et al., <xref rid="B65" ref-type="bibr">2016</xref>; Pan et al., <xref rid="B39" ref-type="bibr">2024</xref>) and delays the localization of road elements (Jallais et al., <xref rid="B19" ref-type="bibr">2014</xref>). However, there is no consensus on which specific eye characteristics are the most reliable for recognizing emotions (Lim et al., <xref rid="B30" ref-type="bibr">2020</xref>). Despite this, multiple studies, with more evidence for anger induced by DS, suggest a common visual pattern associated with anger. For instance, aggressive drivers have reduced horizontal visual scanning, reduced saccade amplitudes and spend less time monitoring the peripheral environment (Lafont et al., <xref rid="B26" ref-type="bibr">2018</xref>; Li G. et al., <xref rid="B27" ref-type="bibr">2020</xref>; Zhang et al., <xref rid="B65" ref-type="bibr">2016</xref>). They also tend to fixate more on the central field of view (Huo et al., <xref rid="B18" ref-type="bibr">2020</xref>). Pan et al. (<xref rid="B39" ref-type="bibr">2024</xref>) examined anger induction in a study where participants had to regain control of an autonomous vehicle in response to a system failure. Anger induced using a video clip and AR, led to a narrowing of visual scanning, reduced horizontal gaze variance, and prolonged fixation durations. Expanding on this, rumination on negative thoughts increases the likelihood of mind-wandering episodes (Albert et al., <xref rid="B1" ref-type="bibr">2022</xref>), which in turn leads to a narrowing of visual attention while driving (He et al., <xref rid="B16" ref-type="bibr">2011</xref>). Collectively, these findings suggest that anger, regardless of whether it originates from driving or unrelated factors, results in a narrowing visual scanning pattern, impairing drivers' ability to detect potential hazards. Consequently, both sources of anger appear to be associated with similar ocular behaviors.</p><p>To summarize, it would appear that anger induced by DS or AR generally increases HR and BR and leads to a narrower visual scanning. HRV data most often show increased cardiac variability, attributed to sympathetic activity (LF, LF/HF, SDNN). However, less consistent findings in HRV and little evidence from ocular behavior, are highlighted by studies inducing anger by methods unrelated to the driving environment. Finally, being confronted with irritating road events while already angry is not studied, leaving the question open. A summary of the exposed literature is provided in <xref rid="T1" ref-type="table">Table 1</xref>.</p><p>Are the physiological differences reported in these studies due to the difference in anger induction methods? What are the impacts of a combination of these methods? Are the signs of eye behavior (i.e., reduced visual field) common to sources of anger? This study aims to answer this by examining the physiological and ocular markers of anger induced by driving-related scenarios (DS) and/or external sources (Autobiographical Recall, AR) in an automated driving context. We used autonomous driving to minimize the impact of motor actions on physiological responses, recognizing that anger can also arise without controlling the vehicle (Techer et al., <xref rid="B54" ref-type="bibr">2019</xref>). Subjectively, we hypothesize that both DS and AR inductions will similarly elevate subjective anger, marked by increased arousal and diminished valence and perceived control, with combined inductions producing stronger effects. Physiologically, we expect both AR and DS elevate HR and BR with differences regarding variabilities: we expect DS-induced anger provoking higher cardiac variability (increased SDNN, LF, LF/HF and reduced HF, RMSSD) and respiratory variability (reduced RMSSD) associated with excitatory activity. We further expect that the combination of induction would increase these variations. Regarding ocular data, we hypothesize that, compared to a neutral state, anger whether induced by AR or DS would lead to a decline in visual attention, characterized by reduced horizontal scanning and fewer fixations on rear-view mirrors. Finally, given the lack of consensus in the literature regarding the relationship between subjective and physiological manifestations, we aim to further investigate these connections. Specifically, we hypothesize that self-reported levels of anger and arousal will be strongly positively correlated with the HRV indicators SDNN, LF, and LF/HF. The results could inform the design of in-car systems that monitor comprehensive anger dynamics, contributing to safer driving conditions in automated vehicles.</p></sec><sec id="s2"><title>2 Materials and methods</title><sec><title>2.1 Participants</title><p>Fifty-three French volunteers were involved. All were Valeo's workers and had a valid driving license for at least 3 years. Six participants were removed from the analysis due to simulator issues, a poor-quality cardiac signal (&#x0003e;15% of missing data) or poor compliance with instructions. Participants were divided into four groups (<italic>aa, an, na, nn</italic>), where each group experienced different combinations of emotional induction (anger or neutral) through two techniques: Autobiographical Recall (AR) and Driving Scenario (DS). The group names reflect the specific conditions, such as &#x0201c;na&#x0201d; for neutral AR and anger DS. Thirteen participants remained in the <italic>aa</italic> group, 12 in <italic>na</italic>, 12 in <italic>an</italic>, and 10 in the <italic>nn</italic> group. A detailed composition of the groups is presented in <xref rid="T2" ref-type="table">Table 2</xref>.</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Composition of groups: mean age (SD) and sex distribution and experimental session assigned.</p></caption><table frame="box" rules="all"><thead><tr style="background-color:#919498;color:#ffffff"><th valign="top" align="left" rowspan="1" colspan="1">
<bold>Characteristics</bold>
</th><th valign="top" align="center" colspan="4" rowspan="1">
<bold>Names of groups</bold>
</th></tr></thead><tbody><tr style="background-color:#919498;color:#ffffff"><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">
<bold>aa</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>na</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>an</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>nn</bold>
</td></tr><tr style="background-color:#919498;color:#ffffff"><td rowspan="1" colspan="1"/><td valign="top" align="center" colspan="4" rowspan="1">
<bold>Associated inductions</bold>
</td></tr><tr style="background-color:#919498;color:#ffffff"><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">
<bold>Anger AR Anger DS</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>Neutral AR Anger DS</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>Anger AR Neutral DS</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>Neutral AR Neutral DS</bold>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">
<italic>N</italic>
</td><td valign="top" align="center" rowspan="1" colspan="1">13</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">12</td><td valign="top" align="center" rowspan="1" colspan="1">10</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Age (SD)</td><td valign="top" align="center" rowspan="1" colspan="1">34.00 (10.93)</td><td valign="top" align="center" rowspan="1" colspan="1">37.97 (14.95)</td><td valign="top" align="center" rowspan="1" colspan="1">38.14 (13.46)</td><td valign="top" align="center" rowspan="1" colspan="1">34.72 (11.18)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Driving experience</td><td valign="top" align="center" rowspan="1" colspan="1">16.08 (12.72)</td><td valign="top" align="center" rowspan="1" colspan="1">19.67 (15.49)</td><td valign="top" align="center" rowspan="1" colspan="1">20.41 (13.19)</td><td valign="top" align="center" rowspan="1" colspan="1">15.33 (11.47)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">M</td><td valign="top" align="center" rowspan="1" colspan="1">8</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="center" rowspan="1" colspan="1">7</td><td valign="top" align="center" rowspan="1" colspan="1">7</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">F</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">5</td><td valign="top" align="center" rowspan="1" colspan="1">3</td></tr></tbody></table></table-wrap></sec><sec><title>2.2 Experimental design</title><p>A between-subjects factorial design was employed with Group (<italic>aa, an, na, nn</italic>) as the only factor.</p></sec><sec><title>2.3 Apparatus</title><p>Unity 3D software and a fixed-base driving simulator composed of a Logitech G29 steering wheel and pedal set were used (<xref rid="F1" ref-type="fig">Figure 1</xref>). Participants were seated 220&#x02013;240 cm (adjustable seat) from a 65-in. screen. BIOPAC MP160 was used to collect measurements of cardiac and respiratory signals (RSP) at a sampling rate of 500 Hz. The electrocardiogram signal (ECG) was collected from three pre-gelled electrodes (Ag-AgCl) placed on the participant's chest. The respiratory signal was collected from a respiration belt placed right under the chest. Finally, Fovio, a desktop eye tracker was used to capture ocular metrics at a sampling rate of 62 Hz.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p>Overview of the driving simulator. Left <bold>(A)</bold> View of the cabin and screen, Right <bold>(B)</bold>, (1) Position of the eye tracker system, (2) Position of the tactile tablet used to transmit instructions and emotion questionnaires during the experiment.</p></caption><graphic xlink:href="fnrgo-06-1548861-g0001" position="float"/></fig></sec><sec><title>2.4 Anger induction materials</title><sec><title>2.4.1 Autobiographical recall (AR)</title><p>The autobiographical recall technique consists in asking individuals to write down a personal memory in which they strongly experienced the targeted emotion. Similar to the study by Jallais and Gilet (<xref rid="B20" ref-type="bibr">2010</xref>), participants were given 10 min to complete this task. The participants in the anger conditions were asked to recall and write down a situation in which they had experienced anger. They were encouraged to include as many details as possible and to vividly recount the event. For the induction of a neutral emotional state, participants were asked to describe their daily routine for the same duration. Autobiographical recall was chosen because it is the method that most closely approximates the rumination of negative thoughts that individuals might experience while driving.</p></sec><sec><title>2.4.2 Driving scenario (DS)</title><p>Participants were involved either in anger or neutral scenarios. These scenarios were designed to be comparable. Since the ego vehicle operated in autonomous mode, the speed and behavior of both the ego vehicle and surrounding vehicles in the simulation were fully controlled. Four specific events were created to provoke anger in the anger scenario. A detailed description of these events, along with their counterparts in the neutral scenario, is provided in the <xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>.</p></sec></sec><sec><title>2.5 Measures</title><sec><title>2.5.1 Subjective measures</title><p>We asked participants to subjectively report their current emotional state according to both dimensional and categorical emotional scales. This double questioning allowed participants to express their emotional state in different ways, giving us a clearer picture. Also, as the autobiographical recall technique can induce other closely related states such as sadness (Mills and D'Mello, <xref rid="B36" ref-type="bibr">2014</xref>), assessing individuals across multiple emotional states allows us to confirm whether the targeted emotion is indeed the predominant one felt.</p><sec><title>2.5.1.1 Dimensional scales</title><p>The Self-Assessment Manikin (SAM; Bradley and Lang, <xref rid="B5" ref-type="bibr">1994</xref>) a simple visual questionnaire was employed to evaluate valence, arousal and the control dimensions of their emotional state. Definitions given to them were: &#x0201c;Valence, evaluate from negative (left) to positive (right) your emotional state;&#x0201d; &#x0201c;Arousal, evaluate from arouse (left) to calm (right) your emotional state;&#x0201d; &#x0201c;Control, Evaluate from low (left) to high (right) the level of control you exert on your emotional state.</p></sec><sec><title>2.5.1.2 Categorical scale</title><p>For the categorical scales, we asked participants to evaluate from 0 (not at all) to 100 (totally) the level of anger, frustration, joy, pleasure, sadness, disappointment, relief, and serenity felt. The words were chosen to provide a broad spectrum of different emotions to define their state.</p></sec></sec><sec><title>2.5.2 Physiological and ocular measures</title><p>ECG, RSP and eye tracking data were collected from participants all along the experiment. For the ECG and RSP signals, the heart/breath rate (HR, BR) and heart/breath rate variabilities (HRV/BRV) measures were used. The HRV and BRV measures included the root mean square of successive difference (RMSSD). HRV measures also included the standard deviation of normal to normal interval (SDNN), the low and high frequencies (LF and HF) and the ratio LF/HF. Eye metrics were relative to the number of fixations on the peripheral (interior and side mirrors) driving environment and the horizontal/vertical gaze variance (HGV, VGV).</p></sec></sec><sec><title>2.6 Protocol</title><p>After participants fulfilled the consent form, we equipped them with all sensors. We then installed them comfortably in the driving simulator cabin and we proceeded to calibrate the eye tracker. The protocol is summarized in <xref rid="F2" ref-type="fig">Figure 2</xref> and the four steps of training, baseline, AR and DS are documented below.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p>Time course of the experiment. Subjective evaluations are assessed after the baseline, post AR and post DS. Anger effects in physiological and ocular data are only measured from the last minute of the driving scenario.</p></caption><graphic xlink:href="fnrgo-06-1548861-g0002" position="float"/></fig><sec><title>2.6.1 Training</title><p>Participants were trained for ~5 min to drive manually and to switch on/off the autonomous driving mode while respecting system alerts. They were also instructed on how to complete dimensional and categorical emotion questionnaires on the tablet.</p></sec><sec><title>2.6.2 Baseline</title><p>We first conducted a 5-min rest baseline in which participants were seated in the cabin and instructed to do nothing but keep their eyes open. The baseline is further used for data normalization (see Section 2.7.1).</p></sec><sec><title>2.6.3 Autobiographical recall (AR)</title><p>The anger/neutral emotion induction by the autobiographical procedure was performed for 10 min (see Section 2.4).</p></sec><sec><title>2.6.4 Driving scenario (DS)</title><p>Likewise, during the training phase, they were instructed to drive in manual mode while following traffic laws and to switch the autonomous driving mode on and off in response to system alerts. They started in manual mode and quickly the system asked them to give control. During the autonomous drive, four events were manipulated in order to induce anger (see Section 2.4). Moreover, in order to prolong the effect of the emotional induction, they had to constantly think about their emotional experience as long as the vehicle was in autonomous driving mode. The scenario lasted 10 min.</p><p>After baseline, AR and DS phases, participants had to report their emotional state by completing the dimensional and categorical emotion assessments.</p></sec></sec><sec><title>2.7 Data analysis</title><sec><title>2.7.1 Data preprocessing</title><p>We applied a band-pass filter between 2 and 40 Hz. The Python toolbox Neurokit2 (version 0.2.0; Makowski et al., <xref rid="B32" ref-type="bibr">2021</xref>) and hrv-analysis (version 1.0.4; Champseix et al., <xref rid="B9" ref-type="bibr">2021</xref>) was used in order to find peaks in ECG and RSP signals then calculated corresponding features (see Section 2.5). Because some peaks in ECG may be misplaced or absent (e.g., in case of artifacts caused by movements), all ECG signals were manually checked and peaks were replaced if the algorithm failed to do it. A time window of 60 s without overlapping was used in features calculation.</p><p>Delta scores were calculated from subjective (emotion questionnaires) and physiological (ECG, RSP) raw data.</p><p>The following transformation was employed for the subjective data:</p><disp-formula id="E1">
<mml:math id="M1" overflow="scroll"><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;</mml:mtext><mml:mo>=</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;</mml:mtext><mml:mo>-</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;</mml:mtext><mml:mo>=</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;</mml:mtext><mml:mo>-</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula><p>The following transformation was employed for the physiological data (cardiac, respiratory, and electrodermal activities):</p><disp-formula id="E2">
<mml:math id="M2" overflow="scroll"><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:mi>D</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;</mml:mtext><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mtext>&#x000a0;</mml:mtext><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>&#x000a0;</mml:mtext><mml:mo>-</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula><p>Concerning eye tracking, raw data were kept for analysis because we did not instruct participants to watch the driving environment during the baseline phase.</p></sec></sec><sec><title>2.8 Statistical analysis</title><p>To determine whether anger induced from different sources (unrelated vs. driving-related) leads to different subjective and physiological responses, we analyzed the subjective and physiological data feature by feature. The subjective data analyzed in this section correspond to the categorical and dimensional emotion assessments completed by participants. Delta scores (difference from baseline) are compared between groups for each moment (Post AR and Post DS) of assessment. For physiological data, delta scores (ratio from baseline) are compared between groups during the last minute of the automated driving scenario. For ocular data, because of the difference between anger and neutral DS, raw scores were compared between the groups <italic>aa</italic>-<italic>na</italic> (anger DS) and <italic>an</italic>-<italic>nn</italic> (neutral DS) during the last minute of the automated driving scenario.</p><p>The normality of residuals was not assumed for a large majority of the features explored (checked visually from Q-Q plots and calculated with Shapiro-Wilk statistical tests). Therefore, we used the Kruskal-Wallis test, a non-parametric method enabling us to assess differences between the scores of more than two independent groups. R studio (version 2022.12.0) was used for data analysis. <italic>Post-hoc</italic> comparisons were conducted using Dunn's test with Bonferroni corrections (with <italic>p</italic> &#x0003c; 0.05).</p><p>To further explore the relationship between subjective feelings and physiological manifestations, we analyzed correlations by calculating Spearman correlation coefficients. Bonferroni corrections were applied with p &#x0003c; 0.05.</p></sec></sec><sec id="s3"><title>3 Results</title><sec><title>3.1 Subjective evidence</title><sec><title>3.1.1 Dimensional scales assessments</title><p>The results are described below and illustrated in <xref rid="F3" ref-type="fig">Figure 3</xref>.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p>Mean delta scores (difference from baseline) of Valence, Arousal and Control dimensional scale at the different moments (Post AR, Post DS) of the experiment and across the four groups. Error bars represent standard errors. Significant pairwise group comparisons (<italic>p</italic> &#x0003c; 0.05) are reported.</p></caption><graphic xlink:href="fnrgo-06-1548861-g0003" position="float"/></fig><sec><title>Post AR</title><p>Kruskal-Wallis test analysis revealed differences among groups for the valence [<inline-formula><mml:math id="M3" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 21.127, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.422], arousal [<inline-formula><mml:math id="M4" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 16.044, <italic>p</italic> &#x0003c; 0.01, &#x003b7;<sup>2</sup> = 0.303], and control [<inline-formula><mml:math id="M5" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 13.643, <italic>p</italic> &#x0003c; 0.01, &#x003b7;<sup>2</sup> = 0.248] dimensions. <italic>Post hoc</italic> test revealed that the score of valence is lower in the <italic>aa</italic> and <italic>an</italic> groups than both <italic>na</italic> and <italic>nn</italic> (<italic>aa-na, Z</italic> = &#x02212;4.11, <italic>p</italic> &#x0003c; 0.001; <italic>aa-nn, Z</italic> = &#x02212;2.98, <italic>p</italic> = 0.017; <italic>an-na, Z</italic> = &#x02212;3.12, <italic>p</italic> = 0.011). The score of arousal is higher for <italic>aa</italic> and <italic>an</italic> groups only in comparison to the <italic>nn</italic> group (<italic>aa-nn, Z</italic> = 3.32, <italic>p</italic> = 0.005; <italic>an-nn, Z</italic> = 3.10, <italic>p</italic> = 0.012). The score of control is lower in <italic>aa</italic> than <italic>nn</italic> and <italic>na</italic> groups (<italic>aa-nn, Z</italic> = &#x02212;2.94, <italic>p</italic> = 0.020; <italic>aa-na, Z</italic> = &#x02212;2.66, <italic>p</italic> = 0.047).</p></sec><sec><title>Post DS</title><p>Kruskal-Wallis test analysis revealed differences among groups for the valence [<inline-formula><mml:math id="M6" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 12.827, <italic>p</italic> &#x0003c; 0.01, &#x003b7;<sup>2</sup> = 0.229], arousal [<inline-formula><mml:math id="M7" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 15.292, <italic>p</italic> &#x0003c; 0.01, &#x003b7;<sup>2</sup> = 0.286], and control [<inline-formula><mml:math id="M8" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 7.943, <italic>p</italic> &#x0003c; 0.05, &#x003b7;<sup>2</sup> = 0.115]. <italic>Post hoc</italic> test revealed that the score of valence is lower in the <italic>aa</italic> group compared to the <italic>na</italic> and <italic>nn</italic> groups (<italic>aa-na, Z</italic> = &#x02212;2.78, <italic>p</italic> = 0.032<italic>; aa-nn, Z</italic> = &#x02212;3.10, <italic>p</italic> = 0.012). The score of arousal remained significantly higher for <italic>aa, na</italic>, and <italic>an</italic> compared to <italic>nn</italic> (<italic>aa-nn, Z</italic> = 3.78, <italic>p</italic> &#x0003c; 0.001; <italic>na-nn, Z</italic> = 2.87, <italic>p</italic> = 0.025; <italic>an-nn, Z</italic> = 2.65, <italic>p</italic> = 0.049). <italic>Post hoc</italic> tests did not reveal significant differences between groups for the control dimension.</p><p>Because our hypotheses focus solely on the anger score, and in order to facilitate reading, only significant pairwise comparisons about anger evaluation are fully described below and illustrated in <xref rid="F4" ref-type="fig">Figure 4</xref>. Results of Kruskal-Wallis tests for each categorical emotion are provided in the <xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p>Mean delta scores (difference from baseline) of the Anger emotion scale at the different moments (Post AR, Post DS) of the experiment and across the four groups. Error bars represent standard errors. Significant pairwise group comparisons (<italic>p</italic> &#x0003c; 0.05) are reported.</p></caption><graphic xlink:href="fnrgo-06-1548861-g0004" position="float"/></fig></sec></sec><sec><title>3.1.2 Categorical emotion assessments</title><sec><title>Post AR</title><p>Kruskal-Wallis test analysis revealed differences among groups for anger [<inline-formula><mml:math id="M9" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 32.873, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.695], frustration [<inline-formula><mml:math id="M10" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> =12.467, <italic>p</italic> &#x0003c; 0.01, &#x003b7;<sup>2</sup> = 0.220], joy [<inline-formula><mml:math id="M11" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> =17.202, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.330], pleasure [<inline-formula><mml:math id="M12" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 20.388, <italic>p</italic> &#x0003c; 0.001, &#x003b7;<sup>2</sup> = 0.404], sadness [<inline-formula><mml:math id="M13" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> =10.712, <italic>p</italic> &#x0003c; 0.05, &#x003b7;<sup>2</sup> = 0.179], disappointment [<inline-formula><mml:math id="M14" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> =13.488, <italic>p</italic> &#x0003c; 0.01, &#x003b7;<sup>2</sup> = 0.244], and serenity [<inline-formula><mml:math id="M15" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> =9.696, <italic>p</italic> &#x0003c; 0.05, &#x003b7;<sup>2</sup> = 0.156]. <italic>Post hoc</italic> test revealed that the score of anger is higher in the <italic>aa</italic> and <italic>an</italic> groups than both <italic>na</italic> and <italic>nn</italic> groups (<italic>aa-na, Z</italic> = 4.70, <italic>p</italic> &#x0003c; 0.001; <italic>aa-nn, Z</italic> = 4.16, <italic>p</italic> &#x0003c; 0.001; <italic>an-na, Z</italic> = 3.76, <italic>p</italic> = 0.004; <italic>an-nn, Z</italic> = 3.27, <italic>p</italic> = 0.006).</p></sec><sec><title>Post DS</title><p>Kruskal-Wallis test analysis revealed differences among groups for anger [<inline-formula><mml:math id="M16" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 10.441, <italic>p</italic> &#x0003c; 0.05, &#x003b7;<sup>2</sup> = 0.173] and disappointment [<inline-formula><mml:math id="M17" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 8.652, <italic>p</italic> &#x0003c; 0.05, &#x003b7;<sup>2</sup> = 0.131]. <italic>Post hoc</italic> test revealed for anger that the difference <italic>aa</italic>-<italic>nn</italic> remained significant (<italic>Z</italic> = 3.17, <italic>p</italic> = 0.009). Nevertheless, the <italic>na</italic> group did not differ significantly (<italic>Z</italic> = 2.27, <italic>p</italic> = 0.140) from the control group.</p></sec></sec></sec><sec><title>3.2 Physiological and ocular evidence</title><sec><title>3.2.1 ECG</title><p>Kruskal-Wallis test analysis revealed only differences between groups in HRV_SDNN [<inline-formula><mml:math id="M18" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 10.357, <italic>p</italic> &#x0003c; 0.05, &#x003b7;<sup>2</sup> = 0.171]. Nearly significant differences are also observed for HRV_LF [<inline-formula><mml:math id="M19" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 7.477, <italic>p</italic> = 0.058, &#x003b7;<sup>2</sup> = 0.104]. <italic>Post hoc</italic> tests revealed that the <italic>aa</italic> group showed an increase in SDNN compared to <italic>an</italic> (<italic>Z</italic> = 2.89, <italic>p</italic> = 0.023).</p><p>No significant results were obtained for HR, BR, LF/HF, HF, HRV_RMSSD (<italic>ps</italic> &#x0003e; 0.150, see <xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>).</p></sec><sec><title>3.2.2 RSP</title><p>Kruskal-Wallis test analysis revealed nearly significant differences between groups in BRV_RMSSD [<inline-formula><mml:math id="M20" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>&#x003c7;</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> = 7.749, <italic>p</italic> = 0.052, &#x003b7;<sup>2</sup> = 0.110]. The score of RMSSD tended (<italic>Z</italic> = &#x02212;2.56, <italic>p</italic> = 0.063) to be higher for the <italic>nn</italic> group than the <italic>na</italic> group.</p></sec><sec><title>3.2.3 Eye tracking</title><p>Neither Kruskal-Wallis tests of VGV, HGV and the number of fixations on mirrors reached significance for the <italic>aa</italic>-<italic>na</italic> and <italic>an</italic>-<italic>nn</italic> comparisons (<italic>ps</italic> &#x0003e; 0.217, see <xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>).</p><p>Significant results are illustrated in <xref rid="F5" ref-type="fig">Figure 5</xref> and summarized in <xref rid="T3" ref-type="table">Table 3</xref>.</p><fig position="float" id="F5"><label>Figure 5</label><caption><p>Delta scores (rapport from baseline) across groups for HRV_SDNN, HRV_LF and BRV_RMSSD during the last minute of the driving scenarios. Error bars represent standard errors. *<italic>p</italic> &#x0003c; 0.05; . &#x0003c; 0.10.</p></caption><graphic xlink:href="fnrgo-06-1548861-g0005" position="float"/></fig><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>Summary of significant results of Kruskal-Wallis tests regarding subjective (valence, arousal, control, anger), cardiac, respiratory, and eye tracking data.</p></caption><table frame="box" rules="all"><thead><tr style="background-color:#919498;color:#ffffff"><th valign="top" align="left" rowspan="1" colspan="1">
<bold>Indicators</bold>
</th><th valign="top" align="center" rowspan="1" colspan="1">
<bold>Moment</bold>
</th><th valign="top" align="center" rowspan="1" colspan="1">
<bold>&#x003c7;<sup>2</sup></bold>
</th><th valign="top" align="center" rowspan="1" colspan="1">
<bold>
<italic>p</italic>
</bold>
</th><th valign="top" align="center" rowspan="1" colspan="1">
<bold>&#x003b7;<sup>2</sup></bold>
</th><th valign="top" align="center" rowspan="1" colspan="1">
<bold>Group differences</bold>
</th></tr></thead><tbody><tr style="background-color:#dee1e1"><td valign="top" align="left" colspan="6" rowspan="1">
<bold>Subjective</bold>
</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Anger</td><td valign="top" align="center" rowspan="1" colspan="1">Post AR</td><td valign="top" align="center" rowspan="1" colspan="1">32.873</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.001</td><td valign="top" align="center" rowspan="1" colspan="1">0.695</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003e; nn (<italic>Z</italic> = 4.16, <italic>p</italic> &#x0003c; 0.001) aa &#x0003e; na (<italic>Z</italic> = 4.70, <italic>p</italic> &#x0003c; 0.001) an &#x0003e; nn (<italic>Z</italic> = 3.27, <italic>p</italic> = 0.006) an &#x0003e; na (<italic>Z</italic> = 3.76, <italic>p</italic> = 0.004)</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">Post DS</td><td valign="top" align="center" rowspan="1" colspan="1">10.441</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.173</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003e; nn (<italic>Z</italic> = 3.17, <italic>p</italic> = 0.009)</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Arousal</td><td valign="top" align="center" rowspan="1" colspan="1">Post AR</td><td valign="top" align="center" rowspan="1" colspan="1">16.044</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.01</td><td valign="top" align="center" rowspan="1" colspan="1">0.303</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003e; nn (<italic>Z</italic> = 3.32, <italic>p</italic> = 0.005) an &#x0003e; nn (<italic>Z</italic> = 3.10, <italic>p</italic> = 0.012)</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">Post DS</td><td valign="top" align="center" rowspan="1" colspan="1">15.292</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.01</td><td valign="top" align="center" rowspan="1" colspan="1">0.286</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003e; nn (<italic>Z</italic> = 3.78, <italic>p</italic> &#x0003c; 0.001) an &#x0003e; nn (<italic>Z</italic> = 2.65, <italic>p</italic> = 0.049) na &#x0003e; nn (<italic>Z</italic> = 2.87, <italic>p</italic> = 0.025)</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Valence</td><td valign="top" align="center" rowspan="1" colspan="1">Post AR</td><td valign="top" align="center" rowspan="1" colspan="1">21.127</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.001</td><td valign="top" align="center" rowspan="1" colspan="1">0.422</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003c; na (<italic>Z</italic> = &#x02212;4.11, <italic>p</italic> &#x0003c; 0.001) an &#x0003c; na (<italic>Z</italic> = &#x02212;3.12, <italic>p</italic> = 0.011) aa &#x0003c; nn (<italic>Z</italic> = &#x02212;2.98, <italic>p</italic> = 0.017)</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">Post DS</td><td valign="top" align="center" rowspan="1" colspan="1">12.827</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.01</td><td valign="top" align="center" rowspan="1" colspan="1">0.229</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003c; nn (<italic>Z</italic> = &#x02212;3.10, <italic>p</italic> = 0.012) aa &#x0003c; na (<italic>Z</italic> = &#x02212;2.78, <italic>p</italic> = 0.032)</td></tr><tr><td valign="top" align="left" rowspan="2" colspan="1">Control</td><td valign="top" align="center" rowspan="1" colspan="1">Post AR</td><td valign="top" align="center" rowspan="1" colspan="1">13.643</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.01</td><td valign="top" align="center" rowspan="1" colspan="1">0.248</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003c; nn (<italic>Z</italic> = &#x02212;2.94, <italic>p</italic> = 0.020) aa &#x0003c; na (<italic>Z</italic> = &#x02212;2.66, <italic>p</italic> = 0.047)</td></tr><tr><td valign="top" align="center" rowspan="1" colspan="1">Post DS</td><td valign="top" align="center" rowspan="1" colspan="1">7.944</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.115</td><td rowspan="1" colspan="1"/></tr><tr style="background-color:#dee1e1"><td valign="top" align="left" colspan="6" rowspan="1">
<bold>Cardiac</bold>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">HRV_SDNN</td><td valign="top" align="center" rowspan="1" colspan="1">Last minute of DS</td><td valign="top" align="center" rowspan="1" colspan="1">10.357</td><td valign="top" align="center" rowspan="1" colspan="1">&#x0003c;0.05</td><td valign="top" align="center" rowspan="1" colspan="1">0.171</td><td valign="top" align="center" rowspan="1" colspan="1">aa &#x0003e; an (<italic>Z</italic> = 2.89, <italic>p</italic> = 0.023)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">HRV_LF</td><td valign="top" align="center" rowspan="1" colspan="1">Last minute of DS</td><td valign="top" align="center" rowspan="1" colspan="1">7.477</td><td valign="top" align="center" rowspan="1" colspan="1">0.058</td><td valign="top" align="center" rowspan="1" colspan="1">0.104</td><td rowspan="1" colspan="1"/></tr><tr style="background-color:#dee1e1"><td valign="top" align="left" colspan="6" rowspan="1">
<bold>Respiration</bold>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">BRV_RMSSD</td><td valign="top" align="center" rowspan="1" colspan="1">Last minute of DS</td><td valign="top" align="center" rowspan="1" colspan="1">7.749</td><td valign="top" align="center" rowspan="1" colspan="1">0.052</td><td valign="top" align="center" rowspan="1" colspan="1">0.110</td><td rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></sec></sec><sec><title>3.3 Correlations analysis between subjective, physiological, and ocular data</title><p>Spearman correlations analysis were performed to examine the relationships between subjective reports and physiological variables (<xref rid="T4" ref-type="table">Table 4</xref>). Only strong correlations are observed within subjective and cardiac data. Notably, the arousal dimension was positively correlated with anger (rho = 0.55; <italic>p</italic> &#x0003c; 0.01) and negatively correlated with valence (rho = &#x02212;0.49; <italic>p</italic> &#x0003c; 0.05). Valence is positively correlated with control (rho = 0.61; <italic>p</italic> &#x0003c; 0.001). HRV_SDNN was positively correlated with HRV_LF (rho = 0.64; <italic>p</italic> &#x0003c; 0.001) and HRV_RMSSD (rho = 0.60; <italic>p</italic> &#x0003c; 0.001). HRV_LF was also positively correlated with HRV_LF/HF (rho = 0.79; <italic>p</italic> &#x0003c; 0.001) and HRV_RMSSD with HRV_HF (rho = 0.57; <italic>p</italic> &#x0003c; 0.01). However, no significant correlations were observed between subjective and physiological measures.</p><table-wrap position="float" id="T4"><label>Table 4</label><caption><p>Spearman correlations between subjective and physiological variables.</p></caption><table frame="box" rules="all"><thead><tr style="background-color:#919498;color:#ffffff"><th rowspan="1" colspan="1"/><th valign="top" align="center" colspan="10" rowspan="1">
<bold>Variables</bold>
</th></tr></thead><tbody><tr style="background-color:#919498;color:#ffffff"><td valign="top" align="left" rowspan="1" colspan="1">
<bold>Variables</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>1</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>2</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>3</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>4</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>5</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>6</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>7</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>8</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>9</bold>
</td><td valign="top" align="center" rowspan="1" colspan="1">
<bold>10</bold>
</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">1. Anger</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">2. Valence</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">3. Arousal</td><td valign="top" align="center" rowspan="1" colspan="1">0.55</td><td valign="top" align="center" rowspan="1" colspan="1">&#x02212;0.49</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">4. Control</td><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.61</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">5. HRV_SDNN</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">6. HRV_LF</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.64</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">7. HRV_LF/HF</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.79</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">8. HRV_RMSSD</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.60</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">9. HRV_HF</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td valign="top" align="center" rowspan="1" colspan="1">0.57</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">10. BRV_RMSSD</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></sec></sec><sec id="s4"><title>4 Discussion</title><p>Anger is prevalent in driving contexts (Underwood et al., <xref rid="B57" ref-type="bibr">1999</xref>) and can arise from both on-road incidents and external influences, such as sudden cut-offs (Wickens et al., <xref rid="B60" ref-type="bibr">2013</xref>) and negative thought rumination (Suhr, <xref rid="B52" ref-type="bibr">2016</xref>). Given the well-established positive correlation between anger and aggressive driving behaviors (Bogdan et al., <xref rid="B3" ref-type="bibr">2016</xref>), monitoring the driver's emotional state is crucial to enhance road safety. To effectively detect and mitigate anger during driving, it is imperative to understand how anger, originating from both driving environments and external factors, affects physiological responses and visual strategies. This study aimed to explore these dynamics, focusing on how the individual and combined effects of different anger sources impact subjective, physiological responses and visual behavior in driving context. Such understanding is essential to guide the development of adaptive in-car systems and improve driver safety.</p><p>We investigated two distinct sources of anger: non-driving-related anger induced via Autobiographical Recall (AR) and anger triggered by driving-related events during automated driving (Driving Scenario, DS). By employing automated driving, motor activity's influence on physiological signals was minimized, ensuring a clearer assessment of emotional responses. AR simulated rumination of negative thoughts while DS involved realistic scenarios that could provoke anger during driving. Each induction was followed by measurements using subjective reports (dimensional and categorical scales). The physiological data (ECG, RSP), and ocular behavior from the last minute of the driving scenario were compared between groups to assess anger's impact comprehensively.</p><p>The results obtained here demonstrated that combined anger sources elicited more pronounced emotional and physiological responses than either source individually. Specifically, no significant physiological and ocular differences were observed between the two sources when tested separately; however, their subjective emotional impacts varied. AR induced a wider range of negative emotions, including frustration and sadness, while DS revealed large individual variability in anger intensity.</p><p>After discussing the effectiveness of the anger induction techniques used in this study, the subjective, physiological, and ocular evidence highlighted in the results is discussed below and some implications are given for the development of anger control and regulation systems.</p><sec><title>4.1 Effectiveness of AR and DS induction</title><p>The effectiveness of AR in inducing anger was consistent with literature findings (e.g., Jallais and Gilet, <xref rid="B20" ref-type="bibr">2010</xref>). Participants reported high arousal, alongside reduced valence and control immediately after AR induction. Interestingly, while anger was the dominant emotion, other negative feelings such as sadness and frustration also emerged, consistent with (Mills and D'Mello, <xref rid="B36" ref-type="bibr">2014</xref>). One interesting finding concerns the differences between groups <italic>an</italic>-<italic>aa</italic> and <italic>an</italic>-<italic>nn</italic>. In <italic>an</italic> and <italic>aa</italic>, participants were first induced in anger by AR and reported (in post AR measurement) an increase in anger and arousal alongside a reduced valence. In the <italic>an</italic> group (confronted to neutral DS), the anger and valence modulations faded over time (in the post DS measurement) while the increase in arousal remained. In the control group (<italic>nn</italic>), no emotional modulation is observed. This suggests that AR differently modulates anger, valence, and arousal over time. Valence and anger are modulated over a short period, while arousal is modulated over a longer period. Therefore, studies that induce anger using AR and assess its effects solely through anger levels (e.g., FakhrHosseini and Jeon, <xref rid="B12" ref-type="bibr">2019</xref>) should also consider arousal and valence levels to provide a more comprehensive understanding. Additionally, future research should investigate the duration of anger and valence post-induction to better understand their temporal dynamics. To prolong the emotional impact of AR-induced anger, future studies might benefit from integrating emotionally charged music alongside AR (Braun et al., <xref rid="B7" ref-type="bibr">2018</xref>; Steinhauser et al., <xref rid="B50" ref-type="bibr">2018</xref>) to sustain the induced emotional state for longer periods.</p><p>For the DS, incorporating specific impeding events caused minor increases in anger, arousal, and disappointment. Notably, no modulation of valence was observed. While AR effectively reduced valence levels at short-term, DS alone (in the <italic>na</italic> group) did not produce the same effect. This finding should be considered alongside the fact that AR induced sadness, an emotion with negative valence, that DS did not trigger. Thus, although both techniques influenced anger and arousal levels, only AR affected the valence dimensions. Moreover, DS introduced more variability in anger levels than AR did. This variability echoes the findings of Cazes et al. (<xref rid="B8" ref-type="bibr">2024</xref>) on the different profiles of drivers in autonomous driving. Faced with the same situations on the road, participants' reactions differ, ranging from those wishing to take control at the slightest complication to those letting the system handle everything as long as there are no alerts. We therefore believe that the different anger reactions of our participants are linked to these differences in profiles. Those who felt little or no anger in the angry driving scenario may be those who don't want to be in control of the vehicle, letting the system handle any situation. Conversely, those with high anger scores may present a profile of drivers wanting to regain control at all costs in any situation. We recommend that future studies on the autonomous driving paradigm integrate the dimension of situational control, by assessing, for example, the level of trust in automation (K&#x000f6;rber et al., <xref rid="B23" ref-type="bibr">2018</xref>) and the locus of control (&#x000d6;zkan and Lajunen, <xref rid="B38" ref-type="bibr">2005</xref>). Drivers with high takeover willingness should be a focus of further study, as they are prone to more aggressive behaviors during takeovers (Pan et al., <xref rid="B39" ref-type="bibr">2024</xref>).</p><p>The differences observed in the emotions felt after AR and DS inductions resonate with the study of Parkinson's (<xref rid="B40" ref-type="bibr">2001</xref>). Responses from questionnaires highlighted that anger experienced while driving tends to be less intense but more distinct, with fewer emotional blends, compared to anger unrelated to the driving activity. The dimension of valence thus seems to be decisive in understanding the source of anger. Research by Du et al. (<xref rid="B11" ref-type="bibr">2020</xref>) suggests that emotional valence, regardless of arousal level, significantly affects takeover performance in automated driving. In our correlation analysis, the level of emotional valence was not correlated with any of the physiological indicators investigated in this study. This analysis was made between subjective measures taken at post DS and physiological measures taken from the last minute of DS. However, we have previously discussed that valence modulation seems to occur in the short term after AR induction. Thus, while changes in emotional valence influence driving performance, they may not be easily captured by heart/breath physiological measures. To enhance the sensitivity and accuracy of in-vehicle emotional monitoring systems, it is crucial to incorporate additional indicators that can capture emotional valence. We suggest that future studies explore the use of facial expression analysis as a promising approach. Recent advancements in deep learning, such as those reported by Toisoul et al. (<xref rid="B56" ref-type="bibr">2021</xref>), have shown encouraging results in detecting subtle changes in facial expressions.</p></sec><sec><title>4.2 Evidence from physiological data</title><p>Our findings do not support the commonly reported elevation in HR found in previous literature (e.g., FakhrHosseini and Jeon, <xref rid="B12" ref-type="bibr">2019</xref>). Instead, they align with studies that report no significant effects (e.g., Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>). However, HRV data underscored autonomic nervous system activation. The double-induced group presented increased heart rate variability (SDNN, LF (nearly-significant) values) without any change in RMSSD and HF values. These differences were particularly significant for SDNN when comparing the <italic>aa</italic> group with the <italic>an</italic> group.</p><p>SDNN serves as a global measure of long-term sympathetic and parasympathetic activity, while RMSSD and HF primarily reflect parasympathetic modulation, and LF is more indicative of sympathetic activation (Li and Zheng, <xref rid="B28" ref-type="bibr">2022</xref>). Correlation analyses in our study revealed strong associations between SDNN and LF, SDNN and RMSSD, and SDNN and LF/HF. However, no significant correlations were found between subjective emotional responses and physiological measures. The relationship between anger, and SDNN remains debated in the literature. Some studies have reported an increase in SDNN following DS induction (Wang et al., <xref rid="B59" ref-type="bibr">2024</xref>), while others have found no effect of AR induction on SDNN (FakhrHosseini and Jeon, <xref rid="B12" ref-type="bibr">2019</xref>). In our study, neither AR nor DS alone significantly modulated SDNN, but their combination did. On average, anger scores increased by almost 20 points (out of 100) for the <italic>an</italic> and <italic>na</italic> groups, and by almost 30 for the <italic>aa</italic> group. In Wang et al. (<xref rid="B59" ref-type="bibr">2024</xref>) participants reported raw anger scores between 49 and 76 in relation to the events in the driving scenario. This suggests that anger may require a certain intensity threshold before SDNN changes become evident. The observed change may also be linked to regulatory strategies implemented by the participants. Indeed, emotional regulation strategies could influence SDNN outcomes. For instance, Francis et al. (<xref rid="B13" ref-type="bibr">2015</xref>) found that SDNN increased following anger induction via arithmetic tasks and video clips, but rather for participants who had previously taken part in a biofeedback regulation exercise. Further research is needed to clarify the relationship between anger and HRV. To do this, it would be interesting to propose a regulation exercise to the <italic>aa</italic> and <italic>nn</italic> groups and compare their SDNN values with the initial groups.</p><p>Respiratory data revealed that the <italic>na</italic> group exhibited near-significant lower RMSSD value compared to the <italic>nn</italic> group. This supports findings from Ritsert et al. (<xref rid="B43" ref-type="bibr">2022</xref>) and Soni and Muniyandi (<xref rid="B49" ref-type="bibr">2019</xref>), which noted higher RMSSD levels in relaxed individuals or meditators. This marker could be worth exploring further to dynamically measure the effectiveness of regulation aimed at calming an angry state.</p><p>Taken together, cardiac and respiratory results suggest that anger predominantly activates the sympathetic system. However, because physiological indicators of anger are only visible in the double anger induced group, this also suggests that a feeling of anger is not always associated with detectable physiological manifestations.</p><p>According to Scherer's Component Process Model (Scherer, <xref rid="B45" ref-type="bibr">2009</xref>), emotions are dynamic states. They result from continuous, multi-level evaluations of a situation. During the autobiographical recall exercise, individuals might recount events where they felt intense anger in the past but now have come to terms with those experiences. As a result, the initial anger may be less aroused and nuanced with less intense negative emotions, such as sadness or disappointment. This could explain why lower levels of felt anger do not always correspond with clear physiological manifestations. For the DS induction, instead of looking at the difference before/after, continuous monitoring of physiological signals can provide a more nuanced understanding of emotional changes in an angry detection model (Yan et al., <xref rid="B63" ref-type="bibr">2018</xref>).</p></sec><sec><title>4.3 Evidence from ocular data</title><p>Contrary to initial expectations and the literature, angry participants did not display a narrowing of visual attention. This lack of effect may be attributed to autonomous driving when environment supervision is required. However, in the study of Pan et al. (<xref rid="B39" ref-type="bibr">2024</xref>) this narrowing of the visual field was also measured in autonomous driving requiring supervision. The most likely interpretation is related to trust in automation. Previous studies (Hergeth et al., <xref rid="B17" ref-type="bibr">2016</xref>; K&#x000f6;rber et al., <xref rid="B23" ref-type="bibr">2018</xref>) suggested that higher trust correlates with lower road monitoring. Participants in Pan et al. (<xref rid="B39" ref-type="bibr">2024</xref>) were taxi drivers and perhaps they present higher trust toward automation than our participants. This highlights the need for further exploration of the relationship between anger expression and trust in automation.</p></sec><sec><title>4.4 Implications for anger detection and regulation systems</title><p>Our findings suggest that the persistence of anger in the <italic>aa</italic> group may reflect a threshold effect where, once a certain level of anger is reached, anger is sustained with subsequent irritating events. The emergence of anger as an emotion reflects a dynamic process (Scherer, <xref rid="B45" ref-type="bibr">2009</xref>), often preceded by related negative states such as frustration (Bosch et al., <xref rid="B4" ref-type="bibr">2020</xref>).</p><p>Our results have important implications for managing anger in driving contexts. Preemptive strategies, such as mindfulness exercises or creating a calming vehicle environment, should be used to help drivers avoid reaching this threshold. However, when anger crosses this threshold and becomes entrenched, longer-term interventions, such as cognitive approaches (e.g., reappraisal, Harris and Nass, <xref rid="B15" ref-type="bibr">2011</xref>), or strong behavioral strategies that switch attention away (in autonomous driving) may be necessary.</p></sec><sec><title>4.5 Limitations and future directions</title><p>Our study faced limitations, notably a small sample size that restricted analysis of individual differences. Additionally, conducting the study in a driving simulator may not fully replicate real-world driving's complexity and stressors. Future research should aim for larger samples and incorporate real-world driving tests to validate these findings. Anger traits were not assessed in this study but could influence individual variability. The inclusion of the Anger Rumination Scale (ARS; Sukhodolsky et al., <xref rid="B53" ref-type="bibr">2001</xref>) and the Driving Anger Scale (DAS; Deffenbacher et al., <xref rid="B10" ref-type="bibr">1994</xref>) in future research could help clarify these individual differences. Moreover, assessing driver profiles based on locus of control (e.g., multidimensional traffic locus of control; &#x000d6;zkan and Lajunen, <xref rid="B38" ref-type="bibr">2005</xref>) and trust in automation (e.g., K&#x000f6;rber, <xref rid="B22" ref-type="bibr">2019</xref>) could further refine our understanding of anger's impact on different driver types.</p><p>For the development of driver monitoring systems, the user experience factors must be considered. Failures in automated driving systems have been shown to reduce trust and positive experiences, ultimately influencing willingness to use automated vehicles (Liu et al., <xref rid="B31" ref-type="bibr">2021</xref>). People generally agree that their mental state should be monitored in the vehicle (Smyth et al., <xref rid="B48" ref-type="bibr">2021</xref>), but a main concern is that the system is too inaccurate to detect anger (Li S. et al., <xref rid="B29" ref-type="bibr">2020</xref>). To optimize in-vehicle anger regulation systems, we recommend that future in-car systems assess drivers' emotional states upon entering the vehicle rather than solely in response to road events.</p><p>For researchers, we encourage to employ a mix of methods to most effectively induce an angry state. To further understand the evolution of anger in this interplay, we recommend additionally assessing the dimensions of valence and arousal, and monitoring the emotional state after each annoying driving event as proposed in Wang et al. (<xref rid="B59" ref-type="bibr">2024</xref>).</p></sec><sec><title>4.6 Conclusion</title><p>To conclude, while anger induced by driving-related events and autobiographical recall yielded distinct subjective emotional responses, physiological, and ocular responses were similar when analyzed separately. The combination of both sources proved more effective at eliciting and sustaining anger, as evidenced by heightened subjective and physiological changes. These findings emphasize that anger in driving contexts is often the result of cumulative effects, where pre-existing anger can amplify responses to frustrating road events. Rather than focusing on differentiating between sources of anger, systems designed for detecting and managing anger should consider the overall dynamics of contributing factors. Future research should prioritize examining these interactions in real-world settings to validate these findings and optimize in-car systems for better emotional monitoring and regulation support.</p></sec></sec></body><back><ack><p>The authors would like to acknowledge S&#x000e9;bastien Zecchinon for developing the driving environment. We would also like to thank Antoine Favre-F&#x000e9;lix for his help with data pre-processing and Alexandre Oriol for his technical support on the simulator.</p></ack><sec sec-type="data-availability" id="s5"><title>Data availability statement</title><p>The datasets presented in this article are not readily available because the participants of this study did not give written consent for their data to be shared publicly, so due to the sensitive nature of the research supporting data is not available. Requests to access the datasets should be directed to <email>jordan.maillant@valeo.com</email>.</p></sec><sec sec-type="ethics-statement" id="s6"><title>Ethics statement</title><p>The studies involving humans were approved by Comit&#x000e9; pour les recherches impliquant la personne humaine (CRPH). The studies were conducted in accordance with the local legislation and institutional requirements. The participants provided their written informed consent to participate in this study. Written informed consent was obtained from the individual(s) for the publication of any potentially identifiable images or data included in this article.</p></sec><sec sec-type="author-contributions" id="s7"><title>Author contributions</title><p>JM: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Visualization, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. CJ: Funding acquisition, Methodology, Project administration, Resources, Supervision, Writing &#x02013; review &#x00026; editing. SD: Conceptualization, Funding acquisition, Methodology, Project administration, Resources, Supervision, Writing &#x02013; review &#x00026; editing.</p></sec><sec sec-type="COI-statement" id="conf1"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec><sec sec-type="ai-statement" id="s9"><title>Generative AI statement</title><p>The author(s) declare that Gen AI was used in the creation of this manuscript. As the author(s) are not English speakers, generative AI was used to improve the grammar.</p></sec><sec sec-type="disclaimer" id="s10"><title>Publisher's note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><sec sec-type="supplementary-material" id="s11"><title>Supplementary material</title><p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fnrgo.2025.1548861/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fnrgo.2025.1548861/full#supplementary-material</ext-link></p><supplementary-material id="SM1" position="float" content-type="local-data"><media xlink:href="Table_1.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albert</surname><given-names>D. A.</given-names></name><name><surname>Claude Ouimet</surname><given-names>M.</given-names></name><name><surname>Brown</surname><given-names>T. G.</given-names></name></person-group> (<year>2022</year>). <article-title>Negative mood mind wandering and unsafe driving in young male drivers</article-title>. <source>Accid. Anal. Prev.</source>
<volume>178</volume>:<fpage>106867</fpage>. <pub-id pub-id-type="doi">10.1016/j.aap.2022.106867</pub-id><pub-id pub-id-type="pmid">36308858</pub-id>
</mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alsaid</surname><given-names>A.</given-names></name><name><surname>Lee</surname><given-names>J. D.</given-names></name><name><surname>Noejovich</surname><given-names>S. I.</given-names></name><name><surname>Chehade</surname><given-names>A.</given-names></name></person-group> (<year>2023</year>). <article-title>The effect of vehicle automation styles on drivers' emotional state</article-title>. <source>IEEE Trans. Intelligent Transp. Syst.</source>
<volume>24</volume>, <fpage>3963</fpage>&#x02013;<lpage>3973</lpage>. <pub-id pub-id-type="doi">10.1109/TITS.2023.3239880</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogdan</surname><given-names>S. R.</given-names></name><name><surname>M&#x00103;irean</surname><given-names>C.</given-names></name><name><surname>Hav&#x000e2;rneanu</surname><given-names>C.-E.</given-names></name></person-group> (<year>2016</year>). <article-title>A meta-analysis of the association between anger and aggressive driving</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>42</volume>, <fpage>350</fpage>&#x02013;<lpage>364</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2016.05.009</pub-id><pub-id pub-id-type="pmid">26918282</pub-id>
</mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosch</surname><given-names>E.</given-names></name><name><surname>Ihme</surname><given-names>K.</given-names></name><name><surname>Drewitz</surname><given-names>U.</given-names></name><name><surname>Jipp</surname><given-names>M.</given-names></name><name><surname>Oehl</surname><given-names>M.</given-names></name></person-group> (<year>2020</year>). <article-title>Why drivers are frustrated: results from a diary study and focus groups</article-title>. <source>Eur. Transp. Res. Rev.</source>
<volume>12</volume>:<fpage>52</fpage>. <pub-id pub-id-type="doi">10.1186/s12544-020-00441-7</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>M. M.</given-names></name><name><surname>Lang</surname><given-names>P. J.</given-names></name></person-group> (<year>1994</year>). <article-title>Measuring emotion: the self-assessment manikin and the semantic differential</article-title>. <source>J. Behav. Ther. Exp. Psychiatry</source>
<volume>25</volume>, <fpage>49</fpage>&#x02013;<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1016/0005-7916(94)90063-9</pub-id><pub-id pub-id-type="pmid">7962581</pub-id>
</mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname><given-names>M.</given-names></name><name><surname>Weber</surname><given-names>F.</given-names></name><name><surname>Alt</surname><given-names>F.</given-names></name></person-group> (<year>2021</year>). <article-title>Affective automotive user interfaces&#x02013;reviewing the state of driver affect research and emotion regulation in the car</article-title>. <source>ACM Comput. Surv.</source>
<volume>54</volume>, <fpage>1</fpage>&#x02013;<lpage>26</lpage>. <pub-id pub-id-type="doi">10.1145/3460938</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Braun</surname><given-names>M.</given-names></name><name><surname>Weiser</surname><given-names>S.</given-names></name><name><surname>Pfleging</surname><given-names>B.</given-names></name><name><surname>Alt</surname><given-names>F.</given-names></name></person-group> (<year>2018</year>). <article-title>&#x0201c;A comparison of emotion elicitation methods for affective driving studies,&#x0201d;</article-title> in <source>Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications</source> (<publisher-loc>Toronto, ON</publisher-loc>: <publisher-name>ACM</publisher-name>), <fpage>77</fpage>&#x02013;<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1145/3239092.3265945</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cazes</surname><given-names>R.</given-names></name><name><surname>Camps</surname><given-names>V.</given-names></name><name><surname>Lemercier</surname><given-names>C.</given-names></name></person-group> (<year>2024</year>). <article-title>Effect of situational factors known to elicit anger on the willingness to take over the driving activity in a highly automated vehicle: a scenario-based study</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>103</volume>, <fpage>53</fpage>&#x02013;<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2024.03.014</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Champseix</surname><given-names>R.</given-names></name><name><surname>Ribiere</surname><given-names>L.</given-names></name><name><surname>Le Couedic</surname><given-names>C.</given-names></name></person-group> (<year>2021</year>). <article-title>A python package for heart rate variability analysis and signal preprocessing</article-title>. <source>J. Open Res. Softw</source>. <volume>9</volume>:<fpage>28</fpage>. <pub-id pub-id-type="doi">10.5334/jors.305</pub-id><pub-id pub-id-type="pmid">35345583</pub-id>
</mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deffenbacher</surname><given-names>J. L.</given-names></name><name><surname>Oetting</surname><given-names>E. R.</given-names></name><name><surname>Lynch</surname><given-names>R. S.</given-names></name></person-group> (<year>1994</year>). <article-title>Development of a driving anger scale</article-title>. <source>Psychol. Rep.</source>
<volume>74</volume>, <fpage>83</fpage>&#x02013;<lpage>91</lpage>. <pub-id pub-id-type="doi">10.2466/pr0.1994.74.1.83</pub-id><pub-id pub-id-type="pmid">8153239</pub-id>
</mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>N.</given-names></name><name><surname>Zhou</surname><given-names>F.</given-names></name><name><surname>Pulver</surname><given-names>E. M.</given-names></name><name><surname>Tilbury</surname><given-names>D. M.</given-names></name><name><surname>Robert</surname><given-names>L. P.</given-names></name><name><surname>Pradhan</surname><given-names>A. K.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Examining the effects of emotional valence and arousal on takeover performance in conditionally automated driving</article-title>. <source>Transp. Res. Part C Emerg. Technol.</source>
<volume>112</volume>, <fpage>78</fpage>&#x02013;<lpage>87</lpage>. <pub-id pub-id-type="doi">10.1016/j.trc.2020.01.006</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>FakhrHosseini</surname><given-names>S. M.</given-names></name><name><surname>Jeon</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>How do angry drivers respond to emotional music? A comprehensive perspective on assessing emotion</article-title>. <source>J. Multimodal User Interfaces</source>
<volume>13</volume>, <fpage>137</fpage>&#x02013;<lpage>150</lpage>. <pub-id pub-id-type="doi">10.1007/s12193-019-00300-3</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francis</surname><given-names>H. M.</given-names></name><name><surname>Penglis</surname><given-names>K. M.</given-names></name><name><surname>McDonald</surname><given-names>S.</given-names></name></person-group> (<year>2015</year>). <article-title>Manipulation of heart rate variability can modify response to anger-inducing stimuli</article-title>. <source>Soc. Neurosci.</source>
<volume>11</volume>, <fpage>545</fpage>&#x02013;<lpage>552</lpage>. <pub-id pub-id-type="doi">10.1080/17470919.2015.1115777</pub-id><pub-id pub-id-type="pmid">26592092</pub-id>
</mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gullett</surname><given-names>N.</given-names></name><name><surname>Zajkowska</surname><given-names>Z.</given-names></name><name><surname>Walsh</surname><given-names>A.</given-names></name><name><surname>Harper</surname><given-names>R.</given-names></name><name><surname>Mondelli</surname><given-names>V.</given-names></name></person-group> (<year>2023</year>). <article-title>Heart rate variability (HRV) as a way to understand associations between the autonomic nervous system (ANS) and affective states: a critical review of the literature</article-title>. <source>Int. J. Psychophysiol.</source>
<volume>192</volume>, <fpage>35</fpage>&#x02013;<lpage>42</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2023.08.001</pub-id><pub-id pub-id-type="pmid">37543289</pub-id>
</mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>H.</given-names></name><name><surname>Nass</surname><given-names>C.</given-names></name></person-group> (<year>2011</year>). <article-title>&#x0201c;Emotion regulation for frustrating driving contexts,&#x0201d;</article-title> in <source>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</source> (<publisher-loc>Vancouver, BC</publisher-loc>: <publisher-name>ACM</publisher-name>), <fpage>749</fpage>&#x02013;<lpage>752</lpage>. <pub-id pub-id-type="doi">10.1145/1978942.1979050</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>J.</given-names></name><name><surname>Becic</surname><given-names>E.</given-names></name><name><surname>Lee</surname><given-names>Y.-C.</given-names></name><name><surname>McCarley</surname><given-names>J. S.</given-names></name></person-group> (<year>2011</year>). <article-title>Mind wandering behind the wheel: performance and oculomotor correlates</article-title>. <source>Hum. Factors J. Hum. Factors Ergon. Soc.</source>
<volume>53</volume>, <fpage>13</fpage>&#x02013;<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1177/0018720810391530</pub-id><pub-id pub-id-type="pmid">21469530</pub-id>
</mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hergeth</surname><given-names>S.</given-names></name><name><surname>Lorenz</surname><given-names>L.</given-names></name><name><surname>Vilimek</surname><given-names>R.</given-names></name><name><surname>Krems</surname><given-names>J. F.</given-names></name></person-group> (<year>2016</year>). <article-title>Keep your scanners peeled: gaze behavior as a measure of automation trust during highly automated driving</article-title>. <source>Hum. Factors J. Hum. Factors Ergon. Soc.</source>
<volume>58</volume>, <fpage>509</fpage>&#x02013;<lpage>519</lpage>. <pub-id pub-id-type="doi">10.1177/0018720815625744</pub-id><pub-id pub-id-type="pmid">26843570</pub-id>
</mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huo</surname><given-names>D.</given-names></name><name><surname>Ma</surname><given-names>J.</given-names></name><name><surname>Chang</surname><given-names>R.</given-names></name></person-group> (<year>2020</year>). <article-title>Lane-changing-decision characteristics and the allocation of visual attention of drivers with an angry driving style</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>71</volume>, <fpage>62</fpage>&#x02013;<lpage>75</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2020.03.008</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jallais</surname><given-names>C.</given-names></name><name><surname>Gabaude</surname><given-names>C.</given-names></name><name><surname>Paire-Ficout</surname><given-names>L.</given-names></name></person-group> (<year>2014</year>). <article-title>When emotions disturb the localization of road elements: effects of anger and sadness</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>23</volume>, <fpage>125</fpage>&#x02013;<lpage>132</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2013.12.023</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jallais</surname><given-names>C.</given-names></name><name><surname>Gilet</surname><given-names>A.-L.</given-names></name></person-group> (<year>2010</year>). <article-title>Inducing changes in arousal and valence: comparison of two mood induction procedures</article-title>. <source>Behav. Res. Methods</source>
<volume>42</volume>, <fpage>318</fpage>&#x02013;<lpage>325</lpage>. <pub-id pub-id-type="doi">10.3758/BRM.42.1.318</pub-id><pub-id pub-id-type="pmid">20160311</pub-id>
</mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeon</surname><given-names>M.</given-names></name><name><surname>Walker</surname><given-names>B. N.</given-names></name><name><surname>Gable</surname><given-names>T. M.</given-names></name></person-group> (<year>2014</year>). <article-title>Anger effects on driver situation awareness and driving performance</article-title>. <source>Presence Teleoperat. Virtual Environ.</source>
<volume>23</volume>, <fpage>71</fpage>&#x02013;<lpage>89</lpage>. <pub-id pub-id-type="doi">10.1162/PRES_a_00169</pub-id><pub-id pub-id-type="pmid">25959334</pub-id>
</mixed-citation></ref><ref id="B22"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>K&#x000f6;rber</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>&#x0201c;Theoretical considerations and development of a questionnaire to measure trust in automation,&#x0201d;</article-title> in <source>Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018)</source>, eds. S. Bagnara, R. Tartaglia, S. Albolino, T. Alexander, and Y. Fujita (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>13</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000f6;rber</surname><given-names>M.</given-names></name><name><surname>Baseler</surname><given-names>E.</given-names></name><name><surname>Bengler</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <article-title>Introduction matters: manipulating trust in automation and reliance in automated driving</article-title>. <source>Appl. Ergon.</source>
<volume>66</volume>, <fpage>18</fpage>&#x02013;<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1016/j.apergo.2017.07.006</pub-id><pub-id pub-id-type="pmid">28958427</pub-id>
</mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreibig</surname><given-names>S. D.</given-names></name></person-group> (<year>2010</year>). <article-title>Autonomic nervous system activity in emotion: a review</article-title>. <source>Biol. Psychol.</source>
<volume>84</volume>, <fpage>394</fpage>&#x02013;<lpage>421</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2010.03.010</pub-id><pub-id pub-id-type="pmid">20371374</pub-id>
</mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lafont</surname><given-names>A.</given-names></name><name><surname>Rog&#x000e9;</surname><given-names>J.</given-names></name><name><surname>Ndiaye</surname><given-names>D.</given-names></name><name><surname>Boucheix</surname><given-names>J.-M.</given-names></name></person-group> (<year>2019</year>). <article-title>Towards a better understanding of emotion blends: the case of anger-related emotion blends elicited via film clips</article-title>. <source>Cogn. Brain Behav. Interdiscip. J.</source>
<volume>23</volume>, <fpage>77</fpage>&#x02013;<lpage>99</lpage>. <pub-id pub-id-type="doi">10.24193/cbb.2019.23.05</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lafont</surname><given-names>A.</given-names></name><name><surname>Roge</surname><given-names>J.</given-names></name><name><surname>Ndiaye</surname><given-names>D.</given-names></name><name><surname>Boucheix</surname><given-names>J. M.</given-names></name></person-group> (<year>2018</year>). <article-title>Driver's emotional state and detection of vulnerable road users: towards a better understanding of how emotions affect drivers' perception using cardiac and ocular metrics</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>55</volume>, <fpage>141</fpage>&#x02013;<lpage>152</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2018.02.032</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Lai</surname><given-names>W.</given-names></name><name><surname>Sui</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Qu</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Influence of traffic congestion on driver behavior in post-congestion driving</article-title>. <source>Accid. Anal. Prev.</source>
<volume>141</volume>:<fpage>105508</fpage>. <pub-id pub-id-type="doi">10.1016/j.aap.2020.105508</pub-id><pub-id pub-id-type="pmid">32334153</pub-id>
</mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Zheng</surname><given-names>L.</given-names></name></person-group> (<year>2022</year>). <article-title>The mechanism of cardiac sympathetic activity assessment methods: current knowledge</article-title>. <source>Front. Cardiovasc. Med.</source>
<volume>9</volume>:<fpage>931219</fpage>. <pub-id pub-id-type="doi">10.3389/fcvm.2022.931219</pub-id><pub-id pub-id-type="pmid">35811701</pub-id>
</mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>S.</given-names></name><name><surname>Zhang</surname><given-names>T.</given-names></name><name><surname>Liu</surname><given-names>N.</given-names></name><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Tao</surname><given-names>D.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name></person-group> (<year>2020</year>). <article-title>Drivers' attitudes, preference, and acceptance of in-vehicle anger intervention systems and their relationships to demographic and personality characteristics</article-title>. <source>Int. J. Ind. Ergon.</source>
<volume>75</volume>:<fpage>102899</fpage>. <pub-id pub-id-type="doi">10.1016/j.ergon.2019.102899</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>J. Z.</given-names></name><name><surname>Mountstephens</surname><given-names>J.</given-names></name><name><surname>Teo</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Emotion recognition using eye-tracking: taxonomy, review and current challenges</article-title>. <source>Sensors</source> 20 :2384. <pub-id pub-id-type="doi">10.3390/s20082384</pub-id><pub-id pub-id-type="pmid">32331327</pub-id>
</mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>P.</given-names></name><name><surname>Jiang</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>T.</given-names></name><name><surname>Wang</surname><given-names>G.</given-names></name><name><surname>Wang</surname><given-names>R.</given-names></name><name><surname>Xu</surname><given-names>Z.</given-names></name></person-group> (<year>2021</year>). <article-title>User experience and usability when the automated driving system fails: findings from a field experiment</article-title>. <source>Accident Anal. Prev.</source>
<volume>161</volume>:<fpage>106383</fpage>. <pub-id pub-id-type="doi">10.1016/j.aap.2021.106383</pub-id><pub-id pub-id-type="pmid">34469855</pub-id>
</mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makowski</surname><given-names>D.</given-names></name><name><surname>Pham</surname><given-names>T.</given-names></name><name><surname>Lau</surname><given-names>Z. J.</given-names></name><name><surname>Brammer</surname><given-names>J. C.</given-names></name><name><surname>Lespinasse</surname><given-names>F.</given-names></name><name><surname>Pham</surname><given-names>H.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>NeuroKit2: a Python toolbox for neurophysiological signal processing</article-title>. <source>Behav. Res. Methods</source>
<volume>53</volume>, <fpage>1689</fpage>&#x02013;<lpage>1696</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-020-01516-y</pub-id><pub-id pub-id-type="pmid">33528817</pub-id>
</mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marci</surname><given-names>C. D.</given-names></name><name><surname>Glick</surname><given-names>D. M.</given-names></name><name><surname>Loh</surname><given-names>R.</given-names></name><name><surname>Dougherty</surname><given-names>D. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Autonomic and prefrontal cortex responses to autobiographical recall of emotions</article-title>. <source>Cogn. Affect. Behav. Neurosci.</source>
<volume>7</volume>, <fpage>243</fpage>&#x02013;<lpage>250</lpage>. <pub-id pub-id-type="doi">10.3758/CABN.7.3.243</pub-id><pub-id pub-id-type="pmid">17993210</pub-id>
</mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCraty</surname><given-names>R.</given-names></name><name><surname>Atkinson</surname><given-names>M.</given-names></name><name><surname>Tiller</surname><given-names>W. A.</given-names></name><name><surname>Rein</surname><given-names>G.</given-names></name><name><surname>Watkins</surname><given-names>A. D.</given-names></name></person-group> (<year>1995</year>). <article-title>The effects of emotions on short-term power spectrum analysis of heart rate variability</article-title>. <source>Am. J. Cardiol.</source>
<volume>76</volume>, <fpage>1089</fpage>&#x02013;<lpage>1093</lpage>. <pub-id pub-id-type="doi">10.1016/S0002-9149(99)80309-9</pub-id><pub-id pub-id-type="pmid">7484873</pub-id>
</mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mesken</surname><given-names>J.</given-names></name><name><surname>Hagenzieker</surname><given-names>M. P.</given-names></name><name><surname>Rothengatter</surname><given-names>T.</given-names></name><name><surname>de Waard</surname><given-names>D.</given-names></name></person-group> (<year>2007</year>). <article-title>Frequency, determinants, and consequences of different drivers' emotions: an on-the-road study using self-reports, (observed) behaviour, and physiology</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>10</volume>, <fpage>458</fpage>&#x02013;<lpage>475</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2007.05.001</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mills</surname><given-names>C.</given-names></name><name><surname>D'Mello</surname><given-names>S.</given-names></name></person-group> (<year>2014</year>). <article-title>On the validity of the autobiographical emotional memory task for emotion induction</article-title>. <source>PLoS ONE</source>
<volume>9</volume>:<fpage>e95837</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0095837</pub-id><pub-id pub-id-type="pmid">24776697</pub-id>
</mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moors</surname><given-names>A.</given-names></name><name><surname>Ellsworth</surname><given-names>P. C.</given-names></name><name><surname>Scherer</surname><given-names>K. R.</given-names></name><name><surname>Frijda</surname><given-names>N. H.</given-names></name></person-group> (<year>2013</year>). <article-title>Appraisal theories of emotion: state of the art and future development</article-title>. <source>Emot. Rev.</source>
<volume>5</volume>, <fpage>119</fpage>&#x02013;<lpage>124</lpage>. <pub-id pub-id-type="doi">10.1177/1754073912468165</pub-id><pub-id pub-id-type="pmid">27941518</pub-id>
</mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>&#x000d6;zkan</surname><given-names>T.</given-names></name><name><surname>Lajunen</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>). <article-title>Multidimensional traffic locus of control scale (T-LOC): factor structure and relationship to risky driving</article-title>. <source>Personal. Individ. Differ.</source>
<volume>38</volume>, <fpage>533</fpage>&#x02013;<lpage>545</lpage>. <pub-id pub-id-type="doi">10.1016/j.paid.2004.05.007</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>H.</given-names></name><name><surname>Payre</surname><given-names>W.</given-names></name><name><surname>Gao</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name></person-group> (<year>2024</year>). <article-title>Exploring driving anger-caused impairment of takeover performance among professional taxi drivers during partially automated driving</article-title>. <source>Accid. Anal. Prev.</source>
<volume>205</volume>:<fpage>107686</fpage>. <pub-id pub-id-type="doi">10.1016/j.aap.2024.107686</pub-id><pub-id pub-id-type="pmid">38909484</pub-id>
</mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parkinson</surname><given-names>B.</given-names></name></person-group> (<year>2001</year>). <article-title>Anger on and off the road</article-title>. <source>Br. J. Psychol.</source>
<volume>92</volume>, <fpage>507</fpage>&#x02013;<lpage>526</lpage>. <pub-id pub-id-type="doi">10.1348/000712601162310</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Precht</surname><given-names>L.</given-names></name><name><surname>Keinath</surname><given-names>A.</given-names></name><name><surname>Krems</surname><given-names>J. F.</given-names></name></person-group> (<year>2017</year>). <article-title>Effects of driving anger on driver behavior &#x02013; results from naturalistic driving data</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>45</volume>, <fpage>75</fpage>&#x02013;<lpage>92</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2016.10.019</pub-id><pub-id pub-id-type="pmid">32729726</pub-id>
</mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rainville</surname><given-names>P.</given-names></name><name><surname>Bechara</surname><given-names>A.</given-names></name><name><surname>Naqvi</surname><given-names>N.</given-names></name><name><surname>Damasio</surname><given-names>A. R.</given-names></name></person-group> (<year>2006</year>). <article-title>Basic emotions are associated with distinct patterns of cardiorespiratory activity</article-title>. <source>Int. J. Psychophysiol.</source>
<volume>61</volume>, <fpage>5</fpage>&#x02013;<lpage>18</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2005.10.024</pub-id><pub-id pub-id-type="pmid">16439033</pub-id>
</mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritsert</surname><given-names>F.</given-names></name><name><surname>Elgendi</surname><given-names>M.</given-names></name><name><surname>Galli</surname><given-names>V.</given-names></name><name><surname>Menon</surname><given-names>C.</given-names></name></person-group> (<year>2022</year>). <article-title>Heart and breathing rate variations as biomarkers for anxiety detection</article-title>. <source>Bioengineering</source>
<volume>9</volume>:<fpage>711</fpage>. <pub-id pub-id-type="doi">10.3390/bioengineering9110711</pub-id><pub-id pub-id-type="pmid">36421112</pub-id>
</mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanghavi</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Jeon</surname><given-names>M.</given-names></name></person-group> (<year>2020</year>). &#x02018;Effects of anger and display urgency on takeover performance in semi-automated vehicles,&#x0201d; in <italic>12th International Conference on Automotive User Interfaces and Interactive Vehicular Applications, AutomotiveUI '20</italic> (New York, NY: Association for Computing Machinery), <fpage>48</fpage>&#x02013;<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1145/3409120.341066</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scherer</surname><given-names>K. R.</given-names></name></person-group> (<year>2009</year>). <article-title>The dynamic architecture of emotion: evidence for the component process model</article-title>. <source>Cogn. Emot.</source>
<volume>23</volume>, <fpage>1307</fpage>&#x02013;<lpage>1351</lpage>. <pub-id pub-id-type="doi">10.1080/02699930902928969</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siedlecka</surname><given-names>E.</given-names></name><name><surname>Denson</surname><given-names>T. F.</given-names></name></person-group> (<year>2019</year>). <article-title>Experimental methods for inducing basic emotions: a qualitative review</article-title>. <source>Emot. Rev.</source>
<volume>11</volume>, <fpage>87</fpage>&#x02013;<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1177/1754073917749016</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaramagkas</surname><given-names>V.</given-names></name><name><surname>Giannakakis</surname><given-names>G.</given-names></name><name><surname>Ktistakis</surname><given-names>E.</given-names></name><name><surname>Manousos</surname><given-names>D.</given-names></name><name><surname>Karatzanis</surname><given-names>I.</given-names></name><name><surname>Tachos</surname><given-names>N. S.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Review of eye tracking metrics involved in emotional and cognitive processes</article-title>. <source>IEEE Rev. Biomed. Eng.</source>
<volume>16</volume>, <fpage>260</fpage>&#x02013;<lpage>277</lpage>. <pub-id pub-id-type="doi">10.1109/RBME.2021.3066072</pub-id><pub-id pub-id-type="pmid">33729950</pub-id>
</mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smyth</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>H.</given-names></name><name><surname>Donzella</surname><given-names>V.</given-names></name><name><surname>Woodman</surname><given-names>R.</given-names></name></person-group> (<year>2021</year>). <article-title>Public acceptance of driver state monitoring for automated vehicles: applying the UTAUT framework</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>83</volume>, <fpage>179</fpage>&#x02013;<lpage>191</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2021.10.003</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soni</surname><given-names>R.</given-names></name><name><surname>Muniyandi</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>Breath rate variability: a novel measure to study the meditation effects</article-title>. <source>Int. J. Yoga</source> 12 :45. <pub-id pub-id-type="doi">10.4103/ijoy.IJOY_27_17</pub-id><pub-id pub-id-type="pmid">30692783</pub-id>
</mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinhauser</surname><given-names>K.</given-names></name><name><surname>Leist</surname><given-names>F.</given-names></name><name><surname>Maier</surname><given-names>K.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>P&#x000e4;rsch</surname><given-names>N.</given-names></name><name><surname>Rigley</surname><given-names>P.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Effects of emotions on driving behavior</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>59</volume>, <fpage>150</fpage>&#x02013;<lpage>163</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2018.08.012</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephens</surname><given-names>A. N.</given-names></name><name><surname>Groeger</surname><given-names>J. A.</given-names></name></person-group> (<year>2011</year>). <article-title>Anger-congruent behaviour transfers across driving situations</article-title>. <source>Cogn. Emot.</source>
<volume>25</volume>, <fpage>1423</fpage>&#x02013;<lpage>1438</lpage>. <pub-id pub-id-type="doi">10.1080/02699931.2010.551184</pub-id><pub-id pub-id-type="pmid">21432626</pub-id>
</mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suhr</surname><given-names>K. A.</given-names></name></person-group> (<year>2016</year>). <article-title>Mulling over anger: indirect and conditional indirect effects of thought content and trait rumination on aggressive driving</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>42</volume>, <fpage>276</fpage>&#x02013;<lpage>285</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2016.07.016</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sukhodolsky</surname><given-names>D. G.</given-names></name><name><surname>Golub</surname><given-names>A.</given-names></name><name><surname>Cromwell</surname><given-names>E. N.</given-names></name></person-group> (<year>2001</year>). <article-title>Development and validation of the anger rumination scale</article-title>. <source>Pers. Individ. Dif.</source>
<volume>31</volume>, <fpage>689</fpage>&#x02013;<lpage>700</lpage>. <pub-id pub-id-type="doi">10.1016/S0191-8869(00)00171-9</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Techer</surname><given-names>F.</given-names></name><name><surname>Ojeda</surname><given-names>L.</given-names></name><name><surname>Barat</surname><given-names>D.</given-names></name><name><surname>Marteau</surname><given-names>J.-Y.</given-names></name><name><surname>Rampillon</surname><given-names>F.</given-names></name><name><surname>Feron</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Anger and highly automated driving in urban areas: the role of time pressure</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>64</volume>, <fpage>353</fpage>&#x02013;<lpage>360</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2019.05.016</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Thanapattheerakul</surname><given-names>T.</given-names></name><name><surname>Mao</surname><given-names>K.</given-names></name><name><surname>Amoranto</surname><given-names>J.</given-names></name><name><surname>Chan</surname><given-names>J. H.</given-names></name></person-group> (<year>2018</year>). <article-title>&#x0201c;Emotion in a century: a review of emotion recognition,&#x0201d;</article-title> in <source>Proceedings of the 10th International Conference on Advances in Information Technology - IAIT 2018</source> (<publisher-loc>Bangkok</publisher-loc>: <publisher-name>ACM Press</publisher-name>), <fpage>1</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1145/3291280.3291788</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toisoul</surname><given-names>A.</given-names></name><name><surname>Kossaifi</surname><given-names>J.</given-names></name><name><surname>Bulat</surname><given-names>A.</given-names></name><name><surname>Tzimiropoulos</surname><given-names>G.</given-names></name><name><surname>Pantic</surname><given-names>M.</given-names></name></person-group> (<year>2021</year>). <article-title>Estimation of continuous valence and arousal levels from faces in naturalistic conditions</article-title>. <source>Nat. Mach. Intell.</source>
<volume>3</volume>, <fpage>42</fpage>&#x02013;<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1038/s42256-020-00280-0</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Underwood</surname><given-names>G.</given-names></name><name><surname>Chapman</surname><given-names>P.</given-names></name><name><surname>Wright</surname><given-names>S.</given-names></name><name><surname>Crundall</surname><given-names>D.</given-names></name></person-group> (<year>1999</year>). <article-title>Anger while driving</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>2</volume>, <fpage>55</fpage>&#x02013;<lpage>68</lpage>. <pub-id pub-id-type="doi">10.1016/S1369-8478(99)00006-6</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>P.</given-names></name><name><surname>Wu</surname><given-names>C.</given-names></name><name><surname>Lin</surname><given-names>Y.</given-names></name><name><surname>Ma</surname><given-names>X.</given-names></name></person-group> (<year>2017</year>). <article-title>On-road experimental study on driving anger identification model based on physiological features by ROC curve analysis</article-title>. <source>IET Intelligent Transp. Syst.</source>
<volume>11</volume>, <fpage>290</fpage>&#x02013;<lpage>298</lpage>. <pub-id pub-id-type="doi">10.1049/iet-its.2016.0127</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Zheng</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>M.</given-names></name></person-group> (<year>2024</year>). <article-title>Inducing driving anger with multi-stage road events in simulator environment</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>101</volume>, <fpage>403</fpage>&#x02013;<lpage>422</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2024.02.001</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wickens</surname><given-names>C. M.</given-names></name><name><surname>Roseborough</surname><given-names>J. E. W.</given-names></name><name><surname>Hall</surname><given-names>A.</given-names></name><name><surname>Wiesenthal</surname><given-names>D. L.</given-names></name></person-group> (<year>2013</year>). <article-title>Anger-provoking events in driving diaries: a content analysis</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>19</volume>, <fpage>108</fpage>&#x02013;<lpage>120</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2013.02.002</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wranik</surname><given-names>T.</given-names></name><name><surname>Scherer</surname><given-names>K. R.</given-names></name></person-group> (<year>2010</year>). <article-title>&#x0201c;Why do I get angry? A componential appraisal approach,&#x0201d;</article-title> in <source>International Handbook of Anger</source>, eds. M. Potegal, G. Stemmler, and C. Spielberger (New York, NY: Springer New York), <fpage>243</fpage>&#x02013;<lpage>266</lpage>. <pub-id pub-id-type="doi">10.1007/978-0-387-89676-2_15</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Gu</surname><given-names>R.</given-names></name><name><surname>Yang</surname><given-names>Q.</given-names></name><name><surname>Luo</surname><given-names>Y. J.</given-names></name></person-group> (<year>2019</year>). <article-title>How do amusement, anger and fear influence heart rate and heart rate variability?</article-title>
<source>Front. Neurosci.</source>
<volume>13</volume>:<fpage>1131</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2019.01131</pub-id><pub-id pub-id-type="pmid">31680848</pub-id>
</mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>L.</given-names></name><name><surname>Wan</surname><given-names>P.</given-names></name><name><surname>Qin</surname><given-names>L.</given-names></name><name><surname>Zhu</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <article-title>The induction and detection method of angry driving: evidences from EEG and physiological signals</article-title>. <source>Discrete Dyn. Nat. Soc.</source>
<volume>2018</volume>, <fpage>1</fpage>&#x02013;<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1155/2018/3702795</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zepf</surname><given-names>S.</given-names></name><name><surname>Hernandez</surname><given-names>J.</given-names></name><name><surname>Schmitt</surname><given-names>A.</given-names></name><name><surname>Minker</surname><given-names>W.</given-names></name><name><surname>Picard</surname><given-names>R. W.</given-names></name></person-group> (<year>2020</year>). <article-title>Driver emotion recognition for intelligent vehicles: a survey</article-title>. <source>ACM Comput. Surv.</source>
<volume>53</volume>, <fpage>1</fpage>&#x02013;<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1145/3388790</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>T.</given-names></name><name><surname>Chan</surname><given-names>A. H. S.</given-names></name><name><surname>Ba</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>W.</given-names></name></person-group> (<year>2016</year>). <article-title>Situational driving anger, driving performance and allocation of visual attention</article-title>. <source>Transp. Res. Part F Traffic Psychol. Behav.</source>
<volume>42</volume>, <fpage>376</fpage>&#x02013;<lpage>388</lpage>. <pub-id pub-id-type="doi">10.1016/j.trf.2015.05.008</pub-id></mixed-citation></ref></ref-list></back></article>