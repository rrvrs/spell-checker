<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS One</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">40408348</article-id><article-id pub-id-type="pmc">PMC12101641</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0324159</article-id><article-id pub-id-type="publisher-id">PONE-D-25-06331</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Recreation</subject><subj-group><subject>Sports</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Recreation</subject><subj-group><subject>Sports</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Sports Science</subject><subj-group><subject>Sports</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Attention</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Electronics Engineering</subject><subj-group><subject>Computer Engineering</subject><subj-group><subject>Man-Computer Interface</subject><subj-group><subject>Virtual Reality</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Computer Architecture</subject><subj-group><subject>User Interfaces</subject><subj-group><subject>Virtual Reality</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Computer Vision</subject><subj-group><subject>Target Detection</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory Perception</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Visual attention and response time to distinguish athletes from non-athletes: A virtual reality study</article-title><alt-title alt-title-type="running-head">Virtual reality for athletes</alt-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Imperiali</surname><given-names>Lucia</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2435-3412</contrib-id><name><surname>Borghi</surname><given-names>Stefano</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Bizzozero</surname><given-names>Sara</given-names></name><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Prandoni</surname><given-names>Elena</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Bisio</surname><given-names>Ambra</given-names></name><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="aff004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4987-2024</contrib-id><name><surname>La Torre</surname><given-names>Antonio</given-names></name><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1608-1899</contrib-id><name><surname>Codella</surname><given-names>Roberto</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref><xref rid="aff005" ref-type="aff">
<sup>5</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>IRCCS Istituto Ortopedico Galeazzi, Milan, Italy</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>Department of Biomedical Sciences for Health, Universit&#x000e0; degli Studi di Milano, Milan, Italy</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Centro Polifunzionale di Scienze Motorie, Universit&#x000e0; degli Studi di Genova, Genoa, Italy</addr-line></aff><aff id="aff004"><label>4</label>
<addr-line>Department of Experimental Medicine, Section of Human Physiology, Universit&#x000e0; degli Studi di Genova, Genoa, Italy</addr-line></aff><aff id="aff005"><label>5</label>
<addr-line>Department of Endocrinology, Nutrition and Metabolic Diseases, IRCCS MultiMedica, Milan, Italy</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Wilkerson</surname><given-names>Gary B.</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>The University of Tennessee at Chattanooga, UNITED STATES OF AMERICA</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>roberto.codella@unimi.it</email></corresp></author-notes><pub-date pub-type="epub"><day>23</day><month>5</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>20</volume><issue>5</issue><elocation-id>e0324159</elocation-id><history><date date-type="received"><day>10</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>21</day><month>4</month><year>2025</year></date></history><permissions><copyright-statement>&#x000a9; 2025 Imperiali et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Imperiali et al</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0324159.pdf">
</self-uri><abstract><p>In recent years, cutting-edge technologies have been increasingly integrated into sports to assess physical and cognitive capacities. Virtual Reality (VR) technology has emerged as a powerful tool, offering an immersive and controlled scenario for examining cognitive functions. In light of the growing adoption of VR-systems, this study aimed to investigate the differences in visual attention and response time (RT) between athletes and non-athletes utilizing a VR-system and evaluate the discriminatory power of VR assessments towards the two groups. Sixty-one participants (Age: 22&#x02009;&#x000b1;&#x02009;1.8years; athletes&#x02009;=&#x02009;33, non-athletes&#x02009;=&#x02009;28) underwent two visual attention evaluations through the Multiple Object Tracking (MOT) paradigm and three RT evaluations, all within a fully immersive VR environment. The visual attention assessments included the &#x0201c;MOT Assessment&#x0201d; (MOT), which did not have a primary target to select, and the &#x0201c;MOT, Primary Target Onset&#x0201d; (MOT-PT), which required selecting a primary target. The three RT evaluations included Continuous RT (RT-C), RT with Inter-Time between stimuli (RT-I), and Go No-Go RT (RT-GNG). In all RT assessments, participants aimed to touch the target that turned green in the shortest time as possible. In the RT-GNG test, participants responded to green targets by touching them with the hand controllers and refrained from touching red targets. No differences were found between athletes and non-athletes in visual attention tasks. However, athletes outperformed non-athletes in RT assessments (RT-C: 504.8&#x02009;&#x000b1;&#x02009;45.9ms vs. 549.1&#x02009;&#x000b1;&#x02009;45.6ms; p&#x02009;&#x0003c;&#x02009;0.001. RT-I: 481.1&#x02009;&#x000b1;&#x02009;44.9ms vs. 534.2&#x02009;&#x000b1;&#x02009;58.6ms; p&#x02009;&#x0003c;&#x02009;0.001. RT-GNG: 502.9&#x02009;&#x000b1;&#x02009;38.8ms vs. 555.6&#x02009;&#x000b1;&#x02009;57.8ms; p&#x02009;&#x0003c;&#x02009;0.001). ROC curve analysis demonstrated moderate accuracy in differentiating athletes from non-athletes in RT assessments (RT-C: AUC&#x02009;=&#x02009;0.75, p&#x02009;&#x0003c;&#x02009;0.001; RT-I: AUC&#x02009;=&#x02009;0.75, p&#x02009;&#x0003c;&#x02009;0.001; RT-GNG: AUC&#x02009;=&#x02009;0.80, p&#x02009;&#x0003c;&#x02009;0.001). These findings underscore the significant role of RT in distinguishing athletes from non-athletes and highlight the discriminative potential of VR-systems as valuable tools in sports evaluation. Including RT assessments into traditional training regimens could offer new insights for evaluating athletic performance.</p></abstract><funding-group><funding-statement>The author(s) received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="2"/><page-count count="11"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The dataset of the study is available on the following URL: <ext-link xlink:href="https://zenodo.org/records/14809126" ext-link-type="uri">https://zenodo.org/records/14809126</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The dataset of the study is available on the following URL: <ext-link xlink:href="https://zenodo.org/records/14809126" ext-link-type="uri">https://zenodo.org/records/14809126</ext-link>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>In many daily contexts, such as driving, work tasks, and sports activities, individuals are challenged to visually perceive and cognitively process multiple moving objects and scenes within a short amount of time [<xref rid="pone.0324159.ref001" ref-type="bibr">1</xref>]. For this reason, visual attention and time to response are critical processes for making accurate decisions, reflecting the efficiency of cognitive processing and motor execution [<xref rid="pone.0324159.ref002" ref-type="bibr">2</xref>,<xref rid="pone.0324159.ref003" ref-type="bibr">3</xref>]. Visual attention is a process that allows for the selection of certain stimuli while ignoring others, facilitating the cognitive organization of appropriate actions in response to relevant stimuli [<xref rid="pone.0324159.ref004" ref-type="bibr">4</xref>]. Thus, it can be considered a sub-process of perception that filters the vast array of available information to highlight aspects relevant to the organism [<xref rid="pone.0324159.ref001" ref-type="bibr">1</xref>]. On the other hand, response time (RT) refers to the duration of the motor response to a visual stimulus, measuring the time from stimulus onset to the completion of the movement [<xref rid="pone.0324159.ref005" ref-type="bibr">5</xref>]. Therefore, both of these processes are essential in everyday life and even more in sports, particularly in open skill sports (e.g., basketball, tennis, squash, or boxing) where participants must respond and adjust to an unpredictable and rapidly changing environment [<xref rid="pone.0324159.ref006" ref-type="bibr">6</xref>]. Similarly, in team sports, maintaining a high level of attention during the game enables players to recognize changes in teammates and opponents&#x02019; positions and simultaneously track the ball dynamically. For this reason, a high level of visual attention and fast RT allow for achieving better performance [<xref rid="pone.0324159.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0324159.ref008" ref-type="bibr">8</xref>]. It is well known that an individual&#x02019;s cognitive abilities, including working memory, processing speed, and decision-making, directly affects visual attention [<xref rid="pone.0324159.ref009" ref-type="bibr">9</xref>]. Athletes typically develop enhanced cognitive processing skills through training, enabling them to focus on relevant visual stimuli while ignoring distractions [<xref rid="pone.0324159.ref010" ref-type="bibr">10</xref>&#x02013;<xref rid="pone.0324159.ref012" ref-type="bibr">12</xref>]. This ability is crucial in sports, where split-second decisions can determine the outcome of a play. While visual attention is important across sports, previous studies have rarely compared athletes from different disciplines [<xref rid="pone.0324159.ref013" ref-type="bibr">13</xref>], likely due to the unique cognitive and perceptual demands each sport imposes [<xref rid="pone.0324159.ref014" ref-type="bibr">14</xref>].</p><p>In recent years, new technologies have been used in sports as innovative tools for assessment of physical capacities, mental training and rehabilitation [<xref rid="pone.0324159.ref015" ref-type="bibr">15</xref>,<xref rid="pone.0324159.ref016" ref-type="bibr">16</xref>]. The advent of Virtual Reality (VR), an immersive technology which enables users to interact with 3D computer generated simulation of a real environment, in real time, using their senses and motor skills, has provided a novel platform for studying cognitive and physical functions [<xref rid="pone.0324159.ref017" ref-type="bibr">17</xref>]. VR allows for the simulation of realistic scenarios, enhancing ecological validity while maintaining experimental control [<xref rid="pone.0324159.ref018" ref-type="bibr">18</xref>]. Generally, VR can be categorized by presentation methods into non-immersive systems (typically displayed on a computer screen) and immersive systems (such as those using headsets and cave environments) [<xref rid="pone.0324159.ref019" ref-type="bibr">19</xref>]. Non-immersive VR-systems are more cost-effective but are better suited for experiments requiring simple reactions due to their less immersive nature [<xref rid="pone.0324159.ref020" ref-type="bibr">20</xref>]. In contrast, immersive VR-systems provide a more realistic and complex physiological and psychological experience, which has become the main focus of VR research and applications in recent years [<xref rid="pone.0324159.ref021" ref-type="bibr">21</xref>]. VR is a widespread technology drawing an increasing interest for athletes and coaches, as it offers a tool to simulate, analyse and train situations that are often too complex to reproduce in the field. Using VR, there is the possibility of adding or removing elements from the immersive scenario, stratifying the reality that the athlete has to deal with to make exercises more basic or more complex [<xref rid="pone.0324159.ref016" ref-type="bibr">16</xref>]. Replicating this kind of scenario in the real world is very difficult, and in some cases, impossible.</p><p>To date, most of the research on visual attention and RT has employed visual displays with 2D sets [<xref rid="pone.0324159.ref022" ref-type="bibr">22</xref>]. However, traditional video simulations on computer screens offer only modest levels of immersion in the action [<xref rid="pone.0324159.ref023" ref-type="bibr">23</xref>]. In addition, these simulations are not sufficiently controllable to allow an objective assessment, nor are they complex enough to reflect the challenges analogous to those encountered by people in their daily lives [<xref rid="pone.0324159.ref022" ref-type="bibr">22</xref>]. Given the increasing adoption of VR systems, this study introduces a novel approach that aligns neuropsychological assessment with ecological tests by simulating real-life scenarios while ensuring reproducibility and controlled regulation of test conditions [<xref rid="pone.0324159.ref024" ref-type="bibr">24</xref>]. In detail, the study leverages an advance VR system to examine differences in visual attention and RT between athletes and non-athletes. Unlike previous studies, our study integrates a fully immersive VR environment, offering a more realistic and dynamic setting of evaluation. This allows for a more precise appraisal of cognitive and perceptual abilities under conditions that closely mirror real-world demands. Furthermore, the study evaluated the discriminatory power of VR-based assessments in distinguishing between the two groups. We hypothesized that athletes would outperform non-athletes in both visual attention and RT assessments.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Materials and methods</title><sec id="sec003"><title>Study design</title><p>This observational, cross-sectional study was conducted at the Universit&#x000e0; degli Studi di Milano (Milan, Italy) between January 15, 2024, and May 17, 2024. The study protocol was approved by the Ethics Committee of the university (ref. n.: 126/23) and adhered to the ethical principles for medical research involving human participants as outlined in the latest version of the World Medical Association Declaration of Helsinki. All participants were informed about the purpose, methods, potential risks, and benefits of the study and provided written informed consent. All participants completed the following evaluations: i) Assessment of visual attention using a VR-system (VR-Brain Tracker software); ii) Assessment of RT using a VR-system (VR-CNS Sprint software); iii) A survey collecting demographic data, sport practice information, and details on the duration and frequency of training. Before conducting the data collection tests, a familiarization session with the VR-system was performed. This session aimed to ensure that all participants were comfortable and accustomed to the VR environment and its interface. During this phase, participants had the opportunity to explore the system, learn how to interact with the virtual scenario, and understand the protocol of the VR assessments. Each subject completed all the tests within their usual training time. Based on survey responses, the sample was categorized into two groups: athletes and non-athletes. Participants were classified as active/trained, following McKay classification [<xref rid="pone.0324159.ref025" ref-type="bibr">25</xref>]. Active participants (Tier&#x02009;&#x02265;&#x02009;2) were registered with Italian sports federations. Sedentary participants (Tier 0) either exhibited sedentary behaviours or trained less than two hours per week, and were not registered with any Italian sports federations.</p></sec><sec id="sec004"><title>Participants</title><p>Participants were enrolled at the Universit&#x000e0; degli Studi di Milano (Milan, Italy). The subjects completed all the assessments within a single day. Participants were engaged for approximately 40 minutes in total, including the time required for survey completion, as well as the visual attention and RT evaluations. The inclusion criteria for selecting participants included: male and female students; aged between 18 and 30 years; classified sedentary (tier 0) or active (tier&#x02009;&#x02265;&#x02009;2) following McKay classification [<xref rid="pone.0324159.ref025" ref-type="bibr">25</xref>]; no experience with VR-systems. The exclusion criteria were as follows: not providing informed consent for the study; neurological or orthopaedic pathological conditions that could potentially affect movement, vision conditions, pathologies or use of medication that could affect the correct execution of assessments. We considered 15 team sport athletes and 18 individual sport athletes. Specifically, the sports included in the study were: Track and Field (7 athletes), Basketball (2 athletes), Beach Volleyball (1 athlete), Climbing (1 athlete), Combat Sports (2 athletes), Dance (2 athletes), Flag Football (1 athlete), Gymnastics (1 athlete), Rowing (5 athletes), Football (1 athlete), Volleyball (6 athletes), and Water Polo (4 athletes). All participants classified as athletes had a minimum of seven years of experience in their respective sports (mean sport experience: 13.1&#x02009;&#x000b1;&#x02009;5.8 years).</p></sec><sec id="sec005"><title>Virtual reality system</title><p>The VR-system used comprises four components: a computer, a headset, two controllers, and specialized software (VR-Brain Tracker and VR-CNS Sprint). The Meta Quest 2 headset (Meta, California, USA) delivers an immersive 360&#x000b0; viewing experience, offering high-resolution imagery at 20 pixels per degree and employing a rapid-switching LCD display boasting 1832 x 1920 pixels per eye. It is equipped with two controllers for precise hand tracking. The headset is powered by 6 GB of RAM integrated with a Qualcomm Snapdragon XR2 platform, ensuring smooth performance. Additionally, it features built-in native 3D audio capabilities. The computer was a Lenovo IdeaPad Gaming 3 15IAH7 model (Lenovo, Beijing, China) with Intel&#x000ae; Core&#x02122; i7-12650H processor with 16 GB RAM, 15.56-inch 1920 x 1080-pixel screen and Microsoft Windows 11 Home operating system with Nvidia RTX 3060 graphics card. The two softwares used in the study were developed and provided by Mind Room Lab s.r.l. (Bassano del Grappa, Italy).</p></sec><sec id="sec006"><title>VR-Brain Tracker</title><p>VR-Brain Tracker software assessed visual attention and memory skills through two evaluations: i) Multiple Object Tracking (MOT); ii) Multiple Object Tracking with Primary Target Onset (MOT-PT). The MOT comprised 20 repetitions within a VR cube, where 8 spheres were displayed. During each repetition, 4 of these spheres randomly flashed green for 3 seconds (<xref rid="pone.0324159.g001" ref-type="fig">Fig 1A</xref>), after which all spheres returned to their original colour and begin moving in various directions within the cube for 7 seconds (<xref rid="pone.0324159.g001" ref-type="fig">Fig 1B</xref>). Subsequently, the spheres come to a halt, prompting the participant to identify the 4 spheres initially highlighted in green (<xref rid="pone.0324159.g001" ref-type="fig">Fig 1C</xref>).</p><fig position="float" id="pone.0324159.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0324159.g001</object-id><label>Fig 1</label><caption><title>Virtual room of MOT performed by VR-Brain Tracker software.</title><p>a) Identification of targets coloured in green; b) Movement of the 8 spheres in the cube; c) Selection of targets.</p></caption><graphic xlink:href="pone.0324159.g001" position="float"/></fig><p>Successful selections prompted an increase in the movement speed of spheres in the next repetition and in the final score of the assessments, while errors lead to a decrease in their movement speed (<xref rid="pone.0324159.g001" ref-type="fig">Fig 1C</xref>); red sphere represents the incorrect selection, whereas the orange sphere indicates the unselected correct target. Upon completion, the system released an Attentional Index (AI), starting from a baseline score of 1.2. Higher scores in AI indicate better visual attention. MOT-PT differed from MOT by including one primary target and two secondary targets, which were distinguished by their colours: blue for the primary target and green for the secondary targets. In each repetition, the primary target was the first one the participant had to select. The AI for MOT (AI<sub>MOT</sub>) and MOT-PT (AI<sub>MOT-PT</sub>) tests were calculated using the Staircase method [<xref rid="pone.0324159.ref026" ref-type="bibr">26</xref>], an adaptive method where each correct response leads to a decrease in the signal level, while each incorrect response increases it. The Staircase method is used to keep stimuli close to the threshold value, adapting the sequence of presentation in relation to the subject&#x02019;s response, reversing the tendency at each change in the response itself [<xref rid="pone.0324159.ref027" ref-type="bibr">27</xref>]. Unlike the traditional up-down method, the Staircase method utilizes different step sizes for upward and downward adjustments. In our study, we employed 1-step increase and &#x02212; 1.5-step decrease. The test was conducted with the participant seated on a chair. They remained stationary during the evaluations and did not move around the VR-environment. Participants made their decisions using hand controller.</p></sec><sec id="sec007"><title>VR-CNS sprint</title><p>VR-CNS Sprint assessed RT in response to visual targets appearing randomly in the field of view (<xref rid="pone.0324159.g002" ref-type="fig">Fig 2</xref>).</p><fig position="float" id="pone.0324159.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0324159.g002</object-id><label>Fig 2</label><caption><title>Virtual room of RT assessments performed by VR-CNS Sprint software.</title><p>a) Adjustment of targets height and distance; b) Virtual room during assessments.</p></caption><graphic xlink:href="pone.0324159.g002" position="float"/></fig><p>The assessments were always conducted using a standard panel with targets positioned within the visual field. The panel consisted of 16 targets arranged in 4 rows and 4 columns. The size of the panel was chosen based on the participant&#x02019;s arm reach, with three options available: extra small (70x70&#x02009;cm), small (90x90&#x02009;cm), and medium (120x120&#x02009;cm). For this study, we consistently used the 70x70&#x02009;cm panel.</p><p>Participants wore hand controllers and were instructed to touch the target that turned green as quickly as possible (hit). The evaluation comprised three tests: i) RT in Continuous (RT-C); ii) RT with Inter-time between stimuli (RT-I); iii) RT with inter-time between stimuli Go No-Go paradigm (RT-GNG). In RT-C test, targets sequentially turned green in random order immediately after the participant previous hit. The evaluation included a total of 96 hits, with each target being activated six times (16 targets x 6&#x02009;=&#x02009;96 hits). RT-I test was characterized from the introduction of intervals of rest between stimuli (0.25s, 0.50s, 0.75s or 1.00s). The interval of rest was randomly repeated between hits, and the assessment included a total of 96 hits, with each target being activated six times (16 targets x 6&#x02009;=&#x02009;96 hits). Finally, in RT-GNG, RT was assessed using the Go No-Go paradigm [<xref rid="pone.0324159.ref028" ref-type="bibr">28</xref>]. Target could appear either green (Go) or red (No-Go). Rest intervals of 0.25s, 0.50s, 0.75s or 1.00s was randomly repeated between targets appearance. The No-Go targets remained illuminated in red for 2.0s before automatically turning off. Participants were instructed to not touch No-Go targets and no errors were performed during the experimental procedures. The distribution included 96 Go targets and 32 No-Go targets (Go targets: 16 targets x 6&#x02009;=&#x02009;96 hits; No-Go targets: 16 targets x 2&#x02009;=&#x02009;32).</p></sec><sec id="sec008"><title>Statistical analysis</title><p>Variables were expressed as mean&#x02009;&#x000b1;&#x02009;standard deviation (SD) and 95% confidence intervals (CI). Based on literature research, to determine the sample size <italic toggle="yes">a priori</italic> (software package, G*Power 3.1.9.2), the following input variables were selected as per a t-test analysis with two tails: a statistical power (1-&#x003b2;) of 0.90, a probability &#x003b1; level of 0.05, an effect size (Cohen <italic toggle="yes">d</italic>) of 0.937, two groups. These inputs were determined by considering RT as primary outcome. Using these parameters, a total sample size of 50 subjects is obtained (25 subjects for each group). To account for any potential subject drop-out during the scientific procedures (which should not exceed 10%), the sample size was increased to 28 subjects per group. The normality of the distribution of the outcome measures was checked using graphical methods and the Shapiro&#x02013;Wilk test. In order to assess differences between sport practice (athletes vs non-athletes), the Mann-Whitney test was performed in case of non-normality of data (age, AI<sub>MOT-PT</sub>, RT-GNG). For data with normal distribution, the unpaired t-test was used. Effect sizes for pairwise comparison were calculated using Cohen&#x02019;s <italic toggle="yes">d</italic> and categorized as trivial (effect size:&#x02009;&#x0003c;&#x02009;0.20), small (0.21&#x02013;0.60), moderate (0.61&#x02013;1.20), large (1.21&#x02013;2.00), or very large (&#x0003e; 2.00) [<xref rid="pone.0324159.ref029" ref-type="bibr">29</xref>]. The significance level was set at p&#x02009;&#x0003c;&#x02009;0.05. The receiver operating characteristics (ROC) curve analysis was performed to ascertain the accuracy and validity of this VR battery assessment. The area under the curve (AUC) value was analysed to determine the discriminatory power of VR assessments towards athletes and non-athletes: high accuracy (AUC&#x02009;&#x0003e;&#x02009;0.9), moderate accuracy (AUC 0.7 to 0.9), low accuracy (AUC 0.5 to 0.7) or a chance result (AUC&#x02009;&#x0003c;&#x02009;0.5) [<xref rid="pone.0324159.ref030" ref-type="bibr">30</xref>,<xref rid="pone.0324159.ref031" ref-type="bibr">31</xref>]. Statistical analysis was performed using Graph Pad Prism Software, version 8.0 for Windows (Graph Pad Software, San Diego, CA).</p></sec></sec><sec sec-type="results" id="sec009"><title>Results</title><sec id="sec010"><title>Study population</title><p>A total of 88 students were screened for eligibility and 61 young adults were recruited. The sample (males: n&#x02009;=&#x02009;32; females: n&#x02009;=&#x02009;29) included 28 non-athletes and 33 athletes, aged between 19 and 26 years (total sample: 22.6&#x02009;&#x000b1;&#x02009;1.9 years. Non-athletes: 22.6&#x02009;&#x000b1;&#x02009;2.1 years, Athletes: 22.6&#x02009;&#x000b1;&#x02009;1.7 years; p&#x02009;=&#x02009;0.687).</p></sec><sec id="sec011"><title>VR-Brain Tracker and VR-CNS sprint</title><sec id="sec012"><title>Athletes and non-athletes.</title><p><xref rid="pone.0324159.t001" ref-type="table">Table 1</xref> reports the results obtained by comparing athletes and non-athletes with the two dependent variables (visual attention and RT).</p><table-wrap position="float" id="pone.0324159.t001"><object-id pub-id-type="doi">10.1371/journal.pone.0324159.t001</object-id><label>Table 1</label><caption><title>Comparison between athletes and non-athletes in VR-Brain Tracker and VR-CNS Sprint assessments.</title></caption><alternatives><graphic xlink:href="pone.0324159.t001" id="pone.0324159.t001g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Variable</th><th align="left" rowspan="1" colspan="1">Total sample<break/>(n&#x02009;=&#x02009;61)</th><th align="left" rowspan="1" colspan="1">Athletes<break/>(n&#x02009;=&#x02009;33)</th><th align="left" rowspan="1" colspan="1">Non-athletes<break/>(n&#x02009;=&#x02009;28)</th><th align="left" rowspan="1" colspan="1">p<break/>(ES)</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>AI</bold><sub><bold>MOT</bold></sub> (au)</td><td align="left" rowspan="1" colspan="1">3.0&#x02009;&#x000b1;&#x02009;1.0<break/>(2.7&#x02013;3.3)</td><td align="left" rowspan="1" colspan="1">3.1&#x02009;&#x000b1;&#x02009;1.1<break/>(2.7&#x02013;3.4)</td><td align="left" rowspan="1" colspan="1">2.9&#x02009;&#x000b1;&#x02009;1.0<break/>(2.5&#x02013;3.3)</td><td align="left" rowspan="1" colspan="1">0.605</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>AI</bold><sub><sub><bold>MOT</bold></sub></sub><bold><sub>-</sub></bold><sub><sub><bold>PT</bold></sub></sub> (au)</td><td align="left" rowspan="1" colspan="1">3.6&#x02009;&#x000b1;&#x02009;0.9<break/>(3.3&#x02013;3.8)</td><td align="left" rowspan="1" colspan="1">3.6&#x02009;&#x000b1;&#x02009;0.9<break/>(3.3&#x02013;3.9)</td><td align="left" rowspan="1" colspan="1">3.5&#x02009;&#x000b1;&#x02009;1.0<break/>(3.1&#x02013;3.9)</td><td align="left" rowspan="1" colspan="1">0.980</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>RT-C</bold> (ms)</td><td align="left" rowspan="1" colspan="1">525.2&#x02009;&#x000b1;&#x02009;50.5<break/>(512.2&#x02013;538.1)</td><td align="left" rowspan="1" colspan="1">504.8&#x02009;&#x000b1;&#x02009;45.9<break/>(488.6&#x02013;521.1)</td><td align="left" rowspan="1" colspan="1">549.1&#x02009;&#x000b1;&#x02009;45.6<break/>(531.5&#x02013;566.8)</td><td align="left" rowspan="1" colspan="1">
<bold>&#x0003c;0.001</bold>
<break/>
<bold>(0.97)</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>RT-I</bold> (ms)</td><td align="left" rowspan="1" colspan="1">505.5&#x02009;&#x000b1;&#x02009;57.7<break/>(490.7&#x02013;520.3)</td><td align="left" rowspan="1" colspan="1">481.1&#x02009;&#x000b1;&#x02009;44.9<break/>(465.2&#x02013;497.0)</td><td align="left" rowspan="1" colspan="1">534.2&#x02009;&#x000b1;&#x02009;58.6<break/>(511.5&#x02013;556.9)</td><td align="left" rowspan="1" colspan="1">
<bold>&#x0003c;0.001</bold>
<break/>
<bold>(1.03)</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>RT-GNG</bold> (ms)</td><td align="left" rowspan="1" colspan="1">527.1&#x02009;&#x000b1;&#x02009;54.8<break/>(513.0&#x02013;541.1)</td><td align="left" rowspan="1" colspan="1">502.9&#x02009;&#x000b1;&#x02009;38.8<break/>(489.1&#x02013;516.6)</td><td align="left" rowspan="1" colspan="1">555.6&#x02009;&#x000b1;&#x02009;57.8<break/>(533.2&#x02013;578.0)</td><td align="left" rowspan="1" colspan="1">
<bold>&#x0003c;0.001</bold>
<break/>
<bold>(1.09)</bold>
</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p>Data are reported as mean&#x02009;&#x000b1;&#x02009;SD (lower and upper 95%CI). AI<sub>MOT</sub>: Attentional Index of the MOT; au: arbitrary units; AI<sub>MOT-PT</sub>: Attentional Index of the MOT-Primary Target Onset; ES: Effect size; p: p-value; RT-C: Response Time in Continuous; RT-GNG: Response Time with Inter-time between Stimuli, Go No-Go paradigm; RT-I: Response Time with Inter-time between Stimuli.</p></fn></table-wrap-foot></table-wrap><p>ROC results are shown in <xref rid="pone.0324159.t002" ref-type="table">Table 2</xref>. In detail, all RT assessments detected a moderate level of accuracy considering the AUC. RT-GNG showed the highest AUC (AUC&#x02009;=&#x02009;0.80, p&#x02009;&#x0003c;&#x02009;0.001) as compared to all other ROC results, followed by RT-I (AUC&#x02009;=&#x02009;0.75, p&#x02009;&#x0003c;&#x02009;0.001) and RT-C (AUC&#x02009;=&#x02009;0.75, p&#x02009;&#x0003c;&#x02009;0.001). Low accuracy was detected in visual attention assessments (MOT: AUC&#x02009;=&#x02009;0.54, p&#x02009;=&#x02009;0.572; MOT-PT: AUC&#x02009;=&#x02009;0.50, p&#x02009;=&#x02009;0.977).</p><table-wrap position="float" id="pone.0324159.t002"><object-id pub-id-type="doi">10.1371/journal.pone.0324159.t002</object-id><label>Table 2</label><caption><title>ROC results for the MOT, MOT-PT, RT-C, RT-I and RT-GNG conducted in athletes and non-athletes.</title></caption><alternatives><graphic xlink:href="pone.0324159.t002" id="pone.0324159.t002g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Variable</th><th align="left" rowspan="1" colspan="1">AUC</th><th align="left" rowspan="1" colspan="1">p value</th><th align="left" rowspan="1" colspan="1">Sensitivity (%)</th><th align="left" rowspan="1" colspan="1">Specificity (%)</th><th align="left" rowspan="1" colspan="1">Cut - point</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><bold>AI</bold><sub><bold>MOT</bold></sub> (au)</td><td align="left" rowspan="1" colspan="1">0.54</td><td align="left" rowspan="1" colspan="1">0.572</td><td align="left" rowspan="1" colspan="1">82.14</td><td align="left" rowspan="1" colspan="1">33.33</td><td align="left" rowspan="1" colspan="1">3.77</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>AI</bold><sub><sub><bold>MOT</bold></sub></sub><bold><sub>-</sub></bold><sub><sub><bold>PT</bold></sub></sub> (au)</td><td align="left" rowspan="1" colspan="1">0.50</td><td align="left" rowspan="1" colspan="1">0.977</td><td align="left" rowspan="1" colspan="1">17.86</td><td align="left" rowspan="1" colspan="1">96.97</td><td align="left" rowspan="1" colspan="1">2.18</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>RT-C</bold> (ms)</td><td align="left" rowspan="1" colspan="1">0.75</td><td align="left" rowspan="1" colspan="1">&#x0003c;0.001</td><td align="left" rowspan="1" colspan="1">78.57</td><td align="left" rowspan="1" colspan="1">63.64</td><td align="left" rowspan="1" colspan="1">521.50</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>RT-I</bold> (ms)</td><td align="left" rowspan="1" colspan="1">0.75</td><td align="left" rowspan="1" colspan="1">&#x0003c;0.001</td><td align="left" rowspan="1" colspan="1">71.43</td><td align="left" rowspan="1" colspan="1">78.79</td><td align="left" rowspan="1" colspan="1">513.50</td></tr><tr><td align="left" rowspan="1" colspan="1"><bold>RT-GNG</bold> (ms)</td><td align="left" rowspan="1" colspan="1">0.80</td><td align="left" rowspan="1" colspan="1">&#x0003c;0.001</td><td align="left" rowspan="1" colspan="1">75.00</td><td align="left" rowspan="1" colspan="1">78.79</td><td align="left" rowspan="1" colspan="1">531.50</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t002fn001"><p>AI<sub>MOT</sub>: Attentional Index of the MOT; AI<sub>MOT-PT</sub>: Attentional Index of the MOT-Primary Target Onset; au: arbitrary units; AUC: Area Under the Curve; RT-C: Response Time in Continuous; RT-GNG: Response Time with Inter-time between Stimuli, Go No-Go paradigm; RT-I: Response Time with Inter-time between Stimuli.</p></fn></table-wrap-foot></table-wrap></sec></sec></sec><sec sec-type="conclusions" id="sec013"><title>Discussion</title><p>Based on the current literature, this study is among the first to analyse differences in visual attention and RT between athletes and non-athletes using VR applications. The main findings of this study were that athletes showed faster RT than non-athletes, and ROC curve analysis showed moderate accuracy in distinguishing athletes from non-athletes in RT assessments.</p><p>The present study did not detect significant differences in AI<sub>MOT</sub> and AI<sub>MOT</sub><sub>-</sub><sub><sub>PT</sub></sub> scores between athletes and non-athletes. Attention and performance in athletes have been widely studied using the MOT paradigm, as evidenced by previous research [<xref rid="pone.0324159.ref032" ref-type="bibr">32</xref>,<xref rid="pone.0324159.ref033" ref-type="bibr">33</xref>]. Nonetheless, findings regarding the performance advantages of athletes remain inconsistent. For example, several studies have reported that athletes outperform non-athletes in MOT tasks [<xref rid="pone.0324159.ref032" ref-type="bibr">32</xref>&#x02013;<xref rid="pone.0324159.ref034" ref-type="bibr">34</xref>]. However, other studies have presented contrasting results. Memmert and colleagues [<xref rid="pone.0324159.ref008" ref-type="bibr">8</xref>], found that experts in team sports did not perform better on basic attention tasks than athletes from individual sports or novice athletes. Similarly, a meta-analysis by Liu et al. [<xref rid="pone.0324159.ref033" ref-type="bibr">33</xref>] observed that when the number of tracking targets was limited, there was no significant difference in tracking accuracy between expert athletes and novices. Additionally, one study within the analysis reported that basketball players had lower MOT scores compared to non-athletes.</p><p>These contrasting results potentially due to various factors influencing differential performance in MOT tasks. For example, the difficulty level of the MOT task can be varied using different number of targets [<xref rid="pone.0324159.ref035" ref-type="bibr">35</xref>] and distractors [<xref rid="pone.0324159.ref036" ref-type="bibr">36</xref>], the speed of the targets [<xref rid="pone.0324159.ref037" ref-type="bibr">37</xref>], and the duration of tracking [<xref rid="pone.0324159.ref038" ref-type="bibr">38</xref>]. Furthermore, attentional capacities, such as selective attention [<xref rid="pone.0324159.ref039" ref-type="bibr">39</xref>], sustained attention [<xref rid="pone.0324159.ref040" ref-type="bibr">40</xref>], and divided attention [<xref rid="pone.0324159.ref041" ref-type="bibr">41</xref>], can be influenced by various factors including the type of sport, level of expertise, and even the individual&#x02019;s physiological state [<xref rid="pone.0324159.ref042" ref-type="bibr">42</xref>,<xref rid="pone.0324159.ref043" ref-type="bibr">43</xref>]. Additionally, various factors, such as certain daily life activities, could help explain the differences observed in MOT performance. For example, gamers often possess greater familiarity with technology, which may enhance their visual attention skills and, consequently, their MOT abilities, due to the consistent engagement with video games [<xref rid="pone.0324159.ref044" ref-type="bibr">44</xref>]. The topic of attention in athletes is widely debated, and undoubtedly requires further and more in-depth research.</p><p>Comparing the results from RT assessments, athletes showed faster RT than non-athletes. These findings align with existing literature, which consistently shows that athletic training and sport practice positively impacts RT performance [<xref rid="pone.0324159.ref007" ref-type="bibr">7</xref>,<xref rid="pone.0324159.ref045" ref-type="bibr">45</xref>]. RT is a crucial measure in sports performance, as it reflects the speed of information processing and the ability to execute motor responses quickly and accurately [<xref rid="pone.0324159.ref006" ref-type="bibr">6</xref>]. Faster RT can provide a competitive advantage, particularly in sports that require rapid responses to changing stimuli. The most common methods in the literature to assess RT in athletes are through the use of computer [<xref rid="pone.0324159.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0324159.ref045" ref-type="bibr">45</xref>,<xref rid="pone.0324159.ref046" ref-type="bibr">46</xref>]. In the study of Akarsu and colleagues [<xref rid="pone.0324159.ref045" ref-type="bibr">45</xref>], the RT of athletes was compared to that of non-athletes. Their results support the view that sport activities and training are beneficial for RT, as athletes performed better than non-athletes in the study assessments. In support of this, H&#x000fc;lsd&#x000fc;nker and colleagues [<xref rid="pone.0324159.ref007" ref-type="bibr">7</xref>] explained that the faster visuomotor RT observed in athletes, compared to non-athletes, may be attributable to both structural and functional adaptations in the central nervous system. Structural adaptations, such as increased myelination and enhanced synaptic plasticity, contribute to faster signal transmission in the nervous system [<xref rid="pone.0324159.ref047" ref-type="bibr">47</xref>]. Additionally, functional changes, including improved coordination between sensory input and motor output, play a pivotal role in enhancing RT [<xref rid="pone.0324159.ref048" ref-type="bibr">48</xref>]. Specifically, chronic training seems to induce adaptations in visual and motor-related processes, affecting both neural function and the structure of grey and white matter [<xref rid="pone.0324159.ref049" ref-type="bibr">49</xref>,<xref rid="pone.0324159.ref050" ref-type="bibr">50</xref>]. These structural and functional adaptations not only explain the enhanced visuomotor RT in athletes but also highlight the broader implications of neuroplasticity in sports training and its potential benefits for individuals at all levels of physical activity [<xref rid="pone.0324159.ref051" ref-type="bibr">51</xref>]. Neuroplasticity refers to the brain&#x02019;s ability to modify its structure and function in response to the stimuli it encounters [<xref rid="pone.0324159.ref052" ref-type="bibr">52</xref>,<xref rid="pone.0324159.ref053" ref-type="bibr">53</xref>]. These neural adaptations are not limited to elite athletes but can also be observed in individuals engaging in regular physical activity, suggesting that even moderate exercise can enhance cognitive and motor functions [<xref rid="pone.0324159.ref054" ref-type="bibr">54</xref>].</p><p>The ROC analysis supported the discriminative validity of the VR setup, as the results showed moderate accuracy in the AUC values for RT assessments between athletes and non-athletes. In fact, an AUC between 0.75 and 0.80 indicates that RT assessments can be classified as a fair, albeit not exclusive, screening tool to distinguish athletes from non-athletes.</p><p>The limitations of this study include the reliance on a questionnaire that only investigated the type of sport practiced and the minutes spent training, without incorporating a training diary to calculate the training load more comprehensively. Additionally, the equipment used in the study lacked specificity to the sports being analysed, which may have influenced the precision and applicability of the findings. In addition, the use of a VR-system offers several advantages over traditional 2D technologies, such as computers [<xref rid="pone.0324159.ref055" ref-type="bibr">55</xref>], that could help overcome some of these limitations in future studies. In our study we try to better understand attentional aspect in athletes using VR technology. This technology allowed for a 3D-MOT, which has been shown to offer several advantages compared to 2D-MOT, such as creating and controlling virtual motion scenes [<xref rid="pone.0324159.ref056" ref-type="bibr">56</xref>], presenting stereoscopic vision [<xref rid="pone.0324159.ref057" ref-type="bibr">57</xref>] and immersing the visual scene. Based on these advantages, some studies indicated that VR technology can more effectively measure perception and motor performance in the field of motion than traditional methods [<xref rid="pone.0324159.ref055" ref-type="bibr">55</xref>]. For this reason, the setup used in the study could be considered a novel approach to evaluate attention and RT in a more lifelike virtual space. This opens up exciting possibilities for practical applications in sports training, benefiting both coaches and sport scientists. Athletes can leverage this technology to enhance their cognitive skills, improve RT, and sharpen focused attention&#x02009;&#x02212;&#x02009;key factors for excelling in competitive sports. These benefits extend across various disciplines, including from team and individual ball sports, combat sports, motorsports and racing, precision and shooting sports, as well as water and endurance sports.</p></sec><sec sec-type="conclusions" id="sec014"><title>Conclusions</title><p>This study utilized VR to assess visual attention and RT and explore how these processes are influenced by sport practice. The findings suggest that athletes exhibit faster RT compared to non-athletes, highlighting that physical training not only enhances motor skills and physical performance but also positively affects information processing speed. This insight could lead to the development of training programs that integrate cognitive exercises, such as visual attention and RT tasks, to further enhance athletes&#x02019; performance. Additionally, VR-based assessments show promise as screening tools for athlete selection, providing a more comprehensive evaluation of cognitive abilities, including visual attention and RT, alongside physical skills. By increasing immersion through a VR scenario, individuals may experience greater engagement and emotional connection, making the training feel more realistic and impactful.</p><p>Future research should investigate the effectiveness of VR as a training tool by comparing it with existing methodologies and determining whether a VR-based training with can improve visual attention and RT in athletes.</p></sec></body><back><ack><p>The authors thank all the participants of the study and extend their gratitude to Otello Sorato for providing the VR equipment.</p></ack><ref-list><title>References</title><ref id="pone.0324159.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>H&#x000fc;ttermann</surname><given-names>S</given-names></name>, <name><surname>Memmert</surname><given-names>D</given-names></name>. <article-title>The attention window: a narrative review of limitations and opportunities influencing the focus of attention</article-title>. <source>Res Q Exerc Sport</source>. <year>2017</year>;<volume>88</volume>(<issue>2</issue>):<fpage>169</fpage>&#x02013;<lpage>83</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/02701367.2017.1293228</pub-id>
<pub-id pub-id-type="pmid">28332919</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>de Brito</surname><given-names>MA</given-names></name>, <name><surname>Fernandes</surname><given-names>JR</given-names></name>, <name><surname>Esteves</surname><given-names>NS</given-names></name>, <name><surname>M&#x000fc;ller</surname><given-names>VT</given-names></name>, <name><surname>Alexandria</surname><given-names>DB</given-names></name>, <name><surname>P&#x000e9;rez</surname><given-names>DIV</given-names></name>, <etal>et al</etal>. <article-title>The effect of neurofeedback on the reaction time and cognitive performance of athletes: a systematic review and meta-analysis</article-title>. <source>Front Hum Neurosci</source>. <year>2022</year>;<volume>16</volume>:<fpage>868450</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fnhum.2022.868450</pub-id>
<pub-id pub-id-type="pmid">35795260</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Orquin</surname><given-names>JL</given-names></name>, <name><surname>Lahm</surname><given-names>ES</given-names></name>, <name><surname>Stoji&#x00107;</surname><given-names>H</given-names></name>. <article-title>The visual environment and attention in decision making</article-title>. <source>Psychol Bull</source>. <year>2021</year>;<volume>147</volume>(<issue>6</issue>):<fpage>597</fpage>&#x02013;<lpage>617</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037/bul0000328</pub-id>
<pub-id pub-id-type="pmid">34843300</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Rizzolatti</surname><given-names>G</given-names></name>, <name><surname>Fogassi</surname><given-names>L</given-names></name>, <name><surname>Gallese</surname><given-names>V</given-names></name>. <article-title>Neurophysiological mechanisms underlying the understanding and imitation of action</article-title>. <source>Nat Rev Neurosci</source>. <year>2001</year>;<volume>2</volume>(<issue>9</issue>):<fpage>661</fpage>&#x02013;<lpage>70</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/35090060</pub-id>
<pub-id pub-id-type="pmid">11533734</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>J-S</given-names></name>, <name><surname>Chang</surname><given-names>S-T</given-names></name>, <name><surname>Shieh</surname><given-names>L-C</given-names></name>, <name><surname>Lim</surname><given-names>A-Y</given-names></name>, <name><surname>Peng</surname><given-names>W-S</given-names></name>, <name><surname>Chen</surname><given-names>W-M</given-names></name>, <etal>et al</etal>. <article-title>Stereopsis and response times between collegiate table tennis athletes and non-athletes</article-title>. <source>Int J Environ Res Public Health</source>. <year>2021</year>;<volume>18</volume>(<issue>12</issue>):<fpage>6287</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/ijerph18126287</pub-id>
<pub-id pub-id-type="pmid">34200687</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Nuri</surname><given-names>L</given-names></name>, <name><surname>Shadmehr</surname><given-names>A</given-names></name>, <name><surname>Ghotbi</surname><given-names>N</given-names></name>, <name><surname>Attarbashi Moghadam</surname><given-names>B</given-names></name>. <article-title>Reaction time and anticipatory skill of athletes in open and closed skill-dominated sport</article-title>. <source>Eur J Sport Sci</source>. <year>2013</year>;<volume>13</volume>(<issue>5</issue>):<fpage>431</fpage>&#x02013;<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/17461391.2012.738712</pub-id>
<pub-id pub-id-type="pmid">24050458</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>H&#x000fc;lsd&#x000fc;nker</surname><given-names>T</given-names></name>, <name><surname>Str&#x000fc;der</surname><given-names>HK</given-names></name>, <name><surname>Mierau</surname><given-names>A</given-names></name>. <article-title>The athletes&#x02019; visuomotor system - Cortical processes contributing to faster visuomotor reactions</article-title>. <source>Eur J Sport Sci</source>. <year>2018</year>;<volume>18</volume>(<issue>7</issue>):<fpage>955</fpage>&#x02013;<lpage>64</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/17461391.2018.1468484</pub-id>
<pub-id pub-id-type="pmid">29738678</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Memmert</surname><given-names>D</given-names></name>, <name><surname>Simons</surname><given-names>DJ</given-names></name>, <name><surname>Grimme</surname><given-names>T</given-names></name>. <article-title>The relationship between visual attention and expertise in sports</article-title>. <source>Psychol Sport Exerc</source>. <year>2009</year>;<volume>10</volume>(<issue>1</issue>):<fpage>146</fpage>&#x02013;<lpage>51</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.psychsport.2008.06.002</pub-id></mixed-citation></ref><ref id="pone.0324159.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Voss</surname><given-names>MW</given-names></name>, <name><surname>Kramer</surname><given-names>AF</given-names></name>, <name><surname>Basak</surname><given-names>C</given-names></name>, <name><surname>Prakash</surname><given-names>RS</given-names></name>, <name><surname>Roberts</surname><given-names>B</given-names></name>. <article-title>Are expert athletes &#x02018;expert&#x02019; in the cognitive laboratory? A meta&#x02010;analytic review of cognition and sport expertise</article-title>. <source>Appl Cogn Psychol</source>. <year>2009</year>;<volume>24</volume>(<issue>6</issue>):<fpage>812</fpage>&#x02013;<lpage>26</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/acp.1588</pub-id></mixed-citation></ref><ref id="pone.0324159.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Logan</surname><given-names>NE</given-names></name>, <name><surname>Henry</surname><given-names>DA</given-names></name>, <name><surname>Hillman</surname><given-names>CH</given-names></name>, <name><surname>Kramer</surname><given-names>AF</given-names></name>. <article-title>Trained athletes and cognitive function: a systematic review and meta-analysis</article-title>. <source>Int J Sport Exerc Psychol</source>. <year>2022</year>;<volume>21</volume>(<issue>4</issue>):<fpage>725</fpage>&#x02013;<lpage>49</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/1612197x.2022.2084764</pub-id></mixed-citation></ref><ref id="pone.0324159.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Brimmell</surname><given-names>J</given-names></name>, <name><surname>Edwards</surname><given-names>EJ</given-names></name>, <name><surname>Vaughan</surname><given-names>RS</given-names></name>. <article-title>Executive function and visual attention in sport: a systematic review</article-title>. <source>Int Rev Sport Exerc Psychol</source>. <year>2022</year>;<volume>17</volume>(<issue>2</issue>):<fpage>1278</fpage>&#x02013;<lpage>311</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/1750984x.2022.2145574</pub-id></mixed-citation></ref><ref id="pone.0324159.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Memmert</surname><given-names>D</given-names></name>. <article-title>Pay attention! A review of visual attentional expertise in sport</article-title>. <source>Int Rev Sport Exerc Psychol</source>. <year>2009</year>;<volume>2</volume>(<issue>2</issue>):<fpage>119</fpage>&#x02013;<lpage>38</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/17509840802641372</pub-id></mixed-citation></ref><ref id="pone.0324159.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Mann</surname><given-names>DTY</given-names></name>, <name><surname>Williams</surname><given-names>AM</given-names></name>, <name><surname>Ward</surname><given-names>P</given-names></name>, <name><surname>Janelle</surname><given-names>CM</given-names></name>. <article-title>Perceptual-cognitive expertise in sport: a meta-analysis</article-title>. <source>J Sport Exerc Psychol</source>. <year>2007</year>;<volume>29</volume>(<issue>4</issue>):<fpage>457</fpage>&#x02013;<lpage>78</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1123/jsep.29.4.457</pub-id>
<pub-id pub-id-type="pmid">17968048</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Williams</surname><given-names>AM</given-names></name>, <name><surname>Davids</surname><given-names>K</given-names></name>. <article-title>Visual search strategy, selective attention, and expertise in soccer</article-title>. <source>Res Q Exerc Sport</source>. <year>1998</year>;<volume>69</volume>(<issue>2</issue>):<fpage>111</fpage>&#x02013;<lpage>28</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/02701367.1998.10607677</pub-id>
<pub-id pub-id-type="pmid">9635326</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Richlan</surname><given-names>F</given-names></name>, <name><surname>Wei&#x000df;</surname><given-names>M</given-names></name>, <name><surname>Kastner</surname><given-names>P</given-names></name>, <name><surname>Braid</surname><given-names>J</given-names></name>. <article-title>Virtual training, real effects: a narrative review on sports performance enhancement through interventions in virtual reality</article-title>. <source>Front Psychol</source>. <year>2023</year>;<volume>14</volume>:<fpage>1240790</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fpsyg.2023.1240790</pub-id>
<pub-id pub-id-type="pmid">37928573</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>D&#x000fc;king</surname><given-names>P</given-names></name>, <name><surname>Holmberg</surname><given-names>H-C</given-names></name>, <name><surname>Sperlich</surname><given-names>B</given-names></name>. <article-title>The potential usefulness of virtual reality systems for athletes: a short SWOT analysis</article-title>. <source>Front Physiol</source>. <year>2018</year>;<volume>9</volume>:<fpage>128</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fphys.2018.00128</pub-id>
<pub-id pub-id-type="pmid">29551978</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Burdea</surname><given-names>G</given-names></name>, <name><surname>Coiffet</surname><given-names>P</given-names></name>. <article-title>Virtual reality technology</article-title>. <source>Presence</source>. <year>2003</year>;<volume>12</volume>(<issue>6</issue>):<fpage>663</fpage>&#x02013;<lpage>4</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/105474603322955950</pub-id></mixed-citation></ref><ref id="pone.0324159.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Romeas</surname><given-names>T</given-names></name>, <name><surname>Chaumillon</surname><given-names>R</given-names></name>, <name><surname>Labb&#x000e9;</surname><given-names>D</given-names></name>, <name><surname>Faubert</surname><given-names>J</given-names></name>. <article-title>Combining 3D-MOT with sport decision-making for perceptual-cognitive training in virtual reality</article-title>. <source>Percept Mot Skills</source>. <year>2019</year>;<volume>126</volume>(<issue>5</issue>):<fpage>922</fpage>&#x02013;<lpage>48</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/0031512519860286</pub-id>
<pub-id pub-id-type="pmid">31272277</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Thorp</surname><given-names>SO</given-names></name>, <name><surname>Rimol</surname><given-names>LM</given-names></name>, <name><surname>Lervik</surname><given-names>S</given-names></name>, <name><surname>Evensmoen</surname><given-names>HR</given-names></name>, <name><surname>Grassini</surname><given-names>S</given-names></name>. <article-title>Comparative analysis of spatial ability in immersive and non-immersive virtual reality: the role of sense of presence, simulation sickness and cognitive load</article-title>. <source>Front Virtual Real</source>. <year>2024</year>;<volume>5</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/frvir.2024.1343872</pub-id></mixed-citation></ref><ref id="pone.0324159.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Shevchuk</surname><given-names>O</given-names></name>, <name><surname>Bululukov</surname><given-names>O</given-names></name>, <name><surname>Lysodyed</surname><given-names>O</given-names></name>, <name><surname>Mamonova</surname><given-names>V</given-names></name>, <name><surname>Matat</surname><given-names>Y</given-names></name>. <article-title>&#x0041d;uman right to virtual reality in the healthcare: legal issues and enforcement problems</article-title>. <source>TBJ</source>. <year>2021</year>;<volume>11</volume>(special). <comment>doi: </comment><pub-id pub-id-type="doi">10.24818/tbj/2021/11/sp/03</pub-id></mixed-citation></ref><ref id="pone.0324159.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Li</surname><given-names>S</given-names></name>, <name><surname>Guo</surname><given-names>J</given-names></name>, <name><surname>Chai</surname><given-names>G</given-names></name>, <name><surname>Cao</surname><given-names>C</given-names></name>. <article-title>The application of virtual reality technology in sports psychology: theory, practice, and prospect</article-title>. <source>Comput Intell Neurosci</source>. <year>2022</year>;<volume>2022</volume>:<fpage>5941395</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1155/2022/5941395</pub-id>
<pub-id pub-id-type="pmid">35990140</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Lopez Ma&#x000ef;t&#x000e9;</surname><given-names>C</given-names></name>, <name><surname>Ga&#x000e9;tane</surname><given-names>D</given-names></name>, <name><surname>Axel</surname><given-names>C</given-names></name>. <article-title>Ecological assessment of divided attention: what about the current tools and the relevancy of virtual reality</article-title>. <source>Rev Neurol (Paris)</source>. <year>2016</year>;<volume>172</volume>(4&#x02013;5):<fpage>270</fpage>&#x02013;<lpage>80</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neurol.2016.01.399</pub-id>
<pub-id pub-id-type="pmid">27108241</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Pag&#x000e9;</surname><given-names>C</given-names></name>, <name><surname>Bernier</surname><given-names>P-M</given-names></name>, <name><surname>Trempe</surname><given-names>M</given-names></name>. <article-title>Using video simulations and virtual reality to improve decision-making skills in basketball</article-title>. <source>J Sports Sci</source>. <year>2019</year>;<volume>37</volume>(<issue>21</issue>):<fpage>2403</fpage>&#x02013;<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/02640414.2019.1638193</pub-id>
<pub-id pub-id-type="pmid">31280685</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Parsey</surname><given-names>CM</given-names></name>, <name><surname>Schmitter-Edgecombe</surname><given-names>M</given-names></name>. <article-title>Applications of technology in neuropsychological assessment</article-title>. <source>Clin Neuropsychol</source>. <year>2013</year>;<volume>27</volume>(<issue>8</issue>):<fpage>1328</fpage>&#x02013;<lpage>61</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/13854046.2013.834971</pub-id>
<pub-id pub-id-type="pmid">24041037</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>McKay</surname><given-names>AKA</given-names></name>, <name><surname>Stellingwerff</surname><given-names>T</given-names></name>, <name><surname>Smith</surname><given-names>ES</given-names></name>, <name><surname>Martin</surname><given-names>DT</given-names></name>, <name><surname>Mujika</surname><given-names>I</given-names></name>, <name><surname>Goosey-Tolfrey</surname><given-names>VL</given-names></name>, <etal>et al</etal>. <article-title>Defining training and performance caliber: a participant classification framework</article-title>. <source>Int J Sports Physiol Perform</source>. <year>2022</year>;<volume>17</volume>(<issue>2</issue>):<fpage>317</fpage>&#x02013;<lpage>31</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1123/ijspp.2021-0451</pub-id>
<pub-id pub-id-type="pmid">34965513</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Kaernbach</surname><given-names>C</given-names></name>. <article-title>Simple adaptive testing with the weighted up-down method</article-title>. <source>Percept Psychophys</source>. <year>1991</year>;<volume>49</volume>(<issue>3</issue>):<fpage>227</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3758/bf03214307</pub-id>
<pub-id pub-id-type="pmid">2011460</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Cornsweet</surname><given-names>TN</given-names></name>. <article-title>The staircase-method in psychophysics</article-title>. <source>Am J Psychol</source>. <year>1962</year>;<volume>75</volume>(<issue>3</issue>):<fpage>485</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2307/1419876</pub-id><pub-id pub-id-type="pmid">13881416</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Langenecker</surname><given-names>SA</given-names></name>, <name><surname>Zubieta</surname><given-names>J-K</given-names></name>, <name><surname>Young</surname><given-names>EA</given-names></name>, <name><surname>Akil</surname><given-names>H</given-names></name>, <name><surname>Nielson</surname><given-names>KA</given-names></name>. <article-title>A task to manipulate attentional load, set-shifting, and inhibitory control: convergent validity and test-retest reliability of the Parametric Go/No-Go Test</article-title>. <source>J Clin Exp Neuropsychol</source>. <year>2007</year>;<volume>29</volume>(<issue>8</issue>):<fpage>842</fpage>&#x02013;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/13803390601147611</pub-id>
<pub-id pub-id-type="pmid">17852593</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Cohen</surname><given-names>J</given-names></name>. <article-title>A power primer</article-title>. <source>Psychol Bull</source>. <year>1992</year>;<volume>112</volume>(<issue>1</issue>):<fpage>155</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037//0033-2909.112.1.155</pub-id>
<pub-id pub-id-type="pmid">19565683</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Swets</surname><given-names>JA</given-names></name>. <article-title>Measuring the accuracy of diagnostic systems</article-title>. <source>Science</source>. <year>1988</year>;<volume>240</volume>(<issue>4857</issue>):<fpage>1285</fpage>&#x02013;<lpage>93</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1126/science.3287615</pub-id>
<pub-id pub-id-type="pmid">3287615</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Fischer</surname><given-names>JE</given-names></name>, <name><surname>Bachmann</surname><given-names>LM</given-names></name>, <name><surname>Jaeschke</surname><given-names>R</given-names></name>. <article-title>A readers&#x02019; guide to the interpretation of diagnostic test properties: clinical example of sepsis</article-title>. <source>Intensive Care Med</source>. <year>2003</year>;<volume>29</volume>(<issue>7</issue>):<fpage>1043</fpage>&#x02013;<lpage>51</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00134-003-1761-8</pub-id>
<pub-id pub-id-type="pmid">12734652</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Mann</surname><given-names>DTY</given-names></name>, <name><surname>Williams</surname><given-names>AM</given-names></name>, <name><surname>Ward</surname><given-names>P</given-names></name>, <name><surname>Janelle</surname><given-names>CM</given-names></name>. <article-title>Perceptual-cognitive expertise in sport: a meta-analysis</article-title>. <source>J Sport Exerc Psychol</source>. <year>2007</year>;<volume>29</volume>(<issue>4</issue>):<fpage>457</fpage>&#x02013;<lpage>78</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1123/jsep.29.4.457</pub-id>
<pub-id pub-id-type="pmid">17968048</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>HJ</given-names></name>, <name><surname>Zhang</surname><given-names>Q</given-names></name>, <name><surname>Chen</surname><given-names>S</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Li</surname><given-names>J</given-names></name>. <article-title>A meta-analysis of performance advantages on athletes in multiple object tracking tasks</article-title>. <source>Sci Rep</source>. <year>2024</year>;<volume>14</volume>(<issue>1</issue>):<fpage>20086</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-024-70793-w</pub-id>
<pub-id pub-id-type="pmid">39209919</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Voss</surname><given-names>MW</given-names></name>, <name><surname>Kramer</surname><given-names>AF</given-names></name>, <name><surname>Basak</surname><given-names>C</given-names></name>, <name><surname>Prakash</surname><given-names>RS</given-names></name>, <name><surname>Roberts</surname><given-names>B</given-names></name>. <article-title>Are expert athletes &#x02018;expert&#x02019; in the cognitive laboratory? A meta&#x02010;analytic review of cognition and sport expertise</article-title>. <source>Appl Cogn Psychol</source>. <year>2009</year>;<volume>24</volume>(<issue>6</issue>):<fpage>812</fpage>&#x02013;<lpage>26</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/acp.1588</pub-id></mixed-citation></ref><ref id="pone.0324159.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Drew</surname><given-names>T</given-names></name>, <name><surname>Horowitz</surname><given-names>TS</given-names></name>, <name><surname>Vogel</surname><given-names>EK</given-names></name>. <article-title>Swapping or dropping? Electrophysiological measures of difficulty during multiple object tracking</article-title>. <source>Cognition</source>. <year>2013</year>;<volume>126</volume>(<issue>2</issue>):<fpage>213</fpage>&#x02013;<lpage>23</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cognition.2012.10.003</pub-id>
<pub-id pub-id-type="pmid">23141025</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Bettencourt</surname><given-names>KC</given-names></name>, <name><surname>Somers</surname><given-names>DC</given-names></name>. <article-title>Effects of target enhancement and distractor suppression on multiple object tracking capacity</article-title>. <source>J Vis</source>. <year>2009</year>;<volume>9</volume>(<issue>7</issue>):<fpage>9</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1167/9.7.9</pub-id>
<pub-id pub-id-type="pmid">19761324</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Meyerhoff</surname><given-names>H</given-names></name>, <name><surname>Papenmeier</surname><given-names>F</given-names></name>, <name><surname>Jahn</surname><given-names>G</given-names></name>, <name><surname>Huff</surname><given-names>M</given-names></name>. <article-title>Exploring the temporal dynamics of attentional reallocations with the multiple object tracking paradigm</article-title>. <source>J Vis</source>. <year>2016</year>;<volume>16</volume>(<issue>12</issue>):<fpage>1262</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1167/16.12.1262</pub-id></mixed-citation></ref><ref id="pone.0324159.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Oksama</surname><given-names>L</given-names></name>, <name><surname>Hy&#x000f6;n&#x000e4;</surname><given-names>J</given-names></name>. <article-title>Is multiple object tracking carried out automatically by an early vision mechanism independent of higher&#x02010;order cognition? An individual difference approach</article-title>. <source>Vis Cogn</source>. <year>2004</year>;<volume>11</volume>(<issue>5</issue>):<fpage>631</fpage>&#x02013;<lpage>71</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/13506280344000473</pub-id></mixed-citation></ref><ref id="pone.0324159.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Duncan</surname><given-names>J</given-names></name>. <article-title>Selective attention and the organization of visual information</article-title>. <source>J Exp Psychol Gen</source>. <year>1984</year>;<volume>113</volume>(<issue>4</issue>):<fpage>501</fpage>&#x02013;<lpage>17</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1037//0096-3445.113.4.501</pub-id>
<pub-id pub-id-type="pmid">6240521</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Chun</surname><given-names>MM</given-names></name>, <name><surname>Golomb</surname><given-names>JD</given-names></name>, <name><surname>Turk-Browne</surname><given-names>NB</given-names></name>. <article-title>A taxonomy of external and internal attention</article-title>. <source>Annu Rev Psychol</source>. <year>2011</year>;<volume>62</volume>:<fpage>73</fpage>&#x02013;<lpage>101</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1146/annurev.psych.093008.100427</pub-id>
<pub-id pub-id-type="pmid">19575619</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref041"><label>41</label><mixed-citation publication-type="journal"><name><surname>Hahn</surname><given-names>B</given-names></name>, <name><surname>Wolkenberg</surname><given-names>FA</given-names></name>, <name><surname>Ross</surname><given-names>TJ</given-names></name>, <name><surname>Myers</surname><given-names>CS</given-names></name>, <name><surname>Heishman</surname><given-names>SJ</given-names></name>, <name><surname>Stein</surname><given-names>DJ</given-names></name>, <etal>et al</etal>. <article-title>Divided versus selective attention: evidence for common processing mechanisms</article-title>. <source>Brain Res</source>. <year>2008</year>;<volume>1215</volume>:<fpage>137</fpage>&#x02013;<lpage>46</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.brainres.2008.03.058</pub-id>
<pub-id pub-id-type="pmid">18479670</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Rahimi</surname><given-names>A</given-names></name>, <name><surname>Roberts</surname><given-names>SD</given-names></name>, <name><surname>Baker</surname><given-names>JR</given-names></name>, <name><surname>Wojtowicz</surname><given-names>M</given-names></name>. <article-title>Attention and executive control in varsity athletes engaging in strategic and static sports</article-title>. <source>PLoS One</source>. <year>2022</year>;<volume>17</volume>(<issue>4</issue>):e0266933. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0266933</pub-id>
<pub-id pub-id-type="pmid">35452468</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Meng</surname><given-names>F-W</given-names></name>, <name><surname>Yao</surname><given-names>Z-F</given-names></name>, <name><surname>Chang</surname><given-names>EC</given-names></name>, <name><surname>Chen</surname><given-names>Y-L</given-names></name>. <article-title>Team sport expertise shows superior stimulus-driven visual attention and motor inhibition</article-title>. <source>PLoS One</source>. <year>2019</year>;<volume>14</volume>(<issue>5</issue>):e0217056. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0217056</pub-id>
<pub-id pub-id-type="pmid">31091297</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Green</surname><given-names>CS</given-names></name>, <name><surname>Bavelier</surname><given-names>D</given-names></name>. <article-title>Enumeration versus multiple object tracking: the case of action video game players</article-title>. <source>Cognition</source>. <year>2006</year>;<volume>101</volume>(<issue>1</issue>):<fpage>217</fpage>&#x02013;<lpage>45</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cognition.2005.10.004</pub-id>
<pub-id pub-id-type="pmid">16359652</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref045"><label>45</label><mixed-citation publication-type="journal"><name><surname>Akarsu</surname><given-names>S</given-names></name>, <name><surname>&#x000c7;ali&#x0015f;kan</surname><given-names>E</given-names></name>, <name><surname>Dane</surname><given-names>&#x0015e;</given-names></name>. <article-title>Athletes have faster eye-hand visual reaction times and higher scores on visuospatial intelligence than nonathletes</article-title>. <source>Turk J Med Sci</source>. <year>2009</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3906/sag-0809-44</pub-id></mixed-citation></ref><ref id="pone.0324159.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Shumski</surname><given-names>EJ</given-names></name>, <name><surname>Anderson</surname><given-names>MN</given-names></name>, <name><surname>Oh</surname><given-names>J</given-names></name>, <name><surname>Schmidt</surname><given-names>JD</given-names></name>, <name><surname>Lynall</surname><given-names>RC</given-names></name>. <article-title>Computerized and functional reaction time in varsity-level female collegiate athletes with and without a concussion history</article-title>. <source>J Sci Med Sport</source>. <year>2023</year>;<volume>26</volume>(<issue>3</issue>):<fpage>189</fpage>&#x02013;<lpage>94</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jsams.2023.02.008</pub-id>
<pub-id pub-id-type="pmid">36906428</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Fields</surname><given-names>RD</given-names></name>. <article-title>A new mechanism of nervous system plasticity: activity-dependent myelination</article-title>. <source>Nat Rev Neurosci</source>. <year>2015</year>;<volume>16</volume>(<issue>12</issue>):<fpage>756</fpage>&#x02013;<lpage>67</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nrn4023</pub-id>
<pub-id pub-id-type="pmid">26585800</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Linford</surname><given-names>CW</given-names></name>, <name><surname>Hopkins</surname><given-names>JT</given-names></name>, <name><surname>Schulthies</surname><given-names>SS</given-names></name>, <name><surname>Freland</surname><given-names>B</given-names></name>, <name><surname>Draper</surname><given-names>DO</given-names></name>, <name><surname>Hunter</surname><given-names>I</given-names></name>. <article-title>Effects of neuromuscular training on the reaction time and electromechanical delay of the peroneus longus muscle</article-title>. <source>Arch Phys Med Rehabil</source>. <year>2006</year>;<volume>87</volume>(<issue>3</issue>):<fpage>395</fpage>&#x02013;<lpage>401</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.apmr.2005.10.027</pub-id>
<pub-id pub-id-type="pmid">16500175</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Tymofiyeva</surname><given-names>O</given-names></name>, <name><surname>Gaschler</surname><given-names>R</given-names></name>. <article-title>Training-induced neural plasticity in youth: a systematic review of structural and functional MRI studies</article-title>. <source>Front Hum Neurosci</source>. <year>2021</year>;<volume>14</volume>:<fpage>497245</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fnhum.2020.497245</pub-id>
<pub-id pub-id-type="pmid">33536885</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Kuang</surname><given-names>S</given-names></name>. <article-title>Is reaction time an index of white matter connectivity during training?</article-title>
<source>Cogn Neurosci</source>. <year>2017</year>;<volume>8</volume>(<issue>2</issue>):<fpage>126</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/17588928.2016.1205575</pub-id>
<pub-id pub-id-type="pmid">27472472</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Seidel-Marzi</surname><given-names>O</given-names></name>, <name><surname>Ragert</surname><given-names>P</given-names></name>. <article-title>Neurodiagnostics in sports: investigating the athlete&#x02019;s brain to augment performance and sport-specific skills</article-title>. <source>Front Hum Neurosci</source>. <year>2020</year>;<volume>14</volume>:<fpage>133</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fnhum.2020.00133</pub-id>
<pub-id pub-id-type="pmid">32327988</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref052"><label>52</label><mixed-citation publication-type="book"><name><surname>Morris</surname><given-names>RG</given-names></name>, <name><surname>Hebb</surname><given-names>DO</given-names></name>. <source>The organization of behavior</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1949</year>. Brain Res Bull. 1999;50(5&#x02013;6):437. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/s0361-9230(99)00182-3</pub-id></mixed-citation></ref><ref id="pone.0324159.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Will</surname><given-names>B</given-names></name>, <name><surname>Dalrymplealford</surname><given-names>J</given-names></name>, <name><surname>Wolff</surname><given-names>M</given-names></name>, <name><surname>Cassel</surname><given-names>J</given-names></name>. <article-title>The concept of brain plasticity &#x02013; Paillard&#x02019;s systemic analysis and emphasis on structure and function. (followed by the translation of a seminal paper by Paillard on plasticity)</article-title>. <source>Behavioural Brain Research</source>. <year>2007</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.bbr.2007.11.008</pub-id></mixed-citation></ref><ref id="pone.0324159.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Mandolesi</surname><given-names>L</given-names></name>, <name><surname>Polverino</surname><given-names>A</given-names></name>, <name><surname>Montuori</surname><given-names>S</given-names></name>, <name><surname>Foti</surname><given-names>F</given-names></name>, <name><surname>Ferraioli</surname><given-names>G</given-names></name>, <name><surname>Sorrentino</surname><given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Effects of physical exercise on cognitive functioning and wellbeing: biological and psychological benefits</article-title>. <source>Front Psychol</source>. <year>2018</year>;<volume>9</volume>:<fpage>509</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fpsyg.2018.00509</pub-id>
<pub-id pub-id-type="pmid">29755380</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Vignais</surname><given-names>N</given-names></name>, <name><surname>Kulpa</surname><given-names>R</given-names></name>, <name><surname>Brault</surname><given-names>S</given-names></name>, <name><surname>Presse</surname><given-names>D</given-names></name>, <name><surname>Bideau</surname><given-names>B</given-names></name>. <article-title>Which technology to investigate visual perception in sport: video vs. virtual reality</article-title>. <source>Hum Mov Sci</source>. <year>2015</year>;<volume>39</volume>:<fpage>12</fpage>&#x02013;<lpage>26</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.humov.2014.10.006</pub-id>
<pub-id pub-id-type="pmid">25461430</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>Bideau</surname><given-names>B</given-names></name>, <name><surname>Multon</surname><given-names>F</given-names></name>, <name><surname>Kulpa</surname><given-names>R</given-names></name>, <name><surname>Fradet</surname><given-names>L</given-names></name>, <name><surname>Arnaldi</surname><given-names>B</given-names></name>, <name><surname>Delamarche</surname><given-names>P</given-names></name>. <article-title>Using virtual reality to analyze links between handball thrower kinematics and goalkeeper&#x02019;s reactions</article-title>. <source>Neurosci Lett</source>. <year>2004</year>;<volume>372</volume>(1&#x02013;2):<fpage>119</fpage>&#x02013;<lpage>22</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neulet.2004.09.023</pub-id>
<pub-id pub-id-type="pmid">15531100</pub-id>
</mixed-citation></ref><ref id="pone.0324159.ref057"><label>57</label><mixed-citation publication-type="journal"><name><surname>Romeas</surname><given-names>T</given-names></name>, <name><surname>Guldner</surname><given-names>A</given-names></name>, <name><surname>Faubert</surname><given-names>J</given-names></name>. <article-title>3D-multiple object tracking training task improves passing decision-making accuracy in soccer players</article-title>. <source>Psychol Sport Exerc</source>. <year>2016</year>;<volume>22</volume>:<fpage>1</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.psychsport.2015.06.002</pub-id></mixed-citation></ref></ref-list></back></article>